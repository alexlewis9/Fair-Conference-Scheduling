Published as a conference paper at ICLR 2022
ASYMMETRY
LEARNING
FOR
COUNTERFACTUAL-
INVARIANT CLASSIFICATION IN OOD TASKS
S Chandra Mouli
Department of Computer Science
Purdue University
chandr@purdue.edu
Bruno Ribeiro
Department of Computer Science
Purdue University
ribeiro@cs.purdue.edu
ABSTRACT
Generalizing from observed to new related environments (out-of-distribution) is
central to the reliability of classiﬁers. However, most classiﬁers fail to predict
label Y from input X when the change in environment is due a (stochastic) input
transformation T te ˝ X1 not observed in training, as in training we observe T tr ˝ X1,
where X1 is a hidden variable. This work argues that when the transformations
in train T tr and test T te are (arbitrary) symmetry transformations induced by a
collection of known m equivalence relations, the task of ﬁnding a robust OOD
classiﬁer can be deﬁned as ﬁnding the simplest causal model that deﬁnes a causal
connection between the target labels and the symmetry transformations that are
associated with label changes. We then propose a new learning paradigm, asymme-
try learning, that identiﬁes which symmetries the classiﬁer must break in order to
correctly predict Y in both train and test. Asymmetry learning performs a causal
model search that, under certain identiﬁability conditions, ﬁnds classiﬁers that
perform equally well in-distribution and out-of-distribution. Finally, we show how
to learn counterfactually-invariant representations with asymmetry learning in two
simulated physics tasks and six image classiﬁcation tasks.
1
INTRODUCTION
A signiﬁcant challenge in classiﬁcation tasks happens when the test distribution differs from the
training distribution (i.e., the task requires out-of-distribution (OOD) generalization), since not
accounting for the distribution shift can lead to poor generalization accuracy (Geirhos et al., 2020;
Hu et al., 2020; Koh et al., 2020; D’Amour et al., 2020). If the learner sees examples from the
test distribution, ﬁnding a classiﬁer invariant to the distribution shift can still be a data-driven
task (e.g., classical domain adaptation Ben-David et al. (2007); Muandet et al. (2013); Zhao et al.
(2019)). This includes cases such as invariant risk minimization (Arjovsky et al., 2019) and its
generalizations (Bellot & van der Schaar, 2020), where the training data and the test data distributions
overlap in a way that can be exploited by data-driven algorithms (Creager et al., 2021; Krueger et al.,
2021; Rosenfeld et al., 2020).
However, if the learner sees no examples from the test distribution, the task is not purely data-driven
and requires assumptions about the data generation process. More formally, our work considers
general OOD tasks with training distribution PpY tr, Xtrq, where Xtr :“ T tr ˝ X:, with X: as a
hidden variable with distribution PpX:q and T tr P T is a random input transformation in training
T tr : X Ñ X, where t ˝ x is the application of transformation t P T on x P X. The difference
between train and test is a change in input transformation with Y te :“ Y tr and Xte :“ T te ˝ X:,
where PpT trq ‰ PpT teq. We are interested in learning an invariant classiﬁer that generalizes well in
held out examples from the training and test distributions.
The deﬁnition of transformation matters in this task. We ﬁrst seek to generalize the existing literature
on transformation invariances, e.g. (Shawe-Taylor, 1993; Kondor & Trivedi, 2018; Finzi et al., 2021;
Maron et al., 2018; Murphy et al., 2019b; Mouli & Ribeiro, 2021; Bronstein et al., 2017). Our
transformations are tied to equivalence relations rather than transformation groups, which frees them
from the need to have inverses (in order to form a transformation group). Our transformations may
not have inverses.
1

Published as a conference paper at ICLR 2022
We also explain why the task of learning an invariant OOD classiﬁer is not, in general, solvable via
traditional data augmentation. Before we continue describing our OOD learning task, it is important
to clarify the connection between Pearl’s causal hierarchy and invariant representation learning.
Pearl’s causal hierarchy and invariant representation learning.
Pearl’s causal hierarchy (Pearl
& Mackenzie, 2018; Bareinboim et al., 2020)) has three layers: Observational (Layer 1), interventional
(Layer 2), and counterfactual (Layer 3). Upper layers can perform lower layer tasks, but not vice-versa
(see Bareinboim et al. (2020)). Tasks should be described using the lowest layer that can solve them.
Layer 1: Any task that can be performed without constraints on the causal model, i.e., by data alone,
is observational (Layer 1). Traditional domain adaptation is a Layer 1 task. Note that a classiﬁer that
performs well OOD is itself a Layer 1 classiﬁer, since it tries to predict PpY te|Xteq.
Layer 2: Without observations from PpXteq and/or PpY te|Xteq, learning an OOD classiﬁer requires
some assumptions about the data generation process (Layers 2 or 3 assumptions). Data augmentation
is traditionally an interventional task (Layer 2), with new interesting methods increasingly using
causal language (Ilse et al., 2021; Teney et al., 2020). For instance, in a task predicting an image’s
foreground, knowing how to act on an image in training Xtr to change the background seen in training
to the backgrounds seen in test Xte “ T ˝ Xtr with a transformation T, implies we know how to
predict PpY |X, dopTqq.
Layer 3: Counterfactuals are the most challenging task. We start our description with an example.
Consider a random continuous transformation T tr
2 (in training) which changes to random transfor-
mation T te
2 (in test). Let X: describe a hidden variable such that Xtr :“ T1 ˝ T tr
2 ˝ T3 ˝ X: and
Xte :“ T1 ˝ T te
2 ˝ T3 ˝ X:, where T1 and T3 are independent continuous random transformations and
PpT tr
2 q ‰ PpT te
2 q. Assume the target variable Y depends only on X:, T1, and T3. To counterfactually
ask what would have happened to the observed input x if we had forced dopT tr
2 “ ˜t2q, we are
inquiring about XpT tr
2 “ ˜t2q|Xtr “ x. Note that dopT tr
2 “ ˜t2q does not change Y . Also note that the
knowledge of Xtr “ x is an indirect statement about T tr
2 since PpT tr
2 |Xtr “ xq ‰ PpT tr
2 q. That is,
for x, x1 P X,
PpXpT tr
2 “ ˜t2q “ x1|Xtr “ xq “
ż
t
PpXpT tr
2 “ ˜t2q “ x1|T tr
2 “ t, Xtr “ xqdPpT tr
2 “ t|Xtr “ xq.
(1)
Equation (1) and the difference between the causal hierarchy layers will be relevant for our results.
Contributions.
Our contributions can be described as follows:
1. We introduce a generalization of transformation groups via symmetry transformations tied to equiv-
alence classes that removes the requirement of invertible transformations common in deﬁnitions
using transformation groups.
2. We introduce the concept of counterfactual invariant representations for symmetry transformations
and show how it can be described as a counterfactual task for causal structure discovery.
3. Finally, we introduce asymmetry learning, which describes a representation regularization that,
under a set of assumptions, learns the correct counterfactual invariant OOD classiﬁer.
2
SYMMETRIES AND TRANSFORMATIONS
Geometrically, an object is called symmetric if there is a transformation on the object that does not
change its shape (in some deﬁnition of shape). For example, a square is symmetric with respect to
rotations. The notion of symmetry however is not restricted to geometric notions. In general, we
can deﬁne a mathematical object as symmetric if there is a transformation on the object that returns
another object equivalent to the ﬁrst (Rosen, 2008, Chapter 10). It is clear from this deﬁnition of
symmetry that we ﬁrst need to deﬁne what we mean by equivalent objects. For instance, we say two
geometrical objects are equivalent if they have the same shape, but we need a more general deﬁnition.
We deﬁne an input symmetry in a space X with at least two elements as an equivalence relation „.
An equivalence relation in X is a binary relation „ such that for all a, b, c P X, we have (i) a „ a,
(ii) a „ b ðñ b „ a, and (iii) (a „ b and b „ cq ùñ a „ c. Equivalence relations allow us to
2

Published as a conference paper at ICLR 2022
deﬁne equivalent objects in X: a „ b means a is equivalent to b. The set of all objects equivalent to
some a P X is called the equivalence class of a, deﬁned as ras :“ tx P X : x „ au. Note that
one can deﬁne m ě 2 equivalence relations on the same input space. The equivalence class of x
with respect to equivalence relation k is denoted rxspkq, k “ 1, . . . , m. Two inputs a, b P X might
be equivalent under one equivalence relation „1, but not equivalent under a different equivalence
relation „2, that is, we can have both b P rasp1q and b R rasp2q. Still, even in this last case it is
possible that a is equivalent to some other input c ‰ b in both equivalence relations, i.e., it is possible
Dc P X, c ‰ a, s.t. c P rasp1q X rasp2q. We denote the collection of equivalence classes of X under
the equivalence relation „k as the quotient space X{ „k:“ trxspkq | x P Xu.
Transformation group example. Consider the bijective transformations t : X Ñ X of a transformation
group G, t P G. We now deﬁne an equivalence relation over G as t ˝ x „G x for all t P G. The
equivalence class rxspGq is x’s orbit deﬁned as rxspGq :“ tx1 : Dt P G, x1 “ t ˝ xu. For example, if
G is the group that permutes the elements of vectors in R3, then p1, 2, 3q „G p2, 1, 3q.
Property functions example. Another way of deriving an equivalence relation is via functions of the
input space z : X Ñ Rp, where the output zpxq is a particular property of the vector x P X. For
example, given an observation of length T from a dynamical system, x P RdˆT , a possible property
function could be zenergyp¨q that computes the energy of the dynamical system. Assuming there are
m known properties z1, . . . , zm with zi : X Ñ Rpi, we can construct corresponding equivalence
relations „1, . . . , „m such that for any x, x1 P X, x „i x1 if zjpxq “ zjpx1q, @j ‰ i. In words, two
inputs are equivalent under „i if they have the same properties for all zj, j ‰ i.
Symmetry transformations. As seen above, symmetries can be deﬁned without deﬁning how the
input is transformed to create the equivalence classes, although deﬁning a set of transformations is
useful when describing the equivalence class. Given an equivalence relation „, we can deﬁne a set of
transformations T that respect the equivalence relation such that @t P T , @x P X, t ˝ x „ x. We call
T the set of symmetry transformations of „. Similar to transformations groups, T always has the
identity transformation tid ˝ x “ x, but in contrast, all the transformations in T need not be bijective.
Join of equivalence relations. Similar to how two groups can be joined to form a larger group, two
equivalence relations can be joined to form a coarser equivalence relation. Given two equivalence
relations, „1 and „2, their join „1 _ „2 is deﬁned as: for all x, x1, xp„1 _ „2qx1 if and only if
there exists a chain of equivalence relations x „k1 x1,
. . . , xh´1 „kh x1 with all kj P t1, 2u. It
is easy to check that „1 _ „2 is an equivalence relation.
We are now ready to deﬁne a general causal model that deﬁnes the training and test distributions in
our setting.
3
SCM FOR SYMMETRY-BASED OOD TASKS
Let X, Y denote the input and output spaces respectively. We deﬁne our general structural causal
model (SCM) as follows. We deﬁne X: P X as the unobserved canonically ordered input
X: :“ gpUuq ,
(2)
with Uu a background random variable and g : Uu Ñ X is a measurable map. This deﬁnition is
general enough to deﬁne any task.
There are m possible symmetries given in the form of equivalence relations „1, . . . , „m over the
input space X. Let T pkq denote a set of symmetric transformations t on X corresponding to the
equivalence relation „k, 1 ď k ď m. In other words, for all x P X and t P T pkq, we have
pt ˝ xq „k x. Similarly, let T be the set of all symmetric transformations with respect to the
join equivalence relation „1,...,m”„1 _ . . . _ „m. We can think of transformation t P T as a
path x
tpk1q
ÝÝÝÑ x1 ¨ ¨ ¨ xh´1
tpkhq
ÝÝÝÑ xh that starts at x, applies a transformation tpk1q P T pk1q to get
x1 P rxspk1q, and so on until it stops and outputs a value xh, h ě 1.
Let U1, . . . , Um be independent background variables associated with the m symmetries, where
Ui P Ui, i “ 1, . . . , m. These background variables together select a function tpU1, . . . , Umq
from the set T as follows. Each Uk independently selects a countable sequence of transformations
tpkq
1,Uk, tpkq
2,Uk, . . . P T pkq. Then, tpU1, . . . , Umq is deﬁned by interleaving these transformations
3

Published as a conference paper at ICLR 2022
Training data
Traditional data augmentation
(a)
Counterfactual data
(c)
(d)
Test data (1 example)
(b)
...
...
...
Counterfactual inputs
we must be invariant to
...
Figure 1: Example that illustrates a few important concepts. (a) Training data shows how Equations (2) to (4)
deﬁne the training distribution PpXtr, Y trq. Task: Given an image of a rod (shown in brown), we wish to
predict the orientation of the rod, i.e., whether the rod is upright or ﬂat (Y :“ hpUrotq). In this example, we
have D “ trotu (image rotations 0˝ and 90˝) and sD “ ttransu (horizontal translations of ´5, 0, `5 units) as
any horizontal translation does not affect the orientation of the rod. (b) The test data (only a single example
shown) suffers an OOD shift through a different distribution over PpUtransq, where non-zero translations can
happen before the second rotation. (c) Here we illustrate why an invariance that is good for traditional data
augmentation, such as counting the brown pixels in the green shaded area, would fail in test if, say, a `5 units
horizontal translation happens before a rotation. (d) Here we illustrate why counterfactual language is needed
to deﬁne how the input data would change in the presence of changes to Utrans. Using counterfactuals, it is
ﬁnally clear that the invariant representation must be able to also consider the number of brown pixels inside the
horizontal purple and green bands (among other horizontal bands).
tpU1, . . . , Umq :“ ptp1q
1,U1 ˝¨ ¨ ¨˝tpmq
1,Umq˝¨ ¨ ¨˝ptp1q
r,U1 ˝¨ ¨ ¨˝tpmq
r,Umq˝¨ ¨ ¨ to construct the path described
above. Since T p1q, T p2q, . . . contain the identity transformation, tpU1, . . . , Umq can be described by
a ﬁnite sequences of transformations. The observed X is the result of a transformation of X:
X :“ tpU1, . . . , Umq ˝ X: .
(3)
Finally, the label Y is deﬁned as a function of the untransformed canonical input X: as
Y :“ hpX:, pUiqiPD, UY q ,
(4)
where D Ď t1, . . . , mu is unknown. This means that Y is not invariant with respect to equivalence
relations „i, i P D, i.e., examples x and x1 P rxspiq can have different labels. A distribution over the
variables Uu, tUium
i“1, UY entails a joint distribution PpX, Y q over the observed variables.
Illustrative SCM example.
Figure 1 illustrates our data generation process. The training data
Figure 1(a) has X: deﬁned as a centered upright brown rod (i.e., X: is deterministic). The label Y
is deﬁned by the rotation transformations T rot “ tT rot
0˝ , T rot
90˝u. The image can also be horizontally
translated by t´5, 0, 5u units via transformations T trans “ tT trans
´5 , T trans
0
, T trans
`5 u (only 0 and `5
translations are depicted), but Y does not depend on these horizontal translations. The transforma-
tions applied to X: are randomly chosen via Urot and Utrans, which are two bidimensional vectors
indexing a sequence four transformations that interleave rotations and translations (see Figure 1). A
representation that counts the number of brown pixels in the green shaded area of Xtr is enough to
achieve 100% accuracy in the training distribution. We formally deﬁne OOD distribution shifts next
using Figure 1 for illustration.
OOD distribution shift.
Let sD “ t1, . . . , muzD be the complement of the set of symme-
try relations D that Y depends on.
We deﬁne the OOD distribution shift between train and
test as a shift in the distribution of PppUiqiPsDq, inﬂuencing the distribution of input transforma-
tions in Equation (3), which in turn can shift the distributions PpXtrq, PpY tr|Xtrq, PpY tr, Xtrq to
4

Published as a conference paper at ICLR 2022
PpXteq, PpY te|Xteq, PpY te, Xteq respectively. Since X does not causally affect Y in our structural
causal model (Equation (4)), changes in input transformations are able to shift PpY |Xq. For example,
in Figure 1(b) the test data (only a single example shown) could suffer an OOD shift due to a different
distribution over PpUtransq that introduces non-zero translations before the second rotation. Note
that the representation that counted the number of brown pixels in the green shaded area, which was
perfect for the training inputs Xtr, will achieve poor accuracy in the test inputs Xte.
Learning OOD classiﬁers.
Equation (4) shows that the label Y is invariant to changes in the
distribution of pUiqiPsD in the test distribution, but we do not know sD. Hence, if our representation of
X is invariant to changes in the distribution of pUiqiPsD, we will be able to perform the OOD task.
4
ASYMMETRY LEARNING & FINDING THE RIGHT REPRESENTATION
SYMMETRY FOR THE OOD TASK
4.1
FINDING OOD-INVARIANT REPRESENTATIONS AS CAUSAL STRUCTURE DISCOVERY
We ﬁrst deﬁne the process of ﬁnding an OOD invariant representations for the symmetries t„iuiPsD
our classiﬁer should be invariant to in the test data. Since Y does not depend on tUiuiPsD, we will
make a representation of X that is invariant to transformations driven by tUiuiPsD.
Deﬁnition 1 introduces the concept of counterfactual invariance for symmetry transformations. We
note that this deﬁnition is less restrictive than the parallel work of Veitch et al. (2021, Deﬁnition 1.1):
whereas Veitch et al. (2021, Deﬁnition 1.1) require invariance over the entire sample space, we only
require invariance over the test support of transformation variable Ui. The deﬁnitions are equivalent
if the test support is the entire sample space of Ui.
Deﬁnition 1 (Counterfactual-invariant representations for symmetric transformations). Assume the
SCM deﬁned in Equations (2) to (4). A representation Γi : X Ñ Rd, d ě 1, is counterfactual-
invariant to the transformations T1,Ui, T2,Ui, . . . of equivalence relation „i, 1 ď i ď m, if
Γipxq “ ΓipXpUi “ ˜uiq|X “ xq
almost everywhere, @˜ui P supppU te
i q, @x P supppXtrq, where supppAq is the support of random
variable A. A representation ΓS : X Ñ Rd, d ě 1, is counterfactual-invariant to a subset
S Ď t1, . . . , mu if it is jointly counterfactual-invariant to the transformation indices tUjujPS of
equivalence relations t„jujPS.
We refer the reader to Equation (1) for the relationship between the counterfactual variables XpUi “
˜uq|Ui “ u and XpUi “ ˜uq|X “ x. Figure 1(d) illustrates why counterfactual language is important
for our task: It states that given an input Xtr “ x we need to know how it would have been different
if we had chosen a different distribution PpUtransq resulting in a different sequence of transformations
T1,Utrans, T2,Utrans. From Figure 1(c) it is clear that we cannot simply data-augment our training data
with translations, since we would think that counting brown pixels in the green shaded area is an
invariant representation for Utrans.
Up until now we have not imposed restrictions on the types of transformations T piq, i “ 1, . . . , m,
we consider in this work. Our next results require imposing conditions on these transformations.
Deﬁnition 2 (Equivalence class lumpability). The quotient space X{ „i is the set of equivalence
classes of X with respect to equivalence relation „i, i “ 1, . . . , m. Let rxspiq P X{ „i be the
equivalence class of x P X with respect to equivalence relation „i. Then, X{ „i is said to be
lumpable with respect to a transformation set T if @rxspiq P X{ „i and @t P T ,
Drx1spiq P pX{ „iq s.t. x˚ P rxspiq ùñ t ˝ x˚ P rx1spiq.
In words, if the lumpability condition in Deﬁnition 2 holds for an equivalence relation „i with respect
to a set of transformations T , then every transformation in T maps all points within an equivalence
class rxspiq P X{ „ to points in a another equivalence class rx1spiq P pX{ „q. To illustrate
the lumpability condition, consider two transformation groups G1 and G2 whose transformations
commute, i.e., @pt1, t2q P G1 ˆ G2, t1 ˝ t2 “ t2 ˝ t1. Then the equivalence classes imposed by Gi,
i.e., the orbits rxspiq “ tti ˝ x : @ti P Giu, are lumpable with respect to the transformations Gj, for
i, j P t1, 2u and j ‰ i.
5

Published as a conference paper at ICLR 2022
(i) Causal DAG
...
...
(ii) Causal DAG in (i) with
counterfactual-invariant
representation of X
...
...
(iii) Asymmetry learning: Causal model search using 
     information in asymmetry (illustration with m=3). 
     Red arrows indicate the asymmetry being
     considered in the causal model.
(a)
(b)
Label Y=0
Label Y=1
(c)
Figure 2: (a) (i) True causal DAG; (ii) causal DAG of counterfactual invariant representation; (iii) Causal model
search. (b) Partial order over invariant representations (arrows indicate higher invariance). (c) An example ﬁgure
where training data has a single example per equivalence class in X{ „1 (green rectangles). Then, we have
COMPpFt1u, Dq “ COMPpFH, Dq even though Ft1u is more invariant (simpler) than FH.
Figure 2a(i) shows our structural causal graph where an edge Ui Ñ Y exists only if i P D. Then,
we use the deﬁnition of lumpability to prove that, under certain conditions, a most-expressive
representation Γi invariant with respect to „i allows us to identify if there is no edge Ui Ñ Y in the
causal DAG.
Theorem 1 (Counterfactual invariance & causal DAG identiﬁcation). Let X{ „i be lumpable given
every T pjq, j ‰ i as in Deﬁnition 2. Then, the structural causal DAG implied by Equations (2) to (4)
(depicted in Figure 2a(i)) does not contain the edge Ui Ñ Y iff
|PpY |ΓipXq, UY q ´ PpY |X, UY q|TV “ 0,
(5)
@PpX:q, @PpU1q, . . . , @PpUmq, where Γi is a most-expressive representation that is invariant with
respect to „i.
The proof is in the Appendix. With the lumpability assumption of X{ „i, Γi in Theorem 1 is a
counterfactual-invariant representation. We now use Figure 2a(ii) to describe the result in Theorem 1.
We ﬁrst note that the representation ΓsD depicted in the ﬁgure is counterfactual invariant to sD, and
hence also counterfactual invariant to k P sD. Next we see that since the representation ΓsD is
counterfactual invariant to Uk, there is no arrow Uk Ñ ΓsDpXq in Figure 2a(ii). If there is no arrow
Uk Ñ Y , the missing arrows from Uk to ΓsDpXq will have no inﬂuence in the ability of ΓsDpXq
to predict Y , assuming ΓsD is most-expressive. If there is an arrow Uk Ñ Y , cutting the arrow
Uk Ñ ΓsDpXq creates a loss in predictive performance from ΓsDpXq to Y for some distribution of the
background and observable variables. If ΓsDpXq never loses any predictive power over Y for any
distribution of the background and observable variables, then there is no arrow Uk Ñ Y .
Assumption 1 (Asymmetry learning training data). In asymmetry learning we assume that every
X{ „i, i P t1, . . . , mu is lumpable given T pjq, j ‰ i, and that in a large training dataset sampled
from pY tr, Xtrq, an arrow Uj Ñ Y in the causal DAG of Figure 2a(i), j P t1, . . . , mu, contains
observations of tUjujPD that violate Equation (5). Hence, if Equation (5) holds for some i P
t1, . . . , mu in this dataset, we can conclude that there is no arrow Ui Ñ Y in the true causal DAG.
See Appendix A for a justiﬁcation of this assumption.
Next we use Assumption 1 and the previous results to search for the right OOD invariance.
4.2
CAUSAL STRUCTURE DISCOVERY OF RELEVANT SYMMETRIES
We need a general procedure for obtaining the unknown set D, which is equivalent to ﬁnding all
transformations indices tUiuiPD Ď tU1, . . . , Umu that act as confounders between Y and X in the
causal DAG in Figure 2a(i). Finding whether an edge exists or not in the causal DAG is known as the
causal structure discovery problem (e.g., Heinze-Deml et al. (2017)). The principle of our search
is learning the causal structure with the fewest possible edges into Y (i.e., where Y is invariant to
most Ui, i “ 1, . . . , m) while also maximizing the likelihood of the observed data. Accordingly,
we take the score-based causal discovery approach (Chickering (2002); Huang et al. (2018)) that
assigns scores to each allowed DAG based on the training data and the complexity of the DAG to
ﬁnd a minimal causal structure that ﬁts the training data. This idea is visualized in Figure 2a(iii)
6

Published as a conference paper at ICLR 2022
where causal graphs with more edges between the transformation indices into Y are deﬁned to have
higher complexity and are higher up in the partial ordering. Our search space is simpler than typical
structure discovery tasks: The DAGs in our search space have the same structure for X and only
differ in edges of the form Ui Ñ Y, i P t1, . . . , mu. Next, we describe a scoring criterion that uses
Theorem 1 and counterfactual-invariant representations to assign scores to the corresponding causal
structures.
Proposed DAG scoring criterion.
For each DAG in the search space, we wish to assign a score
based on the training data D “ tpxpiq, ypiquntr
i“1 under Assumption 1 for a classiﬁcation task with
C classes. Theorem 1 shows that there is a correspondence between a causal structure without the
edge Ui Ñ Y and a predictive probability gap between the original input and a most-expressive
representation Γi that is counterfactually-invariant to Ui. Thus, under Assumption 1, we can represent
the causal search from Figure 2a(iii) in terms of a search over counterfactually-invariant representation
function classes as shown in Figures 2a(iii) and 2b. Formally, we are given a collection of function
classes F :“ tFS : S Ď t1, . . . , muu, where FS is a family of functions ΓS that are counterfactually-
invariant to all Ui, i P S (Deﬁnition 1). We wish to score each of the function classes FS P F to
indirectly learn the correct causal structure.
The minimum description length (MDL) principle (Schwarz, 1978) is commonly used for causal
structure discovery (Budhathoki & Vreeken, 2016; 2017) and comes with the key insight that learning
from data can be viewed as compressing it. Given the collection F and the training dataset D,
MDL ﬁnds the function class FS P F that compresses D the most. While there are several ways of
encoding a dataset given the function class, normalized maximum likelihood (NML) code is known
to be optimal (Shtarkov, 1987). NML code is computed as follows
LnmlpFS, Dq “ ´LpFS|Dq ` COMPpFS, Dq ,
(6)
where LpFS|Dq “ supΓSPFS
řntr
i“1 log Ppypiq|ΓSpxpiqqq is the maximum log-likelihood of FS given
the data and
COMPpFS, Dq “ log
»
———–
ÿ
yp1q,...,ypntrq:
ypiqPt0,...,Cu
sup
ΓSPFS
ntr
ź
i“1
Ppypiq|ΓSpxpiqqq
ﬁ
ﬃﬃﬃﬂ,
(7)
measures the complexity of the function class FS by computing how well it can represent different
label distributions for the given inputs txpiquntr
i“1 in training. We can estimate the combinatorial sum
in Equation (7) by uniformly sampling random labels for all the training examples.
Since COMPpFS, Dq is computed using the training data, it may underestimate the complexity of
function classes if, for instance, all the training examples are generated with Ui “ ui. Then, Ftiu and
FH are given the same score even though Ftiu is clearly more invariant and thus, a simpler function
class. This can happen in practice if, say, all images are upright in training with no rotations applied;
both rotation-invariant and rotation-sensitive function classes get the same complexity score.
In order to break the above ties of our COMP score, asymmetry learning adds an additional term to the
NML score that chooses models that have higher invariance based on the partial order (see Figure 2b).
We extend the penalty proposed by Mouli & Ribeiro (2021) and use RpFSq :“ |tF1 : F1 P F, F1 ą
FSu|, the number of function classes that are higher in the partial order than FS, as the tie-breaking
term. For example, in ﬁgure RpFt1uq “ |tFt1,2u, Ft1,3u, Ft1,2,3uu| “ 3. We deﬁne the ﬁnal score of
each function class FS P F as
SpFS, Dq “ LnmlpFS, Dq ` RpFSq .
(8)
The score in Equation (8) can be minimized by a score-based causal discovery algorithm to obtain
the ﬁnal DAG. We use Greedy Equivalence Search (Chickering, 2002) to showcase a concrete
instantiation of asymmetry learning. Other score-based structure discovery algorithms could also be
used.
Greedy Equivalence Search.
Greedy Equivalence Search (GES) is a greedy search algorithm that
optimizes a given scoring function over DAGs. In our setting, the search begins with a DAG with no
edges of the form Ui Ñ Y, i P t1, . . . , mu. In the ﬁrst phase, GES adds these edges one at a time
7

Published as a conference paper at ICLR 2022
Table 1: Results for different function classes on the pendulum task with D “ t1u and D “ t1, 2u. RpFq,
{
COMPpF, Dq and SpF, Dq are discussed as in Section 4.2. Bold values indicate the function class chosen by
GES method with the proposed scoring criterion. Test accuracy is computed on the extrapolated dataset after
shifting the distribution of PptUiuiPsDq.
D “ t1u
D “ t1, 2u
Model class
Architecture
RpFq
{
COMPpF, Dq
SpF, Dq
Train Acc.
Test Acc.
{
COMPpF, Dq
SpF, Dq
Train Acc.
Test Acc.
F2
X Ñ z1 Ñ Y
0
0.282
23.89
98.5 (0.9)
98.3 ( 1.4)
0.501
532.84
72.7 (0.4)
69.4 (0.5)
F1
X Ñ z2 Ñ Y
0
0.382
633.32
63.8 (7.0)
51.2 ( 1.0)
0.292
284.75
85.2 (0.5)
84.6 (0.2)
FH
X Ñ Y
2
1.256
26.80
98.9 (0.8)
77.6 (11.5)
0.995
4.54
99.7 (0.2)
99.5 (0.2)
that maximally improve the score in Equation (8) until there is no improvement. In the second phase,
GES begins from the DAG obtained at the end of ﬁrst phase and deletes edges one at a time until
such deletions do not improve the score. The DAG obtained at the end of the second phase is the ﬁnal
output of the algorithm. Under the causal Markov and faithfulness assumptions, Chickering (2002)
showed that GES is optimal in the large sample limit if the scoring function is locally consistent.
5
RESULTS
Pendulum task description.
We evaluate the proposed method in a simulated classiﬁcation task.
Our input x is a motion vector over time pθt, dθt
dt qT
t“1 of a simple pendulum of an unknown length l
after it is dropped from some initial angle θ0 with dθ0
dt “ 0. After an initial τ seconds of uninterrupted
motion, we simulate an elastic collision by placing another object of same mass at the bottom. The
classiﬁcation task is to predict whether the kinetic energy imparted by the pendulum is enough to
move the second object beyond a certain threshold.
Physical properties and equivalence relations. We consider the following two properties of the
dynamical system described above: z1 : X Ñ R which computes the initial potential energy of
the system and z2 : X Ñ R which returns the time of collision. The equivalence relations „1 and
„2 are deﬁned using these properties as deﬁned in Section 2. For instance, two pendulum motion
curves x, x1 are equivalent with respect to „1, i.e., x „1 x1, if they have the same time of collision,
z2pxq “ z2px1q. Then T p1q consists of transformations that change the initial potential energy of
the system (for example, by changing the length of the pendulum or the initial dropping angle θ0)
while keeping the time of collision same. Similarly, x „2 x1 if their respective potential energies
are the same and transformations in T p2q change the time of collision while keeping the same initial
potential energies. Note that the space of equivalence classes X{ „1 is lumpable with respect to
T p2q and vice versa (Deﬁnition 2). Thus, by Theorem 1, we can use predictive performance of
counterfactual-invariant representations for scoring the causal DAGs.
Unknown D and OOD classiﬁcation. We consider two scenarios for the label Y given X. First, if
the motion of the pendulum is not damped by friction, then Y depends only on z1pxq, i.e, D “ t1u.
Second, if the motion of the pendulum is damped, then Y depends on both z1pxq and z2pxq, i.e.,
D “ t1, 2u. The extrapolation test data is generated by shifting the distribution of the background
variables tUiuiPsD. The task of a structure discovery algorithm is to correctly identify D.
Results. We use the greedy equivalence search (GES, Section 4.2) algorithm to search over the
different causal graphs with the proposed scoring criterion deﬁned in Equation (8). We build classes
of counterfactual-invariant representations FS corresponding to each possible value of S Ĺ t1, 2u,
where every ΓS P FS is invariant to tUiuiPS. For example, Ft1u is a family of feedforward neural
networks that only take z2pxq as input, i.e., invariant to z1pxq, whereas FH is a sequence model
(e.g., LSTM) with no invariance. Table 1 reports the estimated complexity {
COMPpF, Dq and the
ﬁnal scores SpF, Dq for the different function classes for the two tasks. The bold values indicate the
function class chosen by the GES algorithm. When D “ t1u, the greedy search stops after adding
the edge U1 Ñ Y as adding the second edge U2 Ñ Y only worsens (increases) the score. When
D “ t1, 2u, the greedy search is able to improve the score by adding both edges, ﬁrst U1 Ñ Y and
then U2 Ñ Y . In both the cases, the extrapolation test accuracy achieved by the chosen model class
is the highest.
Image classiﬁcation task.
Appendices A.4 and A.5 also offers an application to image classiﬁcation
using image transformation sets (groups and nongroups).
8

Published as a conference paper at ICLR 2022
6
RELATED WORK
Counterfactual inference and invariances. Recent efforts have brought causal inference to ma-
chine learning (extensively reviewed in Schölkopf et al. (2021); Schölkopf (2022)). Invariant Causal
Prediction (Peters et al., 2015; Heinze-Deml et al., 2018) and Invariant Risk Minimization meth-
ods (Arjovsky et al., 2019; Bellot & van der Schaar, 2020) learn representations that are invariant
across multiple environments but have been shown to be insufﬁcient for OOD generalization in
classiﬁcation tasks without additional assumptions Ahuja et al. (2021). Wang & Jordan (2021) use
counterfactual language to formally deﬁne and learn non-spurious representations from a single
environment that can extrapolate to new environments. Veitch et al. (2021) deﬁne counterfactual
invariant predictors fpXq when X has a single parent Z and provide conditions such predictors must
satisfy over the observed distribution (given an SCM). Kaushik et al. (2020; 2021) propose counter-
factual data augmentation for text datasets but they either require a fully-speciﬁed toy SCM or rely
on humans-in-the-loop to generate the counterfactual data. Other counterfactual methods (Johansson
et al., 2016; Shalit et al., 2017; Qidong et al., 2020) learn representations to predict counterfactual
change in some observed variables whereas in our setting, the transformation variables Ui that gener-
ate the observed X are unobserved. In-depth comparison of our work with the existing counterfactual
methods is presented in Appendix A.3.
Domain adaptation and domain generalization. Domain adaptation and domain generalization
(e.g. (Long et al., 2017; Muandet et al., 2013; Quionero-Candela et al., 2009; Rojas-Carulla et al.,
2018; Shimodaira, 2000; Zhang et al., 2015) and others) consider observed or known shifts in the
data distribution, for instance, given the test distribution PpXteq, rather than counterfactual questions.
Causal structure discovery. The methods for causal structure discovery can be broadly classiﬁed
into two categories. Constraint-based approaches (e.g., Spirtes et al. (2001); Sun et al. (2007)) use
conditional independence tests and reject causal graphs that impose more independence than what
is observed in data. On the other hand, score-based causal discovery approaches (e.g., Chickering
(2002); Huang et al. (2018); Ding et al. (2020); Zhu et al. (2020)) assign scores to each allowed causal
graph based on the data and ﬁnd the one with best score. While there are several works (Budhathoki &
Vreeken, 2016; 2017; Bornschein et al., 2021) that use minimum description length (MDL) (Schwarz,
1978) as a scoring criterion, we show why it is insufﬁcient for out-of-distribution tasks and use an
additional term for tie-breaking. Goudet et al. (2017) minimize the divergence between a distribution
generated by a learnt causal DAG and the observed data distribution; however the method is limited
to orienting edges over observed variables, whereas our transformation variables Ui are unobserved.
Recently, GFlowNets Bengio et al. (2021a;b) have been used to sample DAGs proportional to a score
function for Bayesian structure learning Deleu et al. (2022), however we are interested in ﬁnding the
best DAG with the minimum score.
Group-invariant representations. Majority of the works strictly enforce G-invariances either within
the architecture (e.g., Zaheer et al. (2017); Cohen et al. (2016); Lyle et al. (2020); Murphy et al.
(2019a)) or via data-augmentation (Chen et al., 2020) and do not handle the case when the target
is actually inﬂuenced by the transformation of the input. Other works (Benton et al., 2020; Zhou
et al., 2020; van der Wilk et al., 2018; Anselmi et al., 2019) consider learning symmetries from
the training data but do not consider the extrapolation task that we show can be solved only under
certain conditions. Mouli & Ribeiro (2021) consider the special case where the transformations are
from normal subgroups and do not formally describe the causal task. These works rely on invertible
transformations while we deﬁne symmetries more generally via equivalence relations. Dubois et al.
(2021) also deﬁne invariances via equivalence relations and, under the assumption that all such
invariances hold in the data, the authors design methods for data compression. Our goal is rather
different: We want to discover which equivalence relations (transformations thereof) affect the label.
7
CONCLUSIONS
This work considered an out-of-distribution (OOD) classiﬁcation task where the shift between train
and test environments is through different symmetry transformations of the input, where symmetry
transformations are deﬁned via equivalence relations over the input space. We described the task of
ﬁnding symmetries that affect the label as a causal structure discovery task and show that, under certain
conditions, we can use the predictive performance of invariant representations on the observational
data to predict whether an edge exists in the causal DAG (Theorem 1). We then proposed an MDL-
based scoring for this causal structure discovery. Finally, we test our approach in two simulated
physics tasks and six image classiﬁcation tasks.
9

Published as a conference paper at ICLR 2022
ACKNOWLEDGMENTS
This work was funded in part by the National Science Foundation (NSF) Awards CAREER IIS-
1943364 and CCF-1918483, the Purdue Integrative Data Science Initiative, and the Wabash Heartland
Innovation Network. Any opinions, ﬁndings and conclusions or recommendations expressed in this
material are those of the authors and do not necessarily reﬂect the views of the sponsors.
REFERENCES
Kartik Ahuja, Ethan Caballero, Dinghuai Zhang, Jean-Christophe Gagnon-Audet, Yoshua Bengio,
Ioannis Mitliagkas, and Irina Rish. Invariance principle meets information bottleneck for out-of-
distribution generalization. Advances in Neural Information Processing Systems, 34, 2021.
Fabio Anselmi, Georgios Evangelopoulos, Lorenzo Rosasco, and Tomaso Poggio. Symmetry-adapted
representation learning. Pattern Recognition, 86:201–208, February 2019. ISSN 0031-3203. doi:
10.1016/j.patcog.2018.07.025.
Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization.
arXiv preprint arXiv:1907.02893, 2019.
Elias Bareinboim, Juan Correa, Duligur Ibeling, and Thomas Icard. On Pearl’s hierarchy and the
foundations of causal inference. ACM special volume in honor of Judea Pearl, 2020.
Alexis Bellot and Mihaela van der Schaar. Accounting for unobserved confounding in domain
generalization. arXiv preprint arXiv:2007.10653, 2020.
Shai Ben-David, John Blitzer, Koby Crammer, Fernando Pereira, et al. Analysis of representations
for domain adaptation. Advances in neural information processing systems, 19:137, 2007.
Emmanuel Bengio, Moksh Jain, Maksym Korablyov, Doina Precup, and Yoshua Bengio. Flow
network based generative models for non-iterative diverse candidate generation. Advances in
Neural Information Processing Systems, 34, 2021a.
Yoshua Bengio, Tristan Deleu, Edward J Hu, Salem Lahlou, Mo Tiwari, and Emmanuel Bengio.
Gﬂownet foundations. arXiv preprint arXiv:2111.09266, 2021b.
Gregory Benton, Marc Finzi, Pavel Izmailov, and Andrew Gordon Wilson. Learning invariances in
neural networks from data. NeurIPS, 2020.
Jorg Bornschein, Silvia Chiappa, Alan Malek, and Rosemary Nan Ke. Prequential MDL for Causal
Structure Learning with Neural Networks. July 2021.
Michael M Bronstein, Joan Bruna, Yann LeCun, Arthur Szlam, and Pierre Vandergheynst. Geometric
deep learning: going beyond euclidean data. IEEE Signal Processing Magazine, 34(4):18–42,
2017.
Kailash Budhathoki and Jilles Vreeken. Causal Inference by Compression. In 2016 IEEE 16th
International Conference on Data Mining (ICDM), pp. 41–50, Barcelona, Spain, December 2016.
IEEE. ISBN 978-1-5090-5473-2. doi: 10.1109/ICDM.2016.0015.
Kailash Budhathoki and Jilles Vreeken. MDL for Causal Inference on Discrete Data. In 2017
IEEE International Conference on Data Mining (ICDM), pp. 751–756, November 2017. doi:
10.1109/ICDM.2017.87.
Shuxiao Chen, Edgar Dobriban, and Jane H. Lee. A group-theoretic framework for data augmenta-
tion. Journal of Machine Learning Research, 21(245):1–71, 2020. URL http://jmlr.org/
papers/v21/20-163.html.
David Maxwell Chickering. Optimal Structure Identiﬁcation With Greedy Search. Journal of
Machine Learning Research, 3(Nov):507–554, 2002. ISSN ISSN 1533-7928.
Taco S Cohen, T S Cohen, and Uva Nl. Group Equivariant Convolutional Networks. pp. 10, 2016.
Elliot Creager, Jörn-Henrik Jacobsen, and Richard Zemel. Environment inference for invariant
learning. In International Conference on Machine Learning, pp. 2189–2200. PMLR, 2021.
10

Published as a conference paper at ICLR 2022
Alexander D’Amour, Katherine Heller, Dan Moldovan, Ben Adlam, Babak Alipanahi, Alex Beutel,
Christina Chen, Jonathan Deaton, Jacob Eisenstein, Matthew D Hoffman, et al. Underspeciﬁcation
presents challenges for credibility in modern machine learning. arXiv preprint arXiv:2011.03395,
2020.
Tristan Deleu, António Góis, Chris Emezue, Mansi Rankawat, Simon Lacoste-Julien, Stefan Bauer,
and Yoshua Bengio. Bayesian structure learning with generative ﬂow networks. arXiv preprint
arXiv:2202.13903, 2022.
Chenwei Ding, Biwei Huang, Mingming Gong, Kun Zhang, Tongliang Liu, and Dacheng Tao.
Score-based Causal Discovery from Heterogeneous Data. September 2020.
Yann Dubois, Benjamin Bloem-Reddy, Karen Ullrich, and Chris J Maddison. Lossy compression for
lossless prediction. arXiv preprint arXiv:2106.10800, 2021.
Marc Finzi, Max Welling, and Andrew Gordon Wilson. A practical method for constructing equivari-
ant multilayer perceptrons for arbitrary matrix groups. arXiv preprint arXiv:2104.09459, 2021.
Robert Geirhos, Jörn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias
Bethge, and Felix A Wichmann. Shortcut learning in deep neural networks. Nature Machine
Intelligence, 2(11):665–673, 2020.
Olivier Goudet, Diviyan Kalainathan, Philippe Caillou, Isabelle Guyon, David Lopez-Paz, and
Michèle Sebag. Causal generative neural networks. arXiv preprint arXiv:1711.08936, 2017.
Christina Heinze-Deml, Marloes H. Maathuis, and Nicolai Meinshausen. Causal Structure Learning.
arXiv:1706.09141 [stat], June 2017.
Christina Heinze-Deml, Jonas Peters, and Nicolai Meinshausen. Invariant Causal Prediction for
Nonlinear Models. arXiv:1706.08576 [stat], September 2018.
Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta,
and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs. In Advances
in Neural Information Processing Systems, 2020.
Biwei Huang, Kun Zhang, Yizhu Lin, Bernhard Schölkopf, and Clark Glymour. Generalized Score
Functions for Causal Discovery. KDD : proceedings. International Conference on Knowledge
Discovery & Data Mining, 2018:1551–1560, August 2018. ISSN 2154-817X. doi: 10.1145/
3219819.3220104.
Maximilian Ilse, Jakub M Tomczak, and Patrick Forré. Selecting data augmentation for simulating
interventions. In International Conference on Machine Learning, pp. 4555–4562. PMLR, 2021.
Fredrik Johansson, Uri Shalit, and David Sontag.
Learning representations for counterfactual
inference. In International conference on machine learning, pp. 3020–3029, 2016.
Divyansh Kaushik, Eduard Hovy, and Zachary Lipton. Learning the difference that makes a difference
with counterfactually-augmented data. In International Conference on Learning Representations,
2020. URL https://openreview.net/forum?id=Sklgs0NFvr.
Divyansh Kaushik, Amrith Setlur, Eduard H Hovy, and Zachary Chase Lipton. Explaining the efﬁcacy
of counterfactually augmented data. In International Conference on Learning Representations,
2021. URL https://openreview.net/forum?id=HHiiQKWsOcV.
Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Bal-
subramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Sara Beery, et al. Wilds: A
benchmark of in-the-wild distribution shifts. arXiv preprint arXiv:2012.07421, 2020.
Risi Kondor and Shubhendu Trivedi. On the generalization of equivariance and convolution in neural
networks to the action of compact groups. In International Conference on Machine Learning, pp.
2747–2755. PMLR, 2018.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
11

Published as a conference paper at ICLR 2022
David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai
Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapola-
tion (rex). In International Conference on Machine Learning, pp. 5815–5826. PMLR, 2021.
Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Deep transfer learning with joint
adaptation networks. In International conference on machine learning, pp. 2208–2217. PMLR,
2017.
Clare Lyle, Mark van der Wilk, Marta Kwiatkowska, Yarin Gal, and Benjamin Bloem-Reddy. On the
beneﬁts of invariance in neural networks. arXiv preprint arXiv:2005.00178, 2020.
Haggai Maron, Heli Ben-Hamu, Nadav Shamir, and Yaron Lipman. Invariant and equivariant graph
networks. arXiv preprint arXiv:1812.09902, 2018.
S Chandra Mouli and Bruno Ribeiro. Neural network extrapolations with g-invariances from a
single environment. In International Conference on Learning Representations, 2021. URL
https://openreview.net/forum?id=7t1FcJUWhi3.
Krikamol Muandet, David Balduzzi, and Bernhard Schölkopf. Domain generalization via invariant
feature representation. In International Conference on Machine Learning, pp. 10–18, 2013.
R. Murphy, B. Srinivasan, V. Rao, and B. Ribeiro. Janossy pooling: Learning deep permutation-
invariant functions for variable-size inputs. In International Conference on Learning Representa-
tions, 2019a.
Ryan Murphy, Balasubramaniam Srinivasan, Vinayak Rao, and Bruno Ribeiro. Relational pooling for
graph representations. In Proceedings of the 36th International Conference on Machine Learning,
2019b.
J Pearl and D Mackenzie. The ladder of causation. The book of why: the new science of cause and
effect. New York (NY): Basic Books, pp. 23–52, 2018.
Jonas Peters, Peter Bühlmann, and Nicolai Meinshausen. Causal inference using invariant prediction:
identiﬁcation and conﬁdence intervals. arXiv preprint arXiv:1501.01332, 2015.
Liu Qidong, Tian Feng, Ji Weihua, and Zheng Qinghua. A new representation learning method for
individual treatment effect estimation: Split covariate representation network. In Asian Conference
on Machine Learning, pp. 811–822. PMLR, 2020.
Joaquin Quionero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence. Dataset
shift in machine learning. The MIT Press, 2009.
Mateo Rojas-Carulla, Bernhard Schölkopf, Richard Turner, and Jonas Peters. Invariant models for
causal transfer learning. The Journal of Machine Learning Research, 19(1):1309–1342, 2018.
Joseph Rosen. Symmetry rules: How science and nature are founded on symmetry. Springer Science
& Business Media, 2008.
Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski. The risks of invariant risk minimization.
arXiv preprint arXiv:2010.05761, 2020.
Bernhard Schölkopf. Causality for machine learning. In Probabilistic and Causal Inference: The
Works of Judea Pearl, pp. 765–804. 2022.
Bernhard Schölkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner,
Anirudh Goyal, and Yoshua Bengio. Toward causal representation learning. Proceedings of the
IEEE, 109(5):612–634, 2021.
Gideon Schwarz. Estimating the Dimension of a Model. The Annals of Statistics, 6(2):461–464,
March 1978. ISSN 0090-5364, 2168-8966. doi: 10.1214/aos/1176344136.
Uri Shalit, Fredrik D Johansson, and David Sontag. Estimating individual treatment effect: general-
ization bounds and algorithms. In International Conference on Machine Learning, pp. 3076–3085.
PMLR, 2017.
12

Published as a conference paper at ICLR 2022
John Shawe-Taylor. Symmetries and discriminability in feedforward network architectures. IEEE
Transactions on Neural Networks, 4(5):816–826, 1993.
Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-
likelihood function. Journal of statistical planning and inference, 90(2):227–244, 2000.
Yurii Mikhailovich Shtarkov. Universal sequential coding of single messages. Problemy Peredachi
Informatsii, 23(3):3–17, 1987.
Murray Sidman and William Tailby. Conditional discrimination vs. matching to sample: An expansion
of the testing paradigm. Journal of the Experimental Analysis of behavior, 37(1):5–22, 1982.
Murray Sidman, Ricki Rauzin, Ronald Lazar, Sharon Cunningham, William Tailby, and Philip
Carrigan. A search for symmetry in the conditional discriminations of rhesus monkeys, baboons,
and children. Journal of the experimental analysis of behavior, 37(1):23–44, 1982.
Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556, 2014.
Peter Spirtes, Clark Glymour, and Richard Scheines. Causation, Prediction, and Search, 2nd Edition.
MIT Press Books, The MIT Press, 2001.
Xiaohai Sun, Dominik Janzing, Bernhard Schölkopf, and Kenji Fukumizu. A kernel-based causal
learning algorithm. In Proceedings of the 24th International Conference on Machine Learning,
ICML ’07, pp. 855–862, New York, NY, USA, June 2007. Association for Computing Machinery.
ISBN 978-1-59593-793-3. doi: 10.1145/1273496.1273604.
Damien Teney, Ehsan Abbasnedjad, and Anton van den Hengel. Learning what makes a difference
from counterfactual examples and gradient supervision. In Computer Vision–ECCV 2020: 16th
European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part X 16, pp. 580–599.
Springer, 2020.
Mark van der Wilk, Matthias Bauer, ST John, and James Hensman. Learning invariances using the
marginal likelihood. In Advances in Neural Information Processing Systems, pp. 9938–9948, 2018.
Victor Veitch, Alexander D’Amour, Steve Yadlowsky, and Jacob Eisenstein. Counterfactual invariance
to spurious correlations: Why and how to pass stress tests. arXiv preprint arXiv:2106.00545, 2021.
Yixin Wang and Michael I. Jordan. Desiderata for Representation Learning: A Causal Perspective.
arXiv:2109.03795 [cs, stat], September 2021.
Gesche Westphal-Fitch, Ludwig Huber, Juan Carlos Gomez, and W Tecumseh Fitch. Production
and perception rules underlying visual patterns: effects of symmetry and hierarchy. Philosophical
Transactions of the Royal Society B: Biological Sciences, 367(1598):2007–2022, 2012.
Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Russ R Salakhutdinov, and
Alexander J Smola. Deep Sets. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,
S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems 30,
pp. 3391–3401. Curran Associates, Inc., 2017.
Kun Zhang, Mingming Gong, and Bernhard Schölkopf. Multi-source domain adaptation: A causal
view. In AAAI, volume 1, pp. 3150–3157, 2015.
Han Zhao, Remi Tachet Des Combes, Kun Zhang, and Geoffrey Gordon. On learning invariant
representations for domain adaptation. In International Conference on Machine Learning, pp.
7523–7532. PMLR, 2019.
Allan Zhou, Tom Knowles, and Chelsea Finn. Meta-Learning Symmetries by Reparameterization.
arXiv:2007.02933 [cs, stat], October 2020.
Shengyu Zhu, Ignavier Ng, and Zhitang Chen. Causal Discovery with Reinforcement Learning. pp.
17, 2020.
13

Published as a conference paper at ICLR 2022
A
APPENDIX
A.1
JUSTIFICATION FOR ASSUMPTION 1.
The above assumption is inspired by the deep relationship between symmetries and intelligence.
Young children, unlike monkeys and baboons, assume that a conditional stimulus F given another
stimulus D extrapolates to a symmetric relation D given F without ever seeing any such examples (Sid-
man et al., 1982). That is, if given D, action F produces a treat, the child assumes that given F, action
D also produces a treat. Young children differ from primates in their ability to use symmetries to
build conceptual relations beyond visual patterns (Sidman & Tailby, 1982; Westphal-Fitch et al.,
2012), allowing extrapolations from intelligent reasoning. However, forcing symmetries against
data evidence is undesirable, since symmetries can provide valuable information when they are
broken. Unsurprising, humans are generally able to quickly ﬁnd and pay attention to some types of
asymmetries.
A.2
PROOF OF THEOREM 1
Theorem 1 (Counterfactual invariance & causal DAG identiﬁcation). Let X{ „i be lumpable given
every T pjq, j ‰ i as in Deﬁnition 2. Then, the structural causal DAG implied by Equations (2) to (4)
(depicted in Figure 2a(i)) does not contain the edge Ui Ñ Y iff
|PpY |ΓipXq, UY q ´ PpY |X, UY q|TV “ 0,
(5)
@PpX:q, @PpU1q, . . . , @PpUmq, where Γi is a most-expressive representation that is invariant with
respect to „i.
Proof. Notation
(following
Equation
(3)):
The
observed
input
X
is
X
:“
tpU1, . . . , Ui´1, ui, Ui`1, . . . , Umq ˝ X: where tpU1, . . . , Umq is obtained by interleaving
the transformation sequences from each individual U1, . . . , Um and we have set Ui “ ui.
Necessity: We wish to show that if the SCM does not contain edge Ui Ñ Y , then Equation (5) holds
for all PpX:q, PpU1q, . . . , PpUmq. By this assumption, Y outputs the same label for any value of Ui.
Consider the collection of equivalence classes X{ „i. By the lumpability condition of Deﬁnition 2, all
transformations tpjq P T pjq, j ‰ i, map all points in one equivalence class of „i to points in a different
one. On the other hand, all transformations tpiq P T piq map points to other points within the same
equivalence class under „i. Now, consider the equivalence class of X after all the transformations
have been applied to X:. The equivalence class of X “ tpU1, . . . , Ui´1, ui, Ui`1, . . . , Umq ˝ X: is
the same as that of X˚ “ tpU1, . . . , Ui´1, uid
i , Ui`1, . . . , Umq ˝ X: where Ui “ uid
i always selects
identity transformations. This is because changing ui to uid
i only impacts the transformations chosen
from T piq, and these transformations do not change the equivalence class under „i. Thus, we have
shown that we reach the same equivalence class under „i for both X and X˚.
Now let Γi be a most-expressive representation that is invariant with respect to „i. By deﬁnition, Γi
outputs the same value within an equivalence class, thus, ΓipXq “ ΓipX˚q. But since by assumption
Ui Ñ Y does not exist, X and X˚ have the same label always. Thus, there is no loss of information
incurred by Γi in predicting Y with the additional restraint ΓipXq “ ΓipX˚q. Since Γi is most-
expressive, we have PpY “ y|ΓipXq, UY q “ PpY “ y|X, UY q for all y P Y. This holds for all
values of ui, and hence we get the desired result for any distribution PpUiq.
Sufﬁciency: We wish to show that if Equation (5) holds for all PpX:q and PpU1q, . . . , PpUmq, then
there is no edge Ui Ñ Y in the causal graph. We will prove by contrapositive: Assume there is an
edge Ui Ñ Y , then we will show there exists distributions PpX:q and PpU1q, . . . , PpUmq such that
Equation (5) does not hold.
Deﬁne PpX:q “ δx: for some x: P X where δ denotes a Dirac-delta function. Deﬁne PpUi “
uid
i q “ 0.5 and PpUi “ uiq “ 0.5 for uid
i , ui P supppUiq. As usual, uid
i always selects the identity
transformation, and ui selects a single transformation tui P T piq. Similarly, for all j ‰ i, deﬁne
PpUjq “ δuid
j for uid
j P supppUjq that only select identity transformations. Now, there are two
possible observed inputs: x “ tpuid
1 , . . . , uid
mq ˝ x: “ x: and x1 “ tpuid
1 , . . . , ui, . . . , uid
mq ˝ x: “
tui ˝ x:. Finally, deﬁne Y :“ 1pUi “ uid
i q, thus x and x1 have different labels. But, any invariant
14

Published as a conference paper at ICLR 2022
representation Γi by deﬁnition has Γipxq “ Γipx1q since they belong to the same equivalence class.
Thus, even if Γi is most-expressive, we have |PpY |ΓipXq, UY q ´ PpY |X, UY q|TV “ 0.5.
A.3
ADDITIONAL RELATED WORK
Counterfactual invariances.
Wang & Jordan (2021) use counterfactual language to formally
deﬁne and learn non-spurious, disentangled representations from a single environment. Our work
is different in the following ways. In the structural causal model (SCM) of their work, the authors
assume that there are no confounders between the observed X and the label Y . However, in our
SCM (Figure 2a(i)), we allow unobserved confounders X: and Ui, i P D. The hidden transformation
variables Ui, i P D are confounders because they affect both the observed input X and the labels Y .
We leverage the fact that the confounders are related to symmetries (and do not affect X arbitrarily)
to resolve the issue with unobserved confounding. Wang & Jordan (2021) also require pinpointability
of the cause of the observed X. In our setting, this is typically not possible since there are multiple
paths of transformations from X: to the same observed X. Thus, all the parents of X may not be
pinpointable, speciﬁcally the transformation variables U1, . . . , Um.
Kaushik et al. (2020; 2021) propose counterfactual data augmentation for text datasets where human
annotators are asked to make minimal modiﬁcations to the input document so as to change its
label (for example, by changing a few positive words to negative words) while keeping style, etc.
ﬁxed. This type of augmentation essentially asks the labelers to identify all the causal features in
the document and make modiﬁcations to those features alone. This can be seen as obtaining new
counterfactual examples by simulating the causal model and requires knowing the true function that
describes how the features affect the labels. We consider the more realistic setting where we do not
have access to such a collection of counterfactual examples. In this work, we consider the traditional
automated data augmentations under a mostly unknown data generation process, as opposed to the
counterfactual data augmentation (Kaushik et al., 2020) that either considers a fully-speciﬁed toy
SCM or relies on humans-in-the-loop to generate counterfactual data.
In Figure 1(c) we show that the standard data augmentation is not sufﬁcient for the OOD task.
However, if one had access to the fully-speciﬁed causal model, one could generate the counterfactual
data shown in Figure 1(d) and learn an OOD classiﬁer with the counterfactually augmented data
(as done by Kaushik et al. (2020)). But our work does not assume access to these counterfactual
examples. Additionally, we prove that a counterfactual invariant classiﬁer can be constructed from
traditional data augmentation alone if the lumpability condition (Deﬁnition 2) is satisﬁed. This is not
the case in Figure 1(d).
Veitch et al. (2021) deﬁne counterfactual invariant predictors fpXq when X has a single parent Z and
provide conditions such predictors must satisfy over the observed distribution (given an SCM). Note
also that Veitch et al. (2021) assume that part of the observed input X (XK
Z ) is not causally inﬂuenced
by the confounder Z. In our scenarios this is not generally true. For example, under a color change,
the entire observed image X changes. Still, we show that the notion of a counterfactual invariant
predictor exists. Hence, the deﬁnition of Veitch et al. (2021, Lemma 3.1) of a counterfactually
invariant predictor that requires a segment of X to not causally depend on Z, a fundamental result of
their work, unfortunately does not apply to our setting (since X may have no such segment).
A.4
MNIST-t3, 4u EXPERIMENTS WITH FINITE TRANSFORMATION GROUPS
We test our proposed method on out-of-distribution tasks on images where the equivalence relations
(symmetries) are provided as transformation groups (e.g., 90˝ rotations). We use the MNIST-t3, 4u
(colored) dataset (Mouli & Ribeiro, 2021) that only contains digits 3 and 4, and follow their experi-
mental setup. MNIST-t3, 4u is used to avoid any confounding factors while testing if the proposed
method can learn the correct invariances, not for any practical considerations (e.g., rotated 6 is a 9
and would interfere with some experiments, etc.).
We consider equivalence relations obtained from 3 different transformation groups: rotations by 90˝
(denoted Grot), vertically ﬂipping the image (denoted Gv-ﬂip), and permuting the RGB color channels
of the image (denoted Gcol). The 3 corresponding equivalence relations are lumpable (Deﬁnition 2)
with respect to the transformations in the other two groups in almost all the cases. Only exception
15

Published as a conference paper at ICLR 2022
Table 2:
Results for different function classes on the MNIST-t3, 4u classiﬁcation task with sD
“
trot, col, vﬂipu, D “ H, i.e., task is invariant to 3 groups (sD) and sensitive to none (D). RpFq, {
COMPpF, Dq
and SpF, Dq are as discussed in Section 4.2. Bold values indicate the function class chosen by GES method
with the proposed scoring criterion. Test accuracy is computed on the extrapolated dataset after shifting the
distribution of PptUiuiPsDq. We see that the SpF, Dq loss selects the correct model class in training.
Model class
RpFq
` {
COMPpF, Dq
` NLLpF, Dq
“ SpF, Dq
Train Acc
Test Acc
Ftu
7
6639.310
0.013
6646.324
100.00 ( 0.00)
48.38 ( 5.22)
Ftvﬂipu
3
6639.241
0.079
6642.320
100.00 ( 0.00)
47.08 ( 5.34)
Ftcolu
3
6639.241
0.029
6642.270
100.00 ( 0.00)
53.92 ( 2.47)
Ftcol,vﬂipu
1
6639.241
0.099
6640.340
100.00 ( 0.00)
53.15 ( 1.83)
Ftrotu
3
6639.241
0.037
6642.278
100.00 ( 0.00)
53.06 (10.00)
Ftrot,vﬂipu
1
6639.241
0.580
6640.821
100.00 ( 0.01)
54.86 (13.60)
Ftrot,colu
1
6639.241
0.043
6640.284
100.00 ( 0.00)
90.29 ( 6.76)
Ftrot,col,vﬂipu
0
6639.241
0.210
6639.451
100.00 ( 0.00)
92.02 ( 2.99)
Table 3: Results for different function classes on the MNIST-t3, 4u classiﬁcation task with sD “ trot, vﬂipu, D “
tcolu, i.e., task is invariant to rotation and vertical ﬂip groups (sD) but sensitive to color (D). RpFq, {
COMPpF, Dq
and SpF, Dq are as discussed in Section 4.2. Bold values indicate the function class chosen by GES method
with the proposed scoring criterion. Test accuracy is computed on the extrapolated dataset after shifting the
distribution of PptUiuiPsDq. We see that the SpF, Dq loss selects the correct model class in training.
Model class
RpFq
` {
COMPpF, Dq
` NLLpF, Dq
“ SpF, Dq
Train Acc
Test Acc
Ftu
7
6639.241
0.010
6646.251
100.00 ( 0.00)
54.79 ( 0.74)
Ftvﬂipu
3
6639.241
0.012
6642.253
100.00 ( 0.00)
55.05 ( 1.56)
Ftcolu
3
6639.240
8269.480
14911.720
41.98 ( 5.79)
18.81 ( 2.94)
Ftcol,vﬂipu
1
6639.241
8275.716
14915.957
42.71 ( 4.07)
18.62 ( 2.25)
Ftrotu
3
6638.946
0.132
6642.078
100.00 ( 0.00)
91.40 ( 3.19)
Ftrot,vﬂipu
1
6638.428
0.504
6639.932
100.00 ( 0.00)
92.32 ( 1.84)
Ftrot,colu
1
6639.241
8412.954
15053.194
37.20 ( 1.97)
29.25 ( 5.18)
Ftrot,col,vﬂipu
0
6639.239
8389.719
15028.958
38.01 ( 2.02)
29.98 ( 3.96)
is the equivalence relation „v-ﬂip, which is not lumpable with respect to the transformations in Grot.
Consequently, we do not consider a task with invariance to vertical ﬂip alone. We test our method on
the same 4 classiﬁcation tasks proposed by Mouli & Ribeiro (2021) where each task represents the
case where the target Y has different invariances, i.e., invariant to all three groups, to two, to one,
invariant to none (the task is sensitive to the remaining groups).
We use the VGG architecture (Simonyan & Zisserman, 2014) for image classiﬁcation and construct a
collection of function classes F :“ tFS : S Ď trot, col, v-ﬂipuu corresponding to various invariant
representations. For example, Ftrot,colu is a space of functions (CNNs) that are G-invariant to the
rotation and color-permutation groups (Grot and Gcol), and FH is the space of functions with no
invariance (standard CNN).
Results.
Our results are shown in Tables 2 to 5 for the four tasks respectively where the label is (i)
invariant to all three groups, (ii) invariant to only rotation and vertical ﬂips, (iii) invariant to color-
permutation, and (iv) invariant to none. We show the values for RpFq, {
COMPpF, Dq and SpF, Dq
as as discussed in Section 4.2. Bold values in the tables indicate the function class chosen by GES
method with the proposed scoring criterion (minimizing SpF, Dq). Test accuracy is computed on the
extrapolated dataset after shifting the distribution of PptUiuiPsDq (i.e., by applying the transformations
that the label is invariant to).
In Tables 2 and 3, we see that the proposed method selects the correct model class in training and
achieves the best OOD test accuracy. In Tables 4 and 5, the method is excessively invariant (to
vertical ﬂip) but still achieves within 1% of the best OOD test accuracy. The OOD test accuracy of a
16

Published as a conference paper at ICLR 2022
Table 4: Results for different function classes on the MNIST-t3, 4u classiﬁcation task with sD “ tcolu, D “
trot, vﬂipu, i.e., task is invariant to color (sD) but sensitive to rotation and vertical ﬂips (D). RpFq, {
COMPpF, Dq
and SpF, Dq are as discussed in Section 4.2. Bold values indicate the function class chosen by GES method
with the proposed scoring criterion. Test accuracy is computed on the extrapolated dataset after shifting the
distribution of PptUiuiPsDq. We see that the SpF, Dq loss selects a model that is excessively invariant in training,
but the test accuracy is not that much penalized by the extra invariance (vertical ﬂips).
Model class
RpFq
` {
COMPpF, Dq
` NLLpF, Dq
“ SpF, Dq
Train Acc
Test Acc
Ftu
7
6639.241
2.395
6648.636
100.00 ( 0.01)
16.87 ( 5.88)
Ftvﬂipu
3
6639.233
5.370
6647.603
99.99 ( 0.05)
15.71 ( 5.53)
Ftcolu
3
6639.196
2.315
6644.512
100.00 ( 0.00)
97.28 ( 0.28)
Ftcol,vﬂipu
1
6639.240
3.098
6643.337
100.00 ( 0.00)
96.82 ( 0.54)
Ftrotu
3
6639.228
5296.755
11938.984
56.17 ( 3.90)
6.20 ( 0.86)
Ftrot,vﬂipu
1
6639.221
5325.008
11965.228
55.96 ( 5.39)
7.24 ( 1.48)
Ftrot,colu
1
6639.218
5322.015
11962.233
56.14 ( 3.31)
47.98 ( 1.34)
Ftrot,col,vﬂipu
0
6639.230
5342.805
11982.035
55.32 ( 3.80)
49.25 ( 3.09)
Table 5: Results for different function classes on the MNIST-t3, 4u classiﬁcation task with sD “ H, D “
trot, col, vﬂipu, i.e., task is sensitive to all three groups (D) and insensitive to none (sD). RpFq, {
COMPpF, Dq
and SpF, Dq are as discussed in Section 4.2. Bold values indicate the function class chosen by GES method
with the proposed scoring criterion. Test accuracy is computed on the extrapolated dataset after shifting the
distribution of PptUiuiPsDq. We see that the SpF, Dq loss selects a model that is excessively invariant in training,
but the test accuracy is not that much penalized by the extra invariance (vertical ﬂip).
Model class
RpFq
` {
COMPpF, Dq
` NLLpF, Dq
“ SpF, Dq
Train Acc
Test Acc
Ftu
7
6639.165
1.195
6647.360
100.00 ( 0.00)
96.00 ( 0.60)
Ftvﬂipu
3
6639.117
3.548
6645.665
100.00 ( 0.00)
95.18 ( 0.45)
Ftcolu
3
6639.192
7536.167
14178.359
58.77 ( 3.34)
32.45 ( 2.18)
Ftcol,vﬂipu
1
6639.184
7902.462
14542.645
52.50 ( 7.64)
31.21 ( 2.48)
Ftrot,colu
1
6639.088
13628.356
20268.443
23.78 ( 2.25)
15.93 ( 0.71)
Ftrotu
3
6639.153
5259.957
11902.110
58.12 ( 4.05)
47.23 ( 1.89)
Ftrot,vﬂipu
1
6639.827
5267.771
11908.598
57.13 ( 1.38)
47.57 ( 2.15)
Ftrot,col,vﬂipu
0
6639.055
13705.123
20344.178
22.97 ( 3.32)
16.13 ( 2.22)
standard CNN with no invariance (FH) is typically very low except in Table 5 where sensitivity to all
groups is required. We can also see the importance of RpFq for tie-breaking in these experiments.
As discussed in Section 4.2, {
COMPpF, Dq is unable to distinguish between the different function
classes because the training data contains a single example per equivalence class (see Figure 2c).
A.5
CIFAR10 EXPERIMENTS WITH INFINITE/NONGROUP TRANSFORMATION SETS
In this section, we test our proposed method on out-of-distribution tasks on CIFAR10 im-
ages (Krizhevsky et al., 2009) where the equivalence relations are provided as inﬁnite sets of
transformations that may not form a group. We used (a) arbitrary rotation transformations over an
image (denoted Trot), and (b) shifting the hue of an image (denoted Tcol). Note that for a bounded
image, arbitrary rotation is not a group due to cropping. Further, transformations from the respective
sets commute with each other, and hence, the lumpability condition is satisﬁed (Deﬁnition 2) for the
corresponding equivalence relations.
We tested our method on 2 classiﬁcation tasks: (i) invariant to both sets of transformations (arbitrary
rotations and hue shifts), and (ii) invariant to arbitrary rotations, but sensitive to hue shifts. As before,
we use the VGG architecture (Simonyan & Zisserman, 2014) for image classiﬁcation and construct a
collection of function classes F :“ tFS : S Ď trot, coluu corresponding to the various invariant
representations. We use data augmentation to construct these invariant representations (this is possible
since the lumpability condition holds). For example, Ftrot,colu refers to CNNs that were trained by
17

Published as a conference paper at ICLR 2022
Table 6: Results for different function classes on the CIFAR10 classiﬁcation task with two sets of transformations
(transformations that do not form groups) on images: arbitrary rotations (with cropping due to rotation) and
arbitrary hue shifts. The task is invariant to both sets of transformations (sD) and sensitive to none (D). RpFq,
{
COMPpF, Dq and SpF, Dq are as discussed in Section 4.2. Bold values indicate the function class chosen by
GES method with the proposed scoring criterion. Test accuracy is computed on the extrapolated dataset after
shifting the distribution of PptUiuiPsDq. We see that the SpF, Dq loss selects the correct model class in training.
Model class
RpFq
` {
COMPpF, Dq
` NLLpF, Dq
“ SpF, Dq
Train Acc
Test Acc
Ftu
3
27725.875
17496.615
45225.490
85.60
21.48
Ftcolu
1
27716.947
22715.956
50433.903
81.28
21.85
Ftrotu
1
-60894.145
20365.793
-40527.352
82.65
45.12
Ftrot,colu
0
-66262.157
23538.768
-42723.390
79.99
69.35
Table 7: Results for different function classes on the CIFAR10 classiﬁcation task with two sets of transformations
(transformations that do not form groups) on images: arbitrary angle rotations (with cropping due to rotation)
and arbitrary hue shifts. The task is invariant to arbitrary rotations of the image (sD) but sensitive to color (D).
RpFq, {
COMPpF, Dq and SpF, Dq are as discussed in Section 4.2. Bold values indicate the function class
chosen by GES method with the proposed scoring criterion. Test accuracy is computed on the extrapolated
dataset after shifting the distribution of PptUiuiPsDq. We see that the SpF, Dq loss selects the correct model
class in training.
Model class
RpFq
` {
COMPpF, Dq
` NLLpF, Dq
“ SpF, Dq
Train Acc
Test Acc
Ftu
3
27724.256
42166.993
69894.250
64.37
17.16
Ftcolu
1
27715.023
49744.680
77460.703
42.69
10.91
Ftrotu
1
-91370.533
46218.086
-45151.447
61.77
52.60
Ftrot,colu
0
-92009.184
50246.908
-41762.276
41.45
35.56
augmenting both arbitrarily rotated images and hue-shifted images. Once again, FH is the space of
functions with no invariance (standard CNN with no data augmentations).
Results.
We show in Tables 6 and 7 that our method is able to ﬁnd the correct invariance and
achieves the best OOD test accuracy whereas the standard CNN with no invariance has poor OOD
performance.
A.6
MORE ON LUMPABILITY (DEFINITION 2)
We show that the lumpability condition of Deﬁnition 2 is equivalent to the normal subgroup condition
of Mouli & Ribeiro (2021, Theorem 2) when the given equivalence relations are obtained from trans-
formation groups. However, unlike the normal subgroup condition, the lumpability condition applies
in the general case when the equivalence relations are not necessarily obtained via transformation
groups.
Proposition 1. Let „G1 and „G2 be two equivalence relations on the input space X obtained as
orbits under transformation groups G1 and G2 respectively, i.e., for i “ 1, 2, x „Gi x1 iff there
exists tpiq P Gi with x1 “ tpiq ˝ x. Then, „G1 is lumpable with respect to the transformations G2
(Deﬁnition 2) if and only if G1 is a normal subgroup of G1 _ G2, where _ is the join operator.
Proof. First, given „G1 is lumpable with respect to G2, we wish to prove that G1 is a normal
subgroup of G1 _ G2. By deﬁnition of the join operator on transformation groups, G1 is a subgroup
of G1 _ G2.
Next, consider an equivalence class rxsG1 P X{ „G1. Then, by the lumpability of „G1 with respect
to G2, we have that for all tp2q P G2, there exists rx1sG1 with x˚ P rxsG1 ùñ tp2q ˝ x˚ P rx1sG1.
In other words, each tp2q maps all points in one equivalence class rxsG1 to another equivalence class
18

Published as a conference paper at ICLR 2022
rx1sG1. Speciﬁcally, tp2q maps x P rxsG1 to tp2q ˝x P rx1sG1. Thus, we can set x1 “ tp2q ˝x without
loss of generality.
Then, for all tp2q P G2, we have from the lumpability condition that
x˚ P rxsG1 ùñ tp2q ˝ x˚ P rtp2q ˝ xsG1 .
(9)
Recall from the deﬁnition of the equivalence class derived from a transformation group (i.e., the
orbit) that x˚ P rxsG1 means that there exists a transformation tp1q P G1 that maps x to x˚, i.e.,
x˚ “ tp1q ˝ x. Similarly, tp2q ˝ x˚ P rtp2q ˝ xsG1 means that there exists another transformation ˜tp1q
such that tp2q ˝ x˚ “ ˜tp1q ˝ tp2q ˝ x.
Equation (9) then becomes
Dtp1q P G1 s.t. x˚ “ tp1q ˝ x ùñ D˜tp1q P G1 s.t. tp2q ˝ x˚ “ ˜tp1q ˝ tp2q ˝ x ,
(10)
for all tp2q P G2.
Since Equation (10) holds for all x˚ P rxsG1 and for all x P X, we have @tp2q P G2, @tp1q P
G1, D˜tp1q P G1 such that,
tp2q ˝ tp1q “ ˜tp1q ˝ tp2q ,
which implies that G1 is a normal subgroup of G1 _ G2. The converse can be proved trivially by
reversing the steps of the above proof.
19

