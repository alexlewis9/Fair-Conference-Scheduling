Published as a conference paper at ICLR 2022
MINIBATCH VS LOCAL SGD WITH SHUFFLING:
TIGHT CONVERGENCE BOUNDS AND BEYOND
Chulhee Yun
KAIST AI
chulhee.yun@kaist.ac.kr
Shashank Rajput
Univ. of Wisconsin-Madison CS
rajput3@wisc.edu
Suvrit Sra
MIT EECS
suvrit@mit.edu
ABSTRACT
In distributed learning, local SGD (also known as federated averaging) and its
simple baseline minibatch SGD are widely studied optimization methods. Most
existing analyses of these methods assume independent and unbiased gradient es-
timates obtained via with-replacement sampling. In contrast, we study shufﬂing-
based variants: minibatch and local Random Reshufﬂing, which draw stochastic
gradients without replacement and are thus closer to practice. For smooth func-
tions satisfying the Polyak-Łojasiewicz condition, we obtain convergence bounds
(in the large epoch regime) which show that these shufﬂing-based variants con-
verge faster than their with-replacement counterparts. Moreover, we prove match-
ing lower bounds showing that our convergence analysis is tight. Finally, we
propose an algorithmic modiﬁcation called synchronized shufﬂing that leads to
convergence rates faster than our lower bounds in near-homogeneous settings.
1
INTRODUCTION
Distributed learning within the framework of federated learning (Koneˇcn`y et al., 2016; McMahan
et al., 2017) has witnessed increasing interest recently. A key property of this framework is that
models are trained locally using only private data on devices/machines distributed across a network,
while parameter updates are aggregated and synchronized at a server.1 Communication is often the
key bottleneck for federated learning, which drives the search for algorithms that can train fast while
requiring less communication—see Li et al. (2020a); Kairouz et al. (2021) for recent surveys.
A basic algorithm for federated learning is local stochastic gradient descent (SGD), also known as
federated averaging. The goal is to minimize the global objective that is an average of the local
objectives. In local SGD, we have M machines and a server. After each round of communication,
each of the M machines locally runs B steps of SGD on its local objective. Every B iterations, the
server aggregates the updated local iterates from the machines, averages them, and then synchronizes
the machines with the average. Convergence analysis of local SGD and its variants has drawn
great interest recently (Dieuleveut & Patel, 2019; Haddadpour et al., 2019; Haddadpour & Mahdavi,
2019; Stich, 2019; Yu et al., 2019; Li et al., 2020b;c; Koloskova et al., 2020; Khaled et al., 2020;
Spiridonoff et al., 2020; Karimireddy et al., 2020; Stich & Karimireddy, 2020; Qu et al., 2020).
Of the many, the biggest motivation for our paper comes from the line of work by Woodworth
et al. (2020a;b; 2021). In (Woodworth et al., 2020a;b), minibatch SGD is studied as a simple
yet powerful baseline for this intermittent communication setting. Instead of locally updating the
iterates B times, minibatch SGD aggregates B gradients (evaluated at the last synced iterate) from
each of the M machines, forms a minibatch of size MB, and then updates the shared iterate. Given
the same M and B, local SGD and minibatch SGD have the same number of gradient computations
per round of communication, so it is worthwhile to understand which converges faster. Woodworth
et al. (2020a;b) point out that many existing analyses on local SGD show inferior convergence rate
compared to minibatch SGD. Through their new upper and lower bounds, they identify regimes
where local SGD can be faster than minibatch SGD.
While the theory of local and minibatch SGD has seen recent progress, there is still a gap between
what is analyzed versus what is actually used. Most theoretical results assume independent and
1A distinctive feature of federated learning is that not all devices necessarily participate in the updates;
however, we focus on the full participation setting in this paper.
1

Published as a conference paper at ICLR 2022
unbiased gradient estimates obtained via with-replacement sampling of stochastic gradients (i.e.,
choosing training data indices uniformly at random). In contrast, most practitioners use without-
replacement sampling, where they shufﬂe indices randomly and access them sequentially.
Convergence analysis of without-replacement methods is challenging because gradients sampled
within an epoch lack independence. As a result, the standard theory based on independent gradient
estimates does not apply to shufﬂing-based methods. While shufﬂing-based methods are believed to
be faster in practice (Bottou, 2009), broad theoretical understanding of such methods remains elu-
sive, except for noteworthy recent progress mainly focusing on the analysis of SGD (G¨urb¨uzbalaban
et al., 2019; Haochen & Sra, 2019; Nagaraj et al., 2019; Nguyen et al., 2020; Safran & Shamir,
2020; 2021; Rajput et al., 2020; 2021; Ahn et al., 2020; Mishchenko et al., 2020; 2021; Tran et al.,
2021). These results indicate that in the large-epoch regime (where the number of epochs is greater
than some threshold), without-replacement SGD converges faster than with-replacement SGD.
1.1
OUR CONTRIBUTIONS
We analyze convergence rates of without-replacement versions of local and minibatch SGD, where
local component functions are reshufﬂed at every epoch. We call the respective algorithms local
RR (Algorithm 1) and minibatch RR (Algorithm 2), and their with-replacement counterparts local
SGD and minibatch SGD. Our key contributions are as follows:
• In Section 3, we present convergence bounds on minibatch and local RR for L-smooth func-
tions satisfying the µ-Polyak-Łojasiewicz condition (Theorems 1 & 2). Our theorems give high-
probability bounds, a departure from the common in-expectation bounds in the literature. We
show that minibatch and local RR converge faster than minibatch and local SGD when the num-
ber of epochs is sufﬁciently large. We also identify a regime where local RR converges as fast
as minibatch RR: when synchronization happens frequently enough and local objectives are not
too heterogeneous. See also Appendix A for a detailed comparison with existing upper bounds.
• In Section 4, we prove that the upper bounds obtained in Section 3 are tight, in all factors except
L and µ. We present Theorems 3 & 4 and Proposition 5 which show lower bounds that match
the upper bound up to a factor of L2/µ2. Our lower bound on local RR indicates that if the
synchronization interval B is too large, then local RR has no gain from parallel computation.
• In Section 5, we propose a simple modiﬁcation called synchronized shufﬂing that allows us to
bypass the lower bounds in Section 4, at the cost of a slight increase in communication. By having
the server broadcast random permutations to local machines, we show that in near-homogeneous
settings, the modiﬁed algorithms converge faster than the lower bounds (Theorems 6 & 7).
• In Appendix C, we present numerical experiments that corroborate our theoretical ﬁndings.
2
PROBLEM SETUP
Notation. For a natural number a ∈N, let [a] := {1, 2, . . . , a}. Let Sa be the set of all permutations
of [a]. Since our indices start from 1, we redeﬁne the modulo operation between a ∈Z and b ∈N
as a mod b := a −⌊a−1
b ⌋b, to make a mod b ∈[b].
Optimization task. Consider M machines, each with its objective F m(x) :=
1
N
PN
i=1 f m
i (x),
for m ∈[M]. The m-th machine has access only to the gradients of its own N local components
f m
1 (x), . . . , f m
N (x). In this setting, we wish to minimize the global objective function which is an
average of the local objectives: F(x) :=
1
M
PM
m=1 F m(x) =
1
MN
PM
m=1
PN
i=1 f m
i (x).
Further, we assume that each individual component function f m
i
is L-smooth, so that
f m
i (y) ≤f m
i (x) + ⟨∇f m
i (x), y −x⟩+ L
2 ∥y −x∥2 , for all x, y ∈Rd,
(1)
and that the global objective F satisﬁes the µ-Polyak-Łojasiewicz (PŁ) condition.2
1
2 ∥∇F(x)∥2 ≥µ(F(x) −F ∗) for all x ∈Rd,
where µ > 0.
(2)
Algorithms. Under the above setting, we analyze local RR (Algorithm 1) and minibatch RR (Algo-
rithm 2) and characterize their worst-case convergence rates.3 The algorithms are run over K epochs,
2PŁ functions can be thought as a nonconvex generalization of strongly convex functions.
3In Algorithms 1 and 2, consider SYNCSHUF as FALSE for now. We will discuss SYNCSHUF in Section 5.
2

Published as a conference paper at ICLR 2022
Algorithm 1 Local RR (with and without SYNCSHUF)
Input: Initialization y0, step-size η, # machines M, # components N, # epochs K, sync interval B.
1: Initialize xm
1,0 := y0 for all m ∈[M].
2: for k ∈[K] do
3:
if SYNCSHUF = TRUE then
▷Local RR with SYNCSHUF
4:
Sample σ ∼Unif(SN), π ∼Unif(SM).
5:
Set σm
k (i) := σ((i + N
M π(m)) mod N) for all m ∈[M], i ∈[N].
6:
else
▷Local RR
7:
Sample σm
k ∼Unif(SN) independently and locally, for all m ∈[M].
8:
end if
9:
for i ∈[N] do
10:
for m ∈[M] do locally
11:
Update xm
k,i := xm
k,i−1 −η∇f m
σm
k (i)(xm
k,i−1).
12:
end for
13:
if B divides i then
14:
Aggregate and average yk, i
B :=
1
M
PM
m=1 xm
k,i.
15:
Synchronize xm
k,i := yk, i
B , for all m ∈[M].
16:
end if
17:
end for
18:
xm
k+1,0 := yk, N
B , for all m ∈[M].
19: end for
20: return the last iterate yK, N
B .
Algorithm 2 Minibatch RR (with and without SYNCSHUF)
Input: Initialization x0, step-size η, # machines M, # components N, # epochs K, sync interval B.
1: Initialize x1,0 := x0.
2: for k ∈[K] do
3:
if SYNCSHUF = TRUE then
▷Minibatch RR with SYNCSHUF
4:
Sample σ ∼Unif(SN), π ∼Unif(SM).
5:
Set σm
k (i) := σ((i + N
M π(m)) mod N) for all m ∈[M], i ∈[N].
6:
else
▷Minibatch RR
7:
Sample σm
k ∼Unif(SN) independently and locally, for all m ∈[M].
8:
end if
9:
for i ∈[ N
B ] do
10:
Update xk,i := xk,i−1 −
η
M
XM
m=1
1
B
XiB
j=(i−1)B+1 ∇f m
σm
k (j)(xk,i−1)
|
{z
}
averaging done locally
.
11:
end for
12:
xk+1,0 := xk, N
B .
13: end for
14: return the last iterate xK, N
B .
i.e., K passes over the entire component functions. At the beginning of epoch k, each machine m
shufﬂes its local component functions {f m
i }N
i=1 using a random permutation σm
k
∼Unif(SN).
In local RR, each machine makes B local RR updates to its iterate by sequentially accessing its
shufﬂed component functions, before the server aggregates iterates from all the machines and then
synchronizes the machines with the average iterate. In minibatch RR, instead of making B local
updates, each machine collects B gradients evaluated at the last iterate, and the server aggregates
them to make an update using these MB gradients. Since these two algorithms use the same amount
of communication and local gradients, minibatch RR is a simple yet powerful baseline for local RR.
Below, we collect our assumptions on the algorithm parameters used throughout the paper.
Assumption 1 (Algorithm parameters). We assume M ≥1, N ≥2, and K ≥1. Also, assume that
B divides N. We restrict 1 ≤B ≤N
2 for minibatch RR because B = N makes the algorithm equal
to GD. We also assume 2 ≤B ≤N for local RR because B = 1 makes the two algorithms the
same. We choose a constant step-size scheme, i.e., η > 0 is kept constant over all updates.
We next state assumptions on intra- and inter-machine deviations used in this paper.4
4Assumptions 2, 3 & 4 require that they hold for the whole Rd. We discuss ways to avoid it in Appendix D.7.
3

Published as a conference paper at ICLR 2022
Assumption 2 (Intra-machine deviation). There exists ν ≥0 such that for all m ∈[M] and i ∈[N],
∥∇f m
i (x) −∇F m(x)∥≤ν, for all x ∈Rd.
Assumption 2 requires that the difference between the gradient of each local component function
f m
i (x) and its corresponding local objective function F m(x) is uniformly bounded. It models the
variance of local components f m
i within each machine. While the uniform boundedness requirement
may look strong, we use this assumption to prove high-probability upper bounds, which are stronger
than the common in-expectation bounds. See Appendix A for comparisons with other assumptions,
and also Appendix D.7 for ways to avoid uniform boundedness over the entire Rd.
The next two assumptions capture the deviation across different machines, i.e., the degree of hetero-
geneity, in two different levels of granularity: objective-wise and component-wise.
Assumption 3 (Objective-wise inter-machine deviation). There exist τ ≥0 and ρ ≥1 such that
1
M
XM
m=1 ∥∇F m(x)∥≤τ + ρ ∥∇F(x)∥, for all x ∈Rd.
Assumption 3 models the heterogeneity by bounding the mean of ∥∇F m∥by a constant plus a
multiplicative factor times ∥∇F∥. The assumption includes the homogeneous case (i.e., F 1 = · · · =
F M = F) by τ = 0 and ρ = 1. Assumption 3 is weaker than many other heterogeneity assumptions
in the literature (e.g., Karimireddy et al. (2020)); see Appendix A for detailed comparisons.
Assumption 3 measures heterogeneity by only considering the local objectives F m, not the local
components f m
i . We consider a more ﬁne-grained notion of heterogeneity in Assumption 4:
Assumption 4 (Component-wise inter-machine deviation). For all i ∈[N], let ¯fi :=
1
M
PM
m=1 f m
i .
There exist λ ≥0 such that for all m ∈[M] and i ∈[N],
∇f m
i (x) −∇¯fi(x)
 ≤λ, for all x ∈Rd.
Assumption 4 states that the gradients of the i-th components of local machines are “close” to each
other. The assumption subsumes the component-wise homogeneous setting, i.e., f 1
i = f 2
i = · · · =
f M
i , by λ = 0. In distributed learning, this choice corresponds to the setting where each machine
has the same training dataset. Assumption 4 with λ > 0 is also relevant to the case where each
device has a slightly perturbed (e.g., by data augmentation techniques) version of a certain dataset.
It is straightforward to check that Assumption 4 implies Assumption 3 with τ = λ and ρ = 1.
We conclude this section by deﬁning the function classes we study in this paper.
Deﬁnition 1 (Function classes). We consider two classes of global objective functions F, also taking
into account their local objectives F m and local components f m
i . We assume throughout that f m
i
are differentiable and F is bounded from below.
Fobj(L, µ, ν, τ, ρ):=

F | F is µ-PŁ; f m
i
are L-smooth; F, F m, f m
i
satisfy Assumptions 2 & 3
	
,
Fcmp(L, µ, ν, λ):=

F | F is µ-PŁ; f m
i
are L-smooth; F, F m, f m
i
satisfy Assumptions 2 & 4
	
.
Notice that Fobj(L, µ, ν, τ, ρ) ⊃Fcmp(L, µ, ν, τ) for any ρ ≥1. We only make the PŁ assumption
on the global objective F, not on the local objectives F m nor on the local components f m
i . Using
L and µ, we deﬁne the condition number κ := L/µ ≥1.
3
CONVERGENCE ANALYSIS OF MINIBATCH AND LOCAL RR
3.1
UPPER BOUND FOR MINIBATCH RR
We ﬁrst begin with the convergence result for minibatch RR on Fobj(L, µ, ν, τ, ρ), which exhibits
a faster large-epoch rate compared to the single-machine setting. For upper bounds, we use ˜O(·) to
hide universal constants and logarithmic factors of 1
δ , M, N, K, and B.
Theorem 1 (Upper bound for minibatch RR). Suppose that minibatch RR has parameters satisfying
Assumption 1. For any F ∈Fobj(L, µ, ν, τ, ρ), consider running the algorithm using step-size
η = B log(MNK2)
µNK
for epochs K ≥6κ log(MNK2). Then, with probability at least 1 −δ,
F(xK, N
B ) −F ∗≤F(x0) −F ∗
MNK2
+ ˜O
L2
µ3
ν2
MNK2

.
(3)
4

Published as a conference paper at ICLR 2022
Proof. The proof is in Appendix D.2.
The key challenge in the convergence analysis of our
shufﬂing-based method stems from the indices sampled within an epoch being dependent on each
other. For example, if f m
1 is accessed already, then the index i = 1 will not be used in later iterations
of the epoch; this dependence signiﬁcantly complicates the analysis. Our approach starts with real-
izing that for any permutation σ, PN
i=1 f m
σ(i) = NF m. We decompose gradients ∇f m
σm
k (j)(xk,i−1)
(see Line 10 of Algorithm 2) into ∇f m
σm
k (j)(xk,0) plus noise, then aggregate all updates over an
epoch to get “one big step of GD plus noise”: xk+1,0 = xk,0 −ηN∇F(xk,0) + η2rk. We bound
the noise rk using Lemma 8 (Appendix D.6), which is our extension of the Hoeffding-Serﬂing in-
equality to the mean of M independent without-replacement sums of vectors; the lemma might be of
independent interest too. Lemma 8 shows that averaging accumulated gradients over M machines
reduces variance by M, which leads to the reduction by a factor of M in the bound (3).
Theorem 1 shows that for large enough epochs K ≳κ, minibatch RR converges at a rate of
˜O(
L2ν2
µ3MNK2 ), with high probability.
Compared to the large-epoch rate ˜O(
L2ν2
µ3NK2 ) of single-
machine RR (e.g., Ahn et al. (2020)), we see an additional factor M in the denominator, which
highlights the advantage of multiple machines. If we compare against the with-replacement coun-
terpart, it is known that for strongly convex and smooth F, the optimal convergence rate of minibatch
SGD is Θ(
ν2
µMNK ),5 which is worse than our bound (3) if K ≳κ2. Also notable is that the con-
vergence rate does not depend on the heterogeneity constants (i.e., τ and ρ from Assumption 3) of
the local objective functions. This observation that minibatch RR is “immune” to heterogeneity is
consistent with minibatch SGD in the with-replacement setting (Woodworth et al., 2020b).
Epoch vs communication complexity. One might wonder why (3) does not have the batch size B.
In (3), we wrote convergence rates in terms of epochs K, which captures the gradient computation
complexity because the same number of gradients are evaluated in a single epoch regardless of B. If
we are interested in communication complexity instead, we can write (3) in terms of the number of
communication rounds R := NK
B
and get a rate of ˜O(
L2ν2N
µ3MB2R2 ). From these, we can also discuss
the overall cost of the algorithm. If the cost of a communication round is cc, and the cost of local
gradient computations over an epoch is ce, then the total cost to obtain an ϵ-accurate solution is
Cminibatch(ϵ) = ˜O
ccν
√
N
B
√
Mϵ
+
ceν
√
MNϵ

,
(4)
omitting L and µ for simplicity. The total cost shows that there is essentially no harm increasing the
batch size B in minibatch RR, as we can get more accurate estimates of true gradients as B becomes
larger. In the next subsection, we will see that this is not the case in local RR.
What about K ≲κ? We remark that all upper bounds in this paper hold only for the “large-epoch”
regime, where K ≳κ. Such requirements are common in the literature of without-replacement
SGD (Haochen & Sra, 2019; Nagaraj et al., 2019; Rajput et al., 2020; Ahn et al., 2020), and there is
a recent result (Safran & Shamir, 2021) suggesting that faster convergence of without-replacement
SGD may not be possible in the K ≲κ regime. We defer a more detailed discussion on this regime
to Section 4, after Theorem 3.
3.2
UPPER BOUND FOR LOCAL RR
Next, we are interested in how fast local RR can converge, what is the optimal batch size B, and
whether local RR can be as fast as minibatch RR.
Theorem 2 (Upper bound for local RR). Suppose that local RR has parameters satisfying As-
sumption 1.
For any F ∈Fobj(L, µ, ν, τ, ρ), consider running the algorithm using step-size
η = log(MNK2)
µNK
for epochs K ≥7ρκ log(MNK2). Then, with probability at least 1 −δ,
F(yK, N
B ) −F ∗≤F(y0) −F ∗
MNK2
+ ˜O
L2
µ3

ν2
MNK2 + ν2B
N 2K2 + τ 2B2
N 2K2

.
(5)
5The optimal rate for (with-replacement) SGD after R iterations is Θ( ν2
µR) (see e.g., Rakhlin et al. (2012)).
With-replacement minibatching reduces the variance ν2 to
ν2
MB , and R = NK
B . However, achieving the optimal
rate for last iterates typically requires carefully designed step-size schemes (Jain et al., 2019).
5

Published as a conference paper at ICLR 2022
Proof. The proof is in Appendix D.3. We take the same “big GD step plus noise” approach as in
Theorem 1; however, due to local updates, bounding the noise is much more involved. In the proof,
we obtain the epoch update yk+1,0 = yk,0 −ηN∇F(xk,0) + η2rk,1 + η2rk,2 −η3rk,3, where rk,1
and rk,3 contain errors introduced by local updates. Noise from local updates accumulates over B
iterations, which cannot be remedied by averaging over M machines. They result in two additional
terms in the rate (5), one from intra-machine variance and the other from heterogeneity.
3.2.1
DISCUSSION OF THEOREM 2
Let us compare our high-probability bound (5) with existing in-expectation bounds. For strongly
convex F, the corresponding last-iterate bound of local SGD is ˜O(
Lν2
µ2MNK +
L2ν2B
µ3N2K2 + L2τ 2B2
µ3N 2K2 )6
(Khaled et al., 2020; Spiridonoff et al., 2020; Qu et al., 2020). Notice that (5) is better than this
with-replacement bound when K ≳κ. For average iterates, there are known bounds ˜O(
ν2
µMNK +
Lν2B
µ2N2K2 +
Lτ 2B2
µ2N 2K2 )6 (Koloskova et al., 2020; Woodworth et al., 2020b) which are smaller than the
last-iterate bound by a factor of κ. It is unclear if averaging iterates could improve our rate, because
most such analyses exploit Jensen’s inequality, which we cannot use for nonconvex F.
Dependence on τ and ρ. Out of the two heterogeneity constants τ and ρ (Assumption 3), ρ does
not appear in (5), and it only affects the epoch requirement K ≳ρκ. Consider the case τ = 0 and
ρ > 1, which is heterogeneous but in the “interpolation regime,” because ∇F m(x) = 0 whenever
∇F(x) = 0. In such a case, the rate (5) is equal to the homogeneous case.
Using B = Θ(N) is no better than single-machine. A close look at Theorem 2 reveals a rather
surprising fact. Even in the homogeneous case (τ = 0), if we choose B = Θ(N), then local RR
converges at the rate of ˜O(
1
NK2 ): the same rate as the single-machine RR! In Section 4, we show
that this observation is not due to a suboptimal analysis; the rate ˜O(
1
NK2 ) is tight for B = Θ(N).
Trade-off in the choice of B. As done for Theorem 1, we can compute from (5) that the total cost
of local RR for ϵ-accuracy is (omitting L and µ for simplicity)
Clocal(ϵ) = ˜O

cc
 ν
√
N
B
√
Mϵ
+
ν
√
Bϵ
+ τ√ϵ

+ ce

ν
√
MNϵ
+ ν
√
B
N√ϵ + τB
N√ϵ

.
(6)
Note that for local RR, there exists a trade-off between communication and epoch complexity in the
choice of B. If B is too small, this reduces the number of epochs required but increases communi-
cation costs. On the other hand, if B is too large, this reduces communication rounds but errors that
accumulate in local updates get severer, resulting in the need for more epochs. Hence, the optimal
choice of B must balance the two complexity measures. The existence of this trade-off is indeed
different from minibatch RR where larger B always reduces the total cost Cminibatch(ϵ).
When can local RR match minibatch RR? Comparing the convergence rates (3) and (5), we
can identify some regimes in which local RR converges as fast as minibatch RR. In a nutshell, if
machines are not too heterogeneous and communication happens frequently, then local RR can have
the same upper bound as minibatch RR. For example, if B is chosen to be a constant, M ≲N,
and τ ≲ν
p
N/M, then the ˜O(
L2ν2
µ3MNK2 ) term in (5) becomes the dominating factor and hence
matches (3). Another example of such a regime is when B ≲N
M and τ ≲ν
p
M/N. Note that this
comparison assumes that the same values of B are chosen for both algorithms. Also, such “frequent
communication” regimes are favorable if the communication cost cc is small.
Can local RR ever beat minibatch RR? The upper bounds (3) and (5) indicate that local RR is
always no better than minibatch RR, at least for the function class Fobj(L, µ, ν, τ, ρ). This is in fact
consistent with Woodworth et al. (2020a;b), because the authors identify a regime where local SGD
performs better than minibatch SGD for convex objective functions, but fail to do so for strongly
convex functions. However, as was also pointed out in Woodworth et al. (2020a), there is a simple
extreme scenario in which local RR can be faster: when ν ≈τ ≈0 and ρ ≈1. In this case, we
have f m
i
≈F for all m and i, so local RR corresponds to NK steps of GD, whereas minibatch RR
corresponds to NK
B steps of GD. Clearly, local RR will converge faster, exploiting the advantage of
more updates. Finding out other such regimes is an important future direction.
6Due to differences in assumptions, many existing rates cannot be compared directly. These rates are the
ones we consider “comparable” to our bound. See Appendix A for more detailed comparisons.
6

Published as a conference paper at ICLR 2022
4
MATCHING LOWER BOUNDS
In Section 3, we presented large-epoch upper bounds (i.e., for K ≳κ) for constant step-size mini-
batch and local RR. In this section, we prove matching lower bounds to show that the upper bounds
are tight, in all factors except L and µ. We use Ω(·) to hide universal constants in lower bounds.
4.1
LOWER BOUND FOR MINIBATCH RR
Theorem 3 (Lower bound for minibatch RR). Suppose that minibatch RR has parameters satisfying
Assumption 1. Additionally, assume that N is a multiple of 2. Then, there exist large enough
constants c1, c2 > 0 such that the following holds: For L and µ satisfying κ = L
µ ≥c1, there exists
a function F ∈Fcmp(L, µ, ν, 0) such that for any constant step-size η,
E
h
F(xK, N
K ) −F ∗i
=



Ω

ν2
µMNK

if K < c2κ,
Ω

ν2
µMNK2

if K ≥c2κ.
(7)
Proof. We prove Theorem 3 in Appendix E. The proof is an extension of Rajput et al. (2020); Safran
& Shamir (2020; 2021) to minibatch RR. We will sketch some key intuitions after Theorem 4.
First notice that the function F is from Fcmp(L, µ, ν, 0), where all the machines are component-wise
homogeneous. As seen in Deﬁnition 1, Fcmp(L, µ, ν, 0) ⊂Fobj(L, µ, ν, τ, ρ) for any τ ≥0 and
ρ ≥1, so Theorem 3 provides a lower bound for Fcmp(·) and Fobj(·), with arbitrary heterogeneity
constants. We assume that N is even because we construct functions g1 and g2 such that f m
i
:= g1
if i ≤N
2 , and f m
i
:= g2 if i > N
2 . One can remove this assumption by using a zero function when
N is odd (see e.g., Safran & Shamir (2020)). It is rather unsatisfactory that our theorem requires
large enough constants c1 and c2; we believe a tighter analysis can relax this restriction.
Theorem 3 proves lower bounds for two different regimes: K ≳κ and K ≲κ. In the large-epoch
regime (K ≳κ), we can observe that the lower bound Ω(
ν2
µMNK2 ) matches the upper bound (3) in
Theorem 1, modulo a factor of κ2. Tightening the κ2 gap between upper and lower bounds is left
for future work. In the small-epoch regime (K ≲κ), we observe that the lower bound Ω(
ν2
µMNK )
exactly matches the convergence rate of (with-replacement) minibatch SGD; hence, the lower bound
implies that minibatch RR has no hope for faster convergence than minibatch SGD, at least in the
constant step-size and small-epoch regime. This observation is in line with Safran & Shamir (2021).
Upper bounds for K ≲κ? Even for single-machine RR (M = 1), proving an upper bound that
matches the small-epoch lower bound Ω(
ν2
µNK ) still remains a challenge. Nagaraj et al. (2019, The-
orem 2) prove an upper bound for non-quadratic strongly convex functions that matches Ω(
ν2
µNK ) if
NK ≳κ2; however, they use sufﬁx averaging, so it is not directly comparable to Theorem 3 which
considers last iterates. Safran & Shamir (2021) prove upper bounds for quadratic strongly convex
functions, but assume that their Hessian matrices commute. For noncommutative cases, proving a
small-epoch upper bound seems to require some form of matrix AM-GM inequalities, whose avail-
ability is an open problem (Recht & R´e, 2012; Lai & Lim, 2020; De Sa, 2020; Yun et al., 2021).
Remark 1 (Strong convexity in construction). We note that all lower bounds in this paper are con-
structed with strongly convex functions, a stronger assumption than PŁ functions (2). Thus, our
lower bounds are also applicable to strong convexity counterparts of Fobj(·) and Fcmp(·).
4.2
LOWER BOUNDS FOR LOCAL RR
In this subsection, we present lower bounds for local RR. We prove two bounds that correspond to
homogeneous and heterogeneous cases. By combining the two bounds, we get a lower bound that
matches our upper bound (5) in Theorem 2 up to a factor of κ2.
Theorem 4 (Lower bound for local RR: homogeneous case). Suppose that local RR has parameters
satisfying Assumption 1. Additionally, assume that B is a multiple of 4. Then, there exist large
enough constants c3, c4 > 0 such that the following holds: For L and µ satisfying κ = L
µ ≥c3,
there exists a function F ∈Fcmp(L, µ, ν, 0) such that for any constant step-size η,
E
h
F(yK, N
K ) −F ∗i
=



Ω

ν2
µMNK

if K < max

c4κ, MB
N
	
,
Ω

ν2
µMNK2 +
ν2B
µN2K2

if K ≥max

c4κ, MB
N
	
.
(8)
7

Published as a conference paper at ICLR 2022
Proof. The proof is in Appendix G. For the large-epoch lower bounds in Theorems 3 and 4, we
use “skewed” quadratics f m
i (x) = (L1x≤0 + µ1x>0) x2
2 + ziνx, where zi = +1 if i ≤
N
2 and
zi = −1 otherwise. For x ≈0, the imbalance results in a “drift” towards positive x, whose strength
is approximately proportional to the absolute value of partial sums of random permutations over N
2
+1’s and N
2 −1’s. By averaging the sums over M machines (minibatch RR), their absolute values
shrink by
1
√
M ; in contrast, if each machine makes local updates (local RR), the magnitude of the
drift cannot be reduced with M, because we average after local iterates already have taken B “big”
steps. The proof uses techniques from Rajput et al. (2020).
Proposition 5 (Lower bound for local RR: heterogeneous case). Suppose that local RR has param-
eters satisfying Assumption 1. Additionally, assume that B is a multiple of 2 and κ = L
µ ≥2. Then,
there exists a function F ∈Fobj(L, µ, 0, τ, 1) such that for any constant step-size η,
E
h
F(yK, N
K ) −F ∗i
= Ω
 τ 2B2
µN 2K2

.
(9)
Proof. We note that Proposition 5 is almost identical to Theorem II of Karimireddy et al. (2020);
however, we provide a proof speciﬁc to our algorithm in Appendix I.
Theorem 4 constructs a component-wise homogeneous function from Fcmp(L, µ, ν, 0) and Propo-
sition 5 constructs a heterogeneous function from Fobj(L, µ, 0, τ, 1).
Since Fcmp(L, µ, ν, 0) ∪
Fobj(L, µ, 0, τ, 1) ⊂Fobj(L, µ, ν, τ, ρ) for any ρ ≥1, combining (8) and (9) for the K ≥
max{c4κ, MB
N } case gives a lower bound Ω(max{
ν2
µMNK2 +
ν2B
µN2K2 ,
τ 2B2
µN2K2 }) that matches the
large-epoch upper bound (5) in Theorem 2, up to a factor of κ2. When κN ≳MB, c4κ becomes
the dominating term in the max, in which case the threshold in (8) is Θ(κ). Tightening the κ2 gap as
well as removing additional requirements such as κ ≥c3 and κN ≳MB are left for future work.
Using B = Θ(N) does not help, indeed. In Section 3.2.1, we observed that if B = Θ(N), then
even in the homogeneous case (τ = 0), local RR converges at the rate of ˜O(
1
NK2 ). This is the same
rate as single-machine RR, meaning the efforts by M −1 machines become meaningless. Our lower
bound (8) shows that ˜O(
1
NK2 ) is in fact the best we can hope for (treating L and µ as constants).
In order to make the best use of M machines, B should be smaller than Θ(N), as suggested in
Section 3.2.1. In an existing work, Mishchenko et al. (2021) consider local RR with B = N as a
special case of a proximal algorithm. In Theorem 8 of Mishchenko et al. (2021), the authors claim
“the convergence bound improves with the number of devices involved” because the bound has a
factor of M in the denominator. However, at least under our assumption, this is not the case; if we
apply our Assumption 3 to upper-bound their σ∗, the term “Nσ2
∗” in the numerator grows linearly
with M. Hence, our bounds do not contradict Mishchenko et al. (2021); see Appendix A for details.
Remark 2 (Small-epoch bound is likely loose). We note that while we focused on deriving a match-
ing large-epoch lower bound, we did not try hard to tighten the small-epoch lower bound. Our
small-epoch lower bound in (8) misses a term (such as
ν2B
µN2K2 ) that corresponds to the error from
local updates. We leave investigations on small-epoch lower and upper bounds for future work.
5
SYNCHRONIZED SHUFFLING: HOW TO BYPASS LOWER BOUNDS
Recall from the total complexity of minibatch RR (4) that the total cost shrinks with a factor of
1
√
M .
Using M machines, we are only getting a
√
M-factor speedup. Ideally, we hope to see a linear
speedup, i.e., cost inverse proportional to M. Hence, Theorem 1 falls short of achieving this goal,
and our lower bound in Theorem 3 conﬁrms that linear speedup is indeed impossible.
In this section, we show that the desired linear speedup is possible, at least in some special cases.
We consider the component-wise near-homogeneous case (i.e., Assumption 4 with small λ) and
discuss how a simple modiﬁcation to minibatch and local RR can let us “break” the lower bounds
and achieve linear speedup. This comes at a cost of broadcasting permutations: at the beginning
of the k-th epoch, the server samples σ ∼Unif(SN) and π ∼Unif(SM), and broadcasts them
to the machines. Then, local machines choose their permutations σm
k to be shifted versions of σ,7
i.e., σm
k (i) := σ
  i + N
M π(m)

mod N

. We call this trick synchronized shufﬂing, denoted as
7We assume for simplicity that M divides N.
8

Published as a conference paper at ICLR 2022
SYNCSHUF. Please revisit Algorithms 1 and 2 for the precise descriptions of the modiﬁed algo-
rithms local RR with SYNCSHUF and minibatch RR with SYNCSHUF, respectively.
The intuition why this should help is simple. In the proof of RR, we aggregate the component gra-
dients over an epoch (i.e., N iterations) to write it as a full gradient plus noise. If we are in the
component-wise homogeneous setting and permutations are synchronized, then instead of aggre-
gating N component gradients on a single machine, we can aggregate N
M component gradients on
M machines to get a full gradient. This allows us to reduce the “noise” from without-replacement
sampling. We emphasize here that we do not necessarily set B =
N
M to get a full gradient every
time; our analysis works for arbitrary B and M, as long as both divide N. See Appendix B for a
detailed illustration of SYNCSHUF; also, see Appendix C for experiments showing its effectiveness.
The idea of synchronized shufﬂing is similar to approaches in distributed learning that shufﬂe and
partition datasets and distribute them to local machines (see e.g., Lee et al. (2017); Meng et al.
(2017)). In contrast, we do not communicate data, but communicate how to permute datasets stored
in local machines. Meng et al. (2017, Theorem 3.3) provide an analysis for a distributed method
similar to minibatch RR, but fail to show convergence to global minima in strongly convex cases.
We also note that an independent concurrent result (Szlendak et al., 2021) uses the same idea as
SYNCSHUF to build compressors for communication-efﬁcient distributed optimization.
5.1
UPPER BOUNDS FOR MINIBATCH AND LOCAL RR WITH SYNCSHUF
With SYNCSHUF, we can show that the M’s appearing in the convergence rates ((3) and (5)) in
Theorems 1 and 2 can be replaced with M 2, for a more stringent function class Fcmp(·) that requires
bounded component-wise inter-machine deviation (Assumption 4).
Theorem 6 (Upper bound for minibatch RR with SYNCSHUF). Suppose that minibatch RR with
SYNCSHUF has parameters satisfying Assumption 1. Additionally assume that M divides N. For
any F ∈Fcmp(L, µ, ν, λ), consider running the algorithm using step-size η = B log(M 2NK2)
µNK
for
epochs K ≥6κ log(M 2NK2). Then, with probability at least 1 −δ,
F(xK, N
B ) −F ∗≤F(x0) −F ∗
M 2NK2
+ ˜O
L2
µ3

ν2
M 2NK2 +
λ2
MK2

.
(10)
The proof of Theorem 6 is presented in Appendix D.4. One can check that if the component-
wise deviation constant λ satisﬁes λ ≲
ν
√
MN (i.e., near-homogeneous), then the rate (10) becomes
˜O(
1
M 2NK2 ). It is then easy to conﬁrm that M machines reduce total costs by
1
M —a linear speedup.
A similar speedup can be shown for local RR. In Appendix D.5, we prove that
Theorem 7 (Upper bound for local RR with SYNCSHUF). Suppose that local RR with SYNCSHUF
has parameters satisfying Assumption 1. Additionally assume that M divides N. For any F ∈
Fcmp(L, µ, ν, λ), consider running the algorithm with step-size η = log(M 2NK2)
µNK
for epochs K ≥
7κ log(M 2NK2). Then, with probability at least 1 −δ,
F(yK, N
B ) −F ∗≤F(y0) −F ∗
M 2NK2
+ ˜O
L2
µ3

ν2
M 2NK2 + ν2B
N 2K2 + λ2B2
N 2K2 +
λ2
MK2

. (11)
We can similarly check that if B ≲
N
M 2 and λ ≲
ν
√
MN , i.e., frequent communication and near-
homogeneity, then the ˜O(
1
M 2NK2 ) term dominates in (11), and hence gives a linear speedup that
matches the best rate of minibatch RR with SYNCSHUF (10). Nevertheless, we note again that for
local RR, such a small B is favorable only when the communication cost cc is small (recall (6)).
6
CONCLUSION
We studied convergence bounds for local RR and minibatch RR, which are the practical without-
replacement versions of local and minibatch SGD studied in the theory literature. For smooth func-
tions satisfying the Polyak-Łojasiewicz condition, we showed large-epoch convergence bounds for
minibatch and local RR that are faster than their with-replacement counterparts. We also proved
matching lower bounds showing that our convergence analysis is tight. We also proposed a sim-
ple modiﬁcation called synchronized shufﬂing that leads to convergence rates faster than our lower
bounds in near-homogeneous settings. Immediate future research directions include extension to
small-epoch regimes, as well as to general convex and nonconvex functions.
9

Published as a conference paper at ICLR 2022
ETHICS STATEMENT
This paper develops theoretical guarantees for popular distributed stochastic optimization algo-
rithms. Therefore, the authors do not see any particular concerns related to its ethical aspects or
future societal consequences.
REPRODUCIBILITY STATEMENT
This paper is a theoretical work, without any experimental results. Deﬁnitions and assumptions are
provided in Section 2. Our theoretical contributions as well as some additionally required assump-
tions are clearly stated in Sections 3, 4, and 5. Complete proofs of all the theorems are provided in
the appendix.
REFERENCES
Kwangjun Ahn, Chulhee Yun, and Suvrit Sra. SGD with shufﬂing: optimal rates without component
convexity and large epoch requirements. In Advances in Neural Information Processing Systems,
2020.
L´eon Bottou. Curiously fast convergence of some stochastic gradient descent algorithms. In Pro-
ceedings of the symposium on learning and data science, Paris, 2009.
Christopher M De Sa. Random reshufﬂing is not always better. Advances in Neural Information
Processing Systems, 33, 2020.
Aymeric Dieuleveut and Kumar Kshitij Patel. Communication trade-offs for local-sgd with large
step size. Advances in Neural Information Processing Systems, 32:13601–13612, 2019.
Mert G¨urb¨uzbalaban, Asu Ozdaglar, and Pablo Parrilo. Why random reshufﬂing beats stochastic
gradient descent. Mathematical Programming, pp. 1–36, 2019.
Farzin Haddadpour and Mehrdad Mahdavi. On the convergence of local descent methods in feder-
ated learning. arXiv preprint arXiv:1910.14425, 2019.
Farzin Haddadpour, Mohammad Mahdi Kamani, Mehrdad Mahdavi, and Viveck Cadambe. Local
sgd with periodic averaging: Tighter analysis and adaptive synchronization. Advances in Neural
Information Processing Systems, 32:11082–11094, 2019.
Jeff Haochen and Suvrit Sra. Random shufﬂing beats SGD after ﬁnite epochs. In International
Conference on Machine Learning, pp. 2624–2633, 2019.
Prateek Jain, Dheeraj Nagaraj, and Praneeth Netrapalli. Making the last iterate of sgd information
theoretically optimal. In Conference on Learning Theory, pp. 1752–1755. PMLR, 2019.
Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aur´elien Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, Rafael
G. L. D’Oliveira, Hubert Eichner, Salim El Rouayheb, David Evans, Josh Gardner, Zachary
Garrett, Adri`a Gasc´on, Badih Ghazi, Phillip B. Gibbons, Marco Gruteser, Zaid Harchaoui,
Chaoyang He, Lie He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Ja-
vidi, Gauri Joshi, Mikhail Khodak, Jakub Konecn´y, Aleksandra Korolova, Farinaz Koushanfar,
Sanmi Koyejo, Tancr`ede Lepoint, Yang Liu, Prateek Mittal, Mehryar Mohri, Richard Nock, Ayfer
¨Ozg¨ur, Rasmus Pagh, Hang Qi, Daniel Ramage, Ramesh Raskar, Mariana Raykova, Dawn Song,
Weikang Song, Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian Tram`er, Pra-
neeth Vepakomma, Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang, Felix X. Yu, Han Yu, and
Sen Zhao. Advances and open problems in federated learning. Foundations and Trends® in
Machine Learning, 14(1–2):1–210, 2021. ISSN 1935-8237. doi: 10.1561/2200000083. URL
http://dx.doi.org/10.1561/2200000083.
Hamed Karimi, Julie Nutini, and Mark Schmidt. Linear convergence of gradient and proximal-
gradient methods under the Polyak-łojasiewicz condition. In Joint European Conference on Ma-
chine Learning and Knowledge Discovery in Databases, pp. 795–811. Springer, 2016.
10

Published as a conference paper at ICLR 2022
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In
International Conference on Machine Learning, pp. 5132–5143. PMLR, 2020.
Ahmed Khaled, Konstantin Mishchenko, and Peter Richt´arik. Tighter theory for local sgd on identi-
cal and heterogeneous data. In International Conference on Artiﬁcial Intelligence and Statistics,
pp. 4519–4529. PMLR, 2020.
Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, and Sebastian Stich. A uniﬁed
theory of decentralized sgd with changing topology and local updates. In International Confer-
ence on Machine Learning, pp. 5381–5393. PMLR, 2020.
Jakub Koneˇcn`y, H Brendan McMahan, Felix X Yu, Peter Richt´arik, Ananda Theertha Suresh, and
Dave Bacon.
Federated learning: Strategies for improving communication efﬁciency.
arXiv
preprint arXiv:1610.05492, 2016.
Zehua Lai and Lek-Heng Lim. Recht-R´e noncommutative arithmetic-geometric mean conjecture is
false. In International Conference on Machine Learning, 2020.
Kangwook Lee, Maximilian Lam, Ramtin Pedarsani, Dimitris Papailiopoulos, and Kannan Ram-
chandran. Speeding up distributed machine learning using codes. IEEE Transactions on Infor-
mation Theory, 64(3):1514–1529, 2017.
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges,
methods, and future directions. IEEE Signal Processing Magazine, 37(3):50–60, 2020a.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia
Smith.
Federated optimization in heterogeneous networks.
In I. Dhillon, D. Papailiopou-
los, and V. Sze (eds.), Proceedings of Machine Learning and Systems, volume 2, pp.
429–450, 2020b.
URL https://proceedings.mlsys.org/paper/2020/file/
38af86134b65d0f10fe33d30dd76442e-Paper.pdf.
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of
fedavg on non-iid data. In International Conference on Learning Representations, 2020c.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efﬁcient learning of deep networks from decentralized data. In Artiﬁcial intelli-
gence and statistics, pp. 1273–1282. PMLR, 2017.
Qi Meng, Wei Chen, Yue Wang, Zhi-Ming Ma, and Tie-Yan Liu. Convergence analysis of distributed
stochastic gradient descent with shufﬂing. arXiv preprint arXiv:1709.10432, 2017.
Konstantin Mishchenko, Ahmed Khaled, and Peter Richt´arik. Random reshufﬂing: Simple analysis
with vast improvements. arXiv preprint arXiv:2006.05988, 2020.
Konstantin Mishchenko, Ahmed Khaled, and Peter Richt´arik.
Proximal and federated random
reshufﬂing. arXiv preprint arXiv:2102.06704, 2021.
Dheeraj Nagaraj, Prateek Jain, and Praneeth Netrapalli. SGD without replacement: Sharper rates
for general smooth convex functions. In International Conference on Machine Learning, pp.
4703–4711, 2019.
Lam M. Nguyen, Quoc Tran-Dinh, Dzung T. Phan, Phuong Ha Nguyen, and Marten van Dijk. A uni-
ﬁed convergence analysis for shufﬂing-type gradient methods. arXiv preprint arXiv:2002.08246,
2020.
Iosif Pinelis. An approach to inequalities for the distributions of inﬁnite-dimensional martingales.
In Probability in Banach Spaces, 8: Proceedings of the Eighth International Conference, pp.
128–134. Springer, 1992.
Iosif Pinelis. Optimum bounds for the distributions of martingales in banach spaces. The Annals of
Probability, pp. 1679–1706, 1994.
11

Published as a conference paper at ICLR 2022
Zhaonan Qu, Kaixiang Lin, Jayant Kalagnanam, Zhaojian Li, Jiayu Zhou, and Zhengyuan Zhou.
Federated learning’s blessing: Fedavg has linear speedup.
arXiv preprint arXiv:2007.05690,
2020.
Shashank Rajput, Anant Gupta, and Dimitris Papailiopoulos. Closing the convergence gap of SGD
without replacement. In International Conference on Machine Learning, 2020.
Shashank Rajput, Kangwook Lee, and Dimitris Papailiopoulos. Permutation-based sgd: Is random
optimal? arXiv preprint arXiv:2102.09718, 2021.
Alexander Rakhlin, Ohad Shamir, and Karthik Sridharan. Making gradient descent optimal for
strongly convex stochastic optimization. In Proceedings of the 29th International Coference on
International Conference on Machine Learning, pp. 1571–1578, 2012.
Benjamin Recht and Christopher R´e. Toward a noncommutative arithmetic-geometric mean inequal-
ity: conjectures, case-studies, and consequences. In Conference on Learning Theory, pp. 11–1,
2012.
Itay Safran and Ohad Shamir. How good is SGD with random shufﬂing? In Conference on Learning
Theory, pp. 3250–3284. PMLR, 2020.
Itay Safran and Ohad Shamir.
Random shufﬂing beats SGD only after many epochs on ill-
conditioned problems. arXiv preprint arXiv:2106.06880, 2021.
Markus Schneider. Probability inequalities for kernel embeddings in sampling without replacement.
In Artiﬁcial Intelligence and Statistics, pp. 66–74, 2016.
Robert J Serﬂing. Probability inequalities for the sum in sampling without replacement. The Annals
of Statistics, pp. 39–48, 1974.
Artin Spiridonoff, Alex Olshevsky, and Ioannis Ch Paschalidis. Local sgd with a communication
overhead depending only on the number of workers. arXiv preprint arXiv:2006.02582, 2020.
Sebastian U Stich. Local sgd converges fast and communicates little. In International Conference
on Learning Representations, 2019.
Sebastian U Stich and Sai Praneeth Karimireddy. The error-feedback framework: Better rates for
sgd with delayed gradients and compressed updates. Journal of Machine Learning Research, 21:
1–36, 2020.
Rafał Szlendak, Alexander Tyurin, and Peter Richt´arik. Permutation compressors for provably faster
distributed nonconvex optimization. arXiv preprint arXiv:2110.03300, 2021.
Trang H Tran, Lam M Nguyen, and Quoc Tran-Dinh. Smg: A shufﬂing gradient-based method with
momentum. In International Conference on Machine Learning, pp. 10379–10389. PMLR, 2021.
Blake Woodworth, Kumar Kshitij Patel, Sebastian Stich, Zhen Dai, Brian Bullins, Brendan Mcma-
han, Ohad Shamir, and Nathan Srebro. Is local SGD better than minibatch SGD? In International
Conference on Machine Learning, pp. 10334–10343. PMLR, 2020a.
Blake Woodworth, Brian Bullins, Ohad Shamir, and Nathan Srebro.
The min-max complexity
of distributed stochastic convex optimization with intermittent communication. arXiv preprint
arXiv:2102.01583, 2021.
Blake E Woodworth, Kumar Kshitij Patel, and Nati Srebro. Minibatch vs local SGD for heteroge-
neous distributed learning. Advances in Neural Information Processing Systems, 33:6281–6292,
2020b.
Hao Yu, Sen Yang, and Shenghuo Zhu. Parallel restarted sgd with faster convergence and less
communication: Demystifying why model averaging works for deep learning. In Proceedings of
the AAAI Conference on Artiﬁcial Intelligence, volume 33, pp. 5693–5700, 2019.
Chulhee Yun, Suvrit Sra, and Ali Jadbabaie. Open problem: Can single-shufﬂe SGD be better than
reshufﬂing SGD and GD? In Conference on Learning Theory, pp. 4653–4658. PMLR, 2021.
12

Published as a conference paper at ICLR 2022
CONTENTS
1
Introduction
1
1.1
Our contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
2
Problem setup
2
3
Convergence analysis of minibatch and local RR
4
3.1
Upper bound for minibatch RR . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
3.2
Upper bound for local RR
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
4
Matching lower bounds
7
4.1
Lower bound for minibatch RR . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
4.2
Lower bounds for local RR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
5
Synchronized shufﬂing: how to bypass lower bounds
8
5.1
Upper bounds for minibatch and local RR with SYNCSHUF
. . . . . . . . . . . .
9
6
Conclusion
9
A Comparisons with assumptions and rates in existing results
14
B
More detailed illustration of synchronized shufﬂing
18
C Experimental results
19
C.1
SYNCSHUF improves convergence of minibatch/local RR
. . . . . . . . . . . . .
20
C.2
Local RR becomes closer to single-machine RR as B →N
. . . . . . . . . . . .
21
C.3
With- vs. without-replacement sampling . . . . . . . . . . . . . . . . . . . . . . .
22
D Proofs of upper bounds
23
D.1
Proof outline
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
D.2
Proof of upper bound for minibatch RR (Theorem 1) . . . . . . . . . . . . . . . .
24
D.3
Proof of upper bound for local RR (Theorem 2) . . . . . . . . . . . . . . . . . . .
29
D.4
Proof of upper bound for minibatch RR with SYNCSHUF (Theorem 6) . . . . . . .
35
D.5
Proof of upper bound for local RR with SYNCSHUF (Theorem 7)
. . . . . . . . .
39
D.6
A generalized vector-valued Hoeffding-Serﬂing inequality
. . . . . . . . . . . . .
42
D.7
How can we avoid uniform bounds over Rd in our assumptions? . . . . . . . . . .
44
E
Proof of lower bound for minibatch RR (Theorem 3)
46
E.1
Lower bound for η ≤
B
µNK . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
E.2
Lower bound for η ≥
B
µNK and η ≤
B
513LN
. . . . . . . . . . . . . . . . . . . . .
47
E.3
Lower bound for η ≥
B
µNK and η ≥
B
513LN
. . . . . . . . . . . . . . . . . . . . .
50
13

Published as a conference paper at ICLR 2022
F
Proofs of helper lemmas for Appendix E
52
F.1
Proof of Lemma 11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
F.2
Proof of Lemma 12 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
F.3
Proof of Lemma 13 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
F.4
Proof of Lemma 14 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
57
F.5
Proof of Lemma 15 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
G Proof of lower bound for local RR: homogeneous case (Theorem 4)
59
G.1
Lower bound for η ≤
1
µNK . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
60
G.2
Lower bound for η ≥
1
µNK and η ≤
1
1025LN . . . . . . . . . . . . . . . . . . . . .
60
G.3
Lower bound for η ≥
1
µNK and η ≥
1
1025LN . . . . . . . . . . . . . . . . . . . . .
64
H Proofs of helper lemmas for Appendix G
66
H.1
Proof of Lemma 16 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
66
H.2
Proof of Lemma 17 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
H.3
Proof of Lemma 18 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
H.4
Proof of Lemma 19 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
I
Proof of lower bound for local RR: heterogeneous case (Proposition 5)
73
I.1
Lower bound for
1
8µNK ≤η ≤
1
8µB and
1
8µB ≤η ≤1
µ . . . . . . . . . . . . . . .
73
I.2
Lower bound for η ≤
1
8µNK and η ≥1
µ
. . . . . . . . . . . . . . . . . . . . . . .
75
A
COMPARISONS WITH ASSUMPTIONS AND RATES IN EXISTING RESULTS
In this section, we compare our assumptions and convergence bounds against other existing results
mentioned in the main text. Most existing results that study independent and unbiased gradient
estimates state their assumptions in terms of the expectation over the randomness in the estimate;
for such assumptions, we adapt them to our ﬁnite sum setting in order to make for easier comparison.
Heterogeneity assumptions.
We start by discussing our deﬁnition of objective-wise heterogeneity
(Assumption 3), namely that there exist τ ≥0 and ρ ≥1 such that
1
M
M
X
m=1
∥∇F m(x)∥≤τ + ρ ∥∇F(x)∥, for all x ∈Rd.
(12)
Perhaps the most relevant to this assumption is the (G, B)-BGD assumption that appears in Karim-
ireddy et al. (2020): For all x ∈Rd,
1
M
M
X
m=1
∥∇F m(x)∥2 ≤G2 + B2 ∥∇F(x)∥2 .
(13)
Note that thanks to Jensen’s inequality and a2 + b2 ≤(a + b)2 for a, b ≥0, (13) implies
 
1
M
M
X
m=1
∥∇F m(x)∥
!2
≤1
M
M
X
m=1
∥∇F m(x)∥2 ≤G2 + B2 ∥∇F(x)∥2 ≤(G + B ∥∇F(x)∥)2,
and hence (12) with τ = G and ρ = B. Therefore, our Assumption 3 is weaker than the (G, B)-
BGD assumption. Several papers (Haddadpour & Mahdavi, 2019; Li et al., 2020b) use the same
14

Published as a conference paper at ICLR 2022
assumption (13), with G = 0; therefore, Assumption 3 also subsumes the heterogeneity assumption
posed in these papers. Note that G = 0 implies that, the minima for F are also the minima for F m,
for every m, and hence G = 0 results in a weak form of heterogeneity.
Some papers (Yu et al., 2019; Li et al., 2020c; Qu et al., 2020) assume bounded local gradients: for
all m ∈[M] and x ∈Rd,
1
N
N
X
i=1
∥∇f m
i (x)∥2 ≤G2,
(14)
and this in fact implies the (G, 0)-BGD assumption (13). To see why, from Jensen’s inequality
∥∇F m(x)∥2 :=

1
N
N
X
i=1
∇f m
i (x)

2
≤1
N
N
X
i=1
∥∇f m
i (x)∥2 ≤G2.
Therefore, (14) is a stronger assumption for objective-wise heterogeneity than Assumption 3.
In Theorem 3 of Woodworth et al. (2020b), the authors use the following assumption on heterogene-
ity: for all x ∈Rd,
1
M
M
X
m=1
∥∇F m(x) −∇F(x)∥2 ≤¯ζ2.
(15)
Noting that
1
M
PM
m=1 ∥∇F m(x) −∇F(x)∥2 =
1
M
PM
m=1 ∥∇F m(x)∥2 −∥∇F(x)∥2, we can see
that (15) implies (13) and hence Assumption 2 (12), with τ = ¯ζ and ρ = 1.
Indeed, there are also some results that make weaker heterogeneity assumptions than ours (12), by
requiring bounded deviation only at the global optimum x∗. Given the global optimum x∗of F,
Koloskova et al. (2020) deﬁne
¯ζ2
∗:= 1
M
M
X
m=1
∥∇F m(x∗)∥2 ,
(16)
and use this constant in their bounds. Khaled et al. (2020) also deﬁne a similar quantity that can
capture heterogeneity, but does not provide a result on strongly convex functions in the heteroge-
neous setting. While assuming bounded ¯ζ2
∗(16) is weaker than Assumption 3 in the sense that only
a bound at x∗is required, we note that these assumptions cannot be applied easily in nonconvex
settings; in fact, for nonconvex (but not necessarily PŁ) functions, Koloskova et al. (2020) also use
(13) as their heterogeneity assumption.
Intra-machine variance assumptions.
We next consider our notion of intra-machine deviation
(Assumption 2), namely that there exists ν ≥0 such that for all m ∈[M] and i ∈[N],
∥∇f m
i (x) −∇F m(x)∥≤ν, for all x ∈Rd.
(17)
In many existing results using independent and unbiased gradient estimates (Karimireddy et al.,
2020; Yu et al., 2019; Li et al., 2020c; Qu et al., 2020; Woodworth et al., 2020a;b; 2021), the
bounded variance assumption is adopted: For all m ∈[M] and x ∈Rd,
1
N
N
X
i=1
∥∇f m
i (x) −∇F m(x)∥2 ≤σ2.
(18)
We note that the bounded local gradients assumption (14) also implies (18), by
1
N
N
X
i=1
∥∇f m
i (x) −∇F m(x)∥2 ≤1
N
N
X
i=1
∥∇f m
i (x) −∇F m(x)∥2 + ∥∇F m(x)∥2
= 1
N
N
X
i=1
∥∇f m
i (x)∥2 ≤G2.
(19)
15

Published as a conference paper at ICLR 2022
Some other papers (Haddadpour et al., 2019; Haddadpour & Mahdavi, 2019; Spiridonoff et al.,
2020) consider a generalized version of (18), namely that for all m ∈[M] and x ∈Rd,
1
N
N
X
i=1
∥∇f m
i (x) −∇F m(x)∥2 ≤c ∥∇F m(x)∥2 + σ2,
(20)
for c, σ ≥0. There are other papers (Koloskova et al., 2020; Khaled et al., 2020) that use intra-
machine variance at the global minimum x∗in their bounds. Koloskova et al. (2020) deﬁne
¯σ2
∗:=
1
MN
M
X
m=1
N
X
i=1
∥∇f m
i (x∗) −∇F m(x∗)∥2 ,
(21)
for the global minimum x∗, and use it in their strong convexity and convexity bounds. Khaled et al.
(2020) deﬁne
σ2
opt :=
1
MN
M
X
m=1
N
X
i=1
∥∇f m
i (x∗)∥2 ,
(22)
which is used in their bound on strongly convex functions in homogeneous cases. Note that for
homogeneous cases, ∇F m(x∗) = ∇F(x∗) = 0, so ¯σ2
∗= σ2
opt.
We note that in contrast to our discussion on inter-machine deviation (Assumption 3), the intra-
machine variance assumptions in the existing literature are weaker than our Assumption 2. However,
we utilize our stronger assumption to prove our high-probability upper bounds, which is a departure
from in-expectation bounds in the literature.
Existing upper bounds on local SGD.
In the discussion after Theorem 2, we mentioned some
recent upper bounds on (with-replacement) local SGD. We make more detailed comparisons here.
For the reader’s convenience, we restate our theorem on local RR below.
Theorem 2 (Upper bound for local RR). Suppose that local RR has parameters satisfying As-
sumption 1.
For any F ∈Fobj(L, µ, ν, τ, ρ), consider running the algorithm using step-size
η = log(MNK2)
µNK
for epochs K ≥7ρκ log(MNK2). Then, with probability at least 1 −δ,
F(yK, N
B ) −F ∗≤F(y0) −F ∗
MNK2
+ ˜O
L2
µ3

ν2
MNK2 + ν2B
N 2K2 + τ 2B2
N 2K2

.
(5)
We start with last-iterate bounds in homogeneous cases. Theorem 3 and Corollary 3 of Khaled
et al. (2020) consider local SGD on µ-strongly convex and L-smooth F. Khaled et al. (2020) allow
variable synchronization intervals, where the maximum interval is upper-bounded by B. In this
setting, Corollary 3 of Khaled et al. (2020) shows that local SGD after T total local update steps
yield
E
h
∥¯xT −x∗∥2i
= ˜O
 
∥¯x0 −x∗∥2
T 2
+
σ2
opt
µ2MT + Lσ2
opt(B −1)
µ3T 2
!
,
(23)
where ¯xi is the average over all M machines’ i-th local iterates, and σopt is from (22). Noting that
T corresponds to NK in local SGD and σopt corresponds to ν in Assumption 2, (23) is comparable
to an upper bound8
E [F(¯xT ) −F ∗] = ˜O

Lν2
µ2MNK + L2ν2B
µ3N 2K2

.
(24)
Here, we do not compare F (y0)−F ∗
MNK2
and L∥¯x0−x∗∥2
T 2
because in Theorem 2, the term F (y0)−F ∗
MNK2
can
be made arbitrarily “small” (e.g., F (y0)−F ∗
(MNK)l for any l ∈N) by changing the log factor in η.
A similar homogeneous, strongly convex, and smooth setting is considered in Spiridonoff et al.
(2020), under a intra-machine variance assumption deﬁned in (20). Theorem 1 of Spiridonoff et al.
(2020) proves general theorem statement for arbitrary synchronization intervals. If we specialize to
constant interval B, Corollary 1 of Spiridonoff et al. (2020) gives
E [F(¯xT ) −F ∗] = ˜O
β2(F(¯x0) −F ∗)
T 2
+
Lσ2
µ2MT + L2σ2(B −1)
µ3T 2

,
(25)
8Note that an additional factor L is due to conversion from squared distance to function value.
16

Published as a conference paper at ICLR 2022
where β ≥2κ2 is a constant deﬁned to choose algorithm parameters such as the step-size. Noting
again that T corresponds to NK and σ in (20) is comparable to ν in Assumption 2, (25) also
translates to (24).
The next last-iterate bound we compare against is Qu et al. (2020). Theorem 1 of Qu et al. (2020)
uses bounded intra-machine variance assumption (18) and bounded gradient assumption (14). Spe-
cializing Theorem 1 of Qu et al. (2020) to full device participation and uniform weight (p1 = · · · =
pN = 1
N ) case, their bound reads
E [F(¯xT ) −F ∗] = ˜O
 Lσ2
µ2MT + L2G2B2
µ3T 2

.
(26)
Recalling that T corresponds to NK, σ to ν in Assumption 2, and G to the heterogeneity constant
τ in Assumption 3 and also ν (due to (19)), (26) translates to
E [F(¯xT ) −F ∗] = ˜O

Lν2
µ2MNK + L2(ν2 + τ 2)B2
µ3N 2K2

.
(27)
Comparing the local SGD last-iterate bounds (24) and (27) against our local RR bound (5) in Theo-
rem 2, we can see that the last iterate of local RR satisﬁes a smaller upper bound as soon as K ≥κ.
Admittedly, this is not a fully rigorous comparison given the differences in assumptions and types
of bounds; nevertheless, we believe that the comparison at least provides some degree of evidence
for faster convergence of local RR than local SGD. It is also interesting to see that the “error from
local updates” terms match in with- and without-replacement bounds.
Next, we review existing average-iterate bounds mentioned in the main text, which are better than the
last-iterate bounds. Koloskova et al. (2020) present a unifying framework for analyzing distributed
optimization algorithms over networks, which can specialize to local SGD. For µ-strongly convex
and L-smooth F, Theorem 2 of Koloskova et al. (2020) shows that
E [F(ˆx) −F ∗] = ˜O

LB ∥x0 −x∗∥2 exp

−µT
LB

+
¯σ2
∗
µMT + L¯σ2
∗B
µ2T 2 + L¯ζ2
∗B2
µ2T 2

,
(28)
where ˆx is some weighted average of iterates and ¯ζ2
∗and ¯σ2
∗are deﬁned in (16) and (21), respectively.
Noting that T corresponds to NK, ¯ζ∗to τ in Assumption 3, and ¯σ∗to ν in Assumption 2 (although
our assumptions are stronger), we can see that the bound (28) for large enough T can be translated
into
E [F(ˆx) −F ∗] = ˜O

ν2
µMNK +
Lν2B
µ2N 2K2 + Lτ 2B2
µ2N 2K2

.
(29)
Notice that (29) is smaller than the last-iterate bounds (24) and (27) by a factor of κ. Similarly,
Theorem 3 of Woodworth et al. (2020b) proves that for µ-strongly convex and L-smooth F,
E [F(˜x) −F ∗] = ˜O
 
L2 ∥x0 −x∗∥2
LT + µT 2
+
¯σ2
∗
µMT + Lσ2B
µ2T 2 + L¯ζ2B2
µ2T 2
!
,
(30)
for some weighted average of iterates ˜x. Here, ¯σ2
∗, σ2, and ¯ζ2 are as deﬁned in (21), (18), and (15),
respectively. Substituting ν to its comparable constants ¯σ∗and σ, and τ to ¯ζ, we can similarly check
that (30) can be converted to (29).
Comparison to Mishchenko et al. (2021).
In Mishchenko et al. (2021), the authors study a prox-
imal algorithm referred to as Proximal Random Reshufﬂing (ProxRR), and obtain a distributed op-
timization algorithm called FedRR as a special case. If we set R ≡0 in FedRR, the algorithm then
is equal to local RR with B = N, i.e., the one that synchronizes only after one entire epoch.
Assuming that all component functions f m
i (x) are µ-strongly convex9 and L-smooth, and objective-
wise homogeneity F 1 = · · · = F m = F, the authors obtain Theorem 8 (Mishchenko et al., 2021),
which states that
E
h
∥yK −x∗∥2i
≤(1 −ηµ)NK ∥y0 −x∗∥2 + η2LMNσ2
opt
µM
,
(31)
9This is in fact quite strong compared to this paper, because we only assume F to be PŁ, not F m nor f m
i .
17

Published as a conference paper at ICLR 2022
where y0 and yK are the initialization and last iterate of the algorithm, and σ2
opt was deﬁned above
in (22). The term MNσ2
opt in (31) corresponds to the term “Nσ2
∗” as per the notation in Mishchenko
et al. (2021). If we apply our Assumption 3 to bound σ2
opt, we get σ2
opt ≤ν2, which reduces the last
term in (31) to η2Lν2N
µ
. If we substitute η = log(MNK2)
µNK
to the bound (31), we get
E
h
∥yK −x∗∥2i
≤∥y0 −x∗∥2
MNK2
+ ˜O

Lν2
µ3NK2

,
(32)
which translates to the same convergence rate on F(yK) −F ∗as single-machine RR. For the
heterogeneous setting, applying Lemma 3 of Mishchenko et al. (2021) to Theorem 2, we can obtain
E
h
∥yK −x∗∥2i
≤(1 −ηµ)NK ∥y0 −x∗∥2
+ 2η2L
µM
M
X
m=1
 
N 2 ∥∇F m(x∗)∥2 + 1
4
N
X
i=1
∥∇f m
i (x∗) −∇F m(x∗)∥2
!
= (1 −ηµ)NK ∥y0 −x∗∥2 + 2η2LN 2
µM
M
X
m=1
∥∇F m(x∗)∥2 + η2L¯σ2
∗N
2µ
, (33)
where ¯σ2
∗was deﬁned in (21). Note that in Lemma 3 (Mishchenko et al., 2021), the function
“Fm” in the authors’ notation is equal to NF m in our notation. Recall that the (G, B)-BGD as-
sumption (13) is “comparable” to Assumption 3 (12). If we apply (13) to the bound (33), we get
1
M
PM
m=1 ∥∇F m(x∗)∥2 ≤G2. Similarly, if we apply Assumption 3, we get ¯σ2
∗≤ν2. Substituting
these upper bounds and η = log(MNK2)
µNK
to (33) gives
E
h
∥yK −x∗∥2i
≤∥y0 −x∗∥2
MNK2
+ ˜O
 LG2
µ3K2 +
Lν2
µ3NK2

,
(34)
and after translating this into a bound on function value, we get an upper bound ˜O(
L2ν2
µ3NK2 + L2G2
µ3K2 )
which in fact matches our upper bound (5) in Theorem 2 when we set B = N.
The two upper bounds obtained for homogeneous (32) and heterogeneous (34) settings indicate that,
at least under assumptions on intra- and inter-machine deviation such as ours, the claimed advantage
that “the convergence bound improves with the number of devices involved” (Mishchenko et al.,
2021) is not achievable. As our lower bound shows, one needs to choose B smaller than N in order
to get the most out of parallelism. That being said, since Mishchenko et al. (2021) is free of uniform
intra- and inter-machine deviation assumptions, there may still exist certain scenarios where multiple
machines can speed up performance even with B = N.
B
MORE DETAILED ILLUSTRATION OF SYNCHRONIZED SHUFFLING
In this section, we provide a more detailed explanation on synchronized shufﬂing that we intro-
duced in Section 5. For the illustration, let us consider the component-wise homogeneous case.
Component-wise homogeneity means that all the machines have the same set of components:
f 1
i = f 2
i = · · · = f M
i
=: fi for i ∈[N]. Hence, we have F = F m for all m ∈[M] and our
goal is to minimize F = 1
N
PN
i=1 fi.
In the proof of Theorem 1 (presented in Appendix D.2; see Appendix D.1 for a sketch), we add the
component gradients over an epoch and then use the following key identity: for any permutation σ,
N
X
i=1
∇fσ(i) =
N
X
i=1
∇fi = N∇F.
(35)
We use this identity (35) to represent the per-epoch progress as “one big GD step plus noise.” For
the rest of the proof we bound the “noise” term, and the key to bounding it is to upper bound the
norm of summations of the following form, for i ∈[N/B −1] (see (41) and (43)):
1
M
M
X
m=1
iB
X
j=1
∇fσm
k (j)(xk,0).
(36)
18

Published as a conference paper at ICLR 2022
To bound the norm, we decompose it into two terms using the triangle inequality

1
M
M
X
m=1
iB
X
j=1
∇fσm
k (j)(xk,0)

≤

1
M
M
X
m=1
iB
X
j=1
∇fσm
k (j)(xk,0) −iB∇F(xk,0)

+iB ∥∇F(xk,0)∥,
and we use concentration bounds (44) on the ﬁrst term of the RHS, which gives a high-probability
upper bound on the RHS of the form ˜O

ν
q
iB
M

+ iB ∥∇F∥(45).
The key to proving fast convergence is to make the upper bound above as small as possible. To make
the bound (45) even smaller, we wish to be able to apply the identity (35) to the summation (36).
However, under the standard way of choosing permutations σm
k independently over machines, one
cannot apply the identity because we do not sum over all j = 1, . . . , N. This limitation motivates
our proposed technique synchronized shufﬂing, a manipulation on the choices of σm
k that lets us
prove even faster convergence.
Recall the deﬁnition of synchronized shufﬂing. At the beginning of the k-th epoch, the server sam-
ples σ ∼Unif(SN) and π ∼Unif(SM), and broadcasts them to the machines. Then, local machines
choose their permutations σm
k to be shifted versions of σ: σm
k (i) := σ
  i + N
M π(m)

mod N

.
Now set N = 6 and M = 3. Assume for simplicity that the permutation π ∈S3 of machines satisﬁes
π(m) = m for m ∈[3].10 Suppose the server samples σ = (σ(1), σ(2), σ(3), σ(4), σ(5), σ(6)) and
broadcasts it. Under synchronized shufﬂing, the local machines choose
σ1
k = (σ(3), σ(4), σ(5), σ(6), σ(1), σ(2)),
σ2
k = (σ(5), σ(6), σ(1), σ(2), σ(3), σ(4)),
σ3
k = (σ(1), σ(2), σ(3), σ(4), σ(5), σ(6)).
One can see that each permutation is a shifted version of σ, with an offset that is a multiple of
N
M = 2.
Now consider adding ∇fσm
k (i) over m = 1, 2, 3 and j = 1, 2 (in fact, any two consecutive j’s will
do). By synchronized shufﬂing, we get a summation over all N = 6 component functions, which
by (35) gives us the full gradient:
3
X
m=1
2
X
j=1
∇fσm
k (j) =
6
X
i=1
∇fi = 6∇F.
The point here is that the permutation identity (35) can be applied to the summations (36) to further
reduce their norm bounds. This is in contrast to sampling independent σm
k ’s where one cannot
apply (35). For this reason, synchronized shufﬂing signiﬁcantly reduces the noise that comes from
without-replacement sampling, thus resulting in faster convergence rates in (near-)homogeneous
cases.
C
EXPERIMENTAL RESULTS
In this section, we present some simple numerical experiments that support our theoretical analy-
sis. We evaluate the performance of the algorithms considered in this paper on the “hard instance”
constructed in our lower bounds (Theorems 3 and 4).
Our hard instance F ∈Fcmp(L, µ, ν, 0) is a function in the component-wise homogeneous setting,
where all the machines have the same set of local component functions: f 1
i = f 2
i = · · · = f M
i
=: fi.
In the proofs of Theorems 3 and 4, we construct the global objective F(x) =
1
N
PN
i=1 fi(x) as the
following:
fi(x) := (L1x≤0 + µ1x>0)x2
2 + ziνx, zi =
+1
if 1 ≤i ≤N/2,
−1
if N/2 < i ≤N.
10In fact, permuting the machines by π is not required in the component-wise homogeneous setting (i.e.,
when λ = 0 in Assumption 4).
19

Published as a conference paper at ICLR 2022
With this set of component functions, the global objective F(x) = (L1x≤0+µ1x>0) x2
2 is µ-strongly
convex and L-smooth with a unique global minimizer at x = 0.
We compare the performance of the algorithms on this problem instance, with L = 100, µ = 1,
ν = 1, N = 768, and M = 16, while varying the choice of B ∈{1, 4, 16, 64, 256} and
K ∈{1, 3, 5, 7, 10, 30, 50, 70, 100, 300, 500, 700, 1000}. For each value of B and K, we run the
algorithms for K epochs (KN/B communication rounds for with-replacement algorithms) starting
at x0 = 0 and return the values of F evaluated at the last iterates. Note that the algorithms are not
deterministic, because the sampling/shufﬂing schemes are random. In order to account for random-
ness, for each combination of (algorithm, B, K) we execute 20 independent runs of the algorithm
and plot the mean, ﬁrst quartile, and third quartile of the ﬁnal objective values.
In the subsequent subsections, we compare the following seven algorithms with constant step-sizes.
• Minibatch RR, η = B log(MNK2)
µNK
;
• Local RR, η = log(MNK2)
µNK
;
• Minibatch RR with SYNCSHUF, η = B log(MNK2)
µNK
;
• Local RR with SYNCSHUF, η = log(MNK2)
µNK
;
• Single-machine RR with minibatch size B, η = log(NK2)
µNK
;
• With-replacement minibatch SGD, η = B log(MNK2)
µNK
;
• With-replacement local SGD, η = log(MNK2)
µNK
.
C.1
SYNCSHUF IMPROVES CONVERGENCE OF MINIBATCH/LOCAL RR
In Figure 1, we compare minibatch RR and local RR, with and without SYNCSHUF. Each plot in
Figure 1 shows how the methods’ performance changes with K, for a ﬁxed value B. Each point
on the curve is the mean of the ﬁnal objective function values over 20 independent runs of the
corresponding algorithm with the speciﬁc B and K, and its error bar indicates the ﬁrst and third
quartiles.
Recall from our Theorems 1, 2, 6, and 7 that the four methods satisfy the following convergence
bounds, in homogeneous settings (i.e., τ = λ = 0):
• Minibatch RR: ˜O

L2
µ3
ν2
MNK2

,
• Local RR: ˜O

L2
µ3

ν2
MNK2 +
ν2B
N2K2

,
• Minibatch RR with SYNCSHUF: ˜O

L2
µ3
ν2
M 2NK2

,
• Local RR with SYNCSHUF: ˜O

L2
µ3

ν2
M 2NK2 +
ν2B
N2K2

.
In fact, if B = 1, local RR is identical to minibatch RR. Figure 1(a) conﬁrms that this is indeed
true, and also that the versions with SYNCSHUF outperforms the ones without SYNCSHUF. This
corroborates the additional M factor speedup in our bounds. In Figure 1(b) and 1(c), we can see
that as B increases, the performance of local RR with SYNCSHUF degrades and becomes closer to
local RR without SYNCSHUF. This shows that the ˜O

L2
µ3
ν2B
N2K2

term starts to dominate. Also,
as we increase B further, in Figure 1(c) and 1(d) we see that local RR (without SYNCSHUF) also
starts to degrade and its gap between minibatch RR becomes larger. Again, this means that the
˜O

L2
µ3
ν2B
N2K2

term becomes the dominant factor in the local RR bound. The performance of mini-
batch RR, with and without SYNCSHUF, stays relatively independent of B. One thing to note is that
for large values of B, the small-epoch behavior of minibatch RR looks rather unstable. The choice
of step-size η = B log(MNK2)
µNK
seems to cause overshooting when B is large and K is small. We
20

Published as a conference paper at ICLR 2022
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
MinibatchRR+SyncShuf
LocalRR+SyncShuf
(a) B = 1
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
MinibatchRR+SyncShuf
LocalRR+SyncShuf
(b) B = 4
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
MinibatchRR+SyncShuf
LocalRR+SyncShuf
(c) B = 16
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
MinibatchRR+SyncShuf
LocalRR+SyncShuf
(d) B = 64
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
MinibatchRR+SyncShuf
LocalRR+SyncShuf
(e) B = 256
Figure 1: Comparison between minibatch RR and local RR, with and without SYNCSHUF. Best
viewed in color. The algorithm versions with SYNCSHUF converge faster. Also note the perfor-
mance degradation as B increases, as expected by our theory.
note that this does not contradict our convergence analysis because our theorems only characterize
the large-epoch behavior (K above certain thresholds) of the algorithms. Perhaps in the small-epoch
regime, our choice of η is not necessarily optimal and a smaller η is needed to prevent overshooting.
C.2
LOCAL RR BECOMES CLOSER TO SINGLE-MACHINE RR AS B →N
Our next set of plots presented in Figure 2 provides a comparison of minibatch RR, local RR, and
single-machine RR (i.e., minibatch RR with M = 1). In Theorems 2 and 4, we showed that when
B = Θ(N), then the convergence of local RR becomes just as fast as the single-machine RR.
21

Published as a conference paper at ICLR 2022
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
SingleMachineRR
(a) B = 1
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
SingleMachineRR
(b) B = 4
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
SingleMachineRR
(c) B = 16
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
SingleMachineRR
(d) B = 64
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
SingleMachineRR
(e) B = 256
Figure 2: Comparison of minibatch RR, local RR, and single-machine RR. Best viewed in color.
The large-epoch performance of local RR becomes similar to that of single-shufﬂe RR as B be-
comes closer to N.
Indeed, we can observe from Figure 2 that this is really the case. As B increases, the curve of local
RR moves closer and closer to that of single-machine RR, especially in the large-epoch regime.
C.3
WITH- VS. WITHOUT-REPLACEMENT SAMPLING
Lastly, in Figure 3 we compare the with-replacement and without-replacement versions of mini-
batch/local SGD. In all plots, we can see that the without-replacement versions outperform with-
replacement ones, at least for our problem instance. It is also intriguing to note that the two versions
perform very similarly in the small-epoch regime (for K up to ∼10), but without-replacement starts
22

Published as a conference paper at ICLR 2022
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
MinibatchSGD
LocalSGD
(a) B = 1
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
MinibatchSGD
LocalSGD
(b) B = 4
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
MinibatchSGD
LocalSGD
(c) B = 16
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
MinibatchSGD
LocalSGD
(d) B = 64
100
101
102
103
10-9
10-8
10-7
10-6
10-5
10-4
10-3
10-2
10-1
MinibatchRR
LocalRR
MinibatchSGD
LocalSGD
(e) B = 256
Figure 3: Comparison of with-replacement (SGD) and without-replacement (RR) versions. Best
viewed in color. Without-replacement versions converge faster than with-replacement versions, at
least in our problem instance. Also note that the two versions perform similarly in the small-epoch
regime, which supports our theoretical ﬁndings.
to outperform for larger K’s. This observation supports our theoretical prediction from Theorem 3
that in the small-epoch regime, minibatch RR can at best perform as fast as minibatch SGD.
D
PROOFS OF UPPER BOUNDS
In this section, we provide proofs of our upper bounds stated in Sections 3 and 5. We start by describ-
ing a high-level proof outline that we use for all the proofs presented in this section (Appendix D.1).
In the subsequent subsections, we prove Theorems 1, 2, 6, and 7, in the order they appeared in the
main text. The next subsection (Appendix D.6) states and proves a key lemma that gives concen-
23

Published as a conference paper at ICLR 2022
tration bounds for the mean of multiple without-replacement sums of vectors. This general-purpose
lemma can be of independent interest and it can prove useful in various other settings. Lastly, in
Appendix D.7 we discuss how we can modify the theorem statements to remove the requirement in
Assumptions 2, 3, and 4 that they must hold for the entire Rd.
Notation.
Throughout this section, we use the product notation Q in a slightly unconventional
manner. For indices i ≤j and square matrices Ai, Ai+1, . . . , Aj−1, Aj, we use Qi
l=j Al to denote
the matrix product AjAj−1 · · · Ai+1Ai. If i > j, then Qi
l=j Al = I.
D.1
PROOF OUTLINE
The proofs of upper bounds follow a common structure, consisting of the following three steps:
1. writing one epoch as one step of GD plus noise;
2. getting a high-probability upper bound on the noise term using concentration inequalities;
3. obtaining the convergence rate using the bounds on the noise term.
We ﬁrst unroll the update equations over an epoch, and write an epoch of the algorithms as one step
of gradient descent plus noise:11
xk+1,0 = xk,0 −ηN∇F(xk,0) + η2rk.
Substituting the above to the deﬁnition of L-smoothness of F and arranging terms, we obtain
F(xk+1,0) −F(xk,0)
≤⟨∇F(xk,0), xk+1,0 −xk,0⟩+ L
2 ∥xk+1,0 −xk,0∥2
≤−ηN ∥∇F(xk,0)∥2 + η2 ∥∇F(xk,0)∥∥rk∥+ η2L
2
∥N∇F(xk,0) + ηrk∥2
≤(−ηN + η2LN 2) ∥∇F(xk,0)∥2 + η2 ∥∇F(xk,0)∥∥rk∥+ η4L ∥rk∥2 .
(37)
The next step is to get high-probability upper bounds on the term ∥rk∥. This is done by applying
our concentration inequality lemma (Lemma 8) to partial without-replacement sums of component
gradients. As a result, we will get upper bounds on ∥rk∥and ∥rk∥2, for k = 1, . . . , K, which hold
with probability at least 1 −δ.
In the last part, we substitute the high-probability bounds to (37) and invoke the deﬁnition of PŁ
functions to get a per-epoch progress bound. We then unroll the per-epoch inequality for all epochs
k = 1, . . . , K. Arranging the terms in the resulting inequality gives our desired convergence bound
that holds with probability at least 1 −δ.
D.2
PROOF OF UPPER BOUND FOR MINIBATCH RR (THEOREM 1)
One epoch as one step of GD plus noise.
To simplify the notation throughout the proof, we will
prove the same convergence rate for a rescaled update rule and step-size:
xk,i := xk,i−1 −η
M
M
X
m=1
iB
X
j=(i−1)B+1
∇f m
σm
k (j)(xk,i−1)
(38)
for i ∈[N/B] and k ∈[K], and η = log(MNK2)
µNK
. Note that the gradient term is scaled up by B and
the step-size is scaled down by B. We will prove the convergence rate for this equivalent algorithm.
We start the proof by unrolling the update equations over an epoch and expressing the progress as
xk+1,0 = xk,0 −ηNF(xk,0) + η2rk,
i.e., one step of full gradient descent plus some noise.
11In case of local RR, we replace xk,0 with yk,0.
24

Published as a conference paper at ICLR 2022
To this end, we decompose the gradient ∇f m
σm
k (j)(xk,i−1) into the signal ∇f m
σm
k (j)(xk,0) and noise:
∇f m
σm
k (j)(xk,i−1) = ∇f m
σm
k (j)(xk,0) + ∇f m
σm
k (j)(xk,i−1) −∇f m
σm
k (j)(xk,0)
= ∇f m
σm
k (j)(xk,0) +
Z 1
0
∇2f m
σm
k (j)(xk,0 + t(xk,i−1 −xk,0))dt

(xk,i−1 −xk,0),
where ∇2f(x) denotes the Hessian of f at x, whenever it exists. We remark that the integral
exists, due to the following reason. Since we assumed that each f m
σm
k (j) is differentiable and smooth,
its gradient ∇f m
σm
k (j) is Lipschitz continuous, and hence absolutely continuous. This means that
∇f m
σm
k (j) is differentiable almost everywhere (i.e., ∇2f m
σm
k (j)(x) exists a.e.), and the fundamental
theorem of calculus for Lebesgue integral holds; hence the integral exists.
To simplify notation, we deﬁne the following for all i ∈[N/B]:
gi := 1
M
M
X
m=1
iB
X
j=(i−1)B+1
∇f m
σm
k (j)(xk,0),
Hi := 1
M
M
X
m=1
iB
X
j=(i−1)B+1
Z 1
0
∇2f m
σm
k (j)(xk,0 + t(xk,i−1 −xk,0))dt,
so that we can write (38) as
xk,i = xk,i−1 −ηgi −ηHi(xk,i−1 −xk,0).
(39)
From L-smoothness of f m
i ’s, it is straightforward to check that ∥Hi∥≤LB. Unrolling (39) for
i = 1, . . . , N/B, it turns out that we can write
xk+1,0 = xk,0 −η
N/B
X
i=1


i+1
Y
j=N/B
(I −ηHj)

gi.
Due to summation by parts, the following identity holds:
N/B
X
i=1
aibi = aN/B
N/B
X
j=1
bj −
N/B−1
X
i=1
(ai+1 −ai)
i
X
j=1
bj.
We apply this to the last term, by substituting ai = Qi+1
j=N/B(I −ηHj) and bi = gi:
η
N/B
X
i=1


i+1
Y
j=N/B
(I −ηHj)

gi
= η
N/B
X
j=1
gj −η
N/B−1
X
i=1


i+2
Y
t=N/B
(I −ηHt) −
i+1
Y
t=N/B
(I −ηHt)


i
X
j=1
gj
= ηN∇F(xk,0) −η2
N/B−1
X
i=1


i+2
Y
t=N/B
(I −ηHt)

Hi+1
i
X
j=1
gj
|
{z
}
=:rk
.
With the “noise” rk deﬁned as above, we can write xk+1,0 = xk,0 −ηN∇F(xk,0) + η2rk, as
desired. Next, it follows from L-smoothness of F that
F(xk+1,0) −F(xk,0)
≤⟨∇F(xk,0), xk+1,0 −xk,0⟩+ L
2 ∥xk+1,0 −xk,0∥2
≤−ηN ∥∇F(xk,0)∥2 + η2 ∥∇F(xk,0)∥∥rk∥+ η2L
2
∥N∇F(xk,0) + ηrk∥2
≤(−ηN + η2LN 2) ∥∇F(xk,0)∥2 + η2 ∥∇F(xk,0)∥∥rk∥+ η4L ∥rk∥2 ,
(40)
where the last inequality used ∥a + b∥2 ≤2 ∥a∥2 + 2 ∥b∥2.
25

Published as a conference paper at ICLR 2022
Bounding noise term using concentration.
It is left to bound ∥rk∥. We have
∥rk∥=

N/B−1
X
i=1


i+2
Y
t=N/B
(I −ηHt)

Hi+1
i
X
j=1
gj

≤
N/B−1
X
i=1



i+2
Y
t=N/B
(I −ηHt)

Hi+1
i
X
j=1
gj

≤LB(1 + ηLB)N/B
N/B−1
X
i=1

i
X
j=1
gj

,
(41)
where the last step used ∥Hi∥≤LB for i ∈[N/B]. Recall from the theorem statement that
K ≥6κ log(MNK2) and η = log(MNK2)
µNK
. This means that
(1 + ηLB)N/B =

1 + κB log(MNK2)
NK
N/B
≤

1 + B
6N
N/B
≤e1/6.
(42)
Now, we use Lemma 8 to bound the norm of
i
X
j=1
gj = 1
M
M
X
m=1
iB
X
j=1
∇f m
σm
k (j)(xk,0).
(43)
Note that for any epoch k, the permutations σ1
k, . . . , σM
k
are independent of the ﬁrst iterate xk,0
of the epoch, and hence independent of all ∇f m
i (xk,0). Therefore, we can apply Lemma 8 to the
partial sum (43), with vm
i
←∇f m
i (xk,0), n ←iB, and δ ←
Bδ
NK . By Lemma 8, with probability
at least 1 −Bδ
NK , we have

1
iBM
M
X
m=1
iB
X
j=1
∇f m
σm
k (j)(xk,0) −∇F(xk,0)

≤ν
s
8 log 2NK
Bδ
iBM
.
(44)
Using this concentration bound, with probability at least 1 −Bδ
NK we have

i
X
j=1
gj

≤iBν
s
8 log 2NK
Bδ
iBM
+ iB ∥∇F(xk,0)∥= ν
s
8iB log 2NK
Bδ
M
+ iB ∥∇F(xk,0)∥. (45)
We can now substitute (42) and (45) to (41) to get
∥rk∥≤e1/6LB
N/B−1
X
i=1

ν
s
8iB log 2NK
Bδ
M
+ iB ∥∇F(xk,0)∥


≤e1/6√
8LνB3/2
M 1/2
Z N/B
1
√
tdt
r
log 2NK
Bδ
+ e1/6LB2 ∥∇F(xk,0)∥
N/B−1
X
i=1
i
≤5Lν(N 3/2 −B3/2)
2M 1/2
r
log 2NK
Bδ
+ LN(N −B) ∥∇F(xk,0)∥,
(46)
which holds with probability at least 1 −
δ
K , due to the union bound over i = 1, . . . , N/B −1.
The bound (46) holds for all k ∈[K] with probability 1 −δ if we apply the union bound over
k = 1, . . . , K. Next, by (a + b)2 ≤2a2 + 2b2, we have
∥rk∥2 ≤25L2ν2(N 3/2 −B3/2)2
2M
log 2NK
Bδ
+ 2L2N 2(N −B)2 ∥∇F(xk,0)∥2 ,
(47)
which also holds for all k ∈[K] with probability at least 1 −δ.
26

Published as a conference paper at ICLR 2022
Getting a high-probability convergence rate.
Given our high-probability bounds (46) and (47),
we can substitute them to (40) and get
F(xk+1,0) −F(xk,0)
≤(−ηN + η2LN 2) ∥∇F(xk,0)∥2 + η2 ∥∇F(xk,0)∥∥rk∥+ η4L ∥rk∥2
≤
 −ηN + η2LN 2 + η2LN(N −B) + 2η4L3N 2(N −B)2
∥∇F(xk,0)∥2
+ 5η2Lν(N 3/2 −B3/2)
2M 1/2
r
log 2NK
Bδ
∥∇F(xk,0)∥
+ 25η4L3ν2(N 3/2 −B3/2)2
2M
log 2NK
Bδ .
(48)
The second term in the RHS of (48) can be bounded using ab ≤a2
2 + b2
2 :
5η2Lν(N 3/2 −B3/2)
2M 1/2
r
log 2NK
Bδ
∥∇F(xk,0)∥
=
η1/2N 1/2
2
∥∇F(xk,0)∥
  
5η3/2Lν(N 3/2 −B3/2)
M 1/2N 1/2
r
log 2NK
Bδ
!
≤ηN
8 ∥∇F(xk,0)∥2 + 25η3L2ν2(N 3/2 −B3/2)2
2MN
log 2NK
Bδ .
Putting this inequality to (48) and noting N −B ≤N gives
F(xk+1,0) −F(xk,0) ≤

−7
8ηN + 2η2LN 2 + 2η4L3N 4

∥∇F(xk,0)∥2
+ 25η3L2(1 + ηLN)ν2(N 3/2 −B3/2)2
2MN
log 2NK
Bδ .
(49)
Recall from K ≥6κ log(MNK2) and η =
log(MNK2)
µNK
that ηLN ≤
1
6. Since the inequality
−7
8z + 2z2 + 2z4 ≤−1
2z holds on z ∈[0, 1
6], we have
−7
8ηN + 2η2LN 2 + 2η4L3N 4 ≤−1
2ηN.
Applying this bound to (49) results in
F(xk+1,0) −F(xk,0) ≤−ηN
2 ∥∇F(xk,0)∥2 + 15η3L2ν2(N 3/2 −B3/2)2
MN
log 2NK
Bδ .
We now recall that F is µ-PŁ, so ∥∇F(xk,0)∥2 ≥2µ(F(xk,0) −F ∗):
F(xk+1,0) −F ∗≤(1 −ηµN)(F(xk,0) −F ∗) + 15η3L2ν2(N 3/2 −B3/2)2
MN
log 2NK
Bδ .
(50)
Recall that (50) holds for all k ∈[K], with probability 1 −δ. Therefore, by unrolling the inequality,
F(xK, N
B ) −F ∗≤(1 −ηµN)K(F(x0) −F ∗)
+ 15η3L2ν2(N 3/2 −B3/2)2
MN
log 2NK
Bδ
K−1
X
k=0
(1 −ηµN)k
≤(1 −ηµN)K(F(x0) −F ∗) + 15η2L2ν2(N 3/2 −B3/2)2
µMN 2
log 2NK
Bδ .
(51)
Lastly, substituting η = log(MNK2)
µNK
gives
F(xK, N
B ) −F ∗≤F(x0) −F ∗
MNK2
+ 15L2ν2(N 3/2 −B3/2)2 log 2NK
Bδ log2(MNK2)
µ3MN 4K2
= F(x0) −F ∗
MNK2
+ ˜O
L2ν2
µ3
1
MNK2

.
(52)
27

Published as a conference paper at ICLR 2022
Getting an in-expectation bound from the high-probability bound.
We conclude this subsec-
tion by brieﬂy describing how we can obtain an in-expectation bound from the high-probability
bound we just proved. Recall that the bound we proved above holds under the event E that all the
concentration bounds used throughout the proof hold. The key to proving an in-expectation bound
is to obtain an upper bound under its complement Ec, i.e., conditioned on the event that at least one
of our concentration bounds does not hold. We do so by repeating the same proof without ever using
the Hoeffding-Serﬂing bounds (Lemma 8). Of course, this leads to a much looser bound, but we can
choose δ to be small enough so that the desired bound ˜O

L2ν2
µ3
1
MNK2

holds in expectation.
For the version without concentration bounds, the proof proceeds in the same way until it starts
diverge at (44). Instead of applying concentration inequalities, we loosely bound the quantity as the
following:

1
iBM
M
X
m=1
iB
X
j=1
∇f m
σm
k (j)(xk,0) −∇F(xk,0)

=

1
iBM
M
X
m=1
iB
X
j=1
∇f m
σm
k (j)(xk,0) −1
M
M
X
m=1
F m(xk,0)

≤1
M
M
X
m=1

1
iB
iB
X
j=1
∇f m
σm
k (j)(xk,0) −F m(xk,0)

≤ν.
With this bound, the RHS of the upper bound (45) on ∥Pi
j=1 gj∥becomes iBν + iB ∥∇F(xk,0)∥.
This results in the bounds on ∥rk∥and ∥rk∥2 (corresponding to (46) and (47)) that read
∥rk∥≤LνN(N −B) + LN(N −B) ∥∇F(xk,0)∥,
∥rk∥≤2L2ν2N 2(N −B)2 + 2L2N 2(N −B)2 ∥∇F(xk,0)∥2 .
The rest is substituting the bounds above to (40), and going through the same steps to obtain the
ﬁnal bound. The resulting bound that corresponds to (51) is
F(xK, N
B ) −F ∗≤(1 −ηµN)K(F(x0) −F ∗) + 7η2L2ν2(N −B)2
3µ
,
which, by substituting η = log(MNK2)
µNK
, yields
F(xK, N
B ) −F ∗≤F(x0) −F ∗
MNK2
+ ˜O
L2ν2
µ3
1
K2

.
(53)
To ﬁnish the proof of in-expectation bound, choose δ =
1
MN . Recall that the probabilistic event E
occurs when all our concentration bounds hold. Conditioned on E, which occurs with probability
at least 1 −
1
MN , the tighter bound (52) holds, with log 1
δ replaced by log(MN). The complement
event Ec occurs with probability at most
1
MN , under which the looser bound (53) is true. Thus, in
expectation,
E
h
F(xK, N
B ) −F ∗i
= P(E)E
h
F(xK, N
B ) −F ∗| E
i
+ P(Ec)E
h
F(xK, N
B ) −F ∗| Eci
≤E
h
F(xK, N
B ) −F ∗| E
i
+
1
MN E
h
F(xK, N
B ) −F ∗| Eci
≤3(F(x0) −F ∗)
2MNK2
+ ˜O
L2ν2
µ3
1
MNK2

.
For the remaining high-probability upper bounds proved in the paper, we can similarly follow this
process to obtain matching (up to log factors) in-expectation upper bounds.
28

Published as a conference paper at ICLR 2022
D.3
PROOF OF UPPER BOUND FOR LOCAL RR (THEOREM 2)
One epoch as one step of GD plus noise.
The update rule of local RR can be written as the
following. For k ∈[K], i ∈[N], and m ∈[M],
xm
k,i :=
(
xm
k,i−1 −η∇f m
σm
k (i)(xm
k,i−1)
if B does not divide i,
1
M
PM
m=1(xm
k,i−1 −η∇f m
σm
k (i)(xm
k,i−1)) =: yk,i/B
if B divides i.
(54)
Recall that xm
k,0’s are the initial points of an epoch and they all the same regardless of the machine
m. We deﬁne yk,0 := x1
k,0. For any i in the range of (l −1)B + 1 ≤i ≤lB for some l ∈[M],
we will use yk,l−1 as the “pivot” and decompose the gradients into the ones evaluated at yk,l−1 plus
noise terms.
∇f m
σm
k (i)(xm
k,i−1) = ∇f m
σm
k (i)(yk,l−1) + ∇f m
σm
k (i)(xm
k,i−1) −∇f m
σm
k (i)(yk,l−1)
= ∇f m
σm
k (i)(yk,l−1) +
Z 1
0
∇2f m
σm
k (i)(yk,l−1 + t(xm
k,i−1 −yk,l−1))dt

|
{z
}
=:Hm
i
(xm
k,i−1 −yk,l−1),
where the integral Hm
i
exists due to the reason discussed in Appendix D.2. Also note from L-
smoothness of f m
i ’s that ∥Hm
i ∥≤L. Using the decomposition, one can unroll the updates (54) and
write yk,l in terms of yk,l−1 in the following way:
yk,l = yk,l−1 −η
M
M
X
m=1
lB
X
i=(l−1)B+1


i+1
Y
j=lB
(I −ηHm
j )

∇f m
σm
k (i)(yk,l−1),
(55)
for l = 1, . . . , N/B. Next, we again decompose the gradient ∇f m
σm
k (i)(yk,l−1), this time using yk,0
as the pivot:
∇f m
σm
k (i)(yk,l−1) = ∇f m
σm
k (i)(yk,0) + ∇f m
σm
k (i)(yk,l−1) −∇f m
σm
k (i)(yk,0)
= ∇f m
σm
k (i)(yk,0) +
Z 1
0
∇2f m
σm
k (i)(yk,0 + t(yk,l−1 −yk,0))dt

|
{z
}
=: ˜
Hm
i
(yk,l−1 −yk,0).
This decomposition allows us to rewrite (55) in the following form
yk,l = yk,l−1 −ηtl −ηSl(yk,l−1 −yk,0),
(56)
where
tl := 1
M
M
X
m=1
lB
X
i=(l−1)B+1


i+1
Y
j=lB
(I −ηHm
j )

∇f m
σm
k (i)(yk,0),
(57)
Sl := 1
M
M
X
m=1
lB
X
i=(l−1)B+1


i+1
Y
j=lB
(I −ηHm
j )

˜
Hm
i .
(58)
Unrolling (56) for l = 1, . . . , N/B then gives the progress over an epoch:
yk+1,0 = yk,0 −η
N/B
X
l=1


l+1
Y
j=N/B
(I −ηSj)

tl.
(59)
As done in the proof of Theorem 1 (Appendix D.2), we will express (59) as one step of GD on F
plus some noise. Of course, the noise terms here will be more complicated to handle than they were
in Theorem 1. Due to summation by parts, the following identity holds:
N/B
X
l=1
albl = aN/B
N/B
X
j=1
bj −
N/B−1
X
l=1
(al+1 −al)
l
X
j=1
bj.
29

Published as a conference paper at ICLR 2022
We apply this to the last term of (59), by substituting ai = Ql+1
j=N/B(I −ηSj) and bl = tl:
η
N/B
X
l=1


l+1
Y
j=N/B
(I −ηSj)

tl = η
N/B
X
l=1
tl −η2
N/B−1
X
l=1


l+2
Y
j=N/B
(I −ηSj)

Sl+1
l
X
j=1
tj.
(60)
We also apply the summation by parts to the inner summation of tl’s (57):
tl := 1
M
M
X
m=1
lB
X
i=(l−1)B+1


i+1
Y
j=lB
(I −ηHm
j )

∇f m
σm
k (i)(yk,0)
= 1
M
M
X
m=1
lB
X
i=(l−1)B+1
∇f m
σm
k (i)(yk,0)
−η
M
M
X
m=1
lB−1
X
i=(l−1)B+1
 i+2
Y
t=lB
(I −ηHm
t )
!
Hm
i+1
i
X
j=(l−1)B+1
∇f m
σm
k (j)(yk,0)
(61)
Substituting (61) to (60) gives
yk+1,0 = yk,0 −ηN∇F(yk,0) + η2rk,1 + η2rk,2 −η3rk,3,
where rk,1, rk,2, and rk,3 are noise terms deﬁned as
rk,1 := 1
M
N/B
X
l=1
M
X
m=1
lB−1
X
i=(l−1)B+1
 i+2
Y
t=lB
(I −ηHm
t )
!
Hm
i+1
i
X
t=(l−1)B+1
∇f m
σm
k (t)(yk,0),
rk,2 := 1
M
N/B−1
X
l=1


l+2
Y
j=N/B
(I −ηSj)

Sl+1
M
X
m=1
lB
X
t=1
∇f m
σm
k (t)(yk,0),
rk,3 := 1
M
N/B−1
X
l=1


l+2
Y
j=N/B
(I −ηSj)

Sl+1×
l
X
j=1
M
X
m=1
jB−1
X
i=(j−1)B+1


i+2
Y
t=jB
(I −ηHm
t )

Hm
i+1
i
X
t=(j−1)B+1
∇f m
σm
k (t)(yk,0).
Deﬁning rk := rk,1 + rk,2 −ηrk,3, it follows from L-smoothness of F that
F(yk+1,0) −F(yk,0)
≤⟨∇F(yk,0), yk+1,0 −yk,0⟩+ L
2 ∥yk+1,0 −yk,0∥2
≤−ηN ∥∇F(yk,0)∥2 + η2 ∥∇F(yk,0)∥∥rk∥+ η2L
2
∥N∇F(yk,0) + ηrk∥2
≤(−ηN + η2LN 2) ∥∇F(yk,0)∥2 + η2 ∥∇F(yk,0)∥∥rk∥+ η4L ∥rk∥2 .
(62)
Bounding noise terms using concentration.
We next bound ∥rk∥by bounding each ∥rk,1∥,
∥rk,2∥, and ∥rk,3∥. From this point on, we write gm
t := ∇f m
σm
k (t)(yk,0) to simplify notation.
∥rk,1∥=

1
M
N/B
X
l=1
M
X
m=1
lB−1
X
i=(l−1)B+1
 i+2
Y
t=lB
(I −ηHm
t )
!
Hm
i+1
i
X
t=(l−1)B+1
gm
t

≤1
M
N/B
X
l=1
M
X
m=1
lB−1
X
i=(l−1)B+1

 i+2
Y
t=lB
(I −ηHm
t )
!
Hm
i+1
i
X
t=(l−1)B+1
gm
t

≤L(1 + ηL)B
M
N/B
X
l=1
M
X
m=1
lB−1
X
i=(l−1)B+1

i
X
t=(l−1)B+1
gm
t

,
(63)
30

Published as a conference paper at ICLR 2022
where we used ∥Hm
i ∥≤L. Recall from the theorem statement that K ≥7ρκ log(MNK2) and
η = log(MNK2)
µNK
. This means that
(1 + ηL)B =

1 + κ log(MNK2)
NK
B
≤

1 +
1
7ρN
B
≤

1 + 1
7B
B
≤e1/7.
(64)
Also note from the deﬁnition of Sl (58) that ∥Sl∥≤LB(1 + ηL)B ≤e1/7LB, which we use to get
similar bounds for the next two terms rk,2 and rk,3.
∥rk,2∥=

1
M
N/B−1
X
l=1


l+2
Y
j=N/B
(I −ηSj)

Sl+1
M
X
m=1
lB
X
t=1
gm
t

≤e1/7LB(1 + e1/7ηLB)N/B
M
N/B−1
X
l=1

M
X
m=1
lB
X
t=1
gm
t
 ,
(65)
and we can bound
(1 + e1/7ηLB)N/B =

1 + e1/7κB log(MNK2)
NK
N/B
≤

1 + e1/7B
7ρN
N/B
≤exp
e1/7
7

.
(66)
We similarly bound the norm of the last noise term rk,3:
∥rk,3∥≤e1/7LB(1 + e1/7ηLB)N/B
M
×
N/B−1
X
l=1

l
X
j=1
M
X
m=1
jB−1
X
i=(j−1)B+1


i+2
Y
t=jB
(I −ηHm
t )

Hm
i+1
i
X
t=(j−1)B+1
gm
t

≤e1/7L2B(1 + e1/7ηLB)N/B(1 + ηL)B
M
N/B−1
X
l=1
l
X
j=1
M
X
m=1
jB−1
X
i=(j−1)B+1

i
X
t=(j−1)B+1
gm
t

≤11L2B
7M
N/B−1
X
l=1
l
X
j=1
M
X
m=1
jB−1
X
i=(j−1)B+1

i
X
t=(j−1)B+1
gm
t

,
(67)
where the last inequality used (64), (66), and e2/7 exp(e1/7/7) ≤11/7.
Given the bounds (63), (65), and (67), we now use Lemma 8 to get high-probability bounds for the
partial sums of gm
t that appear in the bounds. For any i satisfying (j −1)B +1 ≤i ≤jB −1, where
j ∈[N/B], and for any m ∈[M], the following bound holds with probability at least 1 −
δ
2MNK :

1
i −(j −1)B
i
X
t=(l−1)B+1
gm
t −1
N
N
X
t=1
gm
t

=

1
i −(j −1)B
i
X
t=(l−1)B+1
∇f m
σm
k (t)(yk,0) −∇F m(yk,0)

≤ν
s
8 log 4MNK
δ
i −(j −1)B .
From this, with probability at least 1 −
δ
2MNK we have

i
X
t=(j−1)B+1
gm
t

≤ν
q
8(i −(j −1)B) log 4MNK
δ
+ (i −(j −1)B) ∥∇F m(yk,0)∥.
(68)
Similarly, for l ∈[N/B −1], the following bound holds with probability at least 1 −
Bδ
2NK :

1
lBM
M
X
m=1
lB
X
t=1
gm
t −
1
MN
M
X
m=1
N
X
t=1
gm
t

31

Published as a conference paper at ICLR 2022
=

1
lBM
M
X
m=1
lB
X
t=1
∇f m
σm
k (t)(yk,0) −∇F(yk,0)
 ≤ν
s
8 log 4NK
Bδ
lBM
,
which gives us

M
X
m=1
lB
X
t=1
gm
t
 ≤ν
q
8lBM log 4NK
Bδ + lBM ∥∇F(yk,0)∥
(69)
By applying the union bound, with probability at least 1 −δ
K , the bound (68) holds for all m ∈[M]
and i ∈SN/B
j=1 [(j −1)B + 1 : jB −1], and the bound (69) holds for all l ∈[N/B −1].
We now substitute the bounds (68) and (69) to (63), (65), and (67) to get upper bounds for ∥rk,1∥,
∥rk,2∥, and ∥rk,3∥, respectively. First,
∥rk,1∥
≤e1/7L
M
N/B
X
l=1
M
X
m=1
lB−1
X
i=(l−1)B+1

ν
q
8(i −(l −1)B) log 4MNK
δ
+ (i −(l −1)B) ∥∇F m(yk,0)∥

= e1/7√
8LνN
B
 B−1
X
i=1
√
i
! r
log 4MNK
δ
+ e1/7LN
B
 B−1
X
i=1
i
!  
1
M
M
X
m=1
∥∇F m(yk,0)∥
!
≤24LνN(B3/2 −1)
11B
r
log 4MNK
δ
+ 3LN(B −1)
5
(τ + ρ ∥∇F(yk,0)∥) ,
(70)
where the last inequality used PB−1
i=1
√
i ≤
R B
1
√zdz = 2
3(B3/2 −1) and Assumption 3. For the
next noise term, we have e1/7(1 + e1/7ηLB)N/B ≤7/5, so
∥rk,2∥≤7LB
5M
N/B−1
X
l=1

ν
q
8lBM log 4NK
Bδ + lBM ∥∇F(yk,0)∥

= 7
√
8LνB3/2
5M 1/2


N/B−1
X
l=1
√
l


r
log 4NK
Bδ
+ 7LB2
5


N/B−1
X
l=1
l

∥∇F(yk,0)∥
≤8Lν(N 3/2 −B3/2)
3M 1/2
r
log 4NK
Bδ
+ 7LN(N −B)
10
∥∇F(yk,0)∥.
(71)
Lastly,
∥rk,3∥≤11L2B
7M
N/B−1
X
l=1
l
X
j=1
M
X
m=1
jB−1
X
i=(j−1)B+1

ν
q
8(i −(j −1)B) log 4MNK
δ
+ (i −(j −1)B) ∥∇F m(yk,0)∥

= 11
√
8L2νB
7


N/B−1
X
l=1
l


 B−1
X
i=1
√
i
! r
log 4MNK
δ
+ 11L2B
7


N/B−1
X
l=1
l


 B−1
X
i=1
i
!  
1
M
M
X
m=1
∥∇F m(yk,0)∥
!
≤3L2νN(N −B)(B3/2 −1)
2B
r
log 4MNK
δ
+ 2L2N(N −B)(B −1)
5
(τ + ρ ∥∇F(yk,0)∥).
(72)
32

Published as a conference paper at ICLR 2022
Recalling the deﬁnition rk := rk,1 + rk,2 −ηrk,3, we get an upper bound for ∥rk∥from (70), (71),
and (72):
∥rk∥≤∥rk,1∥+ ∥rk,2∥+ η ∥rk,3∥
≤Lν
r
log 4MNK
δ
24N(B3/2 −1)
11B
+ 8(N 3/2 −B3/2)
3M 1/2
+ 3ηLN(N −B)(B3/2 −1)
2B

+ Lτ
3N(B −1)
5
+ 2ηLN(N −B)(B −1)
5

+ L ∥∇F(yk,0)∥
3ρN(B −1)
5
+ 7N(N −B)
10
+ 2ηLρN(N −B)(B −1)
5

.
(73)
Recall again that we have K ≥7ρκ log(MNK2) and η = log(MNK2)
µNK
, so ηLN ≤1/7. Using this
and N −B ≤N, we can further simplify (73).
∥rk∥≤Lν
r
log 4MNK
δ
12N(B3/2 −1)
5B
+ 8(N 3/2 −B3/2)
3M 1/2

|
{z
}
=:Φ
+2LτN(B −1)
3
+ L ∥∇F(yk,0)∥
2ρN(B −1)
3
+ 7N(N −B)
10

≤LνΦ
r
log 4MNK
δ
+ 2LτN(B −1)
3
+ 7LρN 2
5
∥∇F(yk,0)∥,
(74)
which holds with probability at least 1 −δ
K . The bound (74) holds for all k ∈[K] with probability
1 −δ if we apply the union bound over k = 1, . . . , K. Next, by (a + b + c)2 ≤3a2 + 3b2 + 3c2,
we have
∥rk∥2 ≤3L2ν2Φ2 log 4MNK
δ
+ 4L2τ 2N 2(B −1)2
3
+ 147L2ρ2N 4
25
∥∇F(yk,0)∥2 ,
(75)
which also holds for all k ∈[K] with probability at least 1 −δ.
Getting a high-probability convergence rate.
Given our high-probability bounds (74) and (75),
we can substitute them to (62) and get
F(yk+1,0) −F(yk,0)
≤(−ηN + η2LN 2) ∥∇F(yk,0)∥2 + η2 ∥∇F(yk,0)∥∥rk∥+ η4L ∥rk∥2
≤

−ηN + η2LN 2 + 7η2LρN 2
5
+ 147η4L3ρ2N 4
25

∥∇F(yk,0)∥2
+ η2LνΦ
r
log 4MNK
δ
∥∇F(yk,0)∥+ 3η4L3ν2Φ2 log 4MNK
δ
+ 2η2LτN(B −1)
3
∥∇F(yk,0)∥+ 4η4L3τ 2N 2(B −1)2
3
.
(76)
The following terms in the RHS of (76) can be bounded using ab ≤a2
2 + b2
2 :
η2LνΦ
r
log 4MNK
δ
∥∇F(yk,0)∥
=
η1/2N 1/2
√
8
∥∇F(yk,0)∥
  √
8η3/2LνΦ
N 1/2
r
log 4MNK
δ
!
≤ηN
16 ∥∇F(yk,0)∥2 + 4η3L2ν2Φ2
N
log 4MNK
δ
,
(77)
2η2LτN(B −1)
3
∥∇F(yk,0)∥
33

Published as a conference paper at ICLR 2022
=
η1/2N 1/2
√
8
∥∇F(yk,0)∥
  
2
√
8η3/2LτN 1/2(B −1)
3
!
≤ηN
16 ∥∇F(yk,0)∥2 + 16η3L2τ 2N(B −1)2
9
.
(78)
Substituting (77) and (78) to (76) results in
F(yk+1,0) −F(yk,0)
≤

−7
8ηN + η2LN 2 + 7η2LρN 2
5
+ 147η4L3ρ2N 4
25

∥∇F(yk,0)∥2
+ η3L2ν2(4 + 3ηLN)Φ2
N
log 4MNK
δ
+ 4η3L2τ 2(4 + 3ηLN)N(B −1)2
9
.
(79)
Again, we have K ≥7ρκ log(MNK2) and η = log(MNK2)
µNK
, so ηLρN ≤1
7. Since the inequality
−7
8z + 12
5 z2 + 147
25 z4 ≤−1
2z holds on z ∈[0, 1
7], we have
−7
8ηN + η2LN 2 + 7η2LρN 2
5
+ 147η4L3ρ2N 4
25
≤−7
8ηN + 12η2LρN 2
5
+ 147η4L3ρ3N 4
25
≤−1
2ηN.
Substituting this inequality to (79), together with 4 + 3ηLN ≤31
7 < 9
2, yields
F(yk+1,0) −F(yk,0) ≤−ηN
2 ∥∇F(yk,0)∥2 + 9η3L2ν2Φ2
2N
log 4MNK
δ
+ 2η3L2τ 2N(B −1)2.
We now recall that F is µ-PŁ, so ∥∇F(yk,0)∥2 ≥2µ(F(yk,0) −F ∗):
F(yk+1,0) −F ∗≤(1 −ηµN)(F(yk,0) −F ∗)
+ 9η3L2ν2Φ2
2N
log 4MNK
δ
+ 2η3L2τ 2N(B −1)2.
(80)
Recall that (80) holds for all k ∈[K], with probability 1 −δ. Therefore, by unrolling the inequality,
F(yK, N
B ) −F ∗≤(1 −ηµN)K(F(y0) −F ∗)
+
9η3L2ν2Φ2
2N
log 4MNK
δ
+ 2η3L2τ 2N(B −1)2
 K−1
X
k=0
(1 −ηµN)k
≤(1 −ηµN)K(F(y0) −F ∗)
+ 9η2L2ν2Φ2
2µN 2
log 4MNK
δ
+ 2η2L2τ 2(B −1)2
µ
.
(81)
Recall that Φ := 12N(B3/2−1)
5B
+ 8(N 3/2−B3/2)
3M 1/2
, hence
Φ2 ≤288N 2(B3/2 −1)2
25B2
+ 128(N 3/2 −B3/2)2
9M
.
Substituting this inequality and also η = log(MNK2)
µNK
gives
F(yK, N
B ) −F ∗
≤F(y0) −F ∗
MNK2
+ 2L2τ 2(B −1)2
µ3N 2K2
log2(MNK2)
+
9L2ν2
2µ3N 4K2 log 4MNK
δ
log2(MNK2)
288N 2(B3/2 −1)2
25B2
+ 128(N 3/2 −B3/2)2
9M

= F(y0) −F ∗
MNK2
+ ˜O
L2τ 2
µ3
B2
N 2K2

+ ˜O
L2ν2
µ3
B
N 2K2

+ ˜O
L2ν2
µ3
1
MNK2

,
with probability at least 1 −δ. This ﬁnishes the proof.
34

Published as a conference paper at ICLR 2022
D.4
PROOF OF UPPER BOUND FOR MINIBATCH RR WITH SYNCSHUF (THEOREM 6)
The ﬁrst part (“One epoch as one step of GD plus noise”) of the proof is identical to that of Theo-
rem 1. We start from the second part.
Bounding noise term using concentration.
It is left to bound ∥rk∥. As seen in (41), we have
∥rk∥≤LB(1 + ηLB)N/B
N/B−1
X
i=1

i
X
j=1
gj

.
(82)
Recall from the theorem statement that K ≥6κ log(MNK2) and η = log(MNK2)
µNK
. This means that
(1 + ηLB)N/B =

1 + κB log(MNK2)
NK
N/B
≤

1 + B
6N
N/B
≤e1/6.
(83)
Next, we bound the norm of
i
X
j=1
gj = 1
M
M
X
m=1
iB
X
j=1
∇f m
σm
k (j)(xk,0),
(84)
exploiting our modiﬁcation SYNCSHUF as well as Lemma 8. For each ∇f m
σm
k (j)(xk,0), we ﬁrst add
and subtract its corresponding ∇¯fσm
k (j)(xk,0), where ¯fi :=
1
M
PM
m=1 f m
i
as deﬁned in Assump-
tion 4. This way, (84) can be decomposed into two sums Pi
j=1 gj =
1
M (pi + qi), where
pi :=
M
X
m=1
iB
X
j=1
∇¯fσm
k (j)(xk,0),
qi :=
M
X
m=1
iB
X
j=1
∇f m
σm
k (j)(xk,0) −∇¯fσm
k (j)(xk,0).
Using this decomposition, we will derive high-probability bounds for ∥pi∥and ∥qi∥.
To simplify expressions to follow, we decompose iBM (i.e., the total number of component gradi-
ents that are summed up) into a multiple of N and the remainder. Let
α(i) :=
iBM
N

, β(i) := iBM −Nα(i),
so that iBM is decomposed into Nα(i) and the remainder 0 ≤β(i) < N. Using this new notation,
we can write pi as
pi =
M
X
m=1
Nα(i)
M
X
j=1
∇¯fσm
k (j)(xk,0) +
M
X
m=1
iB
X
j= Nα(i)
M
+1
∇¯fσm
k (j)(xk,0).
(85)
Here, recall that with SYNCSHUF, we deﬁned σm
k (j) := σ((j+ N
M π(m)) mod N). With this choice
of “shifted” permutations, one can notice that {σm
k (j)}
M, N
M
m=1,j=1 = [N], meaning that adding ¯fσm
k (j)
for m ∈[M] and j ∈[N/M] results in the sum of all N ¯fi’s. In fact, this happens if we sum over
m ∈[M] and any N/M consecutive j’s. From this observation and F =
1
N
PN
i=1 ¯fi, (85) can be
written as
pi = Nα(i)∇F(xk,0) +
M
X
m=1
iB
X
j= Nα(i)
M
+1
∇¯fσ((j+ Nm
M ) mod N)(xk,0).
(86)
Assume for now that β(i) > 0, i.e., Nα(i) < iBM. The summation in the second term of RHS
in (86) is a without-replacement sum (note that the indices j + Nm
M do not overlap) of β(i) terms.
35

Published as a conference paper at ICLR 2022
Hence, it is equal in distribution to Pβ(i)
j=1 ∇¯fσ(j)(xk,0). Also, from Assumption 2, it can be easily
checked that for any i ∈[N]
∇¯fi(xk,0) −∇F(xk,0)
 ≤ν.
These observations mean that we can apply Lemma 8 to get a concentration bound, with M ←1,
v1
i ←∇¯fi(xk,0), n ←β(i), and δ ←
Bδ
2NK . By Lemma 8, with probability at least 1 −
Bδ
2NK (over
the randomness in σ), we have

1
β(i)
M
X
m=1
iB
X
j= Nα(i)
M
+1
∇¯fσ((j+ Nm
M ) mod N)(xk,0) −∇F(xk,0)

≤ν
s
8 log 4NK
Bδ
β(i)
.
(87)
Combining (86) and (87), we get the following upper bound on ∥pi∥, which holds with probability
at least 1 −
Bδ
2NK .
∥pi∥≤∥iBM∇F(xk,0)∥+

M
X
m=1
iB
X
j= Nα(i)
M
+1
∇¯fσ((j+ Nm
M ) mod N)(xk,0) −β(i)∇F(xk,0)

≤iBM ∥∇F(xk,0)∥+ ν
r
8β(i) log 4NK
Bδ
≤iBM ∥∇F(xk,0)∥+ ν
√
N
r
8 log 4NK
Bδ ,
(88)
where the last inequality used β(i) < N. Also recall that we assumed β(i) > 0 in order to use
Lemma 8 and derive (88). However, note that even with β(i) = 0, the bound (88) trivially holds.
We next bound ∥qi∥. This time, we will apply Lemma 8 to the permutation π over the local ma-
chines. To do this, we will condition on a ﬁxed instantiation of the permutation σ and derive a
high-probability bound that holds with conditional probability at least 1 −
Bδ
2NK . The conditional
probability is at least 1 −
Bδ
2NK irrespective of the choice of σ, so we can conclude that the (uncon-
ditional) probability that our bound holds is also at least 1 −
Bδ
2NK .
Without loss of generality, choose the instantiation σ(l) = l for all l ∈[N]. With this σ, we have
σm
k (j) := (j + N
M π(m)) mod N, so the vector qi reads
qi =
M
X
m=1
iB
X
j=1
∇f m
(j+ N
M π(m)) mod N(xk,0) −∇¯f(j+ N
M π(m)) mod N(xk,0).
(89)
Let us consider rewriting this summation as the sum over l ∈[N], where l appears in the subscript
of the component functions. One can check that
l =

j + N
M π(m)

mod N
⇔
N
M | (l −j) and π(m) = (l −j)M
N mod M,
where a | b denotes “a divides b.” From this, we can rewrite (89) as
qi =
N
X
l=1
X
j∈[iB]
N
M |(l−j)

∇f
π−1((l−j) M
N mod M)
l
(xk,0) −∇¯fl(xk,0)

|
{z
}
=:qi,l
.
(90)
By the same reasoning above and below (86), we can see from (90) that for a given index l ∈[N],
the cardinality of the set Jl := {j ∈[iB] :
N
M | (l −j)} is either α(i) or α(i) + 1. From this,
we notice that each qi,l is a without-replacement sum of α(i) or α(i) + 1 terms. For now, suppose
α(i) > 0. For each qi,l, we can apply Lemma 8 to it, and show that with probability (conditioned
on the instantiation σ(l) = l) at least 1 −
Bδ
2N2K , we have
∥qi,l∥≤



λ
q
8(α(i)) log 4N 2K
Bδ
if |Jl| = α(i),
λ
q
8(α(i) + 1) log 4N2K
Bδ
if |Jl| = α(i) + 1.
36

Published as a conference paper at ICLR 2022
Note that cases in the RHS are all bounded from above by λ
q
16α(i) log 4N2K
Bδ . Applying union
bound on all l ∈[N], we get that with probability at least 1 −
Bδ
2NK , we have
∥qi∥≤λN
r
16α(i) log 4N 2K
Bδ
≤λN
r
16iBM
N
log 4N 2K
Bδ
= 4λ
r
iBMN log 4N 2K
Bδ
. (91)
Now consider the case α(i) = 0. Recall from the deﬁnition α(i) :=
 iBM
N

that α(i) = 0 implies
iBM < N. In this case, qi,l = 0 for N −iBM indices l satisfying |Jl| = 0, and ∥qi,l∥≤λ for the
remaining iBM l’s satisfying |Jl| = 1. Summing up, ∥qi∥is bounded from above by λiBM, which
is in fact less than the upper bound in (91). Therefore, the bound (91) holds even for α(i) = 0.
Recall that our goal was to ﬁnd a bound on the norm of Pi
j=1 gj =
1
M (pi + qi). From the high-
probability bounds obtained in (88) and (91), with probability at least 1 −Bδ
NK ,

i
X
j=1
gj

≤iB ∥∇F(xk,0)∥+ ν
√
N
M
r
8 log 4NK
Bδ
+ 4λ
r
iBN
M
r
log 4N 2K
Bδ
.
(92)
We can now substitute (83) and (92) to (82) to get
∥rk∥≤e1/6LB
N/B−1
X
i=1
 
iB ∥∇F(xk,0)∥+ ν
√
N
M
r
8 log 4NK
Bδ
+ 4λ
r
iBN
M
r
log 4N 2K
Bδ
!
≤e1/6LB2 ∥∇F(xk,0)∥
N/B−1
X
i=1
i + e1/6√
8LνN 1/2(N −B)
M
r
log 4NK
Bδ
+ 4e1/6LλB3/2N 1/2
M 1/2
Z N/B
1
√
tdt
r
log 4N 2K
Bδ
≤LN(N −B) ∥∇F(xk,0)∥+ 7LνN 1/2(N −B)
2M
r
log 4NK
Bδ
+ 7LλN 1/2(N 3/2 −B3/2)
2M 1/2
r
log 4N 2K
Bδ
,
(93)
which holds with probability at least 1 −
δ
K , due to the union bound over i = 1, . . . , N/B −1.
The bound (93) holds for all k ∈[K] with probability 1 −δ if we apply the union bound over
k = 1, . . . , K. Next, by (a + b + c)2 ≤3a2 + 3b2 + 3c2, we have
∥rk∥2 ≤3L2N 2(N −B)2 ∥∇F(xk,0)∥2 + 147L2ν2N(N −B)2
4M 2
log 4NK
Bδ
+ 147L2λ2N(N 3/2 −B3/2)2
4M
log 4N 2K
Bδ
,
(94)
which also holds for all k ∈[K] with probability at least 1 −δ.
Getting a high-probability convergence rate.
Given our high-probability bounds (93) and (94),
we can substitute them to (40) and get
F(xk+1,0) −F(xk,0)
≤(−ηN + η2LN 2) ∥∇F(xk,0)∥2 + η2 ∥∇F(xk,0)∥∥rk∥+ η4L ∥rk∥2
≤
 −ηN + η2LN 2 + η2LN(N −B) + 3η4L3N 2(N −B)2
∥∇F(xk,0)∥2
+ 7η2LνN 1/2(N −B)
2M
r
log 4NK
Bδ
∥∇F(xk,0)∥+ 147η4L3ν2N(N −B)2
4M 2
log 4NK
Bδ
+ 7η2LλN 1/2(N 3/2 −B3/2)
2M 1/2
r
log 4N 2K
Bδ
∥∇F(xk,0)∥
+ 147η4L3λ2N(N 3/2 −B3/2)2
4M
log 4N 2K
Bδ
.
(95)
37

Published as a conference paper at ICLR 2022
Two terms in the RHS of (95) can be bounded using ab ≤a2
2 + b2
2 :
7η2LνN 1/2(N −B)
2M
r
log 4NK
Bδ
∥∇F(xk,0)∥
=
η1/2N 1/2
2
√
2
∥∇F(xk,0)∥
  
7
√
2η3/2Lν(N −B)
M
r
log 4NK
Bδ
!
≤ηN
16 ∥∇F(xk,0)∥2 + 49η3L2ν2(N −B)2
M 2
log 4NK
Bδ ,
(96)
7η2LλN 1/2(N 3/2 −B3/2)
2M 1/2
r
log 4N 2K
Bδ
∥∇F(xk,0)∥
=
η1/2N 1/2
2
√
2
∥∇F(xk,0)∥
  
7
√
2η3/2Lλ(N 3/2 −B3/2)
M 1/2
r
log 4N 2K
Bδ
!
≤ηN
16 ∥∇F(xk,0)∥2 + 49η3L2λ2(N 3/2 −B3/2)2
M
log 4N 2K
Bδ
,
(97)
Putting inequalities (96) and (97) to (95) and noting N −B ≤N gives
F(xk+1,0) −F(xk,0) ≤

−7
8ηN + 2η2LN 2 + 3η4L3N 4

∥∇F(xk,0)∥2
+ 49η3L2(4 + 3ηLN)ν2(N −B)2
4M 2
log 4NK
Bδ
+ 49η3L2(4 + 3ηLN)λ2(N 3/2 −B3/2)2
4M
log 4N 2K
Bδ
.
(98)
Recall from K ≥6κ log(M 2NK2) and η =
log(M 2NK2)
µNK
that ηLN ≤
1
6. Since the inequality
−7
8z + 2z2 + 3z4 ≤−1
2z holds on z ∈[0, 1
6], we have
−7
8ηN + 2η2LN 2 + 3η4L3N 4 ≤−1
2ηN.
Applying this bound to (98) results in
F(xk+1,0) −F(xk,0) ≤−ηN
2 ∥∇F(xk,0)∥2 + 56η3L2ν2(N −B)2
M 2
log 4NK
Bδ
+ 56η3L2λ2(N 3/2 −B3/2)2
M
log 4N 2K
Bδ
We now recall that F is µ-PŁ, so ∥∇F(xk,0)∥2 ≥2µ(F(xk,0) −F ∗):
F(xk+1,0) −F ∗≤(1 −ηµN)(F(xk,0) −F ∗) + 56η3L2ν2(N −B)2
M 2
log 4NK
Bδ
+ 56η3L2λ2(N 3/2 −B3/2)2
M
log 4N 2K
Bδ
(99)
Recall that (99) holds for all k ∈[K], with probability 1 −δ. Therefore, by unrolling the inequality,
and using PK−1
k=0 (1 −ηµN)k ≤
1
ηµN , we get
F(xK, N
B ) −F ∗≤(1 −ηµN)K(F(x0) −F ∗) + 56η2L2ν2(N −B)2
µM 2N
log 4NK
Bδ
+ 56η2L2λ2(N 3/2 −B3/2)2
µMN
log 4N 2K
Bδ
(100)
Lastly, substituting η = log(M 2NK2)
µNK
to (100) gives
F(xK, N
B ) −F ∗≤F(x0) −F ∗
M 2NK2
+ 56L2ν2(N −B)2 log 4NK
Bδ log2(M 2NK2)
µ3M 2N 3K2
38

Published as a conference paper at ICLR 2022
+ 56L2λ2(N 3/2 −B3/2)2 log 4N2K
Bδ
log2(M 2NK2)
µ3MN 3K2
= F(x0) −F ∗
M 2NK2
+ ˜O
L2
µ3

ν2
M 2NK2 +
λ2
MK2

.
D.5
PROOF OF UPPER BOUND FOR LOCAL RR WITH SYNCSHUF (THEOREM 7)
The ﬁrst part (“One epoch as one step of GD plus noise”) of the proof is identical to that of Theo-
rem 2. The ﬁrst part deﬁnes our “noise” rk as the sum of three terms rk := rk,1 + rk,2 −ηrk,3. We
start from the second part.
Bounding noise terms using concentration.
We next bound ∥rk∥by bounding each ∥rk,1∥,
∥rk,2∥, and ∥rk,3∥. We have already seen from (63), (64), (65), (66), and (67) in Appendix D.3
that
∥rk,1∥≤e1/7L
M
N/B
X
l=1
M
X
m=1
lB−1
X
i=(l−1)B+1

i
X
t=(l−1)B+1
∇f m
σm
k (t)(yk,0)

,
(101)
∥rk,2∥≤7LB
5M
N/B−1
X
l=1

M
X
m=1
lB
X
t=1
∇f m
σm
k (t)(yk,0)
 ,
(102)
∥rk,3∥≤11L2B
7M
N/B−1
X
l=1
l
X
j=1
M
X
m=1
jB−1
X
i=(j−1)B+1

i
X
t=(j−1)B+1
∇f m
σm
k (t)(yk,0)

.
(103)
As in the previous subsections, the key is to bound the norm of the partial sums of ∇f m
σm
k (t)(yk,0)
using Lemma 8. For the summations appearing in (101) and (103), we apply Lemma 8 in the same
way as (68). For any i satisfying (j −1)B + 1 ≤i ≤jB −1, where j ∈[N/B], and for any
m ∈[M], the following bound holds with probability at least 1 −
δ
3MNK :

i
X
t=(j−1)B+1
∇f m
σm
k (t)(yk,0)

≤ν
q
8(i −(j −1)B) log 6MNK
δ
+ (i −(j −1)B) ∥∇F m(yk,0)∥.
(104)
For the summation that appear in (102), we use the techniques from Appendix D.4. For each l ∈
[N/B −1], we can similarly decompose PM
m=1
PlB
t=1 ∇f m
σm
k (t)(yk,0) into pl + ql, where
pl :=
M
X
m=1
lB
X
t=1
∇¯fσm
k (t)(yk,0),
ql :=
M
X
m=1
lB
X
t=1
∇f m
σm
k (t)(yk,0) −∇¯fσm
k (t)(yk,0).
As done in Appendix D.4, we can follow the same steps and show a high-probability bound, which
is a slightly different version of (88): with probability at least 1 −
Bδ
3NK ,
∥pl∥≤lBM ∥∇F(yk,0)∥+ ν
√
N
r
8 log 6NK
Bδ .
(105)
Similarly, for ∥ql∥we can show a slight modiﬁcation of (91):
∥ql∥≤4λ
r
lBMN log 6N 2K
Bδ
,
(106)
which holds with probability at least 1−
Bδ
3NK . Combining (105) and (106), with probability at least
1 −2Bδ
3NK , we have

M
X
m=1
lB
X
t=1
∇f m
σm
k (t)(yk,0)
 ≤lBM ∥∇F(yk,0)∥+ ν
√
N
r
8 log 6NK
Bδ
39

Published as a conference paper at ICLR 2022
+ 4λ
r
lBMN log 6N 2K
Bδ
.
(107)
By applying the union bound, with probability at least 1−δ
K , the bound (104) holds for all m ∈[M]
and i ∈SN/B
j=1 [(j −1)B + 1 : jB −1], and the bound (107) holds for all l ∈[N/B −1].
We now substitute the bounds (104) and (107) to (101), (102), and (103) to get upper bounds for
∥rk,1∥, ∥rk,2∥, and ∥rk,3∥, respectively. For ∥rk,1∥and ∥rk,3∥, we can apply the same calculations
as in (70) and (72), modulo the fact that Assumption 3 is now implied by Assumption 4, with
constants τ = λ and ρ = 1. We obtain
∥rk,1∥≤24LνN(B3/2 −1)
11B
r
log 6MNK
δ
+ 3LN(B −1)
5
(λ + ∥∇F(yk,0)∥) ,
(108)
∥rk,3∥≤3L2νN(N −B)(B3/2 −1)
2B
r
log 6MNK
δ
+ 2L2N(N −B)(B −1)
5
(λ + ∥∇F(yk,0)∥).
(109)
For ∥rk,2∥, we have
∥rk,2∥≤7LB
5M
N/B−1
X
l=1
 
lBM ∥∇F(yk,0)∥+ ν
√
N
r
8 log 6NK
Bδ
+ 4λ
r
lBMN log 6N 2K
Bδ
!
= 7LB2
5


N/B−1
X
l=1
l

∥∇F(yk,0)∥+ 7
√
8LνN 1/2(N −B)
5M
r
log 6NK
Bδ
+ 28LλB3/2N 1/2
5M 1/2


N/B−1
X
l=1
√
l


r
log 6N 2K
Bδ
≤7LN(N −B)
10
∥∇F(yk,0)∥+ 4LνN 1/2(N −B)
M
r
log 6NK
Bδ
+ 15LλN 1/2(N 3/2 −B3/2)
4M 1/2
r
log 6N 2K
Bδ
.
(110)
Recalling the deﬁnition rk := rk,1 + rk,2 −ηrk,3, we get an upper bound for ∥rk∥from (108),
(109), and (110):
∥rk∥≤∥rk,1∥+ ∥rk,2∥+ η ∥rk,3∥
≤Lν
r
log 6MNK
δ
24N(B3/2 −1)
11B
+ 4N 1/2(N −B)
M
+ 3ηLN(N −B)(B3/2 −1)
2B

+ Lλ
 
3N(B −1)
5
+ 15N 1/2(N 3/2 −B3/2)
4M 1/2
r
log 6N 2K
Bδ
+ 2ηLN(N −B)(B −1)
5
!
+ L ∥∇F(yk,0)∥
3N(B −1)
5
+ 7N(N −B)
10
+ 2ηLN(N −B)(B −1)
5

.
(111)
Recall again that we have K ≥7κ log(M 2NK2) and η = log(M 2NK2)
µNK
, so ηLN ≤1/7. Using this
and N −B ≤N, we can further simplify (111).
∥rk∥≤Lν
r
log 6MNK
δ
12N(B3/2 −1)
5B
+ 4N 1/2(N −B)
M

|
{z
}
=:Φν
+ Lλ
r
log 6N 2K
Bδ
2N(B −1)
3
+ 15N 1/2(N 3/2 −B3/2)
4M 1/2

|
{z
}
=:Φλ
40

Published as a conference paper at ICLR 2022
+ L ∥∇F(yk,0)∥
2N(B −1)
3
+ 7N(N −B)
10

≤LνΦν
r
log 6MNK
δ
+ LλΦλ
r
log 6N 2K
Bδ
+ 7LN 2
5
∥∇F(yk,0)∥,
(112)
which holds with probability at least 1 −δ
K . The bound (112) holds for all k ∈[K] with probability
1 −δ if we apply the union bound over k = 1, . . . , K. Next, by (a + b + c)2 ≤3a2 + 3b2 + 3c2,
we have
∥rk∥2 ≤3L2ν2Φ2
ν log 6MNK
δ
+ 3L2λ2Φ2
λ log 6N 2K
Bδ
+ 147L2N 4
25
∥∇F(yk,0)∥2 ,
(113)
which also holds for all k ∈[K] with probability at least 1 −δ.
Getting a high-probability convergence rate.
Given our high-probability bounds (112) and
(113), we can substitute them to (62) and get
F(yk+1,0) −F(yk,0)
≤(−ηN + η2LN 2) ∥∇F(yk,0)∥2 + η2 ∥∇F(yk,0)∥∥rk∥+ η4L ∥rk∥2
≤

−ηN + η2LN 2 + 7η2LN 2
5
+ 147η4L3N 4
25

∥∇F(yk,0)∥2
+ η2LνΦν
r
log 6MNK
δ
∥∇F(yk,0)∥+ 3η4L3ν2Φ2
ν log 6MNK
δ
+ η2LλΦλ
r
log 6N 2K
Bδ
∥∇F(yk,0)∥+ 3η4L3λ2Φ2
λ log 6N 2K
Bδ
.
(114)
The following terms in the RHS of (114) can be bounded using ab ≤a2
2 + b2
2 :
η2LνΦν
r
log 6MNK
δ
∥∇F(yk,0)∥
=
η1/2N 1/2
√
8
∥∇F(yk,0)∥
  √
8η3/2LνΦν
N 1/2
r
log 6MNK
δ
!
≤ηN
16 ∥∇F(yk,0)∥2 + 4η3L2ν2Φ2
ν
N
log 6MNK
δ
,
(115)
η2LλΦλ
r
log 6N 2K
Bδ
∥∇F(yk,0)∥
=
η1/2N 1/2
√
8
∥∇F(yk,0)∥
  √
8η3/2LλΦλ
N 1/2
r
log 6N 2K
Bδ
!
≤ηN
16 ∥∇F(yk,0)∥2 + 4η3L2λ2Φ2
λ
N
log 6N 2K
Bδ
.
(116)
Substituting (115) and (116) to (114) results in
F(yk+1,0) −F(yk,0)
≤

−7
8ηN + 12η2LN 2
5
+ 147η4L3ρ2N 4
25

∥∇F(yk,0)∥2
+ η3L2ν2(4 + 3ηLN)Φ2
ν
N
log 6MNK
δ
+ η3L2λ2(4 + 3ηLN)Φ2
λ
N
log 6N 2K
Bδ
.
(117)
Again, we have K ≥7κ log(M 2NK2) and η = log(M 2NK2)
µNK
, so ηLN ≤1
7. Since the inequality
−7
8z + 12
5 z2 + 147
25 z4 ≤−1
2z holds on z ∈[0, 1
7], we have
−7
8ηN + 12η2LρN 2
5
+ 147η4L3ρ3N 4
25
≤−1
2ηN.
41

Published as a conference paper at ICLR 2022
Substituting this inequality to (117), together with 4 + 3ηLN ≤31
7 < 9
2, yields
F(yk+1,0) −F(yk,0) ≤−ηN
2 ∥∇F(yk,0)∥2 + 9η3L2ν2Φ2
ν
2N
log 6MNK
δ
+ 9η3L2λ2Φ2
λ
2N
log 6N 2K
Bδ
.
We now recall that F is µ-PŁ, so ∥∇F(yk,0)∥2 ≥2µ(F(yk,0) −F ∗):
F(yk+1,0) −F ∗≤(1 −ηµN)(F(yk,0) −F ∗) + 9η3L2ν2Φ2
ν
2N
log 6MNK
δ
+ 9η3L2λ2Φ2
λ
2N
log 6N 2K
Bδ
.
(118)
Recall that (118) holds for all k ∈[K], with probability 1−δ. Therefore, by unrolling the inequality,
and using PK−1
k=0 (1 −ηµN)k ≤
1
ηµN , we get
F(yK, N
B ) −F ∗≤(1 −ηµN)K(F(y0) −F ∗) + 9η2L2ν2Φ2
ν
2µN 2
log 6MNK
δ
+ 9η2L2λ2Φ2
λ
2µN 2
log 6N 2K
Bδ
.
(119)
Recall that Φν := 12N(B3/2−1)
5B
+ 4N1/2(N−B)
M
and Φλ := 2N(B−1)
3
+ 15N1/2(N 3/2−B3/2)
4M 1/2
, hence
Φ2
ν ≤288N 2(B3/2 −1)2
25B2
+ 32N(N −B)2
M 2
,
Φ2
λ ≤8N 2(B −1)2
9
+ 225N(N 3/2 −B3/2)2
2M
.
Substituting these inequalities and also η = log(M 2NK2)
µNK
gives
F(yK, N
B ) −F ∗
≤F(y0) −F ∗
M 2NK2
+ 9L2ν2 log 6MNK
δ
log2(M 2NK2)
2µ3N 4K2
288N 2(B3/2 −1)2
25B2
+ 32N(N −B)2
M 2

+ 9L2λ2 log 6N2K
Bδ
log2(M 2NK2)
2µ3N 4K2
8N 2(B −1)2
9
+ 225N(N 3/2 −B3/2)2
2M

= F(y0) −F ∗
M 2NK2
+ ˜O
L2
µ3
 ν2B
N 2K2 +
ν2
M 2NK2 + λ2B2
N 2K2 +
λ2
MK2

,
with probability at least 1 −δ. This ﬁnishes the proof.
D.6
A GENERALIZED VECTOR-VALUED HOEFFDING-SERFLING INEQUALITY
We extend the vector-valued Hoeffding-Serﬂing inequality proved in Schneider (2016) to account
for the mean of multiple independent without-replacement sums.
Lemma 8. Suppose there are MN vectors {vm
i }M,N
m=1,i=1 ∈Rd that satisfy ∥vm
i −¯vm∥≤ν
for m ∈[M], where ¯vm :=
1
N
PN
i=1 vm
i . Consider M independently and uniformly sampled
permutations σ1, . . . , σM ∼Unif(SN). For any n ≤N −1, with probability at least 1−δ, we have

1
Mn
M
X
m=1
n
X
i=1
vm
σm(i) −1
M
M
X
m=1
¯vm
 ≤ν
s
8(1 −n−1
N ) log 2
δ
Mn
.
(120)
Proof. The proof is an extension of Theorem 2 of Schneider (2016) which proves the M = 1 case
for vectors in smooth separable Banach spaces. We prove our extended concentration inequality for
Rd, but we note that the proof technique can be applied directly to general smooth separable Banach
spaces, as done in Schneider (2016). Below, we state a special case of Theorem 3 of Pinelis (1992)
and Theorem 3.5 of Pinelis (1994), because this Rd case serves our purpose.
42

Published as a conference paper at ICLR 2022
Lemma 9 (Pinelis (1992; 1994)). Suppose that a sequence of random variables {xj}j≥0 is a mar-
tingale taking values in Rd, and P∞
j=1 ess sup ∥xj −xj−1∥2 ≤c2 for some c > 0. Then, for
λ > 0,
P
 sup{∥xj∥: j ≥0} ≥λ

≤2 exp

−λ2
2c2

.
The proof of Lemma 8 proceeds by deﬁning a sequence of random variables {xj}, showing that it is
a martingale, and applying Lemma 9 to prove our concentration bound. For m ∈[M], deﬁne index
functions km : N ∪{0} →[0 : n] in the following way:
km(j) := max{0, min{n, j −(m −1)n}} =



0
if j ≤(m −1)n,
j −(m −1)n
if (m −1)n + 1 ≤j ≤mn,
n
if j ≥mn + 1.
Using these index functions, we introduce the following sequence of random variables {xj}:
xj :=
M
X
m=1
1
N −km(j)
km(j)
X
i=1
(vm
σm(i) −¯vm),
and show that this is a martingale, i.e.,
E[xj | x1, . . . , xj−1] = xj−1
(121)
for all j ≥1. Notice ﬁrst that by deﬁnition of km’s we have xMn = xMn+1 = xMn+2 = . . . , so
(121) is trivially satisﬁed for all j > Mn. Next, for any j satisfying (l −1)n + 1 ≤j ≤ln where
l ∈[M], we have
xj =
l−1
X
m=1
1
N −n
n
X
i=1
(vm
σm(i) −¯vm) +
1
N −kl(j)
kl(j)
X
i=1
(vl
σl(i) −¯vl)
= xj−1 +

1
N −kl(j) −
1
N −kl(j) + 1
 kl(j)−1
X
i=1
(vl
σl(i) −¯vl)
+
1
N −kl(j)(vl
σl(kl(j)) −¯vl)
(122)
Now note that for any k ∈[N −1], we have
E[vl
σl(k) −¯vl | σl(1), . . . , σl(k −1)] =
1
N −k + 1
N
X
i=k
(vl
σl(i) −¯vl)
= −
1
N −k + 1
k−1
X
i=1
(vl
σl(i) −¯vl),
where the last equality used PN
i=1(vl
σl(i) −¯vl) = 0. Using applying this fact to (122) and noting
1
N−kl(j) −
1
N−kl(j)+1 =
1
(N−kl(j))(N−kl(j)+1),
E[xj | x1, . . . , xj−1] = xj−1 +
1
(N −kl(j))(N −kl(j) + 1)
kl(j)−1
X
i=1
(vl
σl(i) −¯vl)
+
1
N −kl(j)E

vl
σl(kl(j)) −¯vl | x1, . . . , xj−1

= xj−1,
hence proving that {xj}j≥0 is a martingale. We now apply Lemma 9 to our {xj}. For j such that
(l −1)n + 1 ≤j ≤ln, notice from (122) that
(N −kl(j))(xj −xj−1) =
1
(N −kl(j) + 1)


kl(j)−1
X
i=1
(vl
σl(i) −¯vl)

+ (vl
σl(kl(j)) −¯vl)
43

Published as a conference paper at ICLR 2022
= −
1
(N −kl(j) + 1)


N
X
i=kl(j)
(vl
σl(i) −¯vl)

+ (vl
σl(kl(j)) −¯vl),
which leads to
(N −kl(j)) ∥xj −xj−1∥≤ν min{kl(j) −1, N −kl(j) + 1}
N −kl(j) + 1
+ ν ≤2ν,
by the triangle inequality. From this, we get the bound c2 in the statement of Lemma 9:
∞
X
j=1
ess sup ∥xj −xj−1∥2 =
Mn
X
j=1
ess sup ∥xj −xj−1∥2 ≤M
n
X
k=1
4ν2
(N −k)2
=
4ν2M
(N −n)2 + 4ν2M
N−1
X
k=N−n+1
1
k2 ≤
4ν2M
(N −n)2 + 4ν2M(n −1)
(N −n)N
= 4ν2Mn
(N −n)2

1 −n −1
N

,
where the second inequality used the inequality that Pb
k=a+1
1
k2
≤
b−a
a(b+1) (Serﬂing, 1974,
Lemma 2.1). Now, applying Lemma 9 to {xj} with c2 = 4ν2Mn
(N−n)2
 1 −n−1
N

gives
P
 ∥xMn∥≥λ

≤P
 sup{∥xj∥: j ≥0} ≥λ

≤2 exp
 
−
λ2(N −n)2
8ν2Mn
 1 −n−1
N

!
.
(123)
Recall from the deﬁnition of {xj} that
xMn =
1
N −n
M
X
m=1
n
X
i=1
(vm
σm(i) −¯vm).
Substituting λ = Mnϵ
N−n to (123) gives
P
 
1
Mn
M
X
m=1
n
X
i=1
(vm
σm(i) −¯vm)
 ≥ϵ
!
≤2 exp
 
−
Mnϵ2
8ν2  1 −n−1
N

!
,
which ﬁnishes the proof.
D.7
HOW CAN WE AVOID UNIFORM BOUNDS OVER Rd IN OUR ASSUMPTIONS?
In Section 2, we introduced Assumptions 2, 3, and 4 on the intra- and inter-machine deviation. The
assumptions required that inequalities such as ∥∇f m
i (x) −∇F m(x)∥≤ν hold for all x ∈Rd. In
this subsection, we discuss more on this strong requirement “entire Rd.”
In fact, the entire-Rd requirement is posed in our assumptions to simplify the exposition of the main
results, and is not strictly necessary. One can easily check from our proofs that the assumptions are
only applied to the beginning iterates xk,0 (for minibatch RR) or yk,0 (for local RR) of epochs.
Hence, if these iterates lie in a bounded set, then the constants ν, τ, ρ, and λ may become much
smaller, depending on problem instances. Actually, if we explicitly assume that the iterates lie in
a compact set S,12 then Assumptions 2–4 are even guaranteed to hold for some constants; e.g., for
Assumption 2, we can choose
ν :=
max
m∈[M],i∈[N],x∈S ∥∇f m
i (x) −∇F m(x)∥,
since the maximum always exists.
However, assuming that the iterates lie in a speciﬁc set S can be problematic because the distance
that the iterates travel depend on the objective functions. One cannot know a priori if all iterates will
stay in a ﬁxed set S; hence, explicitly assuming bounded iterates should be avoided.
Then, a natural question is whether we can prove bounded iterates under some reasonable conditions,
instead of assuming it. We point out that this can be done by applying the technique developed in
Ahn et al. (2020, Theorem 1) to our upper bound theorems. Using the technique, a modiﬁed version
of our Theorem 1 can be written as follows:
12This bounded iterates assumption is indeed used in some existing results such as Haochen & Sra (2019);
Nagaraj et al. (2019); Rajput et al. (2020); Ahn et al. (2020).
44

Published as a conference paper at ICLR 2022
Theorem 10 (Best-iterate version of Theorem 1). Suppose that minibatch RR has parameters sat-
isfying Assumption 1. Assume that all local component functions f m
i
are L-smooth, the global
objective function F is µ-PŁ, and the set of global minima of F is nonempty and compact. Consider
running the algorithm using step-size η = B log(MNK2)
µNK
and initialization x1,0 := x0, for epochs
K ≥6κ log(MNK2). Then, with probability at least 1 −δ,
min
k∈[K+1] F(xk,0) −F ∗≤F(x0) −F ∗
MNK2
+ ˜O
L2
µ3
ν2
MNK2

,
where the constant ν < ∞is deﬁned as
ν :=
sup
x:F (x)≤F (x0)
max
i∈[N] max
m∈[M] ∥∇f m
i (x) −∇F m(x)∥.
(124)
In the theorem, we used xK+1,0 to denote the last iterate of the algorithm xK, N
B . Theorem 10
differs from Theorem 1 in three aspects: 1) it considers the best-iterate, not the last-iterate; 2) it
additionally assumes that the set of global minima of F is nonempty and compact, which always
holds if F is strongly convex; and 3) it does not rely on Assumption 2, but instead “proves” it for
the F(x0)-sublevel set of F (124). Note that the constant ν (124) can be much smaller than the
uniform bound required to make Assumption 2 hold for the entire Rd. For Theorems 2, 6, and 7, we
can also apply similar techniques to prove best-iterate bounds with smaller intra- and inter-machine
deviation constants ν, τ, ρ, and λ; we omit the precise statements.
We conclude this subsection with the proof of Theorem 10.
Proof. The proof follows that of Ahn et al. (2020, Theorem 1).
Existence of ν.
We ﬁrst show the existence of ν < ∞(124). The global objective function F is
µ-PŁ. If we denote the set of global minima of F as X∗, the set X∗is nonempty and compact by
assumption. Then, by Karimi et al. (2016, Theorem 2) µ-PŁ functions satisfy quadratic growth, i.e.,
denoting by x∗the closest global minimum in X∗to the point x,
F(x) −F ∗≥2µ ∥x −x∗∥2 .
Deﬁne the sublevel set S := {x | F(x) ≤F(x0)}. Due to the quadratic growth property, we have
F(x0) −F ∗≥F(x) −F ∗≥2µ ∥x −x∗∥2 for all x ∈S. This implies that
S := {x ∈Rd | F(x) ≤F(x0)} ⊂

x ∈Rd | ∥x −x∗∥2 ≤F(x0) −F ∗
2µ

.
Since we assumed that X∗is compact, S is also bounded, and hence compact. Now, for any m ∈[M]
and i ∈[N], ∥∇f m
i (x) −∇F m(x)∥is a continuous function on a compact set S, so there must exist
a constant νm
i
< ∞such that ∥∇f m
i (x) −∇F m(x)∥≤νm
i for all x ∈S. Taking the maximum of
νm
i over all m and i gives ν.
Proving the best-iterate bound.
With the constant ν (124), if all the iterates {xk,0}k∈[K+1] stay
within the sublevel set S := {x | F(x) ≤F(x0)}, one can consider Assumption 2 to be true with
constant ν. From this observation, we consider two cases:
1. All the iterates {xk,0}k∈[K+1] stay in the sublevel set S.
2. There exists an iterate xk,0 /∈S.
In fact, the ﬁrst case can be proven by exactly the same steps as Theorem 1, described in Ap-
pendix D.2.
For the second case, suppose that there exists an iterate xk,0 that escapes the sublevel set S. Let
k′ ∈{2, . . . , K + 1} be the ﬁrst such k. Then, since xk′−1,0 is still in S, it follows from (50) in
Appendix D.2 that we have
F(xk′,0)−F ∗≤(1−ηµN)(F(xk′−1,0)−F ∗) + 15η3L2ν2(N 3/2 −B3/2)2
MN
log 2NK
Bδ .
(125)
45

Published as a conference paper at ICLR 2022
However, the fact that xk′,0 /∈S and xk′−1,0 ∈S implies
F(xk′,0) > F(x0) ≥F(xk′−1,0).
(126)
Combining the two bounds (125) and (126), we get
0 < −ηµN(F(xk′−1,0) −F ∗) + 15η3L2ν2(N 3/2 −B3/2)2
MN
log 2NK
Bδ ,
which implies
min
k∈[K+1] F(xk,0) −F ∗≤F(xk′−1,0) −F ∗< 15η2L2ν2(N 3/2 −B3/2)2
µMN 2
log 2NK
Bδ .
Substituting η = log(MNK2)
µNK
13 gives the desired bound and ﬁnishes the proof.
E
PROOF OF LOWER BOUND FOR MINIBATCH RR (THEOREM 3)
For Theorem 3, we consider three step-size ranges and do case analysis for each of them. We
construct functions for each corresponding step-size regime such that the convergence of minibatch
RR is “slow” for the functions on their corresponding step-size regime. The ﬁnal lower bound is
the minimum among the lower bounds obtained for the three regimes. More concretely, we will
construct three one-dimensional functions F1(x), F2(x), and F3(x) satisfying L-smoothness (1),
µ-PŁ condition (2), and Assumption 2 such that14
• Minibatch RR on F1(x) with η ≤
B
µNK and initialization x0 = ν
µ results in
E[F1(xK, N
B )] = Ω
ν2
µ

.
• Minibatch RR on F2(x) with η ≥
B
µNK and η ≤
B
513LN and initialization x0 = 0 results
in
E[F2(xK, N
B )] = Ω

ν2
µMNK2

.
Note that the step-size range requires K ≥513κ, hence this lower bound occurs only in
the “large-epoch” regime, i.e., K ≳κ.
• Minibatch RR on F3(x) with η ≥
B
µNK and η ≥
B
513LN and initialization x0 = 0 results
in
E[F3(xK, N
B )] = Ω

ν2
µMNK

.
Then, the three dimensional function F([x, y, z]⊤) = F1(x) + F2(y) + F3(z) will show bad con-
vergence in any step-size regime. Furthermore,
µI ⪯min(∇2F1, ∇2F2, ∇2F3)I ⪯∇2F ⪯max(∇2F1, ∇2F2, ∇2F3)I ⪯LI,
that is, if F1, F2 and F3 are µ-strongly convex and L-smooth, then so is F. Moreover, since the
component functions in each coordinate are designed to satisfy Assumption 2 with ν, the resulting
three dimensional function F also satisﬁes Assumption 2 with
√
3ν.
Since the ﬁnal lower bound is the minimum among the lower bounds obtained in the step-size ranges,
the lower bound becomes Ω

ν2
µMNK2

if K ≥513κ, and Ω

ν2
µMNK

if K < 513κ (in which case
the second step-size range does not exist).
In the subsequent subsections, we prove the lower bounds for F1, F2, and F3 separately.
13Recall that this is different from η = B log(MNK2)
µNK
in the theorem statement, because for the proofs, we
consider an equivalent “rescaled” version of minibatch RR deﬁned in the beginning of Appendix D.2.
14In fact, the functions constructed in this theorem are µ-strongly convex, which is stronger than µ-PL
required in Deﬁnition 1.
46

Published as a conference paper at ICLR 2022
E.1
LOWER BOUND FOR η ≤
B
µNK
Consider the case where every function at every machine is the same: for all i ∈[N] and m ∈[M],
f m
i (x) := µx2
2 . Hence, F1(x) = µx2
2 .
Let xk,0 and xk, N
B denote the iterates where the k-th epoch starts and ends respectively. Then,
xk+1,0 = xk, N
B = (1 −ηµ)
N
B xk,0.
Initializing at x1,0 = ν
µ and unrolling this for K epochs, we get
xK, N
B = (1 −ηµ)
NK
B · ν
µ ≥

1 −
B
NK
 NK
B
· ν
µ ≥ν
4µ,
since N ≥2, K ≥1, and B divides N. Hence, F1(xK, N
B ) = Ω( ν2
µ ).
E.2
LOWER BOUND FOR η ≥
B
µNK AND η ≤
B
513LN
For most part of this subsection, we consider iterates within a single epoch, and hence we will omit
the subscripts denoting epochs. Let x0 denote the iterate at the beginning of the epoch, and xi denote
the iterate after the i-th communication round in that epoch. In our construction, each machine will
have the same set of component functions, that is, there will be no inter-machine deviation. We
therefore omit the superscript m from the local component functions f m
i . The function we construct
for the lower bound and its component functions are as follows:
F2(x) := 1
N


N
2
X
i=1
f+1(x) +
N
X
i= N
2 +1
f−1(x)

, where
f+1(x) := (L1x≤0 + µ1x>0)x2
2 + νx, and
f−1(x) := (L1x≤0 + µ1x>0)x2
2 −νx
Note that the function F2(x) = (L1x≤0 + µ1x>0) x2
2 is µ-strongly convex and L-smooth with
minimizer at 0, and also satisﬁes Assumption 2.
Let σm be a random permutation of N
2 +1’s and N
2 −1’s. Then, machine m computes gradients on
f−1 and f+1 in the order given by σm. Let σm
j denote the j-th ordered element of σm. Then,
∇fσm
j (x) = (L1x≤0 + µ1x>0)x + νσm
j .
Hence, the last iterate of an epoch, x N
B , is given by
x N
B −x0 =
N
B −1
X
i=0

−η
MB
M
X
m=1
(i+1)B
X
j=iB+1
∇fσm
j (xi)


=
N
B −1
X
i=0

−η
MB
M
X
m=1
(i+1)B
X
j=iB+1
((L1xi≤0 + µ1xi>0)xi + νσm
j )


=
N
B −1
X
i=0

−η
MB
M
X
m=1
(i+1)B
X
j=iB+1
(L1xi≤0 + µ1xi>0)xi


(Since PN
j=1 σm
j = 0)
= −η
N
B −1
X
i=0
(L1xi≤0 + µ1xi>0)xi.
(127)
47

Published as a conference paper at ICLR 2022
Thus, E[x N
B −x0] = −η P N
B −1
i=0 E[(L1xi≤0 + µ1xi>0)xi]. We want to prove that E[x N
B ] keeps
increasing over an epoch, that is E[x N
B −x0] > 0 when x0 is close enough to the minimizer 0.
For this, we ﬁrst consider the case where the ﬁrst iterate x0 of the epoch satisﬁes x0 ≥0. The
x0 < 0 case will be considered later. For the case x0 ≥0, we will show that whenever x0 is small,
the expected amount of update made in the (i+1)-th iteration, E[(L1xi≤0 +µ1xi>0)xi], is negative
in the ﬁrst half of the epoch and not too big in the second half.
We use the following lemmas, proven in Appendices F.1 and F.2, respectively.
Lemma 11. For x0 ≥0, 0 ≤i ≤⌊N
2B ⌋, η ≤
B
513LN , and L
µ ≥7695,
E[(L1xi≤0 + µ1xi>0)xi] ≤6
7Lx0 −ηLν
1536
r
i
MB .
Lemma 12. For x0 ≥0, 0 ≤i ≤N
B −1, and η ≤
B
513LN ,
E[(L1xi≤0 + µ1xi>0)xi] ≤µ

1 + 513iηL
512

x0 + 513ηµν
512
r
i
MB .
The key intuition is that, for L
µ big enough, we can use the lemmas above in (127) to get
E[x N
B −x0] = −η
N
B −1
X
i=0
(L1xi≤0 + µ1xi>0)xi
≈Ω
 
η N
B ηLν
r
N/B
MB
!
,
whenever |x0| is small. Multiplying the above by K (for K epochs) will give us the required lower
bound (up to factors of L
µ ). We will make this approximate calculation precise in the rest of the
proof.
Using the two lemmas above in (127), we get that
E[x N
B −x0]
= −η
N
B −1
X
i=0
E[(L1xi≤0 + µ1xi>0)xi]
= −η
⌊N
2B ⌋
X
i=0
E[(L1xi≤0 + µ1xi>0)xi] −η
N
B −1
X
i=⌊N
2B ⌋+1
E[(L1xi≤0 + µ1xi>0)xi]
≥−η
⌊N
2B ⌋
X
i=0
 
6
7Lx0 −ηLν
1536
r
i
MB
!
−η
N
B −1
X
i=⌊N
2B ⌋+1
 
µ

1 + 513iηL
512

x0 + 513ηµν
512
r
i
MB
!
.
(128)
Since iηL ≤ηLN
B
≤
1
513, µ ≤
L
7695, and N/B ≥2, the following bound holds:
⌊N
2B ⌋
X
i=0
6
7L +
N
B −1
X
i=⌊N
2B ⌋+1
µ

1 + 513iηL
512

≤
 N
2B

+ 1
 6L
7 +
N
B −
 N
2B

−1

L
7695

1 +
1
512

≤6LN
7B +
LN
7680B ≤7LN
8B .
(129)
48

Published as a conference paper at ICLR 2022
Also, note that ⌊N
2B ⌋≥
N
3B whenever N/B ≥2. We have
⌊N
2B ⌋
X
i=0
√
i ≥
Z ⌊N
2B ⌋
0
√
tdt = 2
3
 N
2B
3/2
≥2
3
 N
3B
3/2
=
2N 3/2
9
√
3B3/2 ,
(130)
N
B −1
X
i=⌊N
2B ⌋+1
√
i ≤
Z
N
B
⌊N
2B ⌋+1
√
tdt ≤2
3
"N
B
3/2
−
 N
2B

+ 1
3/2#
≤2
3
"N
B
3/2
−
 N
2B
3/2#
= (2
√
2 −1)N 3/2
3
√
2B3/2
≤N 3/2
2B3/2 .
(131)
Substituting the bounds (129), (130), and (131) into (128), and using µ ≤
L
7695,
E[x N
B −x0] ≥−7ηLN
8B
x0 +
η2LνN 3/2
6912
√
3M 1/2B2 −513η2µνN 3/2
1024M 1/2B2
≥−7ηLN
8B
x0 +
η2LνN 3/2
56000M 1/2B2 .
(132)
For the other case x0 < 0, we have the following Lemma, which we prove in Appendix F.3:
Lemma 13. If η ≤
B
513NL and an epoch starts at x0 < 0, then
E[x N
B | x0 < 0] ≥

1 −7ηLN
8B

x0.
Further, if the ﬁrst epoch of the algorithm is initialized at 0, then for any starting iterate x0 of any
following epoch, we have P(x0 ≥0) ≥1/2.
Using (132) and Lemma 13 we get
E[x N
B ] = P(x0 ≥0)E[x N
B | x0 ≥0] + P(x0 < 0)E[x N
B | x0 < 0]
≥P(x0 ≥0)

1 −7ηLN
8B

x0 +
η2LνN 3/2
56000M 1/2B2

+ P(x0 < 0)

1 −7ηLN
8B

x0
≥

1 −7ηLN
8B

x0 +
η2LνN 3/2
112000M 1/2B2 .
Thus far, we have characterized the expected per-epoch update, starting from the initial iterate x0 and
iterating until the last iterate x N
B of the epoch. Now recall that we run the algorithm for K epochs.
Using xk,i to denote the i-th iterate of the k-th epoch, we get a lower bound on the expectation of
the last iterate xk, N
B if we initialize at x1,0 = 0:
E[xK, N
B ] ≥

1 −7ηLN
8B
K
x1,0 +
η2LνN 3/2
112000M 1/2B2
K−1
X
k=0

1 −7ηLN
8B
k
=
η2LνN 3/2
112000M 1/2B2
1 −

1 −7ηLN
8B
K
7ηLN
8B
=
ηνN 1/2
98000M 1/2B
 
1 −

1 −7ηLN
8B
K!
≥
ηνN 1/2
98000M 1/2B
 
1 −

1 −7L
8µK
K!
.
(Since η ≥
B
µNK )
Note that since L
µ ≥7695 and K ≥513L
µ
(which is implied by
B
µNK ≤η ≤
B
513LN ),
1 −

1 −7L
8µK
K
≥1 −e−7L
8µ ≥1 −e−6733 ≈1.
49

Published as a conference paper at ICLR 2022
Hence, we get from η ≥
B
µNK that
E[xK, N
B ] = Ω
ηνN 1/2
M 1/2B

= Ω

ν
µM 1/2N 1/2K

,
and by Jensen’s inequality, we ﬁnally have
E[F(xK, N
B )] ≥1
2E[µx2
K, N
B ] = Ω(µE[xK, N
B ]2) = Ω

ν2
µMNK2

.
E.3
LOWER BOUND FOR η ≥
B
µNK AND η ≥
B
513LN
Similar to earlier parts of the proof, here as well, each machine will have the same component
functions, that is, there will be no inter-machine deviation. The proof uses a similar construction as
Safran & Shamir (2020; 2021):
F3(x) := 1
N


N
2
X
i=1
f+1(x) +
N
X
i= N
2 +1
f−1(x)

, where
f+1(x) := Lx2
2
+ νx, and f−1(x) := Lx2
2
−νx.
Hence, F3(x) = Lx2
2 , and has its minimizer at 0.
We ﬁrst compute the expected “progress” over a given epoch. For simplicity, let us omit the subscript
for epochs for now. Let x0 denote the iterate at the beginning of the epoch and xi denote the iterate
after the i-th communication round in that epoch. For a given epoch, let σm be the permutation of
N
2 +1’s and N
2 −1’s, sampled by machine m. Then,
x N
B = x N
B −1 −
η
MB
M
X
m=1
N
X
j=( N
B −1)B+1
(Lx N
B −1 + νσm
j )
= (1 −ηL)x N
B −1 −ην
MB
M
X
m=1
N
X
j=( N
B −1)B+1
σm
j
= · · ·
= (1 −ηL)
N
B x0 −ην
MB
N
B
X
i=1
(1 −ηL)
N
B −i
M
X
m=1
iB
X
j=(i−1)B+1
σm
j .
For the rest of this proof, x2
i refers to the square of the i-th iterate. Then,
E[x2
N
B ] = (1 −ηL)
2N
B x2
0 −2ην(1 −ηL)
N
B x0
MB
E




N
B
X
i=1
(1 −ηL)
N
B −i
M
X
m=1
iB
X
j=(i−1)B+1
σm
j




+ η2ν2
M 2B2 E




N
B
X
i=1
(1 −ηL)
N
B −i
M
X
m=1
iB
X
j=(i−1)B+1
σm
j


2

= (1 −ηL)
2N
B x2
0 + η2ν2
M 2B2 E




N
B
X
i=1
(1 −ηL)
N
B −i
M
X
m=1
iB
X
j=(i−1)B+1
σm
j


2
,
(133)
where we used the fact that E[σm
j ] = 0. Further, because σm and σm′ are independent and identi-
cally distributed for different m and m′, we get that
E




N
B
X
i=1
(1 −ηL)
N
B −i
M
X
m=1
iB
X
j=(i−1)B+1
σm
j


2

50

Published as a conference paper at ICLR 2022
= E




M
X
m=1
N
B
X
i=1
(1 −ηL)
N
B −i
iB
X
j=(i−1)B+1
σm
j


2

=
M
X
m=1
E




N
B
X
i=1
(1 −ηL)
N
B −i
iB
X
j=(i−1)B+1
σm
j


2

+
X
m̸=m′
E


N
B
X
i=1
(1 −ηL)
N
B −i
iB
X
j=(i−1)B+1
σm
j

E


N
B
X
i=1
(1 −ηL)
N
B −i
iB
X
j=(i−1)B+1
σm′
j


= ME




N
B
X
i=1
(1 −ηL)
N
B −i
iB
X
j=(i−1)B+1
σ1
j


2
,
where the last equality used the fact that E[σm
j ] = 0 for all m ∈[M] and i ∈[N], and that σm are
identically distributed. Since we only consider the permutation σ1 (i.e., the one for machine 1) from
now on, we henceforth omit the superscript. Substituting this to (133) gives
E[x2
N
B ] = (1 −ηL)
2N
B x2
0 + η2ν2
MB2 E




N
B
X
i=1
(1 −ηL)
N
B −i
iB
X
j=(i−1)B+1
σj


2

|
{z
}
=:Φ
.
(134)
From (134), we have calculated the per-epoch expected update. Recall that we run the algorithm
for K epochs. Using xk,i to denote the i-th iterate of the k-th epoch, we get a lower bound on the
expectation of the last iterate xk, N
B squared:
E[x2
k, N
B ] = (1 −ηL)
2NK
B x2
1,0 + η2ν2
MB2 Φ
K−1
X
k=0
(1 −ηL)
2Nk
B
≥η2ν2
MB2 Φ,
(135)
where the inequality used x1,0 = 0 and PK−1
k=0 (1 −ηL)
2Nk
B
≥(1 −ηL)0 = 1. Next, we analyze
the expectation term, i.e., Φ, deﬁned in (134).
Φ := E




N
B
X
i=1
(1 −ηL)
N
B −i
iB
X
j=(i−1)B+1
σj


2

=
N
X
j=1
(1 −ηL)2( N
B −⌊j−1
B ⌋−1)σ2
j +
X
j̸=j′
(1 −ηL)
N
B −⌊j−1
B ⌋−1(1 −ηL)
N
B −⌊j′−1
B
⌋−1E[σjσj′]
Noting that σ2
j = 1 and E[σjσj′] = −
1
N−1, we get
Φ = B
N
B −1
X
j=0
(1 −ηL)2j −
1
N −1
X
j̸=j′
(1 −ηL)
N
B −⌊j−1
B ⌋−1(1 −ηL)
N
B −⌊j′−1
B
⌋−1
= B
N
B −1
X
j=0
(1 −ηL)2j −
1
N −1





N
X
j=1
(1 −ηL)
N
B −⌊j−1
B ⌋−1


2
−
N
X
j=1
(1 −ηL)2( N
B −⌊j−1
B ⌋−1)



= B
N
B −1
X
j=0
(1 −ηL)2j −
1
N −1


B2


N
B −1
X
j=0
(1 −ηL)j


2
−B
N
B −1
X
j=0
(1 −ηL)2j



=
B2
N −1


N
B
N
B −1
X
j=0
(1 −ηL)2j −


N
B −1
X
j=0
(1 −ηL)j


2


51

Published as a conference paper at ICLR 2022
= B2( N
B −1)
N −1



 
1 +
1
N
B −1
! N
B −1
X
j=0
(1 −ηL)2j −
1
N
B −1


N
B −1
X
j=0
(1 −ηL)j


2

.
(136)
Note that the term in the parenthesis is exactly the right hand side of Equation (23) in Safran &
Shamir (2020) modulo n and α replaced with N
B and ηL, respectively. Hence, by Lemma 1 of
Safran & Shamir (2020), we have
 
1 +
1
N
B −1
! N
B −1
X
j=0
(1 −ηL)2j −
1
N
B −1


N
B −1
X
j=0
(1 −ηL)j


2
≥c · min
 1
ηL, η2L2N 3
B3

,
(137)
for some universal constant c > 0. Using the fact that η ≥
B
513LN , it is easy to check that the RHS
of (137) is lower-bounded by c′
ηL, where c′ > 0 is a universal constant. Combining (135), (136), and
(137) gives
E[x2
k, N
B ] ≥η2ν2
MB2 · B2( N
B −1)
N −1
· c′
ηL = c′ην2
LMB
N −B
N −1 .
Since 2B divides N, we have B ≤N/2. Since N ≥2, we have N−B
N−1 ≥
N
2(N−1) ≥1
2. Using this
and the fact that η ≥
B
µNK , we get
E[F3(xk, N
B )] = L
2 E[x2
k, N
B ] ≥
c′ν2
4µMNK .
F
PROOFS OF HELPER LEMMAS FOR APPENDIX E
F.1
PROOF OF LEMMA 11
First, if i = 0 then the lemma trivially holds, because x0 ≥0 gives
E[(L1x0≤0 + µ1x0>0)x0] = µx0 ≤6
7Lx0.
The inequality holds because L
µ ≥7695.
For the rest of the proof, we consider the case 1 ≤i ≤
N
2B . By the law of total expectation we have
E[(L1xi≤0 + µ1xi>0)xi] = P


M
X
m=1
iB
X
j=1
σm
j > 0

E

(L1xi≤0 + µ1xi>0)xi

M
X
m=1
iB
X
j=1
σm
j > 0


+ P


M
X
m=1
iB
X
j=1
σm
j ≤0

E

(L1xi≤0 + µ1xi>0)xi

M
X
m=1
iB
X
j=1
σm
j ≤0


≤P


M
X
m=1
iB
X
j=1
σm
j > 0

LE

xi

M
X
m=1
iB
X
j=1
σm
j > 0


+ P


M
X
m=1
iB
X
j=1
σm
j ≤0

µE

xi

M
X
m=1
iB
X
j=1
σm
j ≤0

,
(138)
where the last inequality used the fact that (L1t≤0 + µ1t>0)t ≤Lt and (L1t≤0 + µ1t>0)t ≤µt for
any t ∈R.
Deﬁne E := PM
m=1
PiB
j=1 σm
j . We handle each of the two expectations in (138) separately. We ﬁrst
bound E [xi|E > 0].
E [xi|E > 0] = E

x0 −
i−1
X
j=0
η
MB
M
X
m=1
(j+1)B
X
k=jB+1
(νσm
k + (L1xj≤0 + µ1xj>0)xj)

E > 0


52

Published as a conference paper at ICLR 2022
= E

x0 −
i−1
X
j=0
η
MB
M
X
m=1
(j+1)B
X
k=jB+1
(νσm
k + (L1xj≤0 + µ1xj>0)(xj −x0))

E > 0


+ E

−
i−1
X
j=0
η
MB
M
X
m=1
(j+1)B
X
k=jB+1
(L1xj≤0 + µ1xj>0)x0

E > 0


= x0E

1 −η
i−1
X
j=0
(L1xj≤0 + µ1xj>0)

E > 0

−ην
MB E [E|E > 0]
−η
i−1
X
j=0
E

(L1xj≤0 + µ1xj>0)(xj −x0)
E > 0

≤x0E

1 −η
i−1
X
j=0
(L1xj≤0 + µ1xj>0)

E > 0

−ην
MB E [E|E > 0]
+ ηL
i−1
X
j=0
E[|xj −x0| | E > 0].
(139)
Next, we use the following lemma to bound the conditional expectations that arise in (139). This
lemma is proven in Appendix F.4 and it may be of independent interest to readers.
Lemma 14. For m ∈[M], let σm be a random permutation of N
2 +1’s and N
2 −1’s. Then, for any
i ≤N
2 and k ≤B
2 , we have
1
64
 r
i
M +
√
k
!
≤E




1
M
M
X
m=1
i
X
j=1
σm
j

+
i+k
X
j=i+1
σM
j


.
Furthermore, for any 0 ≤i ≤N and 0 ≤k ≤N satisfying i + k ≤N, we have
E




1
M
M
X
m=1
i
X
j=1
σm
j

+
i+k
X
j=i+1
σM
j


≤
r
i
M +
√
k.
Lastly, for any 0 ≤i ≤N
2 and 0 ≤k ≤B
2 satisfying i + k ≥1, we have
P


M
X
m=1
i
X
j=1
σm
j + M
i+k
X
j=i+1
σM
j
> 0

= P


M
X
m=1
i
X
j=1
σm
j + M
i+k
X
j=i+1
σM
j
< 0

≥1
6.
Lemma 14 implies that
1
M E [E|E > 0] ∈
h
1
64
q
iB
M ,
q
iB
M
i
and P(E > 0) = P(E < 0) ≥1/6. From
this, we get
ην
MB E [E|E > 0] ≥ην
64
r
i
MB ,
(140)
E[|xj −x0| | E > 0] ≤E[|xj −x0|]
P(E > 0)
≤6E[|xj −x0|].
(141)
Also, since η ≤
B
LN we have
1 −iηµ ≥1 −η
i−1
X
j=0
(L1xj≤0 + µ1xj>0) ≥1 −ηLN
B
≥0,
which implies that
x0E

1 −η
i−1
X
j=0
(L1xj≤0 + µ1xj>0)

E > 0

≤(1 −iηµ)x0.
(142)
53

Published as a conference paper at ICLR 2022
Substituting (140), (141), and (142) to (139), we obtain
E [xi|E > 0] ≤(1 −iηµ)x0 −ην
64
r
i
MB + 6ηL
i−1
X
j=0
E[|xj −x0|].
(143)
Next, we have the following lemma that we can apply to E[|xj −x0|]. Proof of Lemma 15 can be
found in Appendix F.5.
Lemma 15. For x0 ≥0, 0 ≤i ≤N
B −1 and η ≤
B
513LN ,
E[|xi −x0|] ≤513
512ην
r
i
MB + 513
512iηLx0.
Applying this lemma to (143), we get
E [xi|E > 0] ≤(1 −iηµ)x0 −ην
64
r
i
MB + 1539η2Lν
256
√
MB
i−1
X
j=0
p
j + 1539η2L2x0
256
i−1
X
j=0
j
≤(1 −iηµ)x0 −ην
64
r
i
MB + 513i3/2η2Lν
128
√
MB
+ 1539i2η2L2
512
x0
=

1 −iηµ + 1539i2η2L2
512

x0 −
 1
64 −513iηL
128

ην
r
i
MB
≤

1 −iηµ + 3iηL
512

x0 −ην
128
r
i
MB .
(144)
where we got the last inequality by using the fact that iηL ≤
ηLN
B
≤
1
513, which follows from
η ≤
B
513LN . So far, we have obtained an upper bound for E [xi|E > 0].
Recall that there is another conditional expectation in (138) that we want to bound, namely
E [xi|E ≤0]. We bound it below, using the tools developed so far. For i ≤
N
2B ,
E [xi|E ≤0] = x0 + E [xi −x0 | E ≤0]
≤x0 + E [|xi −x0| | E ≤0]
≤x0 + E [|xi −x0|]
P(E ≤0)
≤x0 + 6E [|xi −x0|]
(Using Lemma 14)
≤x0 + 1539ην
256
r
i
MB + 1539iηLx0
256
(Using Lemma 15)
≤

1 + 1539iηL
256

x0 + 1539ην
256
r
i
MB
(145)
Using (144) and (145) in (138), we get that for i ≤
N
2B :
E[(L1xi≤0 + µ1xi>0)xi]
≤P (E > 0) LE [xi|E > 0] + P (E ≤0) µE [xi|E ≤0]
≤P (E > 0) L
 
1 −iηµ + 3iηL
512

x0 −ην
128
r
i
MB
!
+ P (E ≤0) µ
 
1 + 1539iηL
256

x0 + 1539ην
256
r
i
MB
!
.
(146)
From Lemma 14, note that 1
6 ≤P (E > 0) ≤5
6 and 1
6 ≤P (E ≤0) ≤5
6. We use these inequalities,
along with iηL ≤ηLN
B
≤
1
513 and L
µ ≥7695, to bound the terms appearing in (146).
P (E > 0) L

1 −iηµ + 3iηL
512

x0 + P (E ≤0) µ

1 + 1539iηL
256

x0
54

Published as a conference paper at ICLR 2022
≤5
6L

1 +
1
87552

x0 + 5
6 ·
L
7695

1 +
3
256

x0 ≤6
7Lx0.
(147)
We also have
−P (E > 0) ηLν
128
r
i
MB + P (E ≤0) 1539ηµν
256
r
i
MB
≤−ηLν
768
r
i
MB + 2565ηµν
512
r
i
MB
≤−ηLν
1536
r
i
MB ,
(148)
where we used the assumption L
µ ≥7695. Substituting (147) and (148) to (146), we get
E[(L1xi≤0 + µ1xi>0)xi] ≤6
7Lx0 −ηLν
1536
r
i
MB ,
as desired.
F.2
PROOF OF LEMMA 12
E[(L1xi≤0 + µ1xi>0)xi] ≤µE[xi]
= µx0 + µE[xi −x0]
≤µx0 + µE[|xi −x0|]
≤µx0 + 513
512iηLµx0 + 513
512ηµν
r
i
MB .
(Using Lemma 15)
F.3
PROOF OF LEMMA 13
We consider iterates within a single epoch, and hence we will omit the subscripts denoting epochs.
In our construction, each machine has the same set of component functions, that is, there will be no
inter-machine deviation. We therefore omit the superscript m from the local component functions.
Consider the function
G2(x) := 1
N


N
2
X
i=1
g+1(x) +
N
X
i= N
2 +1
g−1(x)

, where
g+1(x) := Lx2
2
+ νx, and g−1(x) := Lx2
2
−νx.
Hence, G2(x) = Lx2
2 . We will prove the lemma by coupling iterates corresponding to F2 and G2.
In particular, we will perform minibatch RR on F2 and G2 such that both start the given epoch at x0
and all the corresponding machines use the same random permutations. Let xi,F be the iterate after
the i-th round of communication for F2 and xi,G be the iterate after the i-th round of communication
for G2. We use mathematical induction to prove that xi,F ≥xi,G for all i = 0, . . . , N
B . After that,
we will use this to prove our desired statement E[x N
B ,F | x0 < 0] ≥(1 −7ηLN
8B )x0. Let σm be a
random permutation of N
2 +1’s and N
2 −1’s.
Base case.
x0,F ≥x0,G since both start the epoch at the same point x0.
Inductive case.
There can be three cases:
• Case 1: xi,F ≥xi,G ≥0. Then,
xi+1,F −xi+1,G = xi,F −xi,G −
η
MB
M
X
m=1
(i+1)B
X
j=iB+1
(∇fσm
j (xi,F ) −∇gσm
j (xi,G))
55

Published as a conference paper at ICLR 2022
= xi,F −xi,G −
η
MB
M
X
m=1
(i+1)B
X
j=iB+1
 µxi,F + νσm
j −Lxi,G −νσm
j

= xi,F −xi,G −η (µxi,F −Lxi,G)
= xi,F (1 −ηµ) −xi,G(1 −ηL)
≥0.
• Case 2: 0 ≥xi,F ≥xi,G. Then,
xi+1,F −xi+1,G = xi,F −xi,G −
η
MB
M
X
m=1
(i+1)B
X
j=iB+1
(∇fσm
j (xi,F ) −∇gσm
j (xi,G))
= xi,F −xi,G −
η
MB
M
X
m=1
(i+1)B
X
j=iB+1
 Lxi,F + νσm
j −Lxi,G −νσm
j

= xi,F −xi,G −η (Lxi,F −Lxi,G)
= xi,F (1 −ηL) −xi,G(1 −ηL)
≥0.
• Case 3: xi,F ≥0 ≥xi,G. Then,
xi+1,F −xi+1,G = xi,F −xi,G −
η
MB
M
X
m=1
(i+1)B
X
j=iB+1
(∇fσm
j (xi,F ) −∇gσm
j (xi,G))
= xi,F −xi,G −
η
MB
M
X
m=1
(i+1)B
X
j=iB+1
 µxi,F + νσm
j −Lxi,G −νσm
j

= xi,F −xi,G −η (µxi,F −Lxi,G)
= xi,F (1 −ηµ) −xi,G(1 −ηL).
Note that since η ≤
B
LN , xi,F (1 −ηµ) ≥0 and xi,G(1 −ηL) ≤0, which proves that
xi+1,F −xi+1,G ≥0.
Thus, we see that xi+1,F ≥xi+1,G. Further, by linearity of expectation and gradient, it is easy to
check that
E[x N
B ,G] = E[x N
B −1,G −η∇G2(x N
B −1,G)]
= (1 −ηL)E[x N
B −1,G]
= · · ·
= (1 −ηL)
N
B x0.
Using the result that x N
B ,F ≥x N
B ,G which we proved above, we get E[x N
B ,F ] ≥(1 −ηL)
N
B x0 for
any initial iterate x0. Speciﬁcally for x0 < 0, this implies E[x N
B ,F | x0 < 0] ≥(1 −ηL)
N
B x0.
Further, since ηL ≤
B
513N , we have (1 −ηL)
N
B ≤1 −7ηLN
8B . This is because 1 −7zN
8B −(1 −z)
N
B
is nonnegative on the interval
h
0, 1 −(7/8)
1
N/B−1
i
, and 1 −(7/8)
1
N/B−1 ≥
B
513N for all N
B ≥2. To
see why, note that (1 −
1
513(n−1))n−1 ≥7
8 for all n ≥2, and this gives 1 −(7/8)
1
n−1 ≥
1
513(n−1),
which then implies 1 −(7/8)
1
n−1 ≥
1
513n for all n ≥2. Therefore, for x0 < 0, we have E[x N
B ,F |
x0 < 0] ≥(1 −7ηLN
8B )x0.
For the last statement of the lemma, note that by symmetry of the function G2, if we initialize the
Algorithm 2 at 0, then for any starting iterate of an epoch we have P(x0,G ≥0) ≥1/2. This
combined with the fact that xi,F ≥xi,G gives us that P(x0,F ≥0) ≥1/2.
56

Published as a conference paper at ICLR 2022
F.4
PROOF OF LEMMA 14
For m = 1, . . . , M, let σm be a random permutation of N
2 +1’s and N
2 −1’s. Then, we ﬁrst show
that for any i ≤N/2 and k ≤B/2,
1
64
 r
i
M +
√
k
!
≤E




1
M
M
X
m=1
i
X
j=1
σm
j

+
i+k
X
j=i+1
σM
j


.
To prove the lower bound, we will use Khintchine’s inequality along with Lemma 12 from Rajput
et al. (2020). Let us deﬁne random variables am := | 1
M
Pi
j=1 σm
j |, xm := sign(Pi
j=1 σm
j ), bM :=
| Pi+k
j=i+1 σM
j |, and yM := sign(Pi+k
j=i+1 σM
j ). For xm, if the sum Pi
j=1 σm
j
= 0 then xm is +1
with probability 0.5 and −1 with probability 0.5. Ties occurring in yM are also broken similarly.
We can note that xm’s and yM are i.i.d. Rademacher random variables, which allows us to apply
Khintchine’s inequality, Then, by Khintchine’s inequality,
E




1
M
M
X
m=1
i
X
j=1
σm
j

+
i+k
X
j=i+1
σM
j


= E
"
M
X
m=1
amxm + bMyM

#
≥
1
√
2E


 M
X
m=1
a2
m + b2
M
!1/2
.
By applying ∥z∥2 ≥
1
√
d∥z∥1 for z ∈Rd twice, we get
1
√
2E


 M
X
m=1
a2
m + b2
M
!1/2
≥1
2E


 M
X
m=1
a2
m
!1/2
+ bM

≥1
2E
"
1
√
M
M
X
m=1
am + bM
#
.
Next, noticing that am’s are i.i.d.,
1
2E
"
1
√
M
M
X
m=1
am + bM
#
= 1
2E
h√
MaM + bM
i
= 1
2E


1
√
M

i
X
j=1
σM
j

+

i+k
X
j=i+1
σM
j



≥1
64
 r
i
M +
√
k
!
.
(Lemma 12 from Rajput et al. (2020))
Note that Lemma 12 from Rajput et al. (2020) has the requirement that N ≥256. However, that
requirement is for the entire lemma to hold, whereas we need only the ﬁrst inequality in the lemma.
For that, the requirement is simply N ≥8. Further, note that for N = 2, 4, and 6 it can be manually
veriﬁed that the required inequalities in Lemma 12 of Rajput et al. (2020) hold. Hence, this lemma
holds for all even N.
The upper bound comes from Jensen’s inequality:
E




1
M
M
X
m=1
i
X
j=1
σm
j

+
i+k
X
j=i+1
σM
j


≤1
M E



M
X
m=1
i
X
j=1
σm
j


+ E



i+k
X
j=i+1
σM
j



≤1
M
v
u
u
u
u
tE




M
X
m=1
i
X
j=1
σm
j


2
+
v
u
u
u
u
tE




i+k
X
j=i+1
σM
j


2

= 1
M
v
u
u
u
u
t
M
X
m=1
E




i
X
j=1
σm
j


2
+
v
u
u
u
u
tE




i+k
X
j=i+1
σM
j


2

(Since Pi
j=1 σm
j for m = 1, 2 . . . are mean 0 and independent.)
57

Published as a conference paper at ICLR 2022
=
v
u
u
u
u
t
1
M E




i
X
j=1
σM
j


2
+
v
u
u
u
u
tE




i+k
X
j=i+1
σM
j


2

=
v
u
u
u
t 1
M

i +
X
j̸=l
E[σM
j σM
l ]

+
s
k +
X
j̸=l
E[σM
j σM
l ].
E[σM
j σM
l ] ≤0 because σM
j
and σM
l
are negatively correlated. Hence, we get
E




1
M
M
X
m=1
i
X
j=1
σm
j

+
i+k
X
j=i+1
σM
j


≤
r
i
M +
√
k,
as desired.
Next, it is left to show that for 0 ≤i ≤N
2 and 0 ≤k ≤B
2 satisfying i + k ≥1, we have
P


M
X
m=1
i
X
j=1
σm
j + M
i+k
X
j=i+1
σM
j
> 0

= P


M
X
m=1
i
X
j=1
σm
j + M
i+k
X
j=i+1
σM
j
< 0

≥1
6.
By symmetry, proving the equality is straightforward, and hence it is sufﬁcient prove that
P


M
X
m=1
i
X
j=1
σm
j + M
i+k
X
j=i+1
σM
j
= 0

≤2
3.
(149)
For this, it in fact sufﬁces to show that
P


l
X
j=1
σ1
j = 0

≤2
3 for all 1 ≤l ≤N −1,
(150)
because (149) can be derived from (150). We ﬁrst explain why (150) implies (149), and then show
(150).
Suppose (150) is true. Then,
• Case 1: If i = 0, then (149) becomes P(Pk
j=1 σM
j
= 0) ≤2
3, which is true due to (150).
• Case 2: If M = 1, then (149) becomes P(Pi+k
j=1 σ1
j = 0) ≤2
3, which is true due to (150).
• Case 3: If i ≥1 and M ≥2, then we can consider two events that partition the probability
space:
1. E1 := {PM
m=2
Pi
j=1 σm
j + M Pi+k
j=i+1 σM
j
= 0}. Conditioned on this event E1,
P


M
X
m=1
i
X
j=1
σm
j + M
i+k
X
j=i+1
σM
j
= 0 | E1

= P


i
X
j=1
σ1
j = 0

≤2
3
due to independence of machines and (150).
2. E2 := {PM
m=2
Pi
j=1 σm
j + M Pi+k
j=i+1 σM
j
̸= 0}. Conditioned on this event E2, let
c := PM
m=2
Pi
j=1 σm
j + M Pi+k
j=i+1 σM
j . Then,
P


M
X
m=1
i
X
j=1
σm
j + M
i+1
X
j=i+1
σM
j
= 0 | E2

= P


i
X
j=1
σ1
j = −c

.
However, by symmetry, P
Pi
j=1 σ1
j = −c

= P
Pi
j=1 σ1
j = c

≤1
2.
58

Published as a conference paper at ICLR 2022
From these two events, we conclude that (149) must hold.
It is now left to prove (150). It is clear that P(Pi
j=1 σ1
j = 0) = 0 for all odd i, so we assume that
i is even. Also note that P(Pi
j=1 σ1
j = 0) = P(PN
j=i+1 σ1
j = 0) = P(PN−i
j=1 σ1
j = 0), since σ1
j ’s
sum to zero. Therefore, for the rest of the proof, we can focus on even i’s in the range 2 ≤i ≤N
2 .
Note that P(Pi
j=1 σm
j
= 0) is just the probability of having i
2 +1’s and i
2 −1’s in the ﬁrst i spots
in a random shufﬂing of N
2 +1’s and N
2 −1’s. This is equivalent to choosing i
2 indices (for +1) out
of the ﬁrst i, and then choosing N−i
2
indices out of the remaining N −i. Thus,
P


i
X
j=1
σm
j = 0

=
  i
i/2

·
 N−i
N−i
2

  N
N/2

.
Note that the term above is a decreasing function of i for i ≤N/2. Hence, putting i = 2 to the RHS
we get
P


i
X
j=1
σm
j = 0

≤
 2
1

·
 N−2
N−2
2

  N
N/2

=
N
2(N −1) ≤2
3,
where the inequality holds for N ≥4.
F.5
PROOF OF LEMMA 15
E[|xi −x0|] = E



η
MB
i−1
X
j=0
M
X
m=1
(j+1)B
X
k=jB+1
νσm
k + (L1xj<0 + µ1xj≥0)xj



≤ην
B
r
iB
M + ηE



i−1
X
j=0
(L1xj<0 + µ1xj≥0)xj



(By Lemma 14)
≤ην
r
i
MB + ηL
i−1
X
j=0
E[|xj|]
≤ην
r
i
MB + iηLx0 + ηL
i−1
X
j=0
E[|xj −x0|].
Let h(i) := ην
q
i
MB + iηLx0 + ηL Pi−1
j=0 h(j), starting with h(0) = 0. Then using induction, it
can be seen that E[|xi −x0|] ≤h(i). Further, since h(i) is an increasing function of i, we get
h(i) ≤
ην
q
i
MB + iηLx0
1 −iηL
.
Since i ≤N
B and η ≤
B
513LN , we get that
1
1−iηL ≤513
512, so E[|xi−x0|] ≤513
512ην
q
i
MB + 513
512iηLx0.
G
PROOF OF LOWER BOUND FOR LOCAL RR: HOMOGENEOUS CASE
(THEOREM 4)
Recall that Theorem 4 gives the bound for local RR in the homogeneous setting, where all machines
have the same local objectives. Similar to Theorem 3, we consider three step-size ranges and do case
analysis for each of them. We construct functions for each corresponding step-size regime such that
the convergence of local RR is “slow” for the functions on their corresponding step-size regime. The
ﬁnal lower bound is the minimum among the lower bounds obtained for the three regimes. More
concretely, we will construct three one-dimensional functions F1(x), F2(x), and F3(x) satisfying
L-smoothness (1), µ-PŁ condition (2), and Assumption 2 such that15
15Again, the functions constructed in this theorem are µ-strongly convex, which is stronger than µ-PL re-
quired in Deﬁnition 1. Also, our functions satisfy Assumption 3 with τ = 0, ρ = 1.
59

Published as a conference paper at ICLR 2022
• Local RR on F1(x) with η ≤
1
µNK and initialization y0 = ν
µ results in
E[F1(yK, N
B )] = Ω
ν2
µ

.
• Local RR on F2(x) with η ≥
1
µNK and η ≤
1
1025LN and initialization y0 = 0 results in
E[F2(yK, N
B )] = Ω

ν2
µMNK2 +
ν2B
µN 2K2

.
Note that the step-size range requires K ≥1025κ, hence this lower bound occurs only in
the “large-epoch” regime, i.e., K ≳κ.
• Local RR on F3(x) with η ≥
1
µNK and η ≥
1
1025LN and initialization y0 = 0 results in
E[F3(yK, N
B )] = Ω

ν2
µMNK

.
Then, the three dimensional function F([x, y, z]⊤) = F1(x) + F2(y) + F3(z) will show bad con-
vergence in any step-size regime. Furthermore,
µI ⪯min(∇2F1, ∇2F2, ∇2F3)I ⪯∇2F ⪯max(∇2F1, ∇2F2, ∇2F3)I ⪯LI,
that is, if F1, F2 and F3 are µ-strongly convex and L-smooth, then so is F. Moreover, since the
component functions in each coordinate are designed to satisfy Assumption 2 with ν, the resulting
three dimensional function F also satisﬁes Assumption 2 with
√
3ν.
Since the ﬁnal lower bound is the minimum among the lower bounds obtained in the step-size ranges,
the lower bound becomes Ω

ν2
µMNK2 +
ν2B
µN2K2

if K ≥1025κ and K ≥MB
N
(this inequality is
required to make sure
ν2B
µN2K2 ≤
ν2
µMNK ) and Ω

ν2
µMNK

otherwise.
In the subsequent subsections, we prove the lower bounds for F1, F2, and F3 separately.
G.1
LOWER BOUND FOR η ≤
1
µNK
Consider the case where every function at every machine is the same: for all i ∈[N] and m ∈[M],
f m
i (x) := µx2
2 . Hence, F1(x) = µx2
2 .
Since all f m
i ’s are the same, the local updates in all the machines are identical. Hence, for this
subsection we omit the superscript for local machines. Let xk,0 and xk,N denote the local iterates at
the beginning and end of the k-th epoch. Then,
xk,N = (1 −ηµ)Nxk,0.
Initializing at x1,0 = ν
µ and repeating this for K epochs, we get that after K epochs, the last iterate
yK, N
B = xK,N satisﬁes
yK, N
B = xK,N = (1 −ηµ)NK · ν
µ ≥

1 −
1
NK
NK
· ν
µ ≥ν
4µ,
since N ≥2, and K ≥1. Hence, F1(yK, N
B ) = Ω( ν2
µ ).
G.2
LOWER BOUND FOR η ≥
1
µNK AND η ≤
1
1025LN
For most part of this subsection, we consider iterates within a single epoch, and hence we will
omit the subscripts denoting epochs. Let x0 denote the iterate at the beginning of the epoch (which
is the same across all the machines), and xm
i
denote the i-th local iterate for machine m. After
every B local iterates, the server aggregates the local iterates xm
iB, computes their average yi :=
1
M
PM
m=1 xm
iB, and synchronizes all the machines xm
iB := yi.
60

Published as a conference paper at ICLR 2022
Let y0 denote the iterate at the beginning of the epoch (which is the same across all the machines
xm
0 = y0), and xm
i denote the i-th local iterate at machine m. In our construction, each machine
will have the same set of component functions, that is, there will be no inter-machine deviation. We
therefore omit the superscript m from the local component functions f m
i . The function we construct
for the lower bound and its component functions are as follows:
F2(x) := 1
N


N
2
X
i=1
f+1(x) +
N
X
i= N
2 +1
f−1(x)

, where
f+1(x) := (L1x≤0 + µ1x>0)x2
2 + νx, and
f−1(x) := (L1x≤0 + µ1x>0)x2
2 −νx
Note that the function F2(x) = (L1x≤0 + µ1x>0) x2
2 is µ-strongly convex and L-smooth with
minimizer at 0, and also satisﬁes Assumption 2.
Let σm be a random permutation of N
2 +1’s and N
2 −1’s. Then, machine m computes gradients on
f−1 and f+1 in the order given by σm. Let σm
j denote the j-th ordered element of σm. Then,
∇fσm
j (x) = (L1x≤0 + µ1x>0)x + νσm
j .
Hence, the last iterate of an epoch, y N
B , is given by
y N
B −y0 =
N
B −1
X
i=0

−η
M
M
X
m=1
B−1
X
j=0
∇fσm
iB+j+1(xm
iB+j)


= −η
M
N
B −1
X
i=0
M
X
m=1
B−1
X
j=0
((L1xm
iB+j≤0 + µ1xm
iB+j>0)xm
iB+j + νσm
iB+j+1)
= −η
M
N
B −1
X
i=0
M
X
m=1
B−1
X
j=0
(L1xm
iB+j≤0 + µ1xm
iB+j>0)xm
iB+j,
where, in the last line, we used the fact that PN
j=1 σm
j = 0.
Recall that in the construction, each machine has the same component functions. Hence,
E[y N
B −y0] = −η
M E


N
B −1
X
i=0
M
X
m=1
B−1
X
j=0
(L1xm
iB+j≤0 + µ1xm
iB+j>0)xm
iB+j


= −η
N
B −1
X
i=0
B−1
X
j=0
E
h
(L1x1
iB+j≤0 + µ1x1
iB+j>0)x1
iB+j
i
,
(151)
where the last equality holds because the iterates xm
iB+j are identically distributed across different
m ∈[M]. Hence, we need to bound E[(L1x1
iB+j≤0 + µ1x1
iB+j>0)x1
iB+j]. As we did for Theorem 3,
we want to prove that E[y N
B ] keeps increasing over an epoch, that is E[y N
B −y0] > 0 when y0 is
close enough to the minimizer 0.
For this, we ﬁrst consider the case where the ﬁrst iterate y0 of the epoch satisﬁes y0 ≥0. The
y0 < 0 case will be considered later. For the case y0 ≥0, we will show that whenever y0 is small, the
expected amount of update made in the (iB+j+1)-th iteration, E[(L1x1
iB+j≤0+µ1x1
iB+j>0)x1
iB+j],
is negative if i ≤⌊N
2B ⌋and B
4 ≤j ≤B
2 , and not too big otherwise.
We use the following lemmas, proven in Appendices H.1 and H.2, respectively.
Lemma 16. For y0 ≥0, 0 ≤i ≤⌊N
2B ⌋, B
4 ≤j ≤B
2 , η ≤
1
1025LN , and L
µ ≥15375
2
,
E[(L1x1
iB+j≤0 + µ1x1
iB+j>0)x1
iB+j] ≤6
7Ly0 −ηLν
1536
 r
iB
M +
p
j
!
.
61

Published as a conference paper at ICLR 2022
Lemma 17. For y0 ≥0, 0 ≤i ≤N
B −1, 0 ≤j ≤B −1, and η ≤
1
1025LN ,
E[(L1x1
iB+j≤0 + µ1x1
iB+j>0)x1
iB+j] ≤µ

1+ 1025(iB + j)ηL
1024

y0+ 1025ηµν
1024
 r
iB
M +
p
j
!
.
Next, we apply the two lemmas above in (151). For now, we consider the case N/B ≥2. The case
B = N will be handled separately at the end of this subsection. For simplicity of notation, deﬁne
EiB+j := E[(L1x1
iB+j≤0 + µ1x1
iB+j>0)x1
iB+j]. We will divide the summation in (151) into four
groups; for one of them we can apply Lemma 16, and for the other three we apply Lemma 17.
E[y N
B −y0] = −η
N
B −1
X
i=0
B−1
X
j=0
EiB+j
= −η


⌊N
2B ⌋
X
i=0
B
4 −1
X
j=0
EiB+j +
⌊N
2B ⌋
X
i=0
B
2
X
j= B
4
EiB+j +
⌊N
2B ⌋
X
i=0
B−1
X
j= B
2 +1
EiB+j +
N
B −1
X
i=⌊N
2B ⌋+1
B−1
X
j=0
EiB+j


≥−η
⌊N
2B ⌋
X
i=0
B
4 −1
X
j=0
 
µ

1 + 1025(iB + j)ηL
1024

y0 + 1025ηµν
1024
 r
iB
M +
p
j
!!
−η
⌊N
2B ⌋
X
i=0
B
2
X
j= B
4
 
6
7Ly0 −ηLν
1536
 r
iB
M +
p
j
!!
−η
⌊N
2B ⌋
X
i=0
B−1
X
j= B
2 +1
 
µ

1 + 1025(iB + j)ηL
1024

y0 + 1025ηµν
1024
 r
iB
M +
p
j
!!
−η
N
B −1
X
i=⌊N
2B ⌋+1
B−1
X
j=0
 
µ

1 + 1025(iB + j)ηL
1024

y0 + 1025ηµν
1024
 r
iB
M +
p
j
!!
≥−η
⌊N
2B ⌋
X
i=0
B
2
X
j= B
4
 
6
7Ly0 −ηLν
1536
 r
iB
M +
p
j
!!
−η
N
B −1
X
i=0
B−1
X
j=0
 
µ

1 + 1025(iB + j)ηL
1024

y0 + 1025ηµν
1024
 r
iB
M +
p
j
!!
,
(152)
where the last inequality is true because the RHS of the inequality in Lemma 17 is nonnegative.
First consider the terms in (152) that involve y0. Since (iB + j)ηL ≤ηLN ≤
1
1025, µ ≤
2L
15375,
N/B ≥2, and B ≥4, we have the following loose bound:
⌊N
2B ⌋
X
i=0
B
2
X
j= B
4
6
7L +
N
B −1
X
i=0
B−1
X
j=0
µ

1 + 1025(iB + j)ηL
1024

≤
 N
2B

+ 1
 B
4 + 1
 6
7L + N
B · B ·
2L
15375

1 +
1
1024

≤N
B · B
2 · 6
7L + LN
7680 ≤7LN
8
.
(153)
We next bound the terms in (152) that involve summation of square roots. From N/B ≥2, we have
⌊N
2B ⌋≥
N
3B and ⌊N
2B ⌋+ 1 ≥
N
2B , so
⌊N
2B ⌋
X
i=0
B
2
X
j= B
4
 r
iB
M +
p
j
!
=
B
4 + 1
 r
B
M
⌊N
2B ⌋
X
i=0
√
i +
 N
2B

+ 1

B
2
X
j= B
4
p
j
62

Published as a conference paper at ICLR 2022
≥B3/2
4M 1/2
Z ⌊N
2B ⌋
0
√
tdt + N
2B
Z
B
2
B
4 −1
√
tdt
≥B3/2
6M 1/2
 N
3B
3/2
+ N
3B
"B
2
3/2
−
B
4
3/2#
=
N 3/2
18
√
3M 1/2 + (2
√
2 −1)NB1/2
24
.
(154)
For the other sum, we have
N
B −1
X
i=0
B−1
X
j=0
 r
iB
M +
p
j
!
= B3/2
M 1/2
N
B −1
X
i=0
√
i + N
B
B−1
X
j=0
p
j
≤B3/2
M 1/2
Z
N
B
0
√
tdt + N
B
Z B
0
√
tdt
= 2B3/2
3M 1/2
N
B
3/2
+ 2N
3B B3/2
= 2N 3/2
3M 1/2 + 2NB1/2
3
.
(155)
Substituting the bounds (153), (154), and (155) into (152), and using µ ≤
L
40000,
E[y N
B −y0] ≥−7ηLN
8
y0 + η2Lν
1536
 
N 3/2
18
√
3M 1/2 + (2
√
2 −1)NB1/2
24
!
−1025η2µν
1024
 2N 3/2
3M 1/2 + 2NB1/2
3

≥−7ηLN
8
y0 + η2Lν
240000
 N 3/2
M 1/2 + NB1/2

.
(156)
For the other case y0 < 0, we have the following lemma, a local RR counterpart of Lemma 13. In
Appendix H.3, we prove the following:
Lemma 18. If η ≤
1
1025LN and an epoch starts at y0 < 0, then
E
h
y N
B | y0 < 0
i
≥

1 −7ηLN
8

y0.
Further, if the ﬁrst epoch of the algorithm is initialized at 0, then for any starting iterate y0 of any
following epoch, we have P(y0 ≥0) ≥1/2.
Using (156) and Lemma 18, we get
E[y N
B ]
= P(y0 ≥0)E[y N
B | y0 ≥0] + P(y0 < 0)E[y N
B | y0 < 0]
≥P(y0 ≥0)

1 −7ηLN
8

y0 + η2Lν
240000
 N 3/2
M 1/2 + NB1/2

+ P(y0 < 0)

1 −7ηLN
8

y0
≥

1 −7ηLN
8

y0 + η2Lν
480000
 N 3/2
M 1/2 + NB1/2

.
Thus far, we have characterized the expected per-epoch update, starting from the initial iterate y0
and iterating until the last iterate y N
B of the epoch. Now recall that we run the algorithm for K
epochs. Using yk,i to denote the i-th aggregated iterate of the k-th epoch, we get a lower bound on
the expectation of the last iterate yk, N
B if we initialize at y1,0 = 0:
E[yK, N
B ] ≥

1 −7ηLN
8
K
y1,0 + η2Lν
480000
 N 3/2
M 1/2 + NB1/2
 K−1
X
k=0

1 −7ηLN
8
k
63

Published as a conference paper at ICLR 2022
= η2Lν
480000
 N 3/2
M 1/2 + NB1/2
 1 −

1 −7ηLN
8
K
7ηLN
8
=
ην
420000
 N 1/2
M 1/2 + B1/2
  
1 −

1 −7ηLN
8
K!
≥
ην
420000
 N 1/2
M 1/2 + B1/2
  
1 −

1 −7L
8µK
K!
.
(Since η ≥
1
µNK )
Note that since L
µ ≥40000 and K ≥1025L
µ
(which is implied by
1
µNK ≤η ≤
1
1025LN ),
1 −

1 −7L
8µK
K
≥1 −e−7L
8µ ≥1 −e−35000 ≈1.
Hence, we get from η ≥
1
µNK that
E[yK, N
B ] = Ω
ηνN 1/2
M 1/2
+ ηνB1/2

= Ω

ν
µM 1/2N 1/2K + νB1/2
µNK

,
and by Jensen’s inequality, we ﬁnally have
E[F(yK, N
B )] ≥1
2E[µy2
K, N
B ] = Ω(µE[yK, N
B ]2) = Ω

ν2
µMNK2 +
ν2B
µN 2K2

.
Recall that, from the paragraph below Lemmas 16 and 17 to this point, we have assumed N/B ≥2.
We handle the case B = N now. In this case, notice that all the
q
iB
M terms that appear in (152)
disappear, because we always have i = 0. Therefore, the proof goes through in the same why,
modulo the fact that we do not have the terms that originate from the
q
iB
M terms in (152). Therefore,
we can show
E[F(yK, N
B )] ≥1
2E[µy2
K, N
B ] = Ω(µE[yK, N
B ]2) = Ω

ν2
µNK2

.
G.3
LOWER BOUND FOR η ≥
1
µNK AND η ≥
1
1025LN
Similar to earlier parts of the proof, here as well, each machine will have the same component
functions, that is, there will be no inter-machine deviation. The proof uses a similar construction as
Safran & Shamir (2020; 2021):
F3(x) := 1
N


N
2
X
i=1
f+1(x) +
N
X
i= N
2 +1
f−1(x)

, where
f+1(x) := Lx2
2
+ νx, and f−1(x) := Lx2
2
−νx.
Hence, F3(x) = Lx2
2 , and has its minimizer at 0.
We ﬁrst compute the expected “progress” over a given epoch. For simplicity, let us omit the subscript
for epochs for now. Let y0 denote the iterate at the beginning of the epoch (which is the same across
all the machines xm
0 = y0) and xm
i denote the i-th local iterate for machine m. After every B local
iterates, the server aggregates the local iterates xm
iB, computes their average yi :=
1
M
PM
m=1 xm
iB,
and synchronizes all the machines xm
iB := yi.
For the epoch, let σm be the permutation of N
2 +1’s and N
2 −1’s sampled by machine m. Upon
receiving the aggregated iterate xm
iB = yi, each machine m performs B local updates. Unrolling
the local update rules, the iterate after the B updates (and before synchronization) can be written as
follows:
xm
(i+1)B = xm
(i+1)B−1 −η∇fσm
(i+1)B(xm
(i+1)B−1)
64

Published as a conference paper at ICLR 2022
= xm
(i+1)B−1 −η(Lxm
(i+1)B−1 + νσm
(i+1)B)
= (1 −ηL)xm
(i+1)B−1 −ηνσm
(i+1)B
= · · ·
= (1 −ηL)Bxm
iB −ην
(i+1)B
X
j=iB+1
(1 −ηL)(i+1)B−jσm
j
= (1 −ηL)Byi −ην
(i+1)B
X
j=iB+1
(1 −ηL)(i+1)B−jσm
j ,
After synchronization, we get
yi+1 := 1
M
M
X
m=1
xm
(i+1)B = (1 −ηL)Byi −ην
M
M
X
m=1
(i+1)B
X
j=iB+1
(1 −ηL)(i+1)B−jσm
j .
Unrolling the equation above from y N
B (the ﬁnal iterate of the epoch, after synchronization) to y0
(the starting iterate), we get
y N
B = (1 −ηL)By N
B −1 −ην
M
M
X
m=1
N
X
j=N−B+1
(1 −ηL)N−jσm
j
= · · ·
= (1 −ηL)Ny0 −
N
B
X
i=1
(1 −ηL)N−iB ην
M
M
X
m=1
iB
X
j=(i−1)B+1
(1 −ηL)iB−jσm
j
= (1 −ηL)Ny0 −ην
M
M
X
m=1
N
X
j=1
(1 −ηL)N−jσm
j .
Then, by squaring both sides and taking expectations,
E[y2
N
B ] = (1 −ηL)2Ny2
0 −2ην(1 −ηL)Nx0
M
E
" M
X
m=1
N
X
i=1
(1 −ηL)N−iσm
i
#
+ η2ν2
M 2 E


 M
X
m=1
N
X
i=1
(1 −ηL)N−iσm
i
!2

= (1 −ηL)2Ny2
0 + η2ν2
M 2 E


 M
X
m=1
N
X
i=1
(1 −ηL)N−iσm
i
!2
,
(157)
where we used the fact that E[σm
i ] = 0. Further, because σm and σm′ are independent‘ and identi-
cally distributed for different m and m′, we get that
E


 
ην
M
M
X
m=1
N
X
i=1
(1 −ηL)N−iσm
i
!2

=
M
X
m=1
E


 N
X
i=1
(1 −ηL)N−iσm
i
!2
+
X
m̸=m′
E
" N
X
i=1
(1 −ηL)N−iσm
i
#
E
" N
X
i=1
(1 −ηL)N−iσm′
i
#
= ME


 N
X
i=1
(1 −ηL)N−iσ1
i
!2
,
where the last equality used the fact that E[σm
j ] = 0 for all m ∈[M] and i ∈[N], and that σm are
identically distributed. Since we only consider the permutation σ1 (i.e., the one for machine 1) from
65

Published as a conference paper at ICLR 2022
now on, we henceforth omit the superscript. Substituting this to (157) gives
E[y2
N
B ] = (1 −ηL)2Ny2
0 + η2ν2
M
E


 N
X
i=1
(1 −ηL)N−iσi
!2

|
{z
}
:=Φ
.
(158)
From (158), we have calculated the per-epoch expected update, because the ﬁnal iterate y N
B is also
the initial iterate of the next epoch. Recall that we run the algorithm for K epochs. We now use yk,i
to denote the iterate after the i-th communication round in the k-th epoch. Using (158), we get a
lower bound on the expectation of the last iterate yK, N
B squared:
E[y2
K, N
B ] = (1 −ηL)2NKy2
1,0 + η2ν2
M Φ
K−1
X
k=0
(1 −ηL)2Nk ≥η2ν2
M Φ.
(159)
where the inequality used that we initialize at y1,0 = 0 and PK−1
k=0 (1 −ηL)2Nk ≥(1 −ηL)0 = 1.
Next, we bound the expectation term, i.e., Φ, deﬁned in (158). Using Lemma 1 from Safran &
Shamir (2020) with n and α replaced with N and ηL respectively, we have
Φ ≥c · min
 1
ηL, η2L2N 3

,
(160)
for some universal constant c > 0. Using the fact that η ≥
1
1025LN , it is easy to check that the RHS
of (160) is lower-bounded by c′
ηL, where c′ > 0 is a universal constant. Combining (159) and (160)
gives
E[y2
K, N
B ] ≥η2ν2
M
· c′
ηL = c′ην2
LM .
Also using the fact that η ≥
1
µNK , we get
E[F3(yK, N
B )] = L
2 E[y2
K, N
B ] ≥
c′ν2
2µMNK .
H
PROOFS OF HELPER LEMMAS FOR APPENDIX G
H.1
PROOF OF LEMMA 16
The proof of Lemma 16 is similar to its minibatch RR counterpart, Lemma 11. From the given
0 ≤i ≤N
B −1, 0 ≤j ≤B −1, deﬁne k := iB + j, in order to simplify notation. We also deﬁne
E :=
1
M
PM
m=1
PiB
l=1 σm
l

+ Pk
l=iB+1 σ1
l .
By the law of total expectation we have
E[(L1x1
k≤0 + µ1x1
k>0)x1
k] = P (E > 0) E
h
(L1x1
k≤0 + µ1x1
k>0)x1
k
E > 0
i
+ P (E ≤0) E
h
(L1x1
k≤0 + µ1x1
k>0)x1
k
E ≤0
i
≤P (E > 0) LE

x1
k
E > 0

+ P (E ≤0) µE

x1
k
E ≤0

,
(161)
where the last inequality used the fact that (L1t≤0 + µ1t>0)t ≤Lt and (L1t≤0 + µ1t>0)t ≤µt for
any t ∈R.
We handle each of the two expectations in (161) separately. We ﬁrst bound E

x1
k
E > 0

. Recall
from the deﬁnition of algorithm iterates that
x1
k −y0 = x1
iB+j −y0 = −η
M
M
X
m=1
iB−1
X
l=0
∇fσm
l+1(xm
l ) −η
k−1
X
l=iB
fσ1
l+1(x1
l ).
(162)
Expanding (162) using the deﬁnition of ∇fσm
l+1’s, we obtain
E

x1
k
E > 0

66

Published as a conference paper at ICLR 2022
= E
"
y0 −η
M
M
X
m=1
iB−1
X
l=0
 νσm
l+1 + (L1xm
l ≤0 + µ1xm
l >0)xm
l

−η
k−1
X
l=iB

νσ1
l+1 + (L1x1
l ≤0 + µ1x1
l >0)x1
l
E > 0
#
= E
"
y0 −η
M
M
X
m=1
iB−1
X
l=0
(L1xm
l ≤0 + µ1xm
l >0)(xm
l −y0)
−η
k−1
X
l=iB
(L1x1
l ≤0 + µ1x1
l >0)(x1
l −y0)
E > 0
#
−ηνE [E|E > 0]
−E
"
η
M
M
X
m=1
iB−1
X
l=0
(L1xm
l ≤0 + µ1xm
l >0)y0 + η
k−1
X
l=iB
(L1x1
l ≤0 + µ1x1
l >0)y0
E > 0
#
= y0E
"
1 −η
M
M
X
m=1
iB−1
X
l=0
(L1xm
l ≤0 + µ1xm
l >0) −η
k−1
X
l=iB
(L1x1
l ≤0 + µ1x1
l >0)
E > 0
#
−E
"
η
M
M
X
m=1
iB−1
X
l=0
(L1xm
l ≤0 + µ1xm
l >0)(xm
l −y0)
+η
k−1
X
l=iB
(L1x1
l ≤0 + µ1x1
l >0)(x1
l −y0)
E > 0
#
−ηνE [E|E > 0]
≤y0E
"
1 −η
M
M
X
m=1
iB−1
X
l=0
(L1xm
l ≤0 + µ1xm
l >0) −η
k−1
X
l=iB
(L1x1
l ≤0 + µ1x1
l >0)
E > 0
#
+ ηL(M −1)
M
iB−1
X
l=0
E

|x2
l −y0| | E > 0

+ ηL
M
iB−1
X
l=0
E

|x1
l −y0| | E > 0

+ ηL
k−1
X
l=iB
E

|x1
l −y0| | E > 0

−ηνE [E|E > 0] ,
where the last inequality used the fact that (L1t≤0 + µ1t>0)t ≤Lt and (L1t≤0 + µ1t>0)t ≤µt
for any t ∈R; and that for different m = 2, . . . , M, the local iterates xm
l are identically distributed
conditioned on E > 0. Next, we use the fact that for any nonnegative random variable v and event
∆, we have that E[v|∆] ≤E[v]/P(∆). Hence,
E

x1
k
E > 0

≤y0E
"
1 −η
M
M
X
m=1
iB−1
X
l=0
(L1xm
l ≤0 + µ1xm
l >0) −η
k−1
X
l=iB
(L1x1
l ≤0 + µ1x1
l >0)
E > 0
#
+ ηL(M −1)
M
iB−1
X
l=0
E

|x2
l −y0|

P(E > 0)
+ ηL
M
iB−1
X
l=0
E

|x1
l −y0|

P(E > 0)
+ ηL
k−1
X
l=iB
E

|x1
l −y0|

P(E > 0)
−ηνE [E|E > 0]
= y0E
"
1 −η
M
M
X
m=1
iB−1
X
l=0
(L1xm
l ≤0 + µ1xm
l >0) −η
k−1
X
l=iB
(L1x1
l ≤0 + µ1x1
l >0)
E > 0
#
−ηνE [E|E > 0] + ηL
k−1
X
l=0
E

|x1
l −y0|

P(E > 0)
(163)
where the last equality used the fact that for different m ∈[M], the local iterates xm
l are identically
distributed when they are not conditioned.
67

Published as a conference paper at ICLR 2022
Next, we use Lemma 14 again to bound the conditional expectations that arise in (163). We restate
the lemma for the reader’s convenience.
Lemma 14. For m ∈[M], let σm be a random permutation of N
2 +1’s and N
2 −1’s. Then, for any
i ≤N
2 and k ≤B
2 , we have
1
64
 r
i
M +
√
k
!
≤E




1
M
M
X
m=1
i
X
j=1
σm
j

+
i+k
X
j=i+1
σM
j


.
Furthermore, for any 0 ≤i ≤N and 0 ≤k ≤N satisfying i + k ≤N, we have
E




1
M
M
X
m=1
i
X
j=1
σm
j

+
i+k
X
j=i+1
σM
j


≤
r
i
M +
√
k.
Lastly, for any 0 ≤i ≤N
2 and 0 ≤k ≤B
2 satisfying i + k ≥1, we have
P


M
X
m=1
i
X
j=1
σm
j + M
i+k
X
j=i+1
σM
j
> 0

= P


M
X
m=1
i
X
j=1
σm
j + M
i+k
X
j=i+1
σM
j
< 0

≥1
6.
Lemma 14 implies that E [E|E > 0] ∈
h
1
64
q
iB
M + √j

,
q
iB
M + √j
i
and P(E > 0) = P(E <
0) ≥1/6. From this, we get
ηνE [E|E > 0] ≥ην
64
 r
iB
M +
p
j
!
,
(164)
E

|x1
l −y0|

P(E > 0)
≤6E

|x1
l −y0|

.
(165)
Also, since η ≤
1
LN we have
1 −kηµ ≥1 −η
M
M
X
m=1
iB−1
X
l=0
(L1xm
l ≤0 + µ1xm
l >0) −η
k−1
X
l=iB
(L1x1
l ≤0 + µ1x1
l >0) ≥1 −ηLN ≥0,
which implies that
y0E
"
1 −η
M
M
X
m=1
iB−1
X
l=0
(L1xm
l ≤0 + µ1xm
l >0) −η
k−1
X
l=iB
(L1x1
l ≤0 + µ1x1
l >0)
E > 0
#
≤(1 −kηµ)y0.
(166)
Substituting (164), (165), and (166) to (163), we obatin
E

x1
k
E > 0

≤(1 −kηµ)y0 −ην
64
 r
iB
M +
p
j
!
+ 6ηL
k−1
X
l=0
E

|x1
l −y0|

.
(167)
Next, we have the following lemma that we can apply to E[|x1
l −y0|]. Proof of Lemma 19 can be
found in Appendix H.4.
Lemma 19. For y0 ≥0, 0 ≤i ≤N
B −1, 0 ≤j ≤B −1, and η ≤
1
1025LN ,
E[|x1
iB+j −y0|] ≤1025
1024ην
 r
iB
M +
p
j
!
+ 1025
1024(iB + j)ηLy0.
Applying this lemma to (167) and arranging the bounds (recall that k := iB + j), we get
1024
1025
k−1
X
l=0
E

|x1
l −y0|

68

Published as a conference paper at ICLR 2022
≤ην
k−1
X
l=0
 r
B⌊l/B⌋
M
+
p
l −B⌊l/B⌋
!
+ ηLy0
k−1
X
l=0
l
= ην
iB−1
X
l=0
 r
B⌊l/B⌋
M
+
p
l −B⌊l/B⌋
!
+ ην
iB+j−1
X
l=iB
 r
B⌊l/B⌋
M
+
p
l −B⌊l/B⌋
!
+ ηLy0
k−1
X
l=0
l
= ην
 
B
i−1
X
l=0
r
lB
M + j
r
iB
M + i
B−1
X
l=0
√
l +
j−1
X
l=0
√
l
!
+ ηLy0
k−1
X
l=0
l.
(168)
The terms in (168) can be bounded using Pc−1
l=0
√
l ≤
R c
0
√
tdt:
1024
1025
k−1
X
l=0
E

|x1
l −y0|

≤ην
2i3/2B3/2
3M 1/2
+ i1/2jB1/2
M 1/2
+ 2iB3/2
3
+ 2j3/2
3

+ k2ηLy0
2
≤ην
 
(2iB + 3j)
3
r
iB
M + 4iBj1/2
3
+ 2j3/2
3
!
+ k2ηLy0
2
= ην
 
(2iB + 3j)
3
r
iB
M + (4iB + 2j)
3
p
j
!
+ k2ηLy0
2
≤4kην
3
 r
iB
M +
p
j
!
+ k2ηLy0
2
,
(169)
where the second last inequality used B
4 ≤j (and hence B1/2 ≤2j1/2), and the last inequality used
2iB + 3j ≤4(iB + j) = 4k and 4iB + 2j ≤4(iB + j) = 4k. Substituting (169) to (167), we get
E

x1
k
E > 0

(170)
≤(1 −kηµ)y0 −ην
64
 r
iB
M +
p
j
!
+ 1025kη2Lν
128
 r
iB
M +
p
j
!
+ 3075k2η2L2y0
1024
=

1 −kηµ + 3075k2η2L2
1024

y0 −
 1
64 −1025kηL
128

ην
 r
iB
M +
p
j
!
≤

1 −kηµ + 3kηL
1024

y0 −ην
128
 r
iB
M +
p
j
!
.
(171)
The last inequality here used kηL ≤ηLN ≤
1
1025, which follows from η ≤
1
1025LN . Thus far, we
have obtained an upper bound for E

x1
k
E > 0

.
Recall that there is another conditional expectation in (161) that we want to bound, namely
E

x1
k
E ≤0

. We bound it below, using the tools developed so far. For i ≤
N
2B and B
4 ≤j ≤B
2 ,
E

x1
k
E ≤0

= y0 + E

x1
k −y0 | E ≤0

≤y0 + E

|x1
k −y0| | E ≤0

≤y0 + E

|x1
k −x0|

P(E ≤0)
≤y0 + 6E

|x1
k −x0|

(Using Lemma 14)
≤y0 + 3075ην
512
 r
iB
M +
p
j
!
+ 3075kηLy0
512
(Using Lemma 19)
≤

1 + 3075kηL
512

y0 + 3075ην
512
 r
iB
M +
p
j
!
.
(172)
69

Published as a conference paper at ICLR 2022
Using (171) and (172) in (161), we get that for i ≤
N
2B and B
4 ≤j ≤B
2 :
E[(L1x1
k≤0 + µ1x1
k>0)x1
k]
≤P (E > 0) LE

x1
k
E > 0

+ P (E ≤0) µE

x1
k
E ≤0

≤P (E > 0) L
 
1 −kηµ + 3kηL
1024

y0 −ην
128
 r
iB
M +
p
j
!!
+ P (E ≤0) µ
 
1 + 3075kηL
512

y0 + 3075ην
512
 r
iB
M +
p
j
!!
.
(173)
From Lemma 14, note that 1
6 ≤P (E > 0) ≤5
6 and 1
6 ≤P (E ≤0) ≤5
6. We use these inequalities,
along with kηL ≤ηLN ≤
1
1025 and L
µ ≥15375
2
, to bound the terms appearing in (173).
P (E > 0) L

1 −kηµ + 3kηL
1024

y0 + P (E ≤0) µ

1 + 3075kηL
512

y0
≤5
6L

1 +
3
1049600

y0 + 5
6 ·
2L
15375

1 +
3
512

y0 ≤6
7Ly0.
(174)
We also have
−P (E > 0) ηLν
128
 r
iB
M +
p
j
!
+ P (E ≤0) 3075ηµν
512
 r
iB
M +
p
j
!
≤−ηLν
768
 r
iB
M +
p
j
!
+ 5125ηµν
1024
 r
iB
M +
p
j
!
≤−ηLν
1536
 r
iB
M +
p
j
!
,
(175)
where we used the assumption L
µ ≥15375
2
. Substituting (174) and (175) to (173), we get
E[(L1x1
k≤0 + µ1x1
k>0)x1
k] ≤6
7Ly0 −ηLν
1536
 r
iB
M +
p
j
!
,
which ﬁnishes the proof.
H.2
PROOF OF LEMMA 17
E[(L1x1
iB+j≤0 + µ1x1
iB+j>0)x1
iB+j] ≤µE[x1
iB+j]
= µy0 + µE[x1
iB+j −y0]
≤µy0 + µE[|x1
iB+j −x0|]
≤µy0 + 1025(iB + j)ηLµ
1024
y0 + 1025ηµν
1024
 r
iB
M +
p
j
!
,
where the last inequality used Lemma 19.
H.3
PROOF OF LEMMA 18
We consider iterates within a single epoch, and hence we omit the subscripts denoting epochs. In
our construction, each machine has the same set of component functions, that is, there will be no
inter-machine deviation. We therefore omit the superscript m from the local component functions.
Consider the function
G2(x) := 1
N


N
2
X
i=1
g+1(x) +
N
X
i= N
2 +1
g−1(x)

, where
70

Published as a conference paper at ICLR 2022
g+1(x) := Lx2
2
+ νx, and g−1(x) := Lx2
2
−νx.
Hence, G2(x) = Lx2
2 . We prove the lemma by coupling iterates corresponding to F2 and G2. In
particular, we perform local RR on F2 and G2 such that both start the given epoch at y0 and all the
corresponding machines use the same random permutations. Let xm
iB+j,F and xm
iB+j,G denote the
iterates (for (iB + j)-th iteration at machine m) for F2 and G2 respectively. We use mathematical
induction to prove that xm
iB+j,F ≥xm
iB+j,G for all i = 0, . . . , N
B −1 and j = 0, . . . , B and machines
m = 1, . . . , M. After that, we will use this to prove our desired statement E[y N
B ,F | y0 < 0] =
E[ 1
M
PM
m=1 xm
N,F | y0 < 0] ≥(1 −7ηLN
8B )y0.
Let σm be a random permutation of N
2 +1’s and N
2 −1’s. First we consider i = 0 and 0 ≤j ≤B.
Base case.
For the base case, we know that xm
0,F ≥xm
0,G, since xm
0,F = xm
0,G = y0 for all m.
Inductive case.
There can be three cases:
• Case 1: xm
iB+j,F ≥xm
iB+j,G ≥0. Then,
xm
iB+j+1,F −xm
iB+j+1,G
= xm
iB+j,F −xm
iB+j,G −η(∇fσm
iB+j+1(xiB+j,F ) −∇gσm
iB+j+1(xiB+j,G))
= xm
iB+j,F −xm
iB+j,G −η
 µxm
iB+j,F + νσm
iB+j+1 −Lxm
iB+j,G −νσm
iB+j+1

= xm
iB+j,F −xm
iB+j,G −η
 µxm
iB+j,F −Lxm
iB+j,G

= xm
iB+j,F (1 −ηµ) −xm
iB+j,G(1 −ηL) ≥0.
• Case 2: 0 ≥xm
iB+j,F ≥xm
iB+j,G. Then,
xm
iB+j+1,F −xm
iB+j+1,G
= xm
iB+j,F −xm
iB+j,G −η(∇fσm
iB+j+1(xiB+j,F ) −∇gσm
iB+j+1(xiB+j,G))
= xm
iB+j,F −xm
i,G −η
 Lxm
iB+j,F + νσm
iB+j+1 −Lxm
iB+j,G −νσm
iB+j+1

= xm
iB+j,F −xm
iB+j,G −η
 Lxm
iB+j,F −Lxm
iB+j,G

= xm
iB+j,F (1 −ηL) −xm
iB+j,G(1 −ηL) ≥0.
• Case 3: xiB+j,F ≥0 ≥xiB+j,G. Then,
xm
iB+j+1,F −xm
iB+j+1,G
= xm
iB+j,F −xm
iB+j,G −η(∇fσm
iB+j+1(xiB+j,F ) −∇gσm
iB+j+1(xiB+j,G))
= xm
iB+j,F −xm
iB+j,G −η
 µxm
iB+j,F + νσm
iB+j+1 −Lxm
iB+j,G −νσm
iB+j+1

= xm
iB+j,F −xm
iB+j,G −η
 µxm
iB+j,F −Lxm
iB+j,G

= xm
iB+j,F (1 −ηµ) −xm
iB+j,G(1 −ηL).
Note that since η ≤
1
LN , we get that xm
iB+j,F (1 −ηµ) ≥0 and xm
iB+j,G(1 −ηL) ≤0,
which proves that xm
iB+j+1,F −xm
iB+j+1,G ≥0.
Thus, we see that xm
iB+j+1,F ≥xm
iB+j+1,G for all the three cases, which proves by mathematical
induction that xm
iB+j,F ≥xm
iB+j,G for all 0 ≤j ≤B and i = 0. Note that this implies that, the
aggregated averages y1,F :=
1
M
PM
m=1 xm
B,F and y1,G :=
1
M
PM
m=1 xm
B,G satisfy y1,F ≥y1,G.
Hence, after synchronization is complete, we get that for i = 1 and j = 0, xm
iB+j,F ≥xm
iB+j,G for
all machines m. This proves the base case for i = 1. Now, we can repeat the Inductive cases for
1 ≤j ≤B and i = 1, and thereby prove that y2,F ≥y2,G. Continuing on this process, we get that
xm
iB+j,F ≥xm
iB+j,G for all 0 ≤j ≤B and 0 ≤i ≤N
B −1, and consequently, y N
B ,F ≥y N
B ,G.
Further, by linearity of expectation and gradient, it is easy to check that for any machine m,
E[y N
B ,G] = (1 −ηL)Ny0.
71

Published as a conference paper at ICLR 2022
Using the result that y N
B ,F ≥y N
B ,G which we proved above, we get E[y N
B ,F ] ≥(1 −ηL)Ny0 for
any initial iterate y0. Speciﬁcally for y0 < 0, this implies E[y N
B ,F | y0 < 0] ≥(1 −ηL)Ny0.
Further, since ηL ≤
1
1025N , we have (1 −ηL)N ≤1 −7ηLN
8
. This is because 1 −7zN
8
−(1 −z)N
is nonnegative on the interval
h
0, 1 −(7/8)
1
N−1
i
, and 1 −(7/8)
1
N−1 ≥
1
1025N for all N ≥2. To
see why, note that (1 −
1
1025(n−1))n−1 ≥7
8 for all n ≥2, and this gives 1 −(7/8)
1
n−1 ≥
1
1025(n−1),
which then implies 1 −(7/8)
1
n−1 ≥
1
1025n for all n ≥2. Therefore, for y0 < 0, we have E[y N
B ,F |
y0 < 0] ≥(1 −7ηLN
8
)y0.
For the last statement of the lemma, note that by symmetry of the function G2, if we initialize
Algorithm 1 at 0, then for any starting iterate of an epoch we have P(y0,G ≥0) ≥1/2. This
combined with the fact that yi,F ≥yi,G gives us that P(y0,F ≥0) ≥1/2.
H.4
PROOF OF LEMMA 19
E[|x1
iB+j −y0|]
= E
"
η
M
M
X
m=1
iB−1
X
l=0
νσm
l+1 + (L1xm
l <0 + µ1xm
l ≥0)xm
l + η
iB+j−1
X
l=iB
νσ1
l+1 + (L1x1
l <0 + µ1x1
l ≥0)x1
l

#
≤ην
 r
iB
M +
p
j
!
+ ηE
"
iB+j−1
X
l=0
(L1x1
l <0 + µ1x1
l ≥0)x1
l

#
(By Lemma 14)
≤ην
 r
iB
M +
p
j
!
+ ηL
iB+j−1
X
l=0
E[|x1
l |]
≤ην
 r
iB
M +
p
j
!
+ (iB + j)ηLy0 + ηL
iB+j−1
X
l=0
E[|x1
l −y0|].
Now deﬁne
h(k) := ην
 r
B⌊k/B⌋
M
+
p
k −B⌊k/B⌋
!
+ kηLy0 + ηL
k−1
X
l=0
h(l).
In terms of i and j, note that k corresponds to k = iB + j. Then using induction, it can be seen that
E[|x1
k −y0|] ≤h(k). Further, since h(k) is an increasing function of k, we get
h(k) = ην
 r
B⌊k/B⌋
M
+
p
k −B⌊k/B⌋
!
+ kηLy0 + ηL
k−1
X
l=0
h(l)
≤ην
 r
B⌊k/B⌋
M
+
p
k −B⌊k/B⌋
!
+ kηLy0 + kηLh(k)
=⇒h(k) ≤
ην
q
B⌊k/B⌋
M
+
p
k −B⌊k/B⌋

+ kηLy0
1 −kηL
.
Since k ≤N and η ≤
1
1025LN , we get that
E[|x1
iB+j −y0|] ≤1025
1024ην
 r
iB
M +
p
j
!
+ 1025
1024(iB + j)ηLy0,
as desired.
72

Published as a conference paper at ICLR 2022
I
PROOF OF LOWER BOUND FOR LOCAL RR: HETEROGENEOUS CASE
(PROPOSITION 5)
Recall that Proposition 5 gives the bound for local RR in the heterogeneous setting, where different
machines have different local objectives. In this section, we construct examples where there is no
intra-machine variation (i.e., f m
1 = f m
2 = · · · = f m
N for all m ∈[M]), but there is certain level of
heterogeneity among different machines.
Similar to the other two lower bounds, we consider four step-size ranges and do case analysis for
each of them. This time, we construct a single function F for these step-size regimes such that
the convergence of local RR is “slow” for F. The ﬁnal lower bound is the minimum among the
lower bounds obtained for the four regimes. More concretely, we will construct a one-dimensional
function F(x) satisfying L-smoothness (1), µ-PŁ condition (2), and Assumption 3 such that16
• Local RR on F(x) with η ≤
1
8µNK and initialization y0 = τ
µ results in
E[F(yK, N
B )] = Ω
τ 2
µ

.
• Local RR on F(x) with
1
8µNK ≤η ≤
1
8µB and initialization y0 = 0 results in
E[F(yK, N
B )] = Ω
 τ 2B2
µN 2K2

.
• Local RR on F(x) with
1
8µB ≤η ≤1
µ and initialization y0 = 0 results in
E[F(yK, N
B )] = Ω
τ 2
µ

.
• Local RR on F(x) with η ≥1
µ and initialization y0 = τ
µ results in
E[F(yK, N
B )] = Ω
τ 2
µ

.
In the subsequent subsections, we prove the lower bounds for F for the four step-size intervals.
I.1
LOWER BOUND FOR
1
8µNK ≤η ≤
1
8µB AND
1
8µB ≤η ≤1
µ
We ﬁrst consider the two intervals in the middle, because they are more interesting cases. The global
objective function F and its local objective functions are as follows.
F(x) := 1
M


M
2
X
i=1
f1(x) +
M
X
i= M
2 +1
f2(x)

, where
f1(x) := −τx, and f2(x) := µx2 + τx
In this construction, M/2 machines will have the function f1 as their N local component functions
(and hence their local objective functions) and the other M/2 machines will have the function f2.
Then, B local RR updates in each machine corresponds to B updates using either f1 or f2. If we
start from xm
iB = yi, the B local updates on machine m result in
xm
(i+1)B =
(
xm
iB + ητB
if machine m has f1,
(1 −2ηµ)Bxm
iB −ητ PB−1
j=0 (1 −2ηµ)j
if machine m has f2.
Taking the average of the M machines, we get that
yi+1 = 1
M

M
2 (yi + ητB) + M
2

(1 −2ηµ)Byi −ητ
B−1
X
j=0
(1 −2ηµ)j




16Again, the functions constructed in this theorem are µ-strongly convex, which is stronger than µ-PL re-
quired in Deﬁnition 1. Also, our functions satisfy Assumption 2 with ν = 0.
73

Published as a conference paper at ICLR 2022
= 1
2
 1 + (1 −2ηµ)B
yi + ητ
2

B −
B−1
X
j=0
(1 −2ηµ)j

.
Since there are total NK
B such communication rounds over K epochs, at the end of the run we have
yK, N
B =
1
2
 1 + (1 −2ηµ)B NK
B
y0
+ ητ
2

B −
B−1
X
j=0
(1 −2ηµ)j


NK
B −1
X
l=0
1
2
 1 + (1 −2ηµ)Bl
= ητ
2

B −1 −(1 −2ηµ)B
2ηµ
 1 −
  1
2
 1 + (1 −2ηµ)B NK
B
1 −1
2 (1 + (1 −2ηµ)B)
,
(176)
where we used initialization y0 = 0. Having deﬁned the function and calculated its last iterate (176),
let us now handle the two step-size regimes separately.
We ﬁrst consider
1
8µNK ≤η ≤
1
8µB . In this case, we exploit the fact that
1 −2ηµB + η2µ2B2 ≤(1 −2ηµ)B ≤1 −2ηµB + 4η2µ2B2,
(177)
when 0 ≤η ≤
1
8µB . To see why, consider substituting z := 2ηµ. Then h1(z) := 1 −Bz + B2z2 −
(1 −z)B has h′′
1(z) ≥0 on z ∈[0, 1], h′
1(0) = 0, and h1(0) = 0, implying that h1(z) ≥0 on
z ∈[0, 1]. On the other hand, let h2(z) := 1 −Bz + B2z2
4
−(1 −z)B. If B = 2, then h2 ≡0. If
B > 2, then it can be checked that h2(z) ≤0 for small enough interval [0,
1
4B ].
Using (177) on (176),
yK, N
B = ητ
2

B −1 −(1 −2ηµ)B
2ηµ
 1 −
  1
2
 1 + (1 −2ηµ)B NK
B
1 −1
2 (1 + (1 −2ηµ)B)
≥ητ
2

B −1 −(1 −2ηµB + η2µ2B2)
2ηµ
 1 −
  1
2
 1 + 1 −2ηµB + 4η2µ2B2 NK
B
1 −1
2 (1 + 1 −2ηµB + η2µ2B2)
= ητ
2
ηµB2
2
 1 −
 1 −ηµB + 2η2µ2B2 NK
B
ηµB −1
2η2µ2B2
≥η2µτB2
4
· 1 −
 1 −ηµB + 1
4ηµB
 NK
B
ηµB
≥ητB
4
 
1 −

1 −3ηµB
4
 NK
B !
,
where we used ηµB ≤1
8. Now, substituting η ≥
1
8µNK to above, we obtain
yK, N
B ≥ητB
4
 
1 −

1 −3ηµB
4
 NK
B !
≥
τB
32µNK
 
1 −

1 −
3B
32NK
 NK
B !
≥(1 −e−3/32)τB
32µNK
.
Therefore, F(yK, N
B ) = Ω

τ 2B2
µN2K2

.
Next, consider
1
8µB ≤η ≤1
µ. We take a close look at the term that appears in (176):
B −
B−1
X
j=0
(1 −2ηµ)j = B −1 −(1 −2ηµ)B
2ηµ
.
74

Published as a conference paper at ICLR 2022
For this term, we would like to ﬁnd a lower bound which holds for all η ∈[
1
8µB , 1
µ]. To this end,
consider substituting z := 2ηµ. Then, the function
h3(z) := B −
B−1
X
j=0
(1 −z)j
(178)
is increasing on z ∈[ 1
4B , 1], and we have
h3
  1
4B

= B −4B

1 −
 1 −
1
4B
B
≤h3(z), for all z ∈
 1
4B , 1

.
Using B ≥2, h3( 1
4B ) can be lower-bounded as
h3
  1
4B

≥B −4B

1 −
 1 −1
8
2
= B
16.
Next, for z ≥1, the derivative of h3(z) := B −PB−1
j=0 (1 −z)j = B −1−(1−z)B
z
is h′
3(z) =
1−(1−z)B−1((B−1)z+1)
z
. Since B ≥2 is assumed to be even, it is easy to check that h′
3(z) ≥0 for
z ≥1, which means that h3 keeps increasing on [1, 2]. Therefore, we conclude that
B
16 ≤h3
  1
4B

≤h3(z), for all z ∈
 1
4B , 2

,
and hence
B −
B−1
X
j=0
(1 −2ηµ)j ≥B
16,
for all
1
8µB ≤η ≤1
µ. Using yK, N
B from (176), we get
yK, N
B = ητ
2

B −
B−1
X
j=0
(1 −2ηµ)j


NK
B −1
X
l=0
1
2
 1 + (1 −2ηµ)Bl
≥ητ
2

B −
B−1
X
j=0
(1 −2ηµ)j

≥ητB
32
≥
τ
256µ.
Here, we used the fact that P NK
B −1
l=0
  1
2
 1 + (1 −2ηµ)Bl ≥
  1
2
 1 + (1 −2ηµ)B0 = 1.
Hence, we obtain F(yK, N
B ) = Ω( τ 2
µ ), ﬁnishing the proof.
I.2
LOWER BOUND FOR η ≤
1
8µNK AND η ≥1
µ
We now conclude with the “extreme” step-size regimes. We consider the same function F as in the
previous subsection, but with a different initialization y0 = τ
µ.
For F, recall from (176) that
yK, N
B =
1
2
 1 + (1 −2ηµ)B NK
B
y0
+ ητ
2

B −
B−1
X
j=0
(1 −2ηµ)j


NK
B −1
X
l=0
1
2
 1 + (1 −2ηµ)Bl
.
(179)
This time, we want to lower-bound the second term on the RHS of (179) with zero and focus on the
ﬁrst term. To this end, we revisit our discussion on h3 (178). It is easy to check that h3 is in fact
increasing on the entire [0, ∞), and h3(0) = 0. This shows B −PB−1
j=0 (1 −2ηµ)j ≥0 for any
η ≥0. Next, since B is even, 1
2
 1 + (1 −2ηµ)B
≥0 for any η ≥0. This gives
yK, N
B ≥
1
2
 1 + (1 −2ηµ)B NK
B
y0 =
1
2
 1 + (1 −2ηµ)B NK
B
τ
µ.
(180)
75

Published as a conference paper at ICLR 2022
First, consider the interval 0 ≤η ≤
1
8µNK . Recall from (177) that for this η,
(1 −2ηµ)B ≥1 −2ηµB + η2µ2B2 ≥1 −2ηµB,
(181)
so
yK, N
B ≥
1
2
 1 + (1 −2ηµ)B NK
B
τ
µ ≥(1 −ηµB)
NK
B τ
µ ≥

1 −
B
8NK
 NK
B
τ
µ ≥7τ
8µ,
since NK
B
≥1. Hence, F(yK, N
B ) = Ω( τ 2
µ ).
Finally, if η ≥1
µ, then we have (1 −2ηµ)B ≥1, so
yK, N
B ≥
1
2
 1 + (1 −2ηµ)B NK
B
τ
µ ≥τ
µ.
As a result, F(yK, N
B ) = Ω( τ 2
µ ).
76

