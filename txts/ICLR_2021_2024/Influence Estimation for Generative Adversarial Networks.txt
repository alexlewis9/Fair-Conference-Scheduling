Published as a conference paper at ICLR 2021
INFLUENCE ESTIMATION FOR GENERATIVE ADVER-
SARIAL NETWORKS
Naoyuki Terashita
Hiroki Ohashi
Yuichi Nonaka
Takashi Kanemaru
Hitachi, Ltd.
Tokyo, Japan
ABSTRACT
Identifying harmful instances, whose absence in a training dataset improves model
performance, is important for building better machine learning models. Although
previous studies have succeeded in estimating harmful instances under super-
vised settings, they cannot be trivially extended to generative adversarial networks
(GANs). This is because previous approaches require that (i) the absence of a
training instance directly affects the loss value and that (ii) the change in the loss
directly measures the harmfulness of the instance for the performance of a model.
In GAN training, however, neither of the requirements is satisï¬ed. This is because,
(i) the generatorâ€™s loss is not directly affected by the training instances as they are
not part of the generatorâ€™s training steps, and (ii) the values of GANâ€™s losses nor-
mally do not capture the generative performance of a model. To this end, (i) we
propose an inï¬‚uence estimation method that uses the Jacobian of the gradient of
the generatorâ€™s loss with respect to the discriminatorâ€™s parameters (and vice versa)
to trace how the absence of an instance in the discriminatorâ€™s training affects the
generatorâ€™s parameters, and (ii) we propose a novel evaluation scheme, in which
we assess harmfulness of each training instance on the basis of how GAN eval-
uation metric (e.g., inception score) is expected to change due to the removal of
the instance. We experimentally veriï¬ed that our inï¬‚uence estimation method cor-
rectly inferred the changes in GAN evaluation metrics. We also demonstrated that
the removal of the identiï¬ed harmful instances effectively improved the modelâ€™s
generative performance with respect to various GAN evaluation metrics.
1
INTRODUCTION
Generative adversarial networks (GANs) proposed by Goodfellow et al. (2014) are a powerful sub-
class of generative model, which is successfully applied to a number of image generation tasks
(Antoniou et al., 2017; Ledig et al., 2017; Wu et al., 2016). The expansion of the applications of
GANs makes improvements in the generative performance of models increasingly crucial.
An effective approach for improving machine learning models is to identify training instances that
harm the model performance. Traditionally, statisticians manually screen a dataset for harmful in-
stances, which misguide a model into producing biased predictions. Recent inï¬‚uence estimation
methods (Khanna et al., 2019; Hara et al., 2019) automated the screening of datasets for deep learn-
ing settings, in which the sizes of both datasets and data dimensions are too large for users to man-
ually determine the harmful instances. Inï¬‚uence estimation measures the effect of removing an
individual training instance on a modelâ€™s prediction without the computationally prohibitive cost of
model retraining. The recent studies identiï¬ed harmful instances by estimating how the loss value
changes if each training instance is removed from the dataset.
Although previous studies have succeeded in identifying the harmful instances in supervised set-
tings, the extension of their approaches to GAN is non-trivial. Previous approaches require that (i)
the existence or absence of a training instance directly affects a loss value, and that (ii) the decrease
in the loss value represents the harmfulness of the removed training instance. In GAN training,
however, neither of the requirements is satisï¬ed. (i) As training instances are only fed into the dis-
criminator, they only indirectly affect the generatorâ€™s loss, and (ii) the changes in the losses of GAN
1

Published as a conference paper at ICLR 2021
do not necessarily capture how the removed instances harm the generative performance. This is
because the ability of the loss to evaluate the generator is highly dependent on the performance of
the discriminator.
To this end, (i) we propose an inï¬‚uence estimation method that uses the Jacobian of the gradient
of the discriminatorâ€™s loss with respect to the generatorâ€™s parameters (and vice versa), which traces
how the absence of an instance in the discriminatorâ€™s training affects the generatorâ€™s parameters. In
addition, (ii) we propose a novel evaluation scheme to judge if an instance is harmful or not on the
basis of inï¬‚uence on GAN evaluation metric, that is, how a GAN evaluation metric (e.g., inception
score (Salimans et al., 2016)) changes if a given training instance is removed from the dataset. We
identify harmful instances by estimating the inï¬‚uence on GAN evaluation metric by leveraging our
inï¬‚uence estimation method.
We veriï¬ed that the proposed inï¬‚uence estimation method correctly estimated the inï¬‚uence on GAN
evaluation metrics across different settings of the dataset, model architecture, and GAN evaluation
metrics. We also demonstrated that removing harmful instances, which were identiï¬ed by the pro-
posed method, effectively improved various GAN evaluation metrics.1
Our contributions are summarized as follows:
â€¢ We propose an inï¬‚uence estimation method that uses the Jacobian of the gradient of the dis-
criminatorâ€™s loss with respect to the generatorâ€™s parameters (and vice versa), which traces
how the absence of an instance in the discriminatorâ€™s training affects the generatorâ€™s pa-
rameters.
â€¢ We propose a novel evaluation scheme to judge if an instance is harmful or not on the basis
of inï¬‚uence on GAN evaluation metrics rather than that on the loss value, and to leverage
the proposed inï¬‚uence estimation method to identify harmful instances.
â€¢ We experimentally veriï¬ed that our inï¬‚uence estimation method correctly inferred the in-
ï¬‚uence on GAN evaluation metrics. Further, we demonstrated that the removal of the
harmful instances suggested by the proposed method effectively improved the generative
performance with respect to various GAN evaluation metrics.
2
PRELIMINARIES
Notation
For column vectors a, b âˆˆRp, we denote the inner product by âŸ¨a, bâŸ©= Pp
i=1 aibi. For
a function f(a), we denote its gradient with respect to a by âˆ‡af(a). We denote the identity matrix
of size p by Ip, the zero vector of length p by 0p, and the ones vector of length p by 1p.
Generative Adversarial Networks (GAN)
For simplicity, we consider an unconditional GAN
that consists of the generator G : Rdz â†’Rdx and the discriminator D : Rdx â†’R, where dz and dx
are the number of dimensions of latent variable z âˆ¼p(z) and data point x âˆ¼p(x), respectively. The
parameters of generator Î¸G âˆˆRdG and discriminator Î¸D âˆˆRdD are learned though the adversarial
training; G tries to sample realistic data while D tries to identify whether the data is real or generated.
Formulation of GAN Objectives
For the generality, we adopt the formulation of Gidel et al.
(2019) in which G and D try to minimize LG and LD, respectively, to obtain the following Nash
equilibrium (Î¸âˆ—
G, Î¸âˆ—
D):
Î¸âˆ—
G âˆˆarg min
Î¸G LG (Î¸G, Î¸âˆ—
D) and Î¸âˆ—
D âˆˆarg min
Î¸D LD (Î¸âˆ—
G, Î¸D) .
(1)
For the latter part of this paper, we use a coupled parameter vector Î¸ := (Î¸G, Î¸D)âŠ¤âˆˆRdÎ¸=dG+dD
when we refer to the whole parameters of GAN.
In this paper, we assume that LG and LD have the following forms2:
LG (Î¸) := Ezâˆ¼p(z) [fG (z; Î¸)] ,
LD (Î¸) := Ezâˆ¼p(z)
h
f [z]
D (z; Î¸)
i
+ Exâˆ¼p(x)
h
f [x]
D (x; Î¸)
i
. (2)
1Code is at https://github.com/hitachi-rd-cv/influence-estimation-for-gans
2This covers the common settings of GAN objectives: the non-zero-sum game proposed by Goodfellow
et al. (2014), Wasserstein distance (Arjovsky et al., 2017), and the least squares loss (Mao et al., 2017).
2

Published as a conference paper at ICLR 2021
We can recover the original minimax objective by taking fG (z; Î¸) = log (1 âˆ’DÎ¸D (GÎ¸G (z))),
f [z]
D = âˆ’fG, and f [x]
D (x; Î¸) = âˆ’log DÎ¸D (x).
Adversarial SGD (ASGD)
To make our derivation easier to understand, we newly formulate the
parameter update of a GAN trained by stochastic gradient descent, which we call adversarial SGD
(ASGD). For simplicity, this paper considers simultaneous training, in which the generator and the
discriminator are simultaneously updated at a single step. We denote the dataset by Dx := {xn âˆ¼
p(x)}N
n=1, which consists of N data points. Let St âŠ‚{1, . . . , N} be a set of sample indices at
the t-th step. We assume that the mini-batch of the t-th step consists of instances {xi}iâˆˆSt and a
set of latent variables Zt = {z[t]
l
âˆ¼p(z)}|St|
l=1, which are sampled independently at each step t.
We denote the mean of LG and LD across the mini-batch by L G(Z; Î¸) :=
1
|Z|
P
zâˆˆZ fG (z; Î¸)
and L D(S, Z; Î¸) :=
1
|Z|
P
zâˆˆZ f [z]
D (z; Î¸) + P
iâˆˆS f [x]
D (xi; Î¸)

, respectively. The t-th step of
ASGD updates the coupled parameters by Î¸[t+1] = Î¸[t] âˆ’Btg
 St, Zt; Î¸[t]
, where
Bt :=
 
Î·[t]
G IdG
O
O
Î·[t]
D IdD
!
âˆˆRdÎ¸Ã—dÎ¸, g (S, Z; Î¸) :=

âˆ‡Î¸GL G (Z; Î¸)
âˆ‡Î¸DL D (S, Z; Î¸)

âˆˆRdÎ¸.
(3)
Î·[t]
G âˆˆR+ and Î·[t]
D âˆˆR+ are the learning rates of the t-th step for Î¸G and Î¸D, respectively.
3
PROPOSED METHOD
This section explains the two main contributions of our paper: the inï¬‚uence estimation method for
GANs that predicts how the removal of a training instance changes the output of the generator and
the discriminator (Section 3.1), and two important parts of our instance evaluation scheme, that are,
the deï¬nition of inï¬‚uence on GAN evaluation metric and its estimation algorithm (Section 3.2).
3.1
INFLUENCE ESTIMATION FOR GAN
We refer to inï¬‚uence estimation as the estimation of changes in a modelâ€™s output under a training
instanceâ€™s absence. As the modelâ€™s output changes through the changes in the modelâ€™s parameters,
we start with the deï¬nition of ASGD-Inï¬‚uence, which represents the changes in parameters, and
then formulate its estimator.
ASGD-Inï¬‚uence
ASGD-Inï¬‚uence is deï¬ned on the basis of the following counterfactual ASGD.
Let Î¸[t]
âˆ’j denote the parameters at t-th step trained without using j-th training instance. Counter-
factual ASGD starts optimization from Î¸[1]
âˆ’j = Î¸[1] and updates the parameters of the t-th step by
Î¸[t+1]
âˆ’j
= Î¸[t]
âˆ’jâˆ’Btg

St \ {j}, Zt; Î¸[t]
âˆ’j

. We deï¬ne ASGD-Inï¬‚uence âˆ†Î¸âˆ’j as the parameter differ-
ence between counterfactual ASGD and ASGD at the ï¬nal step t = T, namely âˆ†Î¸âˆ’j := Î¸[T ]
âˆ’j âˆ’Î¸[T ].
Estimator of ASGD-Inï¬‚uence
Our estimator uses an approximation of the mean of the gradi-
ent. Let
 âˆ‡Î¸GL G(Z; Î¸), âˆ‡Î¸DL D(S, Z; Î¸)
âŠ¤be the joint gradient vector of the mini-batch. We
introduce the Jacobian of the joint gradient vector of the t-th mini-batch with respect to Î¸:
Jt :=
 
J[t]
GG
J[t]
GD
J[t]
DG
J[t]
DD
!
=

âˆ‡2
Î¸GL G
 Zt; Î¸[t]
âˆ‡Î¸Dâˆ‡Î¸GL G
 Zt; Î¸[t]
âˆ‡Î¸Gâˆ‡Î¸DL D
 St, Zt; Î¸[t]
âˆ‡2
Î¸DL D
 St, Zt; Î¸[t]

.
(4)
When we assume both LG(Î¸) and LG(Î¸) are second-order differentiable with respect to Î¸, the
ï¬rst-order Taylor approximation gives g

St, Zt; Î¸[t]
âˆ’j

âˆ’g
 St, Zt; Î¸[t]
â‰ˆJt

Î¸[t]
âˆ’j âˆ’Î¸[t]
. With
this approximation, we have
Î¸[t+1]
âˆ’j
âˆ’Î¸[t+1] =

Î¸[t]
âˆ’j âˆ’Î¸[t]
âˆ’Bt

g

St, Zt; Î¸[t]
âˆ’j

âˆ’g

St, Zt; Î¸[t]
â‰ˆ(IdÎ¸ âˆ’BtJt)

Î¸[t]
âˆ’j âˆ’Î¸[t]
, âˆ€j Ì¸âˆˆSt.
(5)
3

Published as a conference paper at ICLR 2021
For simplicity,
we ï¬rst focus on 1-epoch ASGD in which each instance appears only
once.
Let Ï€ (j) be the step where the j-th instance is used.
Considering the absence of
âˆ‡Î¸Df [x]
D (xj; Î¸[Ï€(j)]) in the Ï€(j)-th step of counterfactual ASGD, we have Î¸[Ï€(j)+1]
âˆ’j
âˆ’Î¸[Ï€(j)+1] =
Î·[Ï€(j)]
D
|SÏ€(j)|

0dG, âˆ‡Î¸Df [x]
D (xj; Î¸[Ï€(j)])
âŠ¤
. By denoting Zt := IdÎ¸ âˆ’BtJt and recursively applying
the approximation (5), we obtain
âˆ†Î¸âˆ’j â‰ˆÎ·[Ï€(j)]
D
|SÏ€(j)|ZT âˆ’1ZT âˆ’2 Â· Â· Â· ZÏ€(j)+1

0dG
âˆ‡Î¸Df [x]
D
 xj; Î¸[Ï€(j)]

.
(6)
For the practical situation of K-epoch ASGD, in which the j-th instance is sampled K times at
t = Ï€1 (j) , . . . , Ï€K (j), the estimator of the ASGD-Inï¬‚uence is given by
âˆ†Ë†Î¸âˆ’j :=
K
X
k=1
ï£«
ï£­
T âˆ’Ï€k(j)âˆ’1
Y
s=1
ZT âˆ’s
ï£¶
ï£¸Î·[Ï€k(j)]
D
|SÏ€k(j)|

0dG
âˆ‡Î¸Df [x]
D
 xj; Î¸[Ï€k(j)]

.
(7)
Linear Inï¬‚uence
To estimate the inï¬‚uence on outputs, we introduce linear inï¬‚uence L[T ]
âˆ’j(u) :=
âŸ¨u, âˆ†Î¸âˆ’jâŸ©of a given query vector u âˆˆRdÎ¸. If we take u = âˆ‡Î¸fG
 z; Î¸[T ]
, the linear inï¬‚uence
approximates the inï¬‚uence on the generatorâ€™s loss L[T ]
âˆ’j(u) â‰ˆfG

z; Î¸[T ]
âˆ’j

âˆ’fG
 z; Î¸[T ]
.
Let

u[t]âŠ¤
G
âˆˆRdG, u[t]âŠ¤
D
âˆˆRdD

:= uâŠ¤ZT âˆ’1ZT âˆ’2 Â· Â· Â· Zt+1. The linear inï¬‚uence of the j-th in-
stance is approximated by the proposed estimator:
L[T ]
âˆ’j (u) â‰ˆ
D
u, âˆ†Ë†Î¸âˆ’j
E
=
K
X
k=1
Î·[Ï€k(j)]
D
|SÏ€k(j)|
D
u[Ï€k(j)]
D
, âˆ‡Î¸Df [x]
D

xj; Î¸[Ï€k(j)]E
.
(8)
The estimation algorithm consists of two phases; training phase performs K-epoch ASGD
by storing information A[t] â†(St, Î·[t]
G , Î·[t]
D , Î¸[t], Zt) and inference phase calculates (8) using
A[1], . . . , A[T âˆ’1]. See Appendix A for the detailed algorithm.
3.2
INFLUENCE ON GAN EVALUATION METRIC
This section explains our proposal of a new evaluation approach for data screening for GANs. Firstly
we propose to evaluate harmfulness of an instance on the basis of inï¬‚uence on GAN evaluation
metrics. Secondly we propose to leverage the inï¬‚uence-estimation algorithm explained in Section
3.1 to identify harmful instances with respect to the GAN evaluation metrics.
Inï¬‚uence on GAN Evaluation Metric
Let V (D) be a GAN evaluation metric that maps a set
of data points D := {Ëœxm âˆˆRdx}M
m=1 into a scalar value that gives the performance measure of
G. Let generated dataset DG(Z; Î¸G) := {G(z; Î¸G)| z âˆˆZ}. Using a set of latent variables
Z := {Ëœzm âˆ¼p(z)}M
n=1 that is sampled independently from the training, we deï¬ne the inï¬‚uence on
GAN evaluation metric by
âˆ†V [T ]
âˆ’j := V

DG

Z; Î¸[T ]
G,âˆ’j

âˆ’V

DG

Z; Î¸[T ]
G

,
(9)
where Î¸[T ]
G,âˆ’j and Î¸[T ]
G are the generator parameters of counterfactual ASGD and the ASGD of the
T-th step, respectively.
Estimation Algorithm
In order to build the estimation algorithm of the inï¬‚uence on GAN evalu-
ation metric, we focus on an important property of some common evaluation metrics for which the
gradient with respect to the element of their input âˆ‡ËœxmV (D) is computable. For example, Monte
Carlo estimation of inception score has a form of exp( 1
|D|
P
ËœxmâˆˆD KL(pc(y|Ëœxm)âˆ¥pc(y)) where pc
is a distribution of class label y drawn by a pretrained classiï¬er. When the classiï¬er is trained using
back-propagation, âˆ‡ËœxmV (D) is computable.
4

Published as a conference paper at ICLR 2021
Here, we assume V (D) is ï¬rst-order differentiable with respect to Ëœxm. From the chain rule, we have
a gradient of the GAN evaluation metrics with respect to Î¸:
âˆ‡Î¸V (DG(Z; Î¸[T ]
G )) =
 PM
n=1 âˆ‡Î¸Gâˆ‡ËœxnV

DG

Z; Î¸[T ]
G

0dD
!
.
(10)
Our estimation algorithm performs the inference phase of linear inï¬‚uence taking u
=
âˆ‡Î¸V (DG(Z; Î¸[T ]
G )) in order to obtain the approximation L[T ]
âˆ’j(âˆ‡Î¸V (DG(Z; Î¸[T ]
G ))) â‰ˆâˆ†V [T ]
âˆ’j .
4
RELATED STUDIES
SGD-Inï¬‚uence
Hara et al. (2019) proposed a novel deï¬nition of the inï¬‚uence called SGD-
Inï¬‚uence and its estimator, which greatly inspired us to propose the inï¬‚uence estimation method
for GANs. Suppose a machine learning model with parameters Ï† âˆˆRdÏ† is trained to minimize
the mean of the loss 1
N
PN
n=1 L (Ï‡n; Ï†) across the training instances Ï‡1, . . . , Ï‡N. Let the mean of
the loss of the mini-batch L (S; Ï†) :=
1
|S|
P
iâˆˆS L (Ï‡i; Ï†). They introduced two SGD steps with
learning rate Î·t âˆˆR+: SGD given by Ï†[t+1] = Ï†[t] âˆ’Î·tâˆ‡Ï†L
 St; Ï†[t]
, and counterfactual SGD
given by Ï†[t+1]
âˆ’j
= Ï†[t]
âˆ’j âˆ’Î·tâˆ‡Ï†L

St \ {j} ; Ï†[t]
âˆ’j

. Their estimator of SGD-Inï¬‚uence Ï†[T ]
âˆ’j âˆ’Ï†[T ]
is based on the following approximation:
Ï†[t+1]
âˆ’j
âˆ’Ï†[t+1] â‰ˆ

IdÏ† âˆ’Î·tâˆ‡2
Ï†L

St; Ï†[t] 
Ï†[t]
âˆ’j âˆ’Ï†[t]
, âˆ€j Ì¸âˆˆSt.
(11)
Hara et al. (2019) also identiï¬ed harmful instances for classiï¬cation based on linear inï¬‚uence of the
cross-entropy loss estimated using a validation dataset. Removing the estimated harmful instances
with their approach demonstrated improvements in the classiï¬cation accuracy.
Our approach differs from Hara et al. (2019)â€™s work in two ways. Firstly, our approach uses the
Jacobian of the joint gradient vector Jt instead of the Hessian of the mean loss âˆ‡2
Ï†L
 St; Ï†[t]
. As
long as LG Ì¸= LD, Jt is asymmetric and inherently different from the Hessian. Moreover, a source
of the asymmetry J[t]
GD plays an important role in transferring the effect of removal of a training
instance from the discriminator to the generator. Let Î¸[t]
G,âˆ’j âˆ’Î¸[t]
G âˆˆRdG and Î¸[t]
D,âˆ’j âˆ’Î¸[t]
D âˆˆRdD
be ASGD-Inï¬‚uence on Î¸G and Î¸D of the t-th step, respectively. The upper blocks of (5) can be
rewritten as
Î¸[t+1]
G,âˆ’j âˆ’Î¸[t+1]
G
â‰ˆ

IdD âˆ’Î·[t]
G J[t]
GG
 
Î¸[t]
G,âˆ’j âˆ’Î¸[t]
G

+ Î·[t]
G J[t]
GD

Î¸[t]
D,âˆ’j âˆ’Î¸[t]
D

.
(12)
Note that J[t]
GD transfers the t-th step of ASGD-Inï¬‚uence on Î¸D to the next step of ASGD-Inï¬‚uence
on Î¸G. The Hessian of Hara et al. (2019), which uses a single combination of the parameters and the
loss function, cannot handle this transfer between the two models. Secondly, we use the inï¬‚uence
on GAN evaluation metrics for identifying harmful instances rather than that on the loss value. This
alleviates the problem of the GANâ€™s loss not representing the generative performance.
Inï¬‚uence Function
Koh & Liang (2017) proposed inï¬‚uence estimation method that incorporated
the idea of inï¬‚uence function (Cook & Weisberg, 1980) in robust statistics. They showed that
inï¬‚uences on parameters and predictions can be estimated with the inï¬‚uence function assuming
the satisfaction of the optimality condition and strong convexity of the loss function. They also
identiï¬ed harmful instances on the basis of the inï¬‚uence on the loss value, assuming consistency of
the loss value with the task performance.
Our inï¬‚uence estimation method is designed to eliminate these assumptions because normally GAN
training does not satisfy the assumptions regarding the optimality condition, the convexity in the
loss function, and the consistency of the loss value with the performance.
5
EXPERIMENTS
We evaluated the effectiveness of the proposed method in two aspects: the accuracy of inï¬‚uence es-
timation on GAN evaluation metrics (Section 5.1), and the improvement in generative performance
by removing estimated harmful instances (Section 5.2)
5

Published as a conference paper at ICLR 2021
GAN Evaluation Metrics
In both experiments, we used three GAN evaluation metrics: aver-
age log-likelihood (ALL), inception score (IS), and FrÂ´echet inception distance (FID) (Heusel et al.,
2017). ALL is the de-facto standard for evaluating generative models (Tolstikhin et al., 2017). Let
Zâ€² := {zâ€²
n âˆ¼p(z)}N â€²
n=1 and Dâ€²
x := {xâ€²
n âˆ¼p(x)}N â€²
n=1, which is sampled separately from p(z) and
the training dataset Dx, respectively. ALL measures the likelihood of the true data under the distri-
bution that is estimated from generated data using kernel density estimation. We calculated ALL of
Dâ€²
x under the distribution estimated from generated dataset DG(Zâ€²; Î¸[T ]
G ). Recall Zâ€² is the set of la-
tent variables sampled independently from the training (Section 3.2). FID measures FrÂ´echet distance
between two sets of feature vectors of real images Dâ€²
x and those of generated images DG(Zâ€²; Î¸[T ]
G ).
The feature vectors are calculated on the basis of a pre-trained classiï¬er. Larger values of ALL and
IS and a smaller value of FID indicate the better generative performance. See Appendix C.1 for the
detailed setting of each GAN evaluation metric.
5.1
EXPERIMENT 1: ESTIMATION ACCURACY
We ran the inï¬‚uence estimation method on GANs to estimate inï¬‚uence on various GAN evaluation
metrics, and then compared the estimated inï¬‚uence with true inï¬‚uence. The detailed setup can be
found in Appendix C.2.
Setup
ALL is known to be effective for low-dimensional data distributions (Borji, 2019) and both
FID and IS are effective for image distributions. We thus prepared two different setups: fully-
connected GAN (FCGAN) trained with 2D multivariate normal distribution (2D-Normal) for ALL,
and DCGAN (Radford et al., 2016) trained with MNIST (LeCun et al., 1998) for IS and FID. IS and
FID require classiï¬ers to obtain class label distribution and feature vectors, respectively. We thus
trained CNN classiï¬er of MNIST3 using Dâ€²
x. We set N = 10k and N â€² = |Dâ€²
x| = |Zâ€²| = 10k.
The experiment was conducted as follows. Firstly, we ran the K-epoch of the training phase of
linear inï¬‚uence with the training dataset Dx. We determined K = 50 since we observed the con-
vergence of GAN evaluation metrics at K = 50. For IS and FID, we trained the classiï¬er using Dâ€²
x
and corresponding labels. We then randomly selected 200 target instances from Dx. We obtained
estimated inï¬‚uence on GAN evaluation metrics of each target instance by performing the inference
phase of linear inï¬‚uence with u = âˆ‡Î¸V (DG(Zâ€²; Î¸[T ]
G )). The true inï¬‚uence of each target instance
was computed by running the counterfactual ASGD.
We used the same evaluation measures as the previous work (Hara et al., 2019): Kendallâ€™s Tau and
the Jaccard index. Kendallâ€™s Tau measures the ordinal correlation between the estimated and true
inï¬‚uence on GAN evaluation metrics. It has a value of 1 when the orders of the two sets of values
are identical. For the Jaccard index, we selected 10 instances with the largest positive and largest
negative inï¬‚uence values to construct a set of 20 critical instances. The Jaccard index is equal to 1
when a set of estimated critical instances is identical to that of true critical instances.
To investigate the relationship between a number of tracing back steps and the estimation accuracy,
we also evaluated the inï¬‚uence on GAN evaluation metrics of k-epoch ASGD. In k-epoch training,
both inference phase of linear inï¬‚uence and the counterfactual ASGD traced back only k â‰¤K
epochs from the latest epoch K. We varied k = 1, 5, 10, 20, 50 and ran the experiment ten times for
each k by changing the random seeds of the experiments.
Results
Figure 1 shows the average Kendalâ€™s Tau and the Jaccard index of the repeated experi-
ments. Hereinafter, we use p < .05 to judge the statistical signiï¬cance of the results. For all k,
Kendallâ€™s Tau and the Jaccard index of estimated inï¬‚uence on ALL were statistically signiï¬cantly
better than the result in which the order of estimated inï¬‚uence values were random (random case).
Even in the more difï¬cult setups of IS and FID, which handled the high-dimensional dataset and
complex architecture, the results were statistically signiï¬cantly better than that of the random case
except for Jaccard index of IS with k = 50. We also observed the estimation accuracy dropped as
k increased. This reï¬‚ects the nature of our estimator that recursively performs linear approximation
3Although the original IS and FID use Inception Net (Szegedy et al., 2016) trained with ImageNet, we
instead adopted a domain-speciï¬c classiï¬er as encouraged by several studies (Zhou et al., 2018; Liu et al.,
2018) to alleviate the domain mismatch with ImageNet.
6

Published as a conference paper at ICLR 2021
Influence on ALL
Influence on IS
Influence on FID
Random
0
10
20
30
40
50
# of tracing back epochs k
0.2
0.0
0.2
0.4
0.6
0.8
1.0
Kendal's Tau
0
10
20
30
40
50
# of tracing back epochs k
0.2
0.4
0.6
0.8
Jaccard index
Figure 1: Average Kendallâ€™s Tau (Â±std) (left) and the Jaccard index (Â±std) (right) calculated from
true and estimated inï¬‚uence on ALL, IS, and FID.
as many times as the number of steps. We thus conclude that when the required number of tracing
back steps is small enough, our inï¬‚uence estimation method is effective and the estimated inï¬‚uence
on GAN evaluation metric is useful for identifying harmful instances.
5.2
EXPERIMENT 2: DATA CLEANSING
We investigated if removing identiï¬ed harmful instances actually improved the generative perfor-
mance to evaluate the effectiveness of our proposed method for data cleansing. We deï¬ne data
cleansing as an attempt to improve GAN evaluation metrics by removing a set of training instances.
See appendix C.3 for the detailed settings.
Setup
We studied the data cleansing for the two setups explained in the previous section: 2D-
Normal with FCGAN and MNIST with DCGAN. We mostly followed the settings of Section 5.1
but set training dataset size N = 50k for both setups.
We identiï¬ed harmful instances in 2D-Normal training dataset using estimated inï¬‚uence on ALL,
and those in MNIST using estimated inï¬‚uence on IS and FID. We considered a training instance
was harmful when it had negative (positive) inï¬‚uence on FID (ALL or IS).
For both setups, we also selected instances using baseline approaches: anomaly detection method,
inï¬‚uence on the discriminator loss, and random values. For anomaly detection, we adopted isolation
forest (Liu et al., 2008). Isolation forest ï¬tted the model using the data points of Dx for 2D-Normal
and feature vectors of the classiï¬er of Dx for MNIST. We adopted the selection based on the in-
ï¬‚uence on the discriminator loss to verify our assumption that the inï¬‚uence on the loss does not
represent the harmfulness of the instances. Inï¬‚uence on the discriminator loss was calculated on
the expected loss of LD (Î¸) with DG(Zâ€²; Î¸[T ]
G ) and Dâ€²
x. We considered instances with negative
inï¬‚uence were harmful.
We conducted the experiments as follows. After the training phase of K epoch, we determined
nh < N harmful instances with the proposed approach and baselines. Then, we ran counterfactual
ASGD with the determined harmful instances excluded. For the reliable estimation accuracy of
inï¬‚uence and reasonable costs of the computation and storage, the inference phase traced back only
1-epoch from the last epoch, and counterfactual ASGD only re-ran the latest epoch. We tested with
various nh.
We refer to the generator of the ï¬nal model as the cleansed generator and denote its parameters by
Î¸â‹†
G. We evaluated the cleansed generator with test GAN evaluation metrics V (DG(Ztest); Î¸â‹†
G)), in
which a set of test latent variables Ztest was obtained by sampling Ntest times from p(z) indepen-
dently from Zâ€² and Z1, . . . , ZT . Test ALL and FID used a test dataset Dtest := {x[n]
test âˆ¼p(x)}Ntest
n=1
that consists of instances newly sampled from 2D-Normal and instances in the original test dataset
of MNIST, respectively. We set Ntest = 10k and ran the experiment 15 times with different random
seeds.
7

Published as a conference paper at ICLR 2021
Influence on ALL (Ours)
Influence on IS (Ours)
Influence on FID (Ours)
Isolation Forest
Influence on Disc. Loss
Random
No Removal
103
104
# of instances removed nh
-2.88
-2.88
-2.87
-2.87
-2.87
-2.87
Average Log Likelihood
(a)
103
104
# of instances removed nh
5.65
5.70
5.75
5.80
5.85
5.90
5.95
Inception Score
(b)
103
104
# of instances removed nh
1.50
1.60
1.70
1.80
1.90
2.00
2.10
2.20
FrÃ©chet Inception Distance
(c)
Figure 2: Average test ALL (a), IS (b), and FID (c) after the data cleansing. Larger values in (a)
and (b), a smaller value in (c) indicate the better generative performance. Error bars and plots of too
large or small values are omitted for better visibility. See Appendix C.3 for full results.
Quantitative Results
Figure 2 shows the average test GAN evaluation metrics of the repeated ex-
periments for each selection approach. For the data cleansing on 2D-Normal, the proposed approach
with inï¬‚uence on ALL showed statistically signiï¬cant improvement from the original model and it
outperformed the baselines (Figure 2a). For the MNIST setup, our approach with inï¬‚uence on FID
and IS statistically signiï¬cantly improved FID (Figure 2c) and IS (Figure 2b), respectively. They
also outperformed the baselines. In addition, the results indicate that data cleansing based on the
inï¬‚uence on a speciï¬c GAN evaluation metric is also effective for another metric that is not used
for the selection; removing harmful instances based on the inï¬‚uence on FID (IS) statistically signiï¬-
cantly improved IS (FID). However, we make no claim that the proposed method can improve all the
other evaluation metrics, such as Kullback-Leibler divergence. This is because all the current GAN
evaluation metrics have their own weaknesses (e.g., IS fails to detect whether a model is trapped
into one bad mode (Zhou et al., 2018)), and the proposed method based on those GAN evaluation
metrics cannot inherently avoid their weaknesses. These improvements thus can be observed only in
a subclass of GAN evaluation metrics. Further evaluation of data cleansing with our method should
incorporate the future improvements of the GAN evaluation metrics.
While the improvements were smaller than the proposed approach, we also observed that data
cleansing based on the inï¬‚uence on the discriminator loss improved all the GAN evaluation metrics.
This counter-intuitive result indicates that the discriminator loss weakly measures the performance
of the generator that is trained along with the discriminator.
Qualitative Results
We examined the characteristics of instances that were evaluated to be harm-
ful by our method. Overall, we observed that our method tends to judge instances as harmful when
they belong to regions from which the generators sample too frequently compared to the true dis-
tribution. Figure 3 shows the estimated harmfulness of the training instances of 2D-Normal and
the distribution of the generated samples. The proposed approach with inï¬‚uence on ALL evaluated
the instances around lower-left and upper-right regions to be harmful (Figure 3a). These regions
correspond to the regions where the generated distribution has higher density than that of the true
distribution (Figure 3b â€œNo removalâ€ and â€œTrueâ€). Similar characteristics were seen in harmful
8

Published as a conference paper at ICLR 2021
(a) Harmful instances
(b) Generated distribution
Figure 3: Harmfulness of 2D-Normal instances suggested using inï¬‚uence on ALL (a) and changes
in the generatorâ€™s distribution (b). (b) includes plots of the true distribution (True) and generatorâ€™s
distributions before (No removal) and after (Cleansed) the data cleansing with nh = 5.0k.
(a) Harmful
(b) No removal
(c) Cleansed
Figure 4: Top 36 harmful MNIST instances predicted on the basis of inï¬‚uence on FID (a), and the
test generated samples before (b) and after (c) the data cleansing with nh = 25.0k. (a) and (b) use
the same series of test latent variables in Ztest.
MNIST instances suggested by our approach with inï¬‚uence on FID. A large number of samples
from class 1 were regarded as harmful as shown in Figure 4a, when the generator sampled images
of the digit 1 too frequently (Figure 4b).
We also investigated how the data cleansing by our approach visually changed the generated sam-
ples. As seen from the distributions in Figure 3b, the probability density in the upper-right region
decreased after the data cleansing (from â€œNo removalâ€ to â€œCleansedâ€). As a result, the generator
distribution moved closer to the true distribution. The same effect was observed in a visually more
interesting form in the data cleansing for MNIST. The generated samples originating from some
latent variables changed from the image of digit 1 to that of other digits after the data cleansing
based on the estimated inï¬‚uence on FID (highlighted samples in Figure 4c). We suppose this effect
improved the diversity in the generated samples, resulting in better FID and IS.
6
CONCLUSION
We proposed an inï¬‚uence estimation method for GAN that uses the Jacobian of the gradient of
the discriminatorâ€™s loss with respect to the generatorâ€™s parameters (and vice versa), which traces
how the absence of an instance in the discriminatorâ€™s training affects the generatorâ€™s parameters.
We also proposed a novel evaluation scheme to judge if an instance is harmful or not on the basis
of the inï¬‚uence on GAN evaluation metrics rather than that on the loss value, and to leverage the
proposed inï¬‚uence estimation method to identify harmful instances. We experimentally veriï¬ed that
estimated and true inï¬‚uence on GAN evaluation metrics had a statistically signiï¬cant correlation.
We also demonstrated removing identiï¬ed harmful instances effectively improved the generative
performance with respect to various GAN evaluation metrics.
9

Published as a conference paper at ICLR 2021
REFERENCES
Antreas Antoniou, Amos Storkey, and Harrison Edwards. Data augmentation generative adversarial
networks. arXiv preprint arXiv:1711.04340, 2017.
Martin Arjovsky, Soumith Chintala, and LÂ´eon Bottou. Wasserstein generative adversarial networks.
In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 214â€“
223, 2017.
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint
arXiv:1607.06450, 2016.
Ashish Bora, Eric Price, and Alexandros G. Dimakis. AmbientGAN: Generative models from lossy
measurements. In International Conference on Learning Representations, 2018.
Ali Borji. Pros and cons of gan evaluation measures. Computer Vision and Image Understanding,
179:41â€“65, 2019.
Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and JÂ¨org Sander. Lof: identifying density-
based local outliers. In Proceedings of the 2000 ACM SIGMOD international conference on
Management of data, pp. 93â€“104, 2000.
R Dennis Cook and Sanford Weisberg. Characterizations of an empirical inï¬‚uence function for
detecting inï¬‚uential cases in regression. Technometrics, 22(4):495â€“508, 1980.
Gauthier Gidel, Hugo Berard, GaÂ¨etan Vignoud, Pascal Vincent, and Simon Lacoste-Julien. A varia-
tional inequality perspective on generative adversarial networks. In International Conference on
Learning Representations, 2019.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information
processing systems, 27:2672â€“2680, 2014.
Satoshi Hara, Atsushi Nitanda, and Takanori Maehara. Data cleansing for models trained with sgd.
In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'AlchÂ´e-Buc, E. Fox, and R. Garnett (eds.),
Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
Gans trained by a two time-scale update rule converge to a local nash equilibrium. In Advances
in neural information processing systems, pp. 6626â€“6637, 2017.
Peter J Huber. Robust statistics, volume 523. John Wiley & Sons, 2004.
Takuhiro Kaneko and Tatsuya Harada. Noise robust generative adversarial networks. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8404â€“8414, 2020.
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyz-
ing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pp. 8110â€“8119, 2020.
Rajiv Khanna, Been Kim, Joydeep Ghosh, and Sanmi Koyejo. Interpreting black box predictions
using ï¬sher kernels. In The 22nd International Conference on Artiï¬cial Intelligence and Statistics,
pp. 3382â€“3390. PMLR, 2019.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua Bengio
and Yann LeCun (eds.), 3rd International Conference on Learning Representations, ICLR 2015,
San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015.
Pang Wei Koh and Percy Liang. Understanding black-box predictions via inï¬‚uence functions. In
International Conference on Machine Learning, pp. 1885â€“1894. PMLR, 2017.
Yann LeCun, LÂ´eon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278â€“2324, 1998.
10

Published as a conference paper at ICLR 2021
Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Alejandro
Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, and Wenzhe Shi. Photo-
realistic single image super-resolution using a generative adversarial network. In Proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017.
Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. Isolation forest. In 2008 Eighth IEEE Interna-
tional Conference on Data Mining, pp. 413â€“422. IEEE, 2008.
Shaohui Liu, Yi Wei, Jiwen Lu, and Jie Zhou. An improved evaluation framework for generative
adversarial networks. arXiv preprint arXiv:1803.07474, 2018.
Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang, and Stephen Paul Smolley.
Least squares generative adversarial networks. In Proceedings of the IEEE international confer-
ence on computer vision, pp. 2794â€“2802, 2017.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep
convolutional generative adversarial networks. In Yoshua Bengio and Yann LeCun (eds.), 4th
International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May
2-4, 2016, Conference Track Proceedings, 2016.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen, and
Xi Chen. Improved techniques for training gans. In D. D. Lee, M. Sugiyama, U. V. Luxburg,
I. Guyon, and R. Garnett (eds.), Advances in Neural Information Processing Systems 29, pp.
2234â€“2242. Curran Associates, Inc., 2016.
Bernhard SchÂ¨olkopf, John C Platt, John Shawe-Taylor, Alex J Smola, and Robert C Williamson.
Estimating the support of a high-dimensional distribution. Neural computation, 13(7):1443â€“1471,
2001.
C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the inception architecture
for computer vision. In 2016 IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 2818â€“2826, 2016.
Ilya O Tolstikhin, Sylvain Gelly, Olivier Bousquet, Carl-Johann Simon-Gabriel, and Bernhard
SchÂ¨olkopf. Adagan: Boosting generative models. In Advances in Neural Information Processing
Systems, pp. 5424â€“5433, 2017.
Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill Freeman, and Josh Tenenbaum. Learning a prob-
abilistic latent space of object shapes via 3d generative-adversarial modeling.
In D. D. Lee,
M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett (eds.), Advances in Neural Information
Processing Systems 29, pp. 82â€“90. Curran Associates, Inc., 2016.
Zhiming Zhou, Han Cai, Shu Rong, Yuxuan Song, Kan Ren, Weinan Zhang, Jun Wang, and Yong
Yu. Activation maximization generative adversarial nets. In International Conference on Learning
Representations, 2018.
11

Published as a conference paper at ICLR 2021
Algorithm 1 Training Phase
Initialize the parameter Î¸[1]
Initialize the sequence as null: A â†âˆ…
for t = 1, 2, . . . , T âˆ’1 do
// sample latent variables
Zt = {z[t]
l
âˆ¼p(z)}|St|
l=1
// store information
A[t] â†

St, Î·[t]
G , Î·[t]
D , Î¸[t], Zt

// update parameters
Î¸[t+1] = Î¸[t] âˆ’Btg
 St, Zt; Î¸[t]
end for
Algorithm 2 Inference Phase
Require: u =
 uG âˆˆRdG, uD âˆˆRdDâŠ¤
Initialize the inï¬‚uence: L[T ]
âˆ’j (u) â†0
for t = T âˆ’1, T âˆ’2, . . . , 1 do
// load information

St, Î·[t]
G , Î·[t]
D , Î¸[t], Zt

â†A[t]
// update the linear inï¬‚uence of jth instance
if j âˆˆSt then
L[T ]
âˆ’j (u) += Î·[t]
D
|St|
D
uD, âˆ‡Î¸Df [x]
D (xj; Î¸[t])
E
end if
// update u
u âˆ’= uâŠ¤BtJt
end for
A
ALGORITHM FOR LINEAR INFLUENCE
The proposed estimation algorithm for linear inï¬‚uence, which is explained in Section 3.1, is divided
into the training phase (Algorithm 1) and inference phase (Algorithm 2).
The training phase executes ASGD training while storing the mini-batch indices St, the learning
rate Î·[t]
G , Î·[t]
D , the parameters Î¸[t] and the sampled latent variable Zt into the information A[t] at each
step.
In the inference phase, L[T ]
âˆ’j (u) is estimated by the recursive calculation. First, we set L[T ]
âˆ’j (u)
to 0 and set the query vector u. The information A[t], which is obtained in the training phase, is
read in the order of t = T âˆ’1, T âˆ’2, . . . , 1. When j âˆˆSt, L[T ]
âˆ’j(u) is updated using (8). Let
ut =

u[t]
G , u[t]
D
âŠ¤
. Each step updates u based on ut+1 = uâŠ¤
t Zt = uâŠ¤
t (IdÎ¸ âˆ’BtJt). A naive
calculation of uâŠ¤
t Jt requires O
 d2
Î¸

memory to store the matrix Jt, which can be prohibitive for
very large models. We can avoid this difï¬culty by directly computing uâŠ¤
t Jt without the explicit
computation of Jt. Because uâŠ¤
t Jt = âˆ‡Î¸

ut, (âˆ‡Î¸GL G, âˆ‡Î¸DL D)âŠ¤
, we need only to compute
the derivative of the inner product of ut and the joint gradient vector.
Our algorithm also covers the alternating gradient descent, in which the two models alternatively
update their parameters at each step. By taking Î·[t]
G and Î·[t]
D such that they alternatively take 0 at
each step, we can have ASGD and the estimator of ASGD-Inï¬‚uence for the alternating gradient
descent. The implementation of linear inï¬‚uence for the alternating gradient descent is available in
our repository4.
B
OTHER RELATED WORKS
Anomaly Detection
A typical approach for identifying harmful instances is outlier detection. Out-
lier detection is used to remove abnormal instances from the training set before training the model
to ensure that the model is not affected by the abnormal instances. For tabular data, there are several
popular methods, such as One-class support vector machine (SchÂ¨olkopf et al., 2001), local outlier
factor (Breunig et al., 2000), and isolation forest (Liu et al., 2008). Although these methods can ï¬nd
abnormal instances, they are not necessarily harmful for the resulting models, as we showed in the
experiment.
Training GAN from Noisy Images
One typical type of data that harm generative performance is
noisy images. AmbientGAN (Bora et al., 2018) and noise-robust GAN (Kaneko & Harada, 2020)
4https://github.com/hitachi-rd-cv/influence-estimation-for-gans
12

Published as a conference paper at ICLR 2021
Table 1: Model architecture of CNN classiï¬er of MNIST in Section 5.1 and 5.2.
Stage
Operation
Stride
Filter Shape
Bias
Norm.
Activation
Output
0
Input
-
-
-
-
-
[28, 28, 1]
1
Conv2D
1
[5, 5]
âœ“
-
Sigmoid
[25, 25, 8]
2
Conv2D
1
[5, 5]
âœ“
-
Sigmoid
[12, 12, 8]
3
MaxPooling
2
[2, 2]
-
-
Sigmoid
[392]
4
Linear
1
-
âœ“
-
Sigmoid
[128]
5
Linear
1
-
âœ“
-
Sigmoid
[10]
are learning algorithms that make it possible to train a clean image generator from noisy images. The
difference between these studies and ours is that these studies assume that the noise (e.g., Gaussian
noise on pixels) given independently from the data distribution of the clean images is the only
problem. However, some instances can affect the performance even if the instances are drawn only
from the data distribution, which is the case robust statistics (Huber, 2004) typically focuses on. Our
experiment 5.2 indicates that the model performance depends not only on noisy images but also on
a non-negligible number of harmful instances in the original dataset.
C
DETAILED EXPERIMENTAL SETTINGS AND RESULTS
C.1
GAN EVALUATION METRICS
We adopted Gaussian kernel with the band-width 1 for kernel density estimation used in ALL. The
architecture of CNN classiï¬er of MNIST used for IS and FID can be found in Table 1. We selected
the output of the 4th layer for the feature vectors for FID.
C.2
EXPERIMENT 1: ESTIMATION ACCURACY
Setup
In the experiment of Section 5.1, we adopted the hyper parameters shown in Table 2. We
trained fullly-connected GAN (FCGAN) for 2D multivariate normal distribution, in which the both
G and D has 1 hidden layer of hG and hD units, respectively (Table 3). 2D-Normal is given by
N(Âµ, Î£), in which the mean vector Âµ = 12 and the covariance matrix Î£ = ((1, 0.8) , (0.8, 1))âŠ¤.
DCGAN consists of transposed convolution (or deconvolution) layers and convolution layers (Ta-
ble 4). The channels of the both layers in G and D were determined by hG and hD, respectively.
We used Layer Normalization (Ba et al., 2016) for the layers shown in Table 4 for the stability of
the training. We also introduced the L2-norm regularization with the rate Î³ âˆˆR+ for all the ker-
nels of both FCGAN and DCGAN. We used the non-zero-sum game objective of the original paper
(Goodfellow et al., 2014) in which G tries to minimize âˆ’DÎ¸D (GÎ¸G (z)) for both models.
C.3
EXPERIMENT 2: DATA CLEANSING
Setup
We adopted the same architecture as the Section 5.1 (Table 3) for FCGAN and slightly
different architecture (Table 4) in which hG and hD are larger (Table 5) for DCGAN. Other hy-
per parameters followed Table 5. We also provide visual explanations of the data settings in the
experiments with inï¬‚uence on ALL, IS, and FID in Figure 5, 6, and 7, respectively.
Results
Table 6-8 show the detailed results of Figure 2. And they clarify with which nh and
selection approach the test GAN evaluation metrics were statistically signiï¬cantly improved.
13

Published as a conference paper at ICLR 2021
Table 2: Hyper parameters in Section 5.1.
K
Î·[t]
G
Î·[t]
D
N
N â€²
St
Î³
hG
hD
2D-Normal
50
10âˆ’3
10âˆ’3
10k
10k
100
10âˆ’3
32
64
MNIST
50
10âˆ’3
10âˆ’3
10k
10k
100
10âˆ’3
8
8
Table 3: Model Architecture of FCGAN in Section 5.1 and 5.2.
Net.
Stage
Operation
Bias
Activation
Output
-
0
Input
-
-
[10]
G
1
Linear
âœ“
ReLU
[hG]
G
2
Linear
âœ“
Tanh
[2]
D
3
Linear
âœ“
ReLU
[hD]
D
4
Linear
âœ“
Sigmoid
[1]
Table 4: Model Architecture of DCGAN in Section 5.1 and 5.2.
Net.
Stage
Operation
Stride
Filter Shape
Bias
Norm.
Activation
Output
-
0
Input
-
-
-
-
-
[32]
G
1
Deconv2D
1
[2, 2]
âœ“
âœ“
Sigmoid
[2, 2, hG]
G
2
Deconv2D
1
[3, 3]
âœ“
âœ“
Sigmoid
[4, 4, hG]
G
3
Deconv2D
2
[3, 3]
âœ“
âœ“
Sigmoid
[9, 9, hG]
G
4
Deconv2D
1
[2, 2]
âœ“
âœ“
Sigmoid
[10, 10, hG]
G
5
Deconv2D
1
[3, 3]
âœ“
âœ“
Sigmoid
[12, 12, hG]
G
6
Deconv2D
2
[3, 3]
âœ“
âœ“
Sigmoid
[25, 25, hG]
G
7
Deconv2D
1
[4, 4]
âœ“
âœ“
Sigmoid
[28, 28, hG]
G
8
Conv2D
1
[1, 1]
âœ“
-
Tanh
[28, 28, 1]
D
9
Conv2D
1
[4, 4]
âœ“
âœ“
Sigmoid
[25, 25, hD]
D
10
Conv2D
2
[3, 3]
âœ“
âœ“
Sigmoid
[12, 12, hD]
D
11
Conv2D
1
[3, 3]
âœ“
âœ“
Sigmoid
[10, 10, hD]
D
12
Conv2D
1
[2, 2]
âœ“
âœ“
Sigmoid
[9, 9, hD]
D
13
Conv2D
2
[3, 3]
âœ“
âœ“
Sigmoid
[4, 4, hD]
D
14
Conv2D
1
[3, 3]
âœ“
âœ“
Sigmoid
[2, 2, hD]
D
15
Conv2D
1
[2, 2]
âœ“
âœ“
Sigmoid
[1, 1, hD]
D
16
Linear
-
-
âœ“
-
Sigmoid
[1]
Table 5: Hyper parameters in Section 5.2.
K
Î·[t]
G
Î·[t]
D
N
N â€²
Ntest
St
Î³
hG
hD
2D-Normal
70
10âˆ’3
10âˆ’3
50k
10k
10k
100
10âˆ’3
32
64
MNIST
20
10âˆ’3
10âˆ’3
50k
10k
10k
100
10âˆ’3
32
32
14

Published as a conference paper at ICLR 2021
Dataset 
for training
ğ’Ÿğ’™
Remove top  ğ‘›â„
harmful instances
Counterfactual ASGD 
training
ASGD
training
ğœ½ğº
ğ‘‡
ğœ½ğº
â‹†
Cleansed training dataset
Dataset
for influence 
estimation
ğ’Ÿğ’™â€²
Dataset
for test 
ğ’Ÿğ‘¡ğ‘’ğ‘ ğ‘¡
Evaluate test ALL  of 
the original  generator
(No removal)
ğ‘‰ğ’Ÿğºğ’µğ‘¡ğ‘’ğ‘ ğ‘¡;ğœ½ğº
ğ‘‡
;ğ’Ÿğ‘¡ğ‘’ğ‘ ğ‘¡
Evaluate test ALL  of 
the cleansed generator
(Cleansed)
ğ‘‰ğ’Ÿğºğ’µğ‘¡ğ‘’ğ‘ ğ‘¡;ğœ½ğº
â‹†; ğ’Ÿğ‘¡ğ‘’ğ‘ ğ‘¡
Influence on ALL
Influence Estimation
ğ¿âˆ’ğ‘—
ğ‘‡
âˆ‡ğœ½ğ‘‰ğ’Ÿğºğ’µâ€²;ğœ½ğº
ğ‘‡
; ğ’Ÿğ’™â€²
True data 
distribution
ğ‘ğ’™= ğ’©ğ, ğšº
Figure 5: The data setting of data cleansing with the inï¬‚uence on ALL (2D-Normal) in Section 5.2.
15

Published as a conference paper at ICLR 2021
Dataset 
for training
ğ’Ÿğ’™
Remove top  ğ‘›â„
harmful instances
Counterfactual ASGD 
training
ASGD
training
ğœ½ğº
ğ‘‡
ğœ½ğº
â‹†
Cleansed training dataset
Evaluate test IS  of 
the original  generator
(No removal)
ğ‘‰ğ’Ÿğºğ’µğ‘¡ğ‘’ğ‘ ğ‘¡;ğœ½ğº
ğ‘‡
Evaluate test IS  of 
the cleansed generator
(Cleansed)
ğ‘‰ğ’Ÿğºğ’µğ‘¡ğ‘’ğ‘ ğ‘¡;ğœ½ğº
â‹†
Influence on IS
Influence Estimation
ğ¿âˆ’ğ‘—
ğ‘‡
âˆ‡ğœ½ğ‘‰ğ’Ÿğºğ’µâ€²;ğœ½ğº
ğ‘‡
Original
training 
dataset of 60k
Figure 6: The data setting of data cleansing with the inï¬‚uence on IS (MNIST) in Section 5.2.
16

Published as a conference paper at ICLR 2021
Dataset 
for training
ğ’Ÿğ’™
Remove top  ğ‘›â„
harmful instances
Counterfactual ASGD 
training
ASGD
training
ğœ½ğº
ğ‘‡
Cleansed training dataset
Dataset
for influence 
estimation
ğ’Ÿğ’™â€²
(ğ’Ÿğ’™âˆ©ğ’Ÿğ’™â€² = ğœ™)
Dataset
for test 
ğ’Ÿğ‘¡ğ‘’ğ‘ ğ‘¡
Evaluate test FID  of 
the original  generator
(No removal)
ğ‘‰ğ’Ÿğºğ’µğ‘¡ğ‘’ğ‘ ğ‘¡;ğœ½ğº
ğ‘‡
;ğ’Ÿğ‘¡ğ‘’ğ‘ ğ‘¡
Evaluate test FID  of 
the cleansed generator
(Cleansed)
ğ‘‰ğ’Ÿğºğ’µğ‘¡ğ‘’ğ‘ ğ‘¡;ğœ½ğº
â‹†; ğ’Ÿğ‘¡ğ‘’ğ‘ ğ‘¡
Influence on FID
Influence Estimation
ğ¿âˆ’ğ‘—
ğ‘‡
âˆ‡ğœ½ğ‘‰ğ’Ÿğºğ’µâ€²;ğœ½ğº
ğ‘‡
; ğ’Ÿğ’™â€²
Original
training 
dataset of 60k
Original
test
dataset of 10k
ğœ½ğº
â‹†
Figure 7: The data setting of data cleansing with the inï¬‚uence on FID (MNIST) in Section 5.2.
17

Published as a conference paper at ICLR 2021
Table 6: Improvements of test average log-likelihood [10âˆ’2] (Â±std) after the data cleansing (2D-
Normal). The metric value is highlighted when the improvement is statistically signiï¬cant with the
signiï¬cant level 0.05
nh
0.5k
1.0k
2.5k
5.0k
7.5k
10.0k
12.5k
15.0k
17.5k
20.0k
Inï¬‚uence
on
ALL
+0.09
(0.06)
+0.16
(0.12)
+0.31
(0.27)
+0.44
(0.50)
+0.40
(0.73)
+0.22
(0.99)
-0.10
(1.28)
-0.53
(1.60)
-1.07
(1.95)
-1.67
(2.33)
Inï¬‚uence
on
Disc. loss
+0.02
(0.03)
+0.04
(0.05)
+0.11
(0.10)
+0.19
(0.19)
+0.26
(0.28)
+0.32
(0.39)
+0.35
(0.51)
+0.35
(0.64)
+0.30
(0.79)
+0.22
(0.95)
Isolation
Forest
+0.03
(0.05)
+0.05
(0.11)
+0.09
(0.27)
+0.12
(0.54)
+0.12
(0.79)
+0.09
(1.05)
+0.02
(1.31)
-0.09
(1.58)
-0.25
(1.86)
-0.46
(2.16)
Random
+0.01
(0.04)
+0.02
(0.08)
+0.04
(0.19)
+0.07
(0.39)
+0.08
(0.61)
+0.06
(0.83)
+0.02
(1.07)
-0.05
(1.34)
-0.16
(1.61)
-0.31
(1.91)
Table 7: Improvements of test inception score (Â±std) after the data cleansing (MNIST). The metric
value is highlighted when the improvement is statistically signiï¬cant with the signiï¬cant level 0.05
nh
0.5k
1.0k
2.5k
5.0k
10.0k
15.0k
20.0k
25.0k
35.0k
45.0k
Inï¬‚uence
on
FID
+0.03
(0.07)
+0.04
(0.09)
+0.04
(0.17)
+0.03
(0.25)
+0.04
(0.24)
+0.09
(0.13)
+0.10
(0.12)
+0.10
(0.13)
+0.04
(0.17)
-0.18
(0.28)
Inï¬‚uence
on
IS
+0.04
(0.05)
+0.04
(0.08)
+0.05
(0.14)
+0.04
(0.23)
+0.08
(0.15)
+0.11
(0.13)
+0.12
(0.14)
+0.14
(0.14)
+0.09
(0.25)
-0.07
(0.24)
Inï¬‚uence
on
Disc. Loss
+0.01
(0.03)
+0.01
(0.05)
+0.02
(0.03)
+0.04
(0.04)
+0.04
(0.05)
+0.04
(0.06)
+0.04
(0.06)
+0.01
(0.06)
+0.00
(0.07)
-0.15
(0.11)
Isolation
Forest
+0.00
(0.02)
+0.01
(0.02)
+0.01
(0.04)
+0.00
(0.05)
-0.01
(0.06)
-0.05
(0.08)
-0.13
(0.13)
-0.23
(0.18)
-0.67
(0.33)
-1.70
(0.75)
Random
+0.01
(0.02)
+0.00
(0.01)
+0.00
(0.02)
-0.01
(0.04)
+0.00
(0.04)
+0.00
(0.05)
-0.01
(0.09)
+0.00
(0.06)
-0.02
(0.07)
+0.00
(0.10)
18

Published as a conference paper at ICLR 2021
Table 8: Improvements of test FID (Â±std) after the data cleansing (MNIST). The metric value is
highlighted when the improvement is statistically signiï¬cant with the signiï¬cant level 0.05
nh
0.5k
1.0k
2.5k
5.0k
10.0k
15.0k
20.0k
25.0k
35.0k
45.0k
Inï¬‚uence
on
FID
-0.10
(0.13)
-0.13
(0.18)
-0.18
(0.28)
-0.19
(0.46)
-0.25
(0.45)
-0.36
(0.35)
-0.38
(0.36)
-0.38
(0.37)
-0.23
(0.46)
+0.23
(0.60)
Inï¬‚uence
on
IS
-0.07
(0.10)
-0.10
(0.14)
-0.14
(0.22)
-0.14
(0.37)
-0.26
(0.28)
-0.32
(0.29)
-0.34
(0.30)
-0.36
(0.30)
-0.22
(0.45)
+0.17
(0.49)
Inï¬‚uence
on
Disc. Loss
-0.03
(0.06)
-0.04
(0.08)
-0.07
(0.07)
-0.13
(0.10)
-0.18
(0.12)
-0.20
(0.13)
-0.19
(0.14)
-0.15
(0.14)
-0.06
(0.12)
+0.34
(0.19)
Isolation
Forest
+0.01
(0.03)
+0.02
(0.03)
+0.05
(0.06)
+0.10
(0.08)
+0.24
(0.15)
+0.42
(0.22)
+0.73
(0.37)
+1.09
(0.54)
+2.56
(0.85)
+6.99
(3.57)
Random
-0.01
(0.04)
-0.01
(0.02)
-0.00
(0.04)
+0.01
(0.06)
+0.00
(0.07)
+0.01
(0.08)
+0.02
(0.16)
-0.01
(0.09)
+0.00
(0.13)
-0.13
(0.18)
D
DETAILED DISCUSSION ON EXPERIMENT 2
This section ï¬rst discusses three aspects of the results in Section 5.2: Section D.1 explains the com-
mon characteristics of harmful instances suggested by our approach, Section D.2 discusses qual-
itative aspects of the data cleansing using generated samples, and Section D.3 discusses how the
characteristics of harmful instances and effect of the data cleansing are consistent among the train-
ings with different random seeds. Finally, we explain the limitation of our method and present the
future direction in Section D.4.
D.1
CHARACTERISTICS OF HARMFUL INSTANCE
In this section, we examine the characteristics of instances that are evaluated to be harmful or helpful
by our method. We regard a sample is helpful if its inï¬‚uence on a metric is opposite of harmful
instances.
Table 9 shows the estimated harmfulness of the training instances of 2D-Normal and the distribution
of the generated samples. The proposed approach with inï¬‚uence on ALL evaluated the instances
around lower-left and upper-right regions to be harmful (Table 9 (a, i)). These regions correspond to
the regions where the generated distribution has higher density than that of the true distribution; The
generator before the cleansing (Table 9 (a, ii, No removal)) sampled too frequently from lower-left
and upper-right regions compared to the true distribution (Table 9 (a, ii, True)). This characteris-
tics was not observed in the plots of baseline approaches. The approach based on inï¬‚uence on the
discriminator loss seems to ignore the difference in the density around the lower-left region (Ta-
ble 9 (b, i)) and isolation forest did not take the generatorâ€™s distribution into account (Table 9 (c, i)).
Similar characteristics were seen in harmful MNIST instances suggested by our approach with in-
ï¬‚uence on IS and FID. When the generator over-sampled a speciï¬c digit (e.g., the digit 1 in Ta-
ble 10 (a, iii)), our approach tended to judge the images of the digit to be harmful (e.g., a large
number of 1 in Table 10 (b-c, i)). Similarly, our method judged instances of a speciï¬c digit as help-
ful (e.g., the digit 6 in Table 10 (b-c, ii)) when the generator failed to sample the digit (e.g., the
absence of 6 in Table 10 (a, iii)). On the contrary, harmful instances suggested on the basis of in-
ï¬‚uence on the discriminator loss did not show the tendency (Table 10 (d, i)). The baseline approach
with isolation forest based on the classiï¬er feature-space seems to have judged the images that were
difï¬cult to be classiï¬ed as harmful, rather than the over-sampled digit (Table 10 (e, i)). It regarded
that instances are helpful when they belong to a digit that seems to have been easy to be classiï¬ed
(Table 10 (e, ii)).
19

Published as a conference paper at ICLR 2021
To summarize, our method tends to judge instances as harmful when they belong to regions from
which the generators sample too frequently compared to the true distribution.
D.2
QUALITATIVE STUDY OF DATA CLEANSING
We then investigate how the data cleansing using the suggested harmful instances visually change
generated samples.
As seen from Table 9 (a, ii), the probability density in the upper-right region decreased after the data
cleansing (from â€œNo removalâ€ to â€œCleansedâ€). As a result, the generator distribution got closer to the
true distribution. Although the baselines indicated the same direction of changes in the distributions
(Table 9 (b-c, ii)), these were not as signiï¬cant as ours.
The same effect was observed in visually more interesting form in the data cleansing for MNIST. The
generated samples originating from some latent variables changed from the image of digit 1 to that
of other digits after the data cleansing based on the estimated inï¬‚uence on IS and FID (highlighted
samples in Table 10 (b-c, iii)). This implies that a certain amount of density that are over-allocated
for the digit 1 moved to the regions of other digits. We assume this effect improved the diversity in
the generated samples, resulting in better FID and IS. This characteristics was not clearly observed
in the baselines (highlighted samples in Table 10 (d-f, iii)).
These observations suggest that our method helps the GANâ€™s training so that the generator re-assigns
the densities that were over-allocated to certain regions to other regions.
D.3
CONSISTENCY OF QUALITATIVE CHARACTERISTICS AMONG DIFFERENT TRAININGS
We show additional visual results to conï¬rm the consistency of the ï¬ndings on the characteristics
of harmful instances and generated samples after data cleansing, which we described in Section D.2
and Section D.3, respectively.
Table 11 shows the harmfulness of the training instances and the distribution of the generated sam-
ples obtained using 5 different random seeds in 2D-Normal case. As seen from the table, regardless
of which region a generator assigns high density to, our method consistently regards the training
samples around the region as harmful. In addition, the distributions of the generated samples get
closer to the true distribution by removing these harmful training instances in the data cleansing.
Table 12 visualizes the MNIST examples of harmful instances, helpful instances, and generated
images before and after the data cleansing. Different rows correspond to different random seeds.
We found the consistency in visual characteristics was moderate in MNIST case. A few results
demonstrated the common qualitative characteristics when the improvements in GAN evaluation
metrics were large (Table 12 (a) and (d)). In the training with the 4th random seed (d), the suggestion
of harmful instances showed some tendency; many instances of digit 7 were regarded as harmful
whereas those of digit 4 were not at all (Table 12 (d, i)). The data cleansing based on this suggestion
seems to have improved the diversity of the generated samples by reducing the samples of digit 7 and
increasing those of digit 4 (highlighted samples in Table 12 (d, iv)). This indicates the consistent
characteristics of the data cleansing discussed in the previous section to some extent; it helps the
GANâ€™s training so that the generator re-assigns the densities that were over-allocated to certain data
regions to other regions.
D.4
CURRENT LIMITATION AND FUTURE DIRECTION
The limitation of our method is that it does not guarantee the harmful instances suggested on the
basis of inï¬‚uence on one GAN evaluation metric are not necessarily harmful from the viewpoint of
other metrics.
For example, we have demonstrated that removing instances that predicted to have
negative inï¬‚uence on FID improved both test FID and IS (Figure 2) and increased visual diversity
in generated images (Table 10 and 12). However, it does not seem to have improved visual quality
(e.g., sharpness, reality, etc.) of the individual generated-samples.
Therefore, it is possible that
these instances are harmful only for some particular aspects of generative performance, i.e. the
diversity in this case, and they are not harmful for the other aspect, i.e. the visual quality in this
case.
20

Published as a conference paper at ICLR 2021
We would argue that this limitation is closely tied with the limitation of the current GAN evaluation
metrics. For example, FID takes the diversity of generated samples into account, but they only partly
take the visual quality into account; e.g., FID based on Inception Net was shown to focus on textures
rather than shapes of the objects (Karras et al. (2020)). In this sense, we clarify that we never claim
our method can improve the â€œtrueâ€ generative performance from all the aspects, considering the
situation that there is no â€œtrueâ€ evaluation metric that measures all the aspects of the generative
performance.
The advantage of our method is that it does not have to care how the evaluation metrics are deï¬ned
as long as they are differentiable with respect to the generated samples. Furthermore, our evaluation
method makes no assumption about what the harmful characteristics of instances are. This means
that it is expected to be easily applied to another evaluation metric if better metric is developed
in the future. One of our main contributions in such sense is that we experimentally veriï¬ed that
our method successfully improved the generative performance in terms of a targeted metric, using
limited but currently widely accepted metrics.
Our future work includes incorporating such future improvements in the GAN evaluation metric to
obtain better insights on the relationship between training instances and generative performance. In
addition, we would like to relax the current constraint on the optimizer. Our method is currently
applicable only to SGD but we would like to ï¬nd a way to extend it to other optimizers such as
Adam (Kingma & Ba (2015)) to deal with the latest GAN models.
21

Published as a conference paper at ICLR 2021
Table 9: (i) harmfulness of 2D-Normal instances suggested by different approaches, (ii) changes in
the generatorâ€™s distribution, and (iii) test ALL after the data cleansing. (ii) includes plots of the true
distribution (True) and generatorâ€™s distributions before (No removal) and after (Cleansed) the data
cleansing with nh = 5.0k. The distributions of generated samples, that refer to DG(Ztest; Î¸[T ]
G ) (No
removal) and DG(Ztest; Î¸â‹†
G) (Cleansed), are estimated with kernel density estimation.
(i) Harmful instances
(ii) Generated distribution
(iii) ALL
(a)
Inï¬‚uence on ALL
(Ours)
+1.24
(b)
Inï¬‚uence on Disc. Loss
+0.67
(c)
Isolation Forest
+0.73
(d)
Random
+0.43
22

Published as a conference paper at ICLR 2021
Table 10: (i) top 36 harmful and (ii) helpful MNIST instances predicted by the different approaches,
(iii) the test generated samples, and (iv) changes in test FID after the data cleansing with nh = 25.0k.
All the generated samples use the same series of test latent variables in Ztest.
(i) Harmful
(ii) Helpful
(iii) Generated
(iv) FID
(a)
No removal
n/a
n/a
Â±0
(b)
Inï¬‚uence on IS
(Ours)
âˆ’0.71
(c)
Inï¬‚uence on FID
(Ours)
âˆ’0.85
(d)
Inï¬‚uence on D Loss
âˆ’0.21
(e)
Isolation Forest
+1.80
(f)
Random
âˆ’0.21
23

Published as a conference paper at ICLR 2021
Table 11: Comparison among different random seeds used in the training in 2D-Normal case. See
Table 9 for how the plots are generated.
(i) Harmful instances
(ii) Generated distribution
(iii) ALL
(a) 1st rand. seed
+1.24
(b) 2nd rand. seed
+0.29
(c) 3rd rand. seed
+0.54
(d) 4th rand. seed
+0.32
(e) 5th rand. seed
+0.58
24

Published as a conference paper at ICLR 2021
Table 12: Comparison among different random seeds used in the training in MNIST case. The
generated samples from the model without cleansing (iii) and cleansed model (iv) in the same row
use the same series of test latent variables. See Table 10 for the detail of how the images are obtained.
(i)
Harmful
(ii)
Helpful
(iii)
Generated
(No removal)
(iv)
Generated
(Cleansed)
(v)
FID
(a) 1st rand. seed
âˆ’0.85
(b) 2nd rand. seed
âˆ’0.45
(c) 3rd rand. seed
+0.09
(d) 4th rand. seed
âˆ’0.71
(e) 5th rand. seed
âˆ’0.12
25

