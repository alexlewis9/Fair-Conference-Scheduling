Improved Algorithms for Stochastic Linear Bandits
Using Tail Bounds for Martingale Mixtures
Hamish Flynn1,2, David Reeb1, Melih Kandemir3, Jan Peters2,4
1Bosch Center for Artificial Intelligence, Renningen, Germany
2Technische UniversitÃ¤t Darmstadt, Germany
3University of Southern Denmark, Odense, Denmark
4Deutsches Forschungszentrum fÃ¼r KÃ¼nstliche Intelligenz (DFKI), Germany
hamish@robot-learning.de, david.reeb@de.bosch.com,
kandemir@imada.sdu.dk, jan.peters@tu-darmstadt.de
Abstract
We present improved algorithms with worst-case regret guarantees for the stochas-
tic linear bandit problem. The widely used â€œoptimism in the face of uncertaintyâ€
principle reduces a stochastic bandit problem to the construction of a confidence
sequence for the unknown reward function. The performance of the resulting bandit
algorithm depends on the size of the confidence sequence, with smaller confidence
sets yielding better empirical performance and stronger regret guarantees. In this
work, we use a novel tail bound for adaptive martingale mixtures to construct
confidence sequences which are suitable for stochastic bandits. These confidence
sequences allow for efficient action selection via convex programming. We prove
that a linear bandit algorithm based on our confidence sequences is guaranteed to
achieve competitive worst-case regret. We show that our confidence sequences are
tighter than competitors, both empirically and theoretically. Finally, we demon-
strate that our tighter confidence sequences give improved performance in several
hyperparameter tuning tasks.
1
Introduction
The stochastic linear bandit problem is a sequential decision-making problem where, in each round
t, a learner chooses an action at and then receives a stochastic reward rt for its choice of action.
The expected value of each reward is a linear function Ï•(at)âŠ¤Î¸âˆ—of a known feature vector Ï•(at)
associated with the corresponding action, while Î¸âˆ—is unknown. The linear bandit problem has
attracted a great deal of attention because it is expressive enough to be a faithful model of many
real-world decision-making problems, such as news recommendation (Li et al., 2010) and dynamic
pricing (Cohen et al., 2020), yet it is simple enough to make theoretical analysis tractable.
A popular way to design algorithms for linear bandits is to follow the principle of optimism in the
face of uncertainty. This principle states that we should choose actions as if the expected reward
function is as nice as plausibly possible. For linear bandits, the principle can be instantiated with a
confidence sequence Î˜0, Î˜1, . . . for the parameter vector Î¸âˆ—âˆˆÎ˜ of the expected reward function. A
confidence sequence is a sequence of subsets of the full parameter space Î˜, which is built iteratively
as data becomes available and is constructed such that with high probability over the observed data,
Î¸âˆ—is contained in each confidence set Î˜t. One can then run an upper confidence bound (UCB)
algorithm, which at round t chooses an action at+1 by maximising the UCB maxÎ¸âˆˆÎ˜t

Ï•(a)âŠ¤Î¸
	
with respect to a.
The popularity of UCB algorithms stems from the fact that they come with worst-case regret guaran-
tees and often perform well in practice. However, the performance of a UCB algorithm is intimately
37th Conference on Neural Information Processing Systems (NeurIPS 2023).

4
2
0
2
4
x
6
4
2
0
2
4
6
8
y
CMM-UCB
4
2
0
2
4
x
6
4
2
0
2
4
6
8
AMM-UCB
4
2
0
2
4
x
6
4
2
0
2
4
6
8
OFUL
Figure 1: Tighter upper and lower confidence bounds via tail bounds for martingale mixtures.
The upper and lower confidence bounds of CMM-UCB (left), AMM-UCB (middle), and OFUL
(Abbasi-Yadkori et al., 2011) (right) for a test function linear in random Fourier features. The bounds
from CMM-UCB and AMM-UCB are visibly closer to the true function (dashed line) than those of
OFUL. The CMM-UCB confidence bounds are slightly tighter than the ones of AMM-UCB.
tied to the size of the confidence sets it uses. The smaller the subsets in the confidence sequence, the
better the regret bound and, perhaps more importantly, the better the algorithm performs in practice.
In this work, we develop a general-purpose tail bound for martingale mixtures, which can be used to
construct confidence sequences. When we specialise our general results to the linear bandit problem,
the maximisation problem to compute the UCB is a convex program. We maximise the UCB over
actions via gradient-based methods, and investigate two procedures for computing the UCB along
with its gradient: (a) Convex Martingale Mixture UCB (CMM-UCB): We employ a convex solver for
the UCB maximisation and calculate its gradients via differentiable convex optimisation (Agrawal
et al., 2019); (b) Analytic Martingale Mixture UCB (AMM-UCB): We exploit weak Lagrangian duality
to obtain an analytic upper bound on the UCB, whose gradient can be computed in closed-form or
via standard automatic differentiation procedures.
Fig. 1 highlights a key observation: both of our UCBs are tighter than those used in the state-of-the-art
OFUL algorithm (Abbasi-Yadkori et al., 2011) for stochastic linear bandits. We verify this claim
empirically in Sec. 8 and prove it in App. C.2. We evaluate CMM-UCB, AMM-UCB, OFUL and
various other linear bandit algorithms in several hyperparameter tuning problems (Sec. 8). We find
that our tighter UCBs result linear bandit algorithms with better performance.
2
Related Work
Algorithms with regret guarantees have been developed for several variants of the stochastic linear
bandit problem. Dani et al. (2008), Abbasi-Yadkori et al. (2009) and Rusmevichientong & Tsitsiklis
(2010) proposed algorithms for a linear bandit problem where the action set is a fixed, possibly
infinite subset of a finite-dimensional vector space. Auer (2002) and Chu et al. (2011) proposed
algorithms for linear bandit problems where the action set has finite cardinality, but may change over
time. Abbasi-Yadkori et al. (2011) proposed the OFUL algorithm for linear bandit problems with a
changing and possibly infinite action set, which is essentially the problem that we investigate. We
consider stochastic linear bandit problems where the reward function is a composition of a possibly
non-linear feature map and a linear function. This can be seen as a restricted version of the stochastic
kernelised bandit problem, where the kernel feature map is finite-dimensional. Srinivas et al. (2010);
Valko et al. (2013); Chowdhury & Gopalan (2017); Camilleri et al. (2021); Salgia et al. (2021) and Li
& Scarlett (2022) proposed algorithms with regret guarantees for various kernelised bandit problems.
In the bandit literature, confidence sets and confidence bounds constructed from online (e.g. non-i.i.d.)
observation points for unknown linear functions have been proposed by Dani et al. (2008); Rus-
mevichientong & Tsitsiklis (2010) and Abbasi-Yadkori et al. (2011). Online confidence sets/bounds
for unknown functions in separable Hilbert spaces and reproducing kernel Hilbert spaces (RKHSs)
have been proposed by Srinivas et al. (2010); Abbasi-Yadkori (2012); Kirschner & Krause (2018) and
Durand et al. (2018). Russo & Van Roy (2013) derived online confidence sets for unknown functions
belonging to arbitrary function classes.
2

We use the term â€œmixture of martingalesâ€, or martingale mixture, to refer to a martingale of the
form Evâˆ¼P [Mt(v)], where (Mt(v)|t âˆˆN) is a collection of martingales indexed by the variable
v âˆˆV. Martingale mixtures can be traced back to (Darling & Robbins, 1968; Robbins, 1970), and
have been used to construct confidence sequences since at least the work of Lai (1976). Proofs of
tail bounds for martingale mixtures typically use the method of mixtures, which was first used by
Robbins & Siegmund (1970) and was later popularised by de la PeÃ±a et al. (2004, 2009). Methods
for martingale mixtures have seen renewed interest in the sequential testing literature (Howard et al.,
2020; Kaufmann & Koolen, 2021). Examples of confidence sequences for bandits that use martingale
mixtures include the works of Abbasi-Yadkori et al. (2011); Abbasi-Yadkori (2012); Kirschner &
Krause (2018); Durand et al. (2018); Neiswanger & Ramdas (2021). Unlike in these examples,
we construct confidence sequences based on adaptive martingale mixtures (Evâˆ¼Pt[Mt(v)]|t âˆˆN),
where the mixture distribution Pt can be refined as more data is acquired at each time t.
3
Problem Statement and Background
We consider a problem in which a learner plays a game over a sequence of T rounds, where T may not
be known in advance. In each round t, the learner observes an action set At and must choose an action
at âˆˆAt. The learner then receives a reward rt = Ï•(at)âŠ¤Î¸âˆ—+ Ïµt. The feature map Ï• : A â†’Rd is
a known function that maps actions to d-dimensional feature vectors, where A = S
t At. Î¸âˆ—âˆˆRd
is an unknown parameter with Euclidean norm bounded by some known B > 0, i.e. âˆ¥Î¸âˆ—âˆ¥2 â‰¤B.
Ïµ1, Ïµ2, . . . , ÏµT are conditionally zero-mean Ïƒ-sub-Gaussian noise variables. These assumptions on Î¸âˆ—
and Ïµ1, Ïµ2, . . . , ÏµT are standard in the linear bandit literature, see e.g. (Abbasi-Yadkori et al., 2011).
While our regret analysis applies to any action sets, our algorithms focus on the case where the action
sets At are continuous subsets of RdA.
The goal of the learner is to choose a sequence of actions that maximises the total expected re-
ward, which is equal to PT
t=1 Ï•(at)âŠ¤Î¸âˆ—after T rounds. We use cumulative regret, which is the
difference between the total expected reward of the learner and the optimal strategy, to evaluate
the learner. For a single round, we define the regret as âˆ†(at) = Ï•(aâˆ—
t )âŠ¤Î¸âˆ—âˆ’Ï•(at)âŠ¤Î¸âˆ—, where
aâˆ—
t = argmaxaâˆˆAt{Ï•(a)âŠ¤Î¸âˆ—}. After T rounds, the cumulative regret is âˆ†1:T = PT
t=1 âˆ†(at).
Confidence Sequences.
For any level Î´ âˆˆ(0, 1], a (1 âˆ’Î´)-confidence sequence for the parameter
vector Î¸âˆ—is a sequence Î˜1, Î˜2, . . . of subsets of Rd, such that each Î˜t can be calculated using the
data a1, r1, . . . , at, rt and the sequence satisfies
Pa1,a2,...,
r1,r2,..., [âˆ€t â‰¥1 : Î¸âˆ—âˆˆÎ˜t] â‰¥1 âˆ’Î´.
A confidence sequence Î˜1, Î˜2, . . . is thus a sequence of data-dependent confidence sets such that
with high probability over the random actions and rewards, Î¸âˆ—âˆˆÎ˜t holds for all t â‰¥1 simultaneously.
We remark that the confidence sets Î˜t in this paper are random closed sets in the sense of Def. 1.1.1
of (Molchanov, 2005), which implies that the event Î¸ âˆˆÎ˜t is actually measurable for all Î¸ âˆˆRd.
4
UCB Algorithms for Linear Bandits
We describe here how to transform confidence sets for Î¸âˆ—into a UCB algorithm for the linear bandit
problem. Such algorithms have appeared under various names, such as LinRel (Auer, 2002), LinUCB
(Li et al., 2010) and OFUL (Abbasi-Yadkori et al., 2011). We refer to this meta algorithm as LinUCB,
and give its pseudo-code in Algorithm 1. When run with our confidence sets, we call this algorithm
CMM-UCB resp. AMM-UCB (see Sec. 6).
In each round t, the first step is to construct a confidence set Î˜t from the previous observations
{(ak, rk)}t
k=1. If Î¸âˆ—âˆˆÎ˜t with high probability, then for any action a,
UCBÎ˜t(a) := max
Î¸âˆˆÎ˜t{Ï•(a)âŠ¤Î¸}
(1)
is an upper confidence bound (UCB) on Ï•(a)âŠ¤Î¸âˆ—. Taking minÎ¸âˆˆÎ˜t in (1) yields the lower confidence
bound LCBÎ˜t(a). Once a confidence set Î˜t has been constructed and the next action set At+1 has
been observed, the LinUCB algorithm chooses the action
at+1 = argmax
aâˆˆAt+1
{UCBÎ˜t(a)} ,
(2)
3

Algorithm 1: LinUCB
for t = 0, 1, 2, . . . do
Construct a confidence set Î˜t from {(ak, rk)}t
k=1
Observe next action set At+1
Play next action at+1 = argmaxaâˆˆAt+1{UCBÎ˜t(a)}
Observe next reward rt+1
end
which maximises the UCB. The remaining challenge lies in the construction of the confidence sets.
5
Confidence Sequences from Martingale Mixtures
In this section, we develop a general-purpose tail bound for adaptive martingale mixtures. We then
specialise our general result to the stochastic linear bandit setting, described in Sec. 3, and construct
confidence sequences for the parameter Î¸âˆ—.
5.1
General-Purpose Tail Bound for Adaptive Martingale Mixtures
We consider a general setting in which we are given a filtration (Ht|t âˆˆN), a sequence of adapted
random functions (Zt : R â†’R|t âˆˆN), and a sequence of predictable random variables (Î»t|t âˆˆN).
For ft âˆˆR, we define the conditional cumulant generating function Ïˆt(ft, Î»t) as
Ïˆt(ft, Î»t) := ln (E [exp(Î»tZt(ft))|Htâˆ’1]) ,
where the expectation E is over Zt(ft) and Î»t (although Î»t is non-random when conditioned on
Htâˆ’1). We use the shorthand f t := (f1, f2, . . . , ft) and Î»t := (Î»1, Î»2, . . . , Î»t). Let
Mt(f t, Î»t) = exp
 
t
X
k=1
Î»kZk(fk) âˆ’Ïˆk(fk, Î»k)
!
.
(3)
Mt(f t, Î»t) is a slight generalisation of the martingale used in App. B.1 of (Russo & Van Roy,
2013). One can show that for any sequence (ft|t âˆˆN), (Mt(f t, Î»t)|t âˆˆN) is a martingale and
E[Mt(f t, Î»t)] = 1 (App. A.1). We will now construct an adaptive martingale mixture.
We call a data-dependent sequence of probability distributions (Pt|t âˆˆN) an adaptive sequence
of mixture distributions if: (a) Pt is a distribution over f t âˆˆRt; (b) Pt is Htâˆ’1-measurable;
(c) the distributions are consistent in the sense that their marginals coincide, i.e.
R
Pt(f t)dft =
Ptâˆ’1(f tâˆ’1) for all t. These conditions on the sequence of distributions ensure that the martingale
mixture (Ef tâˆ¼Pt[Mt(f t, Î»t)]|t âˆˆN) is in fact a martingale. In App. A.1, we verify this and
show that E[Ef tâˆ¼Pt[Mt(f t, Î»t)]] = 1. From here, we can use Villeâ€™s inequality for non-negative
supermartingales (Ville, 1939) to obtain our general-purpose tail bound.
Theorem 5.1 (Tail Bound for Adaptive Martingale Mixtures). For any Î´ âˆˆ(0, 1), any sequence
of predictable random variables (Î»t|t âˆˆN), and any adaptive sequence of mixture distributions
(Pt|t âˆˆN), the following holds with probability at least 1 âˆ’Î´:
ln

E
f tâˆ¼Pt
[Mt(f t, Î»t)]

â‰¤ln(1/Î´)
for all t â‰¥1.
We provide a proof of this result in App. A.2. Note that if each Ïˆk(fk, Î»k) in (3) is replaced by an
upper bound on Ïˆk(fk, Î»k), the statement of the theorem still holds.
Thm. 5.1 is closely related to the general-purpose anytime PAC-Bayes bound in Thm. 3.1 of (Chugg
et al., 2023). The main difference is that our inequality holds for adaptive sequences of mixture
distributions or priors. PAC-Bayes bounds with somewhat similar adaptive sequences of mixture
distributions/priors have recently been proposed by Haddouche & Guedj (2022, 2023).
4

5.2
Confidence Sequences for Stochastic Linear Bandits
We now specialise Thm. 5.1 to the stochastic linear bandit setting. For the filtration (Ht|t âˆˆN), we
set Ht to be the Ïƒ-algebra generated by (a1, r1, . . . , at, rt, at+1). For reasons that will become clear,
we choose Zt(ft) = (ft âˆ’Ï•(at)âŠ¤Î¸âˆ—)Ïµt. Since Z(ft) is linear in the noise variable Ïµt, Ïˆt(ft, Î»t) can
be upper bounded using the sub-Gaussian property of Ïµt. We have
Ïˆt(ft, Î»t) = ln
 E

exp
 Î»t(ft âˆ’Ï•(at)âŠ¤Î¸âˆ—)Ïµt

|Htâˆ’1

â‰¤Î»2
tÏƒ2(ft âˆ’Ï•(at)âŠ¤Î¸âˆ—)2/2.
(4)
With this upper bound on Ïˆt(ft, Î»t), Thm. 5.1 implies that, with probability at least 1 âˆ’Î´
Ef tâˆ¼Pt
"
exp
(
t
X
k=1
Î»k(fk âˆ’Ï•(ak)âŠ¤Î¸âˆ—)(rk âˆ’Ï•(ak)âŠ¤Î¸âˆ—) âˆ’Ïƒ2
2 Î»2
k(fk âˆ’Ï•(ak)âŠ¤Î¸âˆ—)2
)#
â‰¤1
Î´ .
Since Zf(ft) is linear in ft, this integral has a closed-form solution whenever the mixture distribution
is a Gaussian Pt = N(Âµt, T t). Although there is a closed-form solution for any predictable sequence
(Î»t|t âˆˆN) (see App. B.1), we choose Î»t â‰¡1/Ïƒ2, which yields a relatively simple convex quadratic
constraint for Î¸âˆ—. Collecting the feature vectors in Î¦t := [Ï•(a1), . . . , Ï•(at)]âŠ¤âˆˆRtÃ—d and writing
the reward vector rt := [r1, . . . , rt]âŠ¤, we arrive at (see App. B.2)
âˆ¥Î¦tÎ¸âˆ—âˆ’rtâˆ¥2
2 â‰¤(Âµt âˆ’rt)âŠ¤

1 + T t
Ïƒ2
âˆ’1
(Âµt âˆ’rt) + Ïƒ2 ln det

1 + T t
Ïƒ2

+ 2Ïƒ2 ln 1
Î´ .
(5)
This inequality has an attractive interpretation. At each step t of the bandit process, the (unknown)
ground-truth reward vector Î¦âŠ¤
t Î¸âˆ—lies within a sphere around the observed reward vector rt, with
squared radius equal to the RHS of (5). One can think of the mean vector Âµt as a prediction of the
reward vector rt, given the previous data a1, r1, . . . , atâˆ’1, rtâˆ’1, at. The covariance matrix T t can
be thought of as the uncertainty associated with the prediction Âµt. If Âµt is a good prediction of rt,
then the quadratic â€œprediction errorâ€ term in (5) will be close to 0, and we can afford to choose T t
close to zero to minimise the log determinant term. In this situation, (5) can give a much tighter
constraint than the naive bound âˆ¼tÏƒ2, especially when Ïƒ is a pessimistic upper bound on the true
sub-Gaussian parameter. This naive bound follows from the observation that âˆ¥Î¦tÎ¸âˆ—âˆ’rtâˆ¥2 = âˆ¥Ïµtâˆ¥2,
where Ïµt = (Ïµ1, . . . , Ïµt). Combining the constraint in (5) with our assumption âˆ¥Î¸âˆ—âˆ¥2 â‰¤B yields our
confidence sequence for Î¸âˆ—.
Corollary 5.2 (Martingale Mixture Confidence Sequence). For any adaptive sequence of mixture
distributions Pt = N(Âµt, T t), it holds with probability at least 1âˆ’Î´ that for all t â‰¥1 simultaneously,
Î¸âˆ—lies in the set
Î˜t =

Î¸ âˆˆRd
 âˆ¥Î¦tÎ¸ âˆ’rtâˆ¥2 â‰¤RMM,t
and âˆ¥Î¸âˆ¥2 â‰¤B

,
(6)
where we define R2
MM,t as the right-hand-side of Eq. (5).
The boundaries of the constraints in (6) are both ellipsoids in Rd, which means that each Î˜t is the
intersection of (the interiors of) two ellipsoids.
6
Martingale Mixture UCB Algorithms
In this section, we describe our CMM-UCB and AMM-UCB algorithms, which are two different
implementations of LinUCB (Algorithm 1) with our confidence sequence from Corollary 5.2.
6.1
UCB Computation and Optimisation
To run the LinUCB action selection rule with our confidence sequence, we need to be able to maximise
UCBÎ˜t(a) with respect to a. The value of the UCB at the action a is the solution of
UCBÎ˜t(a) = max
Î¸âˆˆRd Ï•(a)âŠ¤Î¸
s.t. âˆ¥Î¦tÎ¸ âˆ’rtâˆ¥2 â‰¤RMM,t
and
âˆ¥Î¸âˆ¥2 â‰¤B.
(7)
5

This is a convex optimisation problem, which can be efficiently solved via convex programming. If
the action sets have finite cardinality, UCBÎ˜t(a) can be maximised by solving (7) for each a âˆˆAt
and then comparing the solutions. If the action sets are continuous subsets of RdA, then exact
maximisation of UCBÎ˜t(a) is (in general) infeasible. For example, when the feature map Ï• is linear
in a, UCBÎ˜t(Â·) is the maximum over a set of linear functions, which is a convex function of a (see
Eq. (3.7) in Sec. 3.2.3 of Boyd & Vandenberghe (2004)). Since maximisation of a convex function is
(in general) NP-hard, exact maximisation of UCBÎ˜t(a) is also (in general) NP-hard. For this reason,
when the action sets are continuous subsets of RdA (and Ï• is differentiable), we approximately
maximise UCBÎ˜t(a) via gradient-based local search.
6.2
Convex Martingale Mixture UCB
Our Convex Martingale Mixture UCB (CMM-UCB) algorithm is based on computing (7) using
numerical convex (conic) solvers from the CVXPY library (Diamond & Boyd, 2016; Agrawal et al.,
2018). Note that (7) is already stated in a conic form, which is favourable for conic solvers (Boyd &
Vandenberghe, 2004). Solving (7) numerically gives the tightest UCBs that can be obtained from
our confidence sequence. To compute the gradient of UCBÎ˜t(a) with respect to the action a, we
use recently developed methods for differentiating conic programs at their optimum (Agrawal et al.,
2019), which are implemented in the cvxpylayers library.
6.3
Analytic Martingale Mixture UCB
Our Analytic Martingale Mixture UCB (AMM-UCB) algorithm uses an analytic upper bound on the
solution of (7). The resulting analytic confidence bounds are looser than the numerical confidence
bounds used by CMM-UCB, but are cheaper to evaluate and maximise. Theorem 6.1 states our upper
bound on the solution of (7).
Theorem 6.1 (Analytic UCB). For all Î± > 0, we have
UCBÎ˜t(a) = max
Î¸âˆˆÎ˜t

Ï•(a)âŠ¤Î¸
	
â‰¤Ï•(a)âŠ¤bÎ¸Î±,t + RAMM,t
q
Ï•(a)âŠ¤ Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Ï•(a),
(8)
where
bÎ¸Î±,t =
 Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Î¦âŠ¤
t rt,
R2
AMM,t = R2
MM,t + Î±B2 âˆ’râŠ¤
t rt + râŠ¤
t Î¦t
 Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Î¦âŠ¤
t rt.
In App. C.1, we derive this analytic UCB by partial optimisation of the Lagrangian dual function.
Using strong duality, one can show that the analytic UCB minimised with respect to Î± is equal to
UCBÎ˜t(a). Due to the closed-form expression of the analytic UCB in (8), its gradient with respect
to a can be computed using standard automatic differentiation packages.
6.4
Choosing the Mixture Distributions
Both of our algorithms require us to choose mixture distributions Pt = N(Âµt, T t). The mixture
distributions play a role similar to the priors used in the PAC-Bayes (Shawe-Taylor & Williamson,
1997; McAllester, 1998; Guedj, 2019; Alquier, 2021) and luckiness (GrÃ¼nwald, 2007, 2023) frame-
works. Our confidence sequences and regret bounds are valid for any sequence of adaptive mixture
distributions, but (as seen in Eq. (5)) if better/worse mixture distributions are chosen, then our
confidence sequences will get smaller/bigger and our regret guarantees will get tighter/looser.
Here, we describe some sensible choices for the mixture distributions. In order for a sequence of
Gaussian mixture distributions (N(Âµt, T t)|t âˆˆN) to be a sequence of adaptive mixture distributions
(as defined in Section 5.1), we require: (a) Âµt and T t can only depend on a1, . . . , at and r1, . . . , rtâˆ’1;
(b) the first t âˆ’1 elements of Âµt must be equal to Âµtâˆ’1; (c) the upper left t âˆ’1 Ã— t âˆ’1 block of T t
must be T tâˆ’1; (d) T t must be positive (semi-)definite. These conditions are all satisfied if we use a
mean vector Âµt and covariance matrix T t of the form
Âµt = [m(a1), m(a2), . . . , m(at)]âŠ¤,
T t =
ï£®
ï£¯ï£¯ï£°
k(a1, a1)
k(a1, a2)
Â· Â· Â·
k(a1, at)
k(a2, a1)
k(a2, a2)
Â· Â· Â·
k(a2, at)
...
...
...
...
k(at, a1)
k(at, a2)
Â· Â· Â·
k(at, at)
ï£¹
ï£ºï£ºï£»,
(9)
6

where m : A â†’R is a mean function and k : A Ã— A â†’R is a positive-definite kernel function. For
the linear bandit problem, it is natural to use a linear mean function m(a) = Ï•(a)âŠ¤Î¸0 and a linear
kernel function k(a, aâ€²) = Ï•(a)âŠ¤Î£0Ï•(aâ€²) (where Î£0 is symmetric and positive-definite), since the
resulting mixture distribution assigns non-zero probability only to those vectors of function values
f t that could have been generated by a linear reward function. By direct computation, the Gaussian
mixture distribution with this m and k, and with Âµt and T t as in (9), is Pt = N(Î¦tÎ¸0, Î¦tÎ£0Î¦âŠ¤
t ).
When Î¸0 = 0 and Î£0 = 1, we recover what we call the standard mixture distributions Pt =
N(0, Î¦tÎ¦âŠ¤
t ).
Choosing T t = Î¦tÎ£0Î¦âŠ¤
t has the additional benefit that it allows for cheaper computation of the
radius RMM,t. In App. F, we show that one (only) has to compute the inverse and determinant of
a d Ã— d matrix instead of the inverse and determinant of the t Ã— t matrix 1 + T t/Ïƒ2. Finally, we
remark that the requirement that (N(Âµt, T t)|t âˆˆN) is an adaptive sequence of mixture distributions
allows for â€œmore adaptiveâ€ choices of Âµt and T t. In App E.2, we describe and investigate a method
for updating Âµt and T t at each round t based on previously observed actions and rewards.
7
Regret Bounds
In this section, we establish cumulative regret bounds for our CMM-UCB and AMM-UCB algorithms.
First, we state a data-dependent regret bound that illustrates how the radius of the analytic UCB from
Sec. 6.3 influences the regret of both algorithms. Then, we prove a data-independent regret bound
which illustrates the worst-case growth rate of the cumulative regret, with explicit dependence on the
feature vector dimension d and the number of rounds T. We begin by stating the assumptions (which
are standard) under which our regret bounds hold.
Assumption
7.1
(Sub-Gaussian
noise).
Let
Ht
denote
(the
Ïƒ-algebra
generated
by)
(a1, r1, . . . , at, rt, at+1). Each noise variable Ïµt is conditionally zero-mean and Ïƒ-sub-Gaussian,
which means
E [Ïµt|Htâˆ’1] = 0,
and
âˆ€Î» âˆˆR, E [exp(Î»Ïµt)|Htâˆ’1] â‰¤exp(Î»2Ïƒ2/2).
Assumption 7.2 (Bounded parameter vector). For some B > 0, âˆ¥Î¸âˆ—âˆ¥2 â‰¤B.
Assumption 7.3 (Bounded feature vectors). For some L > 0, âˆ¥Ï•(a)âˆ¥2 â‰¤L for all a âˆˆA.
Assumption 7.4 (Bounded expected reward). For some C > 0, Ï•(a)âŠ¤Î¸âˆ—âˆˆ[âˆ’C, C] for all a âˆˆA.
We remark that to run our algorithms and evaluate the data-dependent regret bound in Thm. 7.5,
we only need to know (upper bounds on) the sub-Gaussian parameter Ïƒ and the norm bound B.
Assumption 7.2 and Assumption 7.3 together imply that Assumption 7.4 must hold with C â‰¤LB.
We nevertheless state it as a separate assumption because this leaves open the possibility that a better
(than LB) value for C is known.
7.1
Data-Dependent Regret Bounds
Several authors (Dani et al., 2008; Abbasi-Yadkori et al., 2011; Russo & Van Roy, 2013) have shown
that the cumulative regret of a UCB algorithm can be upper bounded by the sum of the widths of
the confidence sets or confidence bounds that it uses. The width of a confidence set Î˜t at the action
a is the difference between the corresponding UCB and the LCB at a (i.e., maxÎ¸âˆˆÎ˜t{Ï•(a)âŠ¤Î¸} âˆ’
minÎ¸âˆˆÎ˜t{Ï•(a)âŠ¤Î¸}). In App. D.1, we show that if a1, a2, . . . , aT are the actions selected by our
CMM-UCB algorithm, then
T
X
t=1
âˆ†(at) â‰¤
T
X
t=1
max
Î¸âˆˆÎ˜tâˆ’1{Ï•(at)âŠ¤Î¸} âˆ’min
Î¸âˆˆÎ˜tâˆ’1{Ï•(at)âŠ¤Î¸}.
(10)
This gives a data-dependent cumulative regret bound for CMM-UCB. AMM-UCB has a similar
data-dependent cumulative regret bound. In App. D.1, we show that if a1, a2, . . . , aT are the actions
selected by our AMM-UCB algorithm, then
T
X
t=1
âˆ†(at) â‰¤
T
X
t=1
AUCBÎ˜tâˆ’1(at) âˆ’ALCBÎ˜tâˆ’1(at),
(11)
7

where AUCBÎ˜t(a) is the right-hand-side of (8) and ALCBÎ˜t(a) is the equivalent analytic LCB.
Since, the analytic UCB/LCB is an upper/lower bound on the numerical UCB/LCB, the bound in
Equation (11) also holds for the actions selected by CMM-UCB. By substituting in the expressions
for the analytic UCB/LCBs, we obtain the following data-dependent cumulative regret bound for
CMM-UCB and AMM-UCB.
Theorem 7.5. Suppose that assumptions 7.1-7.2 hold. For any adaptive sequence of mixture
distributions Pt = N(Âµt, T t), any Î´ âˆˆ(0, 1), any Î± > 0 and all T â‰¥1, with probability at least
1 âˆ’Î´, the cumulative regret of both CMM-UCB and AMM-UCB is bounded by
âˆ†1:T â‰¤
T
X
t=1
2RAMM,tâˆ’1
q
Ï•(at)âŠ¤ Î¦âŠ¤
tâˆ’1Î¦tâˆ’1 + Î±1
âˆ’1 Ï•(at).
A proof is given in App. D.1. This regret bound tells us that if we choose an adaptive sequence of
mixture distributions Pt = N(Âµt, T t), such that the radii RAMM,t are small, then we can expect to
have small cumulative regret.
7.2
Data-Independent Regret Bounds
We now state a data-independent cumulative regret bound for the special case when the adaptive
sequence of mixture distributions is Pt = N(0, cÎ¦tÎ¦âŠ¤
t ), and Î± = Ïƒ2/c. These mixture distributions
are scaled versions of the standard mixture distributions described in Sec. 6.4.
Theorem 7.6. Suppose that assumptions 7.1-7.4 hold. If for any c > 0, the sequence of mixture
distributions is Pt = N(0, cÎ¦tÎ¦âŠ¤
t ), then for all T â‰¥1, with probability at least 1âˆ’Î´, the cumulative
regret of both CMM-UCB and AMM-UCB (with Î± = Ïƒ2/c) is bounded by
âˆ†1:T â‰¤
2
âˆš
ln 2
max
(
C, Ïƒ
s
d ln

1+ cL2T
Ïƒ2d

+ B2
c +2 ln 1
Î´
) s
dT ln

1+ cL2T
Ïƒ2d

â‰¤O(d
âˆš
Tln(T)).
Proof sketch. Choosing Pt = N(0, cÎ¦tÎ¦âŠ¤
t ) and Î± = Ïƒ2/c means that the two quadratic terms in
R2
AMM,t cancel out. We then find a data-independent upper bound for the log det term. Following
Abbasi-Yadkori et al. (2011), the sum of the norms
q
Ï•(at)âŠ¤(Î¦âŠ¤
tâˆ’1Î¦tâˆ’1 + Î±1)âˆ’1Ï•(at) is upper
bounded using an elliptical potential lemma. The result is the data-independent regret bound in the
statement of the theorem.
In App. D.2, we give a proof of this special case. In addition, we also treat a more general case
when the sequence of mixture distributions is Pt = N(Î¦tÎ¸0, Ïƒ2
0Î¦tÎ¦âŠ¤
t ) and Î± is any positive number.
Using Eq. (5) with Âµt = Î¦tÎ¸0 and T t = Ïƒ2
0Î¦tÎ¦âŠ¤
t , one can interpret Î¸0 as a guess for Î¸âˆ—and Ïƒ0 as
a guess for the distance between the reward vector rt and the prediction Î¦tÎ¸0.
Focusing on the dependence on d and T, this regret bound (and the more general one in App. D.2)
is at most O(d
âˆš
Tln(T)), which matches OFUL and is minimax optimal up to the ln(T) factor. If
(upper bounds on) Ïƒ2, B, L and C are known, then we can evaluate this cumulative regret bound
before running the algorithm.
8
Experiments
In all our experiments, we set Î´ = 0.01. When using our analytic UCBs (Thm. 6.1), we always choose
Î± = Ïƒ2. Unless stated otherwise, we use the standard mixture distributions Pt = N(0, Î¦tÎ¦âŠ¤
t ).
8

0
200
400
600
800
1000
T
100
101
Width (log scale)
Scaling With T
CMM-UCB
AMM-UCB
OFUL
0
20
40
60
80
100
d
0
2
4
6
8
Width
Scaling With d
Figure 2: Average confidence bound width for different data set sizes T and feature dimensions d.
8.1
Upper and Lower Confidence Bounds
Compared Methods.
We evaluate the following upper/lower confidence bounds: (a) CMM-UCB:
our numerical UCBs/LCBs from Sect. 6.2; (b) AMM-UCB: our analytic UCBs/LCBs from Thm. 6.1;
(c) OFUL: the UCBs/LCBs used by the OFUL algorithm (Abbasi-Yadkori et al., 2011); (d) Bayes:
a Bayesian credible interval constructed from the Bayesian posterior for linear regression with a
Gaussian prior and likelihood (see App. E.1 for details).
Experimental Setup.
We conduct experiments on randomly generated linear functions of the form
f(x) = Ï•(x)âŠ¤Î¸âˆ—, with inputs x âˆˆRdX and Î¸âˆ—âˆˆRd, the latter drawn from a standard Gaussian
distribution and if necessary scaled down to âˆ¥Î¸âˆ—âˆ¥2 â‰¤10 =: B. For the feature map Ï• : RdX â†’Rd,
we use Random Fourier Features (cf. Algorithm 1 of (Rahimi & Recht, 2007)). We investigate the
properties of upper and lower confidence bounds constructed from random data sets {(xt, yt)}T
t=1,
where yt = Ï•(xt)âŠ¤Î¸âˆ—+ Ïµt, Ïµt âˆ¼N(0, Ïƒ2) and Ïƒ = 0.1.
UCB/LCB Tightness.
Fig. 1 shows the data {(xt, yt)}T
t=1 and the UCBs/LCBs of CMM-UCB,
AMM-UCB and OFUL for a randomly generated linear function with dX = 1 and d = 20.
In this example, the confidence bounds of CMM-UCB are slightly tighter than those of AMM-
UCB, which are considerably tighter than those of OFUL. Next, we investigate the tightness
of the confidence bounds for functions with higher dimensional inputs (dX = 10), a range of
data set sizes (T âˆˆ{1, 2, 5, 10, 20, 50, 100, 200, 500, 1000}) and a range feature vector dimensions
(d âˆˆ{1, 2, 5, 10, 20, 50, 100}). For each T and d, we sample a random feature map Ï• and weight
vector Î¸ of appropriate size. Then, we sample random training data {(xt, yt)}T
t=1 and random test
points {xâ€²
t}100
t=1, where xk and xâ€²
t are drawn uniformly from the dX -dimensional unit hypercube.
Finally, we use the training data to construct confidence bounds with each method and calculate the
average width (UCB minus LCB) at the test points. Fig. 2 shows the average width of the CMM-UCB,
AMM-UCB and OFUL confidence bounds with: d = 10 and varying T (left), and T = 100 and
varying d (right). We observe the same pattern at every d and T: CMM-UCB produces the tightest
confidence bounds followed by AMM-UCB and then OFUL.
Effect of the Mixture Distributions.
Fig. 4 in App. E.1 shows the confidence bounds of CMM-
UCB and a Bayesian credible interval for different choices of the mixture distributions/prior Pt. For
a well-specified prior, either uninformative or informative, the Bayesian credible interval is slightly
tighter than the confidence bounds of CMM-UCB. For a misspecified prior, the confidence bounds of
CMM-UCB become looser whereas the Bayesian credible interval becomes wrong (not containing
the ground-truth function). Here, misspecification refers solely to Bayesian prior misspecification. In
Figs. 5 and 6 in App. E.2 we show that adaptive choices of the mixture distributions Pt can lead to
smaller confidence bounds and smaller cumulative regret in linear bandit problems.
8.2
Linear Bandits
Compared Methods.
We compare: (a) CMM-UCB: cf. Sec. 6.2; (b) AMM-UCB: cf. Sec. 6.3; (c)
OFUL: the OFUL algorithm (Abbasi-Yadkori et al., 2011), with regularisation parameter Î» = Î± = Ïƒ2;
(d) IDS: the frequentist Information Directed Sampling (IDS) algorithm (Kirschner & Krause, 2018),
specifically the DIDS-F version; (e) Freq-TS: Thompson Sampling with posterior covariance inflation
(Agrawal & Goyal, 2013), which we call Frequentist Thompson Sampling.
9

Table 1: Average test accuracy and maximum test accuracy of our UCB algorithms and OFUL, IDS
and Freq-TS in the SVM hyperparameter tuning problems after T = 500 rounds (100 repetitions).
Raisin
Maternal
Banknotes
Mean Acc
Max Acc
Mean Acc
Max Acc
Mean Acc
Max Acc
CMM-UCB (Ours)
0.818 Â± 0.018
0.893 Â± 0.019
0.744 Â± 0.020
0.829 Â± 0.023
0.954 Â± 0.005
1.000 Â± 0.000
AMM-UCB (Ours)
0.800 Â± 0.017
0.892 Â± 0.020
0.736 Â± 0.020
0.829 Â± 0.023
0.948 Â± 0.005
1.000 Â± 0.000
OFUL
0.764 Â± 0.019
0.891 Â± 0.019
0.722 Â± 0.019
0.827 Â± 0.022
0.929 Â± 0.006
1.000 Â± 0.000
IDS
0.706 Â± 0.048
0.891 Â± 0.020
0.714 Â± 0.019
0.827 Â± 0.024
0.926 Â± 0.007
1.000 Â± 0.000
Freq-TS
0.527 Â± 0.022
0.884 Â± 0.019
0.616 Â± 0.018
0.823 Â± 0.022
0.808 Â± 0.012
1.000 Â± 0.000
100
200
300
400
500
t
0.5
0.6
0.7
0.8
0.9
Test Accuracy
Raisin
CMM-UCB
AMM-UCB
OFUL
IDS
Freq-TS
100
200
300
400
500
t
0.45
0.50
0.55
0.60
0.65
0.70
0.75
0.80
Maternal
100
200
300
400
500
t
0.60
0.65
0.70
0.75
0.80
0.85
0.90
0.95
1.00
Banknotes
Figure 3: The smoothed per-round expected reward (test accuracy) of our UCB algorithms compared
with OFUL, IDS and Freq-TS in the SVM hyperparameter tuning experiments on three datasets.
Shown is the mean reward over 100 runs of each experiment, after Gaussian kernel smoothing.
Experimental Setup.
We investigate whether our tighter upper confidence bounds translate to
better UCB algorithms. We use each linear bandit algorithm to optimise the hyperparameters of
a kernel Support Vector Machine (SVM) for three classification data sets from the UCI Machine
Learning Repository (Dua & Graff, 2017): Raisin (Cinar et al., 2020), Maternal (Ahmed et al., 2020),
and Banknotes. The expected reward function f âˆ—(a) is the average test set accuracy of a kernel SVM
trained using an ARD RBF kernel with hyperparameters a = (C, Î³), with C the regularisation and Î³
the length-scales. The observed reward rt is the validation set accuracy at at. The feature map Ï• is a
neural network layer with 20 outputs and random weights. We choose Ïƒ = 0.05 for the sub-Gaussian
parameter and B = 10, i.e. we assume that f âˆ—(a) â‰ˆÏ•(a)âŠ¤Î¸âˆ—for some âˆ¥Î¸âˆ—âˆ¥2 â‰¤10.
Results.
Fig. 3 compares the average test accuracy (expected reward) obtained by each bandit
algorithm for each data set and at each round t = 1, . . . , 500. Our CMM-UCB and AMM-UCB
methods outperform all other methods. From the reward curves of CMM-UCB, AMM-UCB and
OFUL, we observe that CMM-UCB outperforms AMM-UCB, which outperforms OFUL. Therefore,
we can conclude that our tighter confidence bounds (compared to OFULâ€™s) lead to UCB algorithms
with improved performance.
9
Conclusion
In this paper, we developed a novel tail bound for adaptive martingale mixtures and showed that it can
be used to construct tighter confidence sequences for linear bandits. We proved that our CMM-UCB
and AMM-UCB algorithms match the worst-case cumulative regret of OFUL, and we found that our
tighter confidence sequences allowed CMM-UCB and AMM-UCB to achieve greater average and
maximum reward in several hyperparameter tuning problems.
A limitation of our algorithms is that they assume a linear expected reward function, which may not
always be a realistic assumption for real-world bandit problems. Our general-purpose tail bound
in Thm. 5.1 already allows one to derive confidence sequences for non-linear reward functions by
simply choosing Zt(ft) = (ft âˆ’f âˆ—(at))Ïµt, where f âˆ—is the non-linear reward function. In the case
where f âˆ—lies in a reproducing kernel Hilbert space, the corresponding UCB is still the solution of
a convex program. The main challenge in this setting is that the regret bound must now depend on
quantities like the effective dimension or the maximum information gain of the kernel, since the
dimension d of the feature vectors is d = âˆžfor interesting kernels.
We believe that further investigation into the degree to which adaptive mixture distributions can lead
to improved performance and regret bounds (see App. E.2) is another exciting topic for future work.
10

References
Abbasi-Yadkori, Y. Online learning for linearly parametrized control problems. PhD thesis, Univer-
sity of Alberta, 2012.
Abbasi-Yadkori, Y., Antos, A., and SzepesvÃ¡ri, C. Forced-exploration based algorithms for playing
in stochastic linear bandits. In COLT Workshop on On-line Learning with Limited Feedback,
volume 92, pp. 236, 2009.
Abbasi-Yadkori, Y., PÃ¡l, D., and SzepesvÃ¡ri, C. Improved algorithms for linear stochastic bandits.
Advances in neural information processing systems, 24, 2011.
Agrawal, A., Verschueren, R., Diamond, S., and Boyd, S. A rewriting system for convex optimization
problems. Journal of Control and Decision, 5(1):42â€“60, 2018.
Agrawal, A., Amos, B., Barratt, S., Boyd, S., Diamond, S., and Kolter, J. Z. Differentiable convex
optimization layers. Advances in neural information processing systems, 32, 2019.
Agrawal, S. and Goyal, N. Thompson sampling for contextual bandits with linear payoffs. In
International conference on machine learning, pp. 127â€“135. PMLR, 2013.
Ahmed, M., Kashem, M. A., Rahman, M., and Khatun, S. Review and analysis of risk factor of
maternal health in remote area using the internet of things (IoT). In InECCE2019: Proceedings
of the 5th International Conference on Electrical, Control & Computer Engineering, Kuantan,
Pahang, Malaysia, 29th July 2019, pp. 357â€“365. Springer, 2020.
Alquier, P. User-friendly introduction to PAC-Bayes bounds, 2021. URL https://arxiv.org/
abs/2110.11216.
Auer, P. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine
Learning Research, 3(Nov):397â€“422, 2002.
Boyd, S. and Vandenberghe, L. Convex optimization. Cambridge university press, 2004.
Camilleri, R., Jamieson, K., and Katz-Samuels, J. High-dimensional experimental design and kernel
bandits. In International Conference on Machine Learning, pp. 1227â€“1237. PMLR, 2021.
Chowdhury, S. R. and Gopalan, A. On kernelized multi-armed bandits. In International Conference
on Machine Learning, pp. 844â€“853. PMLR, 2017.
Chu, W., Li, L., Reyzin, L., and Schapire, R. Contextual bandits with linear payoff functions. In
Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, pp.
208â€“214. JMLR Workshop and Conference Proceedings, 2011.
Chugg, B., Wang, H., and Ramdas, A. A unified recipe for deriving (time-uniform) PAC-Bayes
bounds. arXiv preprint arXiv:2302.03421, 2023.
Cinar, I., Koklu, M., and Tasdemir, S. Classification of raisin grains using machine vision and
artificial intelligence methods. Gazi MÃ¼hendislik Bilimleri Dergisi, 6(3):200â€“209, 2020.
Cohen, M. C., Lobel, I., and Paes Leme, R. Feature-based dynamic pricing. Management Science,
66(11):4921â€“4943, 2020.
Dani, V., Hayes, T. P., and Kakade, S. M. Stochastic linear optimization under bandit feedback. In
COLT, pp. 355â€“366, 2008.
Darling, D. and Robbins, H. Some further remarks on inequalities for sample sums. Proceedings of
the National Academy of Sciences, 60(4):1175â€“1182, 1968.
de la PeÃ±a, V. H., Klass, M. J., and Leung Lai, T. Self-normalized processes: exponential inequalities,
moment bounds and iterated logarithm laws. Annals of Probability, 32:1902â€“1933, 2004.
de la PeÃ±a, V. H., Lai, T. L., and Shao, Q.-M. Self-normalized processes: Limit theory and Statistical
Applications. Springer, 2009.
11

Diamond, S. and Boyd, S. CVXPY: A Python-embedded modeling language for convex optimization.
Journal of Machine Learning Research, 17(83):1â€“5, 2016.
Donsker, M. D. and Varadhan, S. S. Asymptotic evaluation of certain Markov process expectations
for large timeâ€”iii. Communications on pure and applied Mathematics, 29(4):389â€“461, 1976.
Dua, D. and Graff, C. UCI machine learning repository, 2017. URL http://archive.ics.uci.
edu/ml.
Durand, A., Maillard, O.-A., and Pineau, J. Streaming kernel regression with provably adaptive mean,
variance, and regularization. The Journal of Machine Learning Research, 19(1):650â€“683, 2018.
GrÃ¼nwald, P. D. The minimum description length principle. MIT press, 2007.
GrÃ¼nwald, P. D. The e-posterior. Philosophical Transactions of the Royal Society A, 381(2247):
20220146, 2023.
Guedj, B. A primer on PAC-Bayesian learning. In Proceedings of the second congress of the French
Mathematical Society, volume 33, 2019. URL https://arxiv.org/abs/1901.05353.
Haddouche, M. and Guedj, B. Online PAC-Bayes learning. In Advances in Neural Information
Processing Systems, volume 35, pp. 25725â€“25738. Curran Associates, Inc., 2022.
Haddouche, M. and Guedj, B. PAC-Bayes generalisation bounds for heavy-tailed losses through
supermartingales. Transactions on Machine Learning Research [TMLR], 2023. ISSN 2835-8856.
doi: 10.48550/ARXIV.2210.00928. URL https://openreview.net/forum?id=qxrwt6F3sf.
Howard, S. R., Ramdas, A., McAuliffe, J., and Sekhon, J. Time-uniform Chernoff bounds via
nonnegative supermartingales. Probability Surveys, 17, 2020.
Kaufmann, E. and Koolen, W. M. Mixture martingales revisited with applications to sequential tests
and confidence intervals. The Journal of Machine Learning Research, 22(1):11140â€“11183, 2021.
Kirschner, J. and Krause, A. Information directed sampling and bandits with heteroscedastic noise.
In Conference On Learning Theory, pp. 358â€“384. PMLR, 2018.
Lai, T. L. On confidence sequences. The Annals of Statistics, pp. 265â€“280, 1976.
Li, L., Chu, W., Langford, J., and Schapire, R. E. A contextual-bandit approach to personalized news
article recommendation. In Proceedings of the 19th international conference on World wide web,
pp. 661â€“670, 2010.
Li, Z. and Scarlett, J. Gaussian process bandit optimization with few batches. In International
Conference on Artificial Intelligence and Statistics, pp. 92â€“107. PMLR, 2022.
McAllester, D. A. Some PAC-Bayesian theorems. In Proceedings of the eleventh annual conference
on Computational learning theory, pp. 230â€“234, 1998.
Molchanov, I. S. Theory of random sets, volume 19. Springer, 2005.
Neiswanger, W. and Ramdas, A. Uncertainty quantification using martingales for misspecified
Gaussian processes. In Algorithmic Learning Theory, pp. 963â€“982. PMLR, 2021.
Petersen, K. B., Pedersen, M. S., et al. The matrix cookbook. Technical University of Denmark, 7
(15), 2008.
Rahimi, A. and Recht, B. Random features for large-scale kernel machines. Advances in neural
information processing systems, 20, 2007.
Robbins, H. Statistical methods related to the law of the iterated logarithm. The Annals of Mathemat-
ical Statistics, 41(5):1397â€“1409, 1970.
Robbins, H. and Siegmund, D. Boundary crossing probabilities for the Wiener process and sample
sums. The Annals of Mathematical Statistics, pp. 1410â€“1429, 1970.
12

Rusmevichientong, P. and Tsitsiklis, J. N. Linearly parameterized bandits. Mathematics of Operations
Research, 35(2):395â€“411, 2010.
Russo, D. and Van Roy, B. Eluder dimension and the sample complexity of optimistic exploration.
Advances in Neural Information Processing Systems, 26, 2013.
Salgia, S., Vakili, S., and Zhao, Q. A domain-shrinking based Bayesian optimization algorithm
with order-optimal regret performance. Advances in Neural Information Processing Systems, 34:
28836â€“28847, 2021.
Shawe-Taylor, J. and Williamson, R. C. A PAC analysis of a Bayesian estimator. In Proceedings of
the tenth annual conference on Computational learning theory, pp. 2â€“9, 1997.
Sherman, J. and Morrison, W. J. Adjustment of an inverse matrix corresponding to a change in one
element of a given matrix. The Annals of Mathematical Statistics, 21(1):124â€“127, 1950.
Srinivas, N., Krause, A., Kakade, S., and Seeger, M. Gaussian process optimization in the bandit
setting: No regret and experimental design. In Proc. International Conference on Machine Learning
(ICML), 2010.
Valko, M., Korda, N., Munos, R., Flaounas, I., and Cristianini, N. Finite-Time Analysis of Kernelised
Contextual Bandits. In Uncertainty in Artificial Intelligence, 2013.
Ville, J. Etude critique de la notion de collectif. Bull. Amer. Math. Soc, 45(11):824, 1939.
13

A
Proof of the General-Purpose Tail Bound for Adaptive Martingale
Mixtures
A.1
Verifying Martingale Properties
First, we recall the definition of (Mt(f t, Î»t)|t âˆˆN) in Eq. (3). We are given a filtration (Ht|t âˆˆN),
a sequence of adapted random functions (Zt : R â†’R|t âˆˆN), and a sequence of predictable random
variables (Î»t|t âˆˆN).
A filtration is an increasing sequence of Ïƒ-algebras H0 âŠ†H1 âŠ†H2 Â· Â· Â· . Each Ïƒ-algebra Ht
represents the information available at time t. (Zt : R â†’R|t âˆˆN) being a sequence of adapted (to
the filtration (Ht|t âˆˆN)) functions means that, when conditioned on Ht, Zt is no longer random.
(Î»t|t âˆˆN) being a sequence of predictable random variables means that, when conditioned on Htâˆ’1,
Î»t is no longer random.
For a sequence of real numbers (ft : t âˆˆN), we define
Mt(f t, Î»t) = exp
 
t
X
k=1
Î»kZk(fk) âˆ’Ïˆk(fk, Î»k)
!
,
where Ïˆt(ft, Î»t) is the conditional cumulant generating function
Ïˆt(ft, Î»t) := ln (E [exp(Î»tZt(ft))|Htâˆ’1]) .
Lemma A.1. For any sequence of real numbers (ft|t âˆˆN), (Mt(f t, Î»t)|t âˆˆN) is a martingale and
E[Mt(f t, Î»t)] = 1 for all t âˆˆN.
Proof. For t = 1, we have
E[M1(f 1, Î»1)|H0] = E [exp(Î»1Z1(f1) âˆ’Ïˆ1(f1, Î»1))|H0]
= E [exp(Î»1Z1(f1))|H0] / exp(Ïˆ1(f1, Î»1))
= exp(Ïˆ1(f1, Î»1))/ exp(Ïˆ1(f1, Î»1))
= 1.
Using the tower rule of conditional expectation, we also have
E[M1(f 1, Î»1)] = E[E[M1(f 1, Î»1)|H0]] = 1.
Now, we verify the martingale property. For any t â‰¥2, we have
E [Mt(f t, Î»t)|Htâˆ’1] = E
"
exp
 
t
X
k=1
Î»kZk(fk) âˆ’Ïˆk(fk, Î»k)
! Htâˆ’1
#
= exp
 tâˆ’1
X
k=1
Î»kZk(fk) âˆ’Ïˆk(fk, Î»k)
!
E [exp (Î»tZt(ft) âˆ’Ïˆt(ft, Î»t)) |Htâˆ’1]
= exp
 tâˆ’1
X
k=1
Î»kZk(fk) âˆ’Ïˆk(fk, Î»k)
!
= Mtâˆ’1(f tâˆ’1, Î»tâˆ’1).
Using the tower rule again, we have for any t â‰¥2
E[Mt(f t, Î»t)] = E[E[Mt(f t, Î»t)|Htâˆ’1]] = E[Mtâˆ’1(f tâˆ’1, Î»tâˆ’1)].
Therefore, we have
E[Mt(f t, Î»t)] = E[Mtâˆ’1(f tâˆ’1, Î»tâˆ’1)] = Â· Â· Â· = E[M1(f 1, Î»1)] = 1.
14

Lemma
A.2.
For
any
adaptive
sequence
of
mixture
distributions
(Pt|t
âˆˆ
N),
(Ef tâˆ¼Pt[Mt(f t, Î»t)]|t âˆˆN) is a martingale and E[Ef tâˆ¼Pt[Mt(f t, Î»t)]] = 1 for all t âˆˆN.
Proof. For any t â‰¥1, since Mt(f t, Î»t) is non-negative and Pt is Htâˆ’1-measurable, Tonelliâ€™s
theorem implies
E

Ef tâˆ¼Pt[Mt(f t, Î»t)]|Htâˆ’1

= Ef tâˆ¼Pt [E[Mt(f t, Î»t)|Htâˆ’1]] .
The requirement that the distributions P1, P2, . . . have coinciding marginals, i.e.
R
Pt(f t)dft =
Ptâˆ’1(f tâˆ’1), means that for all t â‰¥2
Ef tâˆ¼Pt[Mtâˆ’1(f tâˆ’1, Î»tâˆ’1)] = Ef tâˆ’1âˆ¼Ptâˆ’1[Mtâˆ’1(f tâˆ’1, Î»tâˆ’1)].
Using these two results, and the fact that (Mt(f t, Î»t)|t âˆˆN) is a martingale for any sequence
(ft|t âˆˆN), we now verify that the martingale mixture (Ef tâˆ¼Pt[Mt(f t, Î»t)]|t âˆˆN) is a martingale
with expected value 1. For t = 1, we have
E

Ef 1âˆ¼P1[M1(f 1, Î»1)]|H0

= Ef 1âˆ¼P1 [E[M1(f 1, Î»1)|H0]]
= Ef 1âˆ¼P1 [1]
= 1.
Using the tower rule as before, this also means that E

Ef 1âˆ¼P1[M1(f 1, Î»1)]

= 1. For any t â‰¥2,
we have
E

Ef tâˆ¼Pt[Mt(f t, Î»t)]|Htâˆ’1

= Ef tâˆ¼Pt [E[Mt(f t, Î»t)|Htâˆ’1]]
= Ef tâˆ¼Pt

Mtâˆ’1(f tâˆ’1, Î»tâˆ’1)

= Ef tâˆ’1âˆ¼Ptâˆ’1

Mtâˆ’1(f tâˆ’1, Î»tâˆ’1)

.
Using the tower rule one more time, we have for any t â‰¥2
E[Ef tâˆ¼Pt[Mt(f t, Î»t)]] = E[E[Ef tâˆ¼Pt[Mt(f t, Î»t)]|Htâˆ’1]] = E[Ef tâˆ’1âˆ¼Ptâˆ’1[Mtâˆ’1(f tâˆ’1, Î»tâˆ’1)]].
Therefore, we have
E[Ef tâˆ¼Pt[Mt(f t, Î»t)]] = E[Ef 1âˆ¼P1[M1(f 1, Î»1)]] = 1.
A.2
Proof of Theorem 5.1
To prove Thm. 5.1, we use Villeâ€™s inequality for non-negative supermartingales (Ville, 1939), which
can be thought of as a time-uniform version of Markovâ€™s inequality. Instead of the martingale property
E[Mt|Htâˆ’1] = Mtâˆ’1, a supermartingale satisfies E[Mt|Htâˆ’1] â‰¤Mtâˆ’1, which means that any
martingale is also a supermartingale. Therefore, Villeâ€™s inequality for non-negative supermartingales
also holds for the non-negative martingale in Lemma A.2.
Lemma A.3 (Villeâ€™s inequality for non-negative supermartingales (Ville, 1939)). Let (Mt|t âˆˆN) be
a non-negative supermartingale with respect to the filtration (Ht|t âˆˆN), which satisfies M0 = 1.
For any Î´ âˆˆ(0, 1], it holds with probability at least 1 âˆ’Î´:
âˆ€t â‰¥1 :
Mt â‰¤1/Î´.
Proof of Thm. 5.1. We choose an arbitrary Î´ âˆˆ(0, 1]. From Lemma A.2, for any adaptive se-
quence of mixture distributions (Pt|t âˆˆN), (Ef tâˆ¼Pt[Mt(f t, Î»t)]|t âˆˆN) is a martingale and
E[Ef tâˆ¼Pt[Mt(f t, Î»t)]] = 1. In addition, (Ef tâˆ¼Pt[Mt(f t, Î»t)]|t âˆˆN) is clearly non-negative.
Therefore, using Lemma A.3, with probability at least 1 âˆ’Î´
âˆ€t â‰¥1,
Ef tâˆ¼Pt[Mt(f t, Î»t)] â‰¤1/Î´.
Taking the logarithm of both sides yields the statement of Thm. 5.1.
15

B
Closed-Form Gaussian Integration
Here, we calculate the integral in the inequality (see beginning of Sec. 5.2):
E
f tâˆ¼N(Âµt,T t)
"
exp
(
t
X
k=1
Î»k(fk âˆ’Ï•(ak)âŠ¤Î¸âˆ—)(rk âˆ’Ï•(ak)âŠ¤Î¸âˆ—) âˆ’Ïƒ2
2 Î»2
k(fk âˆ’Ï•(ak)âŠ¤Î¸âˆ—)2
)#
â‰¤1
Î´ .
(12)
First, we rearrange the integrand into a more convenient form. For every k, using rk = Ï•(ak)âŠ¤Î¸âˆ—+Ïµk,
we have
(Ï•(ak)âŠ¤Î¸âˆ—âˆ’rk)2 âˆ’(fk âˆ’rk)2 = Ïµ2
k âˆ’(fk âˆ’Ï•(ak)âŠ¤Î¸âˆ—âˆ’Ïµk)2
= Ïµ2
k âˆ’(fk âˆ’Ï•(ak)âŠ¤Î¸âˆ—)2 + 2(fk âˆ’Ï•(ak)âŠ¤Î¸âˆ—)Ïµk âˆ’Ïµ2
k
= 2(fk âˆ’Ï•(ak)âŠ¤Î¸âˆ—)(rk âˆ’Ï•(ak)âŠ¤Î¸âˆ—) âˆ’(fk âˆ’Ï•(ak)âŠ¤Î¸âˆ—)2.
Therefore, we have that
Î»k(fk âˆ’Ï•(ak)âŠ¤Î¸âˆ—)(rk âˆ’Ï•(ak)âŠ¤Î¸âˆ—) âˆ’Ïƒ2
2 Î»2
k(fk âˆ’Ï•(ak)âŠ¤Î¸âˆ—)2
= Î»k
2 (Ï•(ak)âŠ¤Î¸âˆ—âˆ’rk)2 âˆ’Î»k
2 (fk âˆ’rk)2 + 1
2(Î»k âˆ’Ïƒ2Î»2
k)(fk âˆ’Ï•(ak)âŠ¤Î¸âˆ—)2.
Equation (12) can now be re-written as
E
f tâˆ¼N(Âµt,T t)
"
exp
(
t
X
k=1
Î»k
2 (Ï•(ak)âŠ¤Î¸âˆ—âˆ’rk)2 âˆ’Î»k
2 (fk âˆ’rk)2 + 1
2(Î»k âˆ’Ïƒ2Î»2
k)(fk âˆ’Ï•(ak)âŠ¤Î¸âˆ—)2
)#
â‰¤1
Î´ .
(13)
In the special case where Î»t â‰¡1/Ïƒ2, we have Î»k âˆ’Ïƒ2Î»2
k = 0, which means that 1
2(Î»k âˆ’Ïƒ2Î»2
k)(fk âˆ’
Ï•(ak)âŠ¤Î¸âˆ—)2 disappears. In addition, (Î»k/2)(Ï•(ak)âŠ¤Î¸âˆ—âˆ’rk)2 does not depend on fk, so it can be
moved outside the integral.
B.1
General Î»t
Let Î›t be the t Ã— t diagonal matrix with diagonal elements Î»1, Î»2, . . . , Î»t. Starting from (13), taking
the logarithm of both sides, rearranging terms and then writing everything in matrix notation, we
arrive at
(Î¦tÎ¸âˆ—âˆ’rt)Î›t(Î¦tÎ¸âˆ—âˆ’rt) â‰¤2 ln(1/Î´)
(14)
âˆ’2 ln

E
f tâˆ¼N(Âµt,T t)

exp

âˆ’1
2(f t âˆ’rt)âŠ¤Î›t(f t âˆ’rt) + 1
2(f t âˆ’Î¦tÎ¸âˆ—)âŠ¤ Î›t âˆ’Ïƒ2Î›2
t

(f t âˆ’Î¦tÎ¸âˆ—)

The expected value inside the logarithm can be re-written as
1
p
(2Ï€)t det(T t)
Z
exp

âˆ’1
2(f t âˆ’Âµt)âŠ¤T âˆ’1
t (f t âˆ’Âµt) âˆ’1
2(f t âˆ’rt)âŠ¤Î›t(f t âˆ’rt)
(15)
+ 1
2(f t âˆ’Î¦tÎ¸âˆ—)âŠ¤ Î›t âˆ’Ïƒ2Î›2
t

(f t âˆ’Î¦tÎ¸âˆ—)

df t.
We will calculate the integral by â€œcompleting the squareâ€, i.e. rewriting the exponent in the form
âˆ’1
2(f t âˆ’b)âŠ¤A(f t âˆ’b) + c, to recover the integral of a Gaussian density function. For a symmetric
matrix A, we have
âˆ’1
2(f t âˆ’b)âŠ¤A(f t âˆ’b) + c = âˆ’1
2f âŠ¤
t Af t + bâŠ¤Af t âˆ’1
2bâŠ¤Ab + c.
16

We also have
âˆ’1
2(f t âˆ’Âµt)âŠ¤T âˆ’1
t (f t âˆ’Âµt) = âˆ’1
2f âŠ¤
t T âˆ’1
t f t + ÂµâŠ¤
t T âˆ’1
t f t âˆ’1
2ÂµâŠ¤
t T âˆ’1
t Âµt
âˆ’1
2(f t âˆ’rt)âŠ¤Î›t(f t âˆ’rt) = âˆ’1
2f âŠ¤
t Î›tf t + râŠ¤
t Î›tf t âˆ’1
2râŠ¤
t Î›trt
1
2(f t âˆ’Î¦tÎ¸âˆ—)âŠ¤ Î›t âˆ’Ïƒ2Î›2
t

(f t âˆ’Î¦tÎ¸âˆ—) = 1
2f âŠ¤
t
 Î›t âˆ’Ïƒ2Î›2
t

f t âˆ’Î¸âˆ—âŠ¤Î¦âŠ¤
t
 Î›t âˆ’Ïƒ2Î›2
t

f t
+ 1
2Î¸âˆ—âŠ¤Î¦âŠ¤
t
 Î›t âˆ’Ïƒ2Î›2
t

Î¦tÎ¸âˆ—.
We now equate coefficients to find A, b and c. We find that A is
A = T âˆ’1
t
+ Ïƒ2Î›2
t.
Note that A is symmetric. We find that b is
bâŠ¤A = ÂµâŠ¤
t T âˆ’1
t
+ râŠ¤
t Î›t âˆ’Î¸âˆ—âŠ¤Î¦âŠ¤
t
 Î›t âˆ’Ïƒ2Î›2
t

=â‡’Ab = T âˆ’1
t Âµt + Î›trt âˆ’
 Î›t âˆ’Ïƒ2Î›2
t

Î¦tÎ¸âˆ—
=â‡’b =
 T âˆ’1
t
+ Ïƒ2Î›2
t
âˆ’1  T âˆ’1
t Âµt + Î›trt âˆ’
 Î›t âˆ’Ïƒ2Î›2
t

Î¦tÎ¸âˆ—
.
Finally, we find that c is
c = 1
2bâŠ¤Ab âˆ’1
2ÂµâŠ¤
t T âˆ’1
t Âµt âˆ’1
2râŠ¤
t Î›trt + 1
2Î¸âˆ—âŠ¤Î¦âŠ¤
t
 Î›t âˆ’Ïƒ2Î›2
t

Î¦tÎ¸âˆ—
= 1
2
 T âˆ’1
t Âµt + Î›trt âˆ’
 Î›t âˆ’Ïƒ2Î›2
t

Î¦tÎ¸âˆ—âŠ¤ T âˆ’1
t
+ Ïƒ2Î›2
t
âˆ’1  T âˆ’1
t Âµt + Î›trt âˆ’
 Î›t âˆ’Ïƒ2Î›2
t

Î¦tÎ¸âˆ—
âˆ’1
2ÂµâŠ¤
t T âˆ’1
t Âµt âˆ’1
2râŠ¤
t Î›trt + 1
2Î¸âˆ—âŠ¤Î¦âŠ¤
t
 Î›t âˆ’Ïƒ2Î›2
t

Î¦tÎ¸âˆ—
Now, we can rewrite and calculate the integral in (15) as
exp(c)
p
(2Ï€)t det(T t)
Z
exp

âˆ’1
2(f t âˆ’b)âŠ¤A(f t âˆ’b)

df t =
exp(c)
q
(2Ï€)t det(Aâˆ’1)
p
(2Ï€)t det(T t)
= exp(c)
s
det(Aâˆ’1)
det(T t)
Substituting this into (14), we obtain the constraint
(Î¦tÎ¸âˆ—âˆ’rt)âŠ¤Î›t(Î¦tÎ¸âˆ—âˆ’rt) â‰¤âˆ’2 ln
ï£«
ï£­exp(c)
s
det(Aâˆ’1)
det(T t)
ï£¶
ï£¸+ 2 ln(1/Î´)
= âˆ’2c + ln (det(AT t)) + 2 ln(1/Î´)
= âˆ’
 T âˆ’1
t Âµt + Î›trt âˆ’
 Î›t âˆ’Ïƒ2Î›2
t

Î¦tÎ¸âˆ—âŠ¤ T âˆ’1
t
+ Ïƒ2Î›2
t
âˆ’1  T âˆ’1
t Âµt + Î›trt âˆ’
 Î›t âˆ’Ïƒ2Î›2
t

Î¦tÎ¸âˆ—
+ ÂµâŠ¤
t T âˆ’1
t Âµt + râŠ¤
t Î›trt âˆ’Î¸âˆ—âŠ¤Î¦âŠ¤
t
 Î›t âˆ’Ïƒ2Î›2
t

Î¦tÎ¸âˆ—+ ln
 det(1 + Ïƒ2Î›2
tT t)

+ 2 ln(1/Î´)
Note that Î¸âˆ—appears on both the left-hand-side and right-hand-side of this inequality. However,
when Î›t âˆ’Ïƒ2Î›2
t is the zero matrix (e.g. when Î»t â‰¡1/Ïƒ2), all the Î¸âˆ—-dependent terms on the
right-hand-side disappear.
B.2
The Special Case Î»t â‰¡1/Ïƒ2
Starting from (13), choosing Î»t â‰¡1/Ïƒ2, taking the logarithm of both sides and then rearranging
terms, we arrive at
âˆ¥Î¦tÎ¸âˆ—âˆ’rtâˆ¥2
2 â‰¤âˆ’2Ïƒ2 ln

E
f tâˆ¼N(Âµt,T t)

exp

âˆ’1
2Ïƒ2 (f t âˆ’rt)âŠ¤(f t âˆ’rt)

+ 2Ïƒ2 ln(1/Î´).
(16)
17

For any tÃ—t covariance matrix T , let Z(T ) denote the normalising constant of a Gaussian distribution
with covariance T , so
Z(T ) =
p
(2Ï€)t det(T ).
For any t-dimensional vectors x and Âµ, and any t Ã— t covariance matrix T , let p(x|Âµ, T ) denote
the density function of a Gaussian distribution with mean Âµ and covariance T , evaluated at x. This
means that
p(x|Âµ, T ) =
1
Z(T )exp

âˆ’1
2(x âˆ’Âµ)âŠ¤T âˆ’1(x âˆ’Âµ)

.
We will use the product of Gaussians trick from (Petersen et al., 2008) (Section 8.1.8, Equation 371),
which states
p(x|Âµ1, Î£1)p(x|Âµ2, Î£2) = p(Âµ1|Âµ2, Î£1 + Î£2)p(x|Âµc, Î£c),
(17)
where
Âµc =
 Î£âˆ’1
1
+ Î£âˆ’1
2
âˆ’1 (Î£âˆ’1
1 Âµ1 + Î£âˆ’1
2 Âµ2),
Î£c =
 Î£âˆ’1
1
+ Î£âˆ’1
2
âˆ’1 .
We have that
E
f tâˆ¼N(Âµt,T t)

exp

âˆ’1
2Ïƒ2 (f t âˆ’rt)âŠ¤(f t âˆ’rt)

=
E
f tâˆ¼N(Âµt,T t)

Z(Ïƒ21)p(f t|rt, Ïƒ21)

= Z(Ïƒ21)
Z
Rt p(f t|Âµt, T t)p(f t|rt, Ïƒ21)df t
= Z(Ïƒ21)
Z
Rt p(Âµt|rt, T t + Ïƒ21)p(f t|Âµc, Î£c)df t
= Z(Ïƒ21)p(Âµt|rt, T t + Ïƒ21)
=
s
det(Ïƒ21)
det(T t + Ïƒ21) exp

âˆ’1
2(Âµt âˆ’rt)âŠ¤(T t + Ïƒ21)âˆ’1(Âµt âˆ’rt)

Substituting this into (16), the constraint becomes
âˆ¥Î¦tÎ¸âˆ—âˆ’rtâˆ¥2
2 â‰¤Ïƒ2(Âµt âˆ’rt)âŠ¤(T t + Ïƒ21)âˆ’1(Âµt âˆ’rt) âˆ’2Ïƒ2 ln
 s
det(Ïƒ21)
det(T t + Ïƒ21)
!
+ 2Ïƒ2 ln
1
Î´

.
= (Âµt âˆ’rt)âŠ¤

1 + T t
Ïƒ2
âˆ’1
(Âµt âˆ’rt) + Ïƒ2 ln det

1 + T t
Ïƒ2

+ 2Ïƒ2 ln
1
Î´

.
C
Computing Upper Confidence Bounds
First, we state and prove some useful lemmas.
Lemma C.1. For any Î± > 0
(Î¦tÎ¸âˆ’rt)âŠ¤(Î¦tÎ¸âˆ’rt)+Î±Î¸âŠ¤Î¸âˆ’R2
MM,tâˆ’Î±B2 = (Î¸âˆ’bÎ¸Î±,t)âŠ¤ Î¦âŠ¤
t Î¦t + Î±1

(Î¸âˆ’bÎ¸Î±,t)âˆ’R2
AMM,t,
where R2
MM,t is the squared radius quantity from Cor. 5.2 and
bÎ¸Î±,t =
 Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Î¦âŠ¤
t rt,
R2
AMM,t = R2
MM,t + Î±B2 âˆ’râŠ¤
t rt + râŠ¤
t Î¦t
 Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Î¦âŠ¤
t rt.
Proof. For any symmetric matrix A, we have
(Î¸ âˆ’b)âŠ¤A(Î¸ âˆ’b) + c = Î¸âŠ¤AÎ¸ âˆ’2bâŠ¤AÎ¸ + bâŠ¤Ab + c.
We also have
(Î¦tÎ¸âˆ’rt)âŠ¤(Î¦tÎ¸âˆ’rt)+Î±Î¸âŠ¤Î¸âˆ’R2
MM,tâˆ’Î±B2 = Î¸âŠ¤ Î¦âŠ¤
t Î¦t + Î±1

Î¸âˆ’2râŠ¤
t Î¦tÎ¸+râŠ¤
t rtâˆ’R2
MM,tâˆ’Î±B2.
18

We can now find A, b and c by equating coefficients. We find that
A = Î¦âŠ¤
t Î¦t + Î±1,
which is a symmetric matrix. We have
bâŠ¤A = râŠ¤
t Î¦t
=â‡’Ab = Î¦âŠ¤
t rt
=â‡’b =
 Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Î¦âŠ¤
t rt = bÎ¸Î±,t.
Finally, we have
c = âˆ’R2
MM,t âˆ’Î±B2 + râŠ¤
t rt âˆ’bâŠ¤Ab
= âˆ’R2
MM,t âˆ’Î±B2 + râŠ¤
t rt âˆ’râŠ¤
t Î¦t
 Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Î¦âŠ¤
t rt
= âˆ’R2
AMM,t.
Therefore, we have shown that
(Î¦tÎ¸âˆ’rt)âŠ¤(Î¦tÎ¸âˆ’rt)+Î±Î¸âŠ¤Î¸âˆ’R2
MM,tâˆ’Î±B2 = (Î¸âˆ’bÎ¸Î±,t)âŠ¤ Î¦âŠ¤
t Î¦t + Î±1

(Î¸âˆ’bÎ¸Î±,t)âˆ’R2
AMM,t.
Lemma C.2. For any symmetric, positive-definite matrix A âˆˆRdÃ—d, any vectors a, b âˆˆRd, any
R > 0, and any Î· < 0,
max
Î¸âˆˆRd

aâŠ¤Î¸ + Î·
 (Î¸ âˆ’b)âŠ¤A(Î¸ âˆ’b) âˆ’R2	
= aâŠ¤b âˆ’1
4Î· aâŠ¤Aâˆ’1a âˆ’Î·R2.
Proof. Let
f(Î¸) = aâŠ¤Î¸ + Î·
 (Î¸ âˆ’b)âŠ¤A(Î¸ âˆ’b) âˆ’R2
The gradient and Hessian of f are
âˆ‚
âˆ‚Î¸ f(Î¸) = a + 2Î·A(Î¸ âˆ’b),
âˆ‚2
âˆ‚Î¸2 f(Î¸) = 2Î·A.
Since A is positive-definite and Î· < 0,
âˆ‚2
âˆ‚Î¸2 f(Î¸) is negative-definite for all Î¸ âˆˆRd. Therefore, any
solution Î¸âˆ—of
âˆ‚
âˆ‚Î¸ f(Î¸) = 0 must be a maximiser of f(Î¸). There is a unique solution, which is
Î¸âˆ—= b âˆ’1
2Î· Aâˆ’1a.
The maximum is
f(Î¸âˆ—) = aâŠ¤b âˆ’1
4Î· aâŠ¤Aâˆ’1a âˆ’Î·R2.
Lemma C.3. For any symmetric, positive-definite matrix A âˆˆRdÃ—d, any vectors a, b âˆˆRd, and
any R > 0,
min
Î·<0

aâŠ¤b âˆ’1
4Î· aâŠ¤Aâˆ’1a âˆ’Î·R2

= aâŠ¤b + R
p
aâŠ¤Aâˆ’1a.
Proof. Let
g(Î·) = aâŠ¤b âˆ’1
4Î· aâŠ¤Aâˆ’1a âˆ’Î·R2.
19

The first and second derivatives of g are
d
dÎ· g(Î·) =
1
4Î·2 aâŠ¤Aâˆ’1a âˆ’R2,
d2
dÎ·2 g(Î·) = âˆ’1
2Î·3 aâŠ¤Aâˆ’1a.
Since A is positive-definite,
d2
dÎ·2 g(Î·) is positive for all Î· < 0. Therefore, any negative solution Î·âˆ—of
d
dÎ· g(Î·) = 0 must be a minimiser of g(Î·). There is a unique (negative) solution, which is
Î·âˆ—= âˆ’1
2R
p
aâŠ¤Aâˆ’1a.
The minimum is
g(Î·âˆ—) = aâŠ¤b + R
p
aâŠ¤Aâˆ’1a.
C.1
Analytic UCBs
Here, we prove Theorem 6.1, which states that for all Î± > 0:
max
Î¸âˆˆÎ˜t

Ï•(a)âŠ¤Î¸
	
â‰¤Ï•(a)âŠ¤bÎ¸Î±,t + RAMM,t
q
Ï•(a)âŠ¤ Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Ï•(a),
(18)
where
bÎ¸Î±,t =
 Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Î¦âŠ¤
t rt,
R2
AMM,t = R2
MM,t + Î±B2 âˆ’râŠ¤
t rt + râŠ¤
t Î¦t
 Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Î¦âŠ¤
t rt.
Î˜t is the confidence set at time t in our confidence sequence from Cor. 5.2 and RMM,t is the radius
from Cor. 5.2 and Eq. (5). As well as proving this statement, we will also show that if Î˜t has an
interior point, then when the right-hand-side of (18) is optimised with respect to Î± > 0, the inequality
in (18) becomes an equality, i.e.
max
Î¸âˆˆÎ˜t

Ï•(a)âŠ¤Î¸
	
= min
Î±>0

Ï•(a)âŠ¤bÎ¸Î±,t + RAMM,t
q
Ï•(a)âŠ¤ Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Ï•(a)

.
(19)
Proof of Thm. 6.1. We use weak Lagrangian duality to prove the upper bound and strong Lagrangian
duality to prove the second part. The convex optimisation problem maxÎ¸âˆˆÎ˜t

Ï•(a)âŠ¤Î¸
	
can be stated
as
max
Î¸âˆˆRd Ï•(a)âŠ¤Î¸
s.t. (Î¦tÎ¸ âˆ’rt)âŠ¤(Î¦tÎ¸ âˆ’rt) â‰¤R2
MM,t
and
Î¸âŠ¤Î¸ â‰¤B2.
(20)
Rewriting both constraints in the form f(Î¸) â‰¤0, we can see that the Lagrangian for this problem is
L(Î¸, Î·1, Î·2) = Ï•(a)âŠ¤Î¸ + Î·1
 (Î¦tÎ¸ âˆ’rt)âŠ¤(Î¦tÎ¸ âˆ’rt) âˆ’R2
MM,t

+ Î·2

Î¸âŠ¤Î¸ âˆ’B2
.
Î·1 and Î·2 are called the Lagrange multipliers. The Lagrange dual function (or just dual function) is
g(Î·1, Î·2) = max
Î¸âˆˆRd {L(Î¸, Î·1, Î·2} .
By weak duality, for any Î·1, Î·2 â‰¤0, the dual function is an upper bound on the solution of the primal
problem in (20), i.e. for any Î·1, Î·2 â‰¤0
max
Î¸âˆˆÎ˜t

Ï•(a)âŠ¤Î¸
	
â‰¤g(Î·1, Î·2).
(21)
Alternatively, (21) can be verified by starting from the inequality Ï•(a)âŠ¤Î¸ â‰¤L(Î¸, Î·1, Î·2) for all
Î¸ âˆˆÎ˜t, Î·1 â‰¤0, and Î·2 â‰¤0. The challenge is to set the Lagrange multipliers such that the
dual function has a closed-form expression while being as close as possible to its minimum value
minÎ·1,Î·2â‰¤0 {g(Î·1, Î·2)}. We will now show that for any Î± > 0, minÎ·â‰¤0 {g(Î·, Î±Î·)} has a closed-
form solution, which is the right-hand-side of (18). The Lagrangian, evaluated with the Lagrange
multipliers Î· and Î±Î·, is
L(Î¸, Î·, Î±Î·) = Ï•(a)âŠ¤Î¸ + Î·

(Î¦tÎ¸ âˆ’rt)âŠ¤(Î¦tÎ¸ âˆ’rt) + Î±Î¸âŠ¤Î¸ âˆ’R2
MM,t âˆ’Î±B2
.
20

Using Lemma C.1, the Lagrangian can be rewritten as
L(Î¸, Î·, Î±Î·) = Ï•(a)âŠ¤Î¸ + Î·

(Î¸ âˆ’bÎ¸Î±,t)âŠ¤ Î¦âŠ¤
t Î¦t + Î±1

(Î¸ âˆ’bÎ¸Î±,t) âˆ’R2
AMM,t

.
Using Lemma C.2, the dual function evaluated at Î· and Î±Î· is
g(Î·, Î±Î·) = max
Î¸âˆˆRd
n
Ï•(a)âŠ¤Î¸ + Î·

(Î¸ âˆ’bÎ¸Î±,t)âŠ¤ Î¦âŠ¤
t Î¦t + Î±1

(Î¸ âˆ’bÎ¸Î±,t) âˆ’R2
AMM,t
o
= Ï•(a)âŠ¤bÎ¸Î±,t âˆ’1
4Î· Ï•(a)âŠ¤ Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Ï•(a) âˆ’Î·R2
AMM,t.
Using Lemma C.3, we have
min
Î·â‰¤0 {g(Î·, Î±Î·)} = min
Î·â‰¤0

Ï•(a)âŠ¤bÎ¸Î±,t âˆ’1
4Î· Ï•(a)âŠ¤ Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Ï•(a) âˆ’Î·R2
AMM,t

= Ï•(a)âŠ¤bÎ¸Î±,t + RAMM,t
q
Ï•(a)âŠ¤ Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Ï•(a).
This concludes the proof of Theorem 6.1.
To prove (19), we use strong duality.
Clearly
minÎ±>0 minÎ·â‰¤0 {g(Î·, Î±Î·)} = minÎ·1,Î·2â‰¤0 {g(Î·1, Î·2)}, so if we optimise the upper bound in (18)
with respect to Î±, then we will recover the minimum of the dual function. If strong duality holds, then
the minimum of the dual function is equal to maxÎ¸âˆˆÎ˜t

Ï•(a)âŠ¤Î¸
	
. Since maxÎ¸âˆˆÎ˜t

Ï•(a)âŠ¤Î¸
	
is a
convex optimisation problem, we can use Slaterâ€™s condition to obtain a sufficient condition for strong
duality to hold. In particular, if Î˜t has an interior point, then strong duality holds, which means
max
Î¸âˆˆÎ˜t{Ï•(a)âŠ¤Î¸} = min
Î±>0 min
Î·â‰¤0 {g(Î·, Î±Î·)}
= min
Î±>0

Ï•(a)âŠ¤bÎ¸Î±,t + RAMM,t
q
Ï•(a)âŠ¤ Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Ï•(a)

.
One can follow the same steps, with a few minor modifications, to prove a similar statement for lower
confidence bounds. For all Î± > 0
min
Î¸âˆˆÎ˜t

Ï•(a)âŠ¤Î¸
	
â‰¥Ï•(a)âŠ¤bÎ¸Î±,t âˆ’RAMM,t
q
Ï•(a)âŠ¤ Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Ï•(a).
If Î˜t has an interior point, then
min
Î¸âˆˆÎ˜t

Ï•(a)âŠ¤Î¸
	
= max
Î±>0

Ï•(a)âŠ¤bÎ¸Î±,t âˆ’RAMM,t
q
Ï•(a)âŠ¤ Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Ï•(a)

.
C.2
OFUL vs AMM-UCB (and CMM-UCB)
We will now show that for any value of the parameter Î±, we can choose a sequence of Gaussian
mixture distributions, such that the confidence bounds of AMM-UCB (and therefore also CMM-UCB)
are always tighter than the confidence bounds of OFUL (Abbasi-Yadkori et al., 2011).
To do this, we will use the following lemma.
Lemma C.4. For any Î³ > 0, v âˆˆRt and M âˆˆRtÃ—d, we have
vâŠ¤v âˆ’vâŠ¤M

M âŠ¤M + Î³1
âˆ’1
M âŠ¤v = vâŠ¤
 1
Î³ MM âŠ¤+ 1
âˆ’1
v.
Proof. We start with the identity
M

M âŠ¤M + Î³1

=

MM âŠ¤+ Î³1

M.
21

By post-multiplying both sides with

M âŠ¤M + Î³1
âˆ’1
and pre-multiplying both sides with

MM âŠ¤+ Î³1
âˆ’1
, we obtain

MM âŠ¤+ Î³1
âˆ’1
M = M

M âŠ¤M + Î³1
âˆ’1
.
(22)
Now, using (22), we have
vâŠ¤v âˆ’vâŠ¤M

M âŠ¤M + Î³1
âˆ’1
M âŠ¤v = vâŠ¤v âˆ’vâŠ¤
MM âŠ¤+ Î³1
âˆ’1
MM âŠ¤v
= vâŠ¤v âˆ’vâŠ¤
MM âŠ¤+ Î³1
âˆ’1 
MM âŠ¤+ Î³1 âˆ’Î³1

v
= vâŠ¤v âˆ’vâŠ¤v + Î³vâŠ¤
MM âŠ¤+ Î³1
âˆ’1
v
= vâŠ¤
 1
Î³ MM âŠ¤+ 1
âˆ’1
v.
With v = rt and M = Î¦t, we obtain
râŠ¤
t rt âˆ’râŠ¤
t Î¦t
 Î¦âŠ¤
t Î¦t + Î³1
âˆ’1 Î¦âŠ¤
t rt = râŠ¤
t
 1
Î³ Î¦tÎ¦âŠ¤
t + 1
âˆ’1
rt.
We will also use the fact that, due to the Weinsteinâ€“Aronszajn identity, for any Î³ > 0
det(Î³Î¦âŠ¤
t Î¦t + 1) = det(Î³Î¦tÎ¦âŠ¤
t + 1).
(23)
For any Î± > 0 (in (Abbasi-Yadkori et al., 2011), what we call Î± is called Î»), the OFUL UCB states
that
Ï•(a)âŠ¤Î¸âˆ—â‰¤Ï•(a)âŠ¤bÎ¸Î±,t + ROFUL,t
q
Ï•(a)âŠ¤ Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Ï•(a),
where
ROFUL,t = Ïƒ
s
ln

det
 1
Î±Î¦âŠ¤
t Î¦t + 1

+ 2 ln(1/Î´) + âˆšÎ±B.
For any Î± > 0 and any Î´ âˆˆ(0, 1], this statement holds with probability at least 1 âˆ’Î´ for all t â‰¥0
and all a âˆˆA. By comparison, our AMM-UCB holds uniformly over all t â‰¥0, all a âˆˆA and all
Î± > 0 (i.e. we could optimise the AMM-UCB with respect to Î± in a data-dependent manner, which
would yield our CMM-UCB).
Notice that for any history a1, r1, a2, r2, . . . and any Î± > 0, the OFUL UCB is the same as our
AMM-UCB, except that our AMM radius quantity RAMM,t is replaced with ROFUL,t. The same
is true for the LCBs of OFUL and AMM-UCB (with the same ROFUL,t), so we will only focus on
the UCBs. We will now show that for any history a1, r1, a2, r2, . . . and any Î± > 0, we can chose
a sequence of Gaussian mixture distributions such that RAMM,t â‰¤ROFUL,t. This means that the
UCBs of our CMM-UCB and AMM-UCB algorithms are never worse than the OFUL UCB.
Without loss of generality, suppose we choose Î± = Ïƒ2/c, for some c > 0. With this choice, the
OFUL radius is
ROFUL,t = Ïƒ
r
ln

det
 c
Ïƒ2 Î¦âŠ¤
t Î¦t + 1

+ 2 ln(1/Î´) + B
âˆšc

.
For any Î± > 0 and a Gaussian mixture distribution Pt = N(Âµt, T t), the squared AMM-UCB radius
is
R2
AMM,t = R2
MM,t + Î±B2 âˆ’râŠ¤
t rt + râŠ¤
t Î¦t
 Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Î¦âŠ¤
t rt
= (Âµt âˆ’rt)âŠ¤

1 + T t
Ïƒ2
âˆ’1
(Âµt âˆ’rt) + Ïƒ2 ln

det

1 + T t
Ïƒ2

+ 2Ïƒ2 ln
1
Î´

+ Î±B2 âˆ’râŠ¤
t rt + râŠ¤
t Î¦t
 Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Î¦âŠ¤
t rt.
22

For AMM-UCB, we will use Î± = Ïƒ2/c and the scaled standard mixture distributions Pt =
N(0, cÎ¦tÎ¦âŠ¤
t ) for each t. With these choices, and using Lemma C.4 and (23), the squared AMM-UCB
radius is
R2
AMM,t = râŠ¤
t
 c
Ïƒ2 Î¦tÎ¦âŠ¤
t + 1
âˆ’1
rt âˆ’râŠ¤
t rt + râŠ¤
t Î¦t

Î¦âŠ¤
t Î¦t + Ïƒ2
c 1
âˆ’1
Î¦âŠ¤
t rt
(24)
+ Ïƒ2 ln

det
 c
Ïƒ2 Î¦tÎ¦âŠ¤
t + 1

+ 2Ïƒ2 ln
1
Î´

+ Ïƒ2B2
c
= Ïƒ2

ln

det
 c
Ïƒ2 Î¦âŠ¤
t Î¦t + 1

+ 2 ln
1
Î´

+ B2
c

.
Using the basic inequality
âˆš
a + b â‰¤âˆša +
âˆš
b for a, b â‰¥0, we have
RAMM,t = Ïƒ
s
ln

det
 c
Ïƒ2 Î¦âŠ¤
t Î¦t + 1

+ 2 ln
1
Î´

+ B2
c
â‰¤Ïƒ
 s
ln

det
 c
Ïƒ2 Î¦âŠ¤
t Î¦t + 1

+ 2 ln
1
Î´

+ B
âˆšc
!
= ROFUL,t.
Therefore, the confidence bounds of AMM-UCB, with Î± = Ïƒ2/c and Pt = N(0, cÎ¦tÎ¦âŠ¤
t ),
are never looser than the confidence bounds of OFUL with an arbitrary Î± = Ïƒ2/c.
Since
ln
 det
  c
Ïƒ2 Î¦âŠ¤
t Î¦t + 1

+ 2 ln
  1
Î´

and B2/c are strictly positive, there is actually a strict inequality.
This means that the AMM-UCB (and CMM-UCB) confidence bounds are always strictly tighter than
the OFUL confidence bounds.
Note that Pt = N(0, cÎ¦tÎ¦âŠ¤
t ) is not necessarily the best choice for the mixture distribution. With a
better choice of the mixture distribution, e.g. a mixture distribution that is chosen using some prior
knowledge about the expected reward function and/or refined using previously observed rewards,
RAMM,t will be smaller and the gap between AMM-UCB and OFUL will be greater.
D
Cumulative Regret Bounds
In this section, we prove the cumulative regret bounds stated in Section 7. We prove the data-
dependent regret bound in Thm. 7.5. We also prove the data-independent regret bound in Thm. 7.6
and another data-independent regret bound, which holds for more general choices of the mixture
distributions and the Î± parameter.
For convenience, we use some more compact notation in this section. For a symmetric positive
semi-definite matrix A and vector x, let
âˆ¥xâˆ¥A :=
âˆš
xâŠ¤Ax.
Before presenting the proof of the main results, we state some useful lemmas.
Lemma D.1 (Donsker-Varadhan Change of Measure (Donsker & Varadhan, 1976)). For any set
X, any measurable function h : X â†’R and any probability distribution P âˆˆP(X) (i.e. any
distribution on X), such that Exâˆ¼P [eh(x)] < âˆž, we have
sup
QâˆˆP(X)

E
xâˆ¼Q [h(x)] âˆ’DKL(Q||P)

= ln

E
xâˆ¼P
h
eh(x)i
.
(25)
By rearranging (25), we have
inf
QâˆˆP(X)

E
xâˆ¼Q [h(x)] + DKL(Q||P)

= âˆ’ln

E
xâˆ¼P
h
eâˆ’h(x)i
.
(26)
23

Lemma D.2 (Determinant-Trace Inequality (Abbasi-Yadkori et al., 2011)). If assumption 7.3 holds
(i.e. âˆ¥Ï•(a)âˆ¥2 â‰¤L), then for any Î³ > 0
ln
 det
 Î³Î¦âŠ¤
t Î¦t + 1

â‰¤d ln
 1 + Î³tL2/d

.
(27)
The Determinant-Trace Inequality in Lemma 10 of (Abbasi-Yadkori et al., 2011) is stated in the form
det

Î¦âŠ¤
t Î¦t + 1
Î³ 1

â‰¤(1/Î³ + tL2/d)d.
(28)
Since det
 Î³Î¦âŠ¤
t Î¦t + 1

= det
 Î¦âŠ¤
t Î¦t + (1/Î³)1

/ det ((1/Î³)1), the statement in (27) follows
from (28).
Lemma D.3. For any Ïƒ > 0 and any Ïƒ0 > 0, define Î£t = ( 1
Ïƒ2 Î¦âŠ¤
t Î¦t +
1
Ïƒ2
0 1)âˆ’1. We have
tr(Î¦âŠ¤
t Î¦tÎ£t) = Ïƒ2d âˆ’Ïƒ2
Ïƒ2
0
tr(Î£t) â‰¤Ïƒ2d.
Proof. Since Î£t is positive-definite, its trace is positive. Now
tr(Î¦âŠ¤
t Î¦tÎ£t) = Ïƒ2tr
 
1
Ïƒ2 Î¦âŠ¤
t Î¦t
 1
Ïƒ2 Î¦âŠ¤
t Î¦t + 1
Ïƒ2
0
1
âˆ’1!
= Ïƒ2tr
  1
Ïƒ2 Î¦âŠ¤
t Î¦t + 1
Ïƒ2
0
1
  1
Ïƒ2 Î¦âŠ¤
t Î¦t + 1
Ïƒ2
0
1
âˆ’1
âˆ’1
Ïƒ2
0
 1
Ïƒ2 Î¦âŠ¤
t Î¦t + 1
Ïƒ2
0
1
âˆ’1!
= Ïƒ2d âˆ’Ïƒ2
Ïƒ2
0
tr(Î£t)
â‰¤Ïƒ2d.
Lemma D.4. For any Ïƒ > 0 and any Ïƒ0 > 0, the matrix Î£t = ( 1
Ïƒ2 Î¦âŠ¤
t Î¦t +
1
Ïƒ2
0 1)âˆ’1 satisfies
tr(Î£t) â‰¤d
Ïƒ2
0
.
Proof. Let {Î³i}d
i=1 denote the eigenvalues of Î¦âŠ¤
t Î¦t. Since Î¦âŠ¤
t Î¦t is positive semi-definite, its
eigenvalues are real and non-negative. From the definition of eigenvalues, one can verify that the
eigenvalues of Î£t are {
Ïƒ2
Î³i+Ïƒ2/Ïƒ2
0 }d
i=1. Using this, we have
tr(Î£t) =
d
X
i=1
Ïƒ2
Î³i + Ïƒ2/Ïƒ2
0
â‰¤
d
X
i=1
Ïƒ2
Ïƒ2/Ïƒ2
0
= d
Ïƒ2
0
.
Lemma D.5. Let Ïµt denote the vector containing the first t noise variables (so rt = Î¦tÎ¸âˆ—+ Ïµt). For
any Î± > 0, we have
(Î¦tÎ¸âˆ—âˆ’rt)âŠ¤(Î¦tÎ¸âˆ—âˆ’rt) âˆ’râŠ¤
t rt + râŠ¤
t Î¦t(Î¦âŠ¤
t Î¦t + Î±1)âˆ’1Î¦âŠ¤
t rt â‰¤
Î¦âŠ¤
t Ïµt
2
(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1
+ 2Î± âˆ¥Î¸âˆ—âˆ¥(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1
Î¦âŠ¤
t Ïµt

(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1 .
24

Proof. Using rt = Î¦tÎ¸âˆ—+ Ïµt, we have
(Î¦tÎ¸âˆ—âˆ’rt)âŠ¤(Î¦tÎ¸âˆ—âˆ’rt) = ÏµâŠ¤
t Ïµt,
and
âˆ’râŠ¤
t rt + râŠ¤
t Î¦t(Î¦âŠ¤
t Î¦t + Î±1)âˆ’1Î¦âŠ¤
t rt = âˆ’(Î¦tÎ¸âˆ—+ Ïµt)âŠ¤(Î¦tÎ¸âˆ—+ Ïµt)
+ (Î¦tÎ¸âˆ—+ Ïµt)âŠ¤Î¦t(Î¦âŠ¤
t Î¦t + Î±1)âˆ’1Î¦âŠ¤
t (Î¦tÎ¸âˆ—+ Ïµt)
= âˆ’ÏµâŠ¤
t Ïµt âˆ’2Î¸âˆ—âŠ¤Î¦âŠ¤
t Ïµt âˆ’Î¸âˆ—âŠ¤Î¦âŠ¤
t Î¦tÎ¸âˆ—+ Î¸âˆ—âŠ¤Î¦âŠ¤
t Î¦t(Î¦âŠ¤
t Î¦t + Î±1)âˆ’1Î¦âŠ¤
t Î¦tÎ¸âˆ—
+ 2Î¸âˆ—âŠ¤Î¦âŠ¤
t Î¦t(Î¦âŠ¤
t Î¦t + Î±1)âˆ’1Î¦âŠ¤
t Ïµt + ÏµâŠ¤
t Î¦t(Î¦âŠ¤
t Î¦t + Î±1)âˆ’1Î¦âŠ¤
t Ïµt
â‰¤âˆ’ÏµâŠ¤
t Ïµt âˆ’2Î¸âˆ—âŠ¤Î¦âŠ¤
t Ïµt + 2Î¸âˆ—âŠ¤Î¦âŠ¤
t Î¦t(Î¦âŠ¤
t Î¦t + Î±1)âˆ’1Î¦âŠ¤
t Ïµt
+ ÏµâŠ¤
t Î¦t(Î¦âŠ¤
t Î¦t + Î±1)âˆ’1Î¦âŠ¤
t Ïµt
= âˆ’ÏµâŠ¤
t Ïµt âˆ’2Î±Î¸âˆ—âŠ¤(Î¦âŠ¤
t Î¦t + Î±1)âˆ’1Î¦âŠ¤
t Ïµt + ÏµâŠ¤
t Î¦t(Î¦âŠ¤
t Î¦t + Î±1)âˆ’1Î¦âŠ¤
t Ïµt.
Using the Cauchy-Schwarz inequality, we have
|Î¸âˆ—âŠ¤(Î¦âŠ¤
t Î¦t + Î±1)âˆ’1Î¦âŠ¤
t Ïµt| â‰¤âˆ¥Î¸âˆ—âˆ¥(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1
Î¦âŠ¤
t Ïµt

(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1 .
Therefore
âˆ’2Î±Î¸âˆ—âŠ¤(Î¦âŠ¤
t Î¦t + Î±1)âˆ’1Î¦âŠ¤
t Ïµt â‰¤2Î± âˆ¥Î¸âˆ—âˆ¥(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1
Î¦âŠ¤
t Ïµt

(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1 ,
and
(Î¦tÎ¸âˆ—âˆ’rt)âŠ¤(Î¦tÎ¸âˆ—âˆ’rt) âˆ’râŠ¤
t rt + râŠ¤
t Î¦t(Î¦âŠ¤
t Î¦t + Î±1)âˆ’1Î¦âŠ¤
t rt â‰¤ÏµâŠ¤
t Ïµt âˆ’ÏµâŠ¤
t Ïµt +
Î¦âŠ¤
t Ïµt
2
(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1
+ 2Î± âˆ¥Î¸âˆ—âˆ¥(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1
Î¦âŠ¤
t Ïµt

(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1
=
Î¦âŠ¤
t Ïµt
2
(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1 + 2Î± âˆ¥Î¸âˆ—âˆ¥(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1
Î¦âŠ¤
t Ïµt

(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1 .
Theorem D.6 (Self-Normalised Bound for Vector-Valued Martingales (Theorem 1 of (Abbasi-Yadkori
et al., 2011))). Let (Ht|t â‰¥0) be a filtration. Let (Ïµt|t â‰¥1) be a real-valued stochastic process such
that Ïµt is Ht-measurable and Ïµt is conditionally Ïƒ-sub-Gaussian for some Ïƒ > 0. Let (Ï•(at)|t â‰¥1)
be an Rd-valued stochastic process such that Ï•(at) is Htâˆ’1-measurable. For any Î´ âˆˆ(0, 1] and any
Î± > 0, with probability at least 1 âˆ’Î´
âˆ€t â‰¥0,
Î¦âŠ¤
t Ïµt
2
(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1 â‰¤Ïƒ2 ln

det
 1
Î±Î¦âŠ¤
t Î¦t + 1

+ 2Ïƒ2 ln(1/Î´).
Lemma D.7. For any symmetric positive semi-definite matrix A with largest eigenvalue Î³max, we
have
âˆ¥xâˆ¥2
A â‰¤Î³max âˆ¥xâˆ¥2
2 .
Proof. Let {Î³i}d
i=1 and {vi}d
i=1 be the eigenvalues and eigenvectors of A. Since {vi}d
i=1 form a
basis, there are constants {ci}d
i=1 such that x = Pd
i=1 civi. We have
âˆ¥xâˆ¥2
A =
d
X
i=1,j=1
cicjvâŠ¤
i Avj =
d
X
i=1,j=1
Î³jcicjvâŠ¤
i vj â‰¤Î³max
d
X
i=1,j=1
cicjvâŠ¤
i vj = Î³max âˆ¥xâˆ¥2
2 .
Lemma D.8. For all x â‰¥0,
min(1, x) â‰¤
1
ln(2) ln(1 + x).
25

Proof. Since ln(1 + x)/ ln(2) is monotonically increasing in x, we only need to prove that x â‰¤
ln(1 + x)/ ln(2) for all x âˆˆ[0, 1]. For any positive constant a, the function a ln(1 + x) is concave
on the domain [0, 1]. Therefore, if x â‰¤a ln(1 + x) at the end points x = 0 and x = 1, then
x â‰¤a ln(1 + x) for every x âˆˆ[0, 1]. At x = 0, we have a ln(1 + x) = 0 for any a, which means
we can choose the smallest a such that 1 â‰¤a ln(1 + 1). By rearranging this inequality, we obtain
a â‰¥1/ ln(2).
D.1
Data-Dependent Regret Bound
First, we show that the cumulative regret of both of our algorithms can be upper bounded by the sum
of the widths of the UCB/LCBs that they use. Let
UCBÎ˜t(a) = max
Î¸âˆˆÎ˜t

Ï•(a)âŠ¤Î¸
	
,
and
LCBÎ˜t(a) = min
Î¸âˆˆÎ˜t

Ï•(a)âŠ¤Î¸
	
.
In words, UCBÎ˜t(a) and LCBÎ˜t(a) are the upper and lower confidence bounds used by CMM-UCB
(evaluated at a). Similarly, let
AUCBÎ˜t(a) = Ï•(a)âŠ¤bÎ¸Î±,t + RAMM,t âˆ¥Ï•(a)âˆ¥(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1 ,
ALCBÎ˜t(a) = Ï•(a)âŠ¤bÎ¸Î±,t âˆ’RAMM,t âˆ¥Ï•(a)âˆ¥(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1 .
AUCBÎ˜t(a) and ALCBÎ˜t(a) are the analytic upper and lower confidence bounds used by AMM-
UCB. Lemma D.9 shows that the cumulative regret of CMM-UCB and AMM-UCB can be upper
bounded by the sum of the widths (UCB minus LCB) of the confidence bounds that they use.
Lemma D.9. Suppose the actions a1, a2, . . . are selected by the CMM-UCB algorithm. For any
adaptive sequence of mixture distributions Pt = N(Âµt, T t) and any Î´ âˆˆ(0, 1], with probability at
least 1 âˆ’Î´
âˆ€T â‰¥1,
T
X
t=1
âˆ†(at) â‰¤
T
X
t=1
UCBÎ˜tâˆ’1(at) âˆ’LCBÎ˜tâˆ’1(at).
(29)
Suppose the actions a1, a2, . . . are selected by the AMM-UCB algorithm. For any adaptive sequence
of mixture distributions Pt = N(Âµt, T t) and any Î´ âˆˆ(0, 1], with probability at least 1 âˆ’Î´
âˆ€Î± > 0, T â‰¥1,
T
X
t=1
âˆ†(at) â‰¤
T
X
t=1
AUCBÎ˜tâˆ’1(at) âˆ’ALCBÎ˜tâˆ’1(at).
(30)
Proof. Using Cor. 5.2 (i.e. the fact that Î˜1, Î˜2, . . . is a confidence sequence), for any adaptive
sequence of mixture distributions Pt = N(Âµt, T t) and any Î´ âˆˆ(0, 1], with probability at least 1 âˆ’Î´
âˆ€a âˆˆA, t â‰¥1,
LCBÎ˜tâˆ’1(a) â‰¤Ï•(a)âŠ¤Î¸âˆ—â‰¤UCBÎ˜tâˆ’1(a).
Using Thm. 6.1, this implies
âˆ€Î± > 0, a âˆˆA, t â‰¥1,
ALCBÎ˜tâˆ’1(a) â‰¤Ï•(a)âŠ¤Î¸âˆ—â‰¤AUCBÎ˜tâˆ’1(a).
Let a1, a2, . . . be the actions selected by CMM-UCB, i.e. at = argmaxaâˆˆAt

UCBÎ˜tâˆ’1(a)
	
. Then,
with probability at least 1 âˆ’Î´, we have
T
X
t=1
âˆ†(at) =
T
X
t=1
Ï•(aâˆ—
t )âŠ¤Î¸âˆ—âˆ’Ï•(at)âŠ¤Î¸âˆ—
â‰¤
T
X
t=1
UCBÎ˜tâˆ’1(aâˆ—
t ) âˆ’LCBÎ˜tâˆ’1(at)
â‰¤
T
X
t=1
UCBÎ˜tâˆ’1(at) âˆ’LCBÎ˜tâˆ’1(at).
26

Now, let a1, a2, . . . be the actions selected by AMM-UCB, i.e. at = argmaxaâˆˆAt

AUCBÎ˜tâˆ’1(a)
	
.
Then, with probability at least 1 âˆ’Î´, we have
T
X
t=1
âˆ†(at) =
T
X
t=1
Ï•(aâˆ—
t )âŠ¤Î¸âˆ—âˆ’Ï•(at)âŠ¤Î¸âˆ—
â‰¤
T
X
t=1
AUCBÎ˜tâˆ’1(aâˆ—
t ) âˆ’ALCBÎ˜tâˆ’1(at)
â‰¤
T
X
t=1
AUCBÎ˜tâˆ’1(at) âˆ’ALCBÎ˜tâˆ’1(at).
Since âˆ€Î± > 0, a âˆˆA and t â‰¥1, AUCBÎ˜tâˆ’1(a) â‰¥UCBÎ˜tâˆ’1(a) and ALCBÎ˜tâˆ’1(a) â‰¤
LCBÎ˜tâˆ’1(a), (29) implies that (30) also holds when a1, a2, . . . are the actions selected by CMM-
UCB.
Proof of Theorem 7.5. We start by using Lemma D.9. Suppose a1, a2, . . . are the actions selected by
CMM-UCB or AMM-UCB. For any adaptive sequence of mixture distributions Pt = N(Âµt, T t) and
any Î´ âˆˆ(0, 1], with probability at least 1 âˆ’Î´
âˆ€Î± > 0, T â‰¥1,
T
X
t=1
âˆ†(at) â‰¤
T
X
t=1
AUCBÎ˜tâˆ’1(at) âˆ’ALCBÎ˜tâˆ’1(at).
Using the definitions of AUCBÎ˜tâˆ’1(at) and ALCBÎ˜tâˆ’1(at), we have
âˆ€Î± > 0, T â‰¥1,
T
X
t=1
âˆ†(at) â‰¤
T
X
t=1
2RAMM,tâˆ’1 âˆ¥Ï•(at)âˆ¥(Î¦âŠ¤
tâˆ’1Î¦tâˆ’1+Î±1)âˆ’1 .
D.2
Data-Independent Regret Bound
To establish data-independent regret bounds, we first prove data-independent upper bounds on the
radius RAMM,t and the norms âˆ¥Ï•(at)âˆ¥(Î¦âŠ¤
tâˆ’1Î¦tâˆ’1+Î±1)âˆ’1. Then, we take the data-dependent regret
bound in Lemma D.9 and substitute in these bounds on the radius and the norms.
D.2.1
Bounding the Radius
Lemma D.10. If, for any c > 0, the sequence of mixture distributions is Pt = N(0, cÎ¦tÎ¦âŠ¤
t ) and
Î± = Ïƒ2/c, then
R2
AMM,t â‰¤Ïƒ2d ln

1 + ctL2
Ïƒ2d

+ Ïƒ2B2
c
+ 2Ïƒ2ln(1/Î´).
(31)
Proof. In Equation (24), we already saw that for this choice of Î± and the mixture distributions, we
have
R2
AMM,t = Ïƒ2 ln

det
 c
Ïƒ2 Î¦âŠ¤
t Î¦t + 1

+ Ïƒ2B2
c
+ 2Ïƒ2ln(1/Î´).
To obtain a data-independent upper bound on the radius, all that remains is to upper bound
ln
 det
  c
Ïƒ2 Î¦âŠ¤
t Î¦t + 1

by a data-independent quantity. Using Lemma D.2, we have
ln

det
 c
Ïƒ2 Î¦âŠ¤
t Î¦t + 1

â‰¤d ln

1 + ctL2
Ïƒ2d

.
Therefore
R2
AMM,t â‰¤Ïƒ2d ln

1 + ctL2
Ïƒ2d

+ Ïƒ2B2
c
+ 2Ïƒ2ln(1/Î´).
27

Lemma D.11. If, for any Î¸0 âˆˆRd and any Ïƒ0 > 0, the sequence of mixture distributions is
Pt = N(Î¦tÎ¸0, Ïƒ2
0Î¦tÎ¦âŠ¤
t ), then for any Î´ âˆˆ(0, 1] and any Î± > 0, with probability at least 1 âˆ’Î´, for
all t â‰¥1
R2
AMM,t â‰¤Ïƒ2d + Ïƒ2
Ïƒ2
0
âˆ¥Î¸âˆ—âˆ’Î¸0âˆ¥2
2 + Ïƒ2dln

1 + tÏƒ2
0L2
Ïƒ2d

+ Î±B2 + 4Ïƒ2ln(1/Î´)
+ Ïƒ2dln
 1 + tL2/(Î±d)

+ 2âˆšÎ± âˆ¥Î¸âˆ—âˆ¥2
p
Ïƒ2dln (1 + tL2/(Î±d)) + 2Ïƒ2ln(1/Î´).
Proof. In App. B.2 (see Equation 16), we saw that the squared radius R2
MM,t can be written as
R2
MM,t = âˆ’2Ïƒ2 ln
 
E
f tâˆ¼N(Î¦tÎ¸0,Ïƒ2
0Î¦tÎ¦âŠ¤
t )

exp

âˆ’1
2Ïƒ2 (f t âˆ’rt)âŠ¤(f t âˆ’rt)
!
+ 2Ïƒ2 ln(1/Î´).
(32)
Using the substitution Î¦tÎ¸ = f t, (32) is equivalent to
R2
MM,t = âˆ’2Ïƒ2 ln
 
E
Î¸âˆ¼N(Î¸0,Ïƒ2
01)

exp

âˆ’1
2Ïƒ2 (Î¦tÎ¸ âˆ’rt)âŠ¤(Î¦tÎ¸ âˆ’rt)
!
+ 2Ïƒ2 ln(1/Î´). (33)
Using the Donsker-Varadhan change of measure inequality (specifically (26)), the first term on the
right-hand-side of (33) is equal to
inf
QâˆˆP(Rd)

E
Î¸âˆ¼Q

(Î¦tÎ¸ âˆ’rt)âŠ¤(Î¦tÎ¸ âˆ’rt)

+ 2Ïƒ2DKL(Q||N(Î¸0, Ïƒ2
01))

.
If we evaluate this at any specific distribution Q, we obtain an upper bound on the infimum over Q.
We choose Q = N(Î¸âˆ—, Î£t), where Î£t = ( 1
Ïƒ2 Î¦âŠ¤
t Î¦t +
1
Ïƒ2
0 1)âˆ’1. Combining everything so far, we
have
R2
MM,t â‰¤
E
Î¸âˆ¼N(Î¸âˆ—,Î£t)

(Î¦tÎ¸ âˆ’rt)âŠ¤(Î¦tÎ¸ âˆ’rt)

+ 2Ïƒ2DKL(N(Î¸âˆ—, Î£t)||N(Î¸0, Ïƒ2
01)) + 2Ïƒ2 ln(1/Î´)
= (Î¦tÎ¸âˆ—âˆ’rt)âŠ¤(Î¦tÎ¸âˆ—âˆ’rt) + tr(Î¦âŠ¤
t Î¦tÎ£t) + Ïƒ2
Ïƒ2
0
tr(Î£t)
âˆ’Ïƒ2d + Ïƒ2
Ïƒ2
0
âˆ¥Î¸âˆ—âˆ’Î¸0âˆ¥2
2 + Ïƒ2ln

det(Î£âˆ’1
t )
det((1/Ïƒ2
0)1)

+ 2Ïƒ2 ln(1/Î´).
(34)
Using Lemma D.3, we have
tr(Î¦âŠ¤
t Î¦tÎ£t) â‰¤Ïƒ2d.
Using Lemma D.4, we have
Ïƒ2
Ïƒ2
0
tr(Î£t) â‰¤Ïƒ2d.
Using Lemma D.2, we have
ln

det(Î£âˆ’1
t )
det((1/Ïƒ2
0)1)

= ln

det
Ïƒ2
0
Ïƒ2 Î¦âŠ¤
t Î¦t + 1

â‰¤d ln

1 + Ïƒ2
0tL2
Ïƒ2d

.
The bound on R2
MM,t in (34) becomes
R2
MM,t â‰¤(Î¦tÎ¸âˆ—âˆ’rt)âŠ¤(Î¦tÎ¸âˆ—âˆ’rt)+ Ïƒ2
Ïƒ2
0
âˆ¥Î¸âˆ—âˆ’Î¸0âˆ¥2
2+Ïƒ2d+Ïƒ2d ln

1 + Ïƒ2
0tL2
Ïƒ2d

+2Ïƒ2ln(1/Î´).
This means that
R2
AMM,t â‰¤(Î¦tÎ¸âˆ—âˆ’rt)âŠ¤(Î¦tÎ¸âˆ—âˆ’rt) + Ïƒ2
Ïƒ2
0
âˆ¥Î¸âˆ—âˆ’Î¸0âˆ¥2
2 + Ïƒ2d + Ïƒ2d ln

1 + Ïƒ2
0tL2
Ïƒ2d

+ 2Ïƒ2ln(1/Î´)
+ Î±B2 âˆ’râŠ¤
t rt + râŠ¤
t Î¦t
 Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Î¦âŠ¤
t rt.
(35)
28

Finally, using Lemma D.5, then Theorem D.6 and Lemma D.7, and then Lemma D.2, for any
Î´ âˆˆ(0, 1] and any Î± > 0, with probability at least 1 âˆ’Î´, for all t â‰¥0 simultaneously
(Î¦tÎ¸âˆ—âˆ’rt)âŠ¤(Î¦tÎ¸âˆ—âˆ’rt) âˆ’râŠ¤
t rt + râŠ¤
t Î¦t
 Î¦âŠ¤
t Î¦t + Î±1
âˆ’1 Î¦âŠ¤
t rt
â‰¤
Î¦âŠ¤
t Ïµt
2
(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1 + 2Î± âˆ¥Î¸âˆ—âˆ¥(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1
Î¦âŠ¤
t Ïµt

(Î¦âŠ¤
t Î¦t+Î±1)âˆ’1
â‰¤Ïƒ2 ln

det
 1
Î±Î¦âŠ¤
t Î¦t + 1

+ 2Ïƒ2 ln(1/Î´) + 2âˆšÎ± âˆ¥Î¸âˆ—âˆ¥2 Ïƒ
s
ln

det
 1
Î±Î¦âŠ¤
t Î¦t + 1

+ 2 ln(1/Î´)
â‰¤Ïƒ2d ln

det

1 + tL2
Î±d

+ 2Ïƒ2 ln(1/Î´) + 2âˆšÎ± âˆ¥Î¸âˆ—âˆ¥2 Ïƒ
s
d ln

det

1 + tL2
Î±d

+ 2 ln(1/Î´).
Substituting this into (35), we have
R2
AMM,t â‰¤Ïƒ2d + Ïƒ2
Ïƒ2
0
âˆ¥Î¸âˆ—âˆ’Î¸0âˆ¥2
2 + Ïƒ2dln

1 + tÏƒ2
0L2
Ïƒ2d

+ Î±B2 + 4Ïƒ2ln(1/Î´)
+ Ïƒ2dln
 1 + tL2/(Î±d)

+ 2âˆšÎ± âˆ¥Î¸âˆ—âˆ¥2
p
Ïƒ2dln (1 + tL2/(Î±d)) + 2Ïƒ2ln(1/Î´).
D.2.2
Bounding the Sum of Norms
We use the following upper bound on the sum of the squared norms.
Lemma D.12 (Lemma 11 of (Abbasi-Yadkori et al., 2011)). For any Î± > 0, we have
T
X
t=1
min

1, âˆ¥Ï•(at)âˆ¥2
(Î¦âŠ¤
tâˆ’1Î¦tâˆ’1+Î±1)
âˆ’1

â‰¤
1
ln(2)d ln

1 + TL2
Î±d

.
In Lemma 11 of (Abbasi-Yadkori et al., 2011), 1/ ln(2) â‰ˆ1.44 is replaced with 2. We achieve an
improved constant by using Lemma D.8 instead of the looser bound min(1, x) â‰¤2 ln(1 + x), for
x â‰¥0.
D.2.3
Regret Bounds
We are now ready to prove our data-independent regret bounds.
Proof of Theorem 7.6. Following the same steps as in the proof of Lemma D.9, we can also obtain
the following data-dependent bound on the per-round regret for actions selected by CMM-UCB or
AMM-UCB. For the mixture distributions Pt = N(0t, cÎ¦tÎ¦âŠ¤
t ), Î± = Ïƒ2/c and any Î´ âˆˆ(0, 1], with
probability at least 1 âˆ’Î´
âˆ€t â‰¥1,
âˆ†(at) â‰¤2RAMM,tâˆ’1 âˆ¥Ï•(at)âˆ¥(Î¦âŠ¤
tâˆ’1Î¦tâˆ’1+ Ïƒ2
c 1)âˆ’1 .
(36)
From Assumption 7.4 (Ï•(a)âŠ¤Î¸âˆ—âˆˆ[âˆ’C, C]), we have another bound on the per-round regret
âˆ†(at) â‰¤2C.
(37)
The combination of (36) and (37) yields
âˆ†(at) â‰¤min(2C, 2RAMM,tâˆ’1 âˆ¥Ï•(at)âˆ¥(Î¦âŠ¤
tâˆ’1Î¦tâˆ’1+ Ïƒ2
c 1)âˆ’1)
â‰¤2 max(C, RAMM,tâˆ’1) min(1, âˆ¥Ï•(at)âˆ¥(Î¦âŠ¤
tâˆ’1Î¦tâˆ’1+ Ïƒ2
c 1)âˆ’1).
Starting with the Cauchy-Schwarz inequality, we have
T
X
t=1
âˆ†(at) â‰¤
v
u
u
tT
T
X
t=1
âˆ†(at)2
(38)
â‰¤
v
u
u
tT
T
X
t=1
4 max

C2, R2
AMM,tâˆ’1

min

1, âˆ¥Ï•(at)âˆ¥2
(Î¦âŠ¤
tâˆ’1Î¦tâˆ’1+ Ïƒ2
c 1)âˆ’1

.
29

We will now use the upper bound on R2
AMM,tâˆ’1 from Lemma D.10. Let U 2
AMM,tâˆ’1 denote this upper
bound (i.e. the right-hand-side of (31)). We have
T
X
t=1
âˆ†(at) â‰¤
v
u
u
tT
T
X
t=1
4 max

C2, U 2
AMM,tâˆ’1

min

1, âˆ¥Ï•(at)âˆ¥2
(Î¦âŠ¤
tâˆ’1Î¦tâˆ’1+ Ïƒ2
c 1)âˆ’1

â‰¤2 max (C, UAMM,T âˆ’1)
v
u
u
tT
T
X
t=1
min

1, âˆ¥Ï•(at)âˆ¥2
(Î¦âŠ¤
tâˆ’1Î¦tâˆ’1+ Ïƒ2
c 1)âˆ’1

Finally, using the bound on the sum of norms in Lemma D.12, we have
T
X
t=1
âˆ†(at) â‰¤
2
p
ln(2)
max
 
C, Ïƒ
s
d ln

1 + c(T âˆ’1)L2
Ïƒ2d

+ B2
c + 2 ln
1
Î´
! s
dT ln

1 + cTL2
Ïƒ2d

.
Now, we state and prove a cumulative regret bound that holds for more general choices of the mixture
distributions and the parameter Î±.
Theorem D.13. Suppose that assumptions 7.1-7.4 hold. If, for any Î¸0 âˆˆRd and any Ïƒ0 > 0, the
sequence of mixture distributions is Pt = N(Î¦tÎ¸0, Ïƒ2
0Î¦tÎ¦âŠ¤
t ), then for any Î´ âˆˆ(0, 1/2] and any
Î± > 0, with probability at least 1 âˆ’2Î´, for all T â‰¥1 simultaneously, the cumulative regret of
CMM-UCB and AMM-UCB is bounded by
âˆ†1:T â‰¤
2
âˆš
ln 2
max {C, UAMM,T âˆ’1}
s
dT ln

1+ L2T
Î±d

= O(d
âˆš
Tln(T)),
where
U 2
AMM,T âˆ’1 â‰¤Ïƒ2d + Ïƒ2
Ïƒ2
0
âˆ¥Î¸âˆ—âˆ’Î¸0âˆ¥2
2 + Ïƒ2dln

1 + (T âˆ’1)Ïƒ2
0L2
Ïƒ2d

+ Î±B2 + 4Ïƒ2ln(1/Î´)
(39)
+ Ïƒ2dln

1 + (T âˆ’1)L2
Î±d

+ 2âˆšÎ± âˆ¥Î¸âˆ—âˆ¥2
s
Ïƒ2dln

1 + (T âˆ’1)L2
Î±d

+ 2Ïƒ2ln(1/Î´).
Proof. Following the proof of Theorem 7.6, we obtain (with high probability)
T
X
t=1
âˆ†(at) â‰¤
v
u
u
tT
T
X
t=1
4 max

C2, R2
AMM,tâˆ’1

min

1, âˆ¥Ï•(at)âˆ¥2
(Î¦âŠ¤
tâˆ’1Î¦tâˆ’1+Î±1)âˆ’1

.
This time, we use the bound on the radius from Lemma D.11. Let UAMM,T âˆ’1 denote this bound on
the radius (i.e. the square root of the right-hand-side of (39)). Also, note that this bound on the radius
holds with probability at 1 âˆ’Î´. Since UAMM,T âˆ’1 is monotonically increasing with T, we have
T
X
t=1
âˆ†(at) â‰¤2 max (C, UAMM,T âˆ’1)
v
u
u
tT
T
X
t=1
min

1, âˆ¥Ï•(at)âˆ¥2
(Î¦âŠ¤
tâˆ’1Î¦tâˆ’1+Î±1)âˆ’1

.
Finally, we use Lemma D.12 to obtain
T
X
t=1
âˆ†(at) â‰¤
2
âˆš
ln 2
max {C, UAMM,T âˆ’1}
s
dT ln

1+ L2T
Î±d

.
We used two inequalities that each hold with probability at least 1 âˆ’Î´. By a union bound argument,
the cumulative regret bound holds with probability at least 1 âˆ’2Î´.
30

E
Additional Experiments
In this section, we present the results of some additional experiments in which we investigate the
effect of the mixture distributions (or priors) on our upper and lower confidence bounds.
E.1
The Effect of The Mixture Distributions
We investigate how our CMM-UCB upper and lower confidence bounds behave when we provide an
uninformative but well-specified mixture distribution/prior, an informative and well-specified mixture
distribution/prior, and a misspecified mixture distribution/prior. Here misspecification refers to prior
misspecification in a Bayesian sense. For reference, we compare the behaviour of our upper and
lower confidence bounds with the upper and lower limits of a Bayesian credible interval.
For a fair comparison with CMM-UCB, we attempt to construct a Bayesian credible interval that
holds with high probability for all rounds t â‰¥0. However, whilst the CMM-UCB confidence
set holds with high probability over the random draw of the data a1, r1, a2, r2, . . . , the Bayesian
credible interval holds with high probability over the random draw of Î¸âˆ—from a prior (for fixed data
a1, r1, a2, r2, . . . ).
For the Bayesian credible interval, we use a Gaussian prior and assume Î¸âˆ—âˆ¼N(Âµ0, Î£0). We assume
a Gaussian likelihood function, i.e. rewards are of the form rt = Ï•(at)âŠ¤Î¸ +Ïµt, where Ïµt âˆ¼N(0, Ïƒ2).
The Bayesian posterior for Î¸âˆ—is another Gaussian N(Âµt, Î£t), where
Âµt = Î£t

Î£âˆ’1
0 Âµ0 + 1
Ïƒ2 Î¦âŠ¤
t rt

,
Î£t =
 1
Ïƒ2 Î¦âŠ¤
t Î¦t + Î£âˆ’1
0
âˆ’1
.
Using Bayesâ€™ rule, at any round t, we have Î¸âˆ—âˆ¼N(Âµt, Î£t). Therefore
(Âµt âˆ’Î¸âˆ—)âŠ¤Î£âˆ’1
t (Âµt âˆ’Î¸âˆ—) âˆ¼Ï‡2(d),
where Ï‡2(d) is a chi-squared distribution with d degrees of freedom. Let Qd(Â·) be the quantile
function of the chi-squared distribution with d degrees of freedom. With probability at least 1 âˆ’Î´t
(over the random draw of Î¸âˆ—from N(Âµt, Î£t))
(Âµt âˆ’Î¸âˆ—)âŠ¤Î£âˆ’1
t (Âµt âˆ’Î¸âˆ—) â‰¤Qd(1 âˆ’Î´t).
(40)
Using a union bound argument, if Î´t =
6Î´
(t+1)2Ï€2 , then (40) holds with probability at least 1 âˆ’Î´t
for all t â‰¥0. Therefore, if Î¸âˆ—âˆ¼N(Âµ0, Î£0), then with high probability the following credible sets
contain Î¸âˆ—for all t â‰¥0 simultaneously:
Î˜t =

Î¸ âˆˆRd
(Âµt âˆ’Î¸âˆ—)âŠ¤Î£âˆ’1
t (Âµt âˆ’Î¸âˆ—) â‰¤Qd

1 âˆ’
6Î´
(t + 1)2Ï€2

.
The upper limit of the credible interval for this credible set (and the one we use in Figure 4) is
sup
Î¸âˆˆÎ˜t

Ï•(a)T Î¸
	
= Ï•(a)T Âµt +
s
Qd

1 âˆ’
6Î´
(t + 1)2Ï€2
q
Ï•(a)âŠ¤Î£tÏ•(a).
We compute confidence bounds/credible intervals for a randomly generated linear function of the
form f(x) = Ï•(x)âŠ¤Î¸âˆ—, with inputs x âˆˆR and Î¸âˆ—âˆˆR20, the latter drawn from a standard Gaussian
distribution and if necessary scaled down to âˆ¥Î¸âˆ—âˆ¥2 â‰¤10 =: B. For the feature map Ï•, we use
Random Fourier Features. We generate random data {(xk, yk)}t
k=1, where yk = Ï•(xk)âŠ¤Î¸âˆ—+ Î·k,
Î·k âˆ¼N(0, Ïƒ2) and Ïƒ = 0.1 (so the Gaussian likelihood is well-specified).
31

4
2
0
2
4
7.5
5.0
2.5
0.0
2.5
5.0
CMM-UCB
4
2
0
2
4
7.5
5.0
2.5
0.0
2.5
5.0
Bayes
4
2
0
2
4
7.5
5.0
2.5
0.0
2.5
5.0
4
2
0
2
4
7.5
5.0
2.5
0.0
2.5
5.0
4
2
0
2
4
7.5
5.0
2.5
0.0
2.5
5.0
4
2
0
2
4
7.5
5.0
2.5
0.0
2.5
5.0
Figure 4: The upper and lower confidence bounds of our CMM-UCB method (left) and Bayesian
posterior credible intervals (right) with different choices of the prior. The top row uses the prior f t âˆ¼
N(0, Î¦tÎ¦âŠ¤
t ) for CMM-UCB and Î¸âˆ—âˆ¼N(0, 1)) for Bayes. The middle row uses an informative
prior: f t âˆ¼N(Î¦tÎ¸âˆ—, 0.1Î¦tÎ¦âŠ¤
t ) for CMM-UCB and Î¸âˆ—âˆ¼N(Î¸âˆ—, 0.11)) for Bayes. The bottom row
uses a misspecified prior: f t âˆ¼N(âˆ’Î¦tÎ¸âˆ—, 0.1Î¦tÎ¦âŠ¤
t ) for CMM-UCB and Î¸âˆ—âˆ¼N(âˆ’Î¸âˆ—, 0.11)) for
Bayes.
Figure 4 shows the CMM-UCB upper and lower confidence bounds (left) and the Bayesian credible
intervals (right) with different choices of the prior. We use roughly equivalent priors for both methods.
If the Bayesian credible interval uses the prior Î¸âˆ—âˆ¼N(Âµ0, Î£0), then CMM-UCB uses the induced
distribution over the function values Î¦tÎ¸âˆ—, i.e. f t âˆ¼N(Î¦tÂµ0, Î¦tÎ£0Î¦âŠ¤
t ).
In the top and middle rows of Figure 4, where the prior is well-specified, we observe that the CMM-
UCB upper and lower confidence bounds are slightly looser than the Bayesian credible intervals.
In the bottom row of Figure 4, when the prior is misspecified, the CMM-UCB interval gets looser
whereas the Bayesian credible interval becomes wrong. In summary, the Bayesian credible interval
appears to be slightly tighter when the prior is well-specified and at least somewhat informative, but
CMM-UCB is robust to â€œmisspecifiedâ€ mixture distributions.
32

E.2
Benefits of Adaptive Mixture Distributions
In this section, we investigate a method for refining Âµt and T t based on previously observed actions
and rewards. Recall that Âµt and T t must be chosen such that: (a) Âµt and T t can only depend on
a1, . . . , at and r1, . . . , rtâˆ’1; (b) the first t âˆ’1 elements of Âµt must be equal to Âµtâˆ’1; (c) the upper
left t âˆ’1 Ã— t âˆ’1 block of T t must be T tâˆ’1; (d) T t must be positive (semi-)definite.
As in Sec. 6.4, m and k are any fixed mean and kernel functions. Each new row and column of T t is
set using an adaptive kernel function ktâˆ’1. For Î² > 0, define
kt(a, aâ€²) := k(a, aâ€²) âˆ’kt(a)âŠ¤(Kt + Î²1)âˆ’1 kt(aâ€²),
where kt(a) = [k(a, a1), . . . , k(a, at)]âŠ¤and Kt is the kernel matrix whose (i, j)th element is
k(ai, aj). For T t, we choose
T t =
ï£®
ï£¯ï£¯ï£°
k0(a1, a1)
k1(a1, a2)
Â· Â· Â·
ktâˆ’1(a1, at)
k1(a2, a1)
k1(a2, a2)
Â· Â· Â·
ktâˆ’1(a2, at)
...
...
...
...
ktâˆ’1(at, a1)
ktâˆ’1(at, a2)
Â· Â· Â·
ktâˆ’1(at, at)
ï£¹
ï£ºï£ºï£».
(41)
The ith column and ith row of this matrix depend only on only a1, r1, . . . , ai. Our motivation for this
kernel function is: (a) generalising the usual Bayesian Gaussian process (GP) posterior covariance,
one can show that if the kernel function k is positive definite, then T t is positive semi-definite; (b) kt
is the Bayesian GP posterior covariance function (with a Gaussian likelihood with variance Î²). Each
new element of Âµt is set by evaluating an adaptive mean function mtâˆ’1 at the latest action at. Define
mt(a) := m(a) âˆ’kt(a)âŠ¤(Kt + Î²1)âˆ’1 (mt âˆ’rt) .
For Âµt, we choose
Âµt = [m0(a1), m1(a2), . . . , mtâˆ’1(at)]âŠ¤.
(42)
The ith element, miâˆ’1(ai), depends on only a1, r1, . . . , ai, so this is a valid choice for Âµt. Note that
mt is the Bayesian GP posterior mean function (again with a Gaussian likelihood with variance Î²).
We now compare the standard â€œnon-adaptiveâ€ mixture distributions (with Âµt and T t as in (9)) and an
adaptive sequence of Gaussian mixture distributions (with Âµt as in (42) and T t as in (41)). With both
sequences of mixture distributions, we use m(a) = 0 and k(a, aâ€²) = Ï•(a)âŠ¤Ï•(aâ€²). For the adaptive
sequence of mixture distributions, we set Î² = 4Ïƒ2.
4
2
0
2
4
6
4
2
0
2
4
Non-Adaptive
Adaptive
Figure 5: The upper and lower confidence bounds of CMM-UCB with the standard (non-adaptive)
sequence of Gaussian mixture distributions (purple) and the adaptive sequence of Gaussian mixture
distributions (red).
Figure 5 shows upper and lower confidence bounds for a randomly generated linear function f(x) =
Ï•(x)âŠ¤Î¸âˆ—, where x âˆˆR, Î¸âˆ—âˆˆR20, and Ï• is a random Fourier feature map. In this example, the
adaptive sequence of mixture distributions leads to tighter upper and lower confidence bounds.
33

100
200
300
400
500
T
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
Radius
Radius
AMM-UCB
Adaptive AMM-UCB
100
200
300
400
500
T
0.50
0.55
0.60
0.65
0.70
0.75
0.80
0.85
Test Accuracy
Test Accuracy / Expected Reward
Figure 6: The radius RAMM,t (left) and test accuracy (right) with the standard sequence of Gaussian
mixture distributions (blue) and the adaptive sequence of Gaussian mixture distributions (orange).
On the left, we plot the mean value of the radius RAMM,t over 10 runs and show the mean Â± one
standard deviation in the shaded regions. On the right, we plot the mean reward over 10 runs and
after Gaussian kernel smoothing.
Figure 6 shows the radius RAMM,t (left) and test accuracy (right) for AMM-UCB in the SVM
hyperparameter tuning problem with the Raisin data set (described in Sec. 8.2). We observe that
AMM-UCB with the adaptive mixture distributions achieves slightly higher test accuracy.
In Sec. D.2.1, we saw that for a standard sequence of mixture distributions, RAMM,T could be
upper bounded by a data-independent quantity of order O(
p
d ln(T)). In Figure 6, RAMM,T does
appear to grow roughly logarithmically with T when the mixture distributions are the standard choice.
However, RAMM,T appears to be bounded by a constant when the mixture distributions are adaptive.
If, when using adaptive mixture distributions, we could prove a data-independent bound on RAMM,T
of order O(
âˆš
d), then we would be able to improve our data-independent cumulative regret bounds
to O(d
p
Tln(T)) (rather than O(d
âˆš
Tln(T))). This would be within a
p
ln(T) factor of the lower
bound â„¦(d
âˆš
T).
F
Efficient Radius Computation
If we compute the squared radius R2
MM,t using the expression in (5), then we have to compute the
inverse and determinant of the t Ã— t matrix 1 + T t/Ïƒ2. We will now show that for any mixture
distribution of the form Pt = N(Âµt, Î¦tÎ£0Î¦âŠ¤
t ), where Î£0 is symmetric and positive-definite, we can
re-write the expression for R2
MM,t such that we instead need to compute the inverse and determinant
of a d Ã— d matrix. When Pt = N(Âµt, Î¦tÎ£0Î¦âŠ¤
t ), the squared radius R2
MM,t is equal to
R2
MM,t = (Âµt âˆ’rt)âŠ¤

1 + Î¦tÎ£0Î¦âŠ¤
t
Ïƒ2
âˆ’1
(Âµt âˆ’rt)+Ïƒ2 ln

det

1 + Î¦tÎ£0Î¦âŠ¤
t
Ïƒ2

+2Ïƒ2 ln(1/Î´).
By using the Weinsteinâ€“Aronszajn identity, and then doing some algebra, we have
det

1 + Î¦tÎ£0Î¦âŠ¤
t
Ïƒ2

= det
 
1 + Î£1/2
0
Î¦âŠ¤
t Î¦tÎ£1/2
0
Ïƒ2
!
= det(Î£0/Ïƒ2) det
 Î¦âŠ¤
t Î¦t + Ïƒ2Î£âˆ’1
0

.
Using Lemma C.4 with Î³ = Ïƒ2, v = Âµt âˆ’rt and M = Î¦tÎ£1/2
0
, we have
(Âµt âˆ’rt)âŠ¤

1 + 1
Ïƒ2 Î¦tÎ£0Î¦âŠ¤
t
âˆ’1
(Âµt âˆ’rt) = (Âµt âˆ’rt)âŠ¤(Âµt âˆ’rt)
âˆ’(Âµt âˆ’rt)âŠ¤Î¦tÎ£1/2
0

Î£1/2
0
Î¦âŠ¤
t Î¦tÎ£1/2
0
+ Ïƒ21
âˆ’1
Î£1/2
0
Î¦âŠ¤
t (Âµt âˆ’rt)
= (Âµt âˆ’rt)âŠ¤(Âµt âˆ’rt) âˆ’(Âµt âˆ’rt)âŠ¤Î¦tÎ£1/2
0

Î£1/2
0
 Î¦âŠ¤
t Î¦t + Ïƒ2Î£âˆ’1
0

Î£1/2
0
âˆ’1
Î£1/2
0
Î¦âŠ¤
t (Âµt âˆ’rt)
= (Âµt âˆ’rt)âŠ¤(Âµt âˆ’rt) âˆ’(Âµt âˆ’rt)âŠ¤Î¦t
 Î¦âŠ¤
t Î¦t + Ïƒ2Î£âˆ’1
0
âˆ’1 Î¦âŠ¤
t (Âµt âˆ’rt).
34

The resulting expression for R2
MM,t is rather cumbersome, but the upshot is that we now (only) need
to compute the inverse and determinant of the d Ã— d matrix Î¦âŠ¤
t Î¦t + Ïƒ2Î£âˆ’1
0 . Since, we compute
R2
MM,t at each round t, we can update the inverse of Î¦âŠ¤
t Î¦t + Ïƒ2Î£âˆ’1
0
incrementally using the
Sherman-Morrison formula (Sherman & Morrison, 1950). The determinant of Î¦âŠ¤
t Î¦t + Ïƒ2Î£âˆ’1
0
can
be updated incrementally using the relation
det
 Î¦âŠ¤
t Î¦t + Ïƒ2Î£âˆ’1
0

= det(Î¦âŠ¤
tâˆ’1Î¦tâˆ’1 + Ïƒ2Î£âˆ’1
0 )(1 + Ï•(at)âŠ¤(Î¦âŠ¤
tâˆ’1Î¦tâˆ’1 + Ïƒ2Î£âˆ’1
0 )âˆ’1Ï•(at)),
which can be found in Eq. (6) in Lemma 11 of (Abbasi-Yadkori et al., 2011). Additionally, recall
that (see Eq. (24)) when Pt = N(0, cÎ¦tÎ¦âŠ¤
t ) and Î± = Ïƒ2/c for any c > 0, the radius RAMM,t of our
analytic confidence bounds simplifies to
R2
AMM,t = Ïƒ2 ln

det
 c
Ïƒ2 Î¦âŠ¤
t Î¦t + 1

+ Ïƒ2B2
c
+ 2Ïƒ2ln(1/Î´).
Note that the inverse (Î¦âŠ¤
t Î¦t + (Ïƒ2/c)1)âˆ’1 still appears in the expression for AUCBÎ˜t(a) and in
the incremental determinant update rule.
35

