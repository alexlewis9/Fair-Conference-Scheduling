MEDCALC-BENCH: Evaluating Large Language
Models for Medical Calculations
Nikhil Khandekar∗1, Qiao Jin∗1, Guangzhi Xiong∗2, Soren Dunn3, 4, Serina S Applebaum5,
Zain Anwar7, Maame Sarfo-Gyamfi8, Conrad W Safranek5, Abid A Anwar6, Andrew Zhang9,
Aidan Gilson5, Maxwell B Singer5, Amisha Dave5, Andrew Taylor5,
Aidong Zhang2, Qingyu Chen5, and Zhiyong Lu†1
1National Library of Medicine, National Institutes of Health, 2University of Virginia, 3University of
Illinois at Urbana Champaign, 4Lapis Labs, 5Yale University School of Medicine, 6University of
Illinois College of Medicine at Chicago, 7Rosalind Franklin University Chicago Medical School,
8Howard University College of Medicine, 9University of Chicago Pritzker School of Medicine
Abstract
As opposed to evaluating computation and logic-based reasoning, current bench-
marks for evaluating large language models (LLMs) in medicine are primarily
focused on question-answering involving domain knowledge and descriptive rea-
soning. While such qualitative capabilities are vital to medical diagnosis, in real-
world scenarios, doctors frequently use clinical calculators that follow quantitative
equations and rule-based reasoning paradigms for evidence-based decision support.
To this end, we propose MEDCALC-BENCH, a first-of-its-kind dataset focused
on evaluating the medical calculation capability of LLMs. MEDCALC-BENCH
contains an evaluation set of over 1000 manually reviewed instances from 55 dif-
ferent medical calculation tasks. Each instance in MEDCALC-BENCH consists of a
patient note, a question requesting to compute a specific medical value, a ground
truth answer, and a step-by-step explanation showing how the answer is obtained.
While our evaluation results show the potential of LLMs in this area, none of them
are effective enough for clinical settings. Common issues include extracting the
incorrect entities, not using the correct equation or rules for a calculation task,
or incorrectly performing the arithmetic for the computation. We hope our study
highlights the quantitative knowledge and reasoning gaps in LLMs within medical
settings, encouraging future improvements of LLMs for various clinical calculation
tasks. 1
1
Introduction
Large language models (LLMs) such as GPT [2, 32], Gemini/PaLM [1, 48], and Llama [51, 52]
have been successfully applied to a variety of biomedical tasks [30, 40, 49, 50], including but not
limited to question answering [28, 31, 44], clinical trial matching [23, 57, 58, 61], and medical
document summarization [42, 47, 53]. However, most of these tasks have a limited evaluation of
domain knowledge and qualitative reasoning ability of LLMs, as demonstrated by the commonly
used medical benchmarks such as MedQA [21], PubMedQA [22], and MedMCQA [35]. While
∗Equal contribution. †Correspondence: zhiyong.lu@nih.gov.
1MEDCALC-BENCH is publicly available at: https://github.com/ncbi-nlp/MedCalc-Bench.
Preprint. Under review.
arXiv:2406.12036v4  [cs.CL]  30 Jun 2024

A 68-year-old man with the left hemiparesis from 2 h previously visited
the emergency room. His medical history included hypertension and
bilateral emphysema due to heavy smoking. Vital sign assessment
revealed tachycardia; examination of the heart revealed atrial [...]
Rule-based Medical Calculation
What is the patient's CHA2DS2-VASc score?
The patient is 68 years old. Because the age is between 65 and 74,
one point added to the score, making the current total 0 + 1 = 1. The
patient's gender is male so no points are added to the current total,
keeping the total at 1. The patient history for congestive heart [...]
7
Patient Note
Question
Explanation
Final Answer
The patient was a 20-year-old previously healthy woman. She was a
university student. Her height and body weight were 168.1 cm and
52.2 kg, respectively. She ingested bamboo salt (about 150 grams )
in a day for the purpose of digestion and weight reduction [...]
Equation-based Medical Calculation
What is the patient's albumin corrected anion gap in mEq/L?
The formula for computing a patient's albumin corrected anion gap is:
anion gap (in mEq/L) + 2.5 * (4 - albumin (in g/dL)). The formula for
computing a patient's anion gap is: sodium (mEq/L) - (chloride
(mEq/L)+ bicarbonate (mEq/L)). The concentration of sodium  [...]
19.25
Patient Note
Question
Explanation
Final Answer
Figure 1: Example instances of the MEDCALC-BENCH dataset.
quantitative tools such as medical calculators are frequently used in clinical settings [8, 14], currently
there is no benchmark evaluating the medical calculation capabilities of LLMs.
Medical calculators are statistical tools derived from high-quality clinical studies, serving various
purposes, including metric conversions [7], disease diagnosis [18], and prognosis prediction [11].
Figure 1 shows two examples of medical calculators. To accurately compute requested medical scores,
the model needs to have three non-trivial capabilities: (1) possessing the knowledge of the rules or
equations for the medical calculation task, (2) identifying and extracting the relevant parameters
within a long patient note, and (3) conducting the arithmetic computation for the task correctly.
In this work, we propose MEDCALC-BENCH, a first-of-its-kind dataset for evaluating the medical
calculation capabilities of LLMs. To construct MEDCALC-BENCH, we first curated 55 common
medical calculation tasks from MDCalc2. Then, we compiled Open-Patients, a collection of over
180k publicly available patient notes, and identified the notes that can be used for each calculation
task. Finally, we collected over 1k instances for MEDCALC-BENCH, where each instance contains:
(1) a patient note, (2) a question requesting to compute a specific medical value, (3) a manually
reviewed ground truth answer, and (4) a step-by-step explanation of the computation process.
Using MEDCALC-BENCH, we conducted systematic evaluations of various LLMs, including the
state-of-the-art proprietary models such as GPT-4 [32], open-source LLMs such as Llama [52] and
Mixtral [20], as well as biomedical domain-specific PMC-LLaMA [59] and MEDITRON [5]. Our
experimental results show that most of the tested models struggle in the task. GPT-4 achieved the
best baseline performance of only 50.9% accuracy using one-shot chain-of-thought prompting. By
analyzing the types of errors made by LLMs, we found that the models suffer mostly from insufficient
medical calculator knowledge in the zero-shot setting. To mitigate this issue, we add a one-shot
exemplar in the prompt, showing the model how to apply the requested medical equations or rules.
Our analysis revealed additional issues in extracting calculator-related attributes and in arithmetic
computations. These results can provide insights into future improvement in the medical calculation
capabilities of LLMs.
In summary, the contributions of our study are threefold:
• We manually curated MEDCALC-BENCH, a novel dataset of over 1k instances for evaluating
the capabilities of LLMs across 55 different medical calculation tasks.
2https://www.mdcalc.com/#Popular
2

• We conducted comprehensive evaluations on MEDCALC-BENCH with various open and
closed-source LLMs. Our results show that all current LLMs are not yet ready for medical
calculations, with the best accuracy of only 50.9% achieved by GPT-4.
• Our error analysis reveals the insufficiency of calculator knowledge in LLMs, as well as
their deficiencies in attribute extraction and arithmetic computation for medical calculation.
2
MEDCALC-BENCH
2.1
Calculation Task Curation
We selected 55 different calculators for MEDCALC-BENCH, all of which were listed as “popular”
on MDCalc, the most commonly used online medical calculator website by clinicians [9]. As
shown in Figure 1, they fall into two major categories, rule-based calculation (19 calculators) and
equation-based calculation (36 calculators).
Rule-based calculators typically contain a list of criteria, where each criterion is a condition of a
specific medical attribute. An instance of this would be the HEART score calculator [45], which takes
in both numerical attributes such as the patient’s age (e.g., if the patient is older than 65 years, add
two points; if the patient’s age is between 45 and 64, add one point; and zero points otherwise) and
categorical variables such as the presence of significant ST elevation (adding two points if present;
zero points otherwise). The final answer for these calculators will be a discrete answer after taking
the sum of the sub-scores.
Like rule-based calculators, equation-based calculators also take in both categorical (e.g., gender,
race) and numerical variables (e.g., creatinine concentration, age, and height). However, equation-
based calculators follow a specific formula to output a decimal, date, or time given the attributes
instead of additively combining sub-scores for each criterion. An instance of an equation-based
calculator would be the MDRD GRF equation [27]. This equation computes the patient’s eGFR,
using the patient’s gender and race as coefficients in addition to the patient’s creatinine concentration.
The only equation-based calculators which do not output a decimal are Estimated Due Date (EDD),
Estimated Date of Conception (EDC), and Estimated Gestational Age (EGA). These three calculators
compute a date (for EDC, EGA) or a time (for EGA) instead.
For each instance, MEDCALC-BENCH also provides a natural language explanation for how the
final answer is computed. We implement template-based explanation generators for each of the 55
calculators. These templates first list the numerical and categorical variable values, and then plug
them in to show how the final answers are obtained. The implementation details can be found in
supplementary materials.
2.2
Dataset Instance Collection
In this section, we describe how patient notes and answers were collected for the 55 different
calculation tasks in MEDCALC-BENCH. We aimed to collect at most 20 notes for each calculator.
Specifically, the patient notes were collected using the following three-step pipeline.
(1) Note collection and attribute extraction. We compiled Open-Patients3, a collection of over 180k
public patient notes, including anonymized real case reports from PMC-Patients [60], case vignettes in
MedQA-USMLE [21], synthetic cases in TREC Clinical Decision Support Tracks [43, 38] and TREC
Clinical Trials Tracks [39]. Using GPT-3.5-Turbo, we identified patient notes for each calculator
based on its eligibility criteria. We then used GPT-4 to extract the attribute values needed for each
calculator from the eligible notes.
(2) Data verification and enrichment. The extracted values were verified and corrected by medical
professionals. After the verification, 34 of the 55 calculators have at least one eligible note with
the extracted attribute required for computation. Of the remaining 21 calculators, 10 of them are
3Publicly available at https://huggingface.co/datasets/ncbi/Open-Patients.
3

equation-based calculators, for which we generated 20 synthesized notes for each of them using
corresponding templates. The other 11 calculators are rule-based for which clinicians synthesized 20
patient notes each.
(3) Answer and explanation generation. After obtaining patient notes with the extracted values, for
each of the 55 calculators, we generated step-by-step explanations to derive the final answers. Specif-
ically, we implemented templates for each calculator to generate the natural language explanations.
From these three steps, we curated 1047 instances for MEDCALC-BENCH, each of which contains a
patient note, a question, along with a ground-truth explanation and final answer.
2.3
Dataset Characteristics
Table 1 shows the statistics of MEDCALC-BENCH and the different calculator sub-types. The
equation-based calculators have between 1 to 7 attributes, while the rule-based calculators have
between 3 to 31 attributes. Thus, it may require a varying number of reasoning steps to solve different
tasks in our dataset.
Table 1: Statistics of MEDCALC-BENCH. Inst.: instance; Avg.: average; Attr.: attribute; Q.: question.
#Tasks
#Inst.
Avg. L
of Note
Avg. L
of Q.
Min
Attr.
Max
Attr.
Avg.
Attr.
Example Calculation
Equation-based Calculation Tasks
Lab
19
327
891.0
22.3
2
7
3.6
LDL Concentration
Physical
12
240
419.3
20.8
1
3
2.0
QTc (Bazett Formula)
Date
3
60
25.3
67.0
2
2
2.0
Estimated Due Date
Dosage
2
40
31.4
31.0
2
6
4.0
Morphine Equivalents
Rule-based Calculation Tasks
Risk
12
240
422.1
14.9
5
31
11.5
Caprini Score for VTE
Severity
4
80
262.6
11.0
3
20
7.7
Pneumonia Severity Idx
Diagnosis
3
60
625.6
15.0
3
9
5.3
PERC Rule for PE
Overall
55
1047
529.7
21.9
1
31
5.4
–
Our dataset evaluates three distinct capabilities required for medical calculation:
(1) Recall of medical calculation knowledge. The first required capability is the recall of correct
medical knowledge for given questions from seven different domains shown in Table 1. As mentioned
above, medical calculators can have various sub-types, which challenge LLMs to recall the exact
knowledge, including medical equations or rules, to solve the clinical calculation task.
(2) Extraction of relevant patient attributes. The second required capability is the extraction
of correct attributes from patient notes, given the noises in the long context of over 500 words
on average. LLMs are required to extract both numerical and categorical attributes. The medical
context complicates such extractions, with the existence of multiple synonyms (e.g., both HbA1c
and glycohemoglobin denote the same entity) and the requirement of determining the presence of
attributes (e.g., a blood pressure of 160/100 mmHg indicates the presence of hypertension) using
medical knowledge and clinical reasoning.
(3) Arithmetic computation of the final results. The third required capability is the computation
of final results, especially the derivation of scores through multi-step reasoning. While datasets like
GSM-8k [6] have tested the arithmetic calculation capability of LLMs, MEDCALC-BENCH presents
a more challenging task, as it requires LLMs to fully understand the sequence and dependencies
among multiple medical equations or rules, in order to make the correct computation. Additionally,
MEDCALC-BENCH also contains some exponential computations that are not covered by other math
datasets.
4

Overall, we believe that MEDCALC-BENCH serves as a comprehensive benchmark which not only
examines the internal medical calculation knowledge of LLMs, but also tests general-purpose skills
such as attribute extraction and arithmetic computation in a more challenging domain-specific setting.
3
Evaluation
3.1
Settings
To establish the baseline performance in MEDCALC-BENCH, we experiment with eight different
LLMs under three common prompting strategies. Specifically, three groups of LLMs are considered:
Medical domain-specific LLMs include PMC-LLaMA-13B [59] and MEDITRON-70B [5]; Pro-
prietary LLMs include GPT-4 [32] and GPT-3.5 [33]; Open-source LLMs, including 8B and 70B
Llama 3 [52], as well as Mistral-7B [19] and Mixtral-8x7B [20].
Similarly, we consider three prompting strategies: Zero-shot Direct Prompting: In this setting,
the LLM is prompted to directly output the answer without any explanation; Zero-shot Chain-of-
Thought (CoT) Prompting: In this setting, the LLM is prompted to first generate step-by-step
rationale and then generate the answer [56]; One-shot CoT Prompting: In this setting, the LLM is
provided with an exemplar of the corresponding calculation task. The exemplar is manually curated
and contains the patient note, question, and the output consisting of the step-by-step explanation and
final answer value.
Based on the output type, we have three different evaluation settings: (1) For all rule-based calculators,
the final answer must be the exact same as the ground-truth answer, (2) For equation-based calculators
that are lab tests, physical tests, and dosage conversion calculators, the predicted answer must be
within 5% of the ground-truth answer, (3) For date-based equation calculations, the predicted dates
should exactly match the ground truth.
3.2
Main Results
Table 2 presents our evaluation results of various LLMs on the 1047 instances from MEDCALC-
BENCH. From the table, we can observe the diverse performance of the models in different settings.
In general, LLMs tend to perform better with the help of CoT prompting and one-shot learning, as
evidenced by the improved accuracy for each LLM shown in the table. Among all LLMs compared,
GPT-4 achieves the best performance in all three settings. In the zero-shot direct promoting setting,
GPT-4 has a mean accuracy of 20.82% on the task. By leveraging its own reasoning ability, the
performance of GPT-4 can be improved to 37.92%. Incorporating external medical knowledge from
a one-shot demonstration further increases its accuracy to 50.91%. Similar patterns can also be
observed in many other LLMs, such as LLama 3 and Mixtral.
In addition to the general trend across different settings, the table also shows how various types of
LLMs perform differently on our MEDCALC-BENCH test. While GPT-4 performs the best in our
evaluation, the open-source Llama 3-70B model shows a competitive performance that is close to
GPT-4. In both zero-shot direct prompting and zero-shot CoT prompting settings, Llama 3-70B
achieves mean accuracies that are comparable to the results of GPT-4. However, GPT-4 significantly
outperforms LLama 3-70B with the one-shot demonstration, which reflects its superior in-context
learning capability for medical calculation. Moreover, by comparing Llama 3-8B/Mistral-7B with
Llama 3-70B/Mixtral-8x7B, we find larger LLMs generally perform better on the medical calculation
tasks, corresponding to the empirical scaling laws [17, 26]. Interestingly, the 70B MEDITRON cannot
beat Mistral-7B in the zero-shot settings, which can be explained by its poor instruction-following
capability as the officially released model has not been instruction-tuned. With the additional
demonstration in a one-shot setting, MEDITRON effectively learns the task and shows an improved
performance close to Mixtral-8x7B.
It can also be observed from the table that the results for different subtasks in MEDCALC-BENCH
present distinct patterns. For example, the performance of GPT-4 on the physical value calculation
5

Table 2: MEDCALC-BENCH accuracy of different systems. All numbers are in percentages. Phys.:
Physical; Sev.: Severity; Diag.: Diagnosis; Avg.: Average; ± std for all results are shown.
Model
Size
Equation
Rule-based
Avg.
Lab
Phys.
Date
Dosage
Risk
Sev.
Diag.
Zero-shot Direct Prompting
PMC-LLaMA [59]
13B
0.00
±0.00
0.00
±0.00
0.00
±0.00
0.00
±0.00
0.00
±0.00
0.00
±0.00
0.00
±0.00
0.00
±0.00
MEDITRON [5]
70B
3.67
±0.01
8.33
±0.02
5.00
±0.03
0.00
±0.00
7.50
±0.02
5.00
±0.02
13.33
±0.04
6.21
±0.01
Mistral [19]
7B
10.70
±0.02
18.33
±0.02
3.33
±0.02
0.00
±0.00
4.58
±0.01
3.75
±0.02
13.33
±0.04
9.84
±0.01
Mixtral [20]
8x7B
12.23
±0.02
23.33
±0.03
5.00
±0.03
7.50
±0.04
12.92
±0.02
7.50
±0.03
16.67
±0.05
14.23
±0.01
Llama 3 [52]
8B
10.70
±0.02
19.17
±0.03
3.33
±0.02
5.00
±0.03
12.50
±0.02
8.75
±0.03
25.00
±0.06
13.09
±0.01
Llama 3 [52]
70B
18.04
±0.02
33.33
±0.03
8.33
±0.04
12.50
±0.05
15.83
±0.02
13.75
±0.04
33.33
±0.06
20.82
±0.01
GPT-3.5 [33]
N/A
17.13
±0.02
35.00
±0.03
13.33
±0.04
5.00
±0.03
12.92
±0.02
6.25
±0.03
18.33
±0.05
18.82
±0.01
GPT-4 [32]
N/A
14.37
±0.02
34.58
±0.03
38.33
±0.06
15.00
±0.06
14.58
±0.02
15.00
±0.04
20.00
±0.05
20.82
±0.01
Zero-shot CoT Prompting
PMC-LLaMA [59]
13B
0.00
±0.00
0.00
±0.00
0.00
±0.00
0.00
±0.00
0.00
±0.00
0.00
±0.00
0.00
±0.00
0.00
±0.00
MEDITRON [5]
70B
0.00
±0.00
0.00
±0.00
3.33
±0.02
0.00
±0.00
0.00
±0.00
0.00
±0.00
3.33
±0.02
0.38
±0.00
Mistral [19]
7B
10.09
±0.02
14.58
±0.02
1.67
±0.02
0.00
±0.00
9.58
±0.02
7.50
±0.03
25.00
±0.06
10.79
±0.01
Mixtral [20]
8x7B
22.63
±0.02
40.00
±0.03
6.67
±0.03
17.50
±0.06
11.25
±0.02
21.25
±0.05
15.00
±0.05
22.35
±0.01
Llama 3 [52]
8B
16.51
±0.02
25.00
±0.03
1.67
±0.02
7.50
±0.04
11.25
±0.02
13.75
±0.04
26.67
±0.06
16.43
±0.01
Llama 3 [52]
70B
33.94
±0.03
66.25
±0.03
25.00
±0.06
20.00
±0.06
18.33
±0.02
16.25
±0.04
36.67
±0.06
35.53
±0.01
GPT-3.5 [33]
N/A
20.49
±0.02
45.00
±0.03
11.67
±0.04
17.50
±0.06
13.33
±0.02
10.00
±0.03
31.67
±0.06
23.69
±0.01
GPT-4 [32]
N/A
26.30
±0.02
71.25
±0.03
48.33
±0.06
40.00
±0.08
27.50
±0.03
15.00
±0.04
28.33
±0.06
37.92
±0.01
One-shot CoT Prompting
PMC-LLaMA [59]
13B
5.20
±0.01
10.42
±0.02
8.33
±0.04
2.50
±0.02
7.08
±0.02
1.25
±0.01
11.67
±0.04
6.97
±0.01
MEDITRON [5]
70B
22.94
±0.02
39.58
±0.03
31.67
±0.06
15.00
±0.06
20.42
±0.03
15.00
±0.04
31.67
±0.06
26.27
±0.01
Mistral [19]
7B
11.01
±0.02
30.42
±0.03
6.67
±0.03
0.00
±0.00
16.25
±0.02
6.25
±0.03
18.33
±0.05
16.05
±0.01
Mixtral [20]
8x7B
28.13
±0.02
50.83
±0.03
8.33
±0.04
22.50
±0.07
21.25
±0.03
8.75
±0.03
33.33
±0.06
29.23
±0.01
Llama 3 [52]
8B
34.86
±0.03
35.42
±0.03
3.33
±0.02
2.50
±0.02
20.00
±0.03
11.25
±0.04
41.67
±0.06
27.13
±0.01
Llama 3 [52]
70B
41.59
±0.03
56.25
±0.03
30.00
±0.06
22.50
±0.07
27.50
±0.03
27.50
±0.05
45.00
±0.06
39.45
±0.02
GPT-3.5 [33]
N/A
30.89
±0.03
59.17
±0.03
41.67
±0.06
15.00
±0.06
23.33
±0.03
17.50
±0.04
35.00
±0.06
34.86
±0.01
GPT-4 [32]
N/A
51.68
±0.03
77.50
±0.03
46.67
±0.06
37.50
±0.08
33.75
±0.03
27.50
±0.05
53.33
±0.06
50.91
±0.02
task is improved by 36.67% by adding CoT prompting, while including an additional demonstration
only further increases its accuracy by 6.25%. In contrast, GPT-4 performance is improved by 8.33%
6

and 25%, respectively, on the diagnosis calculation task, with the help of CoT prompting and one-shot
demonstration. This result reflects that GPT-4 already contains certain medical knowledge concerning
physical value calculation, thus the CoT prompting alone can significantly enhance its performance
on such tasks. Nevertheless, the diagnosis calculation information is insufficient in its parametric
knowledge, so the extra one-shot demonstration offers better help compared to the CoT prompting.
Such an analysis enables us to have insights into the capabilities and limitations of LLMs on various
medical calculation tasks, suggesting their different use cases in real-world applications.
4
Discussion
In this section, we provide an in-depth analysis of errors made by LLMs on MEDCALC-BENCH.
4.1
What types of errors can LLMs make in MEDCALC-BENCH?
We categorize four types of errors that LLMs can make in our dataset: Type A (knowledge errors):
the model does not have the correct knowledge of the equation or rules used in the medical calculation
task; Type B (extraction errors): the model extracts the wrong parameters from the patient note;
Type C (computation errors): the model conducts the arithmetic incorrectly; Type D (other errors):
all other cases of errors. Specific examples of the first three error types are shown in Table 3.
It should be noted that these errors are not independent of each other. For example, LLMs usually
recall the relevant calculator knowledge first, and then extract the relevant parameters, and finally
conduct the computation. If the model recalls the calculator incorrectly, it is highly likely that it
cannot extract the correct set of relevant parameters. Hence, we only consider the earliest error if
there are multiple error types (e.g., if the model has error types A and B, then the error type will be
A).
Table 3: Examples of three error types in MEDCALC-BENCH. The incorrect rationale, # comments,
and evidence are highlighted.
Type
Question
Patient Note
Error of GPT-4 Zero-shot CoT
A
What
is
the
patient’s Wells’
criteria
score
for Deep Vein
Thrombosis?
A 77-year-old man was diagnosed
with RA in 2006 with positive anti-
CCP antibodies and RF; MTX was
used but was changed to GLM in
2016 (the recent dose interval was 6–7
weeks; the last dose was 5 weeks be-
fore vaccine administration) and main-
tained [...]
The Wells’ criteria for Deep Vein
Thrombosis (DVT) includes [...] the
patient has a brain hemorrhage, which
is more likely than a DVT. The patient
scores 1 point for paralysis and 1 point
for an alternative diagnosis being less
likely. # Wrong point assignment
[...]
B
What
are
the
number
of
criteria met for
the PERC Rule
for
Pulmonary
Embolism (PE)?
A 61-year-old male presented to our
emergency department complaining
of [...] A computerized tomography
with contrast of the chest revealed
multiple filling defects within the pul-
monary arterial system, indicative of
bilateral acute on chronic thromboem-
bolic disease. [...]
The PERC Rule for Pulmonary Em-
bolism (PE) includes eight criteria:
[...] The patient is older than 50 years,
his pulse rate is less than 100 bpm,
his SaO2 is less than 94%, there is no
mention of hemoptysis, estrogen use,
prior DVT or PE # The patient had
PE, recent surgery or trauma, or uni-
lateral leg swelling. [...]
C
What
is
the
patient’s
LDL
cholestrol
con-
centration?
Please
outuput
your answer in
terms of mg/dL.
A 37-year-old male presented with
progressive swelling of feet and facial
puffiness for 6 months. On physical
examination, he had mild pallor, mod-
erate pedal edema and cloudy cornea
with a peripheral arcus in both eyes
[...] serum haptoglobin of 64 mg/dl
(normal range: 70–200 mg/dl), total
cholesterol 215 mg/dl, [...]
The patient’s [...] LDL = Total choles-
terol - HDL - (Triglycerides / 5). The
values needed for this calculation are
given in the note: Total cholesterol is
215 mg/dL, HDL is 10 mg/dL, and
Triglycerides are 385 mg/dL. Answer:
LDL = 215 - 10 - (385 / 5) = 142 #
Wrong computation mg/dL
7

4.2
What errors do different LLMs make?
To analyze the errors made by different LLMs, we utilize GPT-4 to classify their error types by
comparing the LLM output to the ground truth in MEDCALC-BENCH. We manually evaluate the
annotations of 200 randomly sampled explanation errors, and find the accuracy of GPT-4 error
classifier to be 89%. As such, we apply it to analyze the mistakes of all CoT prompting results.
Table 4 shows the distribution of error types in different settings. Under the zero-shot CoT setting,
most of the errors (more than 50%) belong to Type A in all LLMs, suggesting that recalling the
correct equations or rules for the corresponding medical calculation task is the biggest challenge
when no exemplar is provided. While Type A error is dominant under the zero-shot setting, its error
rate varies in different LLMs, e.g. 0.96 in PMC-LLaMA and 0.35 in GPT-4. Such a difference reflects
the diverse levels of medical calculation knowledge acquired by various LLMs.
Unlike the distributions in the zero-shot setting, errors that occurred with the one-shot CoT prompting
have less than 50% being categorized as Type A, which is consistently observed in different LLMs.
This shows the effectiveness of the one-shot exemplar in providing the background rule or equation
needed for medical calculation. With the decrease in Type A errors, more Type B and Type C
errors are captured in the wrong answers. This reveals the deficiencies of current LLMs in attribute
extraction and arithmetic computation, which are required capabilities to perform real-world medical
calculations.
Table 4: Error type distribution of LLMs on MEDCALC-BENCH. Numbers in parentheses denote the
relative proportions. Arrows indicate the proportion changes from zero-shot to one-shot learning.
Model
Type A Error
Type B Error
Type C Error
Type D Error
Error Rate
Zero-shot CoT Prompting
PMC-LLaMA-13B
0.96 (96%)
0.03 (3%)
0.00 (0%)
0.01 (1%)
1.00
MEDITRON-70B
0.97 (97%)
0.00 (0%)
0.02 (2%)
0.00 (0%)
1.00
Mistral-7B
0.72 (80%)
0.11 (12%)
0.06 (7%)
0.00 (0%)
0.89
Mixtral-8x7B
0.55 (71%)
0.11 (14%)
0.09 (11%)
0.02 (3%)
0.78
Llama 3-8B
0.60 (72%)
0.11 (13%)
0.13 (15%)
0.00 (0%)
0.84
Llama 3-70B
0.43 (67%)
0.10 (16%)
0.11 (17%)
0.00 (0%)
0.64
GPT-3.5
0.38 (50%)
0.24 (31%)
0.13 (17%)
0.02 (2%)
0.76
GPT-4
0.35 (57%)
0.19 (30%)
0.08 (13%)
0.00 (0%)
0.62
One-shot CoT Prompting
PMC-LLaMA-13B
0.42 (46%↓)
0.31 (34%↑)
0.17 (19%↑)
0.01 (1%–)
0.91
MEDITRON-70B
0.24 (33%↓)
0.23 (32%↑)
0.26 (35%↑)
0.01 (1%↑)
0.74
Mistral-7B
0.32 (38%↓)
0.33 (40%↑)
0.17 (20%↑)
0.01 (1%↑)
0.83
Mixtral-8x7B
0.27 (38%↓)
0.23 (33%↑)
0.19 (27%↑)
0.01 (2%↓)
0.71
Llama 3-8B
0.25 (34%↓)
0.17 (24%↑)
0.29 (40%↑)
0.02 (2%↑)
0.73
Llama 3-70B
0.20 (34%↓)
0.12 (20%↑)
0.23 (39%↑)
0.05 (8%↑)
0.60
GPT-3.5
0.23 (36%↓)
0.20 (30%↓)
0.20 (31%↑)
0.02 (2%–)
0.65
GPT-4
0.20 (40%↓)
0.13 (27%↓)
0.16 (33%↑)
0.00 (0%–)
0.49
4.3
Limitations and future work
While our study provides a first-of-its-kind dataset to evaluate the medical calculation capabilities of
various LLMs, there are several main limitations that can be improved in future work: (1) Due to
the difficulty of manual verification of each instance in MEDCALC-BENCH, our dataset is limited
in size, containing only 1047 instances in total. (2) Sometimes, the entity needed for a calculator
is mentioned multiple times in a patient note, making it hard to extract the correct one. While we
specifically prompt the model to extract the value of an entity that the patient has on their first
day of admission, this is occasionally difficult to determine, especially if the patient note describes
multiple visits. (3) While we saw a significant improvement in model performance with the one-shot
exemplar, benchmarking the model with few-shot instances may have further increased the accuracy.
However, curating such patient notes for rule-based calculators would have been difficult, given the
labor-intensiveness of having to synthesize patient notes often requiring many attributes.
8

5
Related Work
5.1
Language Model Evaluations in Medicine
Existing datasets for evaluating LLMs in biomedicine [10] have primarily focused on verbal reasoning
through multiple choice questions such as PubMedQA [22], MedQA [21], MedMCQA [35], and
the medical questions in MMLU [15]. However, these datasets are mainly focused on qualitative
reasoning instead of quantitative computation. Additionally, the format of multi-choice questions
does not reflect the actual clinical settings where a single answer or response must be determined
without any options provided. In this work, we introduce MEDCALC-BENCH, the first dataset that
measures the quantitative reasoning capabilities of LLMs in medicine in a realistic setting where the
LLM must determine the answer by itself without the support of answer choices.
5.2
Language Model Evaluations in Mathematics
Many efforts have been made to evaluate the mathematical and computation capability of LLMs in
various settings. GSM8k [6] and MATH [16] are two examples which focus on pure mathematical
problems. However, these datasets with general settings may not reflect LLM performance in domain-
specific applications. While there exist mathematical and computation-oriented datasets for specific
domains such as chemistry [34], their lack of manually verified step-by-step explanations weakens
their reliability for model evaluation. MEDCALC-BENCH not only serves as the first dataset for
medical-focused calculations, but also provides explanations that are verified by human experts. A
full comparison of various datasets can be found in Table 5.
Table 5: Comparison of different datasets for LLM evaluation. Medical: tasks for medical evaluation;
Knowledge: dataset tests knowledge to a particular domain; Qualitative (Qual) Reasoning: dataset
tests qualitative reasoning; Comput.: dataset requires computation (i.e., quantitative reasoning);
Non-MCQ: questions which have a single answer and without the use of multiple choices.
Medical
Knowledge
Qual. Reasoning
Comput.
Non-MCQ
MedQA [21]
✔
✔
✔
✗
✗
MedMCQA [35]
✔
✔
✔
✗
✗
PubMedQA [22]
✔
✗
✔
✗
✗
MMLU [15]
✔
✔
✔
✗
✗
GSM8k [6]
✗
✗
✗
✔
✔
MATH [16]
✗
✗
✗
✔
✔
MEDCALC-BENCH
✔
✔
✔
✔
✔
5.3
Tool Learning
One of the key features of language agents is the capability to use tools [36, 46, 54, 62], such as code
interpreters [4, 12] and external APIs [37, 41]. GeneGPT [25] and ChemCrow [29] utilize domain
functionalities for scientific discovery. While OpenMedCalc [13] and AgentMD [24] use medical
calculators to augment LLMs, their evaluations are based on small-scale or automatically constructed
datasets. Our manually-reviewed MEDCALC-BENCH is much larger than their evaluation datasets
and contains both natural language explanations as well as final numeric answers.
6
Conclusion
In conclusion, this study introduces MEDCALC-BENCH, the first dataset specifically designed to
evaluate the capabilities of LLMs for medical calculations. Our evaluations show that while LLMs
like GPT-4 exhibit potential, none are reliable enough for clinical use. The error analysis highlights
areas for improvement, such as knowledge recall and computational accuracy. We hope our work
serves as a call to further improve LLMs and make them more suitable for medical calculations.
9

Acknowledgments and Disclosure of Funding
This research was supported by the NIH Intramural Research Program, National Library of Medicine.
Additionally, the contributions made by Soren Dunn were done using the Delta advanced computing
and data resource which is supported by the National Science Foundation (award OAC tel:2005572)
and the State of Illinois. Delta is a joint effort of the University of Illinois Urbana-Champaign (UIUC)
and its National Center for Supercomputing Applications (NCSA).
Ethics Statement
For curating the patient notes in MEDCALC-BENCH, we only use publicly available patient notes
from published case report articles in PubMed Central and clinician-generated anonymous patient
vignettes. As such, no identifiable personal health information is revealed in this study.
While MEDCALC-BENCH is designed to evaluate the medical calculation capabilities of LLMs, it
should be noted that the dataset is not intended for direct diagnostic use or medical decision-making
without review and oversight by a clinical professional. Individuals should not change their health
behavior solely on the basis of our study.
Broader Impacts
As described in Sec 1, medical calculators are commonly used in the clinical setting. With the rapidly
growing interest in using LLMs for domain-specific applications, healthcare practitioners might
directly prompt chatbots like ChatGPT to perform medical calculation tasks. However, the capabilities
of LLMs in these tasks are currently unknown. Since healthcare is a high-stakes domain and wrong
medical calculations can lead to severe consequences, including misdiagnosis, inappropriate treatment
plans, and potential harm to patients, it is crucial to thoroughly evaluate the performance of LLMs in
medical calculations. Surprisingly, the evaluation results on our MEDCALC-BENCH dataset show
that all the studied LLMs struggle in the medical calculation tasks. The most capable model GPT-4
achieves only 50% accuracy with one-shot learning and chain-of-thought prompting. As such, our
study indicates that current LLMs are not yet ready to be used for medical calculations.
It should be noted that while high scores on MEDCALC-BENCH do not guarantee excellence in
medical calculation tasks, failing in this dataset indicates that the models must not be considered
for such purposes at all. In other words, we believe that passing MEDCALC-BENCH should be a
necessary (but not sufficient) condition for a model to be used for medical calculation.
References
[1] R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos, S. Shakeri, E. Taropa,
P. Bailey, Z. Chen, et al. Palm 2 technical report. arXiv preprint arXiv:2305.10403, 2023.
[2] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,
G. Sastry, A. Askell, et al. Language models are few-shot learners. Advances in neural
information processing systems, 33:1877–1901, 2020.
[3] A. H. Cano, M. Pagliardini, A. Köpf, K. Matoba, A. Mohtashami, X. Wang, O. S. Fan,
A. Marmet, D. Bayazit, I. Krawczuk, Z. Chen, F. Salvi, A. Bosselut, and M. Jaggi. epfllm
megatron-llm, 2023. URL https://github.com/epfLLM/Megatron-LLM.
[4] W. Chen, X. Ma, X. Wang, and W. W. Cohen. Program of thoughts prompting: Disentangling
computation from reasoning for numerical reasoning tasks. Transactions on Machine Learning
Research, 2023.
[5] Z. Chen, A. H. Cano, A. Romanou, A. Bonnet, K. Matoba, F. Salvi, M. Pagliardini, S. Fan,
A. Köpf, A. Mohtashami, et al. Meditron-70b: Scaling medical pretraining for large language
models. arXiv preprint arXiv:2311.16079, 2023.
10

[6] K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plappert, J. Tworek,
J. Hilton, R. Nakano, et al. Training verifiers to solve math word problems. arXiv preprint
arXiv:2110.14168, 2021.
[7] D. W. Cockcroft and H. Gault. Prediction of creatinine clearance from serum creatinine.
Nephron, 16(1):31–41, 1976.
[8] M. A. Dziadzko, O. Gajic, B. W. Pickering, and V. Herasevich. Clinical calculators in hos-
pital medicine: availability, classification, and needs. Computer methods and programs in
biomedicine, 133:1–6, 2016.
[9] A. Elovic and A. Pourmand. Mdcalc medical calculator app review. Journal of digital imaging,
32:682–684, 2019.
[10] J. Fries, L. Weber, N. Seelam, G. Altay, D. Datta, S. Garda, S. Kang, R. Su, W. Kusa, S. Cahyaw-
ijaya, et al. Bigbio: A framework for data-centric biomedical natural language processing.
Advances in Neural Information Processing Systems, 35:25792–25806, 2022.
[11] B. F. Gage, A. D. Waterman, W. Shannon, M. Boechler, M. W. Rich, and M. J. Radford.
Validation of clinical classification schemes for predicting stroke: results from the national
registry of atrial fibrillation. Jama, 285(22):2864–2870, 2001.
[12] L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y. Yang, J. Callan, and G. Neubig. Pal: Program-
aided language models. In International Conference on Machine Learning, pages 10764–10799.
PMLR, 2023.
[13] A. J. Goodell, S. N. Chu, D. Rouholiman, and L. F. Chu. Augmentation of chatgpt with
clinician-informed tools improves performance on medical calculation tasks. medRxiv, pages
2023–12, 2023.
[14] T. A. Green, S. Whitt, J. L. Belden, S. Erdelez, and C.-R. Shyu. Medical calculators: prevalence,
and barriers to use. Computer Methods and Programs in Biomedicine, 179:105002, 2019.
[15] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Measuring
massive multitask language understanding. arXiv preprint arXiv:2009.03300, 2020.
[16] D. Hendrycks, C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song, and J. Steinhardt.
Measuring mathematical problem solving with the MATH dataset. In Thirty-fifth Conference on
Neural Information Processing Systems Datasets and Benchmarks Track (Round 2), 2021. URL
https://openreview.net/forum?id=7Bywt2mQsCe.
[17] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. d. L. Casas,
L. A. Hendricks, J. Welbl, A. Clark, et al. Training compute-optimal large language models.
arXiv preprint arXiv:2203.15556, 2022.
[18] C. Initiative. 2010 rheumatoid arthritis classification criteria. Arthritis & Rheumatism, 62(9):
2569–2581, 2010.
[19] A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. d. l. Casas, F. Bressand,
G. Lengyel, G. Lample, L. Saulnier, et al. Mistral 7b. arXiv preprint arXiv:2310.06825, 2023.
[20] A. Q. Jiang, A. Sablayrolles, A. Roux, A. Mensch, B. Savary, C. Bamford, D. S. Chaplot, D. d. l.
Casas, E. B. Hanna, F. Bressand, et al. Mixtral of experts. arXiv preprint arXiv:2401.04088,
2024.
[21] D. Jin, E. Pan, N. Oufattole, W.-H. Weng, H. Fang, and P. Szolovits. What disease does
this patient have? a large-scale open domain question answering dataset from medical exams.
Applied Sciences, 11(14):6421, 2021.
11

[22] Q. Jin, B. Dhingra, Z. Liu, W. Cohen, and X. Lu. Pubmedqa: A dataset for biomedical
research question answering. In Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on Natural Language
Processing (EMNLP-IJCNLP), pages 2567–2577, 2019.
[23] Q. Jin, Z. Wang, C. S. Floudas, F. Chen, C. Gong, D. Bracken-Clarke, E. Xue, Y. Yang, J. Sun,
and Z. Lu. Matching patients to clinical trials with large language models. ArXiv, 2023.
[24] Q. Jin, Z. Wang, Y. Yang, Q. Zhu, D. Wright, T. Huang, W. J. Wilbur, Z. He, A. Taylor, Q. Chen,
et al. Agentmd: Empowering language agents for risk prediction with large-scale clinical tool
learning. arXiv preprint arXiv:2402.13225, 2024.
[25] Q. Jin, Y. Yang, Q. Chen, and Z. Lu. Genegpt: Augmenting large language models with domain
tools for improved access to biomedical information. Bioinformatics, 40(2):btae075, 2024.
[26] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Rad-
ford, J. Wu, and D. Amodei.
Scaling laws for neural language models.
arXiv preprint
arXiv:2001.08361, 2020.
[27] A. S. Levey, J. P. Bosch, J. B. Lewis, T. Greene, N. Rogers, D. Roth, and M. of Diet in Renal
Disease Study Group*. A more accurate method to estimate glomerular filtration rate from
serum creatinine: a new prediction equation. Annals of internal medicine, 130(6):461–470,
1999.
[28] V. Liévin, C. E. Hother, A. G. Motzfeldt, and O. Winther. Can large language models reason
about medical questions? Patterns, 5(3), 2024.
[29] A. M. Bran, S. Cox, O. Schilter, C. Baldassari, A. D. White, and P. Schwaller. Augmenting
large language models with chemistry tools. Nature Machine Intelligence, pages 1–11, 2024.
[30] H. Nori, N. King, S. M. McKinney, D. Carignan, and E. Horvitz. Capabilities of gpt-4 on
medical challenge problems. arXiv preprint arXiv:2303.13375, 2023.
[31] H. Nori, Y. T. Lee, S. Zhang, D. Carignan, R. Edgar, N. Fusi, N. King, J. Larson, Y. Li, W. Liu,
et al. Can generalist foundation models outcompete special-purpose tuning? case study in
medicine. arXiv preprint arXiv:2311.16452, 2023.
[32] OpenAI, :, J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida,
J. Altenschmidt, S. Altman, S. Anadkat, R. Avila, I. Babuschkin, S. Balaji, V. Balcom, P. Bal-
tescu, H. Bao, M. Bavarian, J. Belgum, I. Bello, J. Berdine, G. Bernadett-Shapiro, C. Berner,
L. Bogdonoff, O. Boiko, M. Boyd, A.-L. Brakman, G. Brockman, T. Brooks, M. Brundage,
K. Button, T. Cai, R. Campbell, A. Cann, B. Carey, C. Carlson, R. Carmichael, B. Chan,
C. Chang, F. Chantzis, D. Chen, S. Chen, R. Chen, J. Chen, M. Chen, B. Chess, C. Cho,
C. Chu, H. W. Chung, D. Cummings, J. Currier, Y. Dai, C. Decareaux, T. Degry, N. Deutsch,
D. Deville, A. Dhar, D. Dohan, S. Dowling, S. Dunning, A. Ecoffet, A. Eleti, T. Eloundou,
D. Farhi, L. Fedus, N. Felix, S. P. Fishman, J. Forte, I. Fulford, L. Gao, E. Georges, C. Gibson,
V. Goel, T. Gogineni, G. Goh, R. Gontijo-Lopes, J. Gordon, M. Grafstein, S. Gray, R. Greene,
J. Gross, S. S. Gu, Y. Guo, C. Hallacy, J. Han, J. Harris, Y. He, M. Heaton, J. Heidecke, C. Hesse,
A. Hickey, W. Hickey, P. Hoeschele, B. Houghton, K. Hsu, S. Hu, X. Hu, J. Huizinga, S. Jain,
S. Jain, J. Jang, A. Jiang, R. Jiang, H. Jin, D. Jin, S. Jomoto, B. Jonn, H. Jun, T. Kaftan, Łukasz
Kaiser, A. Kamali, I. Kanitscheider, N. S. Keskar, T. Khan, L. Kilpatrick, J. W. Kim, C. Kim,
Y. Kim, H. Kirchner, J. Kiros, M. Knight, D. Kokotajlo, Łukasz Kondraciuk, A. Kondrich,
A. Konstantinidis, K. Kosic, G. Krueger, V. Kuo, M. Lampe, I. Lan, T. Lee, J. Leike, J. Leung,
D. Levy, C. M. Li, R. Lim, M. Lin, S. Lin, M. Litwin, T. Lopez, R. Lowe, P. Lue, A. Makanju,
K. Malfacini, S. Manning, T. Markov, Y. Markovski, B. Martin, K. Mayer, A. Mayne, B. Mc-
Grew, S. M. McKinney, C. McLeavey, P. McMillan, J. McNeil, D. Medina, A. Mehta, J. Menick,
L. Metz, A. Mishchenko, P. Mishkin, V. Monaco, E. Morikawa, D. Mossing, T. Mu, M. Mu-
rati, O. Murk, D. Mély, A. Nair, R. Nakano, R. Nayak, A. Neelakantan, R. Ngo, H. Noh,
12

L. Ouyang, C. O’Keefe, J. Pachocki, A. Paino, J. Palermo, A. Pantuliano, G. Parascandolo,
J. Parish, E. Parparita, A. Passos, M. Pavlov, A. Peng, A. Perelman, F. de Avila Belbute Peres,
M. Petrov, H. P. de Oliveira Pinto, Michael, Pokorny, M. Pokrass, V. Pong, T. Powell, A. Power,
B. Power, E. Proehl, R. Puri, A. Radford, J. Rae, A. Ramesh, C. Raymond, F. Real, K. Rimbach,
C. Ross, B. Rotsted, H. Roussez, N. Ryder, M. Saltarelli, T. Sanders, S. Santurkar, G. Sas-
try, H. Schmidt, D. Schnurr, J. Schulman, D. Selsam, K. Sheppard, T. Sherbakov, J. Shieh,
S. Shoker, P. Shyam, S. Sidor, E. Sigler, M. Simens, J. Sitkin, K. Slama, I. Sohl, B. Sokolowsky,
Y. Song, N. Staudacher, F. P. Such, N. Summers, I. Sutskever, J. Tang, N. Tezak, M. Thompson,
P. Tillet, A. Tootoonchian, E. Tseng, P. Tuggle, N. Turley, J. Tworek, J. F. C. Uribe, A. Vallone,
A. Vijayvergiya, C. Voss, C. Wainwright, J. J. Wang, A. Wang, B. Wang, J. Ward, J. Wei,
C. Weinmann, A. Welihinda, P. Welinder, J. Weng, L. Weng, M. Wiethoff, D. Willner, C. Winter,
S. Wolrich, H. Wong, L. Workman, S. Wu, J. Wu, M. Wu, K. Xiao, T. Xu, S. Yoo, K. Yu,
Q. Yuan, W. Zaremba, R. Zellers, C. Zhang, M. Zhang, S. Zhao, T. Zheng, J. Zhuang, W. Zhuk,
and B. Zoph. Gpt-4 technical report, 2023.
[33] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal,
K. Slama, A. Ray, et al. Training language models to follow instructions with human feedback.
Advances in neural information processing systems, 35:27730–27744, 2022.
[34] S. Ouyang, Z. Zhang, B. Yan, X. Liu, J. Han, and L. Qin. Structured chemistry reasoning with
large language models. arXiv preprint arXiv:2311.09656, 2023.
[35] A. Pal, L. K. Umapathi, and M. Sankarasubbu. Medmcqa: A large-scale multi-subject multi-
choice dataset for medical domain question answering. In Conference on Health, Inference, and
Learning, pages 248–260. PMLR, 2022.
[36] Y. Qin, S. Hu, Y. Lin, W. Chen, N. Ding, G. Cui, Z. Zeng, Y. Huang, C. Xiao, C. Han, et al.
Tool learning with foundation models. arXiv preprint arXiv:2304.08354, 2023.
[37] Y. Qin, S. Liang, Y. Ye, K. Zhu, L. Yan, Y. Lu, Y. Lin, X. Cong, X. Tang, B. Qian, et al.
Toolllm: Facilitating large language models to master 16000+ real-world apis. arXiv preprint
arXiv:2307.16789, 2023.
[38] K. Roberts, M. S. Simpson, E. M. Voorhees, and W. R. Hersh. Overview of the trec 2015
clinical decision support track. In TREC, 2015.
[39] K. Roberts, D. Demner-Fushman, E. M. Voorhees, S. Bedrick, and W. R. Hersh. Overview of
the trec 2021 clinical trials track. In Proceedings of the thirtieth text retrieval conference (TREC
2021), 2021.
[40] K. Saab, T. Tu, W.-H. Weng, R. Tanno, D. Stutz, E. Wulczyn, F. Zhang, T. Strother, C. Park,
E. Vedadi, et al. Capabilities of gemini models in medicine. arXiv preprint arXiv:2404.18416,
2024.
[41] T. Schick, J. Dwivedi-Yu, R. Dessì, R. Raileanu, M. Lomeli, E. Hambro, L. Zettlemoyer,
N. Cancedda, and T. Scialom. Toolformer: Language models can teach themselves to use tools.
Advances in Neural Information Processing Systems, 36, 2024.
[42] C. Shaib, M. Li, S. Joseph, I. Marshall, J. J. Li, and B. C. Wallace. Summarizing, simplifying,
and synthesizing medical evidence using gpt-3 (with varying success). In Proceedings of the
61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),
pages 1387–1407, 2023.
[43] M. S. Simpson, E. M. Voorhees, and W. R. Hersh. Overview of the trec 2014 clinical decision
support track. In TREC, 2014.
[44] K. Singhal, S. Azizi, T. Tu, S. S. Mahdavi, J. Wei, H. W. Chung, N. Scales, A. Tanwani,
H. Cole-Lewis, S. Pfohl, et al. Large language models encode clinical knowledge. Nature, 620
(7972):172–180, 2023.
13

[45] A. Six, B. Backus, and J. Kelder. Chest pain in the emergency room: value of the heart score.
Netherlands Heart Journal, 16:191–196, 2008.
[46] T. R. Sumers, S. Yao, K. Narasimhan, and T. L. Griffiths. Cognitive architectures for language
agents. arXiv preprint arXiv:2309.02427, 2023.
[47] L. Tang, Z. Sun, B. Idnay, J. G. Nestor, A. Soroush, P. A. Elias, Z. Xu, Y. Ding, G. Durrett, J. F.
Rousseau, et al. Evaluating large language models on medical evidence summarization. npj
Digital Medicine, 6(1):158, 2023.
[48] G. Team, R. Anil, S. Borgeaud, Y. Wu, J.-B. Alayrac, J. Yu, R. Soricut, J. Schalkwyk, A. M.
Dai, A. Hauth, et al. Gemini: a family of highly capable multimodal models. arXiv preprint
arXiv:2312.11805, 2023.
[49] A. J. Thirunavukarasu, D. S. J. Ting, K. Elangovan, L. Gutierrez, T. F. Tan, and D. S. W. Ting.
Large language models in medicine. Nature medicine, 29(8):1930–1940, 2023.
[50] S. Tian, Q. Jin, L. Yeganova, P.-T. Lai, Q. Zhu, X. Chen, Y. Yang, Q. Chen, W. Kim,
D. C. Comeau, et al. Opportunities and challenges for chatgpt and large language models
in biomedicine and health. Briefings in Bioinformatics, 25(1):bbad493, 2024.
[51] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal,
E. Hambro, F. Azhar, et al. Llama: Open and efficient foundation language models. arXiv
preprint arXiv:2302.13971, 2023.
[52] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra,
P. Bhargava, S. Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv
preprint arXiv:2307.09288, 2023.
[53] D. Van Veen, C. Van Uden, L. Blankemeier, J.-B. Delbrouck, A. Aali, C. Bluethgen, A. Pareek,
M. Polacin, E. P. Reis, A. Seehofnerová, et al. Adapted large language models can outperform
medical experts in clinical text summarization. Nature Medicine, pages 1–9, 2024.
[54] L. Wang, C. Ma, X. Feng, Z. Zhang, H. Yang, J. Zhang, Z. Chen, J. Tang, X. Chen, Y. Lin, et al.
A survey on large language model based autonomous agents. Frontiers of Computer Science,
18(6):1–26, 2024.
[55] X. Wang, Y. Chen, L. Yuan, Y. Zhang, Y. Li, H. Peng, and H. Ji. Executable code actions elicit
better llm agents, 2024.
[56] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou, et al. Chain-of-
thought prompting elicits reasoning in large language models. Advances in neural information
processing systems, 35:24824–24837, 2022.
[57] C. Wong, S. Zhang, Y. Gu, C. Moung, J. Abel, N. Usuyama, R. Weerasinghe, B. Piening,
T. Naumann, C. Bifulco, et al. Scaling clinical trial matching using large language models:
A case study in oncology. In Machine Learning for Healthcare Conference, pages 846–862.
PMLR, 2023.
[58] M. Wornow, A. Lozano, D. Dash, J. Jindal, K. W. Mahaffey, and N. H. Shah. Zero-shot clinical
trial patient matching with llms. arXiv preprint arXiv:2402.05125, 2024.
[59] C. Wu, W. Lin, X. Zhang, Y. Zhang, W. Xie, and Y. Wang. Pmc-llama: toward building
open-source language models for medicine. Journal of the American Medical Informatics
Association, page ocae045, 2024.
[60] Z. Zhao, Q. Jin, F. Chen, T. Peng, and S. Yu. A large-scale dataset of patient summaries for
retrieval-based clinical decision support systems. Scientific Data, 10(1):909, 2023.
14

[61] S. Zhuang, B. Koopman, and G. Zuccon. Team ielab at trec clinical trial track 2023: En-
hancing clinical trial retrieval with neural rankers and large language models. arXiv preprint
arXiv:2401.01566, 2024.
[62] Y. Zhuang, Y. Yu, K. Wang, H. Sun, and C. Zhang. Toolqa: A dataset for llm question answering
with external tools. Advances in Neural Information Processing Systems, 36, 2024.
15

Supplementary Materials for MEDCALC-BENCH
A Dataset Curation - Additional Details
17
A.1
Extraction Process
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
A.2 Templates for Synthetic Notes
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
A.3
Clinician Synthesized Notes
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
A.4 Templates for Natural Language Explanation
. . . . . . . . . . . . . . . . . . . .
30
A.5
MEDCALC-BENCH Calculators Covered
. . . . . . . . . . . . . . . . . . . . . .
34
B
Dataset License and Usage
36
B.1
Dataset License . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
B.2
Dataset Instance Metadata
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
B.3
Reproducing Results
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
B.4
Author Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
C Training Dataset for Fine-Tuning on MEDCALC-BENCH
39
C.1
Training Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
C.2
Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
C.3
Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
D Code-Augmented LLMs Prompt Setting
43
D.1
Code-Augmented LLM Performance . . . . . . . . . . . . . . . . . . . . . . . . .
43
E Additional Analysis
44
E.1
Accuracy vs. Number of Attributes . . . . . . . . . . . . . . . . . . . . . . . . . .
44
16

A
Dataset Curation - Additional Details
A.1
Extraction Process
As mentioned in Section 2, the patient notes used for MEDCALC-BENCH come from three main
sources: (1) Publicly available patient notes from Open-Patients, (2) Notes synthesized from templates
(A.2), (3) Notes synthesized from templates.
The majority of instances of MEDCALC-BENCH comes from Open-Patients, a dataset of 180k
publicly available patient notes which are aggregated from four different sources as shown in the
table below:
Table 6: Publicly available patient notes which make up Open-Patients
Source
# Patients
Average Token Length
Note Type
TREC Clinical Decision Support
90
105.1
This track consists of datasets of
30 patient notes each for three sep-
arate years from 2014-2016. The
motivation of this track was to chal-
lenge participants to obtain rele-
vant articles that can help answer
potential questions for a particu-
lar patient note. The patient notes
2014 and 2015 are synthetic pa-
tient notes hand-written by indi-
viduals with medical training, but
the 2016 dataset consists of real pa-
tient summaries coming from elec-
tronic health records.
TREC Clinical Trials
125
137.7
This track consists of 125 patient
notes, where 50 notes are from
the year of 2021 and 75 notes are
from the year of 2022. This track
was meant to have participants re-
trieve previous clinical trials from
ClinicalTrials.gov that best match
the symptoms described in the pa-
tient note. The notes from both
tracks are synthetic notes written
by individuals with medical train-
ing meant to simulate an admission
statement from an electronic health
record (EHR).
MedQA-USMLE
12,893
135.8
Questions from a multiple-choice
form a professional medical board
exam which can include patient
summaries and will ask questions
about particular issues based on the
summary.
PMC-Patients
167,034
484
Patient summaries extracted from
case reports from PubMedCentral
17

This collection is released on HuggingFace under the CC-BY-SA 4.0 license:
https://
huggingface.co/datasets/ncbi/Open-Patients/tree/main.
Using the Open-Patients dataset, we curated notes for each calculator using this three-stage pipeline:
1. We used GPT-3.5-turbo to identify eligible patient notes for each calculator. We did this by
shortlisting the notes that had at least one relevant required for a given calculator.
2. With the shortlisted notes for each calculator, we then checked whether the note met the eligibility
criteria for using the calculator based on the requirements provided by MDCalc.
3. Lastly, using the clinically eligible notes for each calculator from the second step, we used GPT-4
to extract the remaining attributes. We kept the notes that had all of the numeric parameters needed
for each calculator and which also had enough categorical variables inferred such that 50% of the
numeric and categorical attributes were present for a given patient note.
The attribute extractions of these notes were then verified for by authors of this paper.
Extraction 1 Prompt:
For more details on step 1, we provided a set of 32 parameters which cover at least one attribute
needed for each of the 55 calculators. For each note in Open-Patients, we applied the prompt shown
below to determine which of the 32 parameters could be extracted from each note. From this, we
received a dictionary of the 32 parameter IDs and their extracted values for each note.
18

System Prompt
You are a helpful assistant for extracting the values of medical parameters from a patient note.
Here is the list of parameters to consider:
Parameter
ID
Parameter Name
Type
Values & Units
3
weight
numerical
kg, lbs
4
height
numerical
m, cm, in, ft
5
creatinine
numerical
mg/dL, µmol/L
13
Systolic Blood
Pressure
numerical
mm Hg
16
Albumin
numerical
g/dL, g/L
20
Heart Rate or Pulse
numerical
beats per minute
28
Total cholesterol
numerical
mg/dL, mmol/L
112
Cerebrovascular
disease history
categorical
True, False
133
Absence of cough or
coryza
categorical
True, False
60
Initial troponin
categorical
less than or equal to normal
limit, between the normal
limit or up to three times the
normal limit, greater than
three times normal limit
61
Aspartate
aminotransferase
numerical
U/L
66
Temperature
numerical
degrees fahrenheit, degrees
celsius
73
Sodium
numerical
mEq/L, mmol/L
91
Glucose
numerical
mg/dL, mmol/L
93
Blood Urea Nitrogen
(BUN)
numerical
mg/dL, mmol/L
102
respiratory rate
numerical
breaths per minute
106
White blood cell
count
numerical
count/µL, count/L,
count/mm³
6
History of
Congestive Heart
Failure
categorical
True, False
31
Bilirubin
numerical
mg/dL
63
Platelet count
numerical
count (per billion)/L, count
(per thousand)/µL
114
Partial pressure of
oxygen (PaO2)
numerical
mm Hg
108
FiO2
numerical
%
44
Previously
documented Deep
Vein Thrombosis
categorical
True, False
8
Stroke
categorical
True, False
9
Transient Ischemic
Attacks History
categorical
True, False
7
Hypertension history
categorical
True, False
105
Hematocrit
numerical
%
107
Glasgow Coma Score
numerical
nan
23
Hemoptysis
categorical
True, False
32
international
normalized ratio
numerical
ratio
215
Ideal Body Weight
numerical
(IBW)
kg
47
History of ischemic
heart disease
categorical
True, False
19

System Prompt (continued)
Please check the parameters one-by-one, and output a JSON dict in the following format:
Dict{Str(Parameter_ID): Str(value)}. This JSON should report the parameter id and a value
for the parameter in the patient note (if available) for all 32 parameters. If there are multiple
values for a given measurement or attribute, then please use the value recorded based on
when the patient note was written. You should not be using values that the patient had
post-treatment or values from a patient’s history in the past. For parameters whose ’Type’
is ’categorical’, the exact name provided in the ’Parameter Name’ column might not be
mentioned inside the patient note. For such categorical variables, you should do your best
to infer the value taken by the parameter. Additionally, for parameters whose "Type" is
categorical, please select from one of values separated by commas in the Values & Units
column. Examples: {"8": "True"}, {"164": "Uncomplicated"}. If there is no mention of a
categorical parameter by the exact name and it cannot easily be inferred, then the value of the
parameter should be "Not Mentioned" as the value, e.g. {"26": "Not Mentioned"} or {"90":
"Not Mentioned"}.
If the ’Type’ of the parameter is ’numerical’ and the parameter is mentioned, please extract
the exact values and units from the patient note and separate them by spaces. Examples: {’4’:
5 ’ft’ 4 ’in’}, {’3’: 41.2 kg}, {’13’: 67 mm Hg}, {’20’: 117 beats per minute}. For numerical
parameters whose label is a concentration (mass/volume), the mass units MUST be one of
the following: [mol, mmol, µmol, pmol, g, mg, µg, kg, mEq] and the units of volume MUST
be one of the following: [’L’, ’dL’, ’mL’, ’µL’, ’mm3’, ’cm3’, ’m3’]. Examples: {’16’: 15.5
g/L}, {’5’: 2.34 mg/dL}. The only exception to this rule is for platelet count and white blood
cell count whose mass unit is ’count’ and the volume unit can be one of [’L’, ’dL’, ’mL’, ’µL’,
’mm3’, ’cm3’, ’m3’]. Examples: {’106’: 15034 count/µL}, {’63’: 1750000 count/L]}. For all
other numeric parameters whose labels are not in the form of concentrations (mass/volume),
you MUST use one of the EXACT label names provided in the Values & Type column.
Examples: {’66’: 39 degrees celsius}. Numerical attributes which are not mentioned in the
patient note should have their value set to ’Not Mentioned.’ Please output a JSON dict in the
mentioned format, specifying the value for each parameter ID in the provided list.
20

User Prompt
Your task is to extract the 32 medical attributes and their values provided to you from the
following patient note:
A 23-year-old previously healthy male presented to the ED with complaints of a
headache that was gradual in onset and had been present for the prior 24 hours. He noted
some lightheadedness and dizziness while standing, which prompted him to present to the ED
for evaluation. He was febrile to 100.5 degrees Fahrenheit (F) and tachycardic to 110 beats
per minute (bpm). The remainder of his physical exam was grossly unremarkable with no
meningeal signs or focal neurologic deficits. He was provided antipyretics and intravenous
(IV) fluids with complete resolution of his symptoms and discharged home with a diagnosis
of viral syndrome. Two days later, he returned to the ED with complaints of continued
headache and fever. He recalled a dry, tickling throat which was brief and self-limited
in the prior two days. He was tachycardic, but afebrile on exam. With the exception
of his tachycardia, his physical exam was again unremarkable without an identifiable
infectious source. Laboratory evaluation demonstrated a bandemia of 8% (reference range
0) as well as mild transaminitis with alanine aminotransferase (ALT) 177 units per liter
(U/L) (reference range 17) and aspartate aminotransferase (AST) 171 U/L (reference
range 12˘201339). His rapid heterophile antibody test was positive. He was discharged
home with precautions to avoid contact sports and to have repeated liver function tests
performed by his primary care provider. Three days after his second ED visit, he returned
with jaundice, dark urine, and with continued fever and fatigue. He denied sore throat,
cough, chest pain, abdominal pain, vomiting, diarrhea, hematuria, dysuria, or rash. He was
again febrile with a temperature of 100.9˘00b0 F and a pulse rate of 109 bpm. There was
noticeable scleral icterus and diffuse jaundice. He was also noted to have multiple, palpable,
posterior cervical lymph nodes.Laboratory evaluation was notable for a leukocytosis of 14.8
˘00d7103 cells per microliter (mcL) (reference 4.0˘201310.5) with lymphocytic predominance
of 24% and thrombocytopenia of 99˘00d7103 cells/mcL (reference range 150˘2013450).
Comprehensive metabolic panel was notable for mild hyponatremia of 133 millimoles
(mmol) per L (reference range 136˘2013145 mmol/L), total bilirubin of 7.93 milligrams per
deciliter (mg/dL) (reference 0.15˘20131.00), direct bilirubin of 6.9 mg/dL (reference range
<0.2˘20130.3), alkaline phosphatase of 198 U/L (reference range 40˘2013129), ALT of 753
U/L (reference range 17˘201363), and AST 692 U/L (reference range 12˘201339). Coagulation
studies were within normal limits. Acetaminophen level was negative at <1.5 micrograms
per milliliter (reference range 10˘201330). Hepatitis serologies were notable for a reactive
hepatitis B virus core antibody, non-reactive hepatitis B core antibody IgM, positive hepatitis
B surface antibody, and negative hepatitis B surface antigen consistent with immunity due to
natural infection. Hepatitis C antibody was non-reactive. Human immunodeficiency virus
testing was negative. Blood cultures were also negative. EBV heterophile antibodies were
positive.A formal right upper quadrant ultrasound demonstrated a mildly enlarged liver with
normal contour. The gallbladder was visualized and noted to be contracted. The gallbladder
wall was noted to be mildly thickened with a measurement of 0.34 centimeters. There was
no evidence of cholelithiasis. The patient was admitted to the hospital for supportive care
and further laboratory evaluation. He was provided IV fluids, and liver function tests were
trended every six hours. Liver enzymes gradually decreased and his jaundice resolved. His
thrombocytopenia was thought to be related to acute hepatitis. Coagulation studies remained
within normal limits. He was discharged from the hospital with a diagnosis of cholestatic
hepatitis secondary to EBV. He followed up with internal medicine and had serial liver
function tests over the subsequent weeks."
Remember to use the appropriate units for numerical parameters and to use one of
the values mentioned in the Values & Units column for categorical parameters. There should
only be one extracted value for each parameter and never a list. For numerical parameters
which are not explicitly mentioned, please set the value as ’Not Mentioned’. For categorical
parameters whose value cannot be inferred, please set the value as ’Not Mentioned.’ You
should output all of the parameter IDs and their values inside a JSON dict.
21

Output
{
"3": "Not Mentioned",
"4": "Not Mentioned",
"5": "Not Mentioned",
"13": "110 mm Hg",
"16": "Not Mentioned",
"20": "110 beats per minute",
"28": "Not Mentioned",
"112": "Not Mentioned",
"133": "Not Mentioned",
"60": "Not Mentioned",
"61": "171 U/L",
"66": "100.5 degrees Fahrenheit",
"73": "133 mmol/L",
"91": "Not Mentioned",
"93": "Not Mentioned",
"102": "Not Mentioned",
"106": "14.8 x10^3 cells/mcL",
"6": "Not Mentioned",
"31": "0.34 centimeters",
"63": "99 x10^3 cells/mcL",
"114": "Not Mentioned",
"108": "Not Mentioned",
"44": "Not Mentioned",
"8": "Not Mentioned",
"9": "Not Mentioned",
"7": "Not Mentioned",
"105": "Not Mentioned",
"107": "Not Mentioned",
"23": "Not Mentioned",
"32": "Not Mentioned",
"215": "Not Mentioned",
"47": "Not Mentioned"
}
Step 2: Determine Clinical Eligibility
From step 1, we curated notes for each calculator that had at least one attribute needed for the
calculator. We then determined whether the patient was clinically eligible based on the criteria
provided by MDCalc.
Using GPT-3.5-turbo, we applied the following prompt to find the eligible notes for each calculator
based on the shortlisted set of notes for each calculator in step 1. Shown below is an example for
checking the eligibility for the CURB-65 calculator:
22

System Prompt
You are a helpful assistant that needs to determine if the patient meets the criteria for using
the calculator, Curb-65 Score, based on a patient note the user provides. The eligibility
criteria for using the following calculator is as follows:
You can have an explanation if you would like, but you must respond with ELIGIBILITY:
YOUR_RESPONSE_HERE at the end of your response, where YOUR_ANSWER_HERE
can either be Yes if the patient meets the criteria for using the calculator, or No if the patient
does not meet the eligibility criteria for the calculator. It’s ok if there are missing values for
the calculator that are needed to compute the score for the patient, your only focus is to just
check if the patient’s condition is eligible or not to even use the calculator. If you cannot tell
whether or not the patient’s condition meets the criteria, do your best to make an inference.
User Prompt
User Prompt:
Patient Note: A 70-year-old Caucasian male initially presented to the emergency department
(ED) of our hospital with fever and chills, which began one hour prior to his presentation.
He also reported nausea and a productive cough with greenish sputum. The patient had
been previously admitted to our hospital for pneumonia a month prior to his presentation
and was discharged to a rehabilitation facility for three weeks. His past medical history
was significant for end stage renal disease (ESRD) with dialysis dependence, failed kidney
transplant, coronary artery disease (CAD) status with four drug-eluting stents (DES), type
2 diabetes mellitus, chronic pneumonia, and hypertension. On admission, his vital signs
were as follow: temperature 39.4°C, blood pressure 87/55 mm Hg, pulse 100 beats per
minute (bpm), oxygen saturation 88% on room air and respiratory rate 18 breaths per
minute. Physical examination revealed coarse breath sounds bilaterally on auscultation,
a left upper arm arteriovenous fistula as well as multiple superficial abrasions bilaterally
on his lower extremities. His laboratory findings were as follows: white blood cells 15.12
K/µL, platelets 104 K/µL, sodium 134 mmol/L, blood urea nitrogen 39 mg/dl, creatinine
4.5 mg/dl, lactic acid 2.77 mmol/L and procalcitonin 25.24 ng/ml. Urine analysis was
not performed because the patient was anuric. His chest X-ray showed evidence of small
effusions and bibasilar airspace disease which were indicative of atelectasis or infection.
An electrocardiogram showed normal sinus rhythm, a rate of 99 bpm, normal axis and
no significant ST abnormalities, with paroxysmal ventricular contractions (PVCs). Blood
cultures were drawn, and the patient received ceftriaxone and piperacillin/tazobactam
empiric antibiotics and intravenous (IV) fluids. Gram stain of the blood specimen showed
gram-negative rods. He was initially admitted to the progressive care unit (PCU) with
cardiac telemetry. He was found to have second-degree atrioventricular (AV) block and was
subsequently transferred to the intensive care unit (ICU) for closer management. On the
second day of admission, blood cultures grew Pasteurella multocida. The organism was
sensitive to beta-lactams including ampicillin, amoxicillin, amoxicillin/clavulanic acid and
ampicillin/sulbactam. The patient was treated with IV cefepime due to his comorbidities.
At this time, the patient was further questioned about recent animal contact. He stated that
he lived with his wife and 14 cats and admitted the cats usually scratched him when they
laid on him. His subsequent hospital stay was unremarkable. He was discharged home
six days after admission with amoxicillin/clavulanic acid for two weeks. The patient re-
turned to the outpatient clinic two weeks after discharge and had made an uneventful recovery.
Does this patient meet the eligibility criteria for CURB-65 Score?
Simply check
based on whether the patient’s condition meets the criteria and DO NOT base your answer
based on whether the note mentions the required attributes needed for computing a score with
that calculator. You can have an explanation if you would like, but at the end, your response
MUST include either ELIGIBILITY: Yes or ELIGIBILITY: No somewhere inside your note.
23

Output
ELIGIBILITY: Yes
Based on the information provided in the patient note, the patient meets the eligibility
criteria for using the CURB-65 Score calculator. The calculator is used to risk stratify a
patient’s community-acquired pneumonia in the emergency department setting. Although
some specific values required for computation of the CURB-65 Score are missing in the
patient note, such as confusion, blood urea nitrogen level, respiratory rate, and age, the
information provided in the note indicates that the patient has pneumonia symptoms with a
productive cough, fever, and chills. Additionally, the patient has risk factors such as advanced
age, comorbid conditions including end-stage renal disease, diabetes, and coronary artery
disease, as well as abnormal vital signs including low blood pressure, tachycardia, and low
oxygen saturation.
It is important to note that the CURB-65 Score is used to assess the severity of pneumonia
and determine the need for hospitalization, but additional clinical judgment and evaluation
are necessary for appropriate management and treatment decisions.
24

Prompt for Step 3:
Lastly, after curating the eligible notes for each calculator, we then extracted the remaining parameters
needed for the calculator. We provide the following example of how the parameter extraction from a
patient note is done for the CURB-65 Score calculator:
System Prompt
You are a helpful assistant for extracting the values of medical parameters needed for CURB-
65 Score for Pneumonia Severity from a patient note. Here is a table of parameters to
consider:
Parameter ID
Parameter
Name
Type
Values & Units
Description
102
respiratory rate
numerical
breaths per minute
nan
13
Systolic Blood
Pressure
numerical
mm Hg
nan
14
Diastolic Blood
Pressure
numerical
mm Hg
nan
176
Confusion
categorical
True, False
nan
2
age
numerical
years, months, weeks,
days
nan
93
Blood Urea
Nitrogen (BUN)
numerical
mg/dL, mmol/L
nan
Please check the parameters one-by-one, and output a JSON dictionary in the following
format: Dict{Str(Parameter_ID): Str(value)}. This JSON should report the parameter id and
a value for the parameter in the patient note (if available) for all the parameters mentioned.
If there are multiple values for a given measurement or attribute, then please use the value
recorded based on when the patient note was written. You should not be using values that the
patient had post-treatment or values from a patient’s history in the past.
For parameters whose ’Type’ is ’categorical’, the exact name provided in the ’Parameter
Name’ column might not be mentioned inside the patient note. For such categorical variables,
you should do your best to infer the value taken by the parameter. If available, you should
use the information in the ’Description’ column to help you get more context about a variable
and it’s values which may help with inferring the value. Additionally, for parameters whose
"Type" is categorical, please select from one of values separated by commas in the Values &
Units column. Examples: {"8": "True"}, {"164": "Uncomplicated"}. If there is no mention
of a categorical parameter by the exact name and it cannot easily be inferred, then the value
of the parameter should be "Not Mentioned" as the value, e.g. {"26": "Not Mentioned"} or
{"90": "Not Mentioned"}. Numerical parameters should never be inferred if explicitly not
given and should be taken to be "Not Mentioned," if the parameter is not mentioned in the
patient note.
If the ’Type’ of the parameter is ’numerical’ and the parameter is mentioned, please extract
the exact values and units from the patient note and separate them by spaces. Examples: {’4’:
5 ’ft’ 4 ’in’}, {’3’: 41.2 kg}, {’13’: 67 mm Hg}, {’20’: 117 beats per minute}. For numerical
parameters whose label is a concentration (mass/volume), the mass units MUST be one of
the following: [mol, mmol, µmol, pmol, g, mg, µg, kg, mEq] and the units of volume MUST
be one of the following: [’L’, ’dL’, ’mL’, ’µL’, ’mm3’, ’cm3’, ’m3’]. Examples: {’16’: 15.5
g/L}, {’5’: 2.34 mg/dL}. The only exception to this rule is for platelet count and white blood
cell count whose mass unit is ’count’ and the volume unit can be one of [’L’, ’dL’, ’mL’, ’µL’,
’mm3’, ’cm3’, ’m3’]. Examples: {’106’: 15034 count/µL}, {’63’: 1750000 count/L]}. For all
other numeric parameters whose labels are not in the form of concentrations (mass/volume),
you MUST use one of the EXACT label names provided in the Values & Type column.
Examples: {’66’: 39 degrees celsius}. Please output a JSON dict in the mentioned format,
specifying the value for each parameter ID in the provided table.
25

User Prompt
Your task is to extract the parameters used for that calculator from the following patient note:
A 70-year-old Caucasian male initially presented to the emergency department (ED)
of our hospital with fever and chills, which began one hour prior to his presentation. He
also reported nausea and a productive cough with greenish sputum. The patient had been
previously admitted to our hospital for pneumonia a month prior to his presentation and
was discharged to a rehabilitation facility for three weeks. His past medical history was
significant for end stage renal disease (ESRD) with dialysis dependence, failed kidney
transplant, coronary artery disease (CAD) status with four drug-eluting stents (DES), type
2 diabetes mellitus, chronic pneumonia, and hypertension. On admission, his vital signs
were as follow: temperature 39.4°C, blood pressure 87/55 mm Hg, pulse 100 beats per
minute (bpm), oxygen saturation 88% on room air and respiratory rate 18 breaths per
minute. Physical examination revealed coarse breath sounds bilaterally on auscultation,
a left upper arm arteriovenous fistula as well as multiple superficial abrasions bilaterally
on his lower extremities. His laboratory findings were as follows: white blood cells 15.12
K/µL, platelets 104 K/µL, sodium 134 mmol/L, blood urea nitrogen 39 mg/dl, creatinine
4.5 mg/dl, lactic acid 2.77 mmol/L and procalcitonin 25.24 ng/ml. Urine analysis was
not performed because the patient was anuric. His chest X-ray showed evidence of small
effusions and bibasilar airspace disease which were indicative of atelectasis or infection.
An electrocardiogram showed normal sinus rhythm, a rate of 99 bpm, normal axis and
no significant ST abnormalities, with paroxysmal ventricular contractions (PVCs). Blood
cultures were drawn, and the patient received ceftriaxone and piperacillin/tazobactam
empiric antibiotics and intravenous (IV) fluids. Gram stain of the blood specimen showed
gram-negative rods. He was initially admitted to the progressive care unit (PCU) with
cardiac telemetry. He was found to have second-degree atrioventricular (AV) block and was
subsequently transferred to the intensive care unit (ICU) for closer management. On the
second day of admission, blood cultures grew Pasteurella multocida. The organism was
sensitive to beta-lactams including ampicillin, amoxicillin, amoxicillin/clavulanic acid and
ampicillin/sulbactam. The patient was treated with IV cefepime due to his comorbidities.
At this time, the patient was further questioned about recent animal contact. He stated that
he lived with his wife and 14 cats and admitted the cats usually scratched him when they
laid on him. His subsequent hospital stay was unremarkable. He was discharged home
six days after admission with amoxicillin/clavulanic acid for two weeks. The patient re-
turned to the outpatient clinic two weeks after discharge and had made an uneventful recovery.
Remember to use the appropriate units for numerical parameters and to use one of
the values mentioned in the Values & Units column for categorical parameters. For numerical
parameters which are not explicitly mentioned, please set the value as ’Not Mentioned’. For
categorical parameters which are not explicitly mentioned in the patient note, do your best to
infer the value. You should output all of the parameter IDs and their values inside a JSON
dict.
Output
{
"2": "70 years",
"13": "87 mm Hg",
"14": "55 mm Hg",
"93": "39 mg/dL",
"102": "18 breaths per minute",
"176": "Not Mentioned"
}
At the end of this step, we parsed the parameter extractions for each note to ensure that all numeric
attributes had an integer or decimal value and categorical variables were either “Not Mentioned,”
or exactly matched one of the options provided in the Values & Units column. After manually
26

verifying the parameter extractions, we then had 1047 instances which covered 34 calculators of our
dataset. We capped a maximum of 20 notes for each calculator and so some calculators had less than
20 notes. The remaining 21 calculators had their notes and extracted parameters either produced
using template-based functions implemented in Python or the notes and the needed parameters were
handwritten by clinicians.
A.2
Templates for Synthetic Notes
For the following 11 calculators, we did not acquire any patient notes from Open-Patients. Instead,
we used a template implemented in Python to create a patient note with the necessary values needed
for each of the calculators:
1. QTc Calculators - {Bazett, Framingham, Rautaharju, Hodges, Fredericia}
2. Target Body Weight
3. MME Conversion
4. Steroid Conversion
5. Estimated Due Date
6. Estimated Gestational Age
7. Estimated Date of Conception
For each of the notes, we take random, but clinically plausible values for the required attributes
needed for a particular calculator using the random library from Python. Shown below is an example
of how we generate a note using a template for the MME Conversion calculator:
def mme_conversion():
mme_drugs = ["Codeine", "FentaNYL␣buccal", "FentANYL␣patch", "
HYDROcodone", "HYDROmorphone", "Methadone", "Morphine", "OxyCODONE", "
OxyMORphone", "Tapentadol", "TraMADol"]
drugs = random.sample(mme_drugs, 3)
note = "The␣patient␣takes␣"
input_parameters = {}
for i in range(3):
num_doses = random.randint(1, 3)
num_amount = round(random.randint(1, 7)) * 10
key_name_dose = drugs[i] + "␣Dose"
key_name_dose_per_day = drugs[i] + "␣Dose␣Per␣Day"
if drugs[i] == "FentaNYL␣buccal" or drugs[i] == "FentaNYL␣patch":
input_parameters[key_name_dose] = [num_amount , "$\mu$g"]
else:
input_parameters[key_name_dose] = [num_amount , "mg"]
input_parameters[key_name_dose_per_day] = [num_doses, "per␣day"]
add_s = ’s’
if num_doses == 1:
add_s = ’’
27

if i == len(drugs) - 1:
note += f"and␣{num_amount}␣mg␣of␣{drugs[i]}␣{num_doses}␣time{
add_s}␣a␣day."
else:
note += f"{num_amount}␣mg␣of␣{drugs[i]}␣{num_doses}␣time{add_s}
␣a␣day,␣"
return note, input_parameters
Hence, making calls to mme_conversion() would generate patient notes which all follow the same
structure, but with different drugs and dosage amounts. Here are three such instances generated by
the mme_conversion() function:
1. The patient takes 70 mg of OxyMORphone 3 times a day, 60 mg of Codeine 2 times a day, and 30
mg of FentaNYL buccal 1 time a day.
2. The patient takes 30 mg of TraMADol 2 times a day, 40 mg of OxyMORphone 1 time a day, and
50 mg of OxyCODONE 1 time a day.
3. The patient takes 60 mg of HYDROmorphone 1 time a day, 50 mg of Codeine 2 times a day, and
30 mg of Methadone 1 time a day.
We used a similar approach for the other 10 calculators for which we needed a synthesized template.
These templates can be found in synthesize_patient_note.py file of the Github repository.
A.3
Clinician Synthesized Notes
For the following 10 rule-based calculators, there were no notes curated from PMC-Patients and
so we had notes synthesized from clinicians based on a set of pre-annotated values: Revised Score
for Cardiac Risk index, HAS-BLED Score, Charlson Comorbidity Index, PSI Score, Child-Pugh
Score for Cirrhosis Mortality, Glasgow Coma Score, APACHE II, SODA, Caprini Score for Venous
Thromboembolism.
For synthesizing the notes, the following instructions were provided:
28

Synthetic Patient Note Instructions
• Calculator Information: For each calculator, we provide a link from MDCalc.com
which computes the medical value associated with a calculator, given the necessary
inputs. You can use this link to get more information about the calculator, the details
of the attributes and the values needed for a calculator, and any details about how a
computation is performed.
• How to synthesize a patient note: Once you familiarize yourself with the calculator,
please take a look at the Excel sheet provided for a given calculator. Here is the
information about each of the columns:
– The first column (“Variable Name”) lists all of the attribute names needed for a
given calculator.
– The second column (“Values & Units”) will correspond to the possible values
or units that the attribute can take on. For attributes that are categorical and do
not take an integer or decimal value, you MUST use one of the values provided
specified in the “Values & Units” column for that given attribute (i.e. for the
attribute “Hepatic Disease History” if the “Values & Units” column lists “True,
False” as the possible attributes, then you must use one of these). If an attribute
is numerical, then you MUST use an integer (i.e. 43 years for the attribute
“age”) or a decimal value (i.e. 3.32 mg/dL for the attribute “Creatinine”).
– The third column (“Pre-Annotated Value”) will correspond to the assigned
value for a given attribute for a specific patient note. These are the values that
are initially assigned for each item, but you can change them if they are not at
all humanly plausible. In this case, you should adhere to the rules mentioned
in the second bullet point for assigning an appropriate value and units. As
mentioned, you can skip some descriptive (non-numeric) attributes and in this
case, the value should be “Not Mentioned.”
– For some calculators, there will be a fourth column (“Description”) that will
provide more context about the attribute. It may also specify the criteria that
need to be met if someone assigns a particular value for a given attribute.
In all, you need to synthesize a patient note based on the attributes provided in the first column
and assign these attributes to the values provided in the third column.
To make the patient note as authentic as possible, for attributes that take on categorical values,
try to avoid using the same exact name of the value in your note.
For example, from the calculator, Charlson Comorbidity Index (CCI), one of the attributes
checks for the presence of liver disease with the following values: (None, Mild, Moderate to
Severe). Instead of saying “The patient’s liver disease severity is classified as ‘mild,’” write
something like “The patient presents with symptoms suggestive of chronic hepatitis, including
persistent fatigue, abdominal discomfort, and elevated liver enzymes, warranting further
evaluation for viral hepatitis markers and liver function tests.” By not directly specifying the
value associated with liver disease, the patient note reads more authentically and we can use
this to benchmark an LLM’s ability to properly determine the severity of the patient’s liver
disease when provided with the categories.
Similarly, for the attribute “Moderate to Severe CKD” in the CCI calculator, instead of writing,
“the patient did not pass the screening for chronic kidney disease,” write something like “the
patient’s serum creatinine is 1.23 mg/dL.” This is equally indicative that the “Moderate to
Severe CKD” attribute in the CCI calculator should be false. For numerical attributes, you
can directly specify the value, but you should try to vary the units associated with the value.
This is not to say that you can never directly specify an attribute with a value provided from
the third column, but you should vary your methods of conveying the values for an attribute
so that we can measure how good an LLM is at deducing the value for a given attribute.
29

Synthetic Patient Note Instructions (continued)
For attributes whose values are categorical, it’s fine if you do not mention every attribute
needed for a calculator. All numerical attributes and gender need to be mentioned (i.e. age,
creatinine concentration, etc.). However, you must have up to 50% of the attributes in total
in your note and you should change attributes you are omitting for each of the 5 patient
notes. In this case, for non-numeric attribute values that you do change, please update the
third column value to be “Not Mentioned.” You should also add other medical values (both
descriptive and numeric) that are not relevant to the calculator so that we can determine if an
LLM can sift through the noise and extract the correct values.
Example for Wells’ Criteria for PE:
Variable Name
Values & Units
Pre-Annotated Value
Clinical signs and symptoms of DVT
True, False
False
PE is #1 diagnosis OR equally likely
True, False
True
Heart rate > 100
beats per minute
120
Immobilization at least 3 days
True, False
True
Surgery in the previous 4 weeks
True, False
False
Previous, objectively diagnosed PE
True, False
False
Previous, objectively diagnosed DVT
True, False
False
Hemoptysis
True, False
True
Malignancy w/ treatment within 6 months
True, False
False
Patient Note:
A 52-year-old female presents with swelling and discomfort in her left calf for the past two
days. She mentions a recent period of reduced activity due to being bedridden for three days
after sustaining a minor injury. The patient reports experiencing shortness of breath and chest
discomfort, which she attributes to a recent respiratory issue. She recalls a recent episode
of mild coughing with a small amount of blood-tinged sputum two days ago. She denies
any recent surgical procedures or major illnesses, apart from a health issue she had dealt
with a few years back. On examination, there is tenderness and warmth noted over the left
calf. Her heart rate is elevated at 120 beats per minute, blood pressure is 140/90 mmHg, and
respiratory rate is 18 breaths per minute. She is afebrile with a temperature of 98.6°F. Given
the combination of recent sickness, respiratory symptoms, and mild hemoptysis, further
evaluation with imaging studies is planned to rule out any significant pathology. The patient’s
laboratory tests including complete blood count, electrolyte panel, and renal function tests
are within normal limits.
Based on these instructions, clinicians synthesized 20 notes for each of the 10 rule-based calculators.
They also provided the extracted parameter values in the same dictionary format that was used for
obtaining the ground truth parameter values from Open-Patients.
A.4
Templates for Natural Language Explanation
A core component of MEDCALC-BENCH is the natural language explanations for showing how the
final answer is obtained. For each of the 55 calculators, we implement a function that takes in the
input parameters needed for the calculator and outputs a step-by-step natural language explanation of
how the final answer is obtained.
It should be noted that the parameter extractions from Section A.1 needed to go through an additional
parsing step before they could be passed into template-based explanation functions. Firstly, we
mapped each extracted parameter ID to the input variable name that would be used in Python.
Additionally, for numerical attributes such as creatinine concentration, age, weight, etc., we extracted
the integer/decimal along with the label from the string. For categorical variables whose string value
was either "True" or "False," we converted these strings to boolean literals. Lastly, for categorical
variables that required a specific value based on the MDCalc list, we ensured the value given by
GPT-4 matched one of the values provided by MDCalc.
30

Shown below is an example of this processing done for the input parameters for a patient note using
the Glasgow-Blatchford Bleeding Score:
Extracted Parameters:
{
"96": "False",
"93": "34 mg/dL",
"95": "False",
"20": "80 beats per minute",
"92": "13 g/dL",
"1": "Female",
"13": "90 mm Hg",
"97": true,
"94": true
}
From this, we transform the extracted attribute names to their names as Python variables for the
template-based explanation function. We also convert the values into a format that can be used for
the template-based explanation functions:
Python Input Parameters:
{
"hepatic_disease_history": false,
"bun": [
34.0,
"mg/dL"
],
"syncope": false,
"heart_rate": [
80.0,
"beats per minute"
],
"hemoglobin": [
13.0,
"g/dL"
],
"sex": "Female",
"sys_bp": [
90.0,
"mm Hg"
],
"cardiac_failure": true,
"melena_present": true
}
It should be noted that not all categorical variables may be reported in the present in a patient note.
Hence, if the value of the variable cannot be inferred, we state that it is not mentioned inside the
template, and then report that we assume it to be false.
Based on this structure for generating the inputs to the explanation-based functions, we have imple-
mented a template for providing a step-by-step explanation for all 55 calculators. Here is an example
for how Glasgow-Blatchford Bleeding Score (GBS) explanation template was implemented:
def glasgow_bleeding_score_explanation(input_parameters):
score = 0
31

hemoglobin_exp, hemoglobin = unit_converter_new.conversion_explanation(
input_parameters["hemoglobin"][0], "hemoglobin", 64500, None, input_parameters[
"hemoglobin"][1], "g/dL")
bun_exp, bun = unit_converter_new.conversion_explanation(input_parameters["bun"
][0], "BUN", 28.08, None, input_parameters["bun"][1], "mg/dL")
gender = input_parameters["sex"]
systiolic_bp = input_parameters["sys_bp"][0]
heart_rate = input_parameters["heart_rate"][0]
explanation = f"The␣current␣glasgow␣bleeding␣score␣is␣0.␣The␣patient’s␣gender␣is
␣{gender}.\n"
explanation += hemoglobin_exp
if gender == "Male":
if 12 < hemoglobin <= 13:
explanation += f"Because␣the␣patient␣is␣a␣male␣and␣the␣hemoglobin␣
concentration␣is␣between␣12␣and␣13␣g/dL,␣we␣add␣one␣point,␣making␣the␣current␣
score␣{score}␣+␣1␣=␣{score␣+␣1}.\n"
score += 1
elif 10 <= hemoglobin < 12:
explanation += f"Because␣the␣patient␣is␣a␣male␣and␣the␣hemoglobin␣
concentration␣is␣between␣10␣and␣12␣g/dL,␣we␣add␣three␣points,␣making␣the␣
current␣score␣{score}␣+␣3␣=␣{score␣+␣3}.\n"
score += 3
elif hemoglobin < 10:
explanation += f"Because␣the␣patient␣is␣a␣male␣and␣the␣hemoglobin␣
concentration␣is␣less␣than␣10␣and␣12␣g/dL,␣we␣add␣six␣points,␣making␣the␣
current␣score␣{score}␣+␣6␣=␣{score␣+␣6}.\n"
score += 6
elif hemoglobin > 13:
explanation += f"Because␣the␣patient␣is␣a␣male␣and␣the␣hemoglobin␣
concentration␣is␣greater␣than␣13␣g/dL,␣we␣do␣not␣add␣any␣points,␣keeping␣the␣
current␣score␣at␣{score}.\n"
else:
if 10 < hemoglobin <= 12:
explanation += f"Because␣the␣patient␣is␣a␣female␣and␣the␣hemoglobin␣
concentration␣is␣between␣10␣and␣12␣mg/dL,␣we␣add␣one␣point,␣making␣the␣current␣
score␣{score}␣+␣1␣=␣{score␣+␣1}.\n"
score += 1
elif hemoglobin < 10:
explanation += f"Because␣the␣patient␣is␣a␣female␣and␣the␣hemoglobin␣
concentration␣is␣less␣than␣10␣mg/dL,␣we␣add␣three␣points,␣making␣the␣current␣
score␣{score}␣+␣3␣=␣{score␣+␣3}.\n"
score += 6
elif hemoglobin > 12:
explanation += f"Because␣the␣patient␣is␣a␣female␣and␣the␣hemoglobin␣
concentration␣is␣greater␣than␣12␣mg/dL,␣we␣do␣not␣add␣any␣points,␣keeping␣the␣
current␣score␣at␣{score}.\n"
explanation += bun_exp
if 18.2 <= bun < 22.4:
explanation += f"The␣BUN␣concentration␣is␣between␣18.2␣and␣22.4␣mg/dL,␣and␣
so␣we␣add␣two␣points,␣making␣the␣current␣score␣{score}␣+␣2␣=␣{score␣+␣2}.\n"
score += 2
elif 22.4 <= bun < 28:
explanation += f"The␣BUN␣concentration␣is␣between␣22.4␣and␣28␣mg/dL,␣and␣so␣
we␣add␣three␣points,␣making␣the␣current␣score␣{score}␣+␣3␣=␣{score␣+␣3}.\n"
score += 3
elif 28 <= bun < 70:
explanation += f"The␣BUN␣concentration␣is␣between␣28␣and␣70␣mg/dL,␣and␣so␣we
␣add␣four␣points,␣making␣the␣current␣score␣{score}␣+␣4␣=␣{score␣+␣4}.\n"
score += 4
32

elif bun > 70:
explanation += f"The␣BUN␣concentration␣is␣greater␣than␣70␣mg/dL,␣and␣so␣we␣
add␣six␣points,␣making␣the␣current␣score␣{score}␣+␣6␣=␣{score␣+␣6}.\n"
score += 6
elif bun < 18.2:
explanation += f"The␣BUN␣concentration␣is␣less␣than␣18.2␣mg/dL,␣and␣so␣we␣do
␣not␣make␣any␣changes␣to␣the␣score,␣keeping␣the␣score␣at␣{score}.\n"
explanation += f"The␣patient’s␣blood␣pressure␣is␣{systiolic_bp}␣mm␣Hg.␣"
if 100 <= systiolic_bp < 110:
explanation += f"Because␣the␣patient’s␣systolic␣blood␣pressure␣is␣between␣
100␣and␣110␣mm␣Hg,␣we␣increase␣the␣score␣by␣one␣point,␣making␣the␣current␣score
␣{score}␣+␣1␣=␣{score␣+␣1}.\n"
score += 1
elif 90 <= systiolic_bp < 100:
explanation += f"Because␣the␣patient’s␣systolic␣blood␣pressure␣is␣between␣90
␣and␣100␣mm␣Hg,␣we␣increase␣the␣score␣by␣two␣points,␣making␣the␣current␣score␣{
score}␣+␣2␣=␣{score␣+␣2}.\n"
score += 2
elif systiolic_bp < 90:
explanation += f"Because␣the␣patient’s␣systolic␣blood␣pressure␣is␣less␣than␣
90␣mm␣Hg,␣we␣increase␣the␣score␣by␣three␣points,␣making␣the␣current␣score␣{
score}␣+␣3␣=␣{score␣+␣3}.\n"
score += 3
elif systiolic_bp >= 110:
explanation += f"Because␣the␣patient’s␣systolic␣blood␣pressure␣is␣greater␣
than␣or␣equal␣to␣110␣mm␣Hg,␣we␣do␣not␣add␣points␣to␣the␣score,␣keeping␣the␣
current␣score␣at␣{score}␣+␣3␣=␣{score␣+␣3}.\n"
explanation += f"The␣patient’s␣heart␣rate␣is␣{heart_rate}␣beats␣per␣minute.␣"
if heart_rate >= 100:
explanation += f"Because␣the␣heart␣rate␣is␣greater␣or␣equal␣to␣than␣100␣
beats␣per␣minute,␣we␣increase␣the␣score␣by␣one␣point,␣making␣the␣current␣score␣{
score}␣+␣1␣=␣{score␣+␣1}.\n"
score += 1
else:
explanation += f"Because␣the␣heart␣rate␣is␣less␣than␣100␣beats␣per␣minute,␣
we␣do␣not␣change␣the␣score,␣keeping␣the␣current␣score␣at␣{score}.\n"
default_parameters = {"melena_present": "melena", "syncope": "recent␣syncope", "
hepatic_disease_history": "hepatic␣disease␣history", "cardiac_failure": "
cardiac␣failure"}
for parameter in default_parameters:
if parameter not in input_parameters:
explanation += f"The␣patient’s␣status␣for␣{default_parameters[parameter
]}␣is␣missing␣from␣the␣patient␣note␣and␣so␣we␣assume␣it␣is␣absent␣from␣the␣
patient.\n"
input_parameters[parameter] = False
explanation += f"Hence,␣we␣do␣not␣add␣any␣points␣to␣the␣score,␣keeping␣
it␣at␣{score}.\n"
elif parameter in [’syncope’, ’hepatic_disease_history’, ’cardiac_failure’]
and input_parameters[parameter]:
explanation +=
f"The␣patient␣has␣a␣{default_parameters[parameter]},␣and
␣so␣we␣add␣two␣points␣to␣the␣current␣total,␣making␣the␣current␣total␣{score}␣+␣
2␣=␣␣{score␣+␣2}.\n"
score += 2
elif input_parameters[parameter]:
33

explanation +=
f"The␣patient␣has␣{default_parameters[parameter]}␣and␣so
␣we␣add␣one␣point␣to␣the␣current␣total,␣making␣the␣current␣total␣{score}␣+␣1␣=␣
␣{score␣+␣1}.\n"
score += 1
else:
explanation +=
f"The␣patient’s␣status␣for␣{default_parameters[parameter
]}␣is␣reported␣to␣be␣absent␣for␣the␣patient,␣and␣so␣we␣do␣not␣add␣any␣points,␣
keeping␣the␣current␣total␣at␣{score}.\n"
explanation += f"The␣patient’s␣Glasgow␣Bleeding␣Score␣is␣{score}.\n"
return {"Explanation": explanation, "Answer": score, "Calculator␣Answer":
glasgow_bleeding_score(input_parameters)}
After applying the GBS explanation functionglasgow_bleeding_score_explanation, onto the
python input parameters provided in Section A.4, we get the following output explanation:
The current Glasgow bleeding score is 0.
The patient’s gender is Female.
The concentration of hemoglobin is 13.0 g/dL. Because the patient is a
female and the hemoglobin concentration is greater than 12 mg/dL, we do
not add any points, keeping the current score at 0.
The concentration of
BUN is 34.0 mg/dL. The BUN concentration is between 28 and 70 mg/dL, and so
we add four points, making the current score 0 + 4 = 4.The patient’s blood
pressure is 90.0 mm Hg.
Because the patient’s systolic blood pressure is
between 90 and 100 mm Hg, we increase the score by two points, making the
current score 4 + 2 = 6.The patient’s heart rate is 80.0 beats per minute.
Because the heart rate is less than 100 beats per minute, we do not change
the score, keeping the current score at 6.The patient has melena and so
we add one point to the current total, making the current total 6 + 1 =
7.
The patient’s status for recent syncope is reported to be absent for
the patient, and so we do not add any points, keeping the current total at
7.The patient’s status for hepatic disease history is reported to be absent
for the patient, and so we do not add any points, keeping the current total
at 7.The patient has a cardiac failure, and so we add two points to the
current total, making the current total 7 + 2 = 9.
The patient’s Glasgow
Bleeding Score is 9.
A.5
MEDCALC-BENCH Calculators Covered
MEDCALC-BENCH involves 55 different calculators. Shown below is a table providing more
information about each calculator:
Table 9: Information for each calculator in MEDCALC-BENCH test set
Calculator Name
Type
Sub-Type
Number of
Attributes
Number of
Notes
Creatinine Clearance (Cockcroft-
Gault Equation)
Equation-Based
Lab Test
5
20
CKD-EPI Equations for Glomeru-
lar Filtration Rate
Equation-Based
Lab Test
3
20
CHA2DS2-VASc Score for Atrial
Fibrillation Stroke Risk
Rule-Based
Risk
10
20
Mean Arterial Pressure (MAP)
Equation-Based
Physical
3
20
Body Mass Index (BMI)
Equation-Based
Physical
3
20
Calcium Correction for Hypoalbu-
minemia
Equation-Based
Lab Test
2
20
Continued on next page
34

Table 9: Information for each calculator in MEDCALC-BENCH test dataset
(continued)
Calculator Name
Type
Sub-Type
Number of
Attributes
Number of
Notes
Wells’ Criteria for Pulmonary Em-
bolism
Rule-Based
Risk
9
20
MDRD GFR Equation
Equation-Based
Lab Test
4
20
Ideal Body Weight
Equation-Based
Physical
2
20
QTc Bazett Calculator
Equation-Based
Physical
2
20
Child-Pugh Score for Cirrhosis
Mortality
Rule-Based
Severity
5
20
Wells’ Criteria for DVT
Rule-Based
Risk
11
20
Revised Cardiac Risk Index for
Pre-Operative Risk
Rule-Based
Risk
6
20
HEART Score for Major Cardiac
Events
Rule-Based
Risk
13
20
Fibrosis-4 (FIB-4) Index for Liver
Fibrosis
Equation-Based
Lab Test
4
20
Centor Score (Modified/McIsaac)
for Strep Pharyngitis
Rule-Based
Severity
5
20
Maintenance Fluids Calculations
Equation-Based
Physical
1
20
MELD Na (UNOS/OPTN)
Equation-Based
Lab Test
6
5
HAS-BLED
Score
for
Major
Bleeding Risk
Rule-Based
Risk
10
20
Sodium Correction for Hyper-
glycemia
Equation-Based
Lab Test
2
20
Glasgow-Blatchford
Bleeding
Score (GBS)
Rule-Based
Risk
9
20
Serum Osmolality
Equation-Based
Lab Test
3
20
HOMA-IR (Homeostatic Model
Assessment for Insulin Resistance)
Equation-Based
Lab Test
2
2
Charlson Comorbidity Index (CCI)
Rule-Based
Risk
18
20
FeverPAIN Score for Strep Pharyn-
gitis
Rule-Based
Diagnosis
5
20
Free Water Deficit
Equation-Based
Lab Test
4
20
Anion Gap
Equation-Based
Lab Test
3
20
Fractional Excretion of Sodium
(FENa)
Equation-Based
Lab Test
4
5
LDL Calculated
Equation-Based
Lab Test
3
20
CURB-65 Score for Pneumonia
Severity
Rule-Based
Risk
6
20
Framingham Risk Score for Hard
Coronary Heart Disease
Equation-Based
Lab Test
7
16
PERC Rule for Pulmonary Em-
bolism
Rule-Based
Diagnosis
9
20
SIRS Criteria
Rule-Based
Diagnosis
5
20
QTc Fridericia Calculator
Equation-Based
Physical
2
20
QTc Framingham Calculator
Equation-Based
Physical
2
20
QTc Hodges Calculator
Equation-Based
Physical
2
20
QTc Rautaharju Calculator
Equation-Based
Physical
2
20
Body Surface Area Calculator
Equation-Based
Physical
2
20
Adjusted Body Weight
Equation-Based
Physical
3
20
Delta Gap
Equation-Based
Lab Test
3
20
Delta Ratio
Equation-Based
Lab Test
3
20
Albumin Corrected Anion Gap
Equation-Based
Lab Test
4
20
Albumin Corrected Delta Gap
Equation-Based
Lab Test
4
20
Continued on next page
35

Table 9: Information for each calculator in MEDCALC-BENCH test dataset
(continued)
Calculator Name
Type
Sub-Type
Number of
Attributes
Number of
Notes
Albumin Corrected Delta Ratio
Equation-Based
Lab Test
4
20
PSI Score: Pneumonia Severity In-
dex for CAP
Rule-Based
Severity
20
20
Glasgow Coma Score (GCS)
Rule-Based
Severity
3
20
APACHE II Score
Rule-Based
Risk
20
20
Sequential Organ Failure Assess-
ment (SOFA) Score
Rule-Based
Risk
16
20
Caprini Score for Venous Throm-
boembolism (2005)
Rule-Based
Risk
31
20
Estimated Due Date
Equation-Based
Date
1
20
Steroid Conversion Calculator
Equation-Based
Dosage
11
20
Target weight
Equation-Based
Physical
2
20
Morphine Milligram Equivalents
(MME) Calculator
Equation-Based
Dosage
14
20
Estimated Date of Conception
Equation-Based
Date
1
20
Estimated Gestational Age
Equation-Based
Date
2
20
In addition to the 1,047 instances for MEDCALC-BENCH, we also curated a training dataset of 10,053
to fine-tune open-source LLMs. We followed the exact same procedure as the one we used for the
testing dataset, except authors of this paper did not manually verify the parameter extractions from
GPT-4. In spite of this, we still gained a significant increase in performance for the two open-source
LLMs that we fine-tuned on using this dataset. More details on the training dataset can be found in
Section C.
B
Dataset License and Usage
B.1
Dataset License
As mentioned in Section A.1, the notes come from Open-Patients, templates, or are handwritten by
clinicians. The notes coming from the latter two are our property, but the notes from Open-Patients
were created using existing datasets (TREC, MedQA, and PMC-Patients). We have verified that we
can use these datasets for making MEDCALC-BENCH.
Specifically, although there is no issued license for the TREC datasets, the clinical trials and clinical
decision support datasets from TREC are government-released datasets that were released for public
use and distribution. The MedQA data is released by the MIT License. Hence, we can use instances
from this dataset for MEDCALC-BENCH. Lastly, the PMC-Patients dataset is released by the CC-
BY-SA 4.0 license. This gives us permission to re-distribute the dataset for MEDCALC-BENCH as
long as it is not for commercial use. Additionally, because the PMC-Patients dataset is released by
CC-BY-SA 4.0 license, we had to release Open-Patients, and consequently MEDCALC-BENCH, by
the same license. Hence, both the training and testing instances of the MEDCALC-BENCH dataset
are released by the CC-BY-SA 4.0 license and can be distributed for any non-commercial purposes.
The
dataset
and
all
the
code
for
reproducing
our
results
can
be
found
at:
https://github.com/ncbi-nlp/MedCalc-Bench.
Additionally, we provide access to the
training and test sets for MEDCALC-BENCH in a Croissant format using HuggingFace dataset as
well: https://huggingface.co/datasets/ncbi/MedCalc-Bench.
36

B.2
Dataset Instance Metadata
For the MEDCALC-BENCH dataset uploaded on HuggingFace, each instance in both the training and
testing dataset of MEDCALC-BENCH is a row that contains the following information:
• Row Number - Specifies the index of the instance.
• Calculator ID - Specifies the integer ID of the calculator.
• Calculator Name - Specifies the name of the clinical calculation task.
• Category - Specifies the sub-category of the calculator. For equation-based calculators, the
options are lab test, dosage, date, or physical and for rule-based calculators, the options are
risk, severity, and diagnosis.
• Output Type - Specifies the format type that the calculator will return. The options are
decimal, integer, date (MM/DD/YY), or time in terms of weeks and days (i.e. (17 weeks, 4
days)).
• Note ID - Specifies the ID of the patient note. The ID of the note will either be the ID
given by Open-Patients or it will be an integer value if the patient note was handwritten by
clinicians or synthesized by a template.
• Patient Note - Specifies the patient note which provides the information needed to compute
the final answer.
• Question - Specifies the question that is asked to the model to compute a specific medical
value based on a particular calculator.
• Relevant Entities - Provides a dictionary of the parameters and their extracted values based
on the patient note.
• Ground Truth Answer - Specifies the ground truth value without any units for the medical
value that needs to be calculated.
• Lower Limit - For equation-based calculators whose output is a decimal, this value is 95%
of the ground truth answer value. For all other cases, the lower limit is the same as the
ground-truth value.
• Upper Limit - For equation-based calculators whose output is a decimal, this is value is
105% of the ground truth answer value. For all other cases, the upper limit is the same as
the ground-truth value.
• Ground Truth Explanation - A paragraph for the data instance providing a step-by-step
explanation for how the final answer was obtained.
B.3
Reproducing Results
The main results for our dataset are the performances of various LLMs under different prompt settings.
These are all shown in Table 2. First, please create a conda environment and install packages in the
requirements.txt file. Then, please add your OpenAI API key to this environment. To obtain
these results, simply execute the following command: python run.py – model <model_name>
– prompt <prompt_style>.
The 8 options for the model argument as follows:
• Mistral 7B: mistralai/Mistral-7B-Instruct-v0.2
• Mixtral 8x7B: mistralai/Mixtral-8x7B-Instruct-v0.1
• Llama3-8B: meta-llama/Meta-Llama-3-8B-Instruct
• Llama3-70B: meta-llama/Meta-Llama-3-70B-Instruct
• Meditron-70B: epfl-llm/meditron-70b
• PMC-Llama-13B: axiong/PMC_LLaMA_13B
37

• GPT-3.5: OpenAI/gpt-3.5-turbo
• GPT-4: OpenAI/gpt-4
Additionally, we provide three options for the prompt argument:
• Direct answer = direct_answer
• Zero shot = zero_shot
• One shot = one_shot_cot
All open-source LLMs are run on 4 A100-80B GPUs for model inference. We provide the settings
for the first three prompts settings below:
Table 10: Number of tokens used for zero-shot direct prompting
PMC-LLaMA
MEDITRON
Mistral
Mixtral
Llama 3-8B
Llama 3-70B
GPT-3.5
GPT-4
Input
276.9k
736.9k
669.9k
669.9k
727.5k
727.5k
662.5k
662.5k
Output
23
10.6k
130.1k
36.7k
8.6k
7.4k
8.1k
8.5k
Table 11: Number of tokens used for zero-shot CoT prompting
PMC-LLaMA
MEDITRON
Mistral
Mixtral
Llama 3-8B
Llama 3-70B
GPT-3.5
GPT-4
Input
332.6k
823.8k
721.2k
721.2k
778.8k
778.8k
713.8k
713.8k
Output
240.9k
18.0k
241.5k
222.6k
230.3k
223.9k
191.4k
216.8k
Table 12: Number of tokens used for one-shot CoT prompting
PMC-LLaMA
MEDITRON
Mistral
Mixtral
Llama 3-8B
Llama 3-70B
GPT-3.5
GPT-4
Input
861.3k
1.4M
1.8M
1.8M
1.8M
1.8M
1.8M
1.8M
Output
222.7k
387.7k
263.9k
290.3k
360.4k
351.7k
327.7k
330.4k
Upon executing run.py, the results will be saved in a file called <model>_<prompt>.jsonl. Each
instance will have the following metadata associated with them:
{
"Row Number": ,
"Calculator Name": ,
"Calculator ID": ,
"Category": ,
"Note ID": ,
"Question": ,
"LLM Answer": ,
"LLM Explanation": ,
"Ground Truth Answer": ,
"Ground Truth Explanation": ,
"Result":
}
Here is what each item means:
• “Row Number” - specifies the row in the MEDCALC-BENCH CSV
• “Calculator Name” - specifies which calculator that is being covered by this instance
• “Calculator ID” - unique ID of the calculator
38

• “Category” - sub-category for the calculator
• “Note ID” - specifies the Note ID from MEDCALC-BENCH
• “Patient Note” - provides the patient note covered by this instance
• “Question” - question being asked by this instance
• “LLM Answer” - the final answer value given by the LLM
• “LLM Explanation” - the explanation provided by the LLM for the problem
• “Ground Truth Answer” - the ground truth answer for the instance
• “Ground Truth Explanation” - the ground truth explanation for the instance
• “Result” - either “Correct” or “Incorrect” by comparing the LLM Answer and Ground Truth
Answer
Note that in the direct answer setting, the LLM is only expected to provide a direct answer and so the
“LLM Explanation” section will be “N/A” for all of them.
B.4
Author Statement
Although we have verified that our dataset is available by CC-BY-SA 4.0 license, all the authors
bear responsibility for any infringements. For any updates on the dataset that needs to be made (i.e.
adding new calculators, more notes, ect), we will update the Github repository and still keep archives
of previous versions of the dataset on both the repository and HuggingFace.
C
Training Dataset for Fine-Tuning on MEDCALC-BENCH
C.1
Training Dataset
In addition to the 1,047 manually verified instances for MEDCALC-BENCH, we also curated a training
dataset of 10,053 instances consisting of patient notes, questions, final answers, and explanations
using the same extraction process that we used for curating the test set. This training dataset contained
notes for 40 calculators. These calculators either had over 20 patient notes from Open-Patients or
were one of the 11 calculators which had their notes synthesized from a template-based function (80
notes were synthesized for these calculators). The remaining 15 calculators had no patient notes to
train with inside the training dataset. Shown in the table below are the number of instances for each
calculator in the training dataset, along with their calculator type and sub-type.
Table 13: Information about each calculator in MEDCALC-BENCH train-
ing dataset
Calculator Name
Type
Sub-Type
Number of
Attributes
Number of
Notes
Creatinine Clearance (Cockcroft-
Gault Equation)
Equation-Based
Lab Test
5
157
CKD-EPI Equations for Glomeru-
lar Filtration Rate
Equation-Based
Lab Test
3
519
CHA2DS2-VASc Score for Atrial
Fibrillation Stroke Risk
Rule-Based
Risk
10
517
Mean Arterial Pressure (MAP)
Equation-Based
Physical
3
948
Body Mass Index (BMI)
Equation-Based
Physical
3
519
Calcium Correction for Hypoalbu-
minemia
Equation-Based
Lab Test
2
212
Wells’ Criteria for Pulmonary Em-
bolism
Rule-Based
Risk
9
445
Continued on next page
39

Table 13: Information about each calculator in MEDCALC-BENCH train-
ing dataset (continued)
Calculator Name
Type
Sub-Type
Number of
Attributes
Number of
Notes
MDRD GFR Equation
Equation-Based
Lab Test
4
312
Ideal Body Weight
Equation-Based
Physical
2
621
QTc Bazett Calculator
Equation-Based
Physical
2
80
Wells’ Criteria for DVT
Rule-Based
Risk
11
578
HEART Score for Major Cardiac
Events
Rule-Based
Risk
13
222
Fibrosis-4 (FIB-4) Index for Liver
Fibrosis
Equation-Based
Lab Test
4
120
Maintenance Fluids Calculations
Equation-Based
Physical
1
889
Sodium Correction for Hyper-
glycemia
Equation-Based
Lab Test
2
295
Serum Osmolality
Equation-Based
Lab Test
3
370
FeverPAIN Score for Strep Pharyn-
gitis
Rule-Based
Diagnosis
5
42
Free Water Deficit
Equation-Based
Lab Test
4
296
Anion Gap
Equation-Based
Lab Test
3
216
LDL Calculated
Equation-Based
Lab Test
3
66
CURB-65 Score for Pneumonia
Severity
Rule-Based
Risk
6
125
PERC Rule for Pulmonary Em-
bolism
Rule-Based
Diagnosis
9
153
SIRS Criteria
Rule-Based
Diagnosis
5
252
QTc Fridericia Calculator
Equation-Based
Physical
2
80
QTc Framingham Calculator
Equation-Based
Physical
2
80
QTc Hodges Calculator
Equation-Based
Physical
2
80
QTc Rautaharju Calculator
Equation-Based
Physical
2
80
Body Surface Area Calculator
Equation-Based
Physical
2
929
Target weight
Equation-Based
Physical
2
80
Adjusted Body Weight
Equation-Based
Physical
3
570
Delta Gap
Equation-Based
Lab Test
3
331
Delta Ratio
Equation-Based
Lab Test
3
288
Albumin Corrected Anion Gap
Equation-Based
Lab Test
4
91
Albumin Corrected Delta Gap
Equation-Based
Lab Test
4
75
Albumin Corrected Delta Ratio
Equation-Based
Lab Test
4
74
MME Conversion
Equation-Based
Dosage
2
80
Steroid Conversion
Equation-Based
Dosage
2
80
Estimated Due Date
Equation-Based
Date
2
80
Estimated Date of Conception
Equation-Based
Date
2
80
Estimated Gestational Age
Equation-Based
Date
2
80
C.2
Training Details
We fine-tuned Mistral-7B and Llama2-7B on our dataset. All fine-tuning runs are performed on a
single 4xA100 40GB node. We use an adapted version of the Code-Act [55] training scripts which
are based on a fork of Megatron-LLM [3]. We train Llama2-7b and not Llama3-7B which was
benchmarked in the main paper as this model is not currently supported by Megatron-LLM. Both
training and test data are converted into a chatML form. Shown below is an example:
System Message
Below is a patient note as well as a medical question about the patient. Provide an accurate answer to
the question based on the note. Explain your reasoning before stating your final answer and put your
final answer at the end of your response in the format Answer: INSERT_ANSWER
40

User Message
Patient Note:
A 78-year-old male with history of hypertension, dyslipidemia, and prosthetic aortic valve replace-
ment presented to the emergency department with complaints of exertional shortness of breath for
few days. Chest X-ray showed widened mediastinum. Subsequently, CT angiogram of the chest
showed massively dilated ascending aorta with maximum diameter of 10.2 cm []. Transthoracic
echocardiogram revealed normal ejection fraction with mild aortic insufficiency, well-functioning
prosthetic aortic valve, and no aortic stenosis. His creatinine was 1.8 mg/dl, and he had received 150
ml of contrast for CT angiogram. It was necessary to evaluate his coronary arteries before surgery
for AAA. There were two options in this case: coronary CT angiography or conventional coronary
angiography. Coronary CT angiography would require about 150 ml of contrast.[] A diagnostic
coronary angiogram can be done using about 50 ml of contrast.[] Given his renal insufficiency, we
decided to do conventional coronary angiography. Since the ascending aorta and root were extremely
dilated, we knew it would not be possible to engage the coronaries using regular catheters and
standard technique. Hence, telescopic technique was used. Amplatz left 3 (AL3) 7F (French) guide
catheter (90 cm) was initially used, and nonselective injection of contrast was done to see the coronary
ostium [ and ]. After that, a 5F multipurpose (MP) catheter (110 cm) was telescoped through 7F AL3
guide catheter to engage the ostium of the left main coronary artery [ and ]. Using this technique,
images of coronaries were obtained, and it showed minimal luminal irregularities in major epicardial
coronary arteries. Total of 50 ml contrast was used. The patient underwent successful surgery with
aortic valve replacement and excision of aneurysm with graft placement. The most likely etiology of
giant aortic aneurysm in our patient was atherosclerosis. However, we did not have any record of his
previous aortic valve surgery, and we do not know if it was a bicuspid aortic valve. In that case, he
could have had aortopathy associated with bicuspid aortic valve.
Question: Using the MDRD GFR equation, what is the patient’s Glomerular Filtration Rate (GFR)
in terms of mL/min/1.73 m²?
Response:
The patient is 78 years old. The concentration of Creatinine is 1.8 mg/dL. The race of the patient
is not provided, so the default value of the race coefficient is 1.0. The patient is male, so the
gender coefficient is 1.0. The patient’s estimated GFR is calculated using the MDRD equation
as: The formula for GFR is given by: 175 × creatinine−1.154 × age−0.203 × race_coefficient ×
gender_coefficient. The creatinine concentration is mg/dL. Plugging in these values will give us:
175×1.8−1.154×78−0.203×1.0×1.0 = 36.674. Hence, the patient’s GFR is 36.674 mL/min/1.73m².
Answer: 36.674
Following the implementation used for finetuning LLMs for CodeAct , we only calculate and optimize
the loss on the assistant response, pack short instances into longer ones, and train using flash attention.
We train for two epochs with a batch size of 32 on 4 parallel GPU’s with a learning rate of 1e-5, 50
warmup steps, and cosine decay.
C.3
Results
From the above fine-tuning procedure, we achieved the following results on the MEDCALC-BENCH
test set:
Table 14: Results after fine-tuning open-source LLMs on MEDCALC-BENCH training dataset
Model
Original Accuracy
Fine-tuned Accuracy
Mistral-7B
10.79%
49.19%
Llama-2-7B
1.53%
45.75%
41

Both fine-tuning results significantly increased their respective models’ performance with the lower
Llama-2 performance likely due to its lower context length. Hence, we show the efficacy of the
training dataset for MEDCALC-BENCH in improving a model’s ability to recall the correct equations,
retrieve relevant parameters, and correctly perform arithmetic. Although these results demonstrate a
significant performance improvement that fine-tuning has on our dataset, this still shows that more
work needs to be done in improving LLMs for them to be reliable clinical calculators.
42

D
Code-Augmented LLMs Prompt Setting
D.1
Code-Augmented LLM Performance
To minimize a model’s arithmetic errors on MEDCALC-BENCH, we instead prompt a model to write
code for performing any arithmetic operations. The user will then execute the code and provide the
output from the console. If there are any compiling issues, the model has up to 20 tries to output the
answer. For further details on this implementation, please refer to the generate_code_prompt.py
file in the repository.
Due to limited compute, we only ran the code execution prompts for GPT-3.5 and GPT-4 and did
not perform this experiment for open-source LLMs. Hence, we only included these results in the
supplemental section and not the main paper as not all LLMs were benchmarked in this setting.
Shown below are the results for zero-shot chain-of-thought (CoT) for GPT-3.5-turbo and GPT-4,
along with the code-augmented results for GPT-3.5-turbo-16k and GPT-4:
Table 15: Comparison of GPT-3.5-turbo and GPT-4 in zero-shot CoT before and after adding code
interpreter
GPT-3.5-turbo
GPT-4
Zero-Shot CoT
Code Prompt
Zero-Shot CoT
Code Prompt
Equation
Lab Test
20.49%
30.04%
26.30%
49.85%
Physical
45.00%
56.76%
71.25%
81.66%
Dosage
17.50%
15.79%
40.00%
32.50%
Date
11.67%
28.33%
48.33%
43.33%
Rule
Severity
10.00%
13.33%
15.00%
18.75%
Diagnosis
31.67%
25.00%
28.33%
23.33%
Risk
13.33%
12.68%
27.50%
33.75%
Overall
23.69%
30.29%
37.92%
48.51%
After augmenting with a code interpreter, the accuracies of GPT-3.5-turbo and GPT-4 have increased
by 6.60% and 10.59%, respectively. Hence, we conclude that LLMs can significantly benefit from
using a code interpreter to reduce its arithmetic mistakes and, thereby, become better at solving
clinical calculations.
43

E
Additional Analysis
E.1
Accuracy vs. Number of Attributes
Figure 2: Accuracy vs. Number of Parameters for Equation-Based Calcula-
tors
Figure 3: Accuracy vs. Number of Parameters for Rule-Based Calculators
While we have conducted analyses for LLM performance based on sub-category type, we also
examine the performance for models based on the number of parameters. Using a line-of-best-fit for
a second degree polynomial, we see the following trend for the number of parameters vs. accuracy
for each of the eight models. Figure 2 shows the results for equation-based calculators and Figure 3
shows the results for rule-based calculators. As seen, the overall trend is that model performance tends
to drop as the number of attributes increases. For models such as Meditron-70B and PMC-Llama-13B
the drop is not as drastic, but that is because the accuracy was already close to 0 even for calculation
tasks with the minimum number of attributes. However, for models such as Llama3-70B and GPT-4
which perform well relative to the other LLMs, the drop is much more drastic as the parameter
44

count increases. Hence, these plots show that even the highest-performing LLMs are at best able to
make progress only on basic computation tasks and struggle significantly as the number of attributes
increase.
45

