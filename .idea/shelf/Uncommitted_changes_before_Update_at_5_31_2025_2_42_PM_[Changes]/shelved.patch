Index: src/models/clustering.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import math\r\nimport heapq\r\nimport numpy as np\r\n\r\nfrom src.models.graph import Graph\r\n\r\n\r\ndef tau_closest_agents(agent_index, remaining_indices_list, adj_matrix, tau) -> tuple[list[int], float]:\r\n    \"\"\"\r\n    Find the tau closest agents to a given agent based on the provided adjacency matrix.\r\n\r\n    Args:\r\n        agent_index (int): Index of the agent (row in adj_matrix) to find neighbors for.\r\n        remaining_indices_list (list[int]): List of candidate agent indices (global indices) to search within.\r\n        adj_matrix (np.ndarray): A 2D numpy array representing pairwise distances between agents.\r\n        tau (int): Number of closest agents to select (including the agent itself if present).\r\n\r\n    Returns:\r\n        tuple[list[int], float]:\r\n            - List of the global indices of the tau closest agents.\r\n            - Distance to the furthest agent in this tau-sized neighborhood.\r\n    \"\"\"\r\n    # Get distances from point i to all other points\r\n    distances = adj_matrix[agent_index][remaining_indices_list]\r\n    # Use a heap to get the tau closest agents\r\n    tau_closest = heapq.nsmallest(tau, zip(remaining_indices_list, distances), key=lambda x: x[1])\r\n    # Extract the indices of the closest agents\r\n    cluster_indices = [i for i, _ in tau_closest]\r\n    # Get the distance to the furthest agent in the tau closest agents\r\n    dist_to_furthest_agent = tau_closest[-1][1]\r\n\r\n    return cluster_indices, dist_to_furthest_agent\r\n\r\n\r\ndef SmallestAgentBall(remaining_indices_list, adj_matrix, tau) -> list[int]:\r\n    \"\"\"\r\n    Identify the tightest group (\"smallest ball\") of tau agents from the remaining set,\r\n    minimizing the radius (distance to the furthest member from a center).\r\n\r\n    Args:\r\n        remaining_indices_list (list[int]): Global indices of unclustered agents.\r\n        adj_matrix (np.ndarray): A 2D numpy array representing pairwise distances between agents.\r\n        tau (int): Desired number of agents in the group.\r\n\r\n    Returns:\r\n        list[int]: Global indices of the tau agents forming the smallest-radius ball.\r\n                   If the number of remaining agents is less than or equal to tau, returns all.\r\n    \"\"\"\r\n    if len(remaining_indices_list) <= tau:\r\n        return remaining_indices_list\r\n    \r\n    min_radius = float('inf')\r\n    best_cluster = None\r\n\r\n    for i in remaining_indices_list:\r\n        cluster_indices, dist_to_furthest_agent = tau_closest_agents(i, remaining_indices_list, adj_matrix, tau)\r\n        \r\n        # Update if this ball is smaller\r\n        if dist_to_furthest_agent < min_radius:\r\n            min_radius = dist_to_furthest_agent\r\n            best_cluster = cluster_indices\r\n\r\n    return best_cluster\r\n\r\n\r\ndef GreedyCohesiveClustering(graph: Graph, k) -> list[list[str]]:\r\n    \"\"\"\r\n    Partition agents into k cohesive clusters using a greedy approach that minimizes\r\n    the radius of each cluster.\r\n\r\n    Each cluster contains approximately n/k agents (rounded up), and is selected\r\n    based on the agent whose tau-neighborhood forms the smallest \"ball\" in terms of max distance.\r\n\r\n    Args:\r\n        graph (Graph): Graph object containing:\r\n            - nodes: a list of node objects, each with an `id` attribute.\r\n            - adj_matrix: a 2D numpy array representing pairwise distances between nodes.\r\n        k (int): Number of clusters to produce.\r\n\r\n    Returns:\r\n        list[list[str]]: A list of k clusters, where each cluster is a list of node IDs.\r\n                         If fewer than k meaningful clusters are found, remaining entries are empty lists.\r\n    \"\"\"\r\n    n = len(graph.nodes)\r\n    clusters = [] # each cluster is a list of id\r\n    N = set(range(n))\r\n    per_cluster = math.ceil(n/k)\r\n\r\n    while len(N) >= per_cluster:\r\n        # Create a submatrix for the remaining points\r\n        remaining_indices_list = list(N)\r\n\r\n        # Find the smallest ball in the remaining points\r\n        C_j = SmallestAgentBall(remaining_indices_list, graph.adj_matrix, per_cluster)\r\n\r\n        # Get the node IDs\r\n        cluster_node_ids = [graph.nodes[i].id for i in C_j]\r\n        \r\n        # Add the cluster to the result\r\n        clusters.append(cluster_node_ids)\r\n        \r\n        # Remove the clustered points from the remaining set\r\n        N -= set(C_j)\r\n\r\n    if N:\r\n        remaining_node_ids = [graph.nodes[i].id for i in N]\r\n        clusters.append(remaining_node_ids)\r\n\r\n    # Add empty clusters if fewer than k clusters were created\r\n    while len(clusters) < k:\r\n        clusters.append([])\r\n\r\n    return clusters
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/models/clustering.py b/src/models/clustering.py
--- a/src/models/clustering.py	(revision 2938cefbbd1fcb9af8415be6ea705e466fcac4c8)
+++ b/src/models/clustering.py	(date 1748635425000)
@@ -63,7 +63,7 @@
     return best_cluster
 
 
-def GreedyCohesiveClustering(graph: Graph, k) -> list[list[str]]:
+def greedy_cohesive_clustering(graph: Graph, k) -> list[list[str]]:
     """
     Partition agents into k cohesive clusters using a greedy approach that minimizes
     the radius of each cluster.
@@ -91,7 +91,7 @@
         remaining_indices_list = list(N)
 
         # Find the smallest ball in the remaining points
-        C_j = SmallestAgentBall(remaining_indices_list, graph.adj_matrix, per_cluster)
+        C_j = SmallestAgentBall(remaining_indices_list, graph.adj_mat, per_cluster)
 
         # Get the node IDs
         cluster_node_ids = [graph.nodes[i].id for i in C_j]
Index: README.md
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Fair-Conference-Scheduling\r\n\r\n\r\n## Process csv to PaperNodes: \r\n```\r\npython -m src.data_processing.csv_to_paper_node ./data/test/papers.csv --emb-column  emb_v2\r\n```\r\n\r\n## Process data (.json) to embeddings:\r\n```\r\n python -m src.cli.generate_embeddings ./data/test/test.json ./data/emb/ --model text-embedding-3-small --include title,authors\r\n```
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/README.md b/README.md
--- a/README.md	(revision 2938cefbbd1fcb9af8415be6ea705e466fcac4c8)
+++ b/README.md	(date 1748664148000)
@@ -1,12 +1,12 @@
 # Fair-Conference-Scheduling
 
 
-## Process csv to PaperNodes: 
-```
-python -m src.data_processing.csv_to_paper_node ./data/test/papers.csv --emb-column  emb_v2
-```
-
 ## Process data (.json) to embeddings:
 ```
- python -m src.cli.generate_embeddings ./data/test/test.json ./data/emb/ --model text-embedding-3-small --include title,authors
+ python -m src.cli.generator --config ./src/configs/embed.yaml
+```
+
+## Clustering and evaluate:
+```
+ python -m src.cli.clusterer --config ./src/configs/clusterer.yaml
 ```
\ No newline at end of file
Index: src/models/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from .node import Node\r\nfrom .paper_node import PaperNode\r\nfrom .graph import Graph\r\nfrom .clustering import GreedyCohesiveClustering
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/models/__init__.py b/src/models/__init__.py
--- a/src/models/__init__.py	(revision 2938cefbbd1fcb9af8415be6ea705e466fcac4c8)
+++ b/src/models/__init__.py	(date 1748632773000)
@@ -1,4 +1,4 @@
 from .node import Node
 from .paper_node import PaperNode
 from .graph import Graph
-from .clustering import GreedyCohesiveClustering
\ No newline at end of file
+from .clustering import greedy_cohesive_clustering
\ No newline at end of file
Index: src/cli/generate_embeddings.py
===================================================================
diff --git a/src/cli/generate_embeddings.py b/src/cli/generate_embeddings.py
deleted file mode 100644
--- a/src/cli/generate_embeddings.py	(revision 2938cefbbd1fcb9af8415be6ea705e466fcac4c8)
+++ /dev/null	(revision 2938cefbbd1fcb9af8415be6ea705e466fcac4c8)
@@ -1,22 +0,0 @@
-import argparse
-from src.data_processing.generate_embeddings import generate_embeddings
-
-
-def main():
-    parser = argparse.ArgumentParser(description="Generate embeddings for text files.")
-    parser.add_argument("input_path", help="Path to the input folder containing text files")
-    parser.add_argument("output_path", help="Path to the output JSON file")
-    parser.add_argument("--model", default="text-embedding-3-small", help="Model to use for embedding generation")
-    parser.add_argument('--include', type=lambda s: s.split(','),
-                        default=[], help='Comma-separated list of keys at each entry to include')
-    parser.add_argument('--exclude', type=lambda s: s.split(','),
-                        default=[], help='Comma-separated list of keys at each entry to exclude')
-    args = parser.parse_args()
-    try:
-        generate_embeddings(args.input_path, args.output_path, args.model, include=args.include, exclude=args.exclude)
-    except Exception as e:
-        print(f"Error: {e}")
-
-
-if __name__ == "__main__":
-    main()
\ No newline at end of file
Index: src/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># src/__init__.py\r\nfrom .models import Graph\r\nfrom .models import Node\r\nfrom .models import PaperNode\r\nfrom .models import GreedyCohesiveClustering\r\nfrom .data_processing import process_pdfs\r\nfrom .data_processing import Encoder\r\nfrom .data_processing import generate_embeddings\r\n# from .data_processing import csv_to_paper_node\r\nfrom .config import PROJECT_ROOT, DATA_DIR\r\n\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/__init__.py b/src/__init__.py
--- a/src/__init__.py	(revision 2938cefbbd1fcb9af8415be6ea705e466fcac4c8)
+++ b/src/__init__.py	(date 1748715684413)
@@ -2,7 +2,7 @@
 from .models import Graph
 from .models import Node
 from .models import PaperNode
-from .models import GreedyCohesiveClustering
+from .models import greedy_cohesive_clustering
 from .data_processing import process_pdfs
 from .data_processing import Encoder
 from .data_processing import generate_embeddings
Index: src/eval/kmeans.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/eval/kmeans.py b/src/eval/kmeans.py
new file mode 100644
--- /dev/null	(date 1748715764204)
+++ b/src/eval/kmeans.py	(date 1748715764204)
@@ -0,0 +1,22 @@
+import numpy as np
+
+from src.models.graph import Graph
+
+
+def kmeans_objective(graph: Graph, clusters):
+    total_wcss = 0.0
+
+    for cluster in clusters:
+        if not cluster:
+            continue
+        # Get all embeddings in this cluster
+        embeddings = np.array([graph.get_node(node_id).emb for node_id in cluster])
+
+        # Compute centroid
+        centroid = embeddings.mean(axis=0)
+
+        # Sum of squared distances to centroid
+        sq_dists = ((embeddings - centroid) ** 2).sum(axis=1)
+        total_wcss += sq_dists.sum()
+
+    return total_wcss
\ No newline at end of file
