<html><head><meta charset='utf-8'><title>Divide-and-Conquer Meets Consensus_ Unleashing the Power of Functions in Code Generation</title></head><body><h1>Divide-and-Conquer Meets Consensus_ Unleashing the Power of Functions in Code Generation</h1><h3>By: ['Jingchang Chen', 'Hongxuan Tang', 'Zheng Chu', 'Qianglong Chen', 'Zekun Wang', 'Ming Liu', 'Bing Qin']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>NeurIPS</div><h4>url</h4><div style='margin-bottom:1em'>https://neurips.cc/virtual/2024/oral/97965</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> Despite recent progress made by large language models in code generation, they still struggle with programs that meet complex requirements. Recent work utilizes plan-and-solve decomposition to decrease the complexity and leverage self-tests to refine the generated program. Yet, planning deep-inside requirements in advance can be challenging, and the tests need to be accurate to accomplish self-improvement. To this end, we propose FunCoder, a code generation framework incorporating the divide-and-conquer strategy with functional consensus. Specifically, FunCoder recursively branches off sub-functions as smaller goals during code generation, represented by a tree hierarchy. These sub-functions are then composited to attain more complex objectives. Additionally, we designate functions via a consensus formed by identifying similarities in program behavior, mitigating error propagation. FunCoder outperforms state-of-the-art methods by +9.8% on average in HumanEval, MBPP, xCodeEval and MATH with GPT-3.5 and GPT-4. Moreover, our method demonstrates superiority on smaller models: With FunCoder, StableCode-3b surpasses GPT-3.5 by +18.6% and achieves 97.7% of GPT-4's performance on HumanEval. Further analysis reveals that our proposed dynamic function decomposition is capable of handling complex requirements, and the functional consensus prevails over self-testing in correctness evaluation.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 3D: Natural Language Processing</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=cFqAANINgW</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=cFqAANINgW</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 3D: Natural Language Processing</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 3D: Natural Language Processing</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 3B: Natural Language Processing</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 3D: Natural Language Processing</div><h4>tsne_0</h4><div style='margin-bottom:1em'>-1.3633782863616943</div><h4>tsne_1</h4><div style='margin-bottom:1em'>-0.8081914782524109</div></body></html>