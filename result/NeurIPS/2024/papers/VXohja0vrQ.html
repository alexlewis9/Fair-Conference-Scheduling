<html><head><meta charset='utf-8'><title>MedCalc-Bench_ Evaluating Large Language Models for Medical Calculations</title></head><body><h1>MedCalc-Bench_ Evaluating Large Language Models for Medical Calculations</h1><h3>By: ['Nikhil Khandekar', 'Qiao Jin', 'Guangzhi Xiong', 'Soren Dunn', 'Serina Applebaum', 'Zain Anwar', 'Maame Sarfo-Gyamfi', 'Conrad Safranek', 'Abid Anwar', 'Andrew Zhang', 'Aidan Gilson', 'Maxwell Singer', 'Amisha Dave', 'Anrew Taylor', 'Aidong Zhang', 'Qingyu Chen', 'Zhiyong Lu']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>NeurIPS</div><h4>url</h4><div style='margin-bottom:1em'>https://neurips.cc/virtual/2024/oral/98021</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> Current benchmarks for evaluating large language models (LLMs) in medicine are primarily focused on question-answering involving domain knowledge and descriptive reasoning. While such qualitative capabilities are vital to medical diagnosis, in real-world scenarios, doctors frequently use clinical calculators that follow quantitative equations and rule-based reasoning paradigms for evidence-based decision support. To this end, we propose MedCalc-Bench, a first-of-its-kind dataset focused on evaluating the medical calculation capability of LLMs. MedCalc-Bench contains an evaluation set of over 1000 manually reviewed instances from 55 different medical calculation tasks. Each instance in MedCalc-Bench consists of a patient note, a question requesting to compute a specific medical value, a ground truth answer, and a step-by-step explanation showing how the answer is obtained. While our evaluation results show the potential of LLMs in this area, none of them are effective enough for clinical settings. Common issues include extracting the incorrect entities, not using the correct equation or rules for a calculation task, or incorrectly performing the arithmetic for the computation. We hope our study highlights the quantitative knowledge and reasoning gaps in LLMs within medical settings, encouraging future improvements of LLMs for various clinical calculation tasks. MedCalc-Bench is publicly available at: https://github.com/ncbi-nlp/MedCalc-Bench.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 6C: New Data</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://arxiv.org/pdf/2406.12036</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=VXohja0vrQ</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 6C: New Data</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 6C: New Data</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 2D: Generative Models</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 3A: Generative Models</div></body></html>