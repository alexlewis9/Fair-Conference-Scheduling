<html><head><meta charset='utf-8'><title>Learning diffusion at lightspeed</title></head><body><h1>Learning diffusion at lightspeed</h1><h3>By: ['Antonio Terpin', 'Nicolas Lanzetti', 'Mart√≠n Gadea', 'Florian Dorfler']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>NeurIPS</div><h4>url</h4><div style='margin-bottom:1em'>https://neurips.cc/virtual/2024/oral/97944</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> Diffusion regulates numerous natural processes and the dynamics of many successful generative models. Existing models to learn the diffusion terms from observational data rely on complex bilevel optimization problems and model only the drift of the system.We propose a new simple model, JKOnet , which bypasses the complexity of existing architectures while presenting significantly enhanced representational capabilities: JKOnet recovers the potential, interaction, and internal energy components of the underlying diffusion process. JKOnet* minimizes a simple quadratic loss and outperforms other baselines in terms of sample efficiency, computational complexity, and accuracy. Additionally, JKOnet* provides a closed-form optimal solution for linearly parametrized functionals, and, when applied to predict the evolution of cellular processes from real-world data, it achieves state-of-the-art accuracy at a fraction of the computational cost of all existing methods.Our methodology is based on the interpretation of diffusion processes as energy-minimizing trajectories in the probability space via the so-called JKO scheme, which we study via its first-order optimality conditions.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 1C: Optimization and Learning Theory</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=y10avdRFNK</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=y10avdRFNK</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 1C: Optimization and Learning Theory</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 1C: Optimization and Learning Theory</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 5D: Machine Learning and Science</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 3D: Natural Language Processing</div></body></html>