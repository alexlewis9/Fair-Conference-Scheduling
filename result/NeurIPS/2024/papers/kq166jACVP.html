<html><head><meta charset='utf-8'><title>Aligner_ Efficient Alignment by Learning to Correct</title></head><body><h1>Aligner_ Efficient Alignment by Learning to Correct</h1><h3>By: ['Jiaming Ji', 'Boyuan Chen', 'Hantao Lou', 'Donghai Hong', 'Borong Zhang', 'Xuehai Pan', 'Tianyi (Alex) Qiu', 'Juntao Dai', 'Yaodong Yang']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>NeurIPS</div><h4>url</h4><div style='margin-bottom:1em'>https://neurips.cc/virtual/2024/oral/97959</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> With the rapid development of large language models (LLMs) and ever-evolving practical requirements, finding an efficient and effective alignment method has never been more critical. However, the tension between the complexity of current alignment methods and the need for rapid iteration in deployment scenarios necessitates the development of a model-agnostic alignment approach that can operate under these constraints. In this paper, we introduce Aligner, a novel and simple alignment paradigm that learns the correctional residuals between preferred and dispreferred answers using a small model. Designed as a model-agnostic, plug-and-play module, Aligner can be directly applied to various open-source and API-based models with only one-off training, making it suitable for rapid iteration. Notably, Aligner can be applied to any powerful, large-scale upstream models. Moreover, it can even iteratively bootstrap the upstream models using corrected responses as synthetic human preference data, breaking through the model's performance ceiling. Our experiments demonstrate performance improvements by deploying the same Aligner model across 11 different LLMs, evaluated on the 3H dimensions (helpfulness, harmlessness, and honesty). Specifically, Aligner-7B has achieved an average improvement of 68.9% in helpfulness and 22.8% in harmlessness across the tested LLMs while also effectively reducing hallucination. In the Alpaca-Eval leaderboard, stacking Aligner-2B on GPT-4 Turbo improved its LC Win Rate from 55.0% to 58.3%, surpassing GPT-4 Omni's 57.5% Win Rate (community report).</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 6B: Safety, New Data</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=kq166jACVP</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=kq166jACVP</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 6B: Safety, New Data</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 1B: Human-AI Interaction</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 6B: Safety, New Data</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 3A: Generative Models</div><h4>tsne_0</h4><div style='margin-bottom:1em'>-1.4151290655136108</div><h4>tsne_1</h4><div style='margin-bottom:1em'>-2.546933889389038</div></body></html>