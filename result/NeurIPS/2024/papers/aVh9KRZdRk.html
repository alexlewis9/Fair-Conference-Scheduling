<html><head><meta charset='utf-8'><title>Learning to grok_ Emergence of in-context learning and skill composition in modular arithmetic tasks</title></head><body><h1>Learning to grok_ Emergence of in-context learning and skill composition in modular arithmetic tasks</h1><h3>By: ['Tianyu He', 'Darshil Doshi', 'Aritra Das', 'Andrey Gromov']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>NeurIPS</div><h4>url</h4><div style='margin-bottom:1em'>https://neurips.cc/virtual/2024/oral/97968</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> Large language models can solve tasks that were not present in the training set. This capability is believed to be due to in-context learning and skill composition. In this work, we study the emergence of in-context learning and skill composition in a collection of modular arithmetic tasks. Specifically, we consider a finite collection of linear modular functions $z = a  x + b  y \text{ mod } p$ labeled by the vector $(a, b) \in \mathbb{Z}_p^2$. We use some of these tasks for pre-training and the rest for out-of-distribution testing. We empirically show that a GPT-style transformer exhibits a transition from in-distribution to out-of-distribution generalization as the number of pre-training tasks increases. We find that the smallest model capable of out-of-distribution generalization requires two transformer blocks, while for deeper models, the out-of-distribution generalization phase is *transient*, necessitating early stopping. Finally, we perform an interpretability study of the pre-trained models, revealing highly structured representations in both attention heads and MLPs; and discuss the learned algorithms. Notably, we find an algorithmic shift in deeper models, as we go from few to many in-context examples.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 1A: Neuroscience and Intepretability</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=aVh9KRZdRk</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=aVh9KRZdRk</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 1A: Neuroscience and Intepretability</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 1A: Neuroscience and Intepretability</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 1A: Neuroscience and Intepretability</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 1A: Neuroscience and Intepretability</div></body></html>