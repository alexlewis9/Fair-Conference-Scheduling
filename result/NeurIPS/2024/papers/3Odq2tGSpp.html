<html><head><meta charset='utf-8'><title>Stylus_ Automatic Adapter Selection for Diffusion Models</title></head><body><h1>Stylus_ Automatic Adapter Selection for Diffusion Models</h1><h3>By: ['Michael Luo', 'Justin Wong', 'Brandon Trabucco', 'Yanping Huang', 'Joseph Gonzalez', 'zhifeng Chen', 'Ruslan Salakhutdinov', 'Ion Stoica']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>NeurIPS</div><h4>url</h4><div style='margin-bottom:1em'>https://neurips.cc/virtual/2024/oral/98000</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> Beyond scaling base models with more data or parameters, fine-tuned adapters provide an alternative way to generate high fidelity, custom images at reduced costs. As such, adapters have been widely adopted by open-source communities, accumulating a database of over 100K adaptersâ€”most of which are highly customized with insufficient descriptions. To generate high quality images, this paper explores the problem of matching the prompt to a Stylus of relevant adapters, built on recent work that highlight the performance gains of composing adapters. We introduce Stylus, which efficiently selects and automatically composes task-specific adapters based on a prompt's keywords. Stylus outlines a three-stage approach that first summarizes adapters with improved descriptions and embeddings, retrieves relevant adapters, and then further assembles adapters based on prompts' keywords by checking how well they fit the prompt. To evaluate Stylus, we developed StylusDocs, a curated dataset featuring 75K adapters with pre-computed adapter embeddings. In our evaluation on popular Stable Diffusion checkpoints, Stylus achieves greater CLIP/FID Pareto efficiency and is twice as preferred, with humans and multimodal models as evaluators, over the base model.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 4B: Diffusion-based Models</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=3Odq2tGSpp</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=3Odq2tGSpp</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 4B: Diffusion-based Models</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 4D: Machine Vision</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 4C: Diffusion-based Models, Mathematics</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 3D: Natural Language Processing</div></body></html>