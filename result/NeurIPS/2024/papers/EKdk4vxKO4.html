<html><head><meta charset='utf-8'><title>MDAgents_ An Adaptive Collaboration of LLMs for Medical Decision-Making</title></head><body><h1>MDAgents_ An Adaptive Collaboration of LLMs for Medical Decision-Making</h1><h3>By: ['Yubin Kim', 'Chanwoo Park', 'Hyewon Jeong', 'Yik Siu Chan', 'Xuhai "Orson" Xu', 'Daniel McDuff', 'Hyeonhoon Lee', 'Marzyeh Ghassemi', 'Cynthia Breazeal', 'Hae Park']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>NeurIPS</div><h4>url</h4><div style='margin-bottom:1em'>https://neurips.cc/virtual/2024/oral/97988</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> Foundation models are becoming valuable tools in medicine. Yet despite their promise, the best way to leverage Large Language Models (LLMs) in complex medical tasks remains an open question. We introduce a novel multi-agent framework, named **M**edical **D**ecision-making **Agents** (**MDAgents**) that helps to address this gap by automatically assigning a collaboration structure to a team of LLMs. The assigned solo or group collaboration structure is tailored to the medical task at hand, a simple emulation inspired by the way real-world medical decision-making processes are adapted to tasks of different complexities. We evaluate our framework and baseline methods using state-of-the-art LLMs across a suite of real-world medical knowledge and clinical diagnosis benchmarks, including a comparison ofLLMsâ€™ medical complexity classification against human physicians. MDAgents achieved the **best performance in seven out of ten** benchmarks on tasks requiring an understanding of medical knowledge and multi-modal reasoning, showing a significant **improvement of up to 4.2\%** ($p$ < 0.05) compared to previous methods' best performances. Ablation studies reveal that MDAgents effectively determines medical complexity to optimize for efficiency and accuracy across diverse medical tasks. Notably, the combination of moderator review and external medical knowledge in group collaboration resulted in an average accuracy **improvement of 11.8\%**. Our code can be found at https://github.com/mitmedialab/MDAgents.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 6A: Machine Learning and Science, Safety</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=EKdk4vxKO4</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=EKdk4vxKO4</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 6A: Machine Learning and Science, Safety</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 3B: Natural Language Processing</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 2D: Generative Models</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 6A: Machine Learning and Science, Safety</div><h4>tsne_0</h4><div style='margin-bottom:1em'>-0.04494214057922363</div><h4>tsne_1</h4><div style='margin-bottom:1em'>-5.14279842376709</div></body></html>