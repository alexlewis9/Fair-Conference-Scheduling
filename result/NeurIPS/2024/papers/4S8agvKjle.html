<html><head><meta charset='utf-8'><title>AgentBoard_ An Analytical Evaluation Board of Multi-turn LLM Agents</title></head><body><h1>AgentBoard_ An Analytical Evaluation Board of Multi-turn LLM Agents</h1><h3>By: ['Ma Chang', 'Junlei Zhang', 'Zhihao Zhu', 'Cheng Yang', 'Yujiu Yang', 'Yaohui Jin', 'Zhenzhong Lan', 'Lingpeng Kong', 'Junxian He']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>NeurIPS</div><h4>url</h4><div style='margin-bottom:1em'>https://neurips.cc/virtual/2024/oral/98026</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> Evaluating large language models (LLMs) as general-purpose agents is essential for understanding their capabilities and facilitating their integration into practical applications. However, the evaluation process presents substantial challenges. A primary obstacle is the benchmarking of agent performance across diverse scenarios within a unified framework, especially in maintaining partially-observable environments and ensuring multi-round interactions. Moreover, current evaluation frameworks mostly focus on the final success rate, revealing few insights during the process and failing to provide a deep understanding of the model abilities. To address these challenges, we introduce AgentBoard, a pioneering comprehensive benchmark and accompanied open-source evaluation framework tailored to analytical evaluation of LLM agents. AgentBoard offers a fine-grained progress rate metric that captures incremental advancements as well as a comprehensive evaluation toolkit that features easy assessment of agents for multi-faceted analysis through interactive visualization. This not only sheds light on the capabilities and limitations of LLM agents but also propels the interpretability of their performance to the forefront. Ultimately, AgentBoard serves as a significant step towards demystifying agent behaviors and accelerating the development of stronger LLM agents.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 2A: Agents</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://arxiv.org/pdf/2401.13178</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=4S8agvKjle</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 2A: Agents</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 2A: Agents</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 2A: Agents</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 2C: Reinforcement Learning</div><h4>tsne_0</h4><div style='margin-bottom:1em'>-2.536205291748047</div><h4>tsne_1</h4><div style='margin-bottom:1em'>-1.7009824514389038</div></body></html>