<html><head><meta charset='utf-8'><title>NeuroClips_ Towards High-fidelity and Smooth fMRI-to-Video Reconstruction</title></head><body><h1>NeuroClips_ Towards High-fidelity and Smooth fMRI-to-Video Reconstruction</h1><h3>By: ['Zixuan Gong', 'Guangyin Bao', 'Qi Zhang', 'Zhongwei Wan', 'Duoqian Miao', 'Shoujin Wang', 'Lei Zhu', 'Changwei Wang', 'Rongtao Xu', 'Liang Hu', 'Ke Liu', 'Yu Zhang']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>NeurIPS</div><h4>url</h4><div style='margin-bottom:1em'>https://neurips.cc/virtual/2024/oral/97992</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> Reconstruction of static visual stimuli from non-invasion brain activity fMRI achieves great success, owning to advanced deep learning models such as CLIP and Stable Diffusion. However, the research on fMRI-to-video reconstruction remains limited since decoding the spatiotemporal perception of continuous visual experiences is formidably challenging. We contend that the key to addressing these challenges lies in accurately decoding both high-level semantics and low-level perception flows, as perceived by the brain in response to video stimuli. To the end, we propose NeuroClips, an innovative framework to decode high-fidelity and smooth video from fMRI. NeuroClips utilizes a semantics reconstructor to reconstruct video keyframes, guiding semantic accuracy and consistency, and employs a perception reconstructor to capture low-level perceptual details, ensuring video smoothness. During inference, it adopts a pre-trained T2V diffusion model injected with both keyframes and low-level perception flows for video reconstruction. Evaluated on a publicly available fMRI-video dataset, NeuroClips achieves smooth high-fidelity video reconstruction of up to 6s at 8FPS, gaining significant improvements over state-of-the-art models in various metrics, e.g., a 128% improvement in SSIM and an 81% improvement in spatiotemporal metrics. Our project is available at https://github.com/gongzix/NeuroClips.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 1A: Neuroscience and Intepretability</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=8qu52Fl1Dt</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=8qu52Fl1Dt</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 1A: Neuroscience and Intepretability</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 1A: Neuroscience and Intepretability</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 2D: Generative Models</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 2D: Generative Models</div></body></html>