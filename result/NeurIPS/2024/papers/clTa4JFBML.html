<html><head><meta charset='utf-8'><title>Return of Unconditional Generation_ A Self-supervised Representation Generation Method</title></head><body><h1>Return of Unconditional Generation_ A Self-supervised Representation Generation Method</h1><h3>By: ['Tianhong Li', 'Dina Katabi', 'Kaiming He']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>NeurIPS</div><h4>url</h4><div style='margin-bottom:1em'>https://neurips.cc/virtual/2024/oral/97963</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> Unconditional generation -- the problem of modeling data distribution without relying on human-annotated labels -- is a long-standing and fundamental challenge in generative models, creating a potential of learning from large-scale unlabeled data. In the literature, the generation quality of an unconditional method has been much worse than that of its conditional counterpart. This gap can be attributed to the lack of semantic information provided by labels. In this work, we show that one can close this gap by generating semantic representations in the representation space produced by a self-supervised encoder. These representations can be used to condition the image generator. This framework, called Representation-Conditioned Generation (RCG), provides an effective solution to the unconditional generation problem without using labels. Through comprehensive experiments, we observe that RCG significantly improves unconditional generation quality: e.g., it achieves a new state-of-the-art FID of 2.15 on ImageNet 256x256, largely reducing the previous best of 5.91 by a relative 64%. Our unconditional results are situated in the same tier as the leading class-conditional ones. We hope these encouraging observations will attract the community's attention to the fundamental problem of unconditional generation. Code is available at https://github.com/LTH14/rcg .</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 3A: Generative Models</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=clTa4JFBML</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=clTa4JFBML</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 3A: Generative Models</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 2D: Generative Models</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 4C: Diffusion-based Models, Mathematics</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 4C: Diffusion-based Models, Mathematics</div></body></html>