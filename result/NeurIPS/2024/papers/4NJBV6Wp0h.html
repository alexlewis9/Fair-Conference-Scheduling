<html><head><meta charset='utf-8'><title>LLM Evaluators Recognize and Favor Their Own Generations</title></head><body><h1>LLM Evaluators Recognize and Favor Their Own Generations</h1><h3>By: ['Arjun Panickssery', 'Samuel Bowman', 'Shi Feng']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>NeurIPS</div><h4>url</h4><div style='margin-bottom:1em'>https://neurips.cc/virtual/2024/oral/97998</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> Self-evaluation using large language models (LLMs) has proven valuable not only in benchmarking but also methods like reward modeling, constitutional AI, and self-refinement. But new biases are introduced due to the same LLM acting as both the evaluator and the evaluatee. One such bias is self-preference, where an LLM evaluator scores its own outputs higher than othersâ€™ while human annotators consider them of equal quality. But do LLMs actually recognize their own outputs when they give those texts higher scores, or is it just a coincidence? In this paper, we investigate if self-recognition capability contributes to self-preference. We discover that, out of the box, LLMs such as GPT-4 and Llama 2 have non-trivial accuracy at distinguishing themselves from other LLMs and humans. By finetuning LLMs, we discover a linear correlation between self-recognition capability and the strength of self-preference bias; using controlled experiments, we show that the causal explanation resists straightforward confounders. We discuss how self-recognition can interfere with unbiased evaluations and AI safety more generally.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 3C: Natural Language Processing</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=4NJBV6Wp0h</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=4NJBV6Wp0h</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 3C: Natural Language Processing</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 1B: Human-AI Interaction</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 2A: Agents</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 2A: Agents</div></body></html>