<html><head><meta charset='utf-8'><title>Conformal Meta-learners for Predictive Inference of Individual Treatment Effects</title></head><body><h1>Conformal Meta-learners for Predictive Inference of Individual Treatment Effects</h1><h3>By: ['Ahmed Alaa', 'Zaid Ahmad', 'Mark van der Laan']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>NeurIPS</div><h4>url</h4><div style='margin-bottom:1em'>https://neurips.cc/virtual/2023/oral/73862</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> We investigate the problem of machine learning-based (ML) predictive inference on individual treatment effects (ITEs). Previous work has focused primarily on developing ML-based “meta-learners” that can provide point estimates of the conditional average treatment effect (CATE)—these are model-agnostic approaches for combining intermediate nuisance estimates to produce estimates of CATE. In this paper, we develop conformal meta-learners, a general framework for issuing predictive intervals for ITEs by applying the standard conformal prediction (CP) procedure on top of CATE meta-learners. We focus on a broad class of meta-learners based on two-stage pseudo-outcome regression and develop a stochastic ordering framework to study their validity. We show that inference with conformal meta-learners is marginally valid if their (pseudo-outcome) conformity scores stochastically dominate “oracle” conformity scores evaluated on the unobserved ITEs. Additionally, we prove that commonly used CATE meta-learners, such as the doubly-robust learner, satisfy a model- and distribution-free stochastic (or convex) dominance condition, making their conformal inferences valid for practically-relevant levels of target coverage. Whereas existing procedures conduct inference on nuisance parameters (i.e., potential outcomes) via weighted CP, conformal meta-learners enable direct inference on the target parameter (ITE). Numerical experiments show that conformal meta-learners provide valid intervals with competitive efficiency while retaining the favorable point estimation properties of CATE meta-learners.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2C Causality</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=IwnINorSZ5</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=IwnINorSZ5</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2C Causality</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 6D Theory</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 5C Probability/Sampling</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 6C Vision</div></body></html>