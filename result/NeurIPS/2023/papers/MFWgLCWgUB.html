<html><head><meta charset='utf-8'><title>Random Cuts are Optimal for Explainable k-Medians</title></head><body><h1>Random Cuts are Optimal for Explainable k-Medians</h1><h3>By: ['Konstantin Makarychev', 'Liren Shan']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>NeurIPS</div><h4>url</h4><div style='margin-bottom:1em'>https://neurips.cc/virtual/2023/oral/73858</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> We show that the RandomCoordinateCut algorithm gives the optimal competitive ratio for explainable $k$-medians in $\ell_1$. The problem of explainable $k$-medians was introduced by Dasgupta, Frost, Moshkovitz, and Rashtchian in 2020. Several groups of authors independently proposed a simple polynomial-time randomized algorithm for the problem and showed that this algorithm is $O(\log k \log\log k)$ competitive.  We provide a tight analysis of the algorithm and prove that its competitive ratio is upper bounded by $2\ln k+2$. This bound matches the $\Omega(\log k)$ lower bound by Dasgupta et al (2020).</div><h4>session</h4><div style='margin-bottom:1em'>Oral 6D Theory</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=MFWgLCWgUB</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=MFWgLCWgUB</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 6D Theory</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 6D Theory</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 5C Probability/Sampling</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 5C Probability/Sampling</div></body></html>