<html><head><meta charset='utf-8'><title>Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution</title></head><body><h1>Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution</h1><h3>By: ['Ananya Kumar', 'Aditi Raghunathan', 'Robbie Jones', 'Tengyu Ma', 'Percy Liang']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2022/oral/5946</div><h4>year</h4><div style='margin-bottom:1em'>2022</div><h4>abstract</h4><div style='margin-bottom:1em'> When transferring a pretrained model to a downstream task, two popular methods are full fine-tuning (updating all the model parameters) and linear probing (updating only the last linear layer---the "head"). It is well known that fine-tuning leads to better accuracy in-distribution (ID). However, in this paper, we find that fine-tuning can achieve worse accuracy than linear probing out-of-distribution (OOD) when the pretrained features are good and the distribution shift is large. On 10 distribution shift datasets (BREEDS-Living17, BREEDS-Entity30, DomainNet, CIFAR $\to$ STL, CIFAR-10.1, FMoW, ImageNetV2, ImageNet-R, ImageNet-A, ImageNet-Sketch), fine-tuning obtains on average 2% higher accuracy ID but 7% lower accuracy OOD than linear probing. We show theoretically that this tradeoff between ID and OOD accuracy arises even in a simple setting: fine-tuning overparameterized two-layer linear networks. We prove that the OOD error of fine-tuning is high when we initialize with a fixed or random head---this is because while fine-tuning learns the head, the lower layers of the neural network change simultaneously and distort the pretrained features. Our analysis suggests that the easy two-step strategy of linear probing then full fine-tuning (LP-FT), sometimes used as a fine-tuning heuristic, combines the benefits of both fine-tuning and linear probing. Empirically, LP-FT outperforms both fine-tuning and linear probing on the above datasets (1% better ID, 10% better OOD than full fine-tuning).</div><h4>session</h4><div style='margin-bottom:1em'>Oral 3: Learning from distribution shift</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=UYneFzXSJWh</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=UYneFzXSJWh</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 3: Learning from distribution shift</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 3: Learning from distribution shift</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 3: Learning from distribution shift</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 3: Meta-learning and adaptation</div></body></html>