<html><head><meta charset='utf-8'><title>iLQR-VAE _ control-based learning of input-driven dynamics with applications to neural data</title></head><body><h1>iLQR-VAE _ control-based learning of input-driven dynamics with applications to neural data</h1><h3>By: ['Marine Schimel', 'Ta-Chu Kao', 'Kristopher Jensen', 'Guillaume Hennequin']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2022/oral/6080</div><h4>year</h4><div style='margin-bottom:1em'>2022</div><h4>abstract</h4><div style='margin-bottom:1em'> Understanding how neural dynamics give rise to behaviour is one of the most fundamental questions in systems neuroscience. To achieve this, a common approach is to record neural populations in behaving animals, and model these data as emanating from a latent dynamical system whose state trajectories can then be related back to behavioural observations via some form of decoding. As recordings are typically performed in localized circuits that form only a part of the wider implicated network, it is important to simultaneously learn the local dynamics and infer any unobserved external input that might drive them. Here, we introduce iLQR-VAE, a novel control-based approach to variational inference in nonlinear dynamical systems, capable of learning both latent dynamics, initial conditions, and ongoing external inputs. As in recent deep learning approaches, our method is based on an input-driven sequential variational autoencoder (VAE). The main novelty lies in the use of the powerful iterative linear quadratic regulator algorithm (iLQR) in the recognition model. Optimization of the standard evidence lower-bound requires differentiating through iLQR solutions, which is made possible by recent advances in differentiable control. Importantly, having the recognition model be implicitly defined by the generative model greatly reduces the number of free parameters and allows for flexible, high-quality inference. This makes it possible for instance to evaluate the model on a single long trial after training on smaller chunks. We demonstrate the effectiveness of iLQR-VAE on a range of synthetic systems, with autonomous as well as input-driven dynamics. We further apply it to neural and behavioural recordings in non-human primates performing two different reaching tasks, and show that iLQR-VAE yields high-quality kinematic reconstructions from the neural data.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2: AI applications</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=wRODLDHaAiW</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=wRODLDHaAiW</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2: AI applications</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 2: Structured learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 3: Meta-learning and adaptation</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 2: AI applications</div></body></html>