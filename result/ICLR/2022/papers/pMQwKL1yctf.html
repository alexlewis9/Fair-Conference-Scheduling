<html><head><meta charset='utf-8'><title>Language modeling via stochastic processes</title></head><body><h1>Language modeling via stochastic processes</h1><h3>By: ['Rose Wang', 'Esin Durmus', 'Noah Goodman', 'Tatsunori Hashimoto']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2022/oral/5951</div><h4>year</h4><div style='margin-bottom:1em'>2022</div><h4>abstract</h4><div style='margin-bottom:1em'> Modern language models can generate high-quality short texts. However, they often meander or are incoherent when generating longer texts. These issues arise from the next-token-only language modeling objective. To address these issues, we introduce Time Control (TC), a language model that implicitly plans via a latent stochastic process. TC does this by learning a representation which maps the dynamics of how text changes in a document to the dynamics of a stochastic process of interest. Using this representation, the language model can generate text by first implicitly generating a document plan via a stochastic process, and then generating text that is consistent with this latent plan. Compared to domain-specific methods and fine-tuning GPT2 across a variety of text domains, TC improves performance on text infilling and discourse coherence. On long text generation settings, TC preserves the text structure both in terms of ordering (up to +40% better) and text length consistency (up to +17% better).  Human evaluators also prefer TC's output 28.6% more than the baselines.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 1: AI Applications</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=pMQwKL1yctf</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=pMQwKL1yctf</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 1: AI Applications</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 3: Meta-learning and adaptation</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 4: Sequence modeling</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 4: Sequence modeling</div></body></html>