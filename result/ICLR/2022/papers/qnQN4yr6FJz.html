<html><head><meta charset='utf-8'><title>Variational Inference for Discriminative Learning with Generative Modeling of Feature Incompletion</title></head><body><h1>Variational Inference for Discriminative Learning with Generative Modeling of Feature Incompletion</h1><h3>By: ['Kohei Miyaguchi', 'Takayuki Katsuki', 'Akira Koseki', 'Toshiya Iwamori']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2022/oral/6534</div><h4>year</h4><div style='margin-bottom:1em'>2022</div><h4>abstract</h4><div style='margin-bottom:1em'> We are concerned with the problem of distributional prediction with incomplete features: The goal is to estimate the distribution of target variables given feature vectors with some of the elements missing. A typical approach to this problem is to perform missing-value imputation and regression, simultaneously or sequentially, which we call the generative approach. Another approach is to perform regression after appropriately encoding missing values into the feature, which we call the discriminative approach. In comparison, the generative approach is more robust to the feature corruption while the discriminative approach is more favorable to maximize the performance of prediction. In this study, we propose a hybrid method to take the best of both worlds. Our method utilizes the black-box variational inference framework so that it can be applied to a wide variety of modern machine learning models, including the variational autoencoders. We also confirmed the effectiveness of the proposed method empirically.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2: Structured learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=qnQN4yr6FJz</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=qnQN4yr6FJz</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2: Structured learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 4: Sequence modeling</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 4: Probablistic Models, Vision</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 3: Meta-learning and adaptation</div></body></html>