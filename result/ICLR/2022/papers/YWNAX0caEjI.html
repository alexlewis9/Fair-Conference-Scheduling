<html><head><meta charset='utf-8'><title>Neural Structured Prediction for Inductive Node Classification</title></head><body><h1>Neural Structured Prediction for Inductive Node Classification</h1><h3>By: ['Meng Qu', 'Huiyu Cai', 'Jian Tang']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2022/oral/5948</div><h4>year</h4><div style='margin-bottom:1em'>2022</div><h4>abstract</h4><div style='margin-bottom:1em'> This paper studies node classification in the inductive setting, i.e., aiming to learn a model on labeled training graphs and generalize it to infer node labels on unlabeled test graphs. This problem has been extensively studied with graph neural networks (GNNs) by learning effective node representations, as well as traditional structured prediction methods for modeling the structured output of node labels, e.g., conditional random fields (CRFs). In this paper, we present a new approach called the Structured Proxy Network (SPN), which combines the advantages of both worlds. SPN defines flexible potential functions of CRFs with GNNs. However, learning such a model is nontrivial as it involves optimizing a maximin game with high-cost inference. Inspired by the underlying connection between joint and marginal distributions defined by Markov networks, we propose to solve an approximate version of the optimization problem as a proxy, which yields a near-optimal solution, making learning more efficient. Extensive experiments on two settings show that our approach outperforms many competitive baselines.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2: Structured learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=YWNAX0caEjI</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=YWNAX0caEjI</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2: Structured learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 3: Learning from distribution shift</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 2: Structured learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 2: Structured learning</div></body></html>