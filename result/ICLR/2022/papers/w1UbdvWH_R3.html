<html><head><meta charset='utf-8'><title>Neural Collapse Under MSE Loss_ Proximity to and Dynamics on the Central Path</title></head><body><h1>Neural Collapse Under MSE Loss_ Proximity to and Dynamics on the Central Path</h1><h3>By: ['X.Y. Han', 'Vardan Papyan', 'David Donoho']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2022/oral/6353</div><h4>year</h4><div style='margin-bottom:1em'>2022</div><h4>abstract</h4><div style='margin-bottom:1em'> The recently discovered Neural Collapse (NC) phenomenon occurs pervasively in today's deep net training paradigm of driving cross-entropy (CE) loss towards zero. During NC, last-layer features collapse to their class-means, both classifiers and class-means collapse to the same Simplex Equiangular Tight Frame, and classifier behavior collapses to the nearest-class-mean decision rule. Recent works demonstrated that deep nets trained with mean squared error (MSE) loss perform comparably to those trained with CE. As a preliminary, we empirically establish that NC emerges in such MSE-trained deep nets as well through experiments on three canonical networks and five benchmark datasets. We provide, in a Google Colab notebook, PyTorch code for reproducing MSE-NC and CE-NC: https://colab.research.google.com/github/neuralcollapse/neuralcollapse/blob/main/neuralcollapse.ipynb. The analytically-tractable MSE loss offers more mathematical opportunities than the hard-to-analyze CE loss, inspiring us to leverage MSE loss towards the theoretical investigation of NC. We develop three main contributions: (I) We show a new decomposition of the MSE loss into (A) terms directly interpretable through the lens of NC and which assume the last-layer classifier is exactly the least-squares classifier; and (B) a term capturing the deviation from this least-squares classifier. (II) We exhibit experiments on canonical datasets and networks demonstrating that term-(B) is negligible during training. This motivates us to introduce a new theoretical construct: the central path, where the linear classifier stays MSE-optimal for feature activations throughout the dynamics. (III) By studying renormalized gradient flow along the central path, we derive exact dynamics that predict NC.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2: Understanding Deep Learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=w1UbdvWH_R3</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=w1UbdvWH_R3</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2: Understanding Deep Learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 4: Sequence modeling</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 2: Understanding Deep Learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 2: Understanding Deep Learning</div></body></html>