<html><head><meta charset='utf-8'><title>Open-Set Recognition_ A Good Closed-Set Classifier is All You Need</title></head><body><h1>Open-Set Recognition_ A Good Closed-Set Classifier is All You Need</h1><h3>By: ['Sagar Vaze', 'Kai Han', 'Andrea Vedaldi', 'Andrew Zisserman']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2022/oral/6728</div><h4>year</h4><div style='margin-bottom:1em'>2022</div><h4>abstract</h4><div style='margin-bottom:1em'> The ability to identify whether or not a test sample belongs to one of the semantic classes in a classifier's training set is critical to practical deployment of the model. This task is termed open-set recognition (OSR) and has received significant attention in recent years. In this paper, we first demonstrate that the ability of a classifier to make the 'none-of-above' decision is highly correlated with its accuracy on the closed-set classes. We find that this relationship holds across loss objectives and architectures, and further demonstrate the trend both on the standard OSR benchmarks as well as on a large-scale ImageNet evaluation. Second, we use this correlation to boost the performance of the maximum softmax probability OSR 'baseline' by improving its closed-set accuracy, and with this strong baseline achieve state-of-the-art on a number of OSR benchmarks. Similarly, we boost the performance of the existing state-of-the-art method by improving its closed-set accuracy, but the resulting discrepancy with the strong baseline is marginal. Our third contribution is to present the 'Semantic Shift Benchmark' (SSB), which better respects the task of detecting semantic novelty, as opposed to low-level distributional shifts as tackled by neighbouring machine learning fields. On this new evaluation, we again demonstrate that there is negligible difference between the strong baseline and the existing state-of-the-art. Code available at: https://github.com/sgvaze/osr closed set all you_need.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 1: AI Applications</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=5hLP5JY9S2d</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=5hLP5JY9S2d</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 1: AI Applications</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 2: AI applications</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 3: Learning from distribution shift</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 3: Meta-learning and adaptation</div></body></html>