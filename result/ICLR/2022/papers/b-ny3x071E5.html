<html><head><meta charset='utf-8'><title>Bootstrapped Meta-Learning</title></head><body><h1>Bootstrapped Meta-Learning</h1><h3>By: ['Sebastian Flennerhag', 'Yannick Schroecker', 'Tom Zahavy', 'Hado van Hasselt', 'David Silver', 'Satinder Singh']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2022/oral/6253</div><h4>year</h4><div style='margin-bottom:1em'>2022</div><h4>abstract</h4><div style='margin-bottom:1em'> Meta-learning empowers artificial intelligence to increase its efficiency by learning how to learn. Unlocking this potential involves overcoming a challenging meta-optimisation problem. We propose an algorithm that tackles this problem by letting the meta-learner teach itself. The algorithm first bootstraps a target from the meta-learner, then optimises the meta-learner by minimising the distance to that target under a chosen (pseudo-)metric. Focusing on meta-learning with gradients, we establish conditions that guarantee performance improvements and show that metric can be used to control meta-optimisation. Meanwhile, the bootstrapping mechanism can extend the effective meta-learning horizon without requiring backpropagation through all updates. We achieve a new state-of-the art for model-free agents on the Atari ALE benchmark and demonstrate that it yields both performance and efficiency gains in multi-task meta-learning. Finally, we explore how bootstrapping opens up new possibilities and find that it can meta-learn efficient exploration in an epsilon-greedy Q-learning agent - without backpropagating through the update rule.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 3: Meta-learning and adaptation</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=b-ny3x071E5</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=b-ny3x071E5</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 3: Meta-learning and adaptation</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 3: Meta-learning and adaptation</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 1: Learning in the wild,  Reinforcement learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 1: Learning in the wild,  Reinforcement learning</div></body></html>