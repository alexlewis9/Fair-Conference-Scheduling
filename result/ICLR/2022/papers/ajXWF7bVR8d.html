<html><head><meta charset='utf-8'><title>Meta-Learning with Fewer Tasks through Task Interpolation</title></head><body><h1>Meta-Learning with Fewer Tasks through Task Interpolation</h1><h3>By: ['Huaxiu Yao', 'Linjun Zhang', 'Chelsea Finn']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2022/oral/7141</div><h4>year</h4><div style='margin-bottom:1em'>2022</div><h4>abstract</h4><div style='margin-bottom:1em'> Meta-learning enables algorithms to quickly learn a newly encountered task with just a few labeled examples by transferring previously learned knowledge. However, the bottleneck of current meta-learning algorithms is the requirement of a large number of meta-training tasks, which may not be accessible in real-world scenarios. To address the challenge that available tasks may not densely sample the space of tasks, we propose to augment the task set through interpolation. By meta-learning with task interpolation (MLTI), our approach effectively generates additional tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels. Under both gradient-based and metric-based meta-learning settings, our theoretical analysis shows MLTI corresponds to a data-adaptive meta-regularization and further improves the generalization. Empirically, in our experiments on eight datasets from diverse domains including image recognition, pose prediction, molecule property prediction, and medical image classification, we find that the proposed general MLTI framework is compatible with representative meta-learning algorithms and consistently outperforms other state-of-the-art strategies.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 3: Meta-learning and adaptation</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=ajXWF7bVR8d</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=ajXWF7bVR8d</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 3: Meta-learning and adaptation</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 3: Meta-learning and adaptation</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 3: Learning from distribution shift</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 3: Meta-learning and adaptation</div></body></html>