{
  "Baseline": {
    "Oral 1A": [
      "agPpmEgf8C: Predictive auxiliary objectives in deep RL mimic learning in the brain",
      "xuY33XhEGR: ClimODE_ Climate and Weather Forecasting with Physics-informed Neural ODEs",
      "zMPHKOmQNb: Protein Discovery with Discrete Walk-Jump Sampling"
    ],
    "Oral 1B": [
      "9JQtrumvg8: A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",
      "jNR6s6OSBT: ASID_ Active Exploration for System Identification in Robotic Manipulation",
      "sFyTZEqmUY: Learning Interactive Real-World Simulators"
    ],
    "Oral 1C": [
      "6PmJoRfdaK: LongLoRA_ Efficient Fine-tuning of Long-Context Large Language Models",
      "KUNzEQMWU7: MathVista_ Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts",
      "uNrFpDPMyo: Model Tells You What to Discard_ Adaptive KV Cache Compression for LLMs"
    ],
    "Oral 1D": [
      "gFR4QwK53h: Gene Regulatory Network Inference in the Presence of Dropouts_ a Causal View",
      "pOoKI3ouv1: Robust agents learn causal world models"
    ],
    "Oral 2A": [
      "VtmBAGCN7o: MetaGPT_ Meta Programming for A Multi-Agent Collaborative Framework",
      "ekeyCgeRfC: Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions",
      "hSyW5go0v8: Self-RAG_ Learning to Retrieve, Generate, and Critique through Self-Reflection"
    ],
    "Oral 2B": [
      "2dnO3LLiJ1: Vision Transformers Need Registers",
      "Ad87VjRqUw: Ghost on the Shell_ An Expressive Representation of General 3D Shapes",
      "sllU8vvsFF: LRM_ Large Reconstruction Model for Single Image to 3D"
    ],
    "Oral 2C": [
      "WNkW0cOwiz: Lipschitz Singularities in Diffusion Models",
      "WNzy9bRDvG: Improved Techniques for Training Consistency Models",
      "gU58d5QeGv: W\u00fcrstchen_ An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models"
    ],
    "Oral 2D": [
      "HSKaGOi7Ar: Beyond Weisfeiler-Lehman_ A Quantitative Framework for GNN Expressiveness",
      "aN4Jf6Cx69: The mechanistic basis of data dependence and abrupt learning in an in-context classification task"
    ],
    "Oral 3A": [
      "LzPWWPAdY4: LoftQ_ LoRA-Fine-Tuning-aware Quantization for Large Language Models",
      "bNt7oajl2a: Phenomenal Yet Puzzling_ Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement",
      "osoWxY8q2E: ReLU Strikes Back_ Exploiting Activation Sparsity in Large Language Models"
    ],
    "Oral 3B": [
      "NSVtmmzeRB: Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks",
      "P15CHILQlg: Learning Energy Decompositions for Partial Inference in GFlowNets",
      "EanCFCwAjM: Cameras as Rays_ Pose Estimation via Ray Diffusion"
    ],
    "Oral 3C": [
      "L0r0GphlIL: Improving Convergence and Generalization Using Parameter Symmetries",
      "TpD2aG1h0D: Meta Continual Learning Revisited_ Implicitly Enhancing Online Hessian Approximation via Variance Reduction",
      "cc8h3I3V4E: Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization"
    ],
    "Oral 3D": [
      "AhizIPytk4: How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks_",
      "yV6fD7LYkF: ValUES_ A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation"
    ],
    "Oral 4A": [
      "VTF8yNQM66: SWE-bench_ Can Language Models Resolve Real-world Github Issues_",
      "w4abltTZ2f: Batched Low-Rank Adaptation of Foundation Models"
    ],
    "Oral 4B": [
      "dLrhRIMVmB: Topological data analysis on noisy quantum computers",
      "g7ohDlTITL: Flow Matching on General Geometries",
      "oO6FsMyDBt: Graph Neural Networks for Learning Equivariant Representations of Neural Networks"
    ],
    "Oral 4C": [
      "LjivA1SLZ6: Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning",
      "c5pwL0Soay: METRA_ Scalable Unsupervised RL with Metric-Aware Abstraction",
      "o2IEmeLL9r: Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning"
    ],
    "Oral 4D": [
      "Ouj6p4ca60: Amortizing intractable inference in large language models",
      "nHESwXvxWK: Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems."
    ],
    "Oral 5A": [
      "ANvmVS2Yr0: Generalization in diffusion models arises from geometry-adaptive harmonic representations",
      "Zsfiqpft6K: Diffusion Model for Dense Matching",
      "tUtGjQEDd4: Generative Modeling with Phase Stochastic Bridge"
    ],
    "Oral 5B": [
      "hTEGyKf0dZ: Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!",
      "hnrB5YHoYu: Finetuning Text-to-Image Diffusion Models for Fairness",
      "jr03SfWsBS: Unprocessing Seven Years of Algorithmic Fairness"
    ],
    "Oral 5C": [
      "T7YV5UZKBc: Neural Fine-Tuning Search for Few-Shot Learning",
      "bTMMNT7IdW: Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time",
      "tqh1zdXIra: Quick-Tune_ Quickly Learning Which Pretrained Model to Finetune and How"
    ],
    "Oral 5D": [
      "5Ca9sSzuDp: Interpreting CLIP's Image Representation via Text-Based Decomposition",
      "Yen1lGns2o: Is ImageNet worth 1 video_ Learning strong image encoders from 1 long unlabelled video"
    ],
    "Oral 6A": [
      "h922Qhkmx1: Multi-Source Diffusion Models for Simultaneous Music Generation and Separation",
      "oTRwljRgiv: ExeDec_ Execution Decomposition for Compositional Generalization in Neural Program Synthesis",
      "pzElnMrgSD: How I Warped Your Noise_ a Temporally-Correlated Noise Prior for Diffusion Models"
    ],
    "Oral 6B": [
      "IGzaH538fz: GNNCert_ Deterministic Certification of Graph Neural Networks against Adversarial Perturbations",
      "KS8mIvetg2: Proving Test Set Contamination in Black-Box Language Models",
      "aIok3ZD9to: LLMCarbon_ Modeling the End-to-End Carbon Footprint of Large Language Models"
    ],
    "Oral 6C": [
      "Fk5IzauJ7F: Candidate Label Set Pruning_ A Data-centric Perspective for Deep Partial-label Learning",
      "HhfcNgQn6p: Towards a statistical theory of data selection under weak supervision",
      "PdaPky8MUn: Never Train from Scratch_ Fair Comparison of Long-Sequence Models Requires Data-Driven Priors"
    ],
    "Oral 6D": [
      "9Cu8MRmhq2: Multi-granularity Correspondence Learning from Long-term Noisy Videos",
      "9WD9KwssyT: Zipformer_ A faster and better encoder for automatic speech recognition"
    ],
    "Oral 7A": [
      "d8w0pmvXbZ: Small-scale proxies for large-scale Transformer training instabilities",
      "mE52zURNGc: An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment",
      "v7ZPwoHU1j: Statistically Optimal $K$-means Clustering via Nonnegative Low-rank Semidefinite Programming"
    ],
    "Oral 7B": [
      "UyNXMqnN3c: DreamGaussian_ Generative Gaussian Splatting for Efficient 3D Content Creation",
      "HE9eUQlAvo: _What Data Benefits My Classifier__ Enhancing Model Performance and Interpretability through Influence-Based Data Selection",
      "WbWtOYIzIK: Knowledge Card_ Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models"
    ],
    "Oral 7C": [
      "jKTUlxo5zy: Less is More_ Fewer Interpretable Region via Submodular Subset Selection",
      "ze7DOLi394: On the Joint Interaction of Models, Data, and Features"
    ],
    "Oral 7D": [
      "0BqyZSWfzo: One-shot Empirical Privacy Estimation for Federated Learning",
      "H3UayAQWoE: On the Humanity of Conversational AI_ Evaluating the Psychological Portrayal of LLMs"
    ],
    "Oral 8A": [
      "1oijHJBRsT: Self-Alignment with Instruction Backtranslation",
      "4Ay23yeuz0: Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space",
      "84n3UwkH7b: Detecting, Explaining, and Mitigating Memorization in Diffusion Models"
    ],
    "Oral 8B": [
      "BV1PHbTJzd: Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks",
      "C61sk5LsK6: InfoBatch_ Lossless Training Speed Up by Unbiased Dynamic Data Pruning",
      "IYxDy2jDFL: Improved Active Learning via Dependent Leverage Score Sampling"
    ],
    "Oral 8C": [
      "1vDArHJ68h: Mastering Memory Tasks with World Models",
      "3f5PALef5B: LEGO-Prover_ Neural Theorem Proving with Growing Libraries"
    ],
    "Oral 8D": [
      "7VPTUWkiDQ: Provable Compositional Generalization for Object-Centric Learning",
      "FVhmnvqnsI: Multisize Dataset Condensation",
      "7Ttk3RzDeu: BooookScore_ A systematic exploration of book-length summarization in the era of LLMs"
    ]
  },
  "GreedyCohesive": {
    "Oral 1A": [
      "aIok3ZD9to: LLMCarbon_ Modeling the End-to-End Carbon Footprint of Large Language Models",
      "xuY33XhEGR: ClimODE_ Climate and Weather Forecasting with Physics-informed Neural ODEs",
      "9JQtrumvg8: A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis"
    ],
    "Oral 1B": [
      "jNR6s6OSBT: ASID_ Active Exploration for System Identification in Robotic Manipulation",
      "sFyTZEqmUY: Learning Interactive Real-World Simulators",
      "c5pwL0Soay: METRA_ Scalable Unsupervised RL with Metric-Aware Abstraction"
    ],
    "Oral 1C": [
      "6PmJoRfdaK: LongLoRA_ Efficient Fine-tuning of Long-Context Large Language Models",
      "LzPWWPAdY4: LoftQ_ LoRA-Fine-Tuning-aware Quantization for Large Language Models",
      "Ouj6p4ca60: Amortizing intractable inference in large language models"
    ],
    "Oral 1D": [
      "HhfcNgQn6p: Towards a statistical theory of data selection under weak supervision",
      "HE9eUQlAvo: _What Data Benefits My Classifier__ Enhancing Model Performance and Interpretability through Influence-Based Data Selection",
      "gFR4QwK53h: Gene Regulatory Network Inference in the Presence of Dropouts_ a Causal View"
    ],
    "Oral 2A": [
      "TpD2aG1h0D: Meta Continual Learning Revisited_ Implicitly Enhancing Online Hessian Approximation via Variance Reduction",
      "VtmBAGCN7o: MetaGPT_ Meta Programming for A Multi-Agent Collaborative Framework",
      "WNzy9bRDvG: Improved Techniques for Training Consistency Models"
    ],
    "Oral 2B": [
      "sllU8vvsFF: LRM_ Large Reconstruction Model for Single Image to 3D",
      "AhizIPytk4: How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks_",
      "EanCFCwAjM: Cameras as Rays_ Pose Estimation via Ray Diffusion"
    ],
    "Oral 2C": [
      "bTMMNT7IdW: Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time",
      "WNkW0cOwiz: Lipschitz Singularities in Diffusion Models",
      "tUtGjQEDd4: Generative Modeling with Phase Stochastic Bridge"
    ],
    "Oral 2D": [
      "pOoKI3ouv1: Robust agents learn causal world models",
      "aN4Jf6Cx69: The mechanistic basis of data dependence and abrupt learning in an in-context classification task",
      "agPpmEgf8C: Predictive auxiliary objectives in deep RL mimic learning in the brain"
    ],
    "Oral 3B": [
      "NSVtmmzeRB: Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks",
      "UyNXMqnN3c: DreamGaussian_ Generative Gaussian Splatting for Efficient 3D Content Creation",
      "zMPHKOmQNb: Protein Discovery with Discrete Walk-Jump Sampling"
    ],
    "Oral 3D": [
      "yV6fD7LYkF: ValUES_ A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation",
      "jKTUlxo5zy: Less is More_ Fewer Interpretable Region via Submodular Subset Selection",
      "7Ttk3RzDeu: BooookScore_ A systematic exploration of book-length summarization in the era of LLMs"
    ],
    "Oral 4A": [
      "w4abltTZ2f: Batched Low-Rank Adaptation of Foundation Models",
      "jr03SfWsBS: Unprocessing Seven Years of Algorithmic Fairness"
    ],
    "Oral 4B": [
      "v7ZPwoHU1j: Statistically Optimal $K$-means Clustering via Nonnegative Low-rank Semidefinite Programming",
      "dLrhRIMVmB: Topological data analysis on noisy quantum computers",
      "L0r0GphlIL: Improving Convergence and Generalization Using Parameter Symmetries"
    ],
    "Oral 4C": [
      "LjivA1SLZ6: Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning",
      "o2IEmeLL9r: Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning",
      "1vDArHJ68h: Mastering Memory Tasks with World Models"
    ],
    "Oral 4D": [
      "pzElnMrgSD: How I Warped Your Noise_ a Temporally-Correlated Noise Prior for Diffusion Models",
      "9Cu8MRmhq2: Multi-granularity Correspondence Learning from Long-term Noisy Videos",
      "nHESwXvxWK: Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems."
    ],
    "Oral 5A": [
      "ANvmVS2Yr0: Generalization in diffusion models arises from geometry-adaptive harmonic representations",
      "h922Qhkmx1: Multi-Source Diffusion Models for Simultaneous Music Generation and Separation",
      "Ad87VjRqUw: Ghost on the Shell_ An Expressive Representation of General 3D Shapes"
    ],
    "Oral 5B": [
      "Zsfiqpft6K: Diffusion Model for Dense Matching",
      "mE52zURNGc: An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment",
      "hnrB5YHoYu: Finetuning Text-to-Image Diffusion Models for Fairness"
    ],
    "Oral 5C": [
      "tqh1zdXIra: Quick-Tune_ Quickly Learning Which Pretrained Model to Finetune and How",
      "T7YV5UZKBc: Neural Fine-Tuning Search for Few-Shot Learning",
      "PdaPky8MUn: Never Train from Scratch_ Fair Comparison of Long-Sequence Models Requires Data-Driven Priors"
    ],
    "Oral 5D": [
      "Yen1lGns2o: Is ImageNet worth 1 video_ Learning strong image encoders from 1 long unlabelled video",
      "2dnO3LLiJ1: Vision Transformers Need Registers",
      "0BqyZSWfzo: One-shot Empirical Privacy Estimation for Federated Learning"
    ],
    "Oral 6A": [
      "P15CHILQlg: Learning Energy Decompositions for Partial Inference in GFlowNets",
      "oTRwljRgiv: ExeDec_ Execution Decomposition for Compositional Generalization in Neural Program Synthesis",
      "g7ohDlTITL: Flow Matching on General Geometries"
    ],
    "Oral 6B": [
      "oO6FsMyDBt: Graph Neural Networks for Learning Equivariant Representations of Neural Networks",
      "IGzaH538fz: GNNCert_ Deterministic Certification of Graph Neural Networks against Adversarial Perturbations",
      "HSKaGOi7Ar: Beyond Weisfeiler-Lehman_ A Quantitative Framework for GNN Expressiveness"
    ],
    "Oral 6C": [
      "C61sk5LsK6: InfoBatch_ Lossless Training Speed Up by Unbiased Dynamic Data Pruning",
      "FVhmnvqnsI: Multisize Dataset Condensation",
      "Fk5IzauJ7F: Candidate Label Set Pruning_ A Data-centric Perspective for Deep Partial-label Learning"
    ],
    "Oral 6D": [
      "9WD9KwssyT: Zipformer_ A faster and better encoder for automatic speech recognition",
      "4Ay23yeuz0: Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space",
      "5Ca9sSzuDp: Interpreting CLIP's Image Representation via Text-Based Decomposition"
    ],
    "Oral 7A": [
      "d8w0pmvXbZ: Small-scale proxies for large-scale Transformer training instabilities",
      "osoWxY8q2E: ReLU Strikes Back_ Exploiting Activation Sparsity in Large Language Models",
      "ekeyCgeRfC: Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions"
    ],
    "Oral 7B": [
      "uNrFpDPMyo: Model Tells You What to Discard_ Adaptive KV Cache Compression for LLMs",
      "WbWtOYIzIK: Knowledge Card_ Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models",
      "84n3UwkH7b: Detecting, Explaining, and Mitigating Memorization in Diffusion Models"
    ],
    "Oral 7C": [
      "7VPTUWkiDQ: Provable Compositional Generalization for Object-Centric Learning",
      "gU58d5QeGv: W\u00fcrstchen_ An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models",
      "ze7DOLi394: On the Joint Interaction of Models, Data, and Features"
    ],
    "Oral 7D": [
      "H3UayAQWoE: On the Humanity of Conversational AI_ Evaluating the Psychological Portrayal of LLMs",
      "VTF8yNQM66: SWE-bench_ Can Language Models Resolve Real-world Github Issues_",
      "hTEGyKf0dZ: Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!"
    ],
    "Oral 8A": [
      "1oijHJBRsT: Self-Alignment with Instruction Backtranslation",
      "KS8mIvetg2: Proving Test Set Contamination in Black-Box Language Models",
      "hSyW5go0v8: Self-RAG_ Learning to Retrieve, Generate, and Critique through Self-Reflection"
    ],
    "Oral 8B": [
      "BV1PHbTJzd: Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks",
      "IYxDy2jDFL: Improved Active Learning via Dependent Leverage Score Sampling",
      "cc8h3I3V4E: Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization"
    ],
    "Oral 8C": [
      "3f5PALef5B: LEGO-Prover_ Neural Theorem Proving with Growing Libraries",
      "bNt7oajl2a: Phenomenal Yet Puzzling_ Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement",
      "KUNzEQMWU7: MathVista_ Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts"
    ]
  },
  "KMedoids": {
    "Oral 1A": [
      "agPpmEgf8C: Predictive auxiliary objectives in deep RL mimic learning in the brain"
    ],
    "Oral 1B": [
      "jNR6s6OSBT: ASID_ Active Exploration for System Identification in Robotic Manipulation",
      "c5pwL0Soay: METRA_ Scalable Unsupervised RL with Metric-Aware Abstraction",
      "sFyTZEqmUY: Learning Interactive Real-World Simulators"
    ],
    "Oral 1C": [
      "6PmJoRfdaK: LongLoRA_ Efficient Fine-tuning of Long-Context Large Language Models",
      "LzPWWPAdY4: LoftQ_ LoRA-Fine-Tuning-aware Quantization for Large Language Models",
      "Ouj6p4ca60: Amortizing intractable inference in large language models",
      "w4abltTZ2f: Batched Low-Rank Adaptation of Foundation Models",
      "uNrFpDPMyo: Model Tells You What to Discard_ Adaptive KV Cache Compression for LLMs",
      "WbWtOYIzIK: Knowledge Card_ Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models",
      "7Ttk3RzDeu: BooookScore_ A systematic exploration of book-length summarization in the era of LLMs"
    ],
    "Oral 1D": [
      "pOoKI3ouv1: Robust agents learn causal world models"
    ],
    "Oral 2A": [
      "9JQtrumvg8: A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",
      "VtmBAGCN7o: MetaGPT_ Meta Programming for A Multi-Agent Collaborative Framework",
      "TpD2aG1h0D: Meta Continual Learning Revisited_ Implicitly Enhancing Online Hessian Approximation via Variance Reduction"
    ],
    "Oral 2B": [
      "2dnO3LLiJ1: Vision Transformers Need Registers"
    ],
    "Oral 2C": [
      "WNkW0cOwiz: Lipschitz Singularities in Diffusion Models",
      "ANvmVS2Yr0: Generalization in diffusion models arises from geometry-adaptive harmonic representations",
      "nHESwXvxWK: Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems.",
      "Zsfiqpft6K: Diffusion Model for Dense Matching",
      "gU58d5QeGv: W\u00fcrstchen_ An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models",
      "pzElnMrgSD: How I Warped Your Noise_ a Temporally-Correlated Noise Prior for Diffusion Models",
      "84n3UwkH7b: Detecting, Explaining, and Mitigating Memorization in Diffusion Models"
    ],
    "Oral 2D": [
      "ekeyCgeRfC: Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions",
      "aN4Jf6Cx69: The mechanistic basis of data dependence and abrupt learning in an in-context classification task"
    ],
    "Oral 3A": [
      "KUNzEQMWU7: MathVista_ Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts",
      "bNt7oajl2a: Phenomenal Yet Puzzling_ Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement",
      "3f5PALef5B: LEGO-Prover_ Neural Theorem Proving with Growing Libraries"
    ],
    "Oral 3B": [
      "NSVtmmzeRB: Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks",
      "UyNXMqnN3c: DreamGaussian_ Generative Gaussian Splatting for Efficient 3D Content Creation",
      "P15CHILQlg: Learning Energy Decompositions for Partial Inference in GFlowNets",
      "g7ohDlTITL: Flow Matching on General Geometries",
      "zMPHKOmQNb: Protein Discovery with Discrete Walk-Jump Sampling"
    ],
    "Oral 3C": [
      "cc8h3I3V4E: Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization"
    ],
    "Oral 3D": [
      "7VPTUWkiDQ: Provable Compositional Generalization for Object-Centric Learning",
      "yV6fD7LYkF: ValUES_ A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation"
    ],
    "Oral 4A": [
      "VTF8yNQM66: SWE-bench_ Can Language Models Resolve Real-world Github Issues_",
      "H3UayAQWoE: On the Humanity of Conversational AI_ Evaluating the Psychological Portrayal of LLMs"
    ],
    "Oral 4B": [
      "dLrhRIMVmB: Topological data analysis on noisy quantum computers"
    ],
    "Oral 4C": [
      "LjivA1SLZ6: Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning",
      "o2IEmeLL9r: Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning"
    ],
    "Oral 4D": [
      "xuY33XhEGR: ClimODE_ Climate and Weather Forecasting with Physics-informed Neural ODEs"
    ],
    "Oral 5A": [
      "9Cu8MRmhq2: Multi-granularity Correspondence Learning from Long-term Noisy Videos",
      "hnrB5YHoYu: Finetuning Text-to-Image Diffusion Models for Fairness",
      "bTMMNT7IdW: Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time",
      "oTRwljRgiv: ExeDec_ Execution Decomposition for Compositional Generalization in Neural Program Synthesis",
      "ze7DOLi394: On the Joint Interaction of Models, Data, and Features",
      "4Ay23yeuz0: Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space",
      "tUtGjQEDd4: Generative Modeling with Phase Stochastic Bridge",
      "v7ZPwoHU1j: Statistically Optimal $K$-means Clustering via Nonnegative Low-rank Semidefinite Programming"
    ],
    "Oral 5B": [
      "jr03SfWsBS: Unprocessing Seven Years of Algorithmic Fairness"
    ],
    "Oral 5C": [
      "T7YV5UZKBc: Neural Fine-Tuning Search for Few-Shot Learning",
      "tqh1zdXIra: Quick-Tune_ Quickly Learning Which Pretrained Model to Finetune and How"
    ],
    "Oral 5D": [
      "5Ca9sSzuDp: Interpreting CLIP's Image Representation via Text-Based Decomposition"
    ],
    "Oral 6A": [
      "h922Qhkmx1: Multi-Source Diffusion Models for Simultaneous Music Generation and Separation"
    ],
    "Oral 6B": [
      "AhizIPytk4: How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks_",
      "Ad87VjRqUw: Ghost on the Shell_ An Expressive Representation of General 3D Shapes",
      "sllU8vvsFF: LRM_ Large Reconstruction Model for Single Image to 3D",
      "EanCFCwAjM: Cameras as Rays_ Pose Estimation via Ray Diffusion",
      "aIok3ZD9to: LLMCarbon_ Modeling the End-to-End Carbon Footprint of Large Language Models"
    ],
    "Oral 6C": [
      "hTEGyKf0dZ: Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!",
      "d8w0pmvXbZ: Small-scale proxies for large-scale Transformer training instabilities",
      "WNzy9bRDvG: Improved Techniques for Training Consistency Models",
      "osoWxY8q2E: ReLU Strikes Back_ Exploiting Activation Sparsity in Large Language Models",
      "PdaPky8MUn: Never Train from Scratch_ Fair Comparison of Long-Sequence Models Requires Data-Driven Priors"
    ],
    "Oral 6D": [
      "9WD9KwssyT: Zipformer_ A faster and better encoder for automatic speech recognition"
    ],
    "Oral 7A": [
      "gFR4QwK53h: Gene Regulatory Network Inference in the Presence of Dropouts_ a Causal View",
      "HSKaGOi7Ar: Beyond Weisfeiler-Lehman_ A Quantitative Framework for GNN Expressiveness",
      "L0r0GphlIL: Improving Convergence and Generalization Using Parameter Symmetries",
      "IGzaH538fz: GNNCert_ Deterministic Certification of Graph Neural Networks against Adversarial Perturbations",
      "mE52zURNGc: An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment",
      "oO6FsMyDBt: Graph Neural Networks for Learning Equivariant Representations of Neural Networks"
    ],
    "Oral 7B": [
      "HhfcNgQn6p: Towards a statistical theory of data selection under weak supervision",
      "HE9eUQlAvo: _What Data Benefits My Classifier__ Enhancing Model Performance and Interpretability through Influence-Based Data Selection"
    ],
    "Oral 7C": [
      "Fk5IzauJ7F: Candidate Label Set Pruning_ A Data-centric Perspective for Deep Partial-label Learning",
      "jKTUlxo5zy: Less is More_ Fewer Interpretable Region via Submodular Subset Selection",
      "C61sk5LsK6: InfoBatch_ Lossless Training Speed Up by Unbiased Dynamic Data Pruning",
      "FVhmnvqnsI: Multisize Dataset Condensation"
    ],
    "Oral 7D": [
      "0BqyZSWfzo: One-shot Empirical Privacy Estimation for Federated Learning"
    ],
    "Oral 8A": [
      "1oijHJBRsT: Self-Alignment with Instruction Backtranslation",
      "KS8mIvetg2: Proving Test Set Contamination in Black-Box Language Models",
      "hSyW5go0v8: Self-RAG_ Learning to Retrieve, Generate, and Critique through Self-Reflection"
    ],
    "Oral 8B": [
      "BV1PHbTJzd: Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks",
      "IYxDy2jDFL: Improved Active Learning via Dependent Leverage Score Sampling"
    ],
    "Oral 8C": [
      "1vDArHJ68h: Mastering Memory Tasks with World Models"
    ],
    "Oral 8D": [
      "Yen1lGns2o: Is ImageNet worth 1 video_ Learning strong image encoders from 1 long unlabelled video"
    ]
  },
  "KMeans": {
    "Oral 1A": [
      "agPpmEgf8C: Predictive auxiliary objectives in deep RL mimic learning in the brain"
    ],
    "Oral 1B": [
      "jNR6s6OSBT: ASID_ Active Exploration for System Identification in Robotic Manipulation",
      "sFyTZEqmUY: Learning Interactive Real-World Simulators"
    ],
    "Oral 1C": [
      "KS8mIvetg2: Proving Test Set Contamination in Black-Box Language Models",
      "uNrFpDPMyo: Model Tells You What to Discard_ Adaptive KV Cache Compression for LLMs",
      "WbWtOYIzIK: Knowledge Card_ Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models",
      "7Ttk3RzDeu: BooookScore_ A systematic exploration of book-length summarization in the era of LLMs"
    ],
    "Oral 1D": [
      "pOoKI3ouv1: Robust agents learn causal world models"
    ],
    "Oral 2A": [
      "xuY33XhEGR: ClimODE_ Climate and Weather Forecasting with Physics-informed Neural ODEs"
    ],
    "Oral 2B": [
      "Ad87VjRqUw: Ghost on the Shell_ An Expressive Representation of General 3D Shapes",
      "g7ohDlTITL: Flow Matching on General Geometries"
    ],
    "Oral 2C": [
      "WNkW0cOwiz: Lipschitz Singularities in Diffusion Models",
      "9Cu8MRmhq2: Multi-granularity Correspondence Learning from Long-term Noisy Videos",
      "yV6fD7LYkF: ValUES_ A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation",
      "hnrB5YHoYu: Finetuning Text-to-Image Diffusion Models for Fairness",
      "bTMMNT7IdW: Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time",
      "oTRwljRgiv: ExeDec_ Execution Decomposition for Compositional Generalization in Neural Program Synthesis",
      "ze7DOLi394: On the Joint Interaction of Models, Data, and Features",
      "4Ay23yeuz0: Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space",
      "tUtGjQEDd4: Generative Modeling with Phase Stochastic Bridge",
      "v7ZPwoHU1j: Statistically Optimal $K$-means Clustering via Nonnegative Low-rank Semidefinite Programming"
    ],
    "Oral 2D": [
      "ekeyCgeRfC: Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions",
      "aN4Jf6Cx69: The mechanistic basis of data dependence and abrupt learning in an in-context classification task"
    ],
    "Oral 3A": [
      "2dnO3LLiJ1: Vision Transformers Need Registers",
      "L0r0GphlIL: Improving Convergence and Generalization Using Parameter Symmetries",
      "hTEGyKf0dZ: Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!",
      "d8w0pmvXbZ: Small-scale proxies for large-scale Transformer training instabilities",
      "osoWxY8q2E: ReLU Strikes Back_ Exploiting Activation Sparsity in Large Language Models",
      "PdaPky8MUn: Never Train from Scratch_ Fair Comparison of Long-Sequence Models Requires Data-Driven Priors"
    ],
    "Oral 3B": [
      "P15CHILQlg: Learning Energy Decompositions for Partial Inference in GFlowNets"
    ],
    "Oral 3C": [
      "cc8h3I3V4E: Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization"
    ],
    "Oral 3D": [
      "AhizIPytk4: How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks_",
      "sllU8vvsFF: LRM_ Large Reconstruction Model for Single Image to 3D",
      "EanCFCwAjM: Cameras as Rays_ Pose Estimation via Ray Diffusion",
      "aIok3ZD9to: LLMCarbon_ Modeling the End-to-End Carbon Footprint of Large Language Models"
    ],
    "Oral 4A": [
      "6PmJoRfdaK: LongLoRA_ Efficient Fine-tuning of Long-Context Large Language Models",
      "LzPWWPAdY4: LoftQ_ LoRA-Fine-Tuning-aware Quantization for Large Language Models",
      "w4abltTZ2f: Batched Low-Rank Adaptation of Foundation Models"
    ],
    "Oral 4B": [
      "dLrhRIMVmB: Topological data analysis on noisy quantum computers"
    ],
    "Oral 4C": [
      "LjivA1SLZ6: Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning",
      "1vDArHJ68h: Mastering Memory Tasks with World Models",
      "o2IEmeLL9r: Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning"
    ],
    "Oral 4D": [
      "Ouj6p4ca60: Amortizing intractable inference in large language models",
      "1oijHJBRsT: Self-Alignment with Instruction Backtranslation",
      "KUNzEQMWU7: MathVista_ Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts",
      "bNt7oajl2a: Phenomenal Yet Puzzling_ Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement",
      "3f5PALef5B: LEGO-Prover_ Neural Theorem Proving with Growing Libraries",
      "hSyW5go0v8: Self-RAG_ Learning to Retrieve, Generate, and Critique through Self-Reflection"
    ],
    "Oral 5A": [
      "Zsfiqpft6K: Diffusion Model for Dense Matching",
      "mE52zURNGc: An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment"
    ],
    "Oral 5B": [
      "jr03SfWsBS: Unprocessing Seven Years of Algorithmic Fairness"
    ],
    "Oral 5C": [
      "T7YV5UZKBc: Neural Fine-Tuning Search for Few-Shot Learning",
      "tqh1zdXIra: Quick-Tune_ Quickly Learning Which Pretrained Model to Finetune and How"
    ],
    "Oral 5D": [
      "5Ca9sSzuDp: Interpreting CLIP's Image Representation via Text-Based Decomposition"
    ],
    "Oral 6A": [
      "ANvmVS2Yr0: Generalization in diffusion models arises from geometry-adaptive harmonic representations",
      "h922Qhkmx1: Multi-Source Diffusion Models for Simultaneous Music Generation and Separation",
      "nHESwXvxWK: Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems.",
      "zMPHKOmQNb: Protein Discovery with Discrete Walk-Jump Sampling",
      "pzElnMrgSD: How I Warped Your Noise_ a Temporally-Correlated Noise Prior for Diffusion Models"
    ],
    "Oral 6B": [
      "HSKaGOi7Ar: Beyond Weisfeiler-Lehman_ A Quantitative Framework for GNN Expressiveness",
      "IGzaH538fz: GNNCert_ Deterministic Certification of Graph Neural Networks against Adversarial Perturbations",
      "oO6FsMyDBt: Graph Neural Networks for Learning Equivariant Representations of Neural Networks"
    ],
    "Oral 6C": [
      "gFR4QwK53h: Gene Regulatory Network Inference in the Presence of Dropouts_ a Causal View",
      "HhfcNgQn6p: Towards a statistical theory of data selection under weak supervision"
    ],
    "Oral 6D": [
      "9WD9KwssyT: Zipformer_ A faster and better encoder for automatic speech recognition"
    ],
    "Oral 7A": [
      "Yen1lGns2o: Is ImageNet worth 1 video_ Learning strong image encoders from 1 long unlabelled video"
    ],
    "Oral 7B": [
      "NSVtmmzeRB: Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks",
      "UyNXMqnN3c: DreamGaussian_ Generative Gaussian Splatting for Efficient 3D Content Creation"
    ],
    "Oral 7C": [
      "Fk5IzauJ7F: Candidate Label Set Pruning_ A Data-centric Perspective for Deep Partial-label Learning",
      "jKTUlxo5zy: Less is More_ Fewer Interpretable Region via Submodular Subset Selection",
      "HE9eUQlAvo: _What Data Benefits My Classifier__ Enhancing Model Performance and Interpretability through Influence-Based Data Selection"
    ],
    "Oral 7D": [
      "VTF8yNQM66: SWE-bench_ Can Language Models Resolve Real-world Github Issues_",
      "H3UayAQWoE: On the Humanity of Conversational AI_ Evaluating the Psychological Portrayal of LLMs"
    ],
    "Oral 8A": [
      "7VPTUWkiDQ: Provable Compositional Generalization for Object-Centric Learning",
      "gU58d5QeGv: W\u00fcrstchen_ An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models",
      "84n3UwkH7b: Detecting, Explaining, and Mitigating Memorization in Diffusion Models"
    ],
    "Oral 8B": [
      "VtmBAGCN7o: MetaGPT_ Meta Programming for A Multi-Agent Collaborative Framework",
      "0BqyZSWfzo: One-shot Empirical Privacy Estimation for Federated Learning",
      "BV1PHbTJzd: Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks",
      "TpD2aG1h0D: Meta Continual Learning Revisited_ Implicitly Enhancing Online Hessian Approximation via Variance Reduction",
      "c5pwL0Soay: METRA_ Scalable Unsupervised RL with Metric-Aware Abstraction",
      "IYxDy2jDFL: Improved Active Learning via Dependent Leverage Score Sampling"
    ],
    "Oral 8C": [
      "9JQtrumvg8: A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis"
    ],
    "Oral 8D": [
      "WNzy9bRDvG: Improved Techniques for Training Consistency Models",
      "C61sk5LsK6: InfoBatch_ Lossless Training Speed Up by Unbiased Dynamic Data Pruning",
      "FVhmnvqnsI: Multisize Dataset Condensation"
    ]
  }
}