<html><head><meta charset='utf-8'><title>MathVista_ Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts</title></head><body><h1>MathVista_ Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts</h1><h3>By: ['Pan Lu', 'Hritik Bansal', 'Tony Xia', 'Jiacheng Liu', 'Chunyuan Li', 'Hannaneh Hajishirzi', 'Hao Cheng', 'Kai-Wei Chang', 'Michel Galley', 'Jianfeng Gao']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2024/oral/19768</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive problem-solving skills in many tasks and domains, but their ability in mathematical reasoning in visual contexts has not been systematically studied. To bridge this gap, we present MathVista, a benchmark designed to combine challenges from diverse mathematical and visual tasks. It consists of 6,141 examples, derived from 28 existing multimodal datasets involving mathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and PaperQA). Completing these tasks requires fine-grained, deep visual understanding and compositional reasoning, which all state-of-the-art foundation models find challenging. With MathVista, we have conducted a comprehensive, quantitative evaluation of 12 prominent foundation models. The best-performing GPT-4V model achieves an overall accuracy of 49.9%, substantially outperforming Bard, the second-best performer, by 15.1%. Our in-depth analysis reveals that the superiority of GPT-4V is mainly attributed to its enhanced visual perception and mathematical reasoning. However, GPT-4V still falls short of human performance by 10.4%, as it often struggles to understand complex figures and perform rigorous reasoning. This significant gap underscores the critical role that MathVista will play in the development of general-purpose AI agents capable of tackling mathematically intensive and visually rich real-world tasks. We further explore the new ability of self-verification, the application of self-consistency, and the interactive chatbot capabilities of GPT-4V, highlighting its promising potential for future research. The project is available at https://mathvista.github.io/.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 1C</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=KUNzEQMWU7</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=KUNzEQMWU7</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 1C</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 1C</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 4D</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 8C</div></body></html>