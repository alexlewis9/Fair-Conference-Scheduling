<html><head><meta charset='utf-8'><title>Self-RAG_ Learning to Retrieve, Generate, and Critique through Self-Reflection</title></head><body><h1>Self-RAG_ Learning to Retrieve, Generate, and Critique through Self-Reflection</h1><h3>By: ['Akari Asai', 'Zeqiu Wu', 'Yizhong Wang', 'Avi Sil', 'Hannaneh Hajishirzi']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2024/oral/19736</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the parametric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad hoc approach that augments LMs with retrieval of relevant knowledge, decreases such issues. However, indiscriminately retrieving and incorporating a fixed number of retrieved passages, regardless of whether retrieval is necessary, or passages are relevant, diminishes LM versatility or can lead to unhelpful response generation. We introduce a new framework called Self-Reflective Retrieval-Augmented Generation (Self-RAG) that enhances an LM's quality and factuality through retrieval and self-reflection. Our framework trains a single arbitrary LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its generations using special tokens, called {\it reflection} tokens. Generating reflection tokens makes the LM controllable during the inference phase, enabling it to tailor its behavior to diverse task requirements. Experiments show that Self-RAG (7B and 13B parameters) significantly outperforms state-of-the-art LLMs and retrieval-augmented models on a diverse set of tasks. Specifically, Self-RAG outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA, reasoning, and fact verification tasks, and it shows significant gains in improving factuality and citation accuracy for long-form generations relative to these models. Our code and trained models are available at https://selfrag.github.io/</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2A</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=hSyW5go0v8</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=hSyW5go0v8</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2A</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 2A</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 4A</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 2A</div></body></html>