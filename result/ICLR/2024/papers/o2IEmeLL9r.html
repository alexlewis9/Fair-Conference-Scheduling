<html><head><meta charset='utf-8'><title>Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning</title></head><body><h1>Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning</h1><h3>By: ['Haoqi Yuan', 'Zhancun Mu', 'Feiyang Xie', 'Zongqing Lu']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2024/oral/19728</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> Pre-training on task-agnostic large datasets is a promising approach for enhancing the sample efficiency of reinforcement learning (RL) in solving complex tasks. We present PTGM, a novel method that pre-trains goal-based models to augment RL by providing temporal abstractions and behavior regularization. PTGM involves pre-training a low-level, goal-conditioned policy and training a high-level policy to generate goals for subsequent RL tasks. To address the challenges posed by the high-dimensional goal space, while simultaneously maintaining the agent's capability to accomplish various skills, we propose clustering goals in the dataset to form a discrete high-level action space. Additionally, we introduce a pre-trained goal prior model to regularize the behavior of the high-level policy in RL, enhancing sample efficiency and learning stability. Experimental results in a robotic simulation environment and the challenging open-world environment of Minecraft demonstrate PTGMâ€™s superiority in sample efficiency and task performance compared to baselines. Moreover, PTGM exemplifies enhanced interpretability and generalization of the acquired low-level skills.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 4C</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=o2IEmeLL9r</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=o2IEmeLL9r</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 4C</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 1B</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 1B</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 4C</div></body></html>