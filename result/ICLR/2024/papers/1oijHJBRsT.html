<html><head><meta charset='utf-8'><title>Self-Alignment with Instruction Backtranslation</title></head><body><h1>Self-Alignment with Instruction Backtranslation</h1><h3>By: ['Xian Li', 'Ping Yu', 'Chunting Zhou', 'Timo Schick', 'Omer Levy', 'Luke Zettlemoyer', 'Jason E Weston', 'Mike Lewis']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2024/oral/19796</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> We present a scalable method to build a high quality instruction following language model by automatically labelling human-written text with corresponding instructions. Our approach, named instruction backtranslation, starts with a language model finetuned on a small amount of seed data, and a given web corpus. The seed model is used to construct training examples by generating instruction prompts for web documents (self-augmentation), and then  selecting high quality examples from among these candidates (self-curation).  This data is then used to finetune a stronger model.  Finetuning LLaMa on two iterations of our approach yields a model that outperforms all other LLaMa-based models on the Alpaca leaderboard not relying on distillation data, demonstrating highly effective self-alignment.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 8A</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=1oijHJBRsT</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=1oijHJBRsT</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 8A</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 8A</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 8A</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 4D</div></body></html>