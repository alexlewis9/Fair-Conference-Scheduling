<html><head><meta charset='utf-8'><title>Neural Fine-Tuning Search for Few-Shot Learning</title></head><body><h1>Neural Fine-Tuning Search for Few-Shot Learning</h1><h3>By: ['Panagiotis Eustratiadis', '≈Åukasz Dudziak', 'Da Li', 'Timothy Hospedales']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2024/oral/19760</div><h4>year</h4><div style='margin-bottom:1em'>2024</div><h4>abstract</h4><div style='margin-bottom:1em'> In few-shot recognition, a classifier that has been trained on one set of classes is required to rapidly adapt and generalize to a disjoint, novel set of classes. To that end, recent studies have shown the efficacy of fine-tuning with carefully-crafted adaptation architectures. However this raises the question of: How can one design the optimal adaptation strategy? In this paper, we study this question through the lens of neural architecture search (NAS). Given a pre-trained neural network, our algorithm discovers the optimal arrangement of adapters, which layers to keep frozen, and which to fine-tune. We demonstrate the generality of our NAS method by applying it to both residual networks and vision transformers and report state-of-the-art performance on Meta-Dataset and Meta-Album.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 5C</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=T7YV5UZKBc</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=T7YV5UZKBc</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 5C</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 5C</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 5C</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 5C</div></body></html>