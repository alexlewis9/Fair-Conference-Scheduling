<html><head><meta charset='utf-8'><title>Self-training For Few-shot Transfer Across Extreme Task Differences</title></head><body><h1>Self-training For Few-shot Transfer Across Extreme Task Differences</h1><h3>By: ['Cheng Perng Phoo', 'Bharath Hariharan']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2021/oral/3442</div><h4>year</h4><div style='margin-bottom:1em'>2021</div><h4>abstract</h4><div style='margin-bottom:1em'> Most few-shot learning techniques are pre-trained on a large, labeled “base dataset”. In problem domains where such large labeled datasets are not available for pre-training (e.g., X-ray, satellite images), one must resort to pre-training in a different “source” problem domain (e.g., ImageNet), which can be very different from the desired target task. Traditional few-shot and transfer learning techniques fail in the presence of such extreme differences between the source and target tasks. In this paper, we present a simple and effective solution to tackle this extreme domain gap: self-training a source domain representation on unlabeled data from the target domain. We show that this improves one-shot performance on the target domain by 2.9 points on average on the challenging BSCD-FSL benchmark consisting of datasets from multiple domains.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 11</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=O3Y56aqpChA</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=O3Y56aqpChA</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 11</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 7</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 3</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 1</div></body></html>