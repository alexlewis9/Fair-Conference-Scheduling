<html><head><meta charset='utf-8'><title>GAN _Steerability_ without optimization</title></head><body><h1>GAN _Steerability_ without optimization</h1><h3>By: ['Nurit Spingarn Eliezer', 'Ron Banner', 'Tomer Michaeli']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2021/spotlight/3478</div><h4>year</h4><div style='margin-bottom:1em'>2021</div><h4>abstract</h4><div style='margin-bottom:1em'> Recent research has shown remarkable success in revealing "steering" directions in the latent spaces of pre-trained GANs. These directions correspond to semantically meaningful image transformations (e.g., shift, zoom, color manipulations), and have the same interpretable effect across all categories that the GAN can generate. Some methods focus on user-specified transformations, while others discover transformations in an unsupervised manner. However, all existing techniques rely on an optimization procedure to expose those directions, and offer no control over the degree of allowed interaction between different transformations. In this paper, we show that "steering" trajectories can be computed in closed form directly from the generator's weights without any form of training or optimization. This applies to user-prescribed geometric transformations, as well as to unsupervised discovery of more complex effects. Our approach allows determining both linear and nonlinear trajectories, and has many advantages over previous methods. In particular, we can control whether one transformation is allowed to come on the expense of another (e.g., zoom-in with or without allowing translation to keep the object centered). Moreover, we can determine the natural end-point of the trajectory, which corresponds to the largest extent to which a transformation can be applied without incurring degradation. Finally, we show how transferring attributes between images can be achieved without optimization, even across different categories.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 9</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=zDy_nQCXiIj</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=zDy_nQCXiIj</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 9</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Outstanding Paper Session 1</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 1</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 12</div></body></html>