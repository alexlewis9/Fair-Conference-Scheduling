<html><head><meta charset='utf-8'><title>Towards Nonlinear Disentanglement in Natural Data with Temporal Sparse Coding</title></head><body><h1>Towards Nonlinear Disentanglement in Natural Data with Temporal Sparse Coding</h1><h3>By: ['David Klindt', 'Lukas Schott', 'Yash Sharma', 'Ivan Ustyuzhaninov', 'Wieland Brendel', 'Matthias Bethge', 'Dylan Paiton']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2021/oral/3443</div><h4>year</h4><div style='margin-bottom:1em'>2021</div><h4>abstract</h4><div style='margin-bottom:1em'> Disentangling the underlying generative factors from complex data has so far been limited to carefully constructed scenarios. We propose a path towards natural data by first showing that the statistics of natural data provide enough structure to enable disentanglement, both theoretically and empirically. Specifically, we provide evidence that objects in natural movies undergo transitions that are typically small in magnitude with occasional large jumps, which is characteristic of a temporally sparse distribution. To address this finding we provide a novel proof that relies on a sparse prior on temporally adjacent observations to recover the true latent variables up to permutations and sign flips, directly providing a stronger result than previous work. We show that equipping practical estimation methods with our prior often surpasses the current state-of-the-art on several established benchmark datasets without any impractical assumptions, such as knowledge of the number of changing generative factors. Furthermore, we contribute two new benchmarks, Natural Sprites and KITTI Masks, which integrate the measured natural dynamics to enable disentanglement evaluation with more realistic datasets. We leverage these benchmarks to test our theory, demonstrating improved performance. We also identify non-obvious challenges for current methods in scaling to more natural domains. Taken together our work addresses key issues in disentanglement research for moving towards more natural settings.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 1</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=EbIDjBynYJ8</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=EbIDjBynYJ8</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 1</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 1</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 11</div><h4>KMeans</h4><div style='margin-bottom:1em'>Outstanding Paper Session 1</div></body></html>