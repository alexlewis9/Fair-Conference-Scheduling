<html><head><meta charset='utf-8'><title>Neural Synthesis of Binaural Speech From Mono Audio</title></head><body><h1>Neural Synthesis of Binaural Speech From Mono Audio</h1><h3>By: ['Alexander Richard', 'Dejan Markovic', 'Israel Gebru', 'Steven Krenn', 'Gladstone A Butler', 'Fernando Torre', 'Yaser Sheikh']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2021/oral/3468</div><h4>year</h4><div style='margin-bottom:1em'>2021</div><h4>abstract</h4><div style='margin-bottom:1em'> We present a neural rendering approach for binaural sound synthesis that can produce realistic and spatially accurate binaural sound in realtime. The network takes, as input, a single-channel audio source and synthesizes, as output, two-channel binaural sound, conditioned on the relative position and orientation of the listener with respect to the source. We investigate deficiencies of the l2-loss on raw waveforms in a theoretical analysis and introduce an improved loss that overcomes these limitations. In an empirical evaluation, we establish that our approach is the first to generate spatially accurate waveform outputs (as measured by real recordings) and outperforms existing approaches by a considerable margin, both quantitatively and in a perceptual study. Dataset and code are available online.</div><h4>session</h4><div style='margin-bottom:1em'>Outstanding Paper Session 1</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=uAX8q61EVRu</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=uAX8q61EVRu</div><h4>Baseline</h4><div style='margin-bottom:1em'>Outstanding Paper Session 1</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Outstanding Paper Session 1</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 8</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 10</div></body></html>