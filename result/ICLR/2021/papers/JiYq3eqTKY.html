<html><head><meta charset='utf-8'><title>On Statistical Bias In Active Learning_ How and When to Fix It</title></head><body><h1>On Statistical Bias In Active Learning_ How and When to Fix It</h1><h3>By: ['Sebastian Farquhar', 'Yarin Gal', 'Tom Rainforth']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2021/spotlight/3414</div><h4>year</h4><div style='margin-bottom:1em'>2021</div><h4>abstract</h4><div style='margin-bottom:1em'> Active learning is a powerful tool when labelling data is expensive, but it introduces a bias because the training data no longer follows the population distribution. We formalize this bias and investigate the situations in which it can be harmful and sometimes even helpful. We further introduce novel corrective weights to remove bias when doing so is beneficial. Through this, our work not only provides a useful mechanism that can improve the active learning approach, but also an explanation for the empirical successes of various existing approaches which ignore this bias. In particular, we show that this bias can be actively helpful when training overparameterized models---like neural networks---with relatively modest dataset sizes.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 2</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=JiYq3eqTKY</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=JiYq3eqTKY</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 2</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 10</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 2</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 2</div></body></html>