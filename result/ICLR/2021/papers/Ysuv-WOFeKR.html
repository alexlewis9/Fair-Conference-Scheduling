<html><head><meta charset='utf-8'><title>Parrot_ Data-Driven Behavioral Priors for Reinforcement Learning</title></head><body><h1>Parrot_ Data-Driven Behavioral Priors for Reinforcement Learning</h1><h3>By: ['Avi Singh', 'Huihan Liu', 'Gaoyue Zhou', 'Albert Yu', 'Nicholas Rhinehart', 'Sergey Levine']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2021/oral/3481</div><h4>year</h4><div style='margin-bottom:1em'>2021</div><h4>abstract</h4><div style='margin-bottom:1em'> Reinforcement learning provides a general framework for flexible decision making and control, but requires extensive data collection for each new task that an agent needs to learn. In other machine learning fields, such as natural language processing or computer vision, pre-training on large, previously collected datasets to bootstrap learning for new tasks has emerged as a powerful paradigm to reduce data requirements when learning a new task. In this paper, we ask the following question: how can we enable similarly useful pre-training for RL agents? We propose a method for pre-training behavioral priors that can capture complex input-output relationships observed in successful trials from a wide range of previously seen tasks, and we show how this learned prior can be used for rapidly learning new tasks without impeding the RL agent's ability to try out novel behaviors. We demonstrate the effectiveness of our approach in challenging robotic manipulation domains involving image observations and sparse reward functions, where our method outperforms prior works by a substantial margin. Additional materials can be found on our project website: https://sites.google.com/view/parrot-rl</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 3</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=Ysuv-WOFeKR</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=Ysuv-WOFeKR</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 3</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 9</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 10</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 8</div></body></html>