<html><head><meta charset='utf-8'><title>Understanding the role of importance weighting for deep learning</title></head><body><h1>Understanding the role of importance weighting for deep learning</h1><h3>By: ['Da Xu', 'Yuting Ye', 'Chuanwei Ruan']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2021/spotlight/3517</div><h4>year</h4><div style='margin-bottom:1em'>2021</div><h4>abstract</h4><div style='margin-bottom:1em'> The recent paper by Byrd & Lipton (2019), based on empirical observations, raises a major concern on the impact of importance weighting for the over-parameterized deep learning models. They observe that as long as the model can separate the training data, the impact of importance weighting diminishes as the training proceeds. Nevertheless, there lacks a rigorous characterization of this phenomenon. In this paper, we provide formal characterizations and theoretical justifications on the role of importance weighting with respect to the implicit bias of gradient descent and margin-based learning theory. We reveal both the optimization dynamics and generalization performance under deep learning models. Our work not only explains the various novel phenomenons observed for importance weighting in deep learning, but also extends to the studies where the weights are being optimized as part of the model, which applies to a number of topics under active research.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 9</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=_WnwtieRHxM</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=_WnwtieRHxM</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 9</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 5</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 8</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 3</div></body></html>