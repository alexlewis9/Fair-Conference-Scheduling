<html><head><meta charset='utf-8'><title>Sparse Quantized Spectral Clustering</title></head><body><h1>Sparse Quantized Spectral Clustering</h1><h3>By: ['Zhenyu Liao', 'Romain Couillet', 'Michael W Mahoney']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2021/spotlight/3382</div><h4>year</h4><div style='margin-bottom:1em'>2021</div><h4>abstract</h4><div style='margin-bottom:1em'> Given a large data matrix, sparsifying, quantizing, and/or performing other entry-wise nonlinear operations can have numerous benefits, ranging from speeding up iterative algorithms for core numerical linear algebra problems to providing nonlinear filters to design state-of-the-art neural network models. Here, we exploit tools from random matrix theory to make precise statements about how the eigenspectrum of a matrix changes under such nonlinear transformations. In particular, we show that very little change occurs in the informative eigenstructure, even under drastic sparsification/quantization, and consequently that very little downstream performance loss occurs when working with very aggressively sparsified or quantized spectral clustering problems.
We illustrate how these results depend on the nonlinearity, we characterize a phase transition beyond which spectral clustering becomes possible, and we show when such nonlinear transformations can introduce spurious non-informative eigenvectors.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 12</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=pBqLS-7KYAF</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=pBqLS-7KYAF</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 12</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 12</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 8</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 3</div></body></html>