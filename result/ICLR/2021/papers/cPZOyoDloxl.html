<html><head><meta charset='utf-8'><title>SMiRL_ Surprise Minimizing Reinforcement Learning in Unstable Environments</title></head><body><h1>SMiRL_ Surprise Minimizing Reinforcement Learning in Unstable Environments</h1><h3>By: ['Glen Berseth', 'Daniel Geng', 'Coline M Devin', 'Nicholas Rhinehart', 'Chelsea Finn', 'Dinesh Jayaraman', 'Sergey Levine']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2021/oral/3453</div><h4>year</h4><div style='margin-bottom:1em'>2021</div><h4>abstract</h4><div style='margin-bottom:1em'> Every living organism struggles against disruptive environmental forces to carve out and maintain an orderly niche. We propose that such a struggle to achieve and preserve order might offer a principle for the emergence of useful behaviors in artificial agents. We formalize this idea into an unsupervised reinforcement learning method called surprise minimizing reinforcement learning (SMiRL). SMiRL alternates between learning a density model to evaluate the surprise of a stimulus, and improving the policy to seek more predictable stimuli. The policy seeks out stable and repeatable situations that counteract the environment's prevailing sources of entropy. This might include avoiding other hostile agents, or finding a stable, balanced pose for a bipedal robot in the face of disturbance forces. We demonstrate that our surprise minimizing agents can successfully play Tetris, Doom, control a humanoid to avoid falls, and navigate to escape enemies in a maze without any task-specific reward supervision. We further show that SMiRL can be used together with standard task rewards to accelerate reward-driven learning.</div><h4>session</h4><div style='margin-bottom:1em'>Oral Session 3</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=cPZOyoDloxl</div><h4>openreview_url</h4><div style='margin-bottom:1em'>https://openreview.net/forum?id=cPZOyoDloxl</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral Session 3</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral Session 9</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral Session 11</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral Session 10</div></body></html>