<html><head><meta charset='utf-8'><title>Effects of Graph Convolutions in Multi-layer Networks</title></head><body><h1>Effects of Graph Convolutions in Multi-layer Networks</h1><h3>By: ['Aseem Baranwal', 'Kimon Fountoulakis', 'Aukosh Jagannath']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12554</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Graph Convolutional Networks (GCNs) are one of the most popular architectures that are used to solve classification problems accompanied by graphical information. We present a rigorous theoretical understanding of the effects of graph convolutions in multi-layer networks. We study these effects through the node classification problem of a non-linearly separable Gaussian mixture model coupled with a stochastic block model. First, we show that a single graph convolution expands the regime of the distance between the means where multi-layer networks can classify the data by a factor of at least $1/\sqrt[4]{\rm deg}$, where ${\rm deg}$ denotes the expected degree of a node. Second, we show that with a slightly stronger graph density, two graph convolutions improve this factor to at least $1/\sqrt[4]{n}$, where $n$ is the number of nodes in the graph. Finally, we provide both theoretical and empirical insights into the performance of graph convolutions placed in different combinations among the layers of a neural network, concluding that the performance is mutually similar for all combinations of the placement. We present extensive experiments on both synthetic and real-world data that illustrate our results.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2 Track 5: Generative models & Theory</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=P-73JPgRs0R</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2 Track 5: Generative models & Theory</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 5 Track 2: Optimization</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 6 Track 1: Theory</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 2 Track 5: Generative models & Theory</div></body></html>