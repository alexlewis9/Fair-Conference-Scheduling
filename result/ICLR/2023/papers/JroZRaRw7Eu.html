<html><head><meta charset='utf-8'><title>Token Merging_ Your ViT But Faster</title></head><body><h1>Token Merging_ Your ViT But Faster</h1><h3>By: ['Daniel Bolya', 'Cheng-Yang Fu', 'Xiaoliang Dai', 'Peizhao Zhang', 'Christoph Feichtenhofer', 'Judy Hoffman']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12533</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> We introduce Token Merging (ToMe), a simple method to increase the throughput of existing ViT models without needing to train. ToMe gradually combines similar tokens in a transformer using a general and light-weight matching algorithm that is as fast as pruning while being more accurate. Off-the-shelf, ToMe can 2x the throughput of state-of-the-art ViT-L @ 512 and ViT-H @ 518 models on images and 2.2x the throughput of ViT-L on video with only a 0.2-0.3% accuracy drop in each case. ToMe can also easily be applied during training, improving in practice training speed up to 2x for MAE fine-tuning on video. Training with ToMe further minimizes accuracy drop, leading to 2x the throughput of ViT-B on audio for only a 0.4% mAP drop. Qualitatively, we find that ToMe merges object parts into one token, even over multiple frames of video. Overall, ToMeâ€™s accuracy and speed are competitive with state-of-the-art on images, video, and audio.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 1 Track 1: Deep Learning and representational learning I</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=JroZRaRw7Eu</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 1 Track 1: Deep Learning and representational learning I</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 5 Track 1: Unsupervised and Self-supervised learning & Social Aspects of Machine Learning-</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 3 Track 4: General Machine Learning & Unsupervised and Self-supervised learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 6 Track 4: Applications & Social Aspects of Machine Learning & General Machine Learning</div></body></html>