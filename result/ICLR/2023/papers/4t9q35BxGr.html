<html><head><meta charset='utf-8'><title>Inequality phenomenon in $l_{_infty}$-adversarial training, and its unrealized threats</title></head><body><h1>Inequality phenomenon in $l_{_infty}$-adversarial training, and its unrealized threats</h1><h3>By: ['Ranjie Duan', 'YueFeng Chen', 'Yao Zhu', 'Xiaojun Jia', 'Rong Zhang', "Hui Xue'"]</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12663</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> The appearance of adversarial examples raises attention from both academia and industry. Along with the attack-defense arms race, adversarial training is the most effective against adversarial examples.However, we find inequality phenomena occur during the $l_{\infty}$-adversarial training, that few features dominate the prediction made by the adversarially trained model. We systematically evaluate such inequality phenomena by extensive experiments and find such phenomena become more obvious when performing adversarial training with increasing adversarial strength (evaluated by $\epsilon$). We hypothesize such inequality phenomena make $l_{\infty}$-adversarially trained model less reliable than the standard trained model when few ``important features" are influenced. To validate our hypothesis, we proposed two simple attacks that either perturb or replace important features with noise or occlusion. Experiments show that $l_{\infty}$-adversarially trained model can be easily attacked when the few important features are influenced. Our work shed light on the limitation of the practicality of $l_{\infty}$-adversarial training.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 6 Track 4: Applications & Social Aspects of Machine Learning & General Machine Learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=4t9q35BxGr</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 6 Track 4: Applications & Social Aspects of Machine Learning & General Machine Learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 1 Track 4: Social Aspects of Machine Learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 6 Track 5: Applications- & Deep Learning and representational learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 1 Track 4: Social Aspects of Machine Learning</div></body></html>