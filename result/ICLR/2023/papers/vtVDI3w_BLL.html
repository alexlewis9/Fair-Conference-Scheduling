<html><head><meta charset='utf-8'><title>AANG _ Automating Auxiliary Learning</title></head><body><h1>AANG _ Automating Auxiliary Learning</h1><h3>By: ['Lucio Dery', 'Paul Michel', 'Mikhail Khodak', 'Graham Neubig', 'Ameet Talwalkar']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12590</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Auxiliary objectives, supplementary learning signals that are introduced to help aid learning on data-starved or highly complex end-tasks, are commonplace in machine learning. Whilst much work has been done to formulate useful auxiliary objectives, their construction is still an art which proceeds by slow and tedious hand-design. Intuition for how and when these objectives improve end-task performance has also had limited theoretical backing. In this work, we present an approach for automatically generating a suite of auxiliary objectives. We achieve this by deconstructing existing objectives within a novel unified taxonomy, identifying connections between them, and generating new ones based on the uncovered structure. Next, we theoretically formalize widely-held intuitions about how auxiliary learning improves generalization on the end-task. This leads us to a principled and efficient algorithm for searching the space of generated objectives to find those most useful to a specified end-task.With natural language processing (NLP) as our domain of study, we demonstrate that our automated auxiliary learning pipeline leads to strong improvements over competitive baselines across continued training experiments on a pre-trained model on 5 NLP end-tasks.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 4 Track 1: Unsupervised and Self-supervised learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=vtVDI3w_BLL</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 4 Track 1: Unsupervised and Self-supervised learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 1 Track 5: Reinforcement Learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 5 Track 2: Optimization</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 5 Track 2: Optimization</div></body></html>