<html><head><meta charset='utf-8'><title>Socratic Models_ Composing Zero-Shot Multimodal Reasoning with Language</title></head><body><h1>Socratic Models_ Composing Zero-Shot Multimodal Reasoning with Language</h1><h3>By: ['Andy Zeng', 'Maria Attarian', 'brian ichter', 'Krzysztof Choromanski', 'Adrian Wong', 'Stefan Welker', 'Federico Tombari', 'Aveek Purohit', 'Michael Ryoo', 'Vikas Sindhwani', 'Johnny Lee', 'Vincent Vanhoucke', 'Pete Florence']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12574</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> We investigate how multimodal prompt engineering can use language as the intermediate representation to combine complementary knowledge from different pretrained (potentially multimodal) language models for a variety of tasks. This approach is both distinct from and complementary to the dominant paradigm of joint multimodal training. It also recalls a traditional systems-building view as in classical NLP pipelines, but with prompting large pretrained multimodal models. We refer to these as Socratic Models (SMs): a modular class of systems in which multiple pretrained models may be composed zero-shot via multimodal-informed prompting to capture new multimodal capabilities, without additional finetuning. We show that these systems provide competitive state-of-the-art performance for zero-shot image captioning and video-to-text retrieval, and also enable new applications such as (i) answering free-form questions about egocentric video, (ii) engaging in multimodal assistive dialogue with people (e.g., for cooking recipes), and (iii) robot perception and planning. We hope this work provides (a) results for stronger zero-shot baseline performance with analysis also highlighting their limitations, (b) new perspectives for building multimodal systems powered by large pretrained models, and (c) practical application advantages in certain regimes limited by data scarcity, training compute, or model access.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 5 Track 4: Applications & Optimization</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=G2Q2Mh3avow</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 5 Track 4: Applications & Optimization</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 6 Track 2: Infrastructure & Social Aspects of Machine Learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 5 Track 4: Applications & Optimization</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 5 Track 4: Applications & Optimization</div></body></html>