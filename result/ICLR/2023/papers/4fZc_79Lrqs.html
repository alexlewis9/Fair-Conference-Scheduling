<html><head><meta charset='utf-8'><title>ACMP_ Allen-Cahn Message Passing with Attractive and Repulsive Forces for Graph Neural Networks</title></head><body><h1>ACMP_ Allen-Cahn Message Passing with Attractive and Repulsive Forces for Graph Neural Networks</h1><h3>By: ['Yuelin Wang', 'Kai Yi', 'Xinliang Liu', 'Yuguang Wang', 'Shi Jin']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12636</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Neural message passing is a basic feature extraction unit for graph-structured data considering neighboring node features in network propagation from one layer to the next. We model such process by an interacting particle system with attractive and repulsive forces and the Allen-Cahn force arising in the modeling of phase transition. The dynamics of the system is a reaction-diffusion process which can separate particles without blowing up. This induces an Allen-Cahn message passing (ACMP) for graph neural networks where the numerical iteration for the particle system solution constitutes the message passing propagation. ACMP which has a simple implementation with a neural ODE solver can propel the network depth up to one hundred of layers with theoretically proven strictly positive lower bound of the Dirichlet energy. It thus provides a deep model of GNNs circumventing the common GNN problem of oversmoothing. GNNs with ACMP achieve state of the art performance for real-world node classification tasks on both homophilic and heterophilic datasets. Codes are available at https://github.com/ykiiiiii/ACMP</div><h4>session</h4><div style='margin-bottom:1em'>Oral 3 Track 5: Deep Learning and representational learning & Neuroscience and Cognitive Science</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=4fZc_79Lrqs</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 3 Track 5: Deep Learning and representational learning & Neuroscience and Cognitive Science</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 3 Track 5: Deep Learning and representational learning & Neuroscience and Cognitive Science</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 4 Track 6: Deep Learning and representational learning- Reinforcement Learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 6 Track 5: Applications- & Deep Learning and representational learning</div></body></html>