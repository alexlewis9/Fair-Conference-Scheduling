<html><head><meta charset='utf-8'><title>Neural Optimal Transport</title></head><body><h1>Neural Optimal Transport</h1><h3>By: ['Alexander Korotin', 'Daniil Selikhanovych', 'Evgeny Burnaev']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12644</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> We present a novel neural-networks-based algorithm to compute optimal transport maps and plans for strong and weak transport costs. To justify the usage of neural networks, we prove that they are universal approximators of transport plans between probability distributions. We evaluate the performance of our optimal transport algorithm on toy examples and on the unpaired image-to-image translation.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2 Track 5: Generative models & Theory</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=d8CBRlWNkqH</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2 Track 5: Generative models & Theory</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 2 Track 5: Generative models & Theory</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 2 Track 5: Generative models & Theory</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 1 Track 2: Machine Learning for Sciences</div></body></html>