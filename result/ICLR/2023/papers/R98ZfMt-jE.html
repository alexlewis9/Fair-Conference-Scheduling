<html><head><meta charset='utf-8'><title>Efficient Discrete Multi Marginal Optimal Transport Regularization</title></head><body><h1>Efficient Discrete Multi Marginal Optimal Transport Regularization</h1><h3>By: ['Ronak Mehta', 'Jeffery Kline', 'Vishnu Lokhande', 'Glenn Fung', 'Vikas Singh']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12599</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Optimal transport has emerged as a powerful tool for a variety of problems in machine learning, and it is frequently used to enforce distributional constraints. In this context, existing methods often use either a Wasserstein metric, or else they apply concurrent barycenter approaches when more than two distributions are considered. In this paper, we  leverage multi-marginal optimal transport (MMOT), where we take advantage of a procedure that computes a generalized earth mover's distance as a sub-routine. We show that not only is our algorithm computationally more efficient compared to other barycentric-based distance methods, but it has the additional advantage that gradients used for backpropagation can be efficiently computed during the forward pass computation itself, which leads to substantially faster model training. We provide technical details about this new regularization term and its properties, and we present experimental demonstrations of faster runtimes when compared to standard Wasserstein-style methods. Finally, on a range of experiments designed to assess effectiveness at enforcing fairness, we demonstrate our method compares well with alternatives.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 3 Track 4: General Machine Learning & Unsupervised and Self-supervised learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=R98ZfMt-jE</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 3 Track 4: General Machine Learning & Unsupervised and Self-supervised learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 1 Track 6: Deep Learning and representational learning II</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 6 Track 1: Theory</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 3 Track 4: General Machine Learning & Unsupervised and Self-supervised learning</div></body></html>