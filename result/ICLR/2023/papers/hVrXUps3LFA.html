<html><head><meta charset='utf-8'><title>Divide to Adapt_ Mitigating Confirmation Bias for Domain Adaptation of Black-Box Predictors</title></head><body><h1>Divide to Adapt_ Mitigating Confirmation Bias for Domain Adaptation of Black-Box Predictors</h1><h3>By: ['JIANFEI YANG', 'Xiangyu Peng', 'Kai Wang', 'Zheng Zhu', 'Jiashi Feng', 'Lihua Xie', 'Yang You']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12702</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Domain Adaptation of Black-box Predictors (DABP) aims to learn a model on an unlabeled target domain supervised by a black-box predictor trained on a source domain. It does not require access to both the source-domain data and the predictor parameters, thus addressing the data privacy and portability issues of standard domain adaptation methods. Existing DABP approaches mostly rely on knowledge distillation (KD) from the black-box predictor, i.e., training the model with its noisy target-domain predictions, which however inevitably introduces the confirmation bias accumulated from the prediction noises and leads to degrading performance. To mitigate such bias, we propose a new strategy, \textit{divide-to-adapt}, that purifies cross-domain knowledge distillation by proper domain division. This is inspired by an observation we make for the first time in domain adaptation: the target domain usually contains easy-to-adapt and hard-to-adapt samples that have different levels of domain discrepancy w.r.t. the source domain, and deep models tend to fit easy-to-adapt samples first. Leveraging easy-to-adapt samples with less noise can help KD alleviate the negative effect of prediction noises from black-box predictors. In this sense, the target domain can be divided into an easy-to-adapt subdomain with less noise and a hard-to-adapt subdomain at the early stage of training. Then the adaptation is achieved by semi-supervised learning. We further reduce distribution discrepancy between subdomains and develop weak-strong augmentation strategy to filter the predictor errors progressively. As such, our method is a simple yet effective solution to reduce error accumulation in cross-domain knowledge distillation for DABP. Moreover, we prove that the target error of DABP is bounded by the noise ratio of two subdomains, i.e., the confirmation bias, which provides the theoretical justifications for our method. Extensive experiments demonstrate our method achieves state of the art on all DABP benchmarks, outperforming the existing best approach by 7.0\% on VisDA-17, and is even comparable with the standard domain adaptation methods that use the source-domain data.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 1 Track 6: Deep Learning and representational learning II</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=hVrXUps3LFA</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 1 Track 6: Deep Learning and representational learning II</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 1 Track 3: Neuroscience and Cognitive Science & General Machine Learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 4 Track 1: Unsupervised and Self-supervised learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 1 Track 6: Deep Learning and representational learning II</div></body></html>