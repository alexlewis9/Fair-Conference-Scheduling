<html><head><meta charset='utf-8'><title>A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification</title></head><body><h1>A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification</h1><h3>By: ['Paul F. Jaeger', 'Carsten LÃ¼th', 'Lukas Klein', 'Till Bungert']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12528</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Reliable application of machine learning-based decision systems in the wild is one of the major challenges currently investigated by the field. A large portion of established approaches aims to detect erroneous predictions by means of assigning confidence scores. This confidence may be obtained by either quantifying the model's predictive uncertainty, learning explicit scoring functions, or assessing whether the input is in line with the training distribution. Curiously, while these approaches all state to address the same eventual goal of detecting failures of a classifier upon real-world application, they currently constitute largely separated research fields with individual evaluation protocols, which either exclude a substantial part of relevant methods or ignore large parts of relevant failure sources. In this work, we systematically reveal current pitfalls caused by these inconsistencies and derive requirements for a holistic and realistic evaluation of failure detection. To demonstrate the relevance of this unified perspective, we present a large-scale empirical study for the first time enabling benchmarking confidence scoring functions w.r.t all relevant methods and failure sources. The revelation of a simple softmax response baseline as the overall best performing method underlines the drastic shortcomings of current evaluation in the plethora of publicized research on confidence scoring. Code and trained models are at https://github.com/https://github.com/IML-DKFZ/fd-shifts</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2 Track 6: Applications & Social Aspects of Machine Learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=YnkGMIh0gvX</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2 Track 6: Applications & Social Aspects of Machine Learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 1 Track 1: Deep Learning and representational learning I</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 6 Track 5: Applications- & Deep Learning and representational learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 6 Track 6: Deep Learning</div></body></html>