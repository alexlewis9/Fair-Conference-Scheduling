<html><head><meta charset='utf-8'><title>Diffusion Posterior Sampling for General Noisy Inverse Problems</title></head><body><h1>Diffusion Posterior Sampling for General Noisy Inverse Problems</h1><h3>By: ['Hyungjin Chung', 'Jeongsol Kim', 'Michael McCann', 'Marc Klasky', 'Jong Ye']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12524</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Diffusion models have been recently studied as powerful generative inverse problem solvers, owing to their high quality reconstructions and the ease of combining existing iterative solvers. However, most works focus on solving simple linear inverse problems in noiseless settings, which significantly under-represents the complexity of real-world problems. In this work, we extend diffusion solvers to efficiently handle general noisy (non)linear inverse problems via the Laplace approximation of the posterior sampling. Interestingly, the resulting posterior sampling scheme is a blended version of diffusion sampling with the manifold constrained gradient without a strict measurement consistency projection step, yielding a more desirable generative path in noisy settings compared to the previous studies. Our method demonstrates that diffusion models can incorporate various measurement noise statistics such as Gaussian and Poisson, and also efficiently handle noisy nonlinear inverse problems such as Fourier phase retrieval and non-uniform deblurring.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2 Track 3: Generative models</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=OnD9zGAGT0k</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2 Track 3: Generative models</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 2 Track 3: Generative models</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 3 Track 3: Generative models</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 4 Track 5: Machine Learning for Sciences & Probabilistic Methods</div></body></html>