<html><head><meta charset='utf-8'><title>Is Adversarial Training Really a Silver Bullet for Mitigating Data Poisoning_</title></head><body><h1>Is Adversarial Training Really a Silver Bullet for Mitigating Data Poisoning_</h1><h3>By: ['Rui Wen', 'Zhengyu Zhao', 'Zhuoran Liu', 'Michael Backes', 'Tianhao Wang', 'Yang Zhang']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12684</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Indiscriminate data poisoning can decrease the clean test accuracy of a deep learning model by slightly perturbing its training samples.There is a consensus that such poisons can hardly harm adversarially-trained (AT) models when the adversarial training budget is no less than the poison budget, i.e., $\epsilon_\mathrm{adv}\geq\epsilon_\mathrm{poi}$. This consensus, however, is challenged in this paper based on our new attack strategy that induces \textit{entangled features} (EntF). The existence of entangled features makes the poisoned data become less useful for training a model, no matter if AT is applied or not. We demonstrate that for attacking a CIFAR-10 AT model under a reasonable setting with $\epsilon_\mathrm{adv}=\epsilon_\mathrm{poi}=8/255$, our EntF yields an accuracy drop of $13.31\%$, which is $7\times$ better than existing methods and equal to discarding $83\%$ training data. We further show the generalizability of EntF to more challenging settings, e.g., higher AT budgets, partial poisoning, unseen model architectures, and stronger (ensemble or adaptive) defenses. We finally provide new insights into the distinct roles of non-robust vs. robust features in poisoning standard vs. AT models and demonstrate the possibility of using a hybrid attack to poison standard and AT models simultaneously. Our code is available at~\url{https://github.com/WenRuiUSTC/EntF}.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 1 Track 4: Social Aspects of Machine Learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=zKvm1ETDOq</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 1 Track 4: Social Aspects of Machine Learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 1 Track 4: Social Aspects of Machine Learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 1 Track 4: Social Aspects of Machine Learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 1 Track 4: Social Aspects of Machine Learning</div></body></html>