<html><head><meta charset='utf-8'><title>Flow Straight and Fast_ Learning to Generate and Transfer Data with Rectified Flow</title></head><body><h1>Flow Straight and Fast_ Learning to Generate and Transfer Data with Rectified Flow</h1><h3>By: ['Xingchao Liu', 'Chengyue Gong', 'Qiang Liu']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12626</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> We present rectified flow, a simple approach to learning (neural) ordinary differential equation (ODE) models to transport between two empirically observed distributions $\pi_0$ and $\pi_1$, hence providing a unified solution to generative modeling and domain transfer, among various other tasks involving distribution transport. The idea of rectified flow is to learn the ODE to follow the straight paths connecting the points drawn from $\pi_0$ and $\pi_1$ as much as possible. This is  achieved by solving a straightforward nonlinear least squares optimization problem, which can be easily scaled to large models without introducing extra parameters beyond standard supervised learning. The straight paths are the shortest paths between two points, and can be simulated exactly without time discretization and hence yield computationally efficient models. We show that, by learning a rectified flow from data, we effectively turn an arbitrary coupling of $\pi_0$ and $\pi_1$ to a  new deterministic coupling with provably non-increasing convex transport costs. In addition, with a ``reflow" procedure that iteratively learns a new rectified flow from the data bootstrapped from the previous one, we obtain a sequence of flows with increasingly straight paths, which can be simulated accurately with coarse time discretization in the inference phase. In empirical studies, we show that rectified flow performs superbly on image generation, image-to-image translation, and domain adaptation. In particular, on image generation and translation, our method yields nearly straight flows that give high quality results even with \emph{a single Euler discretization step}. Code is available at \url{https://github.com/gnobitab/RectifiedFlow}.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 3 Track 3: Generative models</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=XVjTT1nw5z</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 3 Track 3: Generative models</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 1 Track 2: Machine Learning for Sciences</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 2 Track 5: Generative models & Theory</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 3 Track 1: Reinforcement Learning</div></body></html>