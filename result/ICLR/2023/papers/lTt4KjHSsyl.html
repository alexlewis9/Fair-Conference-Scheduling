<html><head><meta charset='utf-8'><title>Emergence of Maps in the Memories of Blind Navigation Agents</title></head><body><h1>Emergence of Maps in the Memories of Blind Navigation Agents</h1><h3>By: ['Erik Wijmans', 'Manolis Savva', 'Irfan Essa', 'Stefan Lee', 'Ari Morcos', 'Dhruv Batra']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12560</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Animal navigation research posits that organisms build and maintain internal spa- tial representations, or maps, of their environment. We ask if machines – specifically, artificial intelligence (AI) navigation agents – also build implicit (or ‘mental’) maps. A positive answer to this question would (a) explain the surprising phenomenon in recent literature of ostensibly map-free neural-networks achieving strong performance, and (b) strengthen the evidence of mapping as a fundamental mechanism for navigation by intelligent embodied agents, whether they be biological or artificial. Unlike animal navigation, we can judiciously design the agent’s perceptual system and control the learning paradigm to nullify alternative navigation mechanisms. Specifically, we train ‘blind’ agents – with sensing limited to only egomotion and no other sensing of any kind – to perform PointGoal navigation (‘go to $\Delta$x, $\Delta$y’) via reinforcement learning. Our agents are composed of navigation-agnostic components (fully-connected and recurrent neural networks), and our experimental setup provides no inductive bias towards mapping. Despite these harsh conditions, we find that blind agents are (1) surprisingly effective navigators in new environments (∼95% success); (2) they utilize memory over long horizons (remembering ∼1,000 steps of past experience in an episode); (3) this memory enables them to exhibit intelligent behavior (following walls, detecting collisions, taking shortcuts); (4) there is emergence of maps and collision detection neurons in the representations of the environment built by a blind agent as it navigates; and (5) the emergent maps are selective and task dependent (e.g. the agent ‘forgets’ exploratory detours). Overall, this paper presents no new techniques for the AI audience, but a surprising finding, an insight, and an explanation.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 1 Track 5: Reinforcement Learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=lTt4KjHSsyl</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 1 Track 5: Reinforcement Learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 2 Track 2: General Machine Learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 1 Track 5: Reinforcement Learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 6 Track 2: Infrastructure & Social Aspects of Machine Learning</div></body></html>