<html><head><meta charset='utf-8'><title>UNIFIED-IO_ A Unified Model for Vision, Language, and Multi-modal Tasks</title></head><body><h1>UNIFIED-IO_ A Unified Model for Vision, Language, and Multi-modal Tasks</h1><h3>By: ['Jiasen Lu', 'Christopher Clark', 'Rowan Zellers', 'Roozbeh Mottaghi', 'Aniruddha Kembhavi']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12725</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> We propose Unified-IO, a model that performs a large variety of AI tasks spanning classical computer vision tasks, including pose estimation, object detection, depth estimation and image generation, vision-and-language tasks such as region captioning and referring expression, to natural language processing tasks such as question answering and paraphrasing. Developing a single unified model for such a large variety of tasks poses unique challenges due to the heterogeneous inputs and outputs pertaining to each task, including RGB images, per-pixel maps, binary masks, bounding boxes, and language. We achieve this unification by homogenizing every supported input and output into a sequence of discrete vocabulary tokens. This common representation across all tasks allows us to train a single transformer-based architecture, jointly on over 90 diverse datasets in the vision and language fields. Unified-IO is the first model capable of performing all 7 tasks on the GRIT benchmark and produces strong results across 16 diverse benchmarks like NYUv2-Depth, ImageNet, VQA2.0, OK-VQA, Swig, VizWizGround, BoolQ, and SciTail, with no task-specific fine-tuning. Code and pre-trained models will be made publicly available.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2 Track 1: Applications</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=E01k9048soZ</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2 Track 1: Applications</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 2 Track 1: Applications</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 5 Track 4: Applications & Optimization</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 2 Track 1: Applications</div></body></html>