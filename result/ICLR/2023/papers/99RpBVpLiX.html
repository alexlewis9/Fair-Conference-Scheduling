<html><head><meta charset='utf-8'><title>Distilling Model Failures as Directions in Latent Space</title></head><body><h1>Distilling Model Failures as Directions in Latent Space</h1><h3>By: ['Saachi Jain', 'Hannah Lawrence', 'Ankur Moitra', 'Aleksander Madry']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12544</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Existing methods for isolating hard subpopulations and spurious correlations in datasets often require human intervention. This can make these methods labor-intensive and dataset-specific. To address these shortcomings, we present a scalable method for automatically distilling a model's failure modes. Specifically, we harness linear classifiers to identify consistent error patterns, and, in turn, induce a natural representation of these failure modes as directions within the feature space. We demonstrate that this framework allows us to discover and automatically caption challenging subpopulations within the training dataset. Moreover, by combining our framework with off-the-shelf diffusion models, we can generate images that are especially challenging for the analyzed model, and thus can be used to perform synthetic data augmentation that helps remedy the model's failure modes.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 5 Track 3: Deep Learning and representational learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=99RpBVpLiX</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 5 Track 3: Deep Learning and representational learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 6 Track 3: Deep Learning and representational learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 6 Track 3: Deep Learning and representational learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 6 Track 3: Deep Learning and representational learning</div></body></html>