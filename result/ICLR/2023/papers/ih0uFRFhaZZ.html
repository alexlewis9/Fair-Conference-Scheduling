<html><head><meta charset='utf-8'><title>Continual Unsupervised Disentangling of Self-Organizing Representations</title></head><body><h1>Continual Unsupervised Disentangling of Self-Organizing Representations</h1><h3>By: ['Zhiyuan Li', 'Xiajun Jiang', 'Ryan Missel', 'Prashnna Gyawali', 'Nilesh Kumar', 'Linwei Wang']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12760</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Limited progress has been made in continual unsupervised learning of representations, especially in reusing, expanding, and continually disentangling learned semantic factors across data environments. We argue that this is because existing approaches treat continually-arrived data independently, without considering how they are related based on the underlying semantic factors. We address this by a new generative model describing a topologically-connected mixture of spike-and-slab distributions in the latent space, learned end-to-end in a continual fashion via principled variational inference. The learned mixture is able to automatically discover the active semantic factors underlying each data environment and to accumulate their relational structure based on that. This distilled knowledge of different data environments can further be used for generative replay and guiding continual disentangling of new semantic factors. We tested the presented method on a split version of 3DShapes to provide the first quantitative disentanglement evaluation of continually learned representations, and further demonstrated its ability to continually disentangle new representations in benchmark datasets.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 1 Track 6: Deep Learning and representational learning II</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=ih0uFRFhaZZ</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 1 Track 6: Deep Learning and representational learning II</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 1 Track 6: Deep Learning and representational learning II</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 1 Track 3: Neuroscience and Cognitive Science & General Machine Learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 4 Track 6: Deep Learning and representational learning- Reinforcement Learning</div></body></html>