<html><head><meta charset='utf-8'><title>Learning where and when to reason in neuro-symbolic inference</title></head><body><h1>Learning where and when to reason in neuro-symbolic inference</h1><h3>By: ['Cristina Cornelio', 'Jan Stuehmer', 'Xu Hu', 'Timothy Hospedales']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12732</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> The integration of hard constraints on neural network outputs is a very desirable capability. This allows to instill trust in AI by guaranteeing the sanity of that neural network predictions with respect to domain knowledge. Recently, this topic has received a lot of attention. However, all the existing methods usually either impose the constraints in a "weak" form at training time, with no guarantees at inference, or fail to provide a general framework that supports different tasks and constraint types. We tackle this open problem from a neuro-symbolic perspective. Our pipeline enhances a conventional neural predictor with (1) a symbolic reasoning module capable of correcting structured prediction errors and (2) a neural attention module that learns to direct the reasoning effort to focus on potential prediction errors, while keeping other outputs unchanged. This framework provides an appealing trade-off between the efficiency of constraint-free neural inference and the prohibitive cost of exhaustive reasoning at inference time. We show that our method outperforms the state of the art on visual-Sudoku, and can also benefit visual scene graph prediction. Furthermore, it can improve the performance of existing neuro-symbolic systems that lack our explicit reasoning during inference.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2 Track 2: General Machine Learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=en9V5F8PR-</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2 Track 2: General Machine Learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 2 Track 2: General Machine Learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 2 Track 2: General Machine Learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 2 Track 2: General Machine Learning</div></body></html>