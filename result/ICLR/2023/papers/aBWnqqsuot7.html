<html><head><meta charset='utf-8'><title>D4FT_ A Deep Learning Approach to Kohn-Sham Density Functional Theory</title></head><body><h1>D4FT_ A Deep Learning Approach to Kohn-Sham Density Functional Theory</h1><h3>By: ['Tianbo Li', 'Min Lin', 'Zheyuan Hu', 'Kunhao Zheng', 'Giovanni Vignale', 'Kenji Kawaguchi', 'A. Castro Neto', 'Kostya Novoselov', 'shuicheng YAN']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12668</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Kohn-Sham Density Functional Theory (KS-DFT) has been traditionally solved by the Self-Consistent Field (SCF) method. Behind the SCF loop is the physics intuition of solving a system of non-interactive single-electron wave functions under an effective potential. In this work, we propose a deep learning approach to KS-DFT. First, in contrast to the conventional SCF loop, we propose to directly minimize the total energy by reparameterizing the orthogonal constraint as a feed-forward computation. We prove that such an approach has the same expressivity as the SCF method, yet reduces the computational complexity from O(N^4) to O(N^3). Second, the numerical integration which involves a summation over the quadrature grids can be amortized to the optimization steps. At each step, stochastic gradient descent (SGD) is performed with a sampled minibatch of the grids. Extensive experiments are carried out to demonstrate the advantage of our approach in terms of efficiency and stability. In addition, we show that our approach enables us to explore more complex neural-based wave functions.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 1 Track 2: Machine Learning for Sciences</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=aBWnqqsuot7</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 1 Track 2: Machine Learning for Sciences</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 2 Track 6: Applications & Social Aspects of Machine Learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 4 Track 5: Machine Learning for Sciences & Probabilistic Methods</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 1 Track 2: Machine Learning for Sciences</div></body></html>