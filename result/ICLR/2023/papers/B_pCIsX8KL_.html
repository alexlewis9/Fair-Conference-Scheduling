<html><head><meta charset='utf-8'><title>GRACE-C_ Generalized Rate Agnostic Causal Estimation via Constraints</title></head><body><h1>GRACE-C_ Generalized Rate Agnostic Causal Estimation via Constraints</h1><h3>By: ['Mohammadsajad Abavisani', 'David Danks', 'Sergey Plis']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12717</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Graphical structures estimated by causal learning algorithms from time series data can provide highly misleading causal information if the causal timescale of the generating process fails to match the measurement timescale of the data. Existing algorithms provide limited resources to respond to this challenge, and so researchers must either use models that they know are likely misleading, or else forego causal learning entirely. Existing methods face up-to-four distinct shortfalls, as they might a) require that the difference between causal and measurement timescales is known; b) only handle very small number of random variables when the timescale difference is unknown; c) only apply to pairs of variables (albeit with fewer assumptions about prior knowledge); or d) be unable to find a solution given statistical noise in the data. This paper aims to address these challenges. We present an approach that combines constraint programming with both theoretical insights into the problem structure and prior information about admissible causal interactions to achieve speed up of multiple orders of magnitude. The resulting system scales to significantly larger sets of random variables ($>100$) without knowledge of the timescale difference while maintaining  theoretical guarantees. This method is also robust to edge misidentification and can use parametric connection strengths, while optionally finding the optimal among many possible solutions.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 4 Track 2: Probabilistic Methods</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=B_pCIsX8KL_</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 4 Track 2: Probabilistic Methods</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 4 Track 2: Probabilistic Methods</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 5 Track 3: Deep Learning and representational learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 4 Track 2: Probabilistic Methods</div></body></html>