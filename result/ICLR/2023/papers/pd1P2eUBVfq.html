<html><head><meta charset='utf-8'><title>Diffusion Models Already Have A Semantic Latent Space</title></head><body><h1>Diffusion Models Already Have A Semantic Latent Space</h1><h3>By: ['Mingi Kwon', 'Jaeseok Jeong', 'Youngjung Uh']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12589</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Diffusion models achieve outstanding generative performance in various domains. Despite their great success, they lack semantic latent space which is essential for controlling the generative process. To address the problem, we propose asymmetric reverse process (Asyrp) which discovers the semantic latent space in frozen pretrained diffusion models. Our semantic latent space, named h-space, has nice properties for accommodating semantic image manipulation: homogeneity, linearity, robustness, and consistency across timesteps. In addition, we measure editing strength and quality deficiency of a generative process at timesteps to provide a principled design of the process for versatility and quality improvements. Our method is applicable to various architectures (DDPM++, iDDPM, and ADM) and datasets (CelebA-HQ, AFHQ-dog, LSUN-church, LSUN-bedroom, and METFACES).</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2 Track 3: Generative models</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=pd1P2eUBVfq</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2 Track 3: Generative models</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 2 Track 3: Generative models</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 2 Track 3: Generative models</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 2 Track 3: Generative models</div></body></html>