<html><head><meta charset='utf-8'><title>Equiformer_ Equivariant Graph Attention Transformer for 3D Atomistic Graphs</title></head><body><h1>Equiformer_ Equivariant Graph Attention Transformer for 3D Atomistic Graphs</h1><h3>By: ['Yi-Lun Liao', 'Tess Smidt']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12753</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Despite their widespread success in various domains, Transformer networks have yet to perform well across datasets in the domain of 3D atomistic graphs such as molecules even when 3D-related inductive biases like translational invariance and rotational equivariance are considered. In this paper, we demonstrate that Transformers can generalize well to 3D atomistic graphs and present Equiformer, a graph neural network leveraging the strength of Transformer architectures and incorporating SE(3)/E(3)-equivariant features based on irreducible representations (irreps). First, we propose a simple and effective architecture by only replacing original operations in Transformers with their equivariant counterparts and including tensor products. Using equivariant operations enables encoding equivariant information in channels of irreps features without complicating graph structures. With minimal modifications to Transformers, this architecture has already achieved strong empirical results. Second, we propose a novel attention mechanism called equivariant graph attention, which improves upon typical attention in Transformers through replacing dot product attention with multi-layer perceptron attention and including non-linear message passing. With these two innovations, Equiformer achieves competitive results to previous models on QM9, MD17 and OC20 datasets.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 1 Track 2: Machine Learning for Sciences</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=KwmPfARgOTD</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 1 Track 2: Machine Learning for Sciences</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 4 Track 5: Machine Learning for Sciences & Probabilistic Methods</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 4 Track 5: Machine Learning for Sciences & Probabilistic Methods</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 1 Track 1: Deep Learning and representational learning I</div></body></html>