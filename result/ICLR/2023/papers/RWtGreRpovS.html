<html><head><meta charset='utf-8'><title>Simplicial Embeddings in Self-Supervised Learning and Downstream Classification</title></head><body><h1>Simplicial Embeddings in Self-Supervised Learning and Downstream Classification</h1><h3>By: ['Samuel Lavoie', 'Christos Tsirigotis', 'Max Schwarzer', 'Ankit Vani', 'Mikhail Noukhovitch', 'Kenji Kawaguchi', 'Aaron Courville']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12601</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Simplicial Embeddings (SEM) are representations learned through self-supervised learning (SSL), wherein a representation is projected into $L$ simplices of $V$ dimensions each using a \texttt{softmax} operation. This procedure conditions the representation onto a constrained space during pretraining and imparts an inductive bias for group sparsity. For downstream classification, we formally prove that the SEM representation leads to better generalization than an unnormalized representation.Furthermore, we empirically demonstrate that SSL methods trained with SEMs have improved generalization on natural image datasets such as CIFAR-100 and ImageNet. Finally, when used in a downstream classification task, we show that SEM features exhibit emergent semantic coherence where small groups of learned features are distinctly predictive of semantically-relevant classes.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 5 Track 1: Unsupervised and Self-supervised learning & Social Aspects of Machine Learning-</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=RWtGreRpovS</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 5 Track 1: Unsupervised and Self-supervised learning & Social Aspects of Machine Learning-</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 3 Track 4: General Machine Learning & Unsupervised and Self-supervised learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 6 Track 3: Deep Learning and representational learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 6 Track 2: Infrastructure & Social Aspects of Machine Learning</div></body></html>