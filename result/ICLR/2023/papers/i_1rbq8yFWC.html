<html><head><meta charset='utf-8'><title>Rhino_ Deep Causal Temporal Relationship Learning with History-dependent Noise</title></head><body><h1>Rhino_ Deep Causal Temporal Relationship Learning with History-dependent Noise</h1><h3>By: ['Wenbo Gong', 'Joel Jennings', 'Cheng Zhang', 'Nick Pawlowski']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12768</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Discovering causal relationships between different variables from time series data has been a long-standing challenge for many domains. For example, in stock markets, the announcement of acquisitions from leading companies may have immediate effects on stock prices and increase the uncertainty of the future market due to this past action. To discover causal relations in such case, the model needs to consider non-linear relations between variables, instantaneous effect and the change of noise distribution due to past actions. We name the latter as history-dependent noise. However, previous works do not offer a solution addressing all these problems together. In this paper, we propose a structural equation model, called Rhino, which combines vector auto-regression, deep learning and variational inference to model non-linear relationships with instantaneous effects while allowing the noise distribution to be modulated by history observations. Theoretically, we prove the structural identifiability of Rhino. Our empirical results from extensive synthetic experiments and two real-world benchmarks demonstrate better discovery performance compared to relevant baselines, with ablation studies revealing its robustness under model misspecification.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 4 Track 2: Probabilistic Methods</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=i_1rbq8yFWC</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 4 Track 2: Probabilistic Methods</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 4 Track 5: Machine Learning for Sciences & Probabilistic Methods</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 5 Track 3: Deep Learning and representational learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 4 Track 2: Probabilistic Methods</div></body></html>