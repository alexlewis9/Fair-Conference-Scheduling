<html><head><meta charset='utf-8'><title>Multi-skill Mobile Manipulation for Object Rearrangement</title></head><body><h1>Multi-skill Mobile Manipulation for Object Rearrangement</h1><h3>By: ['Jiayuan Gu', 'Devendra Singh Chaplot', 'Hao Su', 'Jitendra Malik']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12568</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> We study a modular approach to tackle long-horizon mobile manipulation tasks for object rearrangement, which decomposes a full task into a sequence of subtasks. To tackle the entire task, prior work chains multiple stationary manipulation skills with a point-goal navigation skill, which are learned individually on subtasks. Although more effective than monolithic end-to-end RL policies, this framework suffers from compounding errors in skill chaining, e.g., navigating to a bad location where a stationary manipulation skill can not reach its target to manipulate. To this end, we propose that the manipulation skills should include mobility to have flexibility in interacting with the target object from multiple locations and at the same time the navigation skill could have multiple end points which lead to successful manipulation. We operationalize these ideas by implementing mobile manipulation skills rather than stationary ones and training a navigation skill trained with region goal instead of point goal. We evaluate our multi-skill mobile manipulation method M3 on 3 challenging long-horizon mobile manipulation tasks in the Home Assistant Benchmark (HAB), and show superior performance as compared to the baselines.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2 Track 4: Reinforcement Learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=Z3IClM_bzvP</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2 Track 4: Reinforcement Learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 2 Track 4: Reinforcement Learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 2 Track 4: Reinforcement Learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 2 Track 4: Reinforcement Learning</div></body></html>