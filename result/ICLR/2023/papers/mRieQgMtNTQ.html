<html><head><meta charset='utf-8'><title>Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model</title></head><body><h1>Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model</h1><h3>By: ['Yinhuai Wang', 'Jiwen Yu', 'Jian Zhang']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12622</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Most existing Image Restoration (IR) models are task-specific, which can not be generalized to different degradation operators. In this work, we propose the Denoising Diffusion Null-Space Model (DDNM), a novel zero-shot framework for arbitrary linear IR problems, including but not limited to image super-resolution, colorization, inpainting, compressed sensing, and deblurring. DDNM only needs a pre-trained off-the-shelf diffusion model as the generative prior, without any extra training or network modifications. By refining only the null-space contents during the reverse diffusion process, we can yield diverse results satisfying both data consistency and realness. We further propose an enhanced and robust version, dubbed DDNM+, to support noisy restoration and improve restoration quality for hard tasks. Our experiments on several IR tasks reveal that DDNM outperforms other state-of-the-art zero-shot IR methods. We also demonstrate that DDNM+ can solve complex real-world applications, e.g., old photo restoration.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 6 Track 4: Applications & Social Aspects of Machine Learning & General Machine Learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=mRieQgMtNTQ</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 6 Track 4: Applications & Social Aspects of Machine Learning & General Machine Learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 2 Track 3: Generative models</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 3 Track 3: Generative models</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 3 Track 4: General Machine Learning & Unsupervised and Self-supervised learning</div></body></html>