<html><head><meta charset='utf-8'><title>Emergent World Representations_ Exploring a Sequence Model Trained on a Synthetic Task</title></head><body><h1>Emergent World Representations_ Exploring a Sequence Model Trained on a Synthetic Task</h1><h3>By: ['Kenneth Li', 'Aspen Hopkins', 'David Bau', 'Fernanda Vi√©gas', 'Hanspeter Pfister', 'Martin Wattenberg']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12641</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Language models show a surprising range of capabilities, but the source of their apparent competence is unclear. Do these networks just memorize a collection of surface statistics, or do they rely on internal representations of the process that generates the sequences they see? We investigate this question by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has no a priori knowledge of the game or its rules, we uncover evidence of an emergent nonlinear internal representation of the board state. Interventional experiments indicate this representation can be used to control the output of the network and create "latent saliency maps" that can help explain predictions in human terms.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 3 Track 5: Deep Learning and representational learning & Neuroscience and Cognitive Science</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=DeG07_TcZvT</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 3 Track 5: Deep Learning and representational learning & Neuroscience and Cognitive Science</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 5 Track 1: Unsupervised and Self-supervised learning & Social Aspects of Machine Learning-</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 2 Track 4: Reinforcement Learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 4 Track 4: Reinforcement Learning II</div></body></html>