<html><head><meta charset='utf-8'><title>Domain Generalization via Heckman-type Selection Models</title></head><body><h1>Domain Generalization via Heckman-type Selection Models</h1><h3>By: ['Hyungu Kahng', 'Hyungrok Do', 'Judy Zhong']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12545</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> The domain generalization (DG) setup considers the problem where models are trained on data sampled from multiple domains and evaluated on test domains unseen during training. In this paper, we formulate DG as a sample selection problem where each domain is sampled from a common underlying population through non-random sampling probabilities that correlate with both the features and the outcome. Under this setting, the fundamental iid assumption of the empirical risk minimization (ERM) is violated, so it often performs worse on test domains whose non-random sampling probabilities differ from the domains in the training dataset. We propose a Selection-Guided DG (SGDG) framework to learn the selection probability of each domain and the joint distribution of the outcome and domain selection variables. The proposed SGDG is domain generalizable as it intends to minimize the risk under the population distribution. We theoretically proved that, under certain regular conditions, SGDG can achieve smaller risk than ERM. Furthermore, we present a class of parametric SGDG (HeckmanDG) estimators applicable to continuous, binary, and multinomial outcomes. We also demonstrated its efficacy empirically through simulations and experiments on a set of benchmark datasets comparing with other well-known DG methods.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 1 Track 3: Neuroscience and Cognitive Science & General Machine Learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=fk7RbGibe1</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 1 Track 3: Neuroscience and Cognitive Science & General Machine Learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 1 Track 3: Neuroscience and Cognitive Science & General Machine Learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 4 Track 1: Unsupervised and Self-supervised learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 1 Track 6: Deep Learning and representational learning II</div></body></html>