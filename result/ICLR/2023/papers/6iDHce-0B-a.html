<html><head><meta charset='utf-8'><title>Implicit Bias of Large Depth Networks_ a Notion of Rank for Nonlinear Functions</title></head><body><h1>Implicit Bias of Large Depth Networks_ a Notion of Rank for Nonlinear Functions</h1><h3>By: ['Arthur Jacot']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12530</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> We show that the representation cost of fully connected neural networks with homogeneous nonlinearities - which describes the implicit bias in function space of networks with $L_2$-regularization or with losses such as the cross-entropy - converges as the depth of the network goes to infinity to a notion of rank over nonlinear functions. We then inquire under which conditions the global minima of the loss recover the `true' rank of the data: we show that for too large depths the global minimum will be approximately rank 1 (underestimating the rank); we then argue that there is a range of depths which grows with the number of datapoints where the true rank is recovered. Finally, we discuss the effect of the rank of a classifier on the topology of the resulting class boundaries and show that autoencoders with optimal nonlinear rank are naturally denoising.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 2 Track 5: Generative models & Theory</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=6iDHce-0B-a</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 2 Track 5: Generative models & Theory</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 2 Track 6: Applications & Social Aspects of Machine Learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 4 Track 6: Deep Learning and representational learning- Reinforcement Learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 6 Track 1: Theory</div></body></html>