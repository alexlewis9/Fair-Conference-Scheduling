<html><head><meta charset='utf-8'><title>Data Continuity Matters_ Improving Sequence Modeling with Lipschitz Regularizer</title></head><body><h1>Data Continuity Matters_ Improving Sequence Modeling with Lipschitz Regularizer</h1><h3>By: ['Eric Qu', 'Xufang Luo', 'Dongsheng Li']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12563</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Sequence modeling is a core problem in machine learning, and various neural networks have been designed to process different types of sequence data. However, few attempts have been made to understand the inherent data property of sequence data, neglecting the critical factor that may significantly affect the performance of sequence modeling. In this paper, we theoretically and empirically analyze a generic property of sequence data, i.e., continuity, and connect this property with the performance of deep models. First, we empirically observe that different kinds of models for sequence modeling prefer data with different continuity. Then, we theoretically analyze the continuity preference of different models in both time and frequency domains. To further utilize continuity to improve sequence modeling, we propose a simple yet effective Lipschitz Regularizer, that can flexibly adjust data continuity according to model preferences, and bring very little extra computational cost. Extensive experiments on various tasks demonstrate that altering data continuity via Lipschitz Regularizer can largely improve the performance of many deep models for sequence modeling.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 6 Track 5: Applications- & Deep Learning and representational learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=27uBgHuoSQ</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 6 Track 5: Applications- & Deep Learning and representational learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 1 Track 1: Deep Learning and representational learning I</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 5 Track 5: Deep Learning and representational learning & Reinforcement Learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 1 Track 1: Deep Learning and representational learning I</div></body></html>