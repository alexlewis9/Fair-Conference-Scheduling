<html><head><meta charset='utf-8'><title>Compressing multidimensional weather and climate data into neural networks</title></head><body><h1>Compressing multidimensional weather and climate data into neural networks</h1><h3>By: ['Langwen Huang', 'Torsten Hoefler']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12656</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Weather and climate simulations produce petabytes of high-resolution data that are later analyzed by researchers in order to understand climate change or severe weather. We propose a new method of compressing this multidimensional weather and climate data: a coordinate-based neural network is trained to overfit the data, and the resulting parameters are taken as a compact representation of the original grid-based data. While compression ratios range from 300x to more than 3,000x, our method outperforms the state-of-the-art compressor SZ3 in terms of weighted RMSE, MAE. It can faithfully preserve important large scale atmosphere structures and does not introduce significant artifacts.When using the resulting neural network as a 790x compressed dataloader to train the WeatherBench forecasting model, its RMSE increases by less than 2%. The three orders of magnitude compression democratizes access to high-resolution climate data and enables numerous new research directions.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 1 Track 2: Machine Learning for Sciences</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=Y5SEe3dfniJ</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 1 Track 2: Machine Learning for Sciences</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 1 Track 2: Machine Learning for Sciences</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 1 Track 2: Machine Learning for Sciences</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 1 Track 2: Machine Learning for Sciences</div></body></html>