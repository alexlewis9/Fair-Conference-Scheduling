<html><head><meta charset='utf-8'><title>Nonlinear Reconstruction for Operator Learning of PDEs with Discontinuities</title></head><body><h1>Nonlinear Reconstruction for Operator Learning of PDEs with Discontinuities</h1><h3>By: ['Samuel Lanthaler', 'Roberto Molinaro', 'Patrik Hadorn', 'Siddhartha Mishra']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12757</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Discontinuous solutions arise in a large class of hyperbolic and advection-dominated PDEs. This paper investigates, both theoretically and empirically, the operator learning of PDEs with discontinuous solutions. We rigorously prove, in terms of lower approximation bounds, that methods which entail a linear reconstruction step (e.g. DeepONets or PCA-Nets) fail to efficiently approximate the solution operator of such PDEs. In contrast, we show that certain methods employing a non-linear reconstruction mechanism can overcome these fundamental lower bounds and approximate the underlying operator efficiently. The latter class includes Fourier Neural Operators and a novel extension of DeepONets termed shift-DeepONets. Our theoretical findings are confirmed by empirical results for advection equations, inviscid Burgersâ€™ equation and the compressible Euler equations of gas dynamics.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 6 Track 1: Theory</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=CrfhZAsJDsZ</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 6 Track 1: Theory</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 3 Track 3: Generative models</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 6 Track 1: Theory</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 1 Track 2: Machine Learning for Sciences</div></body></html>