<html><head><meta charset='utf-8'><title>Packed Ensembles for efficient uncertainty estimation</title></head><body><h1>Packed Ensembles for efficient uncertainty estimation</h1><h3>By: ['Olivier Laurent', 'Adrien Lafage', 'Enzo Tartaglione', 'Geoffrey Daniel', 'Jean-marc Martinez', 'Andrei Bursuc', 'Gianni Franchi']</h3><hr><h4>publisher</h4><div style='margin-bottom:1em'>ICLR</div><h4>url</h4><div style='margin-bottom:1em'>https://iclr.cc/virtual/2023/oral/12701</div><h4>year</h4><div style='margin-bottom:1em'>2023</div><h4>abstract</h4><div style='margin-bottom:1em'> Deep Ensembles (DE) are a prominent approach for achieving excellent performance on key metrics such as accuracy, calibration, uncertainty estimation, and out-of-distribution detection. However, hardware limitations of real-world systems constrain to smaller ensembles and lower-capacity networks, significantly deteriorating their performance and properties. We introduce Packed-Ensembles (PE), a strategy to design and train lightweight structured ensembles by carefully modulating the dimension of their encoding space. We leverage grouped convolutions to parallelize the ensemble into a single shared backbone and forward pass to improve training and inference speeds. PE is designed to operate within the memory limits of a standard neural network. Our extensive research indicates that PE accurately preserves the properties of DE, such as diversity, and performs equally well in terms of accuracy, calibration, out-of-distribution detection, and robustness to distribution shift. We make our code available at https://github.com/ENSTA-U2IS/torch-uncertainty.</div><h4>session</h4><div style='margin-bottom:1em'>Oral 6 Track 6: Deep Learning</div><h4>pdf_url</h4><div style='margin-bottom:1em'>https://openreview.net/pdf?id=XXTyv1zD9zD</div><h4>openreview_url</h4><div style='margin-bottom:1em'>nan</div><h4>Baseline</h4><div style='margin-bottom:1em'>Oral 6 Track 6: Deep Learning</div><h4>GreedyCohesive</h4><div style='margin-bottom:1em'>Oral 4 Track 6: Deep Learning and representational learning- Reinforcement Learning</div><h4>KMedoids</h4><div style='margin-bottom:1em'>Oral 6 Track 5: Applications- & Deep Learning and representational learning</div><h4>KMeans</h4><div style='margin-bottom:1em'>Oral 6 Track 6: Deep Learning</div></body></html>