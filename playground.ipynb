{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import math\n",
    "\n",
    "def tau_closest_agents(agent, agents, d, tau) -> tuple[list[str], float]:\n",
    "    \"\"\"Return the list of tau-closest agents to agent.\n",
    "    agent: agent's id\n",
    "    agents: list of agents' id\n",
    "    d: distance function\n",
    "    tau: threshold number (usually number of agents in a cluster)\n",
    "\n",
    "    Return:\n",
    "        - list of tau-closest agents' id\n",
    "        - distance to the furthest agent\n",
    "    \"\"\"\n",
    "    return None # TODO: implement\n",
    "\n",
    "\n",
    "def SmallestAgentBall(agents, d, tau) -> list[str]:\n",
    "    \"\"\"Return the set of per_clusterclosest agents to the agent of the smallest ball.\n",
    "    N: list of agents' id\n",
    "    d: distance function\n",
    "    tau: threshold number (usually number of agents in a cluster)\n",
    "    \"\"\"\n",
    "    if len(agents) <= tau:\n",
    "        return agents[:]\n",
    "    lst = [] # (agent, its tau-closest agent, distance) #TODO: find a better name\n",
    "    for agent in agents:\n",
    "        closest_agents = tau_closest_agents(agent, agents, d, tau) # (list, distance to the furthest)\n",
    "        lst.append((agent, *closest_agents))\n",
    "    min_ball = min(lst, key=lambda x: x[2])\n",
    "    return min_ball[1]\n",
    "\n",
    "\n",
    "def GreedyCohesiveClustering(agents, d, k) -> list[list[str]]:\n",
    "    \"\"\" Return the k cohesive clusters of agents by metric d. Each cluster is a list of id.\n",
    "    agents: list of agents' id\n",
    "    d: distance function\n",
    "    k: number of clusters to return\n",
    "    \"\"\"\n",
    "    clusters = [] # each cluster is a list of id\n",
    "    N = agents[:]\n",
    "    j = 1\n",
    "    per_cluster = math.ceil(len(agents)/k)\n",
    "    while N:\n",
    "        C_j = SmallestAgentBall(N, d, per_cluster)\n",
    "        clusters.append(C_j)\n",
    "        for agent in C_j:\n",
    "            N.remove(agent)\n",
    "        j += 1\n",
    "    return clusters\n"
   ],
   "id": "1cd7d8b7cdaddb13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ],
   "id": "f578a4a43c0fd3d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(\"API KEY:\", os.getenv(\"OPENAI_API_KEY\"))\n",
   "id": "f19b07c79b382cbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "10de2eda30f2c507"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:02:27.590680Z",
     "start_time": "2025-05-13T20:02:27.274417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import fitz\n",
    "from tqdm import tqdm"
   ],
   "id": "8d4c2d4bd210f7e2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:11:10.620595Z",
     "start_time": "2025-05-13T20:11:10.617816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {str(e)}\")\n",
    "        return \"\""
   ],
   "id": "e5968c16715c695",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:22:12.008995Z",
     "start_time": "2025-05-13T20:21:42.316339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read metadata\n",
    "df = pd.read_csv('./data/metadata/ICLR_2021_2024.csv')\n",
    "\n",
    "# Create unified text directory if it doesn't exist\n",
    "os.makedirs('./data/unified_text/ICLR', exist_ok=True)\n",
    "\n",
    "# Process each year\n",
    "# years = range(2021, 2025)\n",
    "years = [2024]\n",
    "for year in years:\n",
    "    year_data = []\n",
    "    year_df = df[df['year'] == year]\n",
    "\n",
    "    for _, row in tqdm(year_df.iterrows(), total=len(year_df)):\n",
    "        paper_id = row['id']\n",
    "        title = row['title']\n",
    "        txt_path = f'./data/txts/ICLR_2021_2024/{title}.txt'\n",
    "        pdf_path = f'./data/pdfs/ICLR_2021_2024/{title}.pdf'\n",
    "\n",
    "        paper_dict = row.to_dict()\n",
    "\n",
    "        # Try to get text from txt file first\n",
    "        if os.path.exists(txt_path):\n",
    "            with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "                paper_dict['text'] = f.read()\n",
    "        # If txt doesn't exist, extract from PDF\n",
    "        elif os.path.exists(pdf_path):\n",
    "            paper_dict['text'] = extract_text_from_pdf(pdf_path)\n",
    "        else:\n",
    "            paper_dict['text'] = \"\"\n",
    "            print(f\"Neither txt nor pdf found for paper {paper_id}\")\n",
    "\n",
    "        year_data.append(paper_dict)\n",
    "\n",
    "    # Save to JSON\n",
    "    output_path = f'./data/unified_text/ICLR/ICLR_{year}.json'\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(year_data, f, ensure_ascii=False, indent=2)\n"
   ],
   "id": "b067757079e3049e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 247/247 [00:28<00:00,  8.66it/s]\n",
      "100%|██████████| 86/86 [00:00<00:00, 102.87it/s]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T19:41:25.793020Z",
     "start_time": "2025-05-13T19:41:25.632110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = extract_text_from_pdf('./data/pdfs/ICLR_2021_2024/An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment.pdf')\n",
    "with open(\"./data/unified_text/ICLR/ICLR_2024.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "for entry in data:\n",
    "    if entry['title'] == 'An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment':\n",
    "        entry['text'] = text\n",
    "with open(\"./data/unified_text/ICLR/ICLR_2024.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n"
   ],
   "id": "4543f961585775c6",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:11:16.887011Z",
     "start_time": "2025-05-13T20:11:16.647474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# unify for neurips\n",
    "# Read metadata\n",
    "df = pd.read_csv('./data/metadata/neurips_2023_2024.csv')\n",
    "\n",
    "# Create unified text directory if it doesn't exist\n",
    "os.makedirs('./data/unified_text/NeurIPS', exist_ok=True)\n",
    "\n",
    "# Process each year\n",
    "years = range(2023, 2025)\n",
    "for year in years:\n",
    "    year_data = []\n",
    "    year_df = df[df['year'] == year]\n",
    "\n",
    "    for _, row in tqdm(year_df.iterrows(), total=len(year_df)):\n",
    "        paper_id = row['id']\n",
    "        title = row['title']\n",
    "        txt_path = f'./data/txts/neurips_2023_2024/{title}.txt'\n",
    "        pdf_path = f'./data/pdfs/neurips_23_24/{title}.pdf'\n",
    "\n",
    "        paper_dict = row.to_dict()\n",
    "\n",
    "        # Try to get text from txt file first\n",
    "        if os.path.exists(txt_path):\n",
    "            with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "                paper_dict['text'] = f.read()\n",
    "        # If txt doesn't exist, extract from PDF\n",
    "        elif os.path.exists(pdf_path):\n",
    "            paper_dict['text'] = extract_text_from_pdf(pdf_path)\n",
    "        else:\n",
    "            paper_dict['text'] = \"\"\n",
    "            print(pdf_path)\n",
    "            print(f\"Neither txt nor pdf found for paper {paper_id}\")\n",
    "\n",
    "        year_data.append(paper_dict)\n",
    "\n",
    "    # Save to JSON\n",
    "    output_path = f'./data/unified_text/NeurIPS/{year}.json'\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(year_data, f, ensure_ascii=False, indent=2)\n"
   ],
   "id": "69a249537e748361",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 2208.22it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 1984.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/pdfs/neurips_23_24/The PRISM Alignment Dataset_ What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models.pdf\n",
      "Neither txt nor pdf found for paper DFr5hteojx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:22:54.091950Z",
     "start_time": "2025-05-13T20:22:52.989533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = extract_text_from_pdf('./data/pdfs/neurips_23_24/The PRISM Alignment Dataset_ What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large L.pdf')\n",
    "with open(\"data/unified_text/NeurIPS/NeurIPS_2024.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "for entry in data:\n",
    "    if entry['title'] == 'The PRISM Alignment Dataset_ What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models':\n",
    "        entry['text'] = text\n",
    "        print('success')\n",
    "with open(\"data/unified_text/NeurIPS/NeurIPS_2024.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n"
   ],
   "id": "266e259a9f2e91e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:25:39.046487Z",
     "start_time": "2025-05-13T20:25:38.623303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/metadata/ICLR_2021_2024.csv')\n",
    "df = df[df['year'] == 2024]\n",
    "print(df.shape)\n",
    "\n",
    "with open(\"./data/unified_text/ICLR/ICLR_2024.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "count = 0\n",
    "miss_content = 0\n",
    "for entry in data:\n",
    "    count += 1\n",
    "    if entry['text'] == '':\n",
    "        miss_content += 1\n",
    "        print(entry['title'])\n",
    "print(count)\n",
    "print(miss_content)"
   ],
   "id": "49a322a0526e8cb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86, 11)\n",
      "86\n",
      "0\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:54:20.858916Z",
     "start_time": "2025-05-14T15:49:11.731835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"Alibaba-NLP/gte-Qwen2-7B-instruct\", trust_remote_code=True)\n",
    "# In case you want to reduce the maximum length:\n",
    "model.max_seq_length = 8192\n",
    "\n",
    "doc1 = \"As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\"\n",
    "\n",
    "doc2 = \"Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.\"\n",
    "\n",
    "\n",
    "\n",
    "doc1_emb = model.encode(doc1)\n",
    "doc2_emb = model.encode(doc2)\n",
    "\n",
    "score = (doc1_emb @ doc2_emb.T) * 100\n",
    "\n",
    "\n",
    "print(score.tolist())\n"
   ],
   "id": "fec346ee15d81d9e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiend\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\tiend\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tiend\\.cache\\huggingface\\hub\\models--Alibaba-NLP--gte-Qwen2-7B-instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "A new version of the following files was downloaded from https://huggingface.co/Alibaba-NLP/gte-Qwen2-7B-instruct:\n",
      "- modeling_qwen.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Fetching 7 files:   0%|          | 0/7 [04:34<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SentenceTransformer\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m model = \u001B[43mSentenceTransformer\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mAlibaba-NLP/gte-Qwen2-7B-instruct\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# In case you want to reduce the maximum length:\u001B[39;00m\n\u001B[32m      5\u001B[39m model.max_seq_length = \u001B[32m8192\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:309\u001B[39m, in \u001B[36mSentenceTransformer.__init__\u001B[39m\u001B[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001B[39m\n\u001B[32m    300\u001B[39m         model_name_or_path = __MODEL_HUB_ORGANIZATION__ + \u001B[33m\"\u001B[39m\u001B[33m/\u001B[39m\u001B[33m\"\u001B[39m + model_name_or_path\n\u001B[32m    302\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_sentence_transformer_model(\n\u001B[32m    303\u001B[39m     model_name_or_path,\n\u001B[32m    304\u001B[39m     token,\n\u001B[32m   (...)\u001B[39m\u001B[32m    307\u001B[39m     local_files_only=local_files_only,\n\u001B[32m    308\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m309\u001B[39m     modules, \u001B[38;5;28mself\u001B[39m.module_kwargs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_load_sbert_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    310\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    311\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    312\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_folder\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    313\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    314\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    315\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    316\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    317\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    318\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    319\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    320\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    321\u001B[39m     modules = \u001B[38;5;28mself\u001B[39m._load_auto_model(\n\u001B[32m    322\u001B[39m         model_name_or_path,\n\u001B[32m    323\u001B[39m         token=token,\n\u001B[32m   (...)\u001B[39m\u001B[32m    330\u001B[39m         config_kwargs=config_kwargs,\n\u001B[32m    331\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1808\u001B[39m, in \u001B[36mSentenceTransformer._load_sbert_model\u001B[39m\u001B[34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001B[39m\n\u001B[32m   1805\u001B[39m \u001B[38;5;66;03m# Try to initialize the module with a lot of kwargs, but only if the module supports them\u001B[39;00m\n\u001B[32m   1806\u001B[39m \u001B[38;5;66;03m# Otherwise we fall back to the load method\u001B[39;00m\n\u001B[32m   1807\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1808\u001B[39m     module = \u001B[43mmodule_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackend\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbackend\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1809\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   1810\u001B[39m     module = module_class.load(model_name_or_path)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:81\u001B[39m, in \u001B[36mTransformer.__init__\u001B[39m\u001B[34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001B[39m\n\u001B[32m     78\u001B[39m     config_args = {}\n\u001B[32m     80\u001B[39m config, is_peft_model = \u001B[38;5;28mself\u001B[39m._load_config(model_name_or_path, cache_dir, backend, config_args)\n\u001B[32m---> \u001B[39m\u001B[32m81\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_load_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackend\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_peft_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     83\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m max_seq_length \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mmodel_max_length\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m tokenizer_args:\n\u001B[32m     84\u001B[39m     tokenizer_args[\u001B[33m\"\u001B[39m\u001B[33mmodel_max_length\u001B[39m\u001B[33m\"\u001B[39m] = max_seq_length\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:181\u001B[39m, in \u001B[36mTransformer._load_model\u001B[39m\u001B[34m(self, model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\u001B[39m\n\u001B[32m    179\u001B[39m     \u001B[38;5;28mself\u001B[39m._load_mt5_model(model_name_or_path, config, cache_dir, **model_args)\n\u001B[32m    180\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m181\u001B[39m     \u001B[38;5;28mself\u001B[39m.auto_model = \u001B[43mAutoModel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    182\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_args\u001B[49m\n\u001B[32m    183\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    185\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_peft_model:\n\u001B[32m    186\u001B[39m     \u001B[38;5;28mself\u001B[39m._load_peft_model(model_name_or_path, config, cache_dir, **model_args, **adapter_only_kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001B[39m, in \u001B[36m_BaseAutoModelClass.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[39m\n\u001B[32m    562\u001B[39m     \u001B[38;5;28mcls\u001B[39m.register(config.\u001B[34m__class__\u001B[39m, model_class, exist_ok=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    563\u001B[39m     model_class = add_generation_mixin_to_remote_model(model_class)\n\u001B[32m--> \u001B[39m\u001B[32m564\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    565\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    566\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    567\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m._model_mapping.keys():\n\u001B[32m    568\u001B[39m     model_class = _get_model_class(config, \u001B[38;5;28mcls\u001B[39m._model_mapping)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:279\u001B[39m, in \u001B[36mrestore_default_torch_dtype.<locals>._wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    277\u001B[39m old_dtype = torch.get_default_dtype()\n\u001B[32m    278\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m279\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    280\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    281\u001B[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4260\u001B[39m, in \u001B[36mPreTrainedModel.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[39m\n\u001B[32m   4250\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   4251\u001B[39m     gguf_file\n\u001B[32m   4252\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m device_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4253\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m ((\u001B[38;5;28misinstance\u001B[39m(device_map, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mdisk\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map.values()) \u001B[38;5;129;01mor\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mdisk\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map)\n\u001B[32m   4254\u001B[39m ):\n\u001B[32m   4255\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   4256\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4257\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mloaded from GGUF files.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4258\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m4260\u001B[39m checkpoint_files, sharded_metadata = \u001B[43m_get_resolved_checkpoint_files\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4261\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4262\u001B[39m \u001B[43m    \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4263\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvariant\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvariant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4264\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgguf_file\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgguf_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4265\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4266\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4267\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_safetensors\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_safetensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4268\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4269\u001B[39m \u001B[43m    \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4270\u001B[39m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4271\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4272\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4273\u001B[39m \u001B[43m    \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4274\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4275\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcommit_hash\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4276\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4278\u001B[39m is_sharded = sharded_metadata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4279\u001B[39m is_quantized = hf_quantizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:1152\u001B[39m, in \u001B[36m_get_resolved_checkpoint_files\u001B[39m\u001B[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash)\u001B[39m\n\u001B[32m   1150\u001B[39m sharded_metadata = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1151\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_sharded:\n\u001B[32m-> \u001B[39m\u001B[32m1152\u001B[39m     checkpoint_files, sharded_metadata = \u001B[43mget_checkpoint_shard_files\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1153\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1154\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresolved_archive_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1155\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1156\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1157\u001B[39m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1158\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1159\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1160\u001B[39m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1161\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1162\u001B[39m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1163\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1164\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1165\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1166\u001B[39m     checkpoint_files = [resolved_archive_file] \u001B[38;5;28;01mif\u001B[39;00m pretrained_model_name_or_path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:1115\u001B[39m, in \u001B[36mget_checkpoint_shard_files\u001B[39m\u001B[34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001B[39m\n\u001B[32m   1111\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m shard_filenames, sharded_metadata\n\u001B[32m   1113\u001B[39m \u001B[38;5;66;03m# At this stage pretrained_model_name_or_path is a model identifier on the Hub. Try to get everything from cache,\u001B[39;00m\n\u001B[32m   1114\u001B[39m \u001B[38;5;66;03m# or download the files\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1115\u001B[39m cached_filenames = \u001B[43mcached_files\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1116\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1117\u001B[39m \u001B[43m    \u001B[49m\u001B[43mshard_filenames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1118\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1119\u001B[39m \u001B[43m    \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1120\u001B[39m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1121\u001B[39m \u001B[43m    \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1122\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1123\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1124\u001B[39m \u001B[43m    \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1125\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1126\u001B[39m \u001B[43m    \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1127\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1128\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1130\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cached_filenames, sharded_metadata\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:439\u001B[39m, in \u001B[36mcached_files\u001B[39m\u001B[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[39m\n\u001B[32m    424\u001B[39m         hf_hub_download(\n\u001B[32m    425\u001B[39m             path_or_repo_id,\n\u001B[32m    426\u001B[39m             filenames[\u001B[32m0\u001B[39m],\n\u001B[32m   (...)\u001B[39m\u001B[32m    436\u001B[39m             local_files_only=local_files_only,\n\u001B[32m    437\u001B[39m         )\n\u001B[32m    438\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m439\u001B[39m         \u001B[43msnapshot_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    440\u001B[39m \u001B[43m            \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    441\u001B[39m \u001B[43m            \u001B[49m\u001B[43mallow_patterns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfull_filenames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    442\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    443\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    444\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    445\u001B[39m \u001B[43m            \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    446\u001B[39m \u001B[43m            \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    447\u001B[39m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    448\u001B[39m \u001B[43m            \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    449\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    450\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    451\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    453\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    454\u001B[39m     \u001B[38;5;66;03m# We cannot recover from them\u001B[39;00m\n\u001B[32m    455\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, RepositoryNotFoundError) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, GatedRepoError):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001B[39m, in \u001B[36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    111\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[32m    112\u001B[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001B[34m__name__\u001B[39m, has_token=has_token, kwargs=kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\huggingface_hub\\_snapshot_download.py:297\u001B[39m, in \u001B[36msnapshot_download\u001B[39m\u001B[34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001B[39m\n\u001B[32m    295\u001B[39m         _inner_hf_hub_download(file)\n\u001B[32m    296\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m297\u001B[39m     \u001B[43mthread_map\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    298\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_inner_hf_hub_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    299\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfiltered_repo_files\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    300\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mFetching \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfiltered_repo_files\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m files\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    301\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_workers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_workers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    302\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# User can use its own tqdm class or the default one from `huggingface_hub.utils`\u001B[39;49;00m\n\u001B[32m    303\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtqdm_class\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtqdm_class\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhf_tqdm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    304\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    306\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m local_dir \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    307\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(os.path.realpath(local_dir))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\tqdm\\contrib\\concurrent.py:69\u001B[39m, in \u001B[36mthread_map\u001B[39m\u001B[34m(fn, *iterables, **tqdm_kwargs)\u001B[39m\n\u001B[32m     55\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     56\u001B[39m \u001B[33;03mEquivalent of `list(map(fn, *iterables))`\u001B[39;00m\n\u001B[32m     57\u001B[39m \u001B[33;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     66\u001B[39m \u001B[33;03m    [default: max(32, cpu_count() + 4)].\u001B[39;00m\n\u001B[32m     67\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     68\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mconcurrent\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfutures\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ThreadPoolExecutor\n\u001B[32m---> \u001B[39m\u001B[32m69\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_executor_map\u001B[49m\u001B[43m(\u001B[49m\u001B[43mThreadPoolExecutor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43miterables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mtqdm_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\tqdm\\contrib\\concurrent.py:51\u001B[39m, in \u001B[36m_executor_map\u001B[39m\u001B[34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001B[39m\n\u001B[32m     47\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m ensure_lock(tqdm_class, lock_name=lock_name) \u001B[38;5;28;01mas\u001B[39;00m lk:\n\u001B[32m     48\u001B[39m     \u001B[38;5;66;03m# share lock in case workers are already using `tqdm`\u001B[39;00m\n\u001B[32m     49\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m PoolExecutor(max_workers=max_workers, initializer=tqdm_class.set_lock,\n\u001B[32m     50\u001B[39m                       initargs=(lk,)) \u001B[38;5;28;01mas\u001B[39;00m ex:\n\u001B[32m---> \u001B[39m\u001B[32m51\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtqdm_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mex\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43miterables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Fair-Conference-Scheduling\\.venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001B[39m, in \u001B[36mtqdm.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1178\u001B[39m time = \u001B[38;5;28mself\u001B[39m._time\n\u001B[32m   1180\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1181\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[32m   1183\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[32m   1184\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:619\u001B[39m, in \u001B[36mExecutor.map.<locals>.result_iterator\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    616\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m fs:\n\u001B[32m    617\u001B[39m     \u001B[38;5;66;03m# Careful not to keep a reference to the popped future\u001B[39;00m\n\u001B[32m    618\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m619\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[43m_result_or_cancel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    620\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    621\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:317\u001B[39m, in \u001B[36m_result_or_cancel\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m    315\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    316\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m317\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfut\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    318\u001B[39m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    319\u001B[39m         fut.cancel()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:451\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    448\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state == FINISHED:\n\u001B[32m    449\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.__get_result()\n\u001B[32m--> \u001B[39m\u001B[32m451\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_condition\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    453\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[32m    454\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\threading.py:359\u001B[39m, in \u001B[36mCondition.wait\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    357\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[32m    358\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m359\u001B[39m         \u001B[43mwaiter\u001B[49m\u001B[43m.\u001B[49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    360\u001B[39m         gotit = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    361\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
