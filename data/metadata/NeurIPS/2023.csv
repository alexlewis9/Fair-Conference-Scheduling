authors,publisher,title,url,year,abstract,session,pdf_url,openreview_url,id,forum_content
"['Jincheng Mei', 'Bo Dai', 'Alekh Agarwal', 'Mohammad Ghavamzadeh', 'Csaba Szepesvari', 'Dale Schuurmans']",NeurIPS,Ordering-based Conditions for Global Convergence of Policy Gradient Methods,https://neurips.cc/virtual/2023/oral/73818,2023," We prove that, for finite-arm bandits with linear function approximation, the global convergence of policy gradient (PG) methods depends on inter-related properties between the policy update and the representation. textcolor{blue}{First}, we establish a few key observations that frame the study: \textbf{(i)} Global convergence can be achieved under linear function approximation without policy or reward realizability, both for the standard Softmax PG and natural policy gradient (NPG). \textbf{(ii)} Approximation error is not a key quantity for characterizing global convergence in either algorithm. \textbf{(iii)} The conditions on the representation that imply global convergence are different between these two algorithms. Overall, these observations call into question approximation error as an appropriate quantity for characterizing the global convergence of PG methods under linear function approximation. \textcolor{blue}{Second}, motivated by these observations, we establish new general results: \textbf{(i)} NPG with linear function approximation achieves global convergence \emph{if and only if} the projection of the reward  onto the representable space preserves the optimal action's rank, a quantity that is not strongly related to approximation error. \textbf{(ii)} The global convergence of Softmax PG occurs if the representation satisfies a non-domination condition and can preserve the ranking of rewards, which goes well beyond policy or reward realizability. We provide experimental results to support these theoretical findings.",Oral 1A RL,https://openreview.net/pdf?id=sW8yGZ4uVJ,https://openreview.net/forum?id=sW8yGZ4uVJ,sW8yGZ4uVJ,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'In this paper, the authors identify a new set of conditions that guarantee global convergence of policy gradient methods in the presence of linear function approximation. The results and the analysis strategy developed in this paper make solid contributions to this topic, which could help advance our understanding about the performance of this widely used policy optimization method. Note that the proof of the main results might require substantial writing in order to improve readability and clarity, which I hope the authors can do in the final version of this paper.'}}, {'comment': {'value': 'Thank you for the response. I have improved my score and recommend the authors to take these points in revision.\n\n1. Sub-optimality gaps in different PG methods under linear function approximation are different. The metric used in natural policy gradient (NPG) [4, Table 2] is not the same as $\\pi_{\\theta_t}^\\top r\\to r(a^\\star)$. \n\n2. The gap between optimal action and second optimal action has been used in literature to show the global convergence of PG methods. The authors shoud discuss and connect this work with them more explicitly. \n\n3. Bandits with function approximation have a large gap with MDPs with function approximation.\n\n4. The ordering-based conditions depend on the order while function approximation error does not. They use different information on MDP.'}}, {'title': {'value': 'Post rebuttal '}, 'comment': {'value': 'I thank the authors for their precise and satisfactory answers to my questions and concerns. I believe this is an interesting and solid paper which provides nice and novel insights about the convergence of PG methods in the linear function approximation setting and which has some potential to be extended to the more challenging MDP setting (despite  important obstacles), the discussion provided by the authors as a general comment (in the rebuttal) regarding this last point is insightful. I raised my score to 8. Here are some minor additional follow-up comments below. \n\n- I read the other reviews and the authors’ responses and I think the discussion regarding the verification of ordering-based conditions following the other reviewers’ comments could be added to the paper. \n\n- 1.b I think the proof in the appendix can be revised to reflect the intuition provided in the rebuttal as a response to 1. b. (i) in particular. I find the overall writing of the third part of the proof rather confusing although the treatment of each of the subcases of the partition is rather clear. I refer in particular to the beginning: Why considering the case where the limit of normalized $\\theta_t$ sequence converges to a constant vector in (47)? It is not very clearly discussed in the appendix what would happen if the normalized sequence does not converge to a fixed vector but rather rotates indefinitely (spiralling towards $+\\infty$). This point was clearer to me after the rebuttal given the responses to 1. b (i) and (ii).  \n\n- 3. A comment added to the paper regarding this would probably be useful, I guess ordering of the features should not be crucial in examples since feature matrices would induce the same linear space. I think it is relevant to show that examples are not only based on column permutations. \n\n- 4. Thank you for the clarification, please update the paper accordingly to clarify this case where there are multiple optimal actions since it is not commented on this. '}}, {'title': {'value': 'Response'}, 'comment': {'value': 'Thank you for the detailed explanation regarding the generalization to MDPs. It further confirms my belief that this paper has made a significant contribution and could potentially lead the way for a new direction. I have read comments from other reviewers, and none raised any new concerns for me. So I will keep my current positive scores. '}}, {'comment': {'value': ""I thank the authors for their thorough and clear response, especially for the discussion of generalization to MDPs. I encourage the authors to present discussions of other cases in the revised version, such as the case where the optimal action is not unique, mentioned by Reviewer WYfH and myself, the case of entropy regularized bandits, and the linear feasibility problem mentioned by Reviewer hbxK. Overall, I am inclined to maintain my score. I will also pay attention to Reviewer WYfH's upcoming comments to see if their concerns on the proofs are cleared up.""}}, {'rebuttal': {'value': 'We appreciate that the reviewer recognized the contribution of the work. We answer the questions as follows.\n\n>**discussion of how to generalize the results to MDPs**\n\nGeneralizing the results to MDPs is an important and challenging next step, as we mentioned in the conclusions. Since other reviewers (P4aQ, m2vF) also asked this question, we present the discussions for MDPs in the common feedback, and please check that for details. Thank you.'}}, {'rebuttal': {'value': 'Thank you for carefully reading and checking the results. The main concerns are addressed as follows.\n\n>**Comment on Khodadadian et al. 2022**\n\nThank you for pointing this out. We will add a remark to mention the similarities and differences between Theorem 2 and Khodadadian et al. 2022.\n\n>**1. (a)**\n\nSuppose there exists $C < \\infty$, s.t. for all $t \\ge 1$, $\\theta_t \\in S_C := \\\\{ \\theta \\in \\mathbb{R}^d: \\\\| \\theta \\\\|_2 \\le C \\\\}$.\n\nFor all $\\theta \\in S_C$, $\\Big\\\\| \\frac{d \\pi\\_{\\theta}^\\top r}{d \\theta} \\Big\\\\|_2 > 0$ (no finite stationary points). Since $S_C$ is compact, we have, $\\inf\\_{\\theta \\in S_C}{ \\Big\\\\| \\frac{d \\pi\\_{\\theta}^\\top r}{d \\theta} \\Big\\\\|_2 } \\ge \\epsilon$ for some $\\epsilon > 0$.\n\nTherefore, for all $t \\ge 1$, $\\Big\\\\| \\frac{d \\pi\\_{\\theta_t}^\\top r}{d \\theta_t} \\Big\\\\|_2 \\ge \\epsilon > 0$, contradicting Eq. (28).\n\n>**1. (b)**\n\n(i) The whole $\\theta_t \\in \\mathbb{R}^d$ space is partitioned into at most $K$ sub-regions (Figure 2). Since the existence of $w \\in \\mathbb{R}^d$, $a^*$ has one sub-region (yellow in Figure 2) which satisfies (by order-preservation),\n\\begin{equation*}\n    \\[ X \\theta_t \\](a^*) = \\max\\_{a \\in [K]} \\[ X \\theta_t \\](a)\n\\end{equation*}\n\nSince $\\\\| \\theta_t \\\\|_2 \\to \\infty$, if **$\\theta_t$ always stays in the above region as $t \\to \\infty$**, then softmax transform gives $\\pi\\_{\\theta_t}(a^*) \\to 1$. We proved that for all $i \\in [K]$ with $r(i) < r(a^*)$, $\\theta_t$ cannot stay in sub-optimal regions forever.\n\nIn addition, $\\theta_t$ cannot switch between different regions. As $\\\\| \\theta \\\\|_2 \\to \\infty$, $\\pi\\_{\\theta}^\\top r \\approx r(i)$ in a region, and switching regions contradicts $\\pi\\_{\\theta\\_{t+1}}^\\top r \\ge \\pi\\_{\\theta_t}^\\top r $ in Eq. (10). Moreover, $\\theta_t$ cannot approach region boundaries, since it makes $\\pi\\_{\\theta_t}$ approach non one-hot policies, such as $(0, 0.5, 0.5, 0)$ in Figure 2, which gives non-zero inner product in Eq. (33), contradicting Eq. (28).\n\n**In summary**, $\\\\| \\theta \\\\|_2 \\to \\infty$ and $\\theta_t$ can only stay in one region, and we proved that $\\theta_t$ cannot stay in any sub-optimal regions, which implies that $\\theta_t$ eventually stays in the optimal region, indicating that $\\pi\\_{\\theta_t}(a^*) \\to 1$.\n\n(ii) Eqs. (69) and (71) give $w^\\top \\theta_t  \\gg 0 \\ge u^\\top \\theta_t$ (the former is unbounded and the later is decreasing), which holds if scaling $w$ and $u$ by constants to get $w\'$ and $u\'$. For a large enough $t \\ge 1$, there exists $w\'$ such that $x_{a^*}^\\top \\theta_t \\ge {w\'}^\\top \\theta_t > {u\'}^\\top \\theta_t \\ge x_{a^-}^\\top \\theta_t$ (geometry argument, $u$ can be arbitrarily close to region boundaries). The direction of $\\theta_t$ approaches $v$ implies $x_{a^*}^\\top v > x_{a^-}^\\top v$, meaning that $\\theta_t$ enters the region in Case 1, contradicting the assumption of Case 2.\n\nFor example, take $u \\propto (-0.9, 1)^\\top$ and $w \\propto (-0.9, -1)^\\top$ in Example 1 (Figure 2), $w^\\top \\theta_t > u^\\top \\theta_t$ implies $\\theta_t(2) < 0$, entering the dark green region (reducing to Case 1). Another example is if $\\\\| x_a \\\\|_2 = 1$ for all $a$ (features are on unit ball), then $u\' = x\\_{a^-}$ satisfies the inequalities.  \n\n(iii) If $j \\in \\mathcal{A}(i)$, then consider the third largest component and discuss the two cases again. If $j \\in \\mathcal{A}(i)$ for all components, then $\\pi_{\\theta_t}$ approaches uniform policy $\\text{softmax}(X v) = \\text{softmax}(\\mathbf{1})$, contradicting $\\theta = \\mathbf{1}$ cannot be a stationary point (unless $ r = \\mathbf{1}$ according to Eq. (33), which is trivial since every policy is optimal).\n\n(iv) This means there exists $C < \\infty$, such that $\\max_{i \\in [K], j \\in [d]} | X_{i,j} | \\le C$ and $\\max_{j \\in [d]} | u(j) | < C$. The result of this is for $y$ in Line 492, $\\max_{i \\in [K]} | y(i) | $ is also bounded since $y := X u$ in Line 489.\n\n>**2.**\n\nIn [1, Thm 1], if $\\theta_1$ is close enough (in a basin of attraction) to one bad local maximum, then gradient ascent will make $\\theta_t$ approach that bad local maximum.\n\nThe ordering-based condition preclude such a case since **first**, Lemma 1 shows that there is no stationary point in any finite region. **Second**, the landscape is ""ordered"" such that any sub-optimal one-hot policy is not a bad local maximum (rigorously speaking they are not even stationary points by being infinitely far). They are ""saddle-point-like"", in the sense of being surrounded by a higher and a lower plateau. This creates a situation that any sub-optimal one-hot is not attracting gradient trajectories, and the optimal plateau is the only ""local-maximum-like stationary point"" in Figure 1(a).\n\n>**3.**\n\nThis is partially correct. If we change the numbers in Example 1 and use the same Examples 2 and 3, the same conclusion still holds, e.g., use $r = (9.2, 7.8, 7.1, 6.3)^\\top$ and $X^\\top = \\[ -0.2, -1.1, 0.1, 2.1 ; -1.9, 0.2, 0.8, 0.1 \\]$ as Example 1.\n\n>**4.**\n\nHaving multiple optimal actions does not change the conclusion of $\\pi_{\\theta_t}^\\top r \\to r(a^*)$. The difference is that the behaviour of optimal actions\' probabilities needs to be discussed in a case by case manner, depending on whether different optimal actions\' plateaus are connected or separated on landscape.\n\nConsider if $a_1^*$ and $a_2^*$ with $r(a_1^*) = r(a_2^*)$. If the plateaus for those two actions are separated on the landscape in Figure 1 (this is an intuitive statement), then we will have either $\\pi_{\\theta_t}(a_1^*) \\to 1$ or $\\pi_{\\theta_t}(a_2^*) \\to 1$ depending on where the initialization $\\theta_1$. Otherwise,  If the plateaus for those two actions are connected on the landscape (neighborhoods of one another), then we will have $\\pi_{\\theta_t}(a_1^*) + \\pi_{\\theta_t}(a_2^*) \\to 1$, since the current analysis only gives $\\theta_t$ approach the ""joint"" optimal plateau formed by $a_1^*$ and $a_2^*$.\n\n>**Typos and Minor comments**\n\nThank you for catching typos and minor issues.  We will ensure these are fixed.'}}, {'rebuttal': {'value': 'We appreciate that the reviewer understood and recognized the contribution of the work. We answer the questions as follows.\n\n>**figures ... y-axis**\n\nWe mentioned that $\\pi_{\\theta}^\\top r$ is used as the vertical axis value in Line 148, and will add this to the figure.\n\n>**Line 52-53 ... approximation error ... Alfano et al. (2023)**\n\nThank you for pointing out the work on PG using overparameterized NNs. We will cite it and mention that zero function approximation error results are useful in this setting, as suggested.\n\n>**Line 361-362**\n\nThank you for the suggestions. We present our current understanding and evidences. Also, please check the common feedback for details.\n\n>**Clarification question ... open problem**\n\nThank you for checking Agarwal et al. (2021) very carefully. It is not explicitly mentioned in that paper **if Softmax PG achieves global convergence with zero approximation error** is an open problem. However, to the best of our knowledge and after extensive communication with the authors of Agarwal et al. (2021), the common understanding is that this problem has remained open in the sense that it has not been solved before. We will clarify in revised versions.\n\n>**optimal action is not unique** \n\nYes, $\\pi_{\\theta_t}^\\top r \\to r(a^*)$ will hold. Consider if there are two optimal actions $a_1^*$ and $a_2^*$ with $r(a_1^*) = r(a_2^*)$. If the plateaus for those two actions are separated on the landscape in Figure 1 (this is an intuitive statement), it will follow that either $\\pi_{\\theta_t}(a_1^*) \\to 1$ or $\\pi_{\\theta_t}(a_2^*) \\to 1$ depending on where $\\theta_1$ is initialized (the arguments are almost identical as the unique optimal action case). Otherwise,  if the plateaus for those two actions are connected on the landscape (neighborhoods of one another), then we will have $\\pi_{\\theta_t}(a_1^*) + \\pi_{\\theta_t}(a_2^*) \\to 1$, since the current analysis only asserts that $\\theta_t$ approaches the ``joint\'\' optimal plateau formed by $a_1^*$ and $a_2^*$.\n\n>**entropy regularized bandit case**\n\nThank you for asking this question. Our speculation is that the answer is yes. In particular, we believe that when the temperature is small enough (entropy does not have much weight comparing to reward), the landscape is modified so that the stationary point is ""moved"" from a one-hot policy to a finite stationary point, hence the nice ""ordered"" landscape is still preserved by adding entropy. Further study is required to rigorously show or disprove this speculation.\n\n>**NPG with non-adaptive geometrically increasing step size still hold**\n\nThank you for pointing this out. We have checked and do not see any difficulty that prevents this generalization.\n\n>**As for the general MDP ... advantage function / Q-function ... challenging obstacle**\n\nThank you for bringing up this idea, which seems to be very reasonable. As mentioned in the common feedback, considering the advantage function / Q-function is also the idea we were looking at. Difficulties are also explained in the common feedback.  We believe additional efforts are needed to make this idea work in MDPs.'}}, {'rebuttal': {'value': 'The review seems to focus on issues arising from misunderstanding or miscommunication. We hope the following can help clarify matters.\n\n>**global convergence is abused ...**\n\n**First**, global convergence simply means $\\pi_{\\theta_t}^\\top r \\to r(a^*)$, i.e., policy\'s reward approaching that of the optimal policy, as mentioned in Lines 230 and 316. It is hard to imagine a more straightforward definition. **Second**, alternative analyses do not change the meaning of global convergence. Sub-linear regret implies that the averaged performance approaches $r(a^*)$. Our global convergence results are for last-iterate, which implies sub-linear regret.\n\n>**... not clear how to interpret Approximation error ...** \n\nWe have explained this clearly in Section 3. **First**, Softmax PG and NPG can still achieve global convergence on Example 1 with non-zero approximation errors. This does not contradict ""zero approximation error leads to global convergence"". **Second**, Examples 1 and 2 have similar non-zero approximation errors but different algorithm behaviors, which makes it impossible to use non-zero approximation error to discriminate the two examples (global convergence or not). **Finally**, we agree that ""approximation error is still an important quantity"", but our observations also clearly show that non-zero approximation errors are not enough to characterize global convergence.\n\n>**... less clear how to check optimal action preservation condition**\n\nChecking the condition for NPG is no harder than checking the approximation error. To determine approximation error $\\\\| \\hat{r} - r \\\\|_2 =  \\min\\_{w \\in \\mathbb{R}^d} \\\\| X w - r \\\\|_2 $ one needs to calculate projection $\\hat{r} := X^\\top (X^\\top X)^{-1} X^\\top r$. Optimal action preservation $\\text{argmax}\\_{a \\in [K]}{\\hat{r}(a)} = \\text{argmax}\\_{a \\in [K]}{r(a)}$ can be immediately verified from the same calculation. Checking the condition for PG requires a linear feasibility check (i.e., a special case of an LP), as discussed in the response to Reviewer hbxK. Note that checking conditions both PG and NPG only requires the same problem information ($X$, r, and $\\hat{r}$) as checking approximation error.\n\n>**in line 96, (4) and (5) ...** \n\nIt is well known that general Softmax PG and NPG methods are foundations of the standard RL methods mentioned. Eqs. (4) and (5) are their updates applied to the one-state setting. \n\n>**in line 102, $1/\\sqrt{t}$ ...** \n\nSorry for the typo. [4, Table 1] contains the correct result of an $O(1/t)$ rate.\n\n>**line 121, insufficiency...**\n\nAs Section 3 shows, small approximation error is neither necessary nor sufficient for the global convergence of PG or NPG.\nZero approximation error (i.e., linear realizability) is not necessary in either case, although it is sufficient for NPG, and proved sufficient for softmax PG for the first time in this paper. We could consider replacing ""insufficiency of"" with ""limitations of"".\n\n>**line 152, check global convergence...**\n\nAs shown in Figure 3(c), we use sub-optimality gap $(\\pi^* - \\pi_{\\theta_t})^\\top r$ to ascertain global convergence.\n\n>**line 191, algorithm dependent ...**\n\nSection 3.3 already demonstrated that the condition must depend on the specific update considered (e.g., Softmax PG vs. NPG). Therefore, one has to study the conditions for Softmax PG and NPG **separately** (rather than one condition for both algorithms).\n\n>**... generalizes the analysis of references [18,12] ...**\n\nOur new results for function approximation are not covered by any of those papers. The gap we consider is for $\\hat{r}$, which is different than the reward gap of $r$ in those papers.\n\n>**The usefulness ... large, even infinite.**\n\n**First**, the common author response provides a detailed discussion of the MDP case, illustrating how the ideas provide useful initial insights for MDPs. **Second**, for large action spaces, checking new conditions are no harder than approximation error, as explained above. **Third**, for infinite action spaces, it is also infeasible to exactly determine the approximation error in general.\n\n>**... serious publication.**\n\nUnderstanding the one-state and deterministic settings are necessary first steps before understanding the more involved MDP and stochastic settings. The significance of our findings seem to be well recognized by the other reviewers.\n\n>**Why is it fair to compare function approximation error ...**\n\nTo our knowledge, approximation error (and its variants) has been the only quantity considered for characterizing function approximation quality in PG analysis. It is therefore necessary to discuss approximation error when studying the convergence of PGs with function approximation. \n\n>**approximation error ... does not depend on MDP ...**\n\nThe approximation error $\\min\\_{w \\in \\mathbb{R}^d}{ \\\\| X w - r \\\\|_2}$ clearly depends on the problem quantity $r$, as do the order-based conditions.\n\n>**... do not explain the basic case.**\n\nConsider $r = \\mathbf{1} \\in \\mathbb{R}^K$ as mentioned. Consider $w = \\mathbf{0} \\in \\mathbb{R}^d$, such that $r^\\prime = X w = \\mathbf{0}$. Note that $r^\\prime$ preserves the order of $r$ by definition (for all $i, j \\in [K]$, $r(i) > r(j)$ if and only if $r^\\prime(i) > r^\\prime(j)$ as in Line 229).\n\n>**... any rate improvement?**\n\nOur results address the function approximation case, which is well beyond tabular analyses [12,18]. Improving rates for the tabular setting is not a focus of this work. It is certainly possible to consider increasing stepsizes [23] for improvement, which is beyond the scope of this paper.\n\n>**... hard MDP instance?**\n\nIt is not possible to rule out hard MDP instances in general. The tabular case is recovered as a special case (Line 232). If hard MDP instances were avoided, they would be avoided in the tabular case, which would contradict [15]. \n\n>**... stochastic bandit problems?**\n\nThis is mentioned in the conclusion as future work, and we are working to obtain  results in this direction.\n'}}, {'rebuttal': {'value': 'We appreciate that the reviewer understands and recognizes the contributions of this work. We address the main concerns as follows.\n\n>**Is there a systematic way to check the existence of such a $w$ given $r$ and $X$:** \n\nYes, checking the existence of $w$ is known as **linear feasibility** in the literature (Grötschel et al., 2012), i.e., determining whether a set of inequalities has a non-empty intersection. In particular, suppose $X \\in \\mathbb{R}^{K \\times d}$ and $r \\in \\mathbb{R}^K$ are given and that $r$ is sorted, i.e., $r(1) \\ge r(2) \\ge \\cdots \\ge r(K)$. Denote $x_i \\in \\mathbb{R}^d$ as the $i$th row vector of $X$. The linear feasibility problem in this case is to check if there exists a $w \\in \\mathbb{R}^d$, such that, for all $i \\in [K-1]$,\n\\begin{align}\n    x_i^\\top w \\ge x_{i+1}^\\top w.\n\\end{align}\nLinear feasibility can be cast as linear programming using a dummy objective and keeping the constraints, hence any LP technique, such as the ellipsoid method, can be used to solve it (Grötschel et al., 2012).\n\n>**How large the subspace of $X$ that satisfies the order-preserving condition is? The question could also be asked for NPG.**\n\n That is an interesting question. **First**, this work shows that the space is strictly larger than the set of $X$s that satisfy linear realizability / zero approximation error (i.e., the set of $X$ such that there exists $w \\in \\mathbb{R}^d$ to satisfy $X w = r$). From Line 232 in the paper, we know that zero approximation error implies order preservation, but **not vice versa** (Examples 1 and 3). **However**, determining how much larger the space is would require choosing a metric, such that we can compare space sizes. This needs further investigation.\n\n[1] Martin Grötschel, László Lovász, and Alexander Schrijver. Geometric algorithms and combinatorial\noptimization, volume 2. Springer Science & Business Media, 2012.'}}, {'rebuttal': {'value': 'We thank the reviewers for their careful reading, valuable comments, and recognition of the contributions. This first, common feedback answers a question raised by multiple reviewers.\n\n>**Generalization to MDPs (Reviewers m2vF, P4aQ, BpdK)**\n\nExtending the results of this work to MDPs is an important and challenging next step as mentioned in the conclusion, and our work provides a new direction as the first step. Here we discuss some research plans, considering Softmax PG for illustration. The discussion provides some new ideas, but resolving this problem is highly non-trivial and requires further investigation.\n\nAccording to the policy gradient theorem [21, Theorem 1], we have, for all $\\theta_t \\in \\mathbb{R}^d$,\n\\begin{equation*}\n    \\theta_{t+1} = \\theta_t + \\eta \\cdot \\sum_{s \\in \\mathcal{S}} d^{\\pi_{\\theta_t}}(s) \\sum_{a \\in \\mathcal{A}} \\frac{\\partial \\pi_{\\theta_t}(s, a)}{\\partial \\theta_t} Q^{\\pi_{\\theta_t}}(s, a)\n\\end{equation*}\n\\begin{equation*}\n    = \\theta_t + \\eta \\cdot \\sum_{s \\in \\mathcal{S}} d^{\\pi_{\\theta_t}}(s) \\cdot X_s^\\top ( \\text{diag}{(\\pi_{\\theta_t}(\\cdot | s))} - \\pi_{\\theta_t}(\\cdot | s)\\pi_{\\theta_t}(\\cdot | s)^\\top ) \\ Q^{\\pi_{\\theta_t}}(s, \\cdot),\n\\end{equation*}\nwhere $X_s \\in \\mathbb{R}^{|\\mathcal{A}| \\times d}$ is the feature matrix under state $s \\in \\mathcal{S}$ and can be shared across multiple states. Comparing with Eq. (4), for all $s \\in \\mathcal{S}$, the reward vector $r \\in \\mathbb{R}^K$ is replaced by $Q^{\\pi_{\\theta_t}}(s, \\cdot) \\in \\mathbb{R}^{|\\mathcal{A}|}$, as mentioned also by Reviewer P4aQ. This fact provides some new ideas as well as difficulties. \n\n**First**, if for all state $s \\in \\mathcal{S}$, the feature matrix can preserve the order of $Q^{\\pi_{\\theta_t}}(s, \\cdot)$ for **all policies**, i.e., for all $t \\ge 1$, there exists $w_t \\in \\mathbb{R}^d$, such that for all $s \\in \\mathcal{S}$, $X_s w_t \\in \\mathbb{R}^{|\\mathcal{A}|}$ preserves the order of $Q^{\\pi_{\\theta_t}}(s, \\cdot)$, then we have,\n\\begin{equation*}\n    \\theta_{t+1}^\\top w_t = \\theta_t^\\top w_t + \\eta \\cdot \\sum_{s \\in \\mathcal{S}} d^{\\pi_{\\theta_t}}(s) \\cdot w_t^\\top X_s^\\top ( \\text{diag}{(\\pi_{\\theta_t}(\\cdot | s))} - \\pi_{\\theta_t}(\\cdot | s)\\pi_{\\theta_t}(\\cdot | s)^\\top ) \\ Q^{\\pi_{\\theta_t}}(s, \\cdot)\n\\end{equation*}\n\\begin{equation*}\n    \\ge \\theta_t^\\top w_t,\n\\end{equation*}\ngeneralizing Eq. (12), a key argument in the one-state setting. However, $w_t$ is  changing over time, since in the update $r \\in \\mathbb{R}^K$ is replaced by $Q^{\\pi_{\\theta_t}}(s, \\cdot)$, which is changing over $\\theta_t$. Comparing with fixed $r$ and $w$ in Eq. (12), using the above inequality with $\\theta_t$ and $w_t$ both changing over time is more challenging and manifests the major technical difficulty.\n\n**Second**, another speculation is that preserving the order of $Q^*(s, \\cdot)$ (value of the optimal policy $\\pi^*$) might be enough to achieve global convergence (if true, there would be no need to preserve the values of all policies). Here we show a local convergence when $\\text{softmax}(X_s \\theta_t)$ is close enough to $\\pi^*( \\cdot | s)$. Suppose that there exists $w^* \\in \\mathbb{R}^d$, such that for all $s \\in \\mathcal{S}$, $X_s w^* \\in \\mathbb{R}^{|\\mathcal{A}|}$ preserves the order of $Q^*(s, \\cdot)$. Then for any $\\theta_t$ such that $Q^{\\pi_{\\theta_t}}(s, \\cdot)$ preserves the order of $Q^*(s, \\cdot)$, we have,\n\\begin{equation*}\n    \\theta_{t+1}^\\top w^* = \\theta_t^\\top w^* + \\eta \\cdot \\sum_{s \\in \\mathcal{S}} d^{\\pi_{\\theta_t}}(s) \\cdot {w^*}^\\top X_s^\\top ( \\text{diag}{(\\pi_{\\theta_t}(\\cdot | s))} - \\pi_{\\theta_t}(\\cdot | s)\\pi_{\\theta_t}(\\cdot | s)^\\top ) \\ Q^{\\pi_{\\theta_t}}(s, \\cdot)\n\\end{equation*}\n\\begin{equation*}\n    \\ge \\theta_t^\\top w^*,\n\\end{equation*}\nbased on which we can show that $\\theta_t$ eventually approaches the direction of $w^*$, implying that $\\pi_{\\theta_t}(a^* | s) = \\text{softmax}(X_s \\theta_t)(a^*) \\to \\pi^*(a^* | s) = 1$ (in combination with Lemma 1). This means that preserving the order of $Q^*(s, \\cdot)$ is enough for $\\pi^*$ to be a local attractor of gradient updates within its neighbourhood. One challenge here is to generalize the arguments for arbitrary initialization $\\theta_1 \\in \\mathbb{R}^d$ rather than $\\theta_t$ close enough to optimal solution, and the difficulty is that $Q^{\\pi_{\\theta_t}}(s, \\cdot)$ does not necessarily preserve the order of $Q^*(s, \\cdot)$, and the last inequality above does not necessarily hold.\n\n**In summary**, this discussion illustrates how the paper provides some new and useful insights for understanding more complex settings, but it requires further investigation to resolve this highly non-trivial problem for general MDPs. We will use an additional page in subsequent versions to present this discussion, as Reviewer P4aQ suggested.'}}, {'summary': {'value': 'This paper considered the problem of global convergence condition of policy gradient (PG) methods with linear function approximation motivated by three observations: i) global convergence under linear function approximation can be achieved without policy or reward realizability; 2) approximation error is not a critical factor for global convergence; and 3) conditions for characterizing global conference should be algorithm-dependent. Based on these observations, the authors developed new ordering-based conditions for global convergence of PG methods: i) For Softmax PG, a sufficient condition for global convergence to occur is that the representation preserves the ranking of the rewards; and ii) For natural PG (NPG), the necessary and sufficient condition of global convergence is that the projection of the reward onto the representation space preserves the optimal action’s rank.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. This paper develops a new set of global convergence conditions for PG methods with linear function approximation, which advances the state of the art of understanding PG methods (Softmax PG in particular).\n\n2. The proof strategies and algorithm analysis techniques are novel.\n\n3. Motivating examples in this paper are insightful.\n'}, 'weaknesses': {'value': '1. The paper could benefit from constructing a bit more larger-scale experiments.\n\n2. This paper could have some further discussions on the implications of the ordering-based conditions.'}, 'questions': {'value': 'I appreciate the new findings and fresh insights of the ordering-based global convergence conditions for PG methods with linear function approximation. One immediate question that comes to my mind after reading this paper is how restrictive (or non-restrictive) these ordering-based conditions are. For example, for the Softmax PG method, it appears to me that given $r$ and $X$, checking the existence of a $w$ that preserves the reward ranking may not be a simple task. Is there a systematic way to check the existence of such a $w$? Is there any other condition equivalent to order-preserving but easier to identify and check? Could the authors discuss how large the subspace of $X$ in $\\mathbb{R}^{d}$ that satisfies the order-preserving condition is? The same questions can also be asked for NPG.'}, 'limitations': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper studies softmax policy gradient and natural policy gradient methods for multi-arm bandits problems using linear function approximation. The authors provide examples to illustrate the global convergence of these methods when the standard function approximation error is not zero. To better characterize the global convergence, the authors provide the ordering-based conditions on rewards. Some numerical examples are provided to verify the proposed conditions. '}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""**orginality**\n\n- The studied deterministic policy gradient methods are well-known in the literature. The authors re-revisit the convergence of these methods for multi-arm bandits with linear function approximation. Such convergence hasn't been studied directly. \n\n- The authors show necessary (and sufficient) conditions for two policy gradient methods to converge in the linear function approximation setting. The analysis generalizes some similar analysis, e.g., reference [18] to linear function approximation. Technical comparisons with the existing analysis are not very clear. \n\n**quality**\n\n- It seems that the global convergence is abused in some way, since the existing convergence studies in the linear function approximation investigate different sub-optimality gaps, e.g., [4] is based on the regret analysis while [24] utilizes the mirror descent analysis. \n\n- It is not clear how to interpret 'Approximation error is not a key quantity for characterizing global convergence in either algorithm'. The reference [24] shows that zero approximation error leads to global convergence. Although this result does not show necessity, approximation error is still an important quantity we use in practice.\n\n-  Compared with approximation error, it is less clear how to check optimal action perseveration condition, especially when the action space is large. So, weaknesses haven't been clearly stated. \n\n**clarity**\n\n- The paper is structured well, but it lacks of technical comparisons with existing results. \n\n- The visualization is not clearly stated, e.g., axes, error bars, speed. \n\n**significance**\n\n- Since the function approximation is widely used in reinforcement learning, this work is important. It provides new understandings of policy gradient methods in bandit cases. ""}, 'weaknesses': {'value': ""- Technical comparisons with existing results are not detailed, sometimes vague. For instance, in line 96 why (4) and (5) for bandits can be used as RL methods; in line 102 which work provides $1/\\sqrt{t}$ rate; line 121, why 'insufficiency'; line 152, how to check global convergence; line 191, what of algorithms the quantity must depend on? Please state claims with concrete justifications. \n\n- Optimal action perseveration generalizes the analysis in reference [18]. It is similar to the gap of optimal action and second optimal action used in literature, e.g., reference [12] and the paper: Regret Analysis of a Markov Policy Gradient Algorithm for Multiarm Bandits. These quantities seem to be known important for global convergence and the authors generalize them to linear function approximation. Therefore, it is important to clarify the connections and position the work in the literature properly. \n\n- The usefulness of proposed ordering-based conditions is still questionable. First, the generalization to MDPs is not provided. Second, it is not clear how to check such conditions when state/action spaces are large, even infinite. \n\n- The paper focuses on multi-arm bandits and deterministic policy gradient methods, which have a large gap with reinforcement learning. This work seems to be still in progress and significant effort is needed to generalize this work for serious publication. ""}, 'questions': {'value': 'Please see questions in Strengths and Weaknesses. \n\nHere are some other questions.\n\n- Why is it fair to compare function approximation error with ordering-based conditions or optimal action gap conditions? The function approximation error is a general quantity that does not depend on MDP structures, while ordering-based conditions depend on the MDPs. In a basic tabular case, ordering-based conditions do not necessarily hold, e.g., equal rewards at any action, but the softmax function approximation error is zero. Hence, such conditions do not explain the basic case.\n\n- The convergence rate seems to be vague in the main paper, which has a dependence on the gap between optimal action and second optimal action, which is known in the tabular case [12, 18]. How much does your rate analysis go beyond the existing analysis? any rate improvement? \n\n- For softmax PG, reference [15] shows that it can take exponential time to converge in a hard MDP instance. How does ordering-based condition rule out the hard MDP instance? \n\n- The setup is limited to deterministic algorithms with exact gradients, which is an ideal setting. Can the authors apply them to practical stochastic bandit problems? '}, 'limitations': {'value': 'Yes. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper challenges (arguably) the current best known policy gradient (PG) convergence analysis, which is the conventional approximation error based analysis originally proposed by the seminal work of Agarwal et al. (2021). To this end, the authors consider the finite-arm bandits with log-linear policy and study the conditions of the global convergence of PG and natural policy gradient (NPG). \n\n**First**, by carefully designing numerical simulations, the authors show that global convergence can be achieved even if the parameterized policy space can not cover the full policy space, or the approximation error is not zero. Consequently, the approximation error is not a key quantity for characterizing global convergence in either algorithm under linear function approximation.\n\n**Second**, the authors establish new conditions of the global convergence of PG and NPG for the same setting, separately. For NPG, the necessary and sufficient condition of the global convergence is whether the projection of the reward vector onto the feature map strictly preserves the top ranking of the optimal action. For PG, the sufficient but not necessary condition of the global convergence is whether there exists a point in the image of the feature map such that it preserves the entire ranking of the reward vector. These conditions are again well supported by numerical simulations.\n\n\n\nAgarwal, Alekh, Sham M. Kakade, Jason D. Lee, and Gaurav Mahajan (2021). On the Theory of Policy Gradient Methods: Optimality, Approximation, and Distribution Shift. Journal of Machine Learning Research 22.98, pp. 1–76.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The paper is revolutionary and the results are surprising. This paper may have the same impact on the theoretical RL community as that of Agarwal et al. (2021). The strengths of the paper can be summarized as follows.\n\n- First, the research question itself on the approximation error assumption is important and revolutionary. Challenging the previous pioneering work is always not easy.\n- However, the argumentation of the paper is impeccable. Readers will probably be surprised at first, but will quickly be convinced by several simple but sophisticated numerical simulations.\n- Not only the authors are able to find negative answers to questions about the role of approximation error for the global convergence of PG methods, they also establish new results characterizing the conditions for the global convergence of PG methods and draw the connection between the new conditions and the approximation error assumption. The novelty of the paper is significant.\n- In addition, the paper is very well written. The research question is well formulated. The new conditions are well presented. And the reasoning is detailed with intuitive explanations, figures, many examples and the proof sketch.\n\nI agree with the authors that this work will open many new directions for understanding PG-based methods in the function approximation regime, especially considering the general Markov decision processes (MDPs).'}, 'weaknesses': {'value': 'Although the paper is well written, I still find some minor points for improvement.\n\n- In the figures, the authors can specify that y-axis is the reward / value function.\n- Line 52-53: ""... approximation error ..., diverting attention from feature designs that achieve useful properties beyond small approximation error."" Although one goal of the paper is to claim that approximation error is not necessary, I find this sentence to be a little too dismissive of approximation error. It may leave the reader with the impression that approximation error is rarely useful outside of the tabular case where the approximation error is zero. It is true that, zero approximation error does not fit well with linear function approximation in general, which is the original motivation for the paper. However, when the approximation error is zero, the conventional approximation error based analysis becomes useful. For instance, another interesting case of zero approximation error is the use of neural networks, recently studied by Alfano et al. (2023) in Section 4.2. That is, a sufficiently wide and shallow ReLU network can infinitely approximate the Q-function such that the approximation error is zero. Consequently, their approximation error based analysis leads to a new SOTA sample complexity of PG method under neural network parameterization.\n- Line 361-362: ""Extending the results and techniques to general Markov decision processes (MDPs) is another important and challenging next step."" The authors can use an extra page in the revised version to discuss the intuition of possible obstacles to such an extension. See also my question below.\n\nAlfano, Carlo, Rui Yuan, and Patrick Rebeschini (2023). A Novel Framework for Policy Mirror Descent with General Parametrization and Linear Convergence.'}, 'questions': {'value': ""First, I have a clarification question. The authors claim that they solve an open problem left by Agarwal et al. (2021). If I understand correctly, the authors refer to this one: _if zero approximation error holds, does softmax PG achieve global convergence ?_ However, I couldn't find this claim in Agarwal et al. (2021). Instead, I found two open problems left by Agarwal et al. (2021). \n\n- __(1)__ In their Remark 11 (journal version) / Remark 5.1 (arxiv version), the first open problem is that, whether or not softmax PG will converge globally if the initial state distribution is not state-wise strictly positive. Since this paper only considers bandit problems with one single state, the initial state distribution is constant 1 with that state. The paper does not resolve this open problem. \n- __(2)__ In their Remark 14 (journal version / Remark 5.2 (arxiv version), the second open problem is whether a polynomial global convergence rate is achievable for softmax PG with the entropy regularizer. This problem envolves entropy regularization, which is outside the scope of the paper. Thus, the paper dose not resolve this problem neither.\n\nCan the authors point me specifically to where Agarwal et al. (2021) claim  the open problem mentioned right after Corollary 1 in this paper ?\n\nNext, I have some more open questions that the authors can decide to include them in the paper or not.\n\n- Do the results of softmax PG and NPG in this paper still hold if the optimal action is not unique ?\n- Same question for entropy regularized bandit case ?\n- Do the results for NPG with non-adaptive geometrically increasing step size still hold ? Note that NPG and variants with non-adaptive geometrically increasing step size have been studied extensively recently (Lan, 2022; Xiao, 2022; Li et al., 2022; Yuan et al., 2023; Alfano et al., 2023). Can we obtain superlinear convergence as discussed in Xiao (Section 4.3, 2022) and Li et al. (2022) ?\n- As for the general MDP, one can think about the compatible function approximation framework of Agarwal et al. (2021). By similarity, the ranking condition of the reward vector for the softmax PG becomes the ranking condition of the advantage function / Q-function. And the projection of the reward vector onto the image of the feature map for NPG becomes the projection of the advantage function / Q-function onto the image of the matrix $[\\nabla_\\theta \\log \\pi_{\\theta}(a \\mid s)]_{s, a}$. What do you think about this idea ? Can this idea and the techniques used in this paper be enough to be extended to general MDP ? If not, what is the missing factor here and what is the challenging obstacle ? For simplicity, one can consider the exact NPG instead of stochastic NPG.\n\nXiao, Lin (2022). On the Convergence Rates of Policy Gradient Methods. Journal of Machine Learning Research 23.282, pp. 1–36.\n\nLi, Yan, Tuo Zhao, and Guanghui Lan (2022). Homotopic Policy Mirror Descent: Policy Convergence, Implicit Regularization, and Improved Sample Complexity.\n\nLan, Guanghui (Apr. 2022). Policy mirror descent for reinforcement learning: linear convergence, new sampling complexity, and generalized problem classes. Mathematical Programming.\n\nYuan, Rui, Simon Shaolei Du, Robert M. Gower, Alessandro Lazaric, and Lin Xiao (2023). Linear Convergence of Natural Policy Gradient Methods with Log-Linear Policies. In International Conference on Learning Representations.\n\nAlfano, Carlo, Rui Yuan, and Patrick Rebeschini (2023). A Novel Framework for Policy Mirror Descent with General Parametrization and Linear Convergence.""}, 'limitations': {'value': 'The authors have adequately addressed the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work studies the global convergence of standard softmax policy gradient and natural policy gradient for finite-arm bandits with linear function approximation (i.e., considering a log-linear policy). It is shown that the approximation error is not crucial for characterizing global convergence since the latter can be achieved even with non-zero approximation error. Ordering-based conditions are provided instead to guarantee the global convergence of softmax PG and natural PG while the approximation error is non-zero. More precisely, this paper establishes that both NPG and softmax PG converge globally when (a)  for NPG, the optimal action’s rank is preserved by the projection of the true reward onto the space of representable rewards and (b) for softmax PG, there exists a linear function preserving the ranking of actions provided by the true reward function. The case of a linearly realizable reward function is a particular case of the aforementioned reward rank preservation condition. Numerical examples illustrate all these results throughout the paper.  \n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '\nThe main results of this paper provide very interesting insights on the global convergence of some PG methods under the function approximation setting for finite-arm bandits. The paper provides strong and solid contributions.\n\n**(a) Originality**: the paper challenges common existing analysis featuring the approximation error as a natural limit when considering function approximation. Results are new to the best of my knowledge.\n\n**(b) Significance**: as also highlighted by the paper in the conclusion, the results are likely to inspire further important developments for function approximation in the more general setting of MDPs, nonlinear approximation and representation learning. \n\n**(c) Correctness**: To the best of my knowledge, except for the proof of Theorem 1 which is more involved and may deserve some clarifications in my opinion (see my comments below), the proofs in the appendix are correct, complete and relatively easy to follow. I checked the appendix in details. \n\n**(d) Clarity and writing**: This paper is very well-written, the structure is clear, the exposition is progressive, the story line is very nice and the illustrations are insightful. This is a solid body of work. \n'}, 'weaknesses': {'value': ""- While the proof of Theorem 2 is very clear to me, some parts of the proof of Theorem 1 (and its sketch l. 266 to 293) deserve some clarifications in my opinion. Please see my comments in the questions section. \n\n- Comment: The proof of Theorem 2 seems to follow similar lines to the proofs in Khodadadian et al. 2022 even if the latter work does not consider linear function approximation nor does it propose ordering-based conditions (while it applies however to MDPs).  The main difference seems in replacing the  true gap $\\Delta$ by the gap induced by the linear approximation $\\hat{\\Delta}$. For similarities, see for e.g., Appendix C in Khodadadian et al. 2022 for the bandits case or the main part of the paper (Theorem 1, Lemma 1, Proposition 1 p. 3-4 and their proofs). \n\nKhodadadian, S., Jhunjhunwala, P. R., Varma, S. M., & Maguluri, S. T. (2022). On linear and super-linear convergence of Natural Policy Gradient algorithm. Systems & Control Letters, 164, 105214.\n\n**Minor:**\n\n-  It is not very clear what is $v_2$ in l. 278-279 (especially that there is also $v$ in l. 278) and what is $v_1$ in l. 283 and how do they relate to $v$ in l. 268, I find the notations and the formulation a bit confusing in l. 266-293. \n\n- Please give the precise reference to Theorem 1 when you reference [8] in lines 116 and 123. \n\n- $r(a^*)$ introduced in l. 110 does not seem to be defined before (definition of $a^*$ comes later in l. 140).  \n\n- Numerical legends in all the figures are almost invisible in a printed format (although visible when zooming on a computer), it would be nice to increase the size of the numerical characters (and save the figure in pdf format if not already done) to ease the reading. \n\n- Eq. (27): Why is the inequality strict? This (strict) positivity does not seem to be used anyway. \n\n- Suggestion: Eq. (102) maybe add $>0$ for clarification. \n\n- Suggestion: Eq. (149) to Eq. (150) maybe add the splitting sum steps with the order summing exchange to detail a bit more for the convenience of the reader. \n\n**Typos:** \n- l. 446: $\\theta’ \\in \\mathbb{R}^d$ instead of $\\mathbb{R}^K$?\n\n- l. 474: $a \\in [K]$ instead of $i \\in [a]$. \n\n- l. 481: Eq. (58) instead of (54).  \n\n- l. 493: Eq. (68) instead of (65). \n\n- Eq. (97): Eq. (94) instead of (91). \n\n- Eq. (101): Eq. (97) instead of (95). \n\n- Eqs. (138) and (139): $\\max_a$ instead of $\\max_i$. \n\n- l. 539, Eq. (144): say there exists $\\theta_{\\zeta} \\in [\\theta, \\theta']$ such that ...\n\n\n""}, 'questions': {'value': ""About the proof of Theorem 1, I have the following technical questions (1. (a)-(b)) which constitute my main concerns and that I would like to be addressed for clarification before updating my evaluation: \u2028\n\n**1. (a)** Second part/Lemma 1 (l. 455): Why does the fact $\\|\\| \\frac{d \\pi_{\\theta_t}^T r}{d \\theta_t}\\| \\|_2 \\to 0$ imply that $\\|\\|\\theta_t\\|\\| \\to \\infty$? I understand that there is no stationary point for any $\\theta \\in \\mathbb{R}^d$ following the proof but how do you conclude properly that then $\\|\\|\\theta_t\\|\\| \\to \\infty$? In particular in the proof, l. 446: what does the assumption \nsuppose there exists $\\theta' \\in \\mathbb{R}^K$ with $\\|\\|\\theta’\\|\\|_2 < \\infty$ mean? \n\nIt is proven (by contradiction) that for every $\\theta’ \\in \\mathbb{R}^d$, we have $\\frac{d \\pi_{\\theta’}^T r}{d \\theta’} \\neq 0$. \nTo conclude that $\\|\\|\\theta_t\\|\\| \\to \\infty$, I would expect that the proof assumes that the sequence $(\\theta_t)$ is bounded and then finds a contradiction. Could you please clarify the reasoning here? \n\n**1. (b)** Third part: the general reasoning and the conclusion l. 498 to 501 are not very clear to me.\n\n \u2028\u2028(i) It is proven by contradiction that every suboptimal action $i$ s.t. (47) is satisfied, $\\pi_{\\theta_t}(i)$ does not converge to 1. How does this help concluding that for the optimal action $a$ (or any optimal action if non unique) we have $\\pi_{\\theta_t}(a)$ converges to 1? Could you clarify the reasoning and the guiding intuition? \n\n\u2028(ii) Could you also elaborate more on how (60), (69), (71) and (72) are used to conclude? \n\n(iii) Is the third case $j \\in \\mathcal{A}(i)$ (i.e., $i,j$ are mapped to the same reward value) handled in the proof? If trivial, maybe a word about it can be added. \n\n\u2028(iv) Minor: what do you mean by $X$ and $u$ are bounded in l. 492? $X$ is the feature matrix and $u$ is a fixed vector in $\\mathbb{R}^d$. \n\n**2.** Could you clarify why the possibility of having exponentially many suboptimal local maxima renders global convergence (to the optimal reward) impossible without further structure on function approximation as stated in l. 123-124? Is it because there is more chance to be stuck at a local suboptimal local maxima? How does the ordering-based condition preclude such a case in Theorem 1? \n\n**3.** Do the examples of section 3 allude to the fact that the ordering of the features matters since the examples only differ between them by column permutations? \n\n**4.** In proposition 1 (and more generally in the paper), do you assume that there exists a unique optimal action? If there are many, I guess any optimal action would work. You may want to add a comment regarding this.  \n""}, 'limitations': {'value': 'Limitations and opportunities for future work are briefly discussed in the conclusion. \n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper theoretically proves that, for finite-arm bandits with linear function approximation, the global convergence of policy gradient (PG) methods is not dependent on approximation error, but rather, on the ordering properties of the reward representation. The global convergence is achievable for both standard Softmax PG and natural policy gradient (NPG) under linear function approximation. This result is also verified using simple examples and empirical experiments.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'This paper provides a completely new understanding on the convergence of policy gradient method, that is, the global convergence only depends on the specific ordering-based condtions instead of some classical approximation requirements. To my own knowledge, I have not seen such result before. \n\nThis novel insight is also significant. There are many situations where the approximation error could never be sufficiently small. This work provides a key to understand the covnergence of PG-based algorithms. And as the author claims, I agree with that this paper will open a new directions for PG-based methods under function approximation. \n\nThis work is well-written. I can clearly understand which problem this paper is solving; especially, examples given in Section 3 are very helpful to understand the motivation of proposing the ordering-based conditions. This paper also has rigorously defined two new preservation condtions on the ordering, and proved the necessarity or sufficiency for those proposed conditions. '}, 'weaknesses': {'value': 'The studied case only contains one state, so it is a simple bandit optimization problem. Though the main result of this paper is inspiring and interesting, this paper lacks of (1) persuading evidence showing that these understandings will also be valid for more general cases, and (2) sufficient discussions on how to generalize this result in a more general Markov decision process. \n'}, 'questions': {'value': 'The single-state MDP is a very special MDP; the proposed idea may or may not work for a more general senario. How this work will be generalized to a multi-state MDP? Is there any simulation results on that? '}, 'limitations': {'value': 'This is a theoretical work so there is no negative societal impact.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Ordering-based Conditions for Global Convergence of Policy Gradient Methods'}, 'authors': {'value': ['Jincheng Mei', 'Bo Dai', 'Alekh Agarwal', 'Mohammad Ghavamzadeh', 'Csaba Szepesvari', 'Dale Schuurmans']}, 'authorids': {'value': ['~Jincheng_Mei1', '~Bo_Dai1', '~Alekh_Agarwal2', '~Mohammad_Ghavamzadeh2', '~Csaba_Szepesvari1', '~Dale_Schuurmans1']}, 'keywords': {'value': ['reinforcement learning', 'policy gradient', 'policy optimization', 'function approximation', 'global convergence']}, 'abstract': {'value': ""We prove that, for finite-arm bandits with linear function approximation, the global convergence of policy gradient (PG) methods depends on inter-related properties between the policy update and the representation. textcolor{blue}{First}, we establish a few key observations that frame the study: \\textbf{(i)} Global convergence can be achieved under linear function approximation without policy or reward realizability, both for the standard Softmax PG and natural policy gradient (NPG). \\textbf{(ii)} Approximation error is not a key quantity for characterizing global convergence in either algorithm. \\textbf{(iii)} The conditions on the representation that imply global convergence are different between these two algorithms. Overall, these observations call into question approximation error as an appropriate quantity for characterizing the global convergence of PG methods under linear function approximation. \\textcolor{blue}{Second}, motivated by these observations, we establish new general results: \\textbf{(i)} NPG with linear function approximation achieves global convergence \\emph{if and only if} the projection of the reward  onto the representable space preserves the optimal action's rank, a quantity that is not strongly related to approximation error. \\textbf{(ii)} The global convergence of Softmax PG occurs if the representation satisfies a non-domination condition and can preserve the ranking of rewards, which goes well beyond policy or reward realizability. We provide experimental results to support these theoretical findings.""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'PG method converges whenever there exists an adequate linear function that ranks actions in the same order as the ground-truth reward function.'}, 'pdf': {'value': '/pdf/4e7ad02450eb8c50a7cd991f28cf2844de6500ab.pdf'}, 'supplementary_material': {'value': '/attachment/29990e1600b0b1cd014d6efc42617301e1ffb7d4.pdf'}, '_bibtex': {'value': '@inproceedings{\nmei2023orderingbased,\ntitle={Ordering-based Conditions for Global Convergence of Policy Gradient Methods},\nauthor={Jincheng Mei and Bo Dai and Alekh Agarwal and Mohammad Ghavamzadeh and Csaba Szepesvari and Dale Schuurmans},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=sW8yGZ4uVJ}\n}'}, 'paperhash': {'value': 'mei|orderingbased_conditions_for_global_convergence_of_policy_gradient_methods'}}]"
"['Kaiyue Wen', 'Zhiyuan Li', 'Tengyu Ma']",NeurIPS,Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization,https://neurips.cc/virtual/2023/oral/73867,2023," Despite extensive studies, the underlying reason as to why overparameterizedneural networks can generalize remains elusive. Existing theory shows that common stochastic optimizers prefer flatter minimizers of the training loss, and thusa natural potential explanation is that flatness implies generalization. This workcritically examines this explanation. Through theoretical and empirical investigation, we identify the following three scenarios for two-layer ReLU networks: (1)flatness provably implies generalization; (2) there exist non-generalizing flattestmodels and sharpness minimization algorithms fail to generalize poorly, and (3)perhaps most strikingly, there exist non-generalizing flattest models, but sharpnessminimization algorithms still generalize. Our results suggest that the relationshipbetween sharpness and generalization subtly depends on the data distributionsand the model architectures and sharpness minimization algorithms do not onlyminimize sharpness to achieve better generalization. This calls for the search forother explanations for the generalization of over-parameterized neural networks",Oral 1D DL Theory,https://openreview.net/pdf?id=Dkmpa6wCIx,https://openreview.net/forum?id=Dkmpa6wCIx,Dkmpa6wCIx,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper provides a rigorous study of the relationship between flat minima, generalization, and the sharpness-aware optimizers such as SAM and presents intriguing and thought-provoking analyses/experiments/observations on the interaction of these three notions. Specifically, the authors show that whether flat minima are optimal or not (in terms of achieving the best generalization performance) depends on the choice of architecture and data distribution. In particular, they prove that for certain configuration of the above, the flattest minima provably correspond to the minima that generalize [and sharpness-aware optimizers can indeed find the flattest minima]. Perhaps more interestingly, the authors show that even when the flattest minima do not generalize well, SAM can still improve generalization. The latter observation is interpreted as there might be other regularization effects in SAM at work that are important for generalization and yet need to be understood.\n\nAll reviewers find the findings of this submission intriguing. and rate for accept. In concordance with them, I believe this paper is a timely research study into one of the biggest recent mysteries of generalization of deep neural networks, and hence recommend accept.'}}, {'comment': {'value': 'Thank you for your clarifications.\n\n- **The setup:** I still think the model setup is simple, but I also understand a proper analysis of noisy settings can be hard in general.\n\n- **Visualization:** Maybe https://arxiv.org/abs/1712.09913 can be helpful?\n\n- **Experiments:** I find the explanation provided satisfactory. Thank you!\n\n- **Comparison with [1]:** Thank you for your complete comparison. \n\nAt the end, I think the work has some fairly important limitations in terms of model setup, but I acknowledge a general analysis can be hard. I will increase my score to 5.\n'}}, {'title': {'value': 'Thank you!'}, 'comment': {'value': 'Thank you for your response, I have raised the score because I think that examples of simple models are important, however I still believe that the presentation of the results and the paper requires improvement.'}}, {'title': {'value': 'Thanks for the response!'}, 'comment': {'value': 'Thanks for the clear answers! I have raised my score and updated my review.'}}, {'rebuttal': {'value': ""We appreciate the detailed review and comment! We would like to answer the reviewers’ questions here.\n\n1. **Q1a.** Our bound is independent of the width of the model. Under the setting of Thm 3.1 and Lemma 3.1, we show our result by using sharpness as an upper bound for the parameter norm square using a uniform bound approach (see Lemmas A.5, A.6, and A.10).\n2. **Q1b.** When the bias is introduced, both Lemma A.5 and A.6 will break. In this case, the sharpness can no longer be used as a valid upper bound for the weight norm and hence the flattest model will no longer fall into the function class defined in Lemma 3.1 with high probability.\n3. **Questions 1.**  You are correct that ‘input data’ should be replaced by ‘training data’. We don’t need the activations on testing data to be all zero because our definition of memorizing solution only involves training data and does not necessarily imply bad generalization (c.f. Proposition 4.1, it takes some extra effort to show there exists a memorizing solution with bad generalization). Also, we would like to note that the construction of memorizing solution doesn’t need orthogonality within the input data. See Figure 3 as an example. We will try to clarify the statement in future versions. Thank you!\n3. **Questions 2.** Here equation 4 characterizes the following correspondence: for each train data, among the activated neurons, the weights of the second layer are proportional to the activations (up to a factor of train data norm). The intuition behind this condition is that the 2-homogeneity of the network cause the gradient of the first and second layer weight ($W_1’$ and $W_2$) must have a constant product in the norm given an input and output pair. Equation 4 is then derived by balancing these two gradients. This proof technique could be useful for future theoretical analysis of homogeneous models.\n\\\nFigure 3 and the memorizing solution we constructed is a special case where both sizes of equation 4 are vectors with only 1 nonzero coordinate. This can be done by choosing the first layer in a similar fashion as in Figure 3 which ensures all the input training data will activate exactly 1 neuron. Other than showing the activation is one-hot for each sample, figure 3 doesn't directly correspond to this additional structure, and shows no information about the second layer because the activated region of each hidden neuron is solely decided by its incoming weight, which belongs to the first layer. \n\n4. **Questions 3.** Yes, the converged model in Figure 4b reaches almost minimal sharpness and we observe strong alignment in $\\mathrm{relu}(W_1x_1 + b_1)$ and $W_2 \\odot 1(W_1x_1 + b_1 > 0)$. The average cosine similarity between the two vectors is above 0.99.\n\n5. **Questions 4.** We agree. We sidestep the infinity issue by using the soft label in the logistic loss. We will make clear the discussion here in future versions. Thank you!\n\nWe would like to thank the reviewer again for the advice on writing and clarifying. We will adopt these suggestions in future versions.\n""}}, {'rebuttal': {'value': ""We appreciate the review and comment! Regarding the reviewer’s concern, there seem to be some misunderstandings that we wish to clarify.\n1. **W1: The generality of the results** \n\nWhile our positive result theorem 3.1 only holds for a 2-layer ReLU network without bias, our main results, which are negative for generalization for flattest models, hold for more general settings (see Theorem 4.1) including the noisy labels setting and multi-layer networks. \n\n2. **W1: Relationship between sharpness and weight norm**\n\nWe would also like to clarify that in all the setups excluding the 2-layer network without bias, sharpness is not necessarily related to weight norm. Lemma 4.1 only holds for data distribution with zero mean and a two-layer network without bias. For a two-layer network with bias, on the synthetic setup we consider, constraining the norm of the weight can actually induce generalization. Proposition 4.1 shows that constraining the sharpness can’t induce generalization, which shows that in this setup, sharpness is actually very different from the weight norm. \n\n3. **W1: Noisy setups and additional related works**\n\nExperimentally SAM does have a generalization benefit over SGD when labels are noisy. But analyzing the generalization benefit of SAM for noisy labels is more complicated because the best performance is usually achieved by early-stopped SAM and interpolating the noise in the labels usually degrades the generalization. We leave understanding the generalization benefit of SAM with noisy labels as future work. \n\nThe authors would like to thank the reviewer for pointing out the missing citation [1] and will add it in the following version. Compared with [1], our works are different in three ways:\n\n(a). [1] considers a two-layer relu net which is essentially linear in its trainable parameters, because the second layer is fixed to be all 1's, and the authors of [1] assume the activations of the first layer don't change throughout the training, while we consider a general two-layer relu net; \n\n(b). Because the model is linear as mentioned in (a) and the loss is l2 loss, all the solutions have the same sharpness (or more explicitly the same hessian) in [1], regardless of whether having noise. In contrast, in our setup, models can have different sharpness; \n\n(c). In the setting of [1], SAM and GD converge to the same solution and there is no generalization bound provided, regardless of having noise or not, while we show the flattest model in certain settings can always have good generalization (thm 3.1).\n\n4. **Experiments.**\n\na. **Weight decay.** We would like to stress that weight decay is not used for SAM because it is already proved that constraining the norm can lead to generalization in many setups (see Figure 4a for example) and our goal is to investigate the relationship between sharpness and generalization so adding weight decay may confound the relationship.\n\nb. **Hyperparameter.**  All the hyperparameters are listed in detail in Table 2 on page 30 of the appendix and we use standard initialization offered by Pytorch. SAM is implemented using an open-source library and the implementation can also be found in the appended material `code/sam.py`.\n\nRegarding the reviewer’s question, the authors perform a hyperparameter search on SAM for the experiments in Figure 4b. We search through learning rate from [3e-2, 1e-2, 3e-3, 1e-3] and perturbation radius from [0.01, 0.03, 0.05, 0.10]. We find out that using small initialization (scaling down the first layer by a factor of 0.01), the model can find a perfect generalizing solution using 1-SAM. We believe this is however caused by the implicit bias of small initialization, which might have a similar effect as norm constraint, as vanilla SGD also reaches good generalization performance using this initialization. However, using the standard initialization, the best model we found only reaches 0.84 validation accuracy and the hyperparameter is exactly the one we adopted in the paper. We believe this shows that what we have shown is not an artifact due to poor hyperparameter and we would also want to stress that we are only claiming that SAM can find a flattest but non-generalizing solution, which is inherently an existential claim.\n\nc. **Extension.** The authors have already done some extended experiments on other synthetic setups (see Figure 7 in the appendix) and also added an experiment on MNIST to further strengthen the paper according to the reviewer’s advice. Please see the general response for a detailed discussion.\n\nd. **Visualization.** We agree that visualization could help the readers better understand what happens during training. Unfortunately, we do not have a good idea of how to visualize a high dimensional trajectory except plotting certain statistics like train/valid acc/loss, sharpness, etc.\n""}}, {'rebuttal': {'value': 'We thank the reviewer for the effort and time invested in the review. However, there are a lot of misunderstandings in the review and we clarify them below one by one.\n1. To our best knowledge, there is no reported correlation between progressive sharpening and better generalization. Arora et al. 2022, shows that normalized GD reduces sharpness after reaching edge of stability and simultaneously improve generalization.\n\n2. The goal of our work is to investigate sharpness and generalization. We agree with the reviewer that in practice many design choices including the batch sampling scheme can affect generalization but we choose to investigate the minimal setting where the data are i.i.d sampled and both the sharpness and the training loss are minimized. As shown in the paper, even this minimal setting would require much investigation.\n\n3. We believe that our work has made a solid step toward revealing the relationship between sharpness and generalization by answering the questions listed in the introductions which are not answered by any previous works that the authors know of. \n\n4. Regarding the title of the sections, the authors have already stated in the introduction that the relationship may subtly depend on architectures and data distributions. The authors have also clarified in both the introduction and section title that statements including `All flattest model generalize` can only be stated under the scenario defined by architectures and data distributions.\n\n5. It is true that the variable is a random variable depending on the training data set. However, the randomness is already explicitly considered in `1 − δ over the random draw of training set`  on line 143.\n'}}, {'rebuttal': {'value': 'We appreciate the reviewer’s positive review! Below are our responses to the reviewer’s concerns:\n\n* **W1.** We would like to clarify that we only perform experiments on synthetic tasks instead of CIFAR10 or CIFAR100 in the paper. However, we added an experiment on MNIST in the rebuttal phase. See the general response for a detailed discussion.\n* **W2.** Thank you for the helpful advice! We will fix and correct the formatting issues in future versions.\n* **Q1.** We made a typo in the quoted sentence — there should be no “poorly” at the end of the sentence. The corrected version is “there exist non-generalizing flattest models and sharpness minimization algorithms fail to generalize”.\n'}}, {'rebuttal': {'value': 'We would like to thank the reviewers for the detailed reviews. Below we address a common question (by reviewers fkTA and ex27) on data distribution, whether the phenomena observed on synthetic datasets in this paper extend to vision datasets, by providing additional MNIST experiments. \n\n**MNIST experiments**. \nWe observe that on the MNIST dataset when running SAM for a sufficiently long time, the validation accuracy will also drop while the sharpness decrease as in the synthetic setup, showing the generality of our result. We also observe that the converged accuracy of 1-SAM, in this case, is lower than the converged accuracy of SGD with weight decay regularization, which is also consistent with our findings in the synthetic setup.\n\nDue to time constraints (we can only use batch size 1 for 1-SAM), we choose to downsample the MNIST image to 7$\\times$7. We use a training sample size of 1000 and a 2-layer ReLU network with a width of 2000 here. The hyperparameters we choose and the resulting training curves are shown in the appended pdf. \n\nFinally, we want to stress that even without additional vision experiments, our theoretical analysis has already excluded the possibility of proving a generalization bound for all flattest interpolating deep relu networks and shows that the relationship between flatness/sharpness minimization algorithm and generalization subtly depends on the architecture. For simplicity of presentation, we choose to focus on the two-layer net in the main paper and leave more studies on more realistic settings for future work.\n'}, 'pdf': {'value': '/pdf/79cde7278999bc85a610f708a6f214c99381f359.pdf'}}, {'summary': {'value': ""This paper explores the relationship between sharpness and generalization in overparameterized neural networks. The authors challenge the popular belief that flatness of the loss function implies better generalization and show that sharpness minimization algorithms do not always lead to better generalization. Through theoretical and empirical investigation, the authors identify three different scenarios for two-layer ReLU networks, showing that the relationship between sharpness and generalization is subtle and depends on the data distributions and the model architectures. The paper's contributions include a theoretical analysis of the relationship between sharpness and generalization.""}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The authors identify three scenarios for two-layer ReLU networks and provide theoretical and empirical evidence to support their findings. I believe the subtle details in architecture and distribution located in this paper are remarkable. Overall, this paper makes significant contributions to the field of generalization theory and challenges the popular belief that the flatness of the loss function implies better generalization.  '}, 'weaknesses': {'value': '1.\t One potential weakness of the paper is that it only examines the relationship between sharpness and generalization for two-layer ReLU networks (personally, I think this is acceptable since it is very hard to analyze more complex scenarios). Additionally, the authors only examine the CIFAR-10 and CIFAR-100 datasets, and it would be valuable to examine their findings on other datasets to determine if their results generalize to other domains. \n2.\tThe expression of the article is not very friendly and a little difficult to understand.\n3.\tThere are some grammatical and formatting problems, some of which are shown as follows.\n1)\tPictures should be resized to make them look more coherent. In addition, the text in the image should be consistent with the font within the paper.\n2)\tThere are some spelling errors, such as “subtlely”.\n3)\tReferences are poorly formatted. Please use a uniform format for references. \n4)\tFormulas and variables should be consistent with the font within the paper.\n5)\tOperators should be carefully defined.\n6)\tThere are some formatting issues. For example, lowercase letters as the first letter of a sentence.\n'}, 'questions': {'value': '1. In abstract, what does this sentence “there exist non-generalizing flattest models and sharpness minimization algorithms fail to generalize poorly” mean?'}, 'limitations': {'value': 'The authors have adequately addressed the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work aims to examine different cases for which flatness implies generalization. The conclusion heavily depends on the underlying model, while there are three different scenarios that contradict with each other. Additionally, the theoretical guarantees study the generalization error at the solution, however the empirical guarantees consider the generalization error at the last iteration of the SAM algorithm. Despite the convergence of the SAM algorithm, the training horizon may also affect generalization. With alternative sampling schedules of the data-set, it can be possible to minimize the training horizon (for instance see Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning by Okanovic et al.). I think it would be useful to examine if the SAM algorithm generalizes better when considering alternative sampling schedules. In such a case, the batch-selection policy could be more significant than the sharpness minimization. As the author also mention flattest solutions are not directly associated with efficient generalization in general.\n\nFurther, there is a deep literature for the edge of stability phenomenon (Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability by Cohen et al.). In this case, the sharpness increases at termination (Understanding Gradient Descent on the Edge of Stability in Deep Learning by Arora et al., Section 2. Related Works), however good generalization performance have been observed in some cases. These cases might be considerd by the authors to provide a more complete picture for the empirical part of the paper, and additional conclusion about sharpness minimization and generalization. \n\n  '}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': 'The results are original and provide a partial evidence between sharpness and generalization, however the conclusion is not clear. Theorem 3.1 is an interesting result, however it is limited to a simple architecture but it is valuable.'}, 'weaknesses': {'value': 'Some parts of the paper are not clear enough. For instance, there exist statements like ""All flattest models generalize"" while the statement holds only for certain cases. It appears that the theoretical guarantees study generalization at the solution, however in practice the generalization of the algorithm might be different (see also the Summary). The main question of the paper has been considered in prior works as well. '}, 'questions': {'value': 'In theorem 3.1 the variable $\\theta^*$ should be a random variable that depends on the training data-set. Is this true? In such a case the authors may consider to use the notation of the conditional expectation in the statement of the Theorem to make this fact clear.'}, 'limitations': {'value': 'The authors have addressed the limitations sufficiently.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper studies the connections between sharpness of the training loss and generalization performance under a simplified MLP architecture. In particular, authors show scenarios of when flat solution do/do not generalize, as well as cases when Sharpness-Aware Minimization (SAM) does/does not generalize.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': 'The theoretical insights of the paper are interesting and hopefully can help better understand the relationship between flatness and generalization.'}, 'weaknesses': {'value': ""I think the paper has several shortcomings, outlined below.\n\n- Model setup: I think the model setup is too simplistic. The input space is binary, which I think is fine. However, no noise is considered in the model and the output label $y=x[1]x[2]$ satisfies a very specific structure. Therefore, it is not clear to me why results discussed in the paper would generalize to broader model setups, and the observations discussed here are not just an artifact of the simplistic model. As shown in Lemma 3.1, the sharpness under the paper's setup is closely related to the weight norm, which may or may not be the case in a more realistic setup. \n\n- Experiments: I don't find the experiments on SAM convincing. How is SAM implemented? How are the algorithm hyper-parameters chosen? How is SAM initialized? Maybe changing the SAM parameters and initialization would change the outcome of the experiments.  Can the observation of SAM converging to non-generalizing flat solution be replicated in a more realistic setup? Is weight decay used for SAM, as specially, in this case sharpness seems to be closely related to the weight norm.\n\n- The authors miss [1]. As this paper discusses the connections between generalization and sharpness/SAM, the authors should discuss and compare their results to [1], specially as [1] discusses noisy setups.\n\n\n[1] Behdin, K., & Mazumder, R. (2023). Sharpness-aware minimization: An implicit regularization perspective. arXiv preprint arXiv:2302.11836.""}, 'questions': {'value': '- Maybe some visualization might help address some of my concerns in the previous part? For example visualizing the SAM/GD trajectories?\n\n- Additional experiments either on noisy data settings or more realistic deep networks might help fill some of the gaps in the paper.\n\n'}, 'limitations': {'value': 'n/a'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper sheds light on the relationship between three concepts: (a) generalization (b) flatness and (c) explicitly inducing flatness via SAM. The paper identifies that the relationship is nuanced and is based on certain architectural properties of the model.\n\n Specifically, depending on the architecture, there are three possible regimes:\n1. A regime where _every flat minimizer generalizes well_ and SAM finds these minimizers.\n2. A regime where _there exists flat minimizers that generalize poorly_ but SAM does _not_ find these minimizers.\n3. A regime where _there exists flat minimizers that generalize poorly_ and SAM _does_ find these minimizers.\n\nThe paper shows that \n\n- Regime (1) happens for 2-layer RELU networks _without_ bias\n- Regime (2) happens for 2-layer RELU networks _with_ bias\n- Regime (3) happens for 2-layer RELU networks _with_ bias, _with_ a simplified Layer Norm.\n\nNote that in all cases, the existence of a flat solution that generalizes/memorizes is proven theoretically; while the effect of SAM is demonstrated empirically.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. The questions formalized in the paper are novel, and well-formulated. \n2. I gained a much clearer understanding of some generally unclear and confusing concepts: (a) flatness, (b) generalization and (c) explicitly inducing flatness. All these ideas are dealt with care and rigor. \n3. The introduction is well-written and the chain of arguments are explained clearly. Despite being a theoretical and nuanced paper, I found it extremely easy to follow the arguments in each section. I thoroughly enjoyed reading the paper!\n4. Rather than unnecessarily complicate the theory, the authors come up with a reasonably minimal settings of a 2-layer _non-linear_ model and support their arguments with either a formal result or with a rightly-designed empirical result. \n5. That there are situations where the flattest solution does not generalize well is surprising from a theoretical point of view.'}, 'weaknesses': {'value': ""I currently do not have any major concerns about this paper. Most of my comments are follow-up questions, which I enumerate in the next section. My most important question --- which may or may not hint at a weakness --- is below:\n\n### Major question\n\nQ1a: Could you be more explicit about any parameter count dependence in the Rademacher complexity term of Thm 3.1 and Lemma 3.1? I am unsure if this is orthogonal to the main point of the result, so I'd also appreciate some clarity on that.  \n\nQ1b: On that note, I'd also like to know why this bound would break down upon the introduction of bias into the architecture. Would one of the terms within the Rademacher complexity end up scaling with the number of datapoints?""}, 'questions': {'value': '1. Def 4.1 for the memorizing solutions appears to be incomplete and can be more formal. First, by _input data_, please clarify that you are referring to the training data. Furthermore, you also require the additional criterion that the activations of the model on _test_ data are all zero --- is this right? If not, the definition appears to be incomplete as even the raw inputs must more or less satisfy the orthogonality assumption with high probability? i.e., when we sample from a high-dimensional hypercube, two samples must more or less be orthogonal. So this alone shouldn\'t characterize a memorization solution? \n\n2. Could you provide intuition for what the ""flattest solution"" in Eq 4 satisfies? It seems to require that _the activated top-layer weights have correspondence to the activations themselves_. I don\'t think Fig 3 captures this specific structure?\n\n3. Do you empirically find that SAM learns a solution whose parameters resemble Eq 4 in any way?\n\n4. The motivation behind the choice of loss function can be made more transparent. In particular, the main loss function used is squared error loss. In the appendix, the authors also use logistic loss _but with label smoothing_. If I am not wrong these choices ensure that the flattest minimizer exists and is unique up to some permutations. However, with pure logistic loss, the flattest minimizer would become ill-defined since there would be many different flat minimizers ""at $\\infty$""? I believe this is the reason behind a line of work in PAC-Bayes literature that tries to ""normalize"" flatness in a well-defined way. In other words, this work ""sidesteps"" this annoying issue; this is okay, as it still helps outline an elegant insight. But this needs to be clearly stated so that readers can put this result in context. \n\n### Minor suggestions\n\n1. I\'d suggest making the specific notion of trace-of-hessian-based flatness clear in the abstract and in the beginning of the introduction. Since there are many notions of flatness, it would be good to be upfront about which notion is being discussed here.\n\n2. In the introduction, I\'d suggest clarifying that the SAM-related results are purely empirical.\n\n3.  Section 4 title seems incorrect. In this regime, SAM finds the _latter_ non-generalizing solution not the former one.\n\n4. Line 167 makes an abrupt reference to a theorem that\'s not discussed until then. \n\n5. It\'s not clear until we get to the discussion of SAM as to whether the proof is empirical or not. \n\n6. In Sec 5.1, instead of simply referring to Thm 3.1 and 4.1, I would add a verbal description so that it\'s easier to follow.\n\n\n### Summary\n\nOverall, I found this paper to be insightful, rigorous and clear in its message. The community would find this valuable given the confusing nature of literature in flatness. \n\n### Post-rebuttal update\n\nI have increased my score since the authors addressed my response satisfactorily. \n**I\'d also like to respectfully express my strong disagreement with concerns raised in the other reviews.**\n- Regarding ""Two-layer network is too simplistic"": When a certain truth has not been proven in any setting to begin with, and when someone makes headway by providing the first proof in a simple setting, it is unfair and counter-productive to hold it against them. For without that headway, there is little hope for more general analyses. In fact, IMO proofs in more general settings (like a multi-layered network) get so unwieldy as to become uninsightful. Furthermore, in this scenario, the setting is a 2-layer network which does not reduce to a linear function of its parameters. IMO, the statements in this paper are already highly non-trivial to identify, let alone prove. \n- Regarding considering other alternate versions of SAM, this is an interesting reformulation of the problem. Thanks to this work, we can be better posed to answer more important questions. Hence, again I don\'t want to fault this paper for not proving its elegant theory in various sophisticated versions of SAM. I would share this review\'s concern had the considered setting been far removed from practice, and promised no tangible way of extending to other situations --- this doesn\'t seem to be the case here, in my humble opinion.'}, 'limitations': {'value': 'The paper lists reasonable limitations in the conclusion.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization'}, 'authors': {'value': ['Kaiyue Wen', 'Zhiyuan Li', 'Tengyu Ma']}, 'authorids': {'value': ['~Kaiyue_Wen1', '~Zhiyuan_Li2', '~Tengyu_Ma1']}, 'keywords': {'value': ['Sharpness', 'Flatness', 'Generalization', 'Generalization Bound', 'SAM']}, 'abstract': {'value': 'Despite extensive studies, the underlying reason as to why overparameterized\nneural networks can generalize remains elusive. Existing theory shows that common stochastic optimizers prefer flatter minimizers of the training loss, and thus\na natural potential explanation is that flatness implies generalization. This work\ncritically examines this explanation. Through theoretical and empirical investigation, we identify the following three scenarios for two-layer ReLU networks: (1)\nflatness provably implies generalization; (2) there exist non-generalizing flattest\nmodels and sharpness minimization algorithms fail to generalize poorly, and (3)\nperhaps most strikingly, there exist non-generalizing flattest models, but sharpness\nminimization algorithms still generalize. Our results suggest that the relationship\nbetween sharpness and generalization subtly depends on the data distributions\nand the model architectures and sharpness minimization algorithms do not only\nminimize sharpness to achieve better generalization. This calls for the search for\nother explanations for the generalization of over-parameterized neural networks'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'For 2 layer ReLU networks, sharpness may not always imply generalization but sharpness minimization algorithms may still generalize even when non-generalizing flattest models exist.'}, 'pdf': {'value': '/pdf/792a3dd52dec1befb169589b56c61753983f0c0a.pdf'}, 'supplementary_material': {'value': '/attachment/4b0c11e1ac24ed5af8744525d9ec3d9a75c6be16.zip'}, '_bibtex': {'value': '@inproceedings{\nwen2023sharpness,\ntitle={Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization},\nauthor={Kaiyue Wen and Zhiyuan Li and Tengyu Ma},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=Dkmpa6wCIx}\n}'}, 'paperhash': {'value': 'wen|sharpness_minimization_algorithms_do_not_only_minimize_sharpness_to_achieve_better_generalization'}}]"
"['Lorenzo Loconte', 'Nicola Di Mauro', 'Robert Peharz', 'Antonio Vergari']",NeurIPS,How to Turn Your Knowledge Graph Embeddings into Generative Models,https://neurips.cc/virtual/2023/oral/73848,2023," Some of the most successful knowledge graph embedding (KGE) models for link prediction – CP, RESCAL, TuckER, ComplEx – can be interpreted as energy-based models. Under this perspective they are not amenable for exact maximum-likelihood estimation (MLE), sampling and struggle to integrate logical constraints. This work re-interprets the score functions of these KGEs as circuits – constrained computational graphs allowing efficient marginalisation. Then, we design two recipes to obtain efficient generative circuit models by either restricting their activations to be non-negative or squaring their outputs. Our interpretation comes with little or no loss of performance for link prediction, while the circuits framework unlocks exact learning by MLE, efficient sampling of new triples, and guarantee that logical constraints are satisfied by design. Furthermore, our models scale more gracefully than the original KGEs on graphs with millions of entities.",Oral 1C Tractable models,https://openreview.net/pdf?id=RSGNGiB1q4,https://openreview.net/forum?id=RSGNGiB1q4,RSGNGiB1q4,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': ""The paper introduces an innovative perspective on knowledge graph embedding (KGE) models, allowing for generative model construction through maximum likelihood estimation (MLE). The incorporation of logical constraints enhances inference validity. The paper's clarity, well-structured presentation, and reimagining of training objectives as MLE have been mentioned as its strengths. The well-designed experiments further support the proposed methods. All reviewers are positive to very positive about his submission. I strongly recommend accepting this paper, as it significantly contributes a fresh perspective to the evolving landscape of KGE research.""}}, {'comment': {'value': 'Thank you for your response. I believe that the paper is worth a clear acceptance.'}}, {'comment': {'value': 'Thank you for the detailed answers. They addressed my concerns and I have raised my score.'}}, {'title': {'value': 'Please read and respond to the rebuttal '}, 'comment': {'value': 'Dear reviewer,\n\nYou rated the paper with the lowest score. Please read and respond to the rebuttal. Has it changed your assessment? Please also read the other reviews which are more positive about the paper. \n\nThanks!'}}, {'rebuttal': {'value': 'We thank the reviewer for all the comments. We believe we addressed all the concerns and are happy to follow up in the discussion phase.\n>The difference between GeKCs and other KGEs is constraining scores or squaring?\n\nYes, although apparently simple, this modeling difference enables the semantic of normalized probabilities which unlocks a new set of capabilities for KGE models: (i) scaling training to very large KGs (ii) guaranteeing satisfaction of constraints by design which is crucial in high-stake scenarios, and (iii) generative capabilities. This is possible only thanks to recent theoretical advancements in circuits [72].\n>Empirical results are not motivating enough\n\nWe remark that the goal of our paper is *not* doing SOTA results for link prediction (L289-290) but to show that a new class of KGEs can excel in other important directions, namely (i-iii) highlighted above. Furthermore, in terms of link prediction only, GeKCs score comparable or better than KGE baselines. Therefore making a strong alternative if one is interested in (i-iii).\n>d-ComplEx2 results are 100 by design, but ComplEx also achieves high numbers\n\nNote that while ComplEx can achieve 99+% semantic consistency, it still predicts more than 360 of semantically invalid triples (see L327-328). Even if it achieved 100% on the test set, it would not guarantee that predictions will be valid for future queries. Our method instead guarantees predictions that will **always be valid**, which is crucial in high-stake applications as pointed out by reviewer t9NK.\n>Can you provide d-ComplEx2\'s link prediction performance\n\nWe did not run D-ComplEx^2 on FB15K-237 and WN18RR because they do not come with constraints, differently from ogbl-biokg. In the attached pdf, we show that GeKCs with domain constraints perform similarly or better than GeKCs alone (and better than other KGEs). We are happy to experiment on additional KGs with domain constraints suggested by the reviewer.\n>Why does the GeKCs scale better?\n\nBecause summations in PLL and MLE can be pushed down to the inputs of circuits, thus requiring only linear time w.r.t. the number of entities and predicates (L148-155). This further simplifies the complexity w.r.t. the batch size, as we formalize in Appendix C.4.1-2.\n\nSquared GeKCs adds a minor overhead (see answer 3 to reviewer S5Mx), which is absorbed by the aspects above.\n>When is PLL/MLE recommended?\n\nMLE is recommended to learn better generative models, to improve sample quality (see Table 2). By contrast, as expected by training with a discriminative objective, training via PLL favors link prediction scores, but falls short in other inference tasks. We detail the PLL-MLE relationship in answer 2 to reviewer t9NK.\n>Can Negative energies be compared?\n\nWe can only compare the scores of triples that answer the same query to get an ordering for ranking (L27). Scores associated to different queries (eg, different predicates) can differ a lot and are not informative without renormalizing. This can negatively affect a concrete scenario such as complex query reasoning, where scores associated to triples with different predicates are compared. Recently this particular aspect has been investigated in [B].\n>Why comparing scores across KGE models?\n\nComparing scores is useful to perform model selection or model integration. For model selection, the log-likelihood is the canonical way to compare probabilistic models but requires normalized probabilities. For integration, consider this real-world application: consolidate several existing KGEs from Wikipedia in different languages or integrate them with a probabilistic LLM: we need scores that are normalized in the same range.\n>Why sampling?\n\nSampling enables us to approximate complex probabilistic inference scenarios, eg, via Monte Carlo estimates. Particularly for KGs, this was useful to approximate the proposed Kernel Triple Distance (Appendix F.3) or to answer complex queries [10,15]. Also, [9] has shown that performing data augmentation via sampling during training can be beneficial for link prediction.\n>Can we set energies to infinity if a query violates constraints?\n\nFiltering EBMs predictions ex-post can be done, but with an external reasoner and this can be very expensive in practice.  Eg, to answer a query $(s,p,?)$ we need first to find all objects $o’$ for which $(s,p,o’)$ violates the constraint. This requires calling a reasoner for possibly millions of objects. For more complex reasoning scenarios, involving predicting multiple links, the number of calls quickly grows (eg, finding all objects $o’$ such that $\\exists V.(s,p,V)\\land (V,p’,o’)$ is satisfied). The missed opportunity here is to amortize all the intermediate reasoning computations done for the same $(s,p)$, or $(p,o)$ when later we want to answer $(?,p,o)$.\nThe knowledge compilation step in our models (L242-244) does exactly this, converting these reasoner calls into a compact circuit structure [18,51].\n>Can we turn all sorts of models into PCs?\n\nInvestigating how to turn other KGE models into GeKCs is surely interesting and worth a follow up, please see our responses to reviewers v5Gr, S5Mx.\n>What does consistent mean?\n\nWe will specify in the camera-ready that consistency means that entities satisfy the logical constraint.\n>There are two levels of ""="".\n\nThanks, we will fix it in the camera-ready.\n>Initializing by CP and ComplEx should not be called distillation.\n\nThanks, we will fix that line by mentioning we are indeed performing fine-tuning as reported in Table F.5.\n>How can KGEs be smaller, now that the presented circuits are already with only 2 layers?\n\nWe can leverage the data to learn __sparser__ structures of KGE models. For example, by clustering triples (or entities/predicates) we can smartly construct connections encoding particular dependencies and avoid “fully connected” layers as they are now. \n\n[B] E. Arakelyan et al. Adapting Neural Link Predictors for Data-Efficient Complex Query Answering 2023\n'}}, {'rebuttal': {'value': 'We thank the reviewer for the positive feedback and pointing out how GeKCs are indeed competitive with existing KGE models.\n\n> Could other KGE models such as TransE, RotatE be viewed as circuits?\n\nThis is a super interesting question. Here are some ideas.\n\nTo our knowledge, distance-based KGE models like TransE and RotatE have not been trained as energy-based models using the pseudo-log-likelihood (PLL). In fact, they are not shown in Figure 2 in [55], which compares several KGE models on different experimental settings.\n\nThis is likely because they have different semantics than tensor factorization-based models.  Indeed, the scores computed by TransE and RotatE are “distances”, while scores given by tensor factorization-based models are “similarities”. The first have been interpreted as energies while the latter as negative energies (see L68-70).\n\nOne possible way to represent TransE as a probabilistic circuit (PC) is by using a squared norm-2 as distance measure. By doing so, the scores (distances) would be a sum over squares, which can be written as a sum of decomposable squared circuits as done in our work. Representing RotatE as a PC is more challenging. This is because to our knowledge, RotatE is based on a norm-1 on complex embeddings and therefore it would require computing square roots. However, if we slightly modify the original RotatE formulation to use a squared norm-2 instead, we should recover a circuit akin to the one for TransE.\n\nOnce we turn TransE/RotatE into a PC, then it would encode a probability distribution $q(S, R, O)$ assigning low probability to likely triples and high probability to unlikely triples, since scores are energies (see above). To solve this issue, it might be possible to model the distribution $p(S,R,O) \\propto 1 - q(S, R, O)$ with a circuit and then re-normalizing it (which can be done efficiently). By doing so, we should possibly be able to train them using the PLL objective, akin to the proposed GeKCs. This is certainly an interesting perspective that deserves to be investigated rigorously in a follow up work.\n\n\n> In line251, how is |c_k| be calculated?\n\n$|c_K|$ is calculated by counting the number of edges in the compiled logic circuit, which depends on how complicated the logical formula $K$ is.\n\nFor domain constraints, we have shown in Proposition A.1 that in the best case it is linear in the sum of the number of entities $|E|$ and the number of predicates $|R|$. In the worst case is instead linear in the product $|E| \\cdot |R|$. In practice, we noticed that on ogbl-biokg the domain constraints are much closer to the best case scenario. In fact, the size of the logic circuit is $306,841$ while $|E|=93,773$ and $|R|=55$.\n\n\n> Does that mean constrained GeKCs generally have higher computational cost compared to the one without constraints?\n\nThe computational cost of constrained GeKCs is similar to the cost of multiplying two circuits. In the **worst** case is the product of the sizes of the two circuits, but this is a loose bound and in practice the complexity is much lower as already noted in [D] [72].\n\nFigure 3 supports this claim in practice, since ComplEx^2 brings only a small overhead with respect to ComplEx+ and can be much faster than ComplEx.\n\nTo put this in context of the constrained circuits, multiplying by a $c_K$ is going to add a similar overhead, worst case proportional to $|c_K|$. Luckily, the size of $c_K$ for ogbl-biokg is $306,841$. Now consider that the size of the circuit for ComplEx(+) with embedding size 1000 is already much larger, about $375 \\cdot 10^6$ and by the same argument in Figure 3 their product should not add more overhead. \n\n\n> Why does training time for squared-COMPLEX in ogbl-biokg decrease compared to COMPLEX/COMPLEX+? \n\nThe times shown in Table 1 are relative to the best models found based on validation data, which might have different hyper-parameters and therefore converge at different rates. The results of a more accurate benchmark on the much larger knowledge graph ogbl-wikikg2 are shown in Figure 3.\n\n[D] Y. Shen et al., Tractable Operations for Arithmetic Circuits of Probabilistic Models (2016)\n'}}, {'rebuttal': {'value': 'We are grateful to the reviewer for valuing the significance of our contribution as well as its execution.\n\n\n> “The constraint adding part can be extended into another work”\n\nThanks for recognizing the significance of our work for reliable decision making in safety-critical scenarios. We have some applications of KGE models in biomedical domains in mind, where indeed making trustworthy predictions is crucial if we want to deploy these models and use them. We are very open to additional suggestions.\n\n\n> It is not clear from line 89 why (2) is considered a proxy for (1). \n\nWe say the PLL is a proxy of the actual log-likelihood because, under certain assumptions, it is possible to show that the PLL objective can retrieve the MLE solution asymptotically with enough data [C].\n\nTo give more context, computing the partition function is infeasible for traditional KGE models when dealing with large knowledge graphs. This generally holds for arbitrary energy-based models (EBMs). In the EBM literature, the pseudo-log-likelihood (PLL) circumvents the problem of computing the log-likelihood exactly as it is easier to compute (it requires summing over only one variable at a time).\n\nAn additional difference is that the PLL is a classical discriminative objective while the MLE is a generative one. As such, it permits to obtain a better estimate of the joint probability distribution, and not just (one or many) conditionals, thus being more suitable for generative tasks such as sampling or imputation.\n\n\n> In Table 2, it is not stated why the results from [12] were not included as a baseline. \n\nOur PLL objective is a generalization of the loss used in [12]. In fact, the loss used in [12] can be retrieved from the PLL by setting $\\omega_s = \\omega_o = 1$ and leaving $\\omega_r$ as an hyperparameter. We highlight this in L920-921 in the appendix.\n\nTherefore, our experimental setting with CP and ComplEx when using the PLL encompasses the one in [12] under the column labeled with PLL in Table 1 (here we are assuming the reviewer is referring to Table 1 and not 2, please let us know if that is not the case). The difference in terms of MRR w.r.t. [12] is due to a simplified experimental protocol: a smaller grid search and fixing $\\omega_r = 1$. This is because of our limited computational resources, but searching more hyperparameters (and for longer) would likely bring better results for all models.\n\n[C] A. Hyvärinen, Consistency of Pseudolikelihood Estimation of Fully Visible Boltzmann Machines (2006)\n'}}, {'rebuttal': {'value': 'We thank the reviewer for appreciating the rigor, novelty and direction of our research! Such a simple idea can open up many valuable perspectives.\n\n> There are other KGE methods (e.g. graph neural networks) that are not covered by this paper.\n\nIndeed, connecting circuits with more general KGEs such as GNNs is a promising idea.  Unfortunately, these models are generally more difficult to deal with, given the presence of some non-linearities that cannot be modeled within the language of tractable circuits. However, recently a connection between GNNs and tensor factorization-based KGE models has been established [A], thus our analysis might well be useful  for connecting GNN-based models and circuits in future work.\n\nAdditionally, in our response 1 to reviewer S5Mx we sketch how to turn other KGE models such as TransE and RotatE into GeKCs. However, this is not straightforward and is left to future  work.\n\n[A] Y. Chen et al. ReFactor GNNs: Revisiting Factorisation-based Models from a Message-Passing Perspective (2022).\n\n'}}, {'rebuttal': {'value': 'We thank all reviewers for the time spent reviewing the paper and recognizing the **significance** (“useful and elegant theoretical framework” – v5Gr, “solid theory” – P87h, “deserves a wide audience for its insights and rigorous analysis” – t9NK) and **novelty** (“Novel combination” – P87h, “making KGEs generative is brilliant!” – t9NK, “novel perspective” – S5Mx) of our research direction, as well as the **quality of the presentation** (“meticulously executed paper” – v5Gr, “clear presentation” – P87h, “well-written, with clear language and a well-structured presentation” – t9NK).\n\nWe provided below individual answers to your reviews, and we are happy to follow up on any aspect in the discussion phase.\n'}, 'pdf': {'value': '/pdf/264e7698db8ab699e18c8baa804750d2d8cc80b4.pdf'}}, {'summary': {'value': 'This paper provides a reduction from several well-known knowledge graph embedding (KGE) methods (e.g., TuckER, CP, etc.) to *decomposable* circuits $\\phi$ which can be efficiently computed in $O( (|E| + |R|) |\\phi|)$ (note that this is mostly due to the decomposable nature of TuckER and its derivatives). The authors then address the problem that $\\phi$ can be negative and hence suitable to directly represent a probability distribution by applying one of two operations---non-negativity or squaring---which allows the circuit to be efficiently learnt and sampled from. Finally, they show how the circuit formalism allows one to easily apply domain constraints as the product of the two circuits.\n\nThe authors then evaluate their proposed variants of the KGE methods on four knowledge graphs, where they show (1) their squared variant produces comparable or better results to the original variants with significant computational speedups, (2) their method guarantees domain constraints, and (3) their squared method generates higher quality samples than state-of-the-art. They authors present several additional results in their appendices including: showing that it is feasible to distilling parameters from already trained circuits to the proposed variants (which allows them to be sampled from) and showing that the proposed variants are better calibrated than the original ones.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""* This is a meticulously executed paper with thorough empirical evaluation. While its key results are in the paper, there are many more interesting and insightful experiments in the appendix.\n* The paper presents a useful and elegant theoretical framework for computing knowledge graph embeddings that *extends* existing methods like TuckER or ComplEx allowing them to be learned and sampled from efficiently (it's not just conceptual).\n* The paper is extremely well-written and clear.""}, 'weaknesses': {'value': '* While the paper reduces several existing KGE methods to circuits, the reduction is quite straightforward and only practical for this family of circuits. There are other KGE methods (e.g. graph neural networks) that are not covered by this paper or its related work.'}, 'questions': {'value': ""The paper is extremely well-written and clear, and I don't have any questions.""}, 'limitations': {'value': '* While the paper reduces several existing KGE methods to circuits, the reduction is quite straightforward and only practical for this family of circuits.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper converts score functions of knowledge graph embeddings into generative KGE circuits (GeKCs) by restricting activations to be non-negative or squaring their outputs. \nThe changes come with little or no loss of link prediction performance, \nwhile enabling probabilistic interpretations, exact maximum-likelihood estimation, better scaling when trained with discriminative objectives, efficient sampling of new triples, and logical constraints such as domain schema definitions. \nThe paper additionally proposes a metric for measuring the quality of sampled subject-predicate-object triples.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- Novel combination of probabilistic circuits and knowledge graph embeddings.\n- Clear presentation. Solid theory.'}, 'weaknesses': {'value': ""1. Multiple questions regarding the motivation (i.e. why the introduced properties are useful) need to be clarified. See Questions.\n2. Empirical results are not motivating enough. \n(a) Sec. 7.1 doesn't show evidence that GeKCs are always preferred for link prediction in terms of accuracy or provide actionable knowledge about on what datasets GeKCs may perform better. \n(b) In Sec. 7.2 Integrating Domain Constraints, d-ComplEx2 results are 100 by design, but the baseline ComplEx also achieves very high numbers (99+) while ComplEx2 has worse-than-baseline results. Can you provide d-ComplEx2's general link prediction performance as compared to methods in Sec. 7.1's experiments, so that people can decide whether it is worth using in practice? Do you have results on more than one dataset and more than one model?""}, 'questions': {'value': '1. To confirm understanding: the model difference between GeKCs and other KGEs is constraining scores to be non-negative or squaring them, and nothing else, right? \n2. About scaling.\n(a) Why does the GeKCs scale better, given the additional squaring operations or non-negative restrictions?\n(b) Is MLE intractable for the models in the paper that can be but are not yet converted to GeKCs? Can you elaborate on why?\n3. About loss. When is PLL training recommended and when is MLE training recommended? Why?\n4. About probabilities. (a) L29 says the scores cannot be compared across different queries, but L27 gives an example of scores being compared. Why? At least within the same model, negative energies can be compared, right? (b) L29: What are the cases where we want to compare scores across KGE models? (c) What\'s the benefit of having a probabilistic model instead of an energy based model?\n5. About sampling. Why would people want to generate a surrogate KG or do data augmentation? The aim for knowledge graph embeddings is to answer queries over incomplete knowledge graphs. Does having a generative model help this purpose?\n6. About logical constraints. Can we set energies to infinity if a query violates logical constraints? It seems that without the probabilistic framework presented in this paper, one may still be able to enforce logical constraints.\n7. About generality of the method. This paper turns the score functions of KGEs into probabilistic circuits. Can the same be applied to turn score functions in all sorts of models into PCs?\n8. L231: What does consistent mean?\n9. Eq. (3): There are two levels of ""="". Please differentiate them to avoid difficulty in parsing the formula.\n10. L307: Initializing by CP and ComplEx should not be called distillation.\n11. L361: How can KGEs be smaller, now that the presented circuits are already with only 2 layers?\n\nUpdate: The authors addressed my major concerns in the rebuttal.'}, 'limitations': {'value': 'The paper mentions future work which may be considered limitations. It does not seem to discuss negative societal impact, which it may not directly have.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors show that standard KGE models, such as COMPLEX, can be represented as structured computational graphs called circuits. They propose a new interpretation of these graphs and their parameters to create efficient and expressive probabilistic models over triples in a KG, called generative KGE circuits (GeKCs). These can be efficiently trained by exact MLE and scale well on large KGs with millions of entities. GeKCs can also sample new triples exactly and efficiently, and predictions at test time never violate logical constraints such as domain schema definitions. Experiments show that these advantages come with little or no loss in link prediction accuracy.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- This paper is well-written, with clear language and a well-structured presentation. I enjoy reading it.\n- The idea of making KGEs generative is brilliant! There have been so many new KGEs in the past years, we constantly rely on real world datasets. Now with the proposed method, we can actually generate KG datasets conveniently.\n- The re-interpretation of existing training objectives as MLE is very clever. \n- Additionally, the proposed method makes it easier to add constraints to KGEs. \n- The experiments are clearly designed and well-executed, further demonstrating the value of this work. \n\nOverall, this paper is a valuable contribution to the field and deserves a wide audience for its insights and rigorous analysis.'}, 'weaknesses': {'value': 'Maybe not a weakness but some extension?\n\n- The constraint adding part can be extended into another work. I can imagine, in high-stake decision-making applications like finance etc, adding constraints can play a vital role.'}, 'questions': {'value': 'Q1: It is not clear from line 89 why (2) is considered a proxy for (1). Can you provide more details on the reasoning behind this?\n\nQ2: In Table 2, it is not stated why the results from [12] were not included as a baseline. Is there a specific reason for this?'}, 'limitations': {'value': 'Limitations are discussed in sec 7.1 and sec 8.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""This paper provides an new perspective for looking at the popular knowledge graph embedding (KGE) method for knowledge graph completion. Specifically, KGEs models are re-interpreted as circuits. The paper first prove the circuits-based equivalence of score functions of several KGE models, and, in order to regulate KGE further as probabilisitic circuits (GeKC), two restrictions (i.e., non-negative, squaring) are introduced to modify the score functions. Additionally, two techniques are proposed to improve GeKCs: firstly, utilizing trained KGEs as initialization for efficient training of GeKCs, and secondly, introducing constraints to modify the support of GeKCs.\n\nThe empirical experiments demonstrate that GeKCs exhibit competitive performance compared to PLL objective applied in KGE. Moreover, the proposed constraint method is justified to avoid constraint violations during inference. Finally, the paper compares GeKCs' ability to the uniform and NNMFAug baseline, showing GeKCs' strong capability to generate new likely triples.""}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'Generally the paper presents a novel perspective for the knowledge graph embedding model. This perspective enables researchers to learn KGE models through MLE and therefore build a generative model based on those models. Additionally, logical constraints can be incorporated to this framework to ensure that projected triples are valid during inference.'}, 'weaknesses': {'value': 'The perspective of probabilistic circuits seems to be limited. As in the paper, the score functions of KGE models interpreted as circuits are mainly basd on tensor factorization.'}, 'questions': {'value': '1. Could other KGE models such as TransE, RotatE be viewed as circuits?\n2. In line251, how is |c_k| be calculated? Does that mean constrained GeKCs generally have higher computational cost compared to the one without constraints?\n3. Why does training time for squared-COMPLEX in ogbl-biokg decrease compared to COMPLEX/COMPLEX+? Theorem 1 suggests that squared-GeKCs have a higher level of complexity than that indicated in proposition 2.'}, 'limitations': {'value': 'I do not find out any potential negative societal impact.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'How to Turn Your Knowledge Graph Embeddings into Generative Models'}, 'authors': {'value': ['Lorenzo Loconte', 'Nicola Di Mauro', 'Robert Peharz', 'Antonio Vergari']}, 'authorids': {'value': ['~Lorenzo_Loconte1', '~Nicola_Di_Mauro1', '~Robert_Peharz5', '~Antonio_Vergari3']}, 'keywords': {'value': ['knowledge graph', 'knowledge graph embeddings', 'probabilistic circuits', 'probabilistic reasoning', 'tractable inference']}, 'TLDR': {'value': 'We cast existing state-of-the-art knowledge graph embedding models into generative models that enable us to perform exact and efficient marginalisation, sampling and to integrate hard constraints with theoretical guarantees.'}, 'abstract': {'value': 'Some of the most successful knowledge graph embedding (KGE) models for link prediction – CP, RESCAL, TuckER, ComplEx – can be interpreted as energy-based models. Under this perspective they are not amenable for exact maximum-likelihood estimation (MLE), sampling and struggle to integrate logical constraints. This work re-interprets the score functions of these KGEs as circuits – constrained computational graphs allowing efficient marginalisation. Then, we design two recipes to obtain efficient generative circuit models by either restricting their activations to be non-negative or squaring their outputs. Our interpretation comes with little or no loss of performance for link prediction, while the circuits framework unlocks exact learning by MLE, efficient sampling of new triples, and guarantee that logical constraints are satisfied by design. Furthermore, our models scale more gracefully than the original KGEs on graphs with millions of entities.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/b6a1b39d773ea904eb73eef1c51b2ae9a563bd18.pdf'}, 'supplementary_material': {'value': '/attachment/d134048902ac0563f8c793ce2489ed219e19bb88.zip'}, '_bibtex': {'value': '@inproceedings{\nloconte2023how,\ntitle={How to Turn Your Knowledge Graph Embeddings into Generative Models},\nauthor={Lorenzo Loconte and Nicola Di Mauro and Robert Peharz and Antonio Vergari},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=RSGNGiB1q4}\n}'}, 'paperhash': {'value': 'loconte|how_to_turn_your_knowledge_graph_embeddings_into_generative_models'}}]"
"['Kaiyu Yang', 'Aidan Swope', 'Alex Gu', 'Rahul Chalamala', 'Peiyang Song', 'Shixing Yu', 'Saad Godil', 'Ryan J Prenger', 'Animashree Anandkumar']",NeurIPS,LeanDojo_ Theorem Proving with Retrieval-Augmented Language Models,https://neurips.cc/virtual/2023/oral/73738,2023," Large language models (LLMs) have shown promise in proving formal theorems using proof assistants such as Lean. However, existing methods are difficult to reproduce or build on, due to private code, data, and large compute requirements. This has created substantial barriers to research on machine learning methods for theorem proving. This paper removes these barriers by introducing LeanDojo: an open-source Lean playground consisting of toolkits, data, models, and benchmarks. LeanDojo extracts data from Lean and enables interaction with the proof environment programmatically. It contains fine-grained annotations of premises in proofs, providing valuable data for premise selection—a key bottleneck in theorem proving. Using this data, we develop ReProver (Retrieval-Augmented Prover): an LLM-based prover augmented with retrieval for selecting premises from a vast math library. It is inexpensive and needs only one GPU week of training. Our retriever leverages LeanDojo's program analysis capability to identify accessible premises and hard negative examples, which makes retrieval much more effective. Furthermore, we construct a new benchmark consisting of 98,734 theorems and proofs extracted from Lean's math library. It features challenging data split requiring the prover to generalize to theorems relying on novel premises that are never used in training. We use this benchmark for training and evaluation, and experimental results demonstrate the effectiveness of ReProver over non-retrieval baselines and GPT-4. We thus provide the first set of open-source LLM-based theorem provers without any proprietary datasets and release it under a permissive MIT license to facilitate further research.",Oral 1B Datasets & Benchmarks,https://openreview.net/pdf?id=g7OX2sOJtn,https://openreview.net/forum?id=g7OX2sOJtn,g7OX2sOJtn,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (Oral)'}, 'comment': {'value': 'The paper introduces an open-source environment (LeanDojo) to extract proof trees out of Lean3, together with the premises of those proofs. These exacted proof trees are then used to build a new dataset for building stronger theorem provers.\nFinally, this dataset is used to train a sota retrieval augmented automated theorem proving model (ReProver) which performs premise retrieval. This model outperforms GPT-4 on tactic generation, and also finds proofs to theorems in the library that are missing proofs. This model also uses significantly less compute that previous models i.e. one GPU for 5 days. \n\nStrengths:\n1. This paper has overwhelming support from all reviewers.\n2. The paper fixes issues with previous environments LeanStep and Lean-gym and advances the sota quite considerably in this area.\n3. The paper execution is thoughtful with excellent and user-friendly documentation, and uses the very best practices.\n4. Unlike previous works with empty claims to be open source, this paper is actually already open-source, and will help the community make large strides of progress.\n\nWeaknesses:\n1. The only main weakness is that the paper can be hard to understand for folks outside the area of theorem proving - but the authors have taken efforts to address this in the rebuttal.'}}, {'comment': {'value': 'Thanks for your response! I think all my comments have been well addressed. Kudos to the authors for the awesome work!'}}, {'title': {'value': 'Response to Reviewer CZ3x'}, 'comment': {'value': 'We are happy to address your questions and really appreciate your willingness to raise the score!\n\n\n## Is There Something LeanStep/lean-gym Can Do That LeanDojo Cannot?\n\nlean-gym has a [shrink_proof](https://github.com/openai/lean-gym/blob/1585ac4d2e56a1ceb72243ce859645b9d0069d34/src/repl.lean#L327) function undocumented in their paper (Polu et al., ICLR 2023). From [comments in their code](https://github.com/openai/lean-gym/blob/1585ac4d2e56a1ceb72243ce859645b9d0069d34/src/tools/shrink_proof.lean#L12%E2%80%93L26), shrink_proof removes redundant tactics in a specific form of proofs. We don’t have sufficient information on the context in which shrink_proof is useful. Other than that, LeanDojo supports everything lean-gym can do.\n\nTo our knowledge, LeanDojo’s extracted data contains all information available in LeanStep.\n\n\n\n\n## How to Get the Required Lean Version of a Repo in Lean 3?\n\n\nAll repos in Lean 3 have a configuration file named leanpkg.toml containing the required Lean version. For example, here are the leanpkg.toml for [mathlib](https://github.com/leanprover-community/mathlib/blob/32a7e535287f9c73f2e4d2aef306a39190f0b504/leanpkg.toml#L4), [ProofNet](https://github.com/zhangir-azerbayev/ProofNet/blob/96c8978850fba27a748c941c276d9e178d0efbd4/leanpkg.toml#L4), [miniF2F](https://github.com/facebookresearch/miniF2F/blob/5271ddec788677c815cf818a06f368ef6498a106/leanpkg.toml#L4), and [lean-example](https://github.com/yangky11/lean-example/blob/5a0360e49946815cb53132638ccdd46fb1859e2a/leanpkg.toml#L4).\n\n\n## Clarification on Proof Styles\n\nMost proofs in mathlib are term-style, tactic-style, or a mix of them (example [here](https://leanprover.github.io/theorem_proving_in_lean4/tactics.html#structuring-tactic-proofs)). Other styles include [calculational proofs](https://leanprover.github.io/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs) and [the conversion tactic mode](https://leanprover.github.io/theorem_proving_in_lean4/conv.html), but they are relatively rare. Regardless of the proof style, ultimately the proof is converted into a term and then type-checked by Lean’s kernel. In this sense, term style is the most general proof style. In principle, you can write down the proof term directly. As we argued in the paper, tactic style is as general as term style, since any term-style proof can be converted into an equivalent tactic-style proof. In contrast, calculational proofs and conversion tactic mode are only applicable to certain types of theorems.\n\nLeanDojo only supports tactic-style proofs. When using LeanDojo to prove a theorem, the model must generate a tactic-style proof. Nevertheless, that theorem may have a human-written proof in any style.'}}, {'comment': {'value': 'Thank you for your detailed response, for clarifying a large number of issues, and for updating LeanDojo to version 4; great work! I will raise my score, but I will nonetheless await your further response before I do so.\n\n- Regarding lean-gym and LeanStep: As you mentioned, LeanDojo surpasses both of these. Is there something (in terms of data extraction or interaction) that these can do that LeanDojo cannot do? (In other words, is LeanDojo a strict improvement over them in all aspects?)\n\n- you mentioned you support https://github.com/zhangir-azerbayev/ProofNet in order to automatically identify Lean\'s version. Have you hardcoded this repo\'s structure to allow it to identify Lean\'s version? I am not sure how to make sense of ""_Under the hood, LeanDojo automatically identifies the required Lean version_"". In the *Getting Started* section, the ""hello word"" repo link you give, https://github.com/yangky11/lean-example, uses a different format.\n(If yes, which repos do you support? Or what layout do the repos have to adhere to? Do you support miniF2F as well?)\n\n- You mentioned that: ""_Another common type of proofs is ‘term-style proofs’. Any term-style proof X can always be converted into an equivalent tactic-style proof exact X, though such conversion may lead to unidiomatic proofs._""        \nI believe term-style proofs and tactic-style proofs are the only major types of proofs possible in Lean, but I believe there are also proofs like calculation proofs, starting with `calc` (though these form a minority). LeanDojo does not cover calculation proofs?       \nIf that is the case, please state clearly what types of proofs LeanDojo covers, and which it doesn\'t (the paper is still great, even if not everything is covered).'}}, {'title': {'value': 'Response to Reviewer fFD9'}, 'comment': {'value': ""Dear reviewer,\n\nThank you for your positive evaluation and constructive feedback! Below we address your questions and concerns. Please feel free to follow up if you have further questions!\n\n\n## Where Are the Extracted ASTs?\n\n\nLeanDojo can extract ASTs, though they were not included in the released datasets due to postprocessing. LeanDojo’s documentation has a [Getting Started](https://leandojo.readthedocs.io/en/latest/getting-started.html) page providing simple examples of extracting ASTs in XML format. The user can easily extract the ASTs corresponding to our released datasets by specifying the right GitHub URL and commit hash (e.g., https://github.com/leanprover-community/mathlib4, `355541ae7a2455222f179dcf7f074aa2c45eb8aa`).\n\n\n## Hard Negative Mining\n\n  \nIf we understand correctly, the reviewer proposes hard negative mining using the trained retriever. We experimented with this strategy earlier but didn't observe any performance improvements. One challenge was that model-selected hard negative premises were often wrong: although the ground truth proof didn't use them, they could be used to prove the theorem. Therefore, they were more like positive examples instead of hard negatives. Random negatives and in-file negatives suffer less from this issue.\n\n\n\n## Computational Cost\n\nWe agree a training time of 120 GPU hours may not be accessible to everyone. Nevertheless, we'd like to clarify a few points. First, the training can be run on a single GPU. Second, the 120 hours consist of two parts: training the premise retrieval + training the tactic generator. If you want to use either of them alone, its training takes only ~60 GPU hours. Third, since we open-source the model checkpoints, other researchers can finetune them on their own datasets with low computational costs.\n\n\n## More Detailed Limitations. Why Does LeanDojo Fail on 1.4% of Proofs?\n\n\nLeanDojo’s documentation contains a dedicated page for [technical limitations](https://leandojo.readthedocs.io/en/latest/limitations.html). We have updated the paper to include a link to this page. Regarding the 1.4% failed proofs, we have sorted the errors into a few categories and documented a few representative examples of each category in [LeanDojo's unit tests](https://github.com/lean-dojo/LeanDojo/blob/main/tests/interaction/test_unexpected_errors.py). The causes of these errors remain unknown. We consulted core developers of Lean. They believe the errors are due to some intricate interplay between Lean 3’s implementation and how metaprogramming is used in LeanDojo. Furthermore, we have verified that our 1.4% failed proofs are a strict subset of lean-gym’s 21% failed proofs.\n\n  \n  \n  \n\n## Timeline for Releasing the Data, Code, and Website.\n\nThe initial versions of the datasets were released on June 14 (Lean 3) and June 20 (Lean 4). The code was released on June 26, and the website was released on June 27. We didn't publicly release them earlier due to cleaning the code, adding documentation, and polishing the website. \n\nFrom our understanding of the [Call for Datasets & Benchmarks](https://neurips.cc/Conferences/2023/CallForDatasetsBenchmarks), it is not required to publicly release the data/code by the deadline. We apologize if their delayed release has caused inconvenience to the reviewing process.""}}, {'title': {'value': 'Response to Reviewer xf1r'}, 'comment': {'value': ""Dear reviewer,\n\nThank you for your enthusiasm for our paper! We address your comments below. Please feel free to follow up if you have further questions!\n\n  \n  \n\n## More Powerful LLMs\n\nWe're actively working on replacing the ByT5 used in this paper with more powerful LLMs such as StarCoder, SantaCoder, and ProofGPT. Preliminary results have revealed a few challenges. First, Lean is quite unique among other programming languages in its extensive use of Unicode characters. We find off-the-shelf pretrained models may struggle with tokenizing Lean code due to Unicode. Second, most state-of-the-art LLMs are decoder-only models, whereas tactic generation can be handled more naturally by encoder-decoder models. We're investigating the performance implication of these challenges.\n\n\n## Potential Impact on Formal Mathematics\n\nWe are excited to explore the impact of neural theorem proving on formal mathematics! There are many exciting future directions, for example, we're trying to train machine learning models in Python, convert them to intermediate representations such as ONNX, and run the inference directly in Lean via Foreign Function Interface (FFI). If successful, it will deeply integrate Lean and machine learning. For example, it will enable people to build LLM-based tactic generators or premise retrievers directly in Lean, which work seamlessly in Lean’s VSCode workflow.""}}, {'title': {'value': 'Response to Reviewer AsmJ'}, 'comment': {'value': 'Dear reviewer,\n\nThank you for your positive evaluation and constructive feedback! Below we address your questions and concerns. Please feel free to follow up if you have further questions!\n\n\n## Which Data Split Was Used to Train ReProver?\n\nResults in Table 1 and Table 2 were produced by two independently trained models. One model was trained/tested on the training/testing set of the “random” split, and the other model was trained/tested on the training/testing set of the “novel_premises” split. Thanks for pointing out the confusion, and we have updated the table captions to clarify.\n\n\n\n## Having Access to All Imports May Inflate the Performance\n\nIn the existing task setup (adopted by our work and prior works, e.g., [14–20]), the model is allowed to access all information before the proof (including file imports) and is only responsible for generating the proof. We agree with the reviewer that it is a simplification of the task faced by humans. When humans prove a theorem, they may need to import the correct premise by adding additional import statements. This can be an interesting alternative task setup, though we are not aware of prior works adopting this setup.\n\n\n\n\n\n## Relation to NaturalProver (Welleck et al. 2022)  \n\nThank you for pointing out the confusion. We have updated the paper to clarify that “prover” here refers only to formal theorem provers.'}}, {'title': {'value': 'Response to Reviewer crGr'}, 'comment': {'value': 'Dear reviewer,\n\nThank you for taking the time to review our paper! Your feedback is really valuable, and we address your questions/concerns below. Please feel free to follow up if you have further questions!\n\n\n\n\n## Accessibility to Readers without Background in Theorem Proving\n\nWe strive to make the paper accessible to general machine learning researchers, and we are sorry if the readability still needs improvements. We have updated the paper to make the example in Fig. 2 more salient and add a link to [LeanDojo’s extensive documentation](https://leandojo.readthedocs.io/). \n\n## Additional Baselines Incorporating the Key Ideas in Prior Works \n\nBelow we summarize the key ideas in prior works on learning to prove theorems in Lean:\n\n* Han et al., “Proof Artifact Co-training for Theorem Proving with Language Models”: Training the tactic generator jointly on tactic generation + auxiliary tasks is better than training on tactic generation alone.\n\n* Polu et al., “Formal Mathematics Statement Curriculum Learning”: The model can be improved further by using it to discover new proofs and adding the new proofs back to the training data. This procedure (called “expert iteration”) can be repeated multiple times. \n\n* Lample et al., ""HyperTree Proof Search for Neural Theorem Proving"": It may help to replace Best-First Search with HyperTree Proof Search (a search algorithm inspired by the Monte Carlo tree search in AlphaZero). \n\nThese ideas are orthogonal to our work, as they can in principle be incorporated into either the baseline or our method. However, as explained at the end of Sec. 5, incorporating these ideas would make the method substantially more complex and computationally expensive.\n\n## GPT-4 with Few-Shot Examples\n\nWe conducted additional experiments to compare the zero-shot GPT-4 baseline with a few-shot GPT-4 baseline. Specifically, given a proof state, we use a finetuned model to retrieve k similar states and use them (together with their corresponding tactics) as few-shot examples for GPT-4 to generate tactics. We use k = 4, as increasing k did not help in small-scale preliminary experiments.\n\nWe tested both models on 600 testing theorems from the “random” data split. They did not show a significant difference in performance (Pass@1 of 141/600 = 23.5% for zero-shot and 148/600 = 24.7% for few-shot). These experiments suggest GPT-4 might not be very good at generating tactics directly, even with few-shot examples in the prompt. A possible reason is that although there is Lean code in GPT-4’s training data, it does not contain latent information not visible in the code, e.g., intermediate proof states between tactics. We believe further research and more delicate methods are required to unleash GPT-4\'s potential for theorem proving.\n\n\n## Are the Proofs Generated by the Model Guaranteed to Be Correct?\n\nYes, they are guaranteed to be correct. Proof assistants such as Lean can check whether a proof correctly proves a given theorem statement. For Lean, the underlying principle is analogous to type checking. According to [Curry–Howard Isomorphism](https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence), a theorem statement is a type, whereas a proof is a value. Therefore, proof checking corresponds to checking if the value has a given type. Other proof assistants may have different logical foundations, but the common takeaway is that proof checking is relatively easy in any proof assistant.\n\n## Self-Training Loop to Continuously Improving the Prover\n\nYes, this is feasible and has been adopted by prior works mentioned in a previous question (“expert iteration” in Polu et al. and “online training” in Lample et al.). We didn’t perform such online improvements, as it is orthogonal to our work and requires a substantially larger compute budget.'}}, {'title': {'value': 'Response to Reviewer CZ3x (2/2)'}, 'comment': {'value': ""## Theorem Proving vs. Code Generation\n\nWe agree that the original statement (`Formal proofs are essentially computer programs. ... theorem proving is a special form of code generation, ...`) is simplistic and can be misleading. In the updated version, we have rephrased it as: `From a computer science perspective, formal proofs can be treated as programs~\\cite{howard1980formulae}. … theorem proving may be considered a special form of code generation, …`, where the citation refers to the Curry-Howard isomorphism (the relationship between programs and proofs that sits behind the logical foundation of Coq and Lean). \n\n```bibtex\n@article{howard1980formulae,\n  title={The formulae-as-types notion of construction},\n  author={Howard, William A},\n  journal={To HB Curry: Essays on Combinatory Logic, Lambda Calculus and Formalism},\n  year={1980}\n}\n```\n\n## Details of Mathematical Areas Covered by LeanDojo Benchmark\n\nWe updated the paper to link to pages ([1](https://leanprover-community.github.io/mathlib_stats.html), [2](https://eric-wieser.github.io/mathlib-import-graph/)) containing statistics, visualizations, and examples of mathematics covered by mathlib3. They will remain relatively stable, as the development of mathlib3 has been [frozen since June 22, 2023](https://leanprover.zulipchat.com/#narrow/stream/113486-announce/topic/Freeze.20of.20mathlib.203), and we have updated the paper to use a more recent version ([32a7e535287f9c73f2e4d2aef306a39190f0b504](https://github.com/leanprover-community/mathlib/tree/32a7e535287f9c73f2e4d2aef306a39190f0b504) released on August 5, 2023)\n\n\n\n\n## How Many Theorems Are Defined Using the `def` Keyword? \n\nIt is **zero** in mathlib (for both Lean 3 and Lean 4). Mathlib has a linter for detecting such unidiomatic uses (see [1](https://github.com/leanprover-community/mathlib/blob/32a7e535287f9c73f2e4d2aef306a39190f0b504/src/tactic/lint/misc.lean#L246) and [2](https://github.com/leanprover/std4/blob/dbffa8cb31b0c51b151453c4ff8f00ede2a84ed8/Std/Tactic/Lint/Misc.lean#L107)). The linter is a part of mathlib’s CI pipeline that runs automatically for each commit. Therefore, in any commit passing all CI checks, there shouldn’t be any theorem defined using the `def` keyword.\n\n\n\n\n## How to Convert Proofs into Tactic-Style Proofs?\n\nWe have updated the paper with a new footnote: “Another common type of proofs is ‘term-style proofs’. Any term-style proof `X` can always be converted into an equivalent tactic-style proof `exact X`, though such conversion may lead to unidiomatic proofs.”\n\n\n## Why is Clipala's Book on Coq Cited in Sec. 3?\n\nWe intended to cite a book on functional programming with dependent types. We agree that other options might be more relevant to Lean, and we have updated the paper with David Thrane Christiansen’s book [Functional Programming in Lean](https://leanprover.github.io/functional_programming_in_lean/).\n\n\n## Link Everything in the Paper Instead of Relying on the Website\n\nThank you for the great suggestion! We have updated the appendix with a new section (A) containing links to assets introduced by our work. It includes:\n\n* LeanDojo's codebase for data extraction and interaction with Lean: https://github.com/lean-dojo/LeanDojo\n* LeanDojo's documentation: https://leandojo.readthedocs.io\n* Datasets: (1) [LeanDojo Benchmark](https://zenodo.org/record/8242196) with DOI `10.5281/zenodo.8242196`. (2) [LeanDojo Benchmark 4](https://zenodo.org/record/8242200) with DOI `10.5281/zenodo.8242200`.\n* ReProver's code and models: https://github.com/lean-dojo/ReProver\n* ChatGPT plugin: https://github.com/lean-dojo/LeanDojoChatGPT\n* LeanDojo Website: https://leandojo.org/""}}, {'title': {'value': 'Response to Reviewer CZ3x (1/2)'}, 'comment': {'value': ""Dear reviewer,\n\nThank you for the detailed review! We truly appreciate your in-depth comments and constructive feedback. Below we address your questions and concerns. Please feel free to follow up if you have further questions!\n\n\n## Detailed Comparison between LeanDojo and LeanStep/lean-gym\n\nThe updated appendix contains a new subsection (B.3) and a new table (A) dedicated to this comparison. We also outline it here:\n\n### Functionality\n\nLeanDojo supports both data extraction and interacting with Lean programmatically. In contrast, LeanStep is only for data extraction, and lean-gym is only for interacting with Lean. They are not actively maintained, so they do not support recent versions of mathlib (tested on August 11, 2023, using mathlib commit [32a7e535287f9c73f2e4d2aef306a39190f0b504](https://github.com/leanprover-community/mathlib/tree/32a7e535287f9c73f2e4d2aef306a39190f0b504)). Also, neither of them supports Lean 4. Our LeanDojo fully supports recent mathlib and Lean 4. Furthermore, LeanStep cannot extract premise information and is not applicable to repos other than mathlib. Last, LeanDojo comes with comprehensive documentation and unit tests, whereas other tools barely have any.\n\n\n### Implementation details\n\nLeanStep and LeanDojo use different mechanisms to extract ASTs and proof trees. LeanStep implements an [ad-hoc parser](https://github.com/jasonrute/lean_proof_recording/blob/master/lean_proof_recording/parser.py) in Python for parsing Lean code into ASTs. It also [intercepts Lean's tactic system to insert logging code](https://github.com/jasonrute/lean_proof_recording/blob/master/lean_modifications/tactic_modifications.lean). Then the logs are used to reconstruct proof trees. This implementation is brittle and does not work for the current versions of Lean/mathlib. In contrast, LeanDojo relies on Lean’s built-in mechanisms for exporting ASTs and proof states (`lean --ast --tsast --tspp`), which works robustly for recent Lean/mathlib. This mechanism was developed after LeanStep.\n\nRegarding interaction with Lean, both lean-gym and LeanDojo rely on Lean's metaprogramming APIs, and LeanDojo partially builds upon lean-gym's code. However, lean-gym has a critical issue that it misjudges many correct proofs as incorrect (Appendix B.2). The main reason is that lean-gym fails to distinguish two subtly different cases when constructing the proof environment: (1) opening a namespace; (2) being inside a namespace. LeanDojo does not suffer from this issue. Instead of operating as a standalone program in the IO monad, it wraps the interaction code into [a special tactic](https://github.com/lean-dojo/LeanDojo/blob/32c14d5839e26be80ebff34190dcecd812eeb30f/src/lean_dojo/interaction/lean3_repl.lean#L564), which is inserted into the correct location in the proof. Therefore, the interaction code is guaranteed to run in the same environment as the original human-written proof.\n\n\n## The Patch for Extracting Premises in Lean 3\n\nThe patch is publicly available [in the LeanDojo repo](https://github.com/lean-dojo/LeanDojo/blob/main/src/lean_dojo/data_extraction/0001-Modify-Lean-for-proof-recording.patch). However, it is an implementation detail hidden from users and does not need to be installed. As in [Getting Started](https://leandojo.readthedocs.io/en/latest/getting-started.html), the user simply specifies a Lean repo (e.g., https://github.com/zhangir-azerbayev/ProofNet, `876bf5f9a424e92fc74d7e72c0bee0eb77bdc0b1`). Under the hood, LeanDojo automatically identifies the required Lean version and applies the patch. This works out of the box without the user being aware of the patch. We have updated the paper to clarify. Sorry for any confusion.\n\nIn addition, the patch is only required for Lean 3. For Lean 4, the elaborator can be accessed through metaprogramming in Lean itself, which does not require modifying Lean’s C++ code. The core of our Lean 4 implementation is [here](https://github.com/lean-dojo/LeanDojo/blob/main/src/lean_dojo/data_extraction/ExtractData.lean). \n\n\n## Lean 4 Support\n\nWe have upgraded LeanDojo to fully support Lean 4 (no longer in the alpha stage), including extracting premise information. Please see our common response at the top of this page.""}}, {'title': {'value': 'Thank you to all reviewers and meta-reviewers!'}, 'comment': {'value': 'Dear reviewers and meta-reviewers,\n\nWe appreciate your time and effort in engaging with our work and providing constructive feedback! We have received five very positive and thoughtful reviews. We are particularly excited that reviewers have found LeanDojo an essential progress towards automated theorem proving and potentially a standard environment for many important future works to build upon.\n\nWe respond to each reviewer to address their questions and comments. The paper and supplementary PDFs have been updated with suggested revisions. We welcome any follow-up discussions!\n\n\n## Update on Lean 4 Support\n\n  \n\nAt the time of submission, Lean 3 was the stable version, and Lean 4 was experimental. Accordingly, LeanDojo fully supported Lean 3 but was experimental for Lean 4, without the capability of extracting premise information for Lean 4. However, after the submission, the Lean/mathlib community has made substantial progress in migrating mathlib from Lean 3 to Lean 4. Now, Lean 4 has become the stable version. The mathlib for Lean 3 has been frozen since June 22, and all future developments will happen in Lean 4.\n\n  \nDuring this time, we also finished upgrading LeanDojo to fully support Lean 4, including extracting premise information. Therefore, we have re-generated the two datasets in this paper:\n\n-   LeanDojo Benchmark: 98,641 theorems/proofs, 217,639 tactics, and 130,151 premises extracted from mathlib (commit [32a7e535287f9c73f2e4d2aef306a39190f0b504](https://github.com/leanprover-community/mathlib/tree/32a7e535287f9c73f2e4d2aef306a39190f0b504) released on Aug. 5)\n-   LeanDojo Benchmark 4: 100,780 theorems/proofs, 209,133 tactics, and 101,500 premises extracted from mathlib4 (commit [355541ae7a2455222f179dcf7f074aa2c45eb8aa](https://github.com/leanprover-community/mathlib4/tree/355541ae7a2455222f179dcf7f074aa2c45eb8aa) released on Aug. 10).\n\nWe have re-run experiments on the new datasets and updated Table 1, 2, B, and C. All conclusions drawn from these tables remain the same.'}}, {'title': {'value': 'Very good paper, but some issues need to be fixed/clarified'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'A new, open-source environment for extracting proof trees out of Lean3 / mathlib3 is presented. This environment is called LeanDojo, and it is tailored to facilitate training data for a machine-learning approach. This is performed in the following way:\n\n- it extracts the entire proof tree (root is the theorem to be proved and the leaf the state after all proof obligations have been discharged)\n- it locates the premises that were used in the proof\n\nThe LeanDojo Benchmark is constructed in this sense, consisting of a diverse area of mathematics and a Retrieval-Augmented Theorem Prover, called ReProver, is trained. Their theorem prover performs well on the premise selection task, as well as on the theorem proving task. In particular, it outperforms GPT-4 in terms of tactic generation.\n\nWhile the theorem prover is a nice addition, the main contribution is the LeanDojo environment and the improvements it brings over existing environment. This is essential progress towards opening up automatic theorem proving in formal mathematics, as issues with the previous two environments, LeanStep, and lean-gym (both of which are discussed in the paper), are fixed. I expect that important work will be built upon LeanDojo. The thoughtful execution, documentation, and user-friendly presentation of LeanDojo will (hopefully) serve as a standard for environments related to the other well-known theorem provers (Mizar, Coq etc.).'}, 'strengths': {'value': '**Overall Strength:** \nAs mentioned in the *Summary and Contributions* section, this paper fills an essential gap in the literature by making research in the domain of formal theorem proving *accessible*. As the authors also state in their paper, there are several other papers that deal with automatic theorem proving but suffer from not open-sourcing the dataset/environment, model, or both. Unfortunately, it seems that for some papers, after they have been accepted, the code is not provided. This shows the importance of being up front with data, which the LeanDojo paper achieves.\n(To illustrate the point above, consider the paper [1] (which the authors cite). Even though in that paper, the authors state in the Checklist (section 7) that ""the code for the Equations environment will be open-sourced. We also plan to make our trained model publicly available to help people in the formal community"", it seems this has not been followed through. I was not able to find the mentioned code/models, there seems to be no GitHub repository -at least not one that can be easily found- by any of the three main authors of that paper; and the code listed on the Openreview site of that paper [2] seems to point to existing Github repositories of Lean etc. rather then this code. I\n[1] G. Lample et al., HyperTree Proof Search for Neural Theorem Proving, https://arxiv.org/pdf/2205.11491.pdf\n[2] https://openreview.net/forum?id=J4pX8Q8cxHH )\n\n\n**Other noteworthy points:** \n\n- the paper consistently uses best practices (reproducibility - e.g., specifying exact commits on which the version of mathlib3 they base their paper on; training - hyperparameters, training setup, etc. are all carefully specified; comprehensive section on *Related Work*)\n\n- the paper bases its environment on Lean 3, but also considers Lean4 (in the supplementary materials) and hints that Lean4Dojo will be made available for Lean4 as well. This is very important since progress on Lean4 and mathlib4 is developing rapidly, and it is expected that Lean4 will become the standard in the near future.\n\n- issues in lean-gym are noticed, their root cause is identified (appendix A.2), and these are fixed by LeanDojo.'}, 'opportunities_for_improvement': {'value': '**Important issues**\n\n1) A more comprehensive comparison of LeanDojo to LeanStep and lean-gym would have been very helpful. The authors obviously spend quite some time familiarizing themselves with these systems (e.g., they found errors in how lean-gym works). Since these build on Lean, which is already complex by itself, it would be a great service to the readers to include a description comparing these systems, that goes in detail. In is clearly explained how LeanDojo collects the prooftree - but how does lean-gym do it? For example, LeanDojo works on mathlib3, while lean-gym works on Lean directly (the paper on lean-gym [lean-gym] says: ""To solve these issues we implemented lean-gym1 – a simple REPL interface over the standard input/output implemented in Lean directly"").\nSuch explanation regarding similarities and differences in implementation, inner workings etc. (ideally summarized in a table) are important if one wants to build on these environments since it illustrates how easy/difficult it is to get them to work, how strongly they are coupled to a specific version of Lean etc.\n\n[lean-gym] S. Polu et al., Formal Mathematics Statement Curriculum Learning, https://arxiv.org/pdf/2202.01344.pdf\n\n2) Clearly indicate the patch which was used to resolve the full names of the premises from Lean3 (and provide installation instructions).\n\n**Less important issues**\n\n1) A slightly computer science-y view of mathematics: \n lines 35-38: ""Formal proofs are essentially computer programs. But unlike conventional programs in C++ or Python, the correctness of proofs can be verified easily using proof assistants. Therefore, theorem proving is a special form\nof code generation, with rigorous evaluation and no room for the model to hallucinate.""\nWhen *verifying* proofs one may think of theorem proving as a special form of code generation. But when it comes to *discovering*, no professional mathematician would say his work is ""code generation"", since proving a theorem involves intuition, visualization etc. I would perhaps slightly rewrite it to clarify this. \nGenerally, it seems that a mathematical perspective could improve this well-written paper even more.\n\n2) I was missing an analysis of which mathematical areas the theorem from the LeanDojo Benchmark belong to (on line 220 is just mentioned ""analysis, algebra, and geometry"" which is a somewhat vague description; at least a somewhat more finegrained-description would have been very helpful here; or perhaps some illuminating examples of theorems, so that the reader can assess their difficulty, mathematical domain etc.). So far the paper is interesting more for computer scientists, than for mathematicians.\n\n3) Issues mentioned in other sections:\n see my questions from the ""Limitations"" section, as well as the ""Clarity"" section.'}, 'limitations': {'value': '**Questions/Suggestions:**\n- The authors clearly indicated which mathlib3 commit / ProofNet commit uses to extract the data and that LeanDojo cannot extract those (somewhat rare) theorems that are defined using the keyword “def” (see line 169 from the appendix).\nIt would have been very helpful though, if the authors had given a precise number of how many such theorems actually are in that commit so that we don\'t have to rely on a somewhat vague adjective of ""rare"". Would it be possible to do that?\n\n- LeanDojo doesn\'t support Lean proofs that are not based on tactics; although the authors state (line 254) that ""tactic-style proofs [...] are sufﬁciently general since any proof can be converted to a tactic-style proof"", which vindicates their approach.\nNonetheless, to ease the burden on the reader regarding the details of the Lean system, would it be possible to add a small paragraph or a reference that explains why (and how) a proof not based on tactics can be converted to one?\n\n**Observations:**\n- LeanDojo for Lean4 is only in alpha stage. But I am confident the authors will work towards the goal of advancing that codebase as well.\n- data contamination when using GPT-4 for tactic generation (line 340) is acknowledged\n- appendix C.3 contains a detailed and convincing account of why a comparison with LLMs is not meaningful\n- For Lean 4, LeanDojo Benchmark 4 is generated, but ReProver is not trained because a dataset split cannot be performed since premise extraction is not yet implemented.\n \n(Lastly, I have some doubts about whether a premise selection approach will ever be able to be scaled to the point where mathematical statements --formalized in Lean-- that are currently unproven statements on the frontier of mathematical research will generate a proof; but this is not a criticism of this paper, but rather of the general research direction.)'}, 'correctness': {'value': 'All verified claims in the paper seem correct. The dataset and benchmark are sounds.'}, 'clarity': {'value': 'The paper is clearly written overall, but it\'s organization is complex since it consists of multiple parts (arXiv + GitHub + Zenodo + readthedocs). I have identified some specific issues below.\n\n**Questions/Suggestions:**\n\n- I am wondering why Clipala\'s work on Coq is cited in section 3; wouldn\'t citing the paper that introduces Lean would have been more relevant here? (Of course, Clipala\'s paper is important too; I\'m simply confused why *only* Clipala was cited here.)\n\n- I found myself frequently going back between Figures 1 and 2 while reading the paper. Perhaps these can be grouped together?\n\n- lines 40-42 from the supplementary material: ""Our modification is released as a Git patch that can be applied to any version of Lean 3 after March 24, 2022."" \nI wasn\'t able to find this patch under https://github.com/lean-dojo, nor any detailed instructions on how to apply it. Could you perhaps elaborate on this?\nIt would also be helpful to detail describe how comprehensive the changes that needed to be made to Lean3 were - and also whether you plan to carry out analogous changes for Lean4.\n\n- In Appendix B, the LeanDojo Benchmark is described, which is an essential piece of the paper. It might be helpful to link to the dataset directly in the body of the text (e.g., in a footnote).\nIn a sequence of unlucky choices, I first was expecting to see a ""LeanDojo Benchmark""  in the GitHub repository since I was initially looking in the GitHub repository for files you listed in the supplementary material, Appendix B.1 ""LeanDojo Benchmark"", as being part of the benchmark (`corpus.jsonl` etc.); not finding such a repository there, but discovering that there are Jupyter notebook files that generate the dataset I assumed that this dataset had to be generated. Only afterwards, I saw on the website that there are links to Zenodo mentioned in the supplementary material, but on Appendix B.3 and on the website as well.\nWhile not every reader will proceed in such an unlucky way, also consider that a paper on arXiv will have a much longer half-life than a website that is dependent on a commercial provider (and continual author payment for the domain). It, therefore, might be helpful to not rely solely on the website to find quickly the source of the dataset and also link to Zenodo either it in the main body of the paper or add a reference in Appendix B.1, that in Appendix B.3 the dataset will be found. \n\n- The above observation ties in with the fact that the organization of the LeanDojo project is rather complex since it consists of readthedocs + Github + Zenodo + arXiv. Since the main entry point is the website, as stated in supplementary section B3., I feel this is somewhat ""fragile"", since the existence of a website is not guaranteed to last; I would (also) make the main entry point the paper, in order to be future-proof for sure. \nAt the very least, I would add a small remark in the main body of the paper pointing to B.3, and clarifying that it is explained there how the project consists of different parts and how they are all tied together. Perhaps also include a quick summary in the paper of what further information can be found in readthedocs.This does not need to take anything away from the website, but it would be a layer of redundancy in case the website, as the current main entry point, goes down.\n\n- I feel a lot of information is contained in the readthedocs.  It could be emphasized a bit more in the paper: Only in section B.3 and on the website it is mentioned that there are further documents. It would be a shame of all this information is somewhat hidden from the reader.\n\n**Observations:**\nThe paper is well written, I didn\'t observe typos, and the explanations were mostly clear and detailed.'}, 'relation_to_prior_work': {'value': 'The paper comprehensively discusses previous work and how it relates to previous Lean environments. One thing that I would have found helpful would have been a more detailed comparison of LeanDojo to LeanStep and lean-gym; I have mentioned this in the *Opportunities For Improvement* section.'}, 'documentation': {'value': ""The LeanDojo environment is well documented, and the specific commits of, e.g., the mathlib3 dataset, ProofNet dataset are mentioned from which the current dataset can be extracted. They also mention their modification of Lean 3, and Jupyter notebook files are provided to generate the dataset. \n\nI haven't reproduced their dataset, but going over the code, which is well written and organized, I am confident I should be able to reproduce their dataset and benchmark with a reasonable amount of effort IF the patch they use to change Lean that resolves the premises' full names is provided / better documented.\n\nAs mentioned in the *Clarity* section, the organization of the various bits and pieces that make up LeanDojo is somewhat complex (readthedoc + Github + Zenodo + arxiv + website). \n\nAll other best practices surrounding dataset availability are present (license, hosting on Zenodo, etc.).""}, 'ethics': {'value': 'Not applicable.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'I have considered the arXiv paper in addition to the pdf submitted here since I noticed that some errors in the version uploaded here are fixed in the version on arXiv: E.g., in Figure 1, as well as line 69, here is written incorrectly ""mode_self,"" while the arXiv paper correctly refers to ""mod_self"".\nI have not mentioned these issues in my review since I assume the authors will use (a perhaps updated version of) the current arXiv for the camera-ready version, which already includes the mentioned fixes.\n\nI have given a score of **8 / clear accept**, *contingent* fixing the important issues I outlined in the *Opportunities For Improvement* section (in particular, 1) a detailed comparison between LeanStep and lean-gym needs to be made and 2) the git patch for Lean needs to be provided (or if it is provided already in the GitHub; though I haven\'t seen it, clearer instructions how I can find and apply the patch need to be given), so that the reader more clearly sees in what way LeanDojo is better than the competition and can easily reproduce the results. \n\nOtherwise, I might have to **downgrade** after the reviewer-author discussion (but I hope that will not be the case). \n\nBut depending on how well and comprehensively these issues are addressed (there are some issues besides the ones I tagged in the *Opportunities For Improvement* section as important), I would also be happy to raise my score to a **9 / strong accept**, since this paper is already a lot of potential.'}}, {'title': {'value': 'Useful Open-Source Benchmark'}, 'rating': {'value': '8: Top 50% of accepted papers, clear accept'}, 'confidence': {'value': '2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper'}, 'summary_and_contributions': {'value': 'The paper presents a new dataset & benchmark: LeanDojo for theorem proving using Lean. From a dataset perspective, LeanDojo provides 97K theorems along with premise & tactic annotations that can be useful to train models. As a benchmark, it enables development and consistent evaluation of future methods by releasing the data and code publicly. They also present a retrieval-augment prover (Reprover) that retrieves relevant premises and then use these premises to generate the tactics at each step. Experimental results show that this approach can outperform heuristics and zero-shot GPT4 model, but the task of generalizing to novel premises still remains challenging.'}, 'strengths': {'value': '- A new dataset for building stronger theorem provers\n- A benchmark for fair and reproducible comparison of theorem provers\n- An efficient retrieval-based approach that outperforms prior work.'}, 'opportunities_for_improvement': {'value': '- The paper is not accessible for readers that are not aware of the theorem proving literature. The authors make an attempt to explain terminology such as ""premise"" and ""tactic"" but the example in Fig. 2 is not sufficient. \n\n- While I understand that the presented approach can\'t be directly compared to prior work, a baseline that incorporates at least one idea from prior work would be useful. Currently their learned system is compared to a non-ML system and a zero-shot model. Could none of the key intuitions from prior work be incorporated into a baseline?\n\n- In similar vein, zero-shot seems like a weak baseline too. Could few-shot examples be provided to GPT3 or GPT4? Could the tactic generator fine-tuned model be replaced by few-shot GPT3 model (further reducing the training compute requirement albeit at the cost of inference compute)?'}, 'limitations': {'value': 'The paper does have an extensive limitation section in the Appendix.'}, 'correctness': {'value': 'Given my limited understanding of the field, everything looks okay to me.'}, 'clarity': {'value': 'As I mentioned before, the paper is not accessible for readers that are not aware of the theorem proving literature. The authors make an attempt to explain terminology such as ""premise"" and ""tactic"" but the example in Fig. 2 is not sufficient.'}, 'relation_to_prior_work': {'value': 'As I mentioned before, the paper is not accessible for readers that are not aware of the theorem proving literature. The authors make an attempt to explain terminology such as ""premise"" and ""tactic"" but the example in Fig. 2 is not sufficient.'}, 'documentation': {'value': 'Yes'}, 'ethics': {'value': 'No'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': '- Are the generated proofs for new tasks, by design, always correct? If not, did you verify what % of the new proofs are correct? If yes, can we use this system in a self-training loop to continuously improve the prover?\n\n\n- Could none of the key intuitions from prior work be incorporated into a baseline?'}}, {'title': {'value': 'Awesome open-source dataset and toolkit for formal theorem proving'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'This paper presents a suite of resources for the task of theorem proving in Lean using language models. This includes a dataset of Lean theorems and proofs, the associated tools for interacting with the Lean environment, and a strong model trained on this dataset. All resources are made publicly available to facilitate research in theorem proving.'}, 'strengths': {'value': '* This work contributes very valuable open resources to the theorem proving community. It is also very relevant to the broader AI community, since theorem proving is one of the most difficult open problems in AI.\n* This work also has potential to make open-source contributions to the Lean interactive theorem prover. It is shown in the paper that the proposed model automatically found new proofs for dozens of theorems in the library that are still missing proofs.\n'}, 'opportunities_for_improvement': {'value': 'The paper looks very solid overall. I made a few comments under the “Correctness” section.'}, 'limitations': {'value': 'Limitations have been comprehensively discussed in the supplementary material. There seems to be no direct societal impact with this work.'}, 'correctness': {'value': 'The construction of dataset and benchmark evaluation look correct. There are a few issues that I hope authors can clarify:\n1. It is mentioned in Section 4 that there are two ways to split the dataset, namely “random” and “novel_premises”. However, I wasn’t able to find the discussion on which split is used to train the ReProver models. In Table 1&2, the authors report performance on the test set of both splits. Since each of the two splits seem to be a full partition of the entire dataset (Appendix B Line 73), if the model is trained on one split’s training set and evaluated on the other split’s test set, there might be data leakage issue. Hopefully the authors can clear this potential suspicion.\n1. Line 291 says that in premise selection, the pool of candidate premises is first limited to those accessible from the current theorem, largely by following file import commands. I wonder if this may risk inflating the performance of premise selection, because when proving a new theorem, knowing which files contain useful premises might not be a safe assumption to make.\n'}, 'clarity': {'value': 'The paper is very well-structured and clearly written.'}, 'relation_to_prior_work': {'value': 'Related work is well-discussed. Minor comments:\n1. The following claim may not be very accurate: “we are the first to augment a learning-based prover with retrieved premises so that the prover can learn how to use them effectively” (Line 132). For example, NaturalProver (Welleck et al., 2022) features a retrieval-augmented theorem prover that works with informal mathematical language.'}, 'documentation': {'value': 'The dataset is documented in supplementary materials Section B. Dataset is hosted on Zenodo, code is hosted on GitHub, and models are hosted on HuggingFace.'}, 'ethics': {'value': 'There seems to be no ethical concern.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'None'}}, {'title': {'value': 'Very interesting paper and good enough'}, 'rating': {'value': '8: Top 50% of accepted papers, clear accept'}, 'confidence': {'value': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'summary_and_contributions': {'value': 'The authors of this research paper introduce LeanDojo, which is an open-source Lean playground consisting of toolkits, data, models, and benchmarks. Then they develop ReProver (Retrieval-Augmented Prover), the first LLM-based prover that is augmented with retrieval for select ing premises from a vast math library. Finally, the authors construct a new benchmark consisting of theorems and proofs extracted from Lean’s math library. The experimental results demonstrate the effectiveness of ReProver over baselines and GPT-4.\n\nThe main contributions of this work are as follows:\n (1) tools for extracting data from and interacting with Lean.\n (2) the first retrieval-augmented language model (ReProver) for theorem proving.\n (3) benchmark for learning-based theorem proving and use it to validate the effectiveness of ReProver\n (4) open research on LLMs for theorem proving by releasing our data, model, and code. '}, 'strengths': {'value': ""(1) the authors introduced LeanDojo, an open-source tool for theorem proving that fills the gap in existing resources. In addition, they proposed a retrieval-augmented prover named ReProver, addressing the critical issue of premise selection in theorem proving.\n(2) they have significantly reduced computational requirements, making it possible to train the model within five days on a single GPU. This increases the model's practicality and accessibility.\n(3) the paper is committed to the open-source ethos by providing the data, model, and code to the research community. This contribution will significantly facilitate further research in this field.\n\n\n\n\n""}, 'opportunities_for_improvement': {'value': 'As the authors mentioned in the supplementary material, I am also very curious about what would happen if the underlying language model is replaced with more powerful LLMs. Actually,  the author of this article has made significant contributions to the research in Theorem Proving. If possible, I am eagerly looking forward to this work playing a larger role in the field of mathematics in future research.'}, 'limitations': {'value': 'The content of this article is very comprehensive and substantial. It is a very interesting and excellent article.'}, 'correctness': {'value': 'NO'}, 'clarity': {'value': 'Well written'}, 'relation_to_prior_work': {'value': 'Yes'}, 'documentation': {'value': 'Yes.'}, 'ethics': {'value': 'NO.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'NO.'}}, {'title': {'value': 'Review of the paper ""LeanDojo: Theorem Proving with Retrieval-Augmented Language Models""'}, 'rating': {'value': '7: Good paper, accept'}, 'confidence': {'value': '3: The reviewer is fairly confident that the evaluation is correct'}, 'summary_and_contributions': {'value': 'The paper describes a tool for extracting machine-learnable data from Lean, an extracted data set that was used in the experiments (extracted from Lean 3), and a model (ReProver) for automatic theorem proving - LeanDojo for short.\n\nThe data extraction tool is written in Lean and wrapped with Python.\nThe dataset comes with a predefined train/validation/test split, and is a directed-acyclic graph with mathlib files as nodes, and directed edges that resemble imports. Every file is represented as an abstract syntax tree (AST).\n\nReProver is claimed to be efficient and is based on a transformer that encodes pairs (state, premise) into vectors. It is trained to minimize `(l_ij - cos(state, premise))^2`, where `l_ij` is either 1 (positive example) or 0 (negative example).\n\n'}, 'strengths': {'value': 'Lean is one of the most significant theorem provers and its size is very appropriate for machine learning. Given that the community is very actively ""translating"" mathlib to Lean 4, the work here might be of interest to many members of the community.\n\nThe paper is well structured and does not go into too many details regarding Lean, so it is accessible to the machine learning community. All the components of LeanDojo are well described, and the paper is easy to follow.\n\nThe experimental setup is mostly well-designed and the results are encouraging.'}, 'opportunities_for_improvement': {'value': 'Even though the data-extraction tools is supposed to extract ASTs of the files as well, I was not able to find them in the dataset webpage(s). In the, for example, test.json file, only the source code is present, which might be hard to ""parse"" by a machine learning methods.\n\nThe in-file negative examples seem to help. However, this is based on human observation of large quantities of data and I wonder whether training a model in two (or more) iterations would be better: \n- first randomly choose training examples (as the authors did originally)\n- using internal cross-validation on the training set, create predictions: a lot of ""false positives"" should appear and they can be used instead of ""in-file"" negatives in the next iteration of learning.\n\nI do not fully agree with the claim that the training of ReProver is efficient. In comparison to other models maybe, but in absolute numbers, 120 hours of GPU time is quite a bit and not accessible to everybody.\n'}, 'limitations': {'value': 'There is probably no potential negative societal impact of their work.\n\nThe limitations of the method has been briefly mentioned, but not explained (in contrast to the limitaions of the competing methods).\nFor example, the authors explain why lean-gym fails to type-check 21% of the proofs, but do not explain why Lean Dojo failes to proof-check 1.4% of them.'}, 'correctness': {'value': ""The claims made in the submission are correct, except for the one mentioned above: I don't agree that 120 hours of GPU training is a low number.\n\nThe experimental design is sound.""}, 'clarity': {'value': 'Yes.'}, 'relation_to_prior_work': {'value': 'Yes.'}, 'documentation': {'value': 'Yes.'}, 'ethics': {'value': 'No.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': '1. It seems that almost all the materials (excluding both pdfs (the paper itself and the supplementary materials)) were put online after the deadline - this includes the webpage - which was ""under construction"" even in the bidding period (https://leandojo.org/), the dataset (e.g., https://zenodo.org/record/8040110) and the relevant github repositories (https://github.com/lean-dojo). Were they accessible anywhere before the deadline? (The current Rating of the paper assumes they were.)\n\n2. Line 205: The paper says ""In addition, LeanDojo produces the AST of each file."" Inspecting the dataset, I was not able to find any ASTs. The dataset (e.g., leandojo_benchmark_4/random/test.json) contains files, imports and source code instead of the ASTs - as shown in the supplementary materials. Are ASTs available as well?\n\n'}}, {'title': {'value': 'LeanDojo: Theorem Proving with Retrieval-Augmented Language Models'}, 'authors': {'value': ['Kaiyu Yang', 'Aidan M Swope', 'Alex Gu', 'Rahul Chalamala', 'Peiyang Song', 'Shixing Yu', 'Saad Godil', 'Ryan Prenger', 'Anima Anandkumar']}, 'authorids': {'value': ['~Kaiyu_Yang1', '~Aidan_M_Swope1', '~Alex_Gu1', '~Rahul_Chalamala1', '~Peiyang_Song1', '~Shixing_Yu1', '~Saad_Godil1', '~Ryan_Prenger1', '~Anima_Anandkumar1']}, 'keywords': {'value': ['Automated Reasoning', 'Theorem Proving', 'Retrieval-Augmented Language Models']}, 'abstract': {'value': ""Large language models (LLMs) have shown promise in proving formal theorems using proof assistants such as Lean. However, existing methods are difficult to reproduce or build on, due to private code, data, and large compute requirements. This has created substantial barriers to research on machine learning methods for theorem proving. This paper removes these barriers by introducing LeanDojo: an open-source Lean playground consisting of toolkits, data, models, and benchmarks. LeanDojo extracts data from Lean and enables interaction with the proof environment programmatically. It contains fine-grained annotations of premises in proofs, providing valuable data for premise selection—a key bottleneck in theorem proving. Using this data, we develop ReProver (Retrieval-Augmented Prover): an LLM-based prover augmented with retrieval for selecting premises from a vast math library. It is inexpensive and needs only one GPU week of training. Our retriever leverages LeanDojo's program analysis capability to identify accessible premises and hard negative examples, which makes retrieval much more effective. Furthermore, we construct a new benchmark consisting of 98,734 theorems and proofs extracted from Lean's math library. It features challenging data split requiring the prover to generalize to theorems relying on novel premises that are never used in training. We use this benchmark for training and evaluation, and experimental results demonstrate the effectiveness of ReProver over non-retrieval baselines and GPT-4. We thus provide the first set of open-source LLM-based theorem provers without any proprietary datasets and release it under a permissive MIT license to facilitate further research.""}, 'venue': {'value': 'NeurIPS 2023 Datasets and Benchmarks Oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Track/Datasets_and_Benchmarks'}, 'TLDR': {'value': 'We introduce open toolkit, benchmarks, and retrieval-augmented language models for theorem proving in Lean.'}, 'pdf': {'value': '/pdf/3fb8576a222b73aa6bbc2ad986d609349ed942db.pdf'}, '_bibtex': {'value': '@inproceedings{\nyang2023leandojo,\ntitle={LeanDojo: Theorem Proving with Retrieval-Augmented Language Models},\nauthor={Kaiyu Yang and Aidan M Swope and Alex Gu and Rahul Chalamala and Peiyang Song and Shixing Yu and Saad Godil and Ryan Prenger and Anima Anandkumar},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\nyear={2023},\nurl={https://openreview.net/forum?id=g7OX2sOJtn}\n}'}, 'paperhash': {'value': 'yang|leandojo_theorem_proving_with_retrievalaugmented_language_models'}}]"
"['Dan Fu', 'Simran Arora', 'Jessica Grogan', 'Isys Johnson', 'Evan Sabri Eyuboglu', 'Armin Thomas', 'Benjamin Spector', 'Michael Poli', 'Atri Rudra', 'Christopher Ré']",NeurIPS,Monarch Mixer_ A Simple Sub-Quadratic GEMM-Based Architecture,https://neurips.cc/virtual/2023/oral/73841,2023," Machine learning models are increasingly being scaled in both sequence length and model dimension to reach longer contexts and better performance. However, existing architectures such as Transformers scale quadratically along both these axes. We ask: are there performant architectures that can scale sub-quadratically along sequence length and model dimension? We introduce Monarch Mixer (M2), a new architecture that uses the same sub-quadratic primitive along both sequence length and model dimension: Monarch matrices, a simple class of expressive structured matrices that captures many linear transforms, achieves high hardware efficiency on GPUs, and scales sub-quadratically. As a proof of concept, we explore the performance of M2 in three domains: non-causal BERT-style language modeling, ViT-style image classification, and causal GPT-style language modeling. For non-causal BERT-style modeling, M2 matches BERT-base and BERT-large in downstream GLUE quality with up to 27% fewer parameters, and achieves up to 9.1$\times$ higher throughput at sequence length 4K. On ImageNet, M2 outperforms ViT-b by 1% in accuracy, with only half the parameters. Causal GPT-style models introduce a technical challenge: enforcing causality via masking introduces a quadratic bottleneck. To alleviate this bottleneck, we develop a novel theoretical view of Monarch matrices based on multivariate polynomial evaluation and interpolation, which lets us parameterize M2 to be causal while remaining sub-quadratic. Using this parameterization, M2 matches GPT-style Transformers at 360M parameters in pretraining perplexity on The PILE—showing for the first time that it may be possible to match Transformer quality without attention or MLPs.",Oral 2A Efficient Learning,https://openreview.net/pdf?id=cB0BImqSS9,https://openreview.net/forum?id=cB0BImqSS9,cB0BImqSS9,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper proposed a new architecture called Monarch Mixer that is able to achieve sub-quadratic cost in many GEMM-based models including ViT, non-causal and causal language models. \n\nThe reviewers generally agree that this work has made nontrivial contribution to the field, and this paper made a timely contribution to the increased computation need for large models. \n\nWe also appreciate the additional experiments made by the authors, which we would also encourage the authors to include in their camera ready version.'}}, {'title': {'value': 'Thanks'}, 'comment': {'value': 'I would like to thank the authors for their rebuttal. I keep my rating.'}}, {'comment': {'value': 'Thank you, we have added it to our updated manuscript!'}}, {'title': {'value': 'Reply to Rebuttal'}, 'comment': {'value': 'Thank you for your clarifying comments. I suggest you incorporate them in your paper. '}}, {'rebuttal': {'value': 'Thank you for your positive feedback on the technical contributions of our paper. We are glad that you found the GPU performance discussion insightful, and we appreciate your constructive comments on how to improve the paper.\n\n**W1. More intuitive explanation of Monarch matrices.** Thank you for your suggestions on how to improve the clarity of the paper. We plan to use the extra space in the camera ready to include both a more complete description of Monarch matrices and the motivation behind their definition. We plan to motivate the Monarch matrices via the FFT algorithm, as follows:\n\nThe motivation behind the Monarch matrix is to adapt and generalize the FFT algorithm. The FFT algorithm splits an FFT of size N into smaller FFT’s over portions of the input, interleaved with permutations. More precisely, let $F_N$ denote the Fourier transform of size $N$, and assume N is a perfect square for simplicity. The FFT breaks down $F_N$ as follows:\n\n$F_N = P F_L P D P F_R P,$\n\nwhere $F_L$ and $F_R$ are block-diagonal matrices whose blocks are made of $F_\\sqrt{N}$, $D$ is a diagonal matrix, and $P$ is a permutation that reshapes a 1D input into $\\sqrt{N} \\times \\sqrt{N}$, and takes the transpose.\n\nA Monarch matrix generalizes this computation pattern by “rolling in” the diagonal matrix, and letting the blocks in the block-diagonal matrices be arbitrary instead of fixed to an FFT:\n\n$M = PLPRP$\n\nThis additional flexibility allows Monarch matrices to express a wider class of structured matrices than the FFT (but they are not as completely expressive as a dense matrix). In our paper, we also generalize Monarch matrices past the order 2 phase, so there can be more than two block-diagonal matrices interleaved with permutations (Figure 1, left in our original submission).\n\n**Q1. Expressivity of $M$ with the order $p$.** This is a little subtle - the expressivity actually goes _down_ with increasing $p$, since we decrease the sizes of the blocks (block size $b$ is $\\sqrt{N}$ for order 2, $\\sqrt[3]{N}$ for order 3: for general $p$ the block size is $b=\\sqrt[p]{N}$). This in turn implies that a $p$-variate Monarch has $O\\left(pN^{1+1/p}\\right)$ many parameters i.e. the number of parameters decreases as $p$ increases and hence its expressivity goes down (this follows e.g. from a counting argument).\n\n$p=1$ gives arbitrary dense matrix, but that is because in that case the block size is now $b=N$ and hence is a trivial case. For $p>1$, a single $p$-variate Monarch matrix cannot express an arbitrary matrix.\n\nHowever, one can show that one can express an arbitrary $N\\times N$ matrix as a product of $m=O(N)$  matrices $M_1,\\dots,M_m$ where each $M_j$ is a $p$-variate Monarch matrix (this follows from a known result that an arbitrary matrix can be represented a product of O(N) Toeplitz matrices).\n\nWe will add a discussion of these properties to the main body when we introduce $p$-order Monarch matrices.\n\n**Q2. Why does M2 outperform attention-based models?** There are two pieces – first, we build on prior work to build sub-quadratic replacements for attention. Second, we replace the MLPs with sub-quadratic alternatives, which achieves the same performance with the same height/width but fewer overall parameters.\n\nM2 builds on prior work studying how to replace attention with a sub-quadratic alternative while maintaining high quality. Many of these models use a combination of long and short convolutions with elementwise multiplication, e.g. [1, 2, 3, 4]. These convolutions are often computed with an FFT, which means that they can be expressed using Monarch matrices and elementwise multiplication. We build on the insights from these architectures when using Monarch for sequence mixing in our M2 models with an alternative that scales sub-quadratically in sequence length while maintaining high quality.\n\nIn addition, M2 uses Monarch matrices to scale sub-quadratically in the model dimension by replacing MLPs. Our results – that the dense layers in MLPs can be replaced by sparse(r) matrices without losing quality – may suggest that the current generation of models is overparameterized, and that there exist much more efficient architectures to develop. We are excited by these possibilities, and we look forward to building on these ideas in the future.\n\n[1] Long Range Language Modeling via Gated State Spaces. Harsh Mehta, Ankit Gupta, Ashok Cutkosky, Behnam Neyshabur. ICLR 2022.\n\n[2] Pretraining Without Attention. Junxiong Wang, Jing Nathan Yan, Albert Gu, Alexander M. Rush. ACL 2023.\n\n[3] Hungry Hungry Hippos: Towards Language Modeling with State Space Models. Daniel Y. Fu, Tri Dao, Khaled K. Saab, Armin W. Thomas, Atri Rudra, Christopher Ré. ICLR 2023.\n\n[4] Hyena Hierarchy: Towards Larger Convolutional Language Models. Michael Poli, Stefano Massaroli, Eric Nguyen, Daniel Y. Fu, Tri Dao, Stephen Baccus, Yoshua Bengio, Stefano Ermon, Christopher Ré. ICML 2023.\n'}}, {'rebuttal': {'value': 'Thank you for your positive feedback and questions. These questions have helped us improve the presentation of our paper. We provide a more detailed explanation of Monarch matrices below, which we plan to add to the paper.\n\n**Q1. Monarch Motivation.** The motivation behind the Monarch matrix is to adapt and generalize the FFT algorithm. The FFT algorithm splits an FFT of size N into smaller FFT’s over portions of the input, interleaved with permutations. More precisely, let $F_N$ denote the Fourier transform of size $N$, and assume N is a perfect square for simplicity. The FFT breaks down $F_N$ as follows:\n\n$F_N = P F_L P D P F_R P,$\n\nwhere $F_L$ and $F_R$ are block-diagonal matrices whose blocks are made of $F_\\sqrt{N}$, $D$ is a diagonal matrix, and $P$ is a permutation that reshapes a 1D input into $\\sqrt{N} \\times \\sqrt{N}$, and takes the transpose.\n\nA Monarch matrix generalizes this computation pattern by “rolling in” the diagonal matrix, and letting the blocks in the block-diagonal matrices be arbitrary instead of fixed to an FFT:\n\n$M = PLPRP$\n\nThis additional flexibility allows Monarch matrices to express a wider class of structured matrices than the FFT (but they are not as completely expressive as a dense matrix). In our paper, we also generalize Monarch matrices past the order 2 phase, so there can be more than two block-diagonal matrices interleaved with permutations (Figure 1, left in our original submission).\n\n**Q2. Scaling Results.** We have seen promising initial scaling results – in the common response, we have reported results for both M2-BERT-Base and M2-BERT-Large. In our original submission, we also saw similar scaling performance on causal language modeling with GPT2-s and GPT2-m equivalent models (Table 9 in the main paper). We look forward to continuing to scale these models and seeing how well the trends hold.\n\n**Q3. Monarch DFT.** A Monarch matrix can exactly express both a DFT and an inverse DFT (see Appendix F, corollary 6 in the original submission for the exact parameterization – they are similar to DFT matrices, but with slight modifications). For these experiments, we set the Monarch matrices to express the DFT and inverse DFT, respectively.\n\n**Q4. Learnable Monarch.** Thank you for the suggestion to extend the experiments for learnable Monarch matrices. Please see the common response for additional experiments along these lines. Making the Monarch matrices learnable yields small benefits in quality.\n\n**Q5. Causal Monarch Interpretation.** One way to interpret a Monarch matrix is to view it as evaluating a polynomial at a set of evaluation points $(a_i)$. When the Monarch matrix is used in a convolution, it is equivalent to multiplying two polynomials, by multiplying their evaluations $h(a_i) = f(a_i)g(a_i)$. The causal parameterization ensures that the resulting polynomial $h(a_i)$ is causal in $f$ – i.e., its coefficients do not depend on coefficients of $f$ that come later in the sequence.'}}, {'rebuttal': {'value': 'Thank you for your positive feedback and insightful suggestions. We hope that the additional experiments reported in the common response have improved the paper, and we look forward to further discussion. Here, we answer the specific weaknesses and questions raised in your review.\n\n**W1. Evaluation on speech applications.** Thank you for the suggestion to evaluate on speech applications. Please see the experiment on speech commands in the common response. We hope this result helps provide further evidence for the generality of our method.\n\n**W2. Comparison against parameter-matched BERT models**. Thank you for your suggestion to evaluate M2-BERT against parameter-matched BERT models. We have reported the results of these experiments in our common response. The 80M BERT model underperforms M2-BERT in quality on GLUE. A highly-optimized 80M BERT achieves higher throughput than M2-BERT on short sequences, but underperforms on inputs longer than 1K.\n\n**Q1. Architecture in synthetics.** For these synthetics, all models, including the Transformer, are small two-layer models with hidden dimension 64.\n\n**Q2 & Q6. BERT-s, ViT-s.** “BERT-s” and “ViT-s” in the submission are typos, we mean BERT-base and ViT-B (the -s terminology is the equivalent model for GPT2-s). These are now fixed in the draft.\n\n**Q3. Dense Matmul FLOP Util.** We report FLOP utilization of dense matmul here, and we have added it to our updated manuscript:\n\n|      |   **4K**  |  **16K**  | **65K**  |\n|-----:|:-----:|:-----:|:-----:|\n| **A100** | 63.0% | 78.0% | 80.0% |\n| **4090** | 74.6% | 96.7% | 97.9% |\n\n**Q4. GPU Inference.** We have reported the GPU inference results in the common response, and we will add them to Table 4 in the updated manuscript.\n\n**Q5. Swin Comparisons.** Thank you for the suggestion to compare to Swin-v2 and Swin-MLP. We have run these experiments and reported them in the common response (Table **4** in the accompanying PDF).'}}, {'rebuttal': {'value': '# Common Response\nWe thank all reviewers for their time and valuable comments, which have helped us improve our paper. In this paper, we introduce Monarch Mixer, a new architecture that is hardware-efficient and sub-quadratic in both sequence length and model dimension. We demonstrate that Monarch Mixer can be used as a drop-in replacement for attention and MLP in Transformers in BERT-style, GPT-style, and ViT-style modeling, matching quality with up to 27% parameter reduction and up to 9x faster inference for long sequences. We are excited to take a first step with this work in developing new architectures that are fundamentally more efficient than Transformers while maintaining quality.\n\nWe are glad to have received positive feedback on the motivation (reviewers **xUjR**, **zN2M**), clear technical contribution (reviewers **qwKK**, **zN2M**), execution and experiments (reviewers **xUjR**, **zN2M**), and overall clarity of presentation (reviewers **xUjR**, **qwKK**).\n\nIn our general response, we are excited to report the results of some additional experiments in pretraining quality, as well as experiments requested by the reviewers:\n* Stronger BERT results:\n  * M2 achieves GLUE performance that matches BERT-Base from (Devlin et al 2018), with 27% fewer parameters and up to 9X faster GPU inference time for long sequences (requested by reviewer **xUjR**)\n  * Scaling up to BERT-Large equivalent – M2-BERT-Large matches BERT-Large in quality with 24% fewer parameters and achieves up to 4X faster GPU inference time (demonstrating scaling performance, as requested by reviewer **qwKK**)\n  * Benchmarks against smaller BERT models (requested by reviewer **xUjR**)\n* Swin-M2: matching ImageNet accuracy with 32% fewer parameters when replacing attention and MLPs in Swin-V2 with Monarch Mixer, as a drop-in replacement (requested by reviewer **xUjR**)\n* Speech: M2 matches state-of-the-art in classification accuracy when classifying raw 16 kHz speech signals on the SpeechCommands task (requested by reviewer **xUjR**)\n* Experiments with learnable Monarch matrices in the sequence mixer for CIFAR, achieving 1.5 points in lift from learning the matrices (requested by reviewer **qwKK**)\n\nThe results tables for these experiments are in the accompanying PDF for the rebuttal. We plan to include these experiments in our updated manuscript and welcome further discussion on how to improve the paper during the discussion period.\n\n## BERT\nSince our initial submission, we have improved our BERT pretraining formula via improvements to pretraining hyperparameters and data. We are happy to report stronger downstream GLUE results, competitive with those from the official BERT-Base model trained by (Devlin et al 2018). We have also included an 80M BERT trained using our formula as a baseline, following the suggestion from reviewer **xUjR**.\n\nTable **1** in the accompanying PDF shows the results. M2-BERT-base is competitive with the Devlin et al BERT-base, with 27% fewer parameters. When scaled up to parameter-match BERT-base, M2-BERT outperforms BERT-base by 1.3 GLUE points on average.\n\nWe have also scaled up to a BERT-Large equivalent, which is competitive with the BERT-Large trained by (Devlin et al 2018). Table **2** in the accompanying PDF shows that M2-BERT-large is competitive with BERT-large with 24% fewer parameters. These results suggest that M2 can scale well.  We are excited to scale up to even larger models in future work (as suggested by reviewer **qwKK**).\n\n**BERT GPU Inference**\n\nNext, we report additional results on GPU inference times for different sequence lengths (addressing a question by reviewer **xUjR**). Inference times are reported as throughput, in tokens/ms on a single A100-40GB.\n\nTable **3** (top) in the accompanying PDF shows that M2-BERT-base achieves higher throughput than even highly-optimized BERT models, and achieves 9.0X higher throughput than a standard BERT-base model for long (4K) input sequences.\n\nTable **3** (bottom) in the accompanying PDF reports throughput against the 80M BERT as well. When parameter-matched, M2-BERT is slower than the most highly-optimized attention kernels for short sequences, but still faster for long sequences.\n\nBenchmarks for BERT-large and M2-BERT-large are omitted for space in the rebuttal, but the trends are similar (but the HF model OOM’s earlier, leading to a maximum speedup over HF of 4.34X at sequence length 2K).\n\n## Swin-M2 Experiments\nReviewer **xUjR** suggests comparing ImageNet performance against Swin-V2 and Swin-MLP. Table **4** in the accompanying PDF reports the results of replacing attention and the MLP in Swin-V2, using M2 as a drop-in replacement. Surprisingly, Swin-M2 outperforms Swin-MLP-B, is competitive with Swin-V1-B, and comes within 1 point of Swin-V2-B – even without any hyperparameter tuning or architecture adjustment from our ViT formula.\n\nWe expect that performance may improve further with hyperparameter tuning specific to M2. These results provide additional evidence that M2 is a strong drop-in replacement for attention and MLPs in various architectures.\n\n## Speech Applications\nReviewer **xUjR** suggests evaluating M2 on speech applications. Table **5** in the accompanying PDF presents the performance of M2 on Speech Commands-10, a speech classification task over raw 1-second clips sampled at 16 kHz. M2 is competitive with state-of-the-art architectures on this task.\n\n## Learnable Monarch Matrices in Sequence Mixer\nReviewer **qwKK** suggests extending the experiments to include the case where the Monarch matrices are learnable. In our submission, the monarch matrices in the state mixer (i.e. MLP) are already learnable. Table **6** in the accompanying PDF presents an experiment evaluating sequence mixers (i.e. attention) with learnable monarch matrices on sequential CIFAR. Learning the Monarch matrices in the sequence mixer yields 1.5 points of lift. We look forward to further exploring this regime in future work.'}, 'pdf': {'value': '/pdf/63de5342b169e4531d12f157393fc540e8873063.pdf'}}, {'summary': {'value': 'The Monarch Mixer (M2) combines MLP mixer and Conv mixer and yields a new family of mixers that is formalized in terms of Monarch matrices. the approach is novel and reminds me of an extension of [15] in their reference. \n\nThe main advantage of M2 is in its sub-quadratic computation capability. The authors evaluate their method on a set of large language models and prove their framework functions properly on meaningful and challenging tasks. The paper is well-written and easy to follow. '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper stands out in its clear and proper presentation. The idea is well motivated from a hardware perspective, explained intuitively, and studied theoretically. Evaluation of the method on causal and non-causal large language models is an asset and demonstrates a clear potential of the method.'}, 'weaknesses': {'value': '- The new approach is only benchmarked on Transformer tasks, while speech applications look relevant but are ignored.\n- It would be fair to see a comparison of inference latency and metric performance of the M2-based BERT with a configuration of BERT that has a smaller number of parameters, but the same number of FLOPs.'}, 'questions': {'value': '- Table 3 mentions a ""Transformer"" model. What is the configuration of the model?\n- Tables 4 to 7 mention BERT-s. What is BERT-s? What are the details of its architecture?\n- Table 2 seems to be incomplete. The FLOP utilization for dense matmul is missing from Table 2.\n- Caption of Table 4 mentions GPU, however the body of the Table contains no inference results on GPU. Did the authors perform inference on CPU only? Why GPU inference is not reported in Table 4?\n- A comparison with SwinMLP-B [1] and other SWIN-v2 models is more informative than the relatively older ViT model. \n- What is BERT-s? What is ViT-s? please provide the model details.\n\n[1]: Zheng, Hao, Guohui Wang, and Xuchen Li. ""Swin-MLP: a strawberry appearance quality identification method by Swin Transformer and multi-layer perceptron."" Journal of Food Measurement and Characterization 16.4 (2022): 2789-2800.'}, 'limitations': {'value': 'While the method clearly shows that the method works well on Transformer models, convolutional models, and speech applications are ignored. \n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper takes a fresh approach by addressing the issue of high complexity in current neural networks. It points out that the computational complexity of Transformers is quadratic with respect to both the sequence length and the feature dimension. Previous papers primarily focused on reducing the complexity related to sequence length, but this paper is the first to propose a method that reduces complexity for both sequence length and feature dimension. The specific approach used is the utilization of second-order Monarch Matrices, with the model structure referred to as the Monarch Mixer. Additionally, the authors introduce a novel initialization method for the Monarch Matrices, enabling them to handle causal l language modeling. The effectiveness of this approach is validated in the areas of non-causal language modeling, causal language modeling, and image classification.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'Indeed, it is novel to consider the optimization of complexity from both the sequence dimension and the feature dimension. Furthermore, initializing the model for the causal scenario poses a definite challenge, and the authors have successfully accomplished this task.'}, 'weaknesses': {'value': ""There aren't many weaknesses, for specific questions, please refer to the **Questions** section.""}, 'questions': {'value': '1. I\'m not very familiar with the Monarch Matrix, but is its core idea to use the product of block-diagonal matrices and permutation matrices as a replacement for the dense matrix?\n\n2. What is the motivation behind the Monarch Matrix? Despite having significantly fewer parameters, it seems to perform comparably to dense matrices in small-scale models. Can this conclusion be extended to models larger than 10 billion parameters?\n\n3. In Line 257, ""We set the Monarch matrices to DFT and inverse DFT matrices, to simulate long convolutions [15, 37], and do not learn them."" Does this refer to setting the block-diagonal matrices of the Monarch Matrix as DFT matrices?\n\n4. The experiments for Non-Causal Language Modeling and Image Classification should be more comprehensive, such as considering the Monarch matrices as learnable.\n\n5. Could you provide a more intuitive explanation of the initialization for the causal scenario? From examining the code, it seems like the Monarch Matrix is initialized as a lower triangular matrix?'}, 'limitations': {'value': 'Yes.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper introduces a new neural network layer which runs efficiently on modern GPUs, and exhibits strong performance against state-of-the art on several benchmarks. The layer is based on Monarch matrices, introduced in [7]. Monarch matrices use permutation matrices, and block diagonal matrices to represent dependancies across features and temporal dimensions. Inspired by butterfly matrices in FFT, this matrix parameterization can represent anything from convolutions to fully connected matrices, depending on their order. The Monarch Mixer layer introduced in this paper uses two monarch matrices as well as a matrix (K) that is used in point-wise multiplication. Performance is compared on language and image classification, replacing transformer and fully connected layers with the M2 layer. Finally, the paper presents a theoretical derivation of how this layer can be modified for use in causal language tasks, while maintaining its computational efficiency. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'Technically, this paper makes a strong contribution by proposing a computationally efficient layer. The computational performance is benchmarked on modern GPUs. I really liked the discussion on factors affecting runtime performance on modern GPUs -- this is a really valuable introduction to this topic. The proposed layer achieves superior performance, with fewer trainable parameters, in less time. Like MLPMixer, it also does away with the attention mechanism of transformers -- which suggests M2 is also a good architectural inductive bias -- perhaps competitive with attention? Comparing against [7], I would say the largest technical contribution of this paper is on how to modify the M2 layer perform in the causal setting.  '}, 'weaknesses': {'value': 'The main weakness of the paper is that it is somewhat hard to read/understand without having to read [7]. Section 4 in particular is quite dense. It seems that the authors struggled to fit the paper within the NeurIPS page limit. '}, 'questions': {'value': '-Does the expressivity of M increase with the order p? Perhaps this is obvious, but it should be stated explicitly in the paper. Can M be used to express any dense matrix? \n\n-Why do you think your model exceeds the performance of other state-of-the art models without using attention? I always thought one of the most important aspects of attention was that it afforded permutation invariance, does M2 serve a similar purpose? '}, 'limitations': {'value': 'Limitations were addressed in second paragraph of Section 6. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture'}, 'authors': {'value': ['Daniel Y Fu', 'Simran Arora', 'Jessica Grogan', 'Isys Johnson', 'Sabri Eyuboglu', 'Armin W Thomas', 'Benjamin Frederick Spector', 'Michael Poli', 'Atri Rudra', 'Christopher Re']}, 'authorids': {'value': ['~Daniel_Y_Fu1', '~Simran_Arora1', '~Jessica_Grogan1', '~Isys_Johnson1', '~Sabri_Eyuboglu1', '~Armin_W_Thomas1', '~Benjamin_Frederick_Spector1', '~Michael_Poli1', '~Atri_Rudra1', '~Christopher_Re1']}, 'keywords': {'value': ['structured matrices', 'transformers', 'efficiency']}, 'TLDR': {'value': 'We present Monarch Mixer, a new simple architecture that scales sub-quadratically in sequence length and model dimension.'}, 'abstract': {'value': 'Machine learning models are increasingly being scaled in both sequence length and model dimension to reach longer contexts and better performance. However, existing architectures such as Transformers scale quadratically along both these axes. We ask: are there performant architectures that can scale sub-quadratically along sequence length and model dimension? We introduce Monarch Mixer (M2), a new architecture that uses the same sub-quadratic primitive along both sequence length and model dimension: Monarch matrices, a simple class of expressive structured matrices that captures many linear transforms, achieves high hardware efficiency on GPUs, and scales sub-quadratically. As a proof of concept, we explore the performance of M2 in three domains: non-causal BERT-style language modeling, ViT-style image classification, and causal GPT-style language modeling. For non-causal BERT-style modeling, M2 matches BERT-base and BERT-large in downstream GLUE quality with up to 27% fewer parameters, and achieves up to 9.1$\\times$ higher throughput at sequence length 4K. On ImageNet, M2 outperforms ViT-b by 1% in accuracy, with only half the parameters. Causal GPT-style models introduce a technical challenge: enforcing causality via masking introduces a quadratic bottleneck. To alleviate this bottleneck, we develop a novel theoretical view of Monarch matrices based on multivariate polynomial evaluation and interpolation, which lets us parameterize M2 to be causal while remaining sub-quadratic. Using this parameterization, M2 matches GPT-style Transformers at 360M parameters in pretraining perplexity on The PILE—showing for the first time that it may be possible to match Transformer quality without attention or MLPs.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/a3bd2e3687826e8e82ec585d32dc63ca32ae9b46.pdf'}, '_bibtex': {'value': '@inproceedings{\nfu2023monarch,\ntitle={Monarch Mixer: A Simple Sub-Quadratic {GEMM}-Based Architecture},\nauthor={Daniel Y Fu and Simran Arora and Jessica Grogan and Isys Johnson and Sabri Eyuboglu and Armin W Thomas and Benjamin Frederick Spector and Michael Poli and Atri Rudra and Christopher Re},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=cB0BImqSS9}\n}'}, 'paperhash': {'value': 'fu|monarch_mixer_a_simple_subquadratic_gemmbased_architecture'}}]"
"['Sindy Löwe', 'Phillip Lippe', 'Francesco Locatello', 'Max Welling']",NeurIPS,Rotating Features for Object Discovery,https://neurips.cc/virtual/2023/oral/73835,2023," The binding problem in human cognition, concerning how the brain represents and connects objects within a fixed network of neural connections, remains a subject of intense debate. Most machine learning efforts addressing this issue in an unsupervised setting have focused on slot-based methods, which may be limiting due to their discrete nature and difficulty to express uncertainty. Recently, the Complex AutoEncoder was proposed as an alternative that learns continuous and distributed object-centric representations. However, it is only applicable to simple toy data. In this paper, we present Rotating Features, a generalization of complex-valued features to higher dimensions, and a new evaluation procedure for extracting objects from distributed representations. Additionally, we show the applicability of our approach to pre-trained features. Together, these advancements enable us to scale distributed object-centric representations from simple toy to real-world data. We believe this work advances a new paradigm for addressing the binding problem in machine learning and has the potential to inspire further innovation in the field.",Oral 2B Objects/ Neuroscience/Vision,https://openreview.net/pdf?id=fg7iyNK81W,https://openreview.net/forum?id=fg7iyNK81W,fg7iyNK81W,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The reviewers were unanimous that this paper should be accepted – with strong support from two of them. There was unanimous agreement that the work is significant and that the method presented is both novel and interesting as an alternative to the popular slot-based approaches. There was also agreement that all experiments are well conducted and the presented method compares favorably to the considered baselines. The AC agrees and recommends the paper to be accepted.'}}, {'comment': {'value': 'Thank you to the authors for so thoroughly engaging in the discussion process. All of my concerns have been addressed. I am raising my score to an 8.'}}, {'title': {'value': 'Comment on further experiments'}, 'comment': {'value': ""Thanks to the authors for performing this last-minute experiment. I think these results will enrich the paper, and it's good to see that the method performs so well when the number of objects is unknown.""}}, {'title': {'value': 'Comment on further experiments'}, 'comment': {'value': ""Thanks to the authors for performing this last-minute experiment. I think these results will enrich the paper, and it's good to see that the method performs so well when the number of objects is unknown.""}}, {'comment': {'value': 'Thank you for your response. Following your suggestion, we have conducted a comparable experiment to test the generalization performance of the Slot Attention model as proposed by [1]. For this, we follow the same training and testing procedure as before, i.e. we train the model on a variant of the 10Shapes dataset in which each image contains six objects, and subsequently test it on images containing between four and ten objects. \n\nThe results are summarized in this table:\n|  Number of Objects          | 4     | 5  | 6 | 7 | 8  |  9 | 10 |\n|--|--|--|--|--|--|--|--|\n| **Number of Objects known**  |  |  |  |  |  |   |  |\n| Slot Attention,  \\#slots = \\#objects+1                    | 0.968 | 0.965 | 0.957 | 0.944 | 0.926 | 0.897 | 0.856 |\n| Rotating Features with k-means, k=\\#objects+1             | 0.957 | 0.944 | 0.927 | 0.909 | 0.889 | 0.867 | 0.843 |\n| **Number of Objects unknown**  |  |  |  |  |  |   |  |\n| Slot Attention, \\#slots = 7               | 0.981 | 0.975 | 0.957 | 0.912 | 0.837 | 0.753 | 0.670  |\n| Rotating Features with k-means, k=7          | 0.893 | 0.921 | 0.927 | 0.889 | 0.836 | 0.777 | 0.719 |\n| Rotating Features with agglomerative clustering        | 0.936 | 0.919 | 0.901 | 0.879 | 0.856 | 0.829 | 0.798 |\n\nAs we can see, when the number of objects is known, Slot Attention slightly outperforms the Rotating Features model for all tested numbers of objects. When the number of objects is unknown, however, and we set the number of slots in Slot Attention to the number of objects observed during training (plus one for the background), we see its performance deteriorate as the number of objects per image increases. When testing on ten objects per image, Slot Attention\'s performance drops to an ARI-BG score of 0.670, while the Rotating Features model with agglomerative clustering achieves a score of 0.798.\n\n---\n[1] Locatello, Francesco, et al. ""Object-centric learning with slot attention."" NeurIPS, 2020.'}}, {'title': {'value': 'Rebuttal Response'}, 'comment': {'value': ""I thank the authors for their responses to my questions. I still believe the limitations of the paper should be more pronounced in the main text. In particular, the fact that the model relies on the depth masks and the differentiation of semantic vs instance segmentation. In the figures provided in the paper there is not a single case of a figure containing multiple instances of the same class such that the method separates them. This should be made more obvious in the text. I'm happy to stick to my current rating of the paper. \n""}}, {'title': {'value': 'Thank You'}, 'comment': {'value': 'Thank you for the rebuttal. The results on CLEVR seem much better relative to CAE and would be nice to include in the paper IMO. I also appreciate testing a gradually increasing number of objects.\n\nI change my rating to 7.'}}, {'title': {'value': 'Reply to rebuttal'}, 'comment': {'value': 'Thanks very much to the authors for these clarifications and additional experiments. The explanations and additional results for points 3-5 helped me to develop a better intuition for the method, and I think they will strengthen the paper. My only remaining question is about whether a comparison with slot attention can be performed for the new experiment (detailed in my reply to the general response).'}}, {'title': {'value': 'Comment on additional experiment'}, 'comment': {'value': 'Thanks to the authors for sharing these additional results. It is very good to see that the method can generalize well to a larger number of objects, even without knowing the number in advance. Is it possible to perform a comparable experiment with slot attention (or another slot-based architecture)? This would be very informative, as it would be good to know what the tradeoffs are for the two approaches with respect to flexibility and generalization.'}}, {'title': {'value': 'Thanks for responses, new experiment strengthens findings further'}, 'comment': {'value': 'I thank the authors for their responses to my questions.  The innovative nature of this work makes it exciting and challenging, and the new experiment demonstrating generalization to more objects further underscores the promise of the approach.  I certainly continue to believe this paper deserves the attention of the community.  While the results may not yet be ground-breaking, the approach and direction certainly are.'}}, {'rebuttal': {'value': ""Thank you for the thoughtful review. We are taking this opportunity to address the concerns and inquiries raised.\n\n### Strengths\n**2) The way weights and biases were applied seems to have been simplified (a welcome change). An ablation experiment highlighting this specific change for the case of n=2 could be useful.**\n\nFigure 4 in the paper shows that when the CAE model is compared to Rotating Features with $n=2$, they achieve equivalent object discovery performances. This suggests that the modified rotation mechanism does not impact the performance significantly.\n\n### Weaknesses\n\n**1/2) A comparison with and without DINO pre-training would be useful to show in the main paper. / Can original CAE be a baseline in the real-data experiment?**\n\nIn line with the reviewer's suggestion, we ran two additional baselines on the Pascal VOC dataset. We firstly applied the Rotating Features model directly to the raw input images, referred to as RF-DINO. Secondly, we applied a CAE model to the DINO preprocessed features, while incorporating our novel evaluation procedure (CAE* +DINO). \n\n|Model|MBO$_i$|MBO$_c$|\n|--|--|--|\n|RF-DINO|0.282$\\pm$0.006|0.320$\\pm$0.006|\n|CAE* +DINO|0.329$\\pm$0.009|0.374$\\pm$0.010|\n|RF+DINO |0.407$\\pm$0.001|0.460$\\pm$0.001|\n\nThe results reveal that our proposed approach of applying Rotating Features to DINO features (RF+DINO) significantly outperforms both baselines. This highlights the importance of our contributions: generalizing the complex-valued features to higher dimensions and using DINO features as the input to our model are both essential to achieving competitive object discovery performance on real-world images. We will include these baselines in the revised paper.\n\n**3) The paper makes the jump from 4 object scenes directly to 10 object scenes. It may be useful to test a more gradual increase.**\n\nIn response to the reviewer's suggestion, we conduct a new experiment to assess how the choice of $n$ impacts the object discovery performance of a Rotating Features model depending on the number of objects in a scene. We accomplish this by creating variations of the 10Shapes dataset that contain between two and ten objects. For each variant, the number of objects per image equals the total number of distinct objects throughout the respective dataset.\n\nAs illustrated in Figure 2 in the PDF uploaded alongside the general response, the object discovery performance significantly drops as the number of objects increase when $n=2$. However, the performance remains consistently high when $n=10$. These findings indicate that the choice of $n$ becomes increasingly critical as the number of objects rises. We will include this experiment in the revised paper.\n\n**4) It would be interesting to see the performance on a standard dataset.**\n\nIn response to the reviewer's suggestion, we evaluate the performance of the proposed Rotating Features model on the Multi-dSprites and CLEVR datasets, comparing it to its predecessor — the CAE model [2]. The outcomes are presented in the table below. Note that since the original CAE was only applicable to grayscale images, we combine it with our proposed evaluation procedure to make it applicable to multi-channel input images, which we denote as CAE*.\n\n|Dataset|Model|ARI-BG|\n|--|--|--|\n|Multi-dSprites|CAE*|0.371$\\pm$0.056|\n||Rotating Features|0.888$\\pm$0.015|\n|CLEVR|CAE*|0.289$\\pm$0.042|\n||Rotating Features|0.664$\\pm$0.013|\n\nThe results indicate that the Rotating Features model significantly surpasses the performance of the CAE*, demonstrating good object separation on these two datasets. However, the results still lack behind the state-of-the-art. The qualitative examples in Figure 3 of the PDF uploaded alongside the general response show that Rotating Features encounter the same issue here, as we have seen with the colored 4Shapes dataset: objects of the same color tend to be grouped together. As demonstrated with the RGB-D version of the colored 4Shapes dataset and our results using pretrained DINO features on real-world images, this issue can be addressed by using higher-level input features.\n\n**5) At test time, can it handle a larger number of objects than shown during training?**\n\nSee the general response above.\n\n### Questions\n\n**1) Is the layer choice important for segmentation? Do these patterns emerge also for the intermediate layers?**\n\nFor object segmentation using Rotating Features, the current architectural layout suggests the output layer's representation as the most logical choice, as it has the highest spatial resolution. \n\nNevertheless, it is interesting to note that object-centric features also emerge in the intermediate layers of the architecture. In Appendix D.3, we examine the object separation within the autoencoder's bottleneck. This experiment reveals that it is possible to distinguish the representations of two separate objects within this layer's representation.\n\n**2) What is the incentive for the model to assign different phases to different objects?**\n\nThe binding mechanism enables the model to process information relatively independently of one another. If features of one object have orientations pointing in a different direction than features of another object, their features can be processed with little interference. This mechanism encourages the model to assign different orientations to features that it aims to process separately, which naturally leads to object-centric representations.\n\n**3) I could not entirely follow the motivation of Appendix D.3.**\n\nThis experiment is related to question 1 above, and investigates whether object separation also emerges in intermediate layers. Since it is not practical to evaluate the object segmentation performance here, we develop an alternative way to investigate object-centricity. Our approach in this case is a weakly-supervised semantic segmentation setup, which tests the alignment between the intermediate object representations and their counterparts at the output layer.""}}, {'rebuttal': {'value': ""Thank you for your insightful review and constructive feedback. We welcome the opportunity to address the questions and concerns that have been brought up.\n\n**1 / 2) How would the model perform when tested on a greater number of objects than it was trained on? / Controlled experiments could be performed to demonstrate the superior representational capacity of rotating features over slot attention (especially when there are more objects than slots).**\n\nSee the general response above.\n\n**3) Have the authors considered sharing the orientation across features at each location in a convolutional feature map?**\n\nWe have experimented with this, but in preliminary results it generally performed worse. Intuitively, we believe it is helpful to have the possibility for each individual feature to have its own orientation (and therefore object binding), as this allows overlapping objects to be represented simultaneously within the same location. This becomes increasingly important as we reduce the feature map size in the architecture, and essential as we move through the fully-connected layers. \n\n**4) Have the authors investigated how the assignment of objects evolves across layers? I am wondering whether the competition that occurs over time in methods like slot attention is somehow distributed across layers in this model.**\n\nThis hypothesis could indeed be correct. In Appendix D.3, we have included an experiment that examines the object separation within the architecture's bottleneck (i.e., after the encoder). While we find a meaningful separation here, it does not seem to be prominent enough, yet, to be able to separate more than two objects at a time. Exploring whether this is indeed a result of some form of competition distributed across layers, and how to modify the network to achieve stronger object separation throughout the entire architecture, would be an intriguing direction for future research.\n\n**5) It would be informative to include an ablation of the binding mechanism. I also found the description of this mechanism somewhat counterintuitive.**\n\nFollowing the reviewer's suggestion, we performed an ablation of the binding mechanism. In this analysis, we modify the Rotating Features model by substituting $\\mathbf{m}_{\\text{bind}}$ with $\\left\\lVert{\\psi}\\right\\rVert_2$ in Equation 4. This effectively removes the binding mechanism ($\\chi$). Then, we apply the adjusted model to the grayscale 4Shapes dataset. While the original model achieves an ARI-BG score of $0.987 \\pm 0.003$ on this dataset, the ablated model fails to learn any object separation ($0.059 \\pm 0.017$). This result highlights the critical role the binding mechanism plays in enabling the Rotating Features to learn object-centric representations. We will include this experiment in the revised paper.\n\nThe model without binding mechanism fails to learn object-centric representations, as it cannot leverage the additional rotation dimensions. Without the binding mechanism, these dimensions inherently do not have a strong effect on the computations. The binding mechanism ensures that features with similar orientations are processed together, while features with dissimilar orientations are essentially masked out. This allows the network to create separate streams of information that it can process separately, which naturally leads to the emergence of object-centric representations.\n\nTo expand on this intuition, imagine the most extreme scenario where a feature is of the opposite orientation to a group of aligned features, as shown on the left-hand side of Figure 3 (cosine similarity = -1). Without the binding mechanism, the misaligned feature would effectively be subtracted from the aligned features, resulting in a smaller output magnitude (as shown for $\\left\\lVert{\\psi}\\right\\rVert_2$). The binding mechanism reduces this effect and results in a larger output magnitude (as shown for $\\mathbf{m}_{\\text{bind}}$). Effectively, the binding mechanism masks out the misaligned feature, as the output magnitude would be the same if the misaligned feature was replaced by a zero vector. We will amend our description in the paper to include this intuition.""}}, {'rebuttal': {'value': ""Thank you for your constructive review. We would like to take the opportunity to respond to the questions and concerns that you have posed.\n\n### Weaknesses\n\n**1) How novel is this evaluation procedure compared to the one used by CAE?**\n\nWhile our proposed evaluation method closely resembles the CAE's evaluation method mathematically - merely requiring the addition of a weighted sum with binary weights - its conceptual significance cannot be understated: it avoids the trivial solutions described in lines 157-160 of the paper that would otherwise make a fair assessment of our approach on multi-channel images impossible.\n\n**2) Depth masks provide a strong supervision signal**\n\nProviding depth information is one possible way to prevent the Rotating Features from grouping together objects of the same color. Alternatively, we show that using features from a pretrained vision transformer works equally well. This approach, utilized by prior work for object discovery [1], is arguably more applicable in practice.\n\n**3) The experiment on FoodSeg103 does not meaningfully test the instance-level grouping ability.**\n\nUnfortunately, the FoodSeg103 dataset, like most semantic segmentation datasets, does not provide instance-level ground truth segmentation masks. This makes it challenging to meaningfully examine the instance-level grouping ability. Nonetheless, we believe that the class-level grouping performance of the Rotating Features on this dataset is noteworthy. For one, the DINO features exhibit a specialization towards the semantic class of a single object per scene when conditioned on the CLS token. In contrast, our experiments assess the performance in extracting multiple objects per scene, without feeding the CLS token into our network. Additionally, the DINO features are only used to set the input magnitudes, with input orientations being set to a fixed value. We evaluate the grouping learned by the output orientations, making our assessment independent of any grouping that may be extractable directly from the DINO features.\n\n### Questions\n\n**1) Why do spherical coordinates lead to instabilities?**\n\nWe will replace the example given in the paper with the following one: When a vector's magnitude is zero, the angular coordinates can take any value without changing the underlying vector. As our network applies ReLU activations on the magnitudes, this singularity may occur regularly, hindering the network from training effectively.\n\n**2) “On the Pascal VOC dataset, we do not compare ARI-BG scores”. I didn’t understand the reasoning behind this choice.**\n\nIn Appendix D.2, we provide a more in-depth discussion on this. \n\n**3) Why can’t the proposed method segregate 2 objects of the same color but spatially well separated?**\n\nIn its current form, Rotating Features do not include any inductive bias to enforce a spatial separation between object representations. We believe that this would be an interesting future direction to explore, as it could provide an alternative to our proposed solution that utilizes higher-level input features to perform binding on complex, real-world inputs.\n\n**4) Could the authors show the grouping performance for the colorized ‘Shapes’ dataset without depth information?**\n\nThese results can be found in Figure 6, and Appendix Table 7 and Figure 14. They indicate that the network benefits strongly from the additional depth information.\n\n**5) How does the proposed method work on colored multi-object datasets typically used in the object-centric literature?**\n\nIn response to the reviewer's suggestion, we evaluate the performance of the proposed Rotating Features model on the Multi-dSprites and CLEVR datasets, comparing it to its predecessor — the CAE model [2]. The outcomes are presented in the table below. Note that since the original CAE was only applicable to grayscale images, we combine it with our proposed evaluation procedure to make it applicable to multi-channel input images, which we denote as CAE*.\n\n|Dataset|Model|ARI-BG|\n|--|--|--|\n|Multi-dSprites|CAE*|0.371$\\pm$0.056|\n||Rotating Features|0.888$\\pm$0.015|\n|CLEVR|CAE*|0.289$\\pm$0.042|\n||Rotating Features|0.664$\\pm$0.013|\n\nThe results indicate that the Rotating Features model significantly surpasses the performance of the CAE*, demonstrating good object separation on these two datasets. However, the results still lack behind the state-of-the-art. The qualitative examples in Figure 3 of the PDF uploaded alongside the general response show that Rotating Features encounter the same issue here, as we have seen with the colored 4Shapes dataset: objects of the same color tend to be grouped together. As demonstrated with the RGB-D version of the colored 4Shapes dataset and with our results using pretrained DINO features on real-world images, this issue can be addressed by using higher-level input features.\n\n**6) How much instance-level grouping is being learned on top of the semantic-level grouping that is already captured by the pretrained DINO features?**\n\nAs described above, Rotating Features do not directly make use of the semantic specialization of the DINO features that may be found when conditioning on the CLS token. Nonetheless, we will add another baseline from the DINOSAUR paper [1] that allows for a direct comparison between the grouping that may be inherent to the DINO features and the grouping achieved by the Rotating Features model. This baseline applies k-means directly to the DINO preprocessed features and achieves an MBO$_i$ score of 0.363 and MBO$_c = 0.405$. For comparison, Rotating Features achieve scores of MBO$_i = 0.407$ and MBO$_c = 0.460$. We therefore conclude that the Rotating Features improve over the instance-level and semantic-level grouping that may be inherently present within the pretrained DINO features.\n\n---\n[1] Maximilian Seitzer, et al. Bridging the gap to real-world object-centric learning. ICLR, 2023.\n\n[2] Sindy Löwe, et al. Complex-valued autoencoders for object discovery. TMLR, 2022.""}}, {'rebuttal': {'value': ""Thank you for the feedback from your thoughtful review. We would like to take this opportunity to address the two questions you posed:\n\n**I found it a bit difficult to be sure I was seeing fair comparisons in table 1. If I understand correctly, DINOSAUR MLP is much simpler than the Rotating Features CNN. Is it slot based in some way?**\n\nThe DINOSAUR MLP model is a slot-based model, which combines Slot Attention with a spatial broadcast decoder. In essence, it encodes the DINO preprocessed features into slots, and subsequently decodes each slot individually via an MLP decoder. The predicted slot mask from this decoder is then used to recombine the individual reconstructions, and to evaluate the object discovery performance of this model. We will clarify our description in the paper to make the comparison between the models more comprehensible.\n\n**I have found it difficult to understand how the binding mechanism described on p.4 works, and I did not feel I got much out of figure 3. perhaps the problem lies in my lack of understanding of the meaning of the superscripts on $z_{in}$. Another source of confusion is the statement that the extra input dimensions of $\\mathbf{x}$ (in line 134) are all set to 0, such that they don't seem to be capable of having any effect. Why are these dimensions then needed? I see that learned bias weights apply to the output of $f_{\\mathbf{w}}$ and that there are $\\mathbb{R}^{n \\times d_{\\text{out}}}$ of these.**\n\nThe rotating feature vector $z_{in} \\in \\mathbb{R}^{n \\times d_{\\text{in}}}$ has $n$ rotating dimensions and $d_{\\text{in}}$ feature dimensions, i.e., channels. Our data does not contain any rotating information, so we introduce the additional dimensions by padding the input with zeros. Your observation regarding the biases is correct - they serve as the model's mechanism that allows it to rotate the initial features, and thus to make use of the additional dimensions and to push them away from zero. Essentially, every feature dimension has the capacity to learn a distinct orientation offset through this bias.\n\nWithout the binding mechanism, the model would fail to learn to leverage these additional dimensions, as they inherently do not have a strong effect on the computations. The binding mechanism ensures that features with similar orientations are processed together, while features with dissimilar orientations are essentially masked out. This allows the network to create separate streams of information that it can process separately - which naturally leads to the emergence of object-centric representations.\n\nRegarding Figure 3, we agree that the superscripts on $z_{in}$ are ambiguous. We will amend the figure caption, improving notation and description, to the following:\n\nEffect of the binding mechanism. We start by randomly sampling two column vectors $\\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^n$ with $\\left\\lVert{\\mathbf{a}}\\right\\rVert_2 = \\left\\lVert{\\mathbf{b}}\\right\\rVert_2 = 1$. Assuming $d_{\\text{in}} = 3, d_{\\text{out}} = 1$ and $f_{\\mathbf{w}}$ is a linear layer, we set $z_{in} = \\left[ \\mathbf{a}, \\mathbf{a}, \\mathbf{b} \\right]$, weights $\\mathbf{w} = \\left[ \\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3} \\right]^T $and biases $b = \\left[0, ..., 0\\right]^T$. Then, we plot $m_{bind}$ and $\\left\\lVert{\\psi}\\right\\rVert_2$ on the y-axis. These denote the magnitudes of the layer's output before the application of the activation function, with (blue) and without (orange) the binding mechanism. Without the binding mechanism, misaligned features are effectively subtracted from the aligned features, resulting in smaller output magnitudes. The binding mechanism masks out features with dissimilar orientations, reducing this effect and leading to consistently larger magnitudes in $m_{bind}$. In the most extreme scenario, features with opposite orientations (i.e., with a cosine similarity of -1) are cancelled out by the binding mechanism, as the output magnitude ($\\frac{2}{3}$) would remain the same if $z_{in} = \\left[ \\mathbf{a}, \\mathbf{a}, \\mathbf{0} \\right]$.""}}, {'rebuttal': {'value': 'We thank the reviewers for their constructive feedback. We are delighted to see the reviewers recognize that the exploration of alternatives to slot-based schemes as studied in our paper is important (e8db, r4Rq) and interesting (cH5o), and that our work may stimulate many interesting directions for future work (cH5o). Further, the reviewers have noted that the experiments are well performed (r4Rq), showing that the proposed Rotating Features achieve promising results (e8db, cH5o, VTkG) while being very efficient to train (e8db, CH5o). Additionally, reviewer r4Rq stated that our paper is very well written.\n\nWe want to use this general response to highlight an additional experiment that we have conducted following suggestions of reviewers cH4o and VTkG. This experiment shows that Rotating Features can generalize beyond the number of objects observed during training, even when the number of objects in the test images is unknown.\n\n### Generalization to more objects\n\nWe conduct an experiment to assess the flexibility of Rotating Features in segmenting varying numbers of objects, thereby testing its ability to generalize beyond the number of objects observed during training. Additionally, this experiment evaluates the adaptability of the model when the number of objects in a scene is unknown.\n\nTo train the Rotating Features model, we make use of a modified version of the 10Shapes dataset. This version includes the same ten unique shapes as the original. However, only six of these shapes are randomly selected to appear in each image.\n\nPost-training, we test the trained model with a range of variants of this dataset, each displaying between four and ten objects per image. We present the results in Figure 1 in the PDF uploaded alongside this general response. First, we observe that when the number of objects is known and $k$ for $k$-means is set accordingly, the performance of the Rotating Features model is best when fewer objects are present in each image, and decreases as more objects are added. However, considering the increase in difficulty when incorporating more objects in a scene of a fixed size, the model maintains a relatively stable performance across various numbers of objects per scene. Second, when the number of objects in a scene is not known, and we apply $k$-means with a fixed value of $k=7$ (corresponding to the number of objects observed during training, plus one for the background), performance degrades considerably the more the true number of objects deviates from the fixed value of $k$. However, this problem can be circumvented by using agglomerative clustering, and by setting the distance threshold on the training dataset to reflect the best performance when there are six objects in a scene. Using the same threshold across all test settings maintains consistent performance for varying numbers of objects in each scene, albeit slightly inferior to the $k$-means baseline, with $k$ representing the true number of objects.\n\nIn summary, our results suggest that Rotating Features can generalize beyond the number of objects observed during training, even when the number of objects in the test images is not known. We will include this experiment in the revised paper.'}, 'pdf': {'value': '/pdf/c83f8e47d9cd2fe04d289046bad59c5cd08ab52d.pdf'}}, {'summary': {'value': ""The paper presents a new approach for extracting objects from distributed representations, based on a binding mechanism called 'rotating features' that extends previous phase-based binding notions to a much higher dimension binding space, and avoids the use of separate slots for individual objects, showing promising results and scaling behavior with both toy and natural-image data sets.""}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The exploration of alternatives to slot-based schemes, so prevalent in transformers and related contemporary architectures, for addressing how neural networks can successfully extract distinct, coherent representations of objects and other entities is an important contribution in itself.  For brain science, it is important because the brain is unlikely to have explicit slots of the kind that can be built into artificial networks.  For AI, this step may be equally important, as it allows for the possibility of more graded approaches to objecthood that could be important for capturing the kind of graded objecthood of many aspects of the natural world, and of avoiding some of the potential brittleness and arbitrariness of imposing slot-based approaches to structured objects made up of sub-objects.\n\nThe model seems to produce fairly impressive results compared to an alternative much more complex transformer models and beats other comparison models as well.  The excellent training time, and the possibility of avoiding explicit k-means clustering for segmentation, and the availability of uncertainly maps all seem like desirable properties of the model.'}, 'weaknesses': {'value': 'I have chosen to ask questions rather than express statements about weaknesses because I found that there were important features of the model and of the comparisons that I simply could not fully understand without going to source papers on DINOSAUR and the binding mechanism.  I do consider it a weakness of the paper that I was not able to understand these things better, and my rating and confidence would be increased further if these questions were addressed in the rebuttal and revision of the paper.'}, 'questions': {'value': ""I found it a bit difficult to be sure I was seeing fair comparisons in table 1.  If I understand correctly, DINOSAUR MLP is much simpler than the Rotating Features CNN.  Is it slot based in some way?  \n\nI have found it difficult to understand how the binding mechanism described on p 4 works and I did not feel I got much out of figure 3.  perhaps the problem lies in my lack of understanding of the meaning of the superscripts on z_in.  Another source of confusion is the statement that the extra input dimensions of x (in line 134) are all set to 0, such that they don't seem to be capable of having any effect.  Why are these dimensions then needed?  I see that learned bias weights apply to the output of f_w and that there are R^(n x d_out) of these.  The references to Lowe et al and Reichert & Serre should not be my only source of an understanding of how the mechanism works.""}, 'limitations': {'value': 'The limitations as stated seem valid, and I look forward to seeing where attempts to address these limitations will lead.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work addresses the problem of unsupervised object discovery. It seeks to remedy some limitations (primarily object storage capacity) of the recently introduced synchrony-based approach, CAE [1], and scales it to more visually complex scenes compared to CAE [1] which was only applied to simple grayscale (Shapes and MNIST) datasets. The key idea behind the proposed method is the extension of the number of feature dimensions used to manipulate “phase” (rotation) values associated with image features from ‘2’ in CAE to ‘n’ dimensions in RF. To control these ‘n’ dimensional rotation values use ‘n’ separate bias terms in every layer. Further, they apply their method on pre-trained DINO features to scale the grouping results to real-world datasets.\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': '1) The problem studied in this paper is well-motivated and important. \n\n2) The method presented is novel and as the model class it uses to perform binding (synchrony-based) has received significantly less attention in the literature compared to slot-based approaches.\n\n3) The paper is very well written.\n\n4) The experiments are well performed and the presented method compares favorably to the considered baselines.\n'}, 'weaknesses': {'value': '1) The authors note that one of their three contributions is a new evaluation method. The phases are weighted but with binary values (0 or 1) which reduces to a difference in the averaging constant (N vs N-k) in the denominator of the weighted averaging operation. The threshold used to compute the weights is just a fixed value (i.e. 0.1 same as in CAE [1]) as opposed to being some learned value based on the magnitudes. So, in practice, how different/novel is this evaluation procedure compared to the one used by CAE to the extent that it can be deemed as a core technical contribution of this work?\n \n2) Depth masks provide a strong supervision signal for discovery of object grouping information. The problem of 2 (or more) objects having the same color being grouped together has been resolved through the use of such depth masks i.e. strong supervision (Figure 6 caption). \n\n3) Lines (244-245): “On FoodSeg103, we limit our evaluation of our model to the MBO_c score, …. ”. MBO_c score only measures semantic grouping not instance-level grouping. The pretrained DINO features already show a high level of specialization to semantic classes (attention maps when conditioning on CLS token). Therefore, this experiment does not really meaningfully test the instance-level grouping ability of the proposed method. \n'}, 'questions': {'value': '1) Why do spherical coordinates lead to instabilities? Could not follow the explanation in footnote 1, specifically the point about ordering of the angles and under certain circumstances subsequent angles having no influence on the orientation. Could the authors clarify this point? A visualization would be greatly beneficial in this regard.\n\n2) Lines (242-243) : “On the Pascal VOC dataset, we do not compare ARI-BG scores, as we have found that a simple baseline significantly surpasses previously reported .….” . I didn’t understand the reasoning behind this choice.\n\n3) (related to weakness #2) Why can’t the proposed method segregate 2 objects of the same color but spatially well separated? If the network has learned a simple rule using just a single feature like color or shape to perform binding, that would be extremely limiting in the general case.\n\n4) (related to weakness #2) Could the authors show the grouping performance (FG-ARI, FULL-ARI) for the colorized ‘Shapes’ dataset without (simply using RGB images as inputs) the use of depth channel information? Have the authors performed an ablation to quantify how much the depth channel information assists the network to predict the object identities?  \n\n5) How does the proposed method work on colored multi-object datasets like Tetrominoes, Multi-dSprites or CLEVR that are the first benchmark suite typically used for evaluation in the object-centric literature?\n\n6) Table 1 (Pascal VOC dataset results), compared to the baseline models which use pre-trained DINO features in the encoder module (i.e. DINOSAUR Transformer/MLP) how much instance-level grouping has been achieved through the use of RF? It’s known that the DINO features already possess a high-level of specialization to semantic classes and therefore can perform semantic grouping (by inspecting the attention masks after conditioning on the CLS token). In this regard, SlotAttention and SLATE baselines cannot be considered like-for-like since they still use the pixel reconstruction objective and are trained from scratch. Short point being that how much instance-level grouping is being learned through the use of RF on top of the semantic-level grouping that is  already captured by the pretrained DINO features?'}, 'limitations': {'value': 'Authors discuss limitations of their method, in particular that the capacity to represent multiple objects is currently limited to the output space of the autoencoder and that the methods still lag behind slot-based methods such as DINOSAUR.\n\n\nReferences: \n\n[1] “Complex-Valued Autoencoders for Object Discovery”, Lowe et. al, TMLR 2022.\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work proposes a novel approach to unsupervised object discovery that does not depend on slots. Instead, the model uses an extra set of dimensions to code object assignment based on rotation, potentially allowing for a more flexible distributed form of object discovery than in standard slot-based approaches. The model is shown to perform well on toy tasks, with promising results on real-world images.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- This work presents an interesting new direction, substantially reconsidering the problem of object discovery relative to the now ubiquitous slot-based methods.\n- The method performs well on toy tasks, scaling to a relatively large number of objects, and also shows promising results on real-world images.\n- The method is significantly more efficient than popular slot-based methods.\n- The paper stimulates many interesting directions for future work.'}, 'weaknesses': {'value': ""I have a number of suggestions and questions that may help to further improve the paper:\n\n- A major potential advantage of the proposed approach is that it is more flexible than slot-based methods, specifically regarding the number of objects that can be segmented. The results in supplementary figure 10 suggest that, with a sufficient number of dimensions (e.g. ~10) a relatively large number of objects can be represented, and that even more objects can be represented without needing to add many more dimensions. Can this advantage over slot attention be empirically demonstrated? For instance, are there any instances in pascal VOC or FoodSeg that involve more objects than the number of slots in DINOSAUR? If so, it would be interesting to see whether rotating features outperforms DINOSAUR on those problems. Alternatively, controlled experiments with CLEVR, or even the Nshapes dataset, could be performed to demonstrate the superior representational capacity of rotating features over slot attention (especially when there are more objects than slots).\n- A desirable feature of slot attention is that it is permutation invariant, which allows for a dynamic binding of features to objects (i.e. by randomly initializing the slots and iteratively refining them through competition). Here, by contrast, particular features have learned biases toward particular orientations, does this interfere with the ability of the model to perform variable-binding in a dynamic manner? How would the model perform when tested on a greater number of objects than it was trained on (given that it has a sufficient number of dimensions to represent those objects)? In other words, is the method more efficient than slot attention because it is also less flexible?\n- Have the authors considered sharing the orientation across features at each location in a convolutional feature map? Intuitively, it seems that all features at a particular location should only be assigned to a single object, rather than having a unique assignment of each feature.\n- Have the authors investigated how the assignment of objects evolves across layers? I am wondering whether the competition that occurs over time in methods like slot attention is somehow distributed across layers in this model.\n- It would be informative to include an ablation of the binding mechanism. I also found the description of this mechanism somewhat counterintuitive. It is described as 'weakening the connections between features with dissimilar orientations', but it almost seems as if it does the exact opposite of this. The magnitude of the features in $\\chi$ is completely unrelated to the orientations of the inputs. Therefore, it seems that mixing $\\chi$ with $\\psi$ is only weakening the influence of orientation, allowing incoming features with dissimilar orientations (but high synaptic weight values) to exercise a greater influence on the magnitude of the feature representation. Can the authors add some additional explanation of this mechanism?""}, 'questions': {'value': 'I have listed some questions in the previous section.'}, 'limitations': {'value': 'There are no discernible negative societal impacts related to this work.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'CAEs promise to resolve some of the concerns of slot-based representation. They bring the promise of flexible object granularity, the promise of extracting part-whole hierarchies as per need, and faster training speeds. However, the original CAE was tested with grayscale images and on a rather small number of objects (2-3). This paper asks the question, *how can we scale CAEs* beyond this.\n\n**Approach.** Compared to classical neural networks, in the proposed model, all activations in the network are “tagged” with the binding information. For this, every scalar value of conventional vector representation is replaced with a $N$ length vector: the magnitude of this vector plays the role of classical activation while its orientation plays the role of capturing the binding information. Compared to original CAEs, the proposed model provides a generalization from having just 2 components (real and imaginary) to $N$ components, where $N$ can be arbitrarily large.\n\nIn **experiments**,\n1. The paper tests whether this change can help improve the capacity of CAEs in terms of the number of objects or not.\n2. The paper is also one of the first works to scale CAEs to real scenes.\n3. The paper also proposes a new procedure for extracting object segments from distributed representations.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. (One of the) First successful attempts to make a CAE-like model scale to more objects and beyond simplistic grayscale images.\n2. The way weights and biases were applied seems to have been simplified (a welcome change) compared to the original CAEs. An ablation experiment highlighting this specific change for the case of $N=2$ could be useful though.\n3. Seems applicable to any data modality— demonstrated to some extent via the applicability of the model on RGB-D data in addition to RGB data.'}, 'weaknesses': {'value': '1. One of the novelty seems to be the use of DINO pre-trained features for the first time in the context of CAEs. Therefore, a comparison with and without DINO pre-training would be useful to show in the main paper. \n2. Can original CAE be a baseline in the real-data experiment?\n3. The paper makes the jump from 4 object scenes directly to 10 object scenes. It may be useful to test perhaps a more gradual increase e.g., by also testing 7 object scenes and 13 object scenes, whether it places gradually more demand on the choice of $N$.\n4. It would be interesting to see the performance on a standard dataset like Tetris or CLEVR that was not deliberately designed for this paper. That being said, it need not outperform the previous slot-based methods here considering various other potential benefits of CAEs. \n5. At test time, can it handle a larger number of objects than shown during training?'}, 'questions': {'value': '1. Is the layer choice important for segmentation? Do these patterns emerge also for the intermediate layers?\n2. I am curious what is the incentive for the model to assign different “phases” to different objects? In slot-based models, this role was played by the inherent capacity bottleneck of slots. I am curious about some insights about this.\n3. I could not entirely follow the motivation of Appendix D.3 “Object separation within the bottleneck of autoencoder utilizing Rotating Features…”'}, 'limitations': {'value': 'Yes, the paper discusses the limitations, but one should also consider the potential benefits of the CAE framework.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Rotating Features for Object Discovery'}, 'authors': {'value': ['Sindy Löwe', 'Phillip Lippe', 'Francesco Locatello', 'Max Welling']}, 'authorids': {'value': ['~Sindy_Löwe1', '~Phillip_Lippe1', '~Francesco_Locatello1', '~Max_Welling1']}, 'keywords': {'value': ['Object Discovery', 'Object-Centric Representations', 'Structured Representation Learning']}, 'abstract': {'value': 'The binding problem in human cognition, concerning how the brain represents and connects objects within a fixed network of neural connections, remains a subject of intense debate. Most machine learning efforts addressing this issue in an unsupervised setting have focused on slot-based methods, which may be limiting due to their discrete nature and difficulty to express uncertainty. Recently, the Complex AutoEncoder was proposed as an alternative that learns continuous and distributed object-centric representations. However, it is only applicable to simple toy data. In this paper, we present Rotating Features, a generalization of complex-valued features to higher dimensions, and a new evaluation procedure for extracting objects from distributed representations. Additionally, we show the applicability of our approach to pre-trained features. Together, these advancements enable us to scale distributed object-centric representations from simple toy to real-world data. We believe this work advances a new paradigm for addressing the binding problem in machine learning and has the potential to inspire further innovation in the field.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'This paper introduces several advancements for continuous and distributed object-centric representations, scaling them from simple toy to real-world data, and thereby paving the way for a new paradigm in objects discovery.'}, 'pdf': {'value': '/pdf/1b8d41a127649b96bbe45664739a0d2037646098.pdf'}, 'supplementary_material': {'value': '/attachment/80427da35b9dfcbc0591d39b21ba7261881553cc.zip'}, '_bibtex': {'value': '@inproceedings{\nl{\\""o}we2023rotating,\ntitle={Rotating Features for Object Discovery},\nauthor={Sindy L{\\""o}we and Phillip Lippe and Francesco Locatello and Max Welling},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=fg7iyNK81W}\n}'}, 'paperhash': {'value': 'löwe|rotating_features_for_object_discovery'}}]"
"['Simon Buchholz', 'Goutham Rajendran', 'Elan Rosenfeld', 'Bryon Aragam', 'Bernhard Schölkopf', 'Pradeep Ravikumar']",NeurIPS,Learning Linear Causal Representations from Interventions under General Nonlinear Mixing,https://neurips.cc/virtual/2023/oral/73823,2023," We study the problem of learning causal representations from unknown, latent interventions in a general setting, where the latent distribution is Gaussian but the mixing function is completely general. We prove strong identifiability results given unknown single-node interventions, i.e., without having access to the intervention targets. This generalizes prior works which have focused on weaker classes, such as linear maps or paired counterfactual data. This is also the first instance of identifiability from non-paired interventions for deep neural network embeddings and general causal structures. Our proof relies on carefully uncovering the high-dimensional geometric structure present in the data distribution after a non-linear density transformation, which we capture by analyzing quadratic forms of precision matrices of the latent distributions. Finally, we propose a contrastive algorithm to identify the latent variables in practice and evaluate its performance on various tasks.",Oral 2C Causality,https://openreview.net/pdf?id=q131tA7HCT,https://openreview.net/forum?id=q131tA7HCT,q131tA7HCT,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper represents a significant contribution to the rapidly blossoming theory for identification of latent causal models. In particular, this result handles the setting of Gaussian latents and arbitrary mixing functions, while most prior works required specific parametric forms (e.g. linear or polynomial). As such, I (and, it seems, the reviewers) believe it has the potential for significant impact in the space.'}}, {'title': {'value': '...'}, 'comment': {'value': 'Thank you for the additional experiments! Like reviewer 2jDD above, I will keep my score of 8, and am willing to advocate for the paper during reviewer-AC discussions.'}}, {'title': {'value': 'Reply to rebuttle'}, 'comment': {'value': 'Thanks for the clarifications. I had some negative impressions on the paper when I first read it, since the identifiability of the latent dimension was the first thing I was looking for in the theoretical results. But it was not mentioned at all. \n\nOverall, this is a solid work on an important problem. I am satisfied with the provided evidence. Therefore, I would raise my score.  \n\n\n\n'}}, {'title': {'value': 'Thanks a lot for the response'}, 'comment': {'value': 'Thanks for the thoughtful comment. That is an extremely good point! So I was mistaken in thinking that i-VAE and Varici can be combined in a simple way to solve a subclass of the problems. If the above example that you point is right, then that is indeed not true. \n\nI am happy to raise my score to 7.'}}, {'title': {'value': 'Reponse to further thoughts'}, 'comment': {'value': ""We thank the reviewer for their clarifying response.\nWe apologize that we slightly misinterpreted  the criticism in your review.\n\n**tl;dr:** We are happy to include additional discussion on these points, which are quite subtle and likely require additional investigation to make work. Please see below for details.\n\n**Identifiability of the setting in the review:**\n\nFirstly, let's focus on the setting considered in the review and clarify why we say that it essentially only covers ICA and not general CRL.\nFor the class of interventions that you consider, the causal structure encoded by $A$ cannot be identified\nand every causal graph is consistent with the observed distributions.  This can be seen as follows. As pointed out in the review, given the observational\nand interventional distributions $x^{(k)}$ we can find a function $g$ such that $x^{(k)}=g(\\varepsilon^{(k)})$\nand $g$ is unique up to permutations and scale, so we can identify $\\varepsilon^{(k)}$.\nHowever, we cannot identify $A$ (which is our goal). \nIndeed, given an arbitrary invertible matrix $\\tilde{A}$ satisfying DAG constraints, we may define a new latent structure by $\\tilde{z}^{(k)}=\\tilde{A}\\varepsilon^{(k)}$.\nThen $x^{(k)}=g(\\varepsilon^{(k)}) =  g\\circ \\tilde{A}^{-1}(\\tilde{z}^{(k)})$, and since $\\tilde{A}$ was arbitrary, we get that the observations are compatible with any causal graph.\n\nThis is consistent with Varici et al. [1] because in case of a linear SCM and interventions that only change the noise distribution (so the setting in the review), it seems that Assumption 3 in [1] is not satisfied for nodes with parents, i.e, the assumptions of their identifiability result are only satisfied for the empty graph. We will give more technical details at the end.\n\nBecause of the counterexample above, it seems that to apply the techniques of [1] to the model considered in the review, we need to\n\n1. either work in the special ICA setting\n\n2. or make additional assumptions (as the reviewer seems to suggest).\n\nFinally, we note that our Theorem 3 applies to the setting in the review and implies identifiability of $\\varepsilon^{(k)}$ up to linear maps. Therefore, we feel it's not fully complementary to this setting. \nGoing further, we expect our linear identifiability result (Theorem 3) can be combined with any result\nfor linear Gaussian SCMs and linear mixings such as [1]  to obtain, e.g., mixing consistency.\n\n==========\n\nIn conclusion, while the ICA case can be obtained from prior works, it is not clear to us how exactly identifiability results for nonlinear mixings beyond the case of independent latents can be obtained by combining known results. \nWe kindly ask the reviewer to clarify whether we misunderstood or overlooked something or what additional data or assumptions are necessary.\nWe think obtaining generalizations of Varici et al. [1] for non-linear mixing (using iVAE or otherwise), is a very interesting and nontrivial problem for future work, which [1] themselves pose as an open problem (in their conclusion section).\n\n\nAs suggested by the reviewer, we will expand the prior work section with more details, and also revise the sentence claiming that this is the first CRL identifiability result for general nonlinear mixing because this is indeed a bit vague as there is no generally agreed upon definition of CRL.\nThanks again for engaging in the discussion, and we are happy to clarify any further concerns.\n\n**Assumption 3 in [1] and pure noise interventions**\n\nBased on our understanding, for linear SCMs and interventions that only change the noise distribution (for the setting in the review),\n Assumption 3 is only satisfied for interventions on nodes without parents, as outlined below.\n\nDenote the score (i.e., $\\nabla \\log (p)$)\nof the observational distribution $p_z$ by $s$ and the score for intervention $i$ with target $i$ by $s^i$.\nThen their Assumption 3 says that if $c\\cdot (s - s^i)=0$ ($p_Z$ a.e.) for some vector $c$ then $c_j=0$ for $j\\in \\overline{pa}(i)=pa(i)\\cup \\{i\\}$.\n\nWe will assume that $i$  has a parent and show that the assumption is not satisfied.\nAssume that the structural equation for node $i$ is $Z_i = \\alpha Z_{pa(i)} +N_i$ without intervention and under intervention $i$ the noise $N_i$ is replaced by $M_i$. Denote the log densities of $N_i$ and $M_i$\nby $n$ and $m$.\nUsing Equations (6), (7) of [1], we get\n\n$s(z)-s^i(z)=\\nabla (\\ln(p(z_i|z_{pa(i)})) - \\ln(p^{(i)}(z_i|z_{pa(i)})))\n=\\nabla (n(z_i - \\alpha z_{pa(i)}) - m(z_i - \\alpha z_{pa(i)})).\n$\n\nLet $k\\in pa(i)$ and denote its coefficient in the structural equation by $\\alpha_k\\neq 0$. Then the vector $c$ with $c_i=\\alpha_k$, $c_k = 1$ and $c_j=0$ for $j\\notin \\{i,k\\}$  satisfies\n\n$\nc \\cdot(s(z)-s^i(z)) = \\alpha_k (n'(z_i - \\alpha z_{pa(i)}) - m'(z_i - \\alpha z_{pa(i)}))\n-\\alpha_k n'(z_i - \\alpha z_{pa(i)}) +\\alpha_k m'(z_i - \\alpha z_{pa(i)})=0.\n$\n\nThus Assumption 3 is not satisfied.\n\n[1] Varici et al., Score-based Causal Representation Learning with Interventions, 2023""}}, {'comment': {'value': ""I am pleased with the author's response to my review and have no remaining questions. I appreciate their consideration of the varsortability / $R^2$-sortability issue, and I agree that these problems are harder to conceptualize in the CRL setting.\n\nI will keep my score of 8, and am willing to advocate for the paper during reviewer-AC discussions.""}}, {'title': {'value': 'Further thoughts'}, 'comment': {'value': 'Thank you for the response. I have some follow up points.\n\nFirstly, I am not saying that your results from the above arguments I presented. However, I believe that the above case that I provided is both a very important one, complementary to your results, and follows from earlier work. I think you should reinterpret your contributions in the light of this example. For instance, you say in the abstract ""This is also the first instance of causal identifiability from non-paired interventions for deep neural network embeddings."" and have made several such statements elsewhere. The example I provided does not use paired interventions and also works for deep neural net embeddings.\n\nEach imperfect intervention can either occur by changing weights or noise distribution. The example I constructed shows that for latter class of imperfect interventions (that alter noise) you can use existing results to get stronger identification that you arrive. I don\'t think this result follows from your results either. Hence, the two results are complementary. Your results consider a larger class of imperfect interventions but arrives at weaker guarantees. The absence of any such discussion in the paper is not fair to earlier contributions that already exist. \n\nIn your current response you seem to say ""we agree that it is a valuable addition to our paper to clarify that the ICA case is substantially simpler and has been solved in earlier work."" This is not exactly what I meant. I would appreciate if you can have a discussion of what I proposed  in the main body (with details in Appendix) of how i-VAE + recent linear mixing works such as Varici et al. solve important sub-cases. '}}, {'rebuttal': {'value': ""We thank all reviewers for their reviews pointing out that the paper 'presents a significant theoretical contribution' (R. 2jDD) that studies 'an important problem in interventional causal representation learning' (R. LWnm), proposes a 'novel and sound algorithm' (R. RqDB), and is 'very clearly written' (R. uV6m). Reviewers 2jDD and uV6m were quite positive about the paper, Reviewers RqDB and LWnm generally acknowledged the contributions of the paper but had questions regarding an alternative proof strategy and identifiability of the latent dimension.\nThose are addressed in the individual responses.\n\nFollowing the optional (and intriguing) suggestions of Reviewers uV6M and 2jDD, we ran additional experiments where we investigated\nthe effects of different noise distributions (to probe misspecification) and data standardization (to probe varsortability) on the algorithm's performance.\nIn addition, we considered more challenging settings for the balls dataset (scaling up from 3 balls to 10 balls). \nThe results can be found in the attached PDF, for additional details we refer to our responses to Reviewers\nuV6M and 2jDD.""}, 'pdf': {'value': '/pdf/f6607ed59a6d868a0cedb865b3810762104a394a.pdf'}}, {'rebuttal': {'value': ""We thank the reviewer for their positive review and are glad the reviewer likes both our tight identifiability results and the contrastive learning algorithm. We agree with the reviewer's suggestions to improve the exposition and are happy to be revise the wording accordingly, including being more upfront about the limitations.\nIn particular we will clarify that $f$ is a property of the world that we try to learn and Gaussian variables are often a useful approximation.\n\nWe also like the reviewer's suggestions for additional experiments.\n\n1. In Table 1 of the attached PDF, we show the results for experiments with non-Gaussian distributions (the setting agrees with the first row \nof Table 2 in the paper), in particular Laplace, Gumbel, Uniform and Exponential distributions.\nWe observe that the recovery with our contrastive learning algorithm gets slightly worse but is still very reasonable. This is in line with the performance of, e.g., causal discovery algorithms based on a Gaussian likelihood score for non-Gaussian data.\n\n2. As suggested, we also scaled up our experiments on the image dataset to 10 balls, please see Table 3. We found that for (much) larger sample size and larger models the performance can be increased significantly (compared to the results we reported), and we can handle  up to 10 balls. While there is certainly still room for improvement (e.g. via hyperparameter turning), the more challenging next step is to handle noisy observations and more complex sceneries.\n\nWe will add these tables to the paper in the final version. We welcome additional feedback to improve the work.""}}, {'rebuttal': {'value': 'We thank the reviewer for their review and positive feedback.\nWe are glad the reviewer also expects our ideas to contribute towards generative modeling in the real world, as that is one of the stronger motivations behind our work.\n\n**Regarding the questions:**\n\n1. We can identify $\\eta$ exactly because the scaling is absorbed in $B$. Or, in other words, $\\eta$ is the amount of shift in the normalized Gaussian (this is evident in equation (2)) and therefore can be identified without scaling indeterminacy.\n\n2. There should be no subscript, thanks for pointing out our typo.\n\n**Regarding the suggestions:**\n\nWe appreciate the insightful suggestion regarding varsortability and will be happy to discuss this in the paper, as well as cite the works you linked. \nWe ran an additional experiment where we standardized $Z$ before applying the non-linearity thereby removing the varsortability (we also checked that in our setting $R^2$-sortability does not deviate substantially from $1/2$). The results are in Table 2 in the attached PDF and show a slightly degraded performance.\nIn general, note that it is not directly clear how varsortability of $Z$ can be exploited because $Z$ is only identifiable up to scaling, as we show.\n\nWe agree with the reviewer that resolving the issues of local optima and sample complexity are of great interest. Although little progress has been made on them so far in this field \n(e.g.,  there are no sample complexity results for causal representation learning that we are aware of), \nthese are important directions for further research. \nWe plan to expand our discussion section to include those directions, and also incorporate your suggestions along with the suggestions by other reviewers.'}}, {'rebuttal': {'value': ""We thank the reviewer for the review and their suggestions. We will address their concerns in order.\n\n**Regarding the identifiability of $d$:**\n\nYes, the dimension $d$ is identifiable from the observational distribution in our setting for the following reason. The image $f(\\mathbb{R}^d)=M\\subset \\mathbb{R}^{d'}$ is a submanifold of dimension $d$, i.e., it locally looks like a $d$ dimensional hyperplane, so its dimension can be identified from the dimension of the tangent space.  Put differently, the datapoints in a small neighborhood of a point $x$ generate essentially a $d$ dimensional linear space.\n\nIn the setting considered in [2] that the reviewer highlighted, the latent dimension can be directly estimated from the rank since the mixing $f$ was assumed to be linear (which is a specialized setting). In general, when $f$ is non-linear as in most representation learning tasks, this task of estimating the latent dimension for complex data is much harder but also highly important and has been subject to intense study.\n\nFor instance, in [1] the authors define a maximum likelihood estimator for the dimension of the data manifold around a data-point $x$ (it exploits that the volume of the $d$-dimensional ball scales like $r^d$ with the radius $r$).\nWe show in the table below our estimates when applying this estimator (for the $k=50$ nearest neighbors) to our MLP setting with observed dimension $d'=100$\nand $n=10000$ samples where we average the estimator over 10 different data-points $x$. We report the mean over 10 different runs and the  reported error is the standard deviation.\n\n| Ground truth $d$    | Estimated $\\hat{d}$ |\n| -------- | ------- |\n| $5$  | $5.3\\pm 0.3$    |\n| $10$ | $9.8 \\pm 0.6$     |\n| $20$    | $16.2 \\pm 0.6$    |\n\nSo for the settings we consider we can estimate the dimension experimentally, but, as one would expect, the problem becomes more difficult for high dimensions.\nTo use our contrastive algorithm with unknown dimension, one could first use a standard estimator to estimate the dimension $d$ of the data manifold (as in [1]) and then apply the contrastive algorithm. \nWe thank the reviewer for bringing up this point, and we will clarify in the paper, that $d$ is also identifiable.\n\n\n**Regarding multi-node interventions:** \n\nThis is an interesting direction that is beyond the scope of our present work but we expect that new block identifiability results can be derived for multi-node interventions. We will be happy to add a discussion of this along with further future directions. \n\n\nWe hope our response clarifies the reviewer's points of concern, especially the ones that led them to reduce their score. We're happy to address any further concerns and also welcome additional feedback on improving the paper.\n\n[1] Elizaveta Levina and Peter Bickel. Maximum Likelihood Estimation of Intrinsic Dimension,  NeurIPS 2004.\n\n[2] C. Squires, A. Seigal, S. Bhate, and C. Uhler. Linear causal disentanglement via interventions, ICML 2023.""}}, {'rebuttal': {'value': ""We thank the reviewer for the review and their insightful suggestion of a simpler proof strategy.\nHowever, the model considered in their argument is the very special case when the causal graph's weights do not change at all under all considered interventions. In particular, their review assumes $z^{(k)} = A\\epsilon^{(k)}$, but our setting is substantially more general and considers the case where $A$ changes (which covers more realistic interventions). We present additional details below.\nRegarding the distributional assumption, we agree it's needed in our work and it has been emphasized in the abstract and introduction. Additionally, we will carefully revise to make it more evident throughout the writeup.\n\n\n==================\n\n**Additional details:**\n\nWe follow your notation in this response, however, note that the matrix $A$ in this response corresponds to $B^{-1}$ in the paper.\nThe review considers interventions of the form $z^{(k)}=A\\varepsilon^{(k)}$ where $\\varepsilon^{(k)}$\nis obtained by shifting and rescaling the noise variable of node $k$. \nAs outlined in the review, this setting is covered by the iVAE theory and earlier identifiability results apply.\nOur work considers, in addition, interventions that change the relation to the parents, in particular perfect interventions that remove the effect from the parents.\nFor such interventions, the matrix $A\\to A^{(k)}$ also depends on the intervention. \nThis is also the interventional setting considered for linear mixing functions in the recent work [1].\nNote that the settings considered by the reviewer and our work both agree in the special ICA case when there are no causal relations but don't agree in cases beyond ICA, which we handle in our work.\n\nTherefore, to achieve our tight identifiability results, we need to exploit the specific form of the interventions. Note that our proofs are not purely linear algebraic but also topological, i.e., we explicitly exploit continuity of the mixing (see Lemma 4) making it unlikely that our results directly follow from known theorems.\nNevertheless, we agree that it is a valuable addition to our paper to clarify that the ICA case is substantially simpler and has been solved in earlier work.\n\nWe hope that this changes your view on our theoretical contribution and other points that may have contributed towards a lower score, and we are happy to discuss this issue and all other questions further.\n\n[1] C. Squires, A. Seigal, S. Bhate, and C. Uhler. Linear causal disentanglement via interventions, ICML 2023.""}}, {'summary': {'value': 'In recent years, the theory of non-linear independent component analysis and causal representation learning has witnessed a lot of interesting developments. In this work, the authors study the problem of causal representation learning in the presence of interventional datasets, where interventions occur on the latents. The authors show that when the latents follow a linear structural causal model with a Gaussian distribution, then under general non-linear mixing (diffeomorphisms) the latents can be recovered up to permutation and scaling. For imperfect interventions, the authors show that it is still possible to recover the partial order under topological ordering of the underlying causal graph G can be recovered.  The authors present a new method based on contrastive learning that learns to distinguish interventional data from observational data and test it out on some synthetic datasets.  \n\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The authors have studied an important problem in the area of intereventional causal representation learning. The results proposed in the work for the case of perfect interventions show that strong identification is achievable with perfect interventional data. The authors also make progress on the difficult problem of tackling imperfect interventions. The theory of the paper is overall quite insightful. '}, 'weaknesses': {'value': ""I have a question and a claim about weakness. Let us consider the following setting. \n\nData generation for obervational data is given as:\n\n$\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 Id)$, \n$z = A \\epsilon$, \n$x  = f(z)$\n\nwhere $A$ is invertible, $\\mathcal{N}$ is normal distribution, $\\epsilon$ is noise (each component is independent), $f(\\cdot)$ is injective. \n\nData generation in interventional environment $k$ where $p^{th}$ component is intervened is given as \n\n$\\epsilon^{(k)} \\sim \\mathcal{N}(\\mu_p e_p, \\sigma^2 Id + \\sigma_p^2 e_p e_p^{\\top})$, $z^{(k)}= A \\epsilon^{(k)}$, $x = f(z^{(k)})$\n\nwhere $e_p$ is a vector with zeros everywhere except at $p^{th}$ entry, $Id$ is identity, $\\mu_p$ is mean under intervened distribution\n\nWe index the observational data as $0$ and interventional data from $1$ to $p$.\n\nIf we condition on the index of the data, the different components of $\\epsilon$ are conditionally independent and follow an exponential distribution.  We can now leverage the theory in i-VAE applied to identifying $\\epsilon$ and mixing function $f \\circ A$.  In this case, if we have $p\\geq 2d$ and sufficient variability condition from Theorem 1 in http://proceedings.mlr.press/v108/khemakhem20a/khemakhem20a.pdf is satisfied, then we achieve permutation and scaling identification.  \n\n\nTherefore, we can assume to have identified $\\epsilon$ up to permutation and scaling. We call this estimate $\\hat{\\epsilon} = P \\Lambda z$, where $P$ is permutation, $\\Lambda$ is diagonal. Note that $\\hat{\\epsilon} =\\Lambda^{-1}P^{-1} A^{-1}z$. We now have a linear relationship between observed $\\hat{\\epsilon} $ and underlying true $z$. \n\nWe can now leverage imperfect intervention results under linear mixing from https://arxiv.org/pdf/2301.08230.pdf (Theorem 13, see Table 1) to achieve mixing consistency based identification of $z$. \n\nWe can even reduce the number of interventional distributions needed from $2d$ to $d$ provided we assume variance in Normal distribution is known by leveraging results from https://proceedings.mlr.press/v177/lachapelle22a/lachapelle22a.pdf. \n\nThe characterization I describe above suggests that it is possible to get identification results by combining i-VAE and  https://arxiv.org/pdf/2301.08230.pdf in a straightforward way. Either I am missing something? I would like the authors to clarify if they considered this simple combination? Further, if the authors agree with above characterization, how do the authors modify their contributions in this light?\n\n\nI don't quite agree with line 253, distributional assumptions. I think Gaussians is still a strong assumption and authors would benefit by being upfront about it.""}, 'questions': {'value': 'Please see the weakness section above. My final score depends on clarifcation to the questions I raised above.'}, 'limitations': {'value': 'The authors would benefit by having a discussion on the limitations. For instance, they should talk about why is Gaussian assumption limiting as an example.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper considers the task of causal representation learning (causal disentanglement) from interventions, with (1) a linear latent structural causal model, (2) a nonlinear mixing function, and (3) single-node interventions. They show that, under perfect interventions, the generative model is identifiable up to trivial indeterminacies. They propose a method based on contrastive learning for recovering the generative model, and show that their method works well in practice (outperforming a baseline which only allow for linear mixing). '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '### Significance\nThis paper presents a significant theoretical contribution to an established line of work, while introducing techniques and connections that will be useful for future works. In particular, the advance from linear (or polynomial) mixing to general non-linear mixing is a big step towards realistic generative modeling. On the practical side, they also develop a solid contribution by showing that contrastive learning can be used to disentangle the latent variables. \n\n### Clarity\nThe paper is very clear in describing its contribution and how it compares to previous work. The presentation is quite thorough: they clearly describe their setup and discuss their assumptions, they show that their sufficient conditions for identifiability are actually necessary conditions, they discuss the unsuitability of polynomial mixing, and they provide a detailed description of their experimental methodology with accompanying code.\n'}, 'weaknesses': {'value': 'There are no major weaknesses. There are some relatively minor points of confusion / potential typos and some small suggestions to improve the paper in the **Questions** section.\n\nIf I had to pick a weakness, it would be that the proposed algorithm suffers from problems with local optima. It would be ideal to have an algorithm which provably recovers the latent representation, and some sample complexity results. These results would make the paper feel very ""complete"", and with these results the paper would probably be a better fit for a journal.'}, 'questions': {'value': '### Questions\n1. In Equation (3), why are we able to identify shifts without scaling indeterminacy? This seems odd: if we scale a variable, I would expect that the shift also scales.\n2. In Equation (7), should $h$ in the last term have a subscript? Then it is not a matrix so I don\'t see how it should be in the inner product.\n\n### Suggestions\n1. In line 26, the cited papers are about independent component analysis, and these are given as examples of identifiability in causal representation learning (CRL). I agree that ICA can be cast as a special case of CRL. However, I have the feeling that for the purposes of clarity, it might be best to use a different umbrella term like ""identifiable representation learning""; there is nothing really ""causal"" about ICA.\n2. Adapt the synthetic data generation process to reduce varsortability and $R^2$-sortability [1,2]. One procedure which takes these issues into account is given by [3]. \n\n[1] Reisach, A., Seiler, C., & Weichwald, S. (2021). Beware of the simulated DAG! Causal discovery benchmarks may be easy to game.\n\n[2] Reisach, A. G., Tami, M., Seiler, C., Chambaz, A., & Weichwald, S. (2023). Simple sorting criteria help find the causal order in additive noise models.\n\n[3] Squires, C., Yun, A., Nichani, E., Agrawal, R., & Uhler, C. (2022). Causal structure discovery between clusters of nodes induced by latent factors.'}, 'limitations': {'value': 'The authors have adequately addressed the limitations of their work.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""This paper aims to identify latent variables via a nonlinear mixing function interventional data. The authors prove strong identifiability results for unknown single-node interventions, extending previous work that focused on linear maps, polynomial mixing functions or paired counterfactual data. The paper proposes an interesting contrastive algorithm to identify the latent variables and evaluates its performance on some synthetic tasks and a simple image dataset modified from Ahuja et al [2023]. While there have been other very recent works that examine the interventional setting, this is the first I'm aware of that only requires $d$ interventions to recover $d$ latents with minimal constrains on the mixing function.""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""* This is the strongest theoretical result that I am aware of in causal representation learning. The gaussian assumption is obviously restrictive, but other than that, the paper proves identifiability for a very practical class of problems: they only need $d$ interventions to identify $d$ latents, and make no further restrictive assumptions on the mixing function beyond standard infectivity / diffeomorphism assumptions. \n* The paper is very clearly written both in the main text and the appendix. \n* The contrastive algorithm that they propose to implement their approach is interesting. It has some optimization issues which the paper is upfront about, but I'm still curious to see how it would work on larger problems.""}, 'weaknesses': {'value': 'I don\'t have many complaints, but I do have some nitpicks.\n* In the introduction (particularly the first paragraph), the paper makes it sound like the generative process for the data is via a neural network (transformers & diffusion models in line 16, and a similar comment is made in line 124 in support of Assumption 1). While we can build generative models of complex data with neural networks, that is not the $f(\\cdot)$ that we care about in causal representation learning. The real generative function, $f(\\cdot)$, is a property of the world---it\'s the camera or microscope that photographs a scene---and we don\'t have control over that. I realize this makes the diffeomorphism assumptions unrealistic, but I think it\'s better to just be upfront about that as a limitation. \n* I have a similar complaint about the defence of the Gaussian assumption in lines 138 - 141: real processes almost certainly are not Gaussian, so we should treat it as a model of the world and be upfront about that (in the Box, ""all models are wrong"" sense). The paper would be strong if you were upfront about the fact that it is clearly restrictive but useful (because it gives strong identifiability results), and then evaluated sensitivity of the method to non-gaussian latents in the experiments. \n\nMore minor:\n* Line 32 - I believe causal representation learning, but it remains to be seen whether it is either necessary or sufficient to build trustworthy systems, so that\'s a strong claim to make.'}, 'questions': {'value': '* Have you experimented with non-gaussian latents? What happens?\n* How well does the method work on larger problems (e.g. 5 - 10 balls? Or more?)'}, 'limitations': {'value': 'As mentioned above, the paper could be a little more upfront about the implication of the assumptions it makes, but overall it does a good job of addressing limitations. I also liked the ""deadends"" section at the end of the appendix.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors study the problem of learning latent causal models from interventional data. The problem was formulated under linear or polynomial mixing in previous works and this work considers a more general setting of nonlinear mixing. The main contributions are the identifiability results of the latent causal model and a contrastive algorithm that identifies the latent model.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': '1. The extension to nonlinear mixing is an important and challenging problem.\n\n2. Using the contrastive algorithm to identify the model parameters is novel and sound.'}, 'weaknesses': {'value': '1. Single-node interventions are considered, while more nodes can be intervened in each environment in practice. For theoretical results, I think focusing on single-node intervention is fine, but it should be discussed whether the results have the potential to be generalized. \n\n2. It was not mentioned whether the latent dimension $d$ is identifiable in the nonlinear setting. For all the identifiability results in the paper, the considered $\\widetilde{Z}^{(i)}$ is assumed to have the same dimension as the true latent variable $Z^{(i)}$ (i.e., $d$). Note that $d$ is identifiable and it equals to the rank of the precision matrix of X in the linear setting. (Section 3.1 [1]). \n\nThis issue occurs in the experiments as well.  $d$ is provided to the contrastive method. But it is often not possible to know $d$ in practical settings.\n\n[1] C. Squires, A. Seigal, S. Bhate, and C. Uhler. Linear causal disentanglement via interventions, 2023.\n\nAdditional comment: I think it would be helpful to provide a concrete toy example to demonstrate the identifiability since the proof intuition is a bit vague. \n\n\n\n\n'}, 'questions': {'value': 'Whether $d$ is identifiable in the nonlinear setting? And how to identify $d$ for the contrastive method?\n\nI would like to raise my score if this problem can be addressed properly. \n\n'}, 'limitations': {'value': 'No potential negative societal impact.\n\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Learning Linear Causal Representations from Interventions under General Nonlinear Mixing'}, 'authors': {'value': ['Simon Buchholz', 'Goutham Rajendran', 'Elan Rosenfeld', 'Bryon Aragam', 'Bernhard Schölkopf', 'Pradeep Kumar Ravikumar']}, 'authorids': {'value': ['~Simon_Buchholz1', '~Goutham_Rajendran1', '~Elan_Rosenfeld1', '~Bryon_Aragam1', '~Bernhard_Schölkopf1', '~Pradeep_Kumar_Ravikumar1']}, 'keywords': {'value': ['Causal Representation Learning', 'Interventional data', 'Gaussian Structural Causal models']}, 'TLDR': {'value': 'We prove identifiability of causal representation learning from interventions with general nonlinear mixing functions and unknown, latent interventions, and propose a contrastive learning algorithm to learn it.'}, 'abstract': {'value': 'We study the problem of learning causal representations from unknown, latent interventions in a general setting, where the latent distribution is Gaussian but the mixing function is completely general. We prove strong identifiability results given unknown single-node interventions, i.e., without having access to the intervention targets. This generalizes prior works which have focused on weaker classes, such as linear maps or paired counterfactual data. This is also the first instance of identifiability from non-paired interventions for deep neural network embeddings and general causal structures. Our proof relies on carefully uncovering the high-dimensional geometric structure present in the data distribution after a non-linear density transformation, which we capture by analyzing quadratic forms of precision matrices of the latent distributions. Finally, we propose a contrastive algorithm to identify the latent variables in practice and evaluate its performance on various tasks.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/216b4284619cd296f9beaa2d57e9e3abf0369c42.pdf'}, 'supplementary_material': {'value': '/attachment/39869436e8494110dc7f0246282a394ae8ef16ca.pdf'}, '_bibtex': {'value': '@inproceedings{\nbuchholz2023learning,\ntitle={Learning Linear Causal Representations from Interventions under General Nonlinear Mixing},\nauthor={Simon Buchholz and Goutham Rajendran and Elan Rosenfeld and Bryon Aragam and Bernhard Sch{\\""o}lkopf and Pradeep Kumar Ravikumar},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=q131tA7HCT}\n}'}, 'paperhash': {'value': 'buchholz|learning_linear_causal_representations_from_interventions_under_general_nonlinear_mixing'}}]"
"['Mina Dalirrooyfard', 'Slobodan Mitrovic', 'Yuriy Nevmyvaka']",NeurIPS,Nearly Tight Bounds For Differentially Private Multiway Cut,https://neurips.cc/virtual/2023/oral/73852,2023," Finding min $s$-$t$ cuts in graphs is a basic algorithmic tool, with applications in image segmentation, community detection, reinforcement learning, and data clustering. In this problem, we are given two nodes as terminals and the goal is to remove the smallest number of edges from the graph so that these two terminals are disconnected. We study the complexity of differential privacy for the min $s$-$t$ cut problem and show nearly tight lower and upper bounds where we achieve privacy at no cost for running time efficiency. We also develop a differentially private algorithm for the multiway $k$-cut problem, in which we are given $k$ nodes as terminals that we would like to disconnect.    As a function of $k$, we obtain privacy guarantees that are exponentially more efficient than applying the advanced composition theorem to known algorithms for multiway $k$-cut.    Finally, we empirically evaluate the approximation of our differentially private min $s$-$t$ cut algorithm and show that it almost matches the quality of the output of non-private ones.",Oral 2D Privacy,https://openreview.net/pdf?id=QDByreuQyk,https://openreview.net/forum?id=QDByreuQyk,QDByreuQyk,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The paper presents new differentially private algorithms for s-t mincut and multiway cut problems. The problem is interesting and the techniques are novel. The reviewers were in agreement that the paper is above bar and I am happy to recommend acceptance. The authors are encouraged to incorporate reviewer feedback, and relevant portions of the rebuttal in the final version of the paper. It would be great also if they could further elaborate on the relevance of their solutions to various ML problems.'}}, {'comment': {'value': 'Thanks to the authors for the detailed responses to the questions from all the reviewers. I am quite happy with the clarifications'}}, {'comment': {'value': 'Thank you for your response.\n\nYou\'re right, obtaining the optimal solution for general $k$ is NP-hard, but using an approximation algorithm for the experiments would also suffice. Because the main theme is ""multiway"" cut, and one of the stated contributions is in reducing the error from $k$ to $\\log k$. I think experimental results which show how the error grows with $k$ would be better support for this claim. \n\nI will keep the score.'}}, {'rebuttal': {'value': '> The proof of Lemma 4.1 does not match exactly the steps of Algorithm 2. ...\n\nWe agree with your comment that Lemma 4.1 does not match exactly the steps of Algorithm 2. Our intent is to represent Algorithm 2 in the simplest form, and Lemma 4.1 provides an alternative view on Algorithm 2, which we then leverage to prove DP. We agree with your comment on how DP guarantees can be proved, and our formal proof – please see Theorem 4.2 – is very similar to the argument you provided.\n\n> There is no related work section? I think the greedy partitioning method for multiway cut [b] could be described here, since it is similar to your non-private multiway cut algorithm.\n\nThank you for providing the references, we will mention the references you suggested. The greedy splitting technique is indeed one of the most widely known algorithms. However, there is a _significant_ difference between the greedy splitting and our approach.\nNamely, the usual greedy splitting has $k$-dependant splits, while ours has only $O(\\log k)$. That $k$ dependence also applies to algorithms GSA and M-GSA in the reference [b]. As a result, we get much stronger DP guarantees compared to the direct application of the folklore greedy splitting yields. As an additional feature, the running time of our algorithm depends only logarithmically in $k$, as opposed to linearly like the algorithms in [b].\n\nEven though Algorithm 2 is simple and intuitive (and similar results have been proved for other problems such as in [a]), our proof is more technically involved and quite different from that of [b].\nThe same problem described above exists for the 2-approximation algorithm outlined in lines 85-87 of our submission.\n\nWe agree that a separate related work section is beneficial to have all the related references in one place and we will make one for the final version of our paper. However, there is very limited work on differentially private min-cut and min s-t cut, and we mention most of the references in the introduction. In addition to the references provided, please let us know if adding any other references or looking into any other problems is beneficial.\n\n> The experiments seem uninformative to me. Why compare the error of your s-t cut algorithm to error of a terminal cut? To me, an evaluation of the k-cut algorithm would be more useful, the setup could be: OPT vs. non-private approximation vs. DP algorithm.\n\nThe terminal cut is the only differentially private benchmark we are aware of. Another potential benchmark is partitioning the vertices randomly without even considering edges. However, although it has perfect privacy, such a benchmark has an extremely high additive error of the order $0.5$ * # of edges. We provide the relative errors in the PDF in the Official Rebuttal, showing that the relative errors are very small.\n\nFor $k>2$, obtaining the optimum solution is NP-hard, so experimenting with that is more tricky. Moreover, we focused on experimentally evaluating Alg 1 because our Alg 2 achieves DP by using Alg 1 as a sub-routine. \n\n> The error in Lemma 3.3, I suspect it should be $O(n / \\epsilon \\cdot \\log n)$? ...\n\nWe still believe the right answer is $O(n / \\epsilon)$. Indeed, it is more involved to show that bound than $O(n \\log n / \\epsilon)$; the bound of $O(n \\log n / \\epsilon)$ is direct as each of the $n$ random variables has value $O(\\log n / \\epsilon)$ with high probability. Intuitively, for a sufficiently large constant $c$, one can still show a bound of $O(n / \\epsilon)$ because only _a small fraction_ of random variables exceeds $c/\\epsilon$; this fraction is roughly $e^{-c}$. We explicitly state this on Line 220 and in Fact 2.1, and then leverage it in our proofs. In the Official rebuttal for the entire submission, we comment more on that paragraph, including expanding on Line 224. We are happy to provide more details in that proof in the final version.\n'}}, {'rebuttal': {'value': '> The main ideas in the paper are quite simple. ...\n\nWe agree that a separate related work section is beneficial to have all the related references in one place, and we will make one for the final version of our paper. However, there is very limited work on differentially private min-cut and min s-t cut, and we mention most of the references in the introduction. The relevant problems to min s-t cut could be the clustering problems referenced on line 34. However, the techniques for clustering problems are very different from cut problems. \n\nThe min-cut problem has a differentially private algorithm that was developed back in 2010 [17] with tight error bound $O(\\log(n)/\\epsilon)$. \n\nFor the multiway-cut problem, we discuss the best approximation algorithms and lower bounds for it in lines 80-83. Several simple algorithms achieve approximation bounds near 2; we mention one of them on lines 85-87. There is also a folklore greedy splitting algorithm (Liang Zhao et al. ""Greedy splitting algorithms for approximating multiway partition problems"") that starts with the whole graph as one partition and at each step greedily cuts one of the partitions, hence after k-1 rounds achieved k partitions. The problem with all of these algorithms is that they require k rounds of min s-t cut, and hence using an $\\epsilon$-private algorithm for min s-t cut in these algorithms would yield a $k\\epsilon$-private 2-approximation algorithm for multiway cut. We show that using Algorithm 2, one can decrease this dependency on $k$ to $\\log(k)$.\n\nWe believe this captures all the related work to our problem. Please let us know if adding any other references or looking into any other problems is beneficial. \n\n\n> The edge privacy model assumes the weight of an edge changes by at most 1 in neighboring graphs (definition 2.3). Suppose this is allowed to be w, do the upper and lower bounds scale accordingly?\n\nThis is a great question. Yes, it does generalize to any $w$. Our proof of Lemmas 3.1 and 3.2 is actually already proved for a general weight difference; we use $\\tau$ instead of $w$ to define this difference. Those proofs show that our Alg 1 is $(\\epsilon \\cdot w, 0)$ DP. As a consequence and by rescaling the input $\\epsilon$ by $w$, our Alg 1 is $(\\epsilon, 0)$ DP and incurs an additive approximation of $O(n \\cdot w / \\epsilon)$. We are happy to include these comments in the final version.\n\n> Are better accuracy bounds possible when the graphs have some special properties?\n\nThis is an interesting question for future research. We are happy to include it in our conclusions. It is worth noting that our lower-bound graph has the min s-t cut equal to 0.\n\n> line 160: the first sentence (""Let G and G\' be two neighboring graphs"") doesn\'t need to be part of the Lemma statement\n\nYou are right. We will fix this.\n\n> It would be interesting to show the relative error of the solution computed by Algorithm 1, i.e., compare the error of Algorithm 1 with the actual s-t mincut. This could be done for the baseline as well. Without that it is hard to really understand how well the algorithms are doing.\n\nYou are right. In the Official rebuttal (please see the attached PDF there) we provided the relative errors. The errors are quite low for both algorithms, though our approach still has lower relative errors.\n'}}, {'rebuttal': {'value': '> What are some computational complexity implications of your work?\n\nThank you for this great question. There are several implications. *First*, our Alg 1 uses a non-private min $s$-$t$ cut algorithm in a black-box manner. Hence, it essentially translates to any popular computation setting without asymptotically increasing complexities compared to non-private algorithms. *Second*, our Alg 2 creates (recursive) graph partitions such that each vertex (and edge) appears in $O(\\log k)$ partitions. To see how it differs from other methods, observe that the standard splitting algorithm performs $k-1$ splits, where some vertices appear in each of the split computations. There are also LP-based algorithms for the multiway $k$-cut problem, but to the best of our knowledge, they are less efficient than the $2$-approximate greedy splitting approach. *Third*, in the centralized and parallel settings such as PRAM, in terms of total work, Alg 2 depends only logarithmically on $k$ while the popular greedy splitting algorithm has linear dependence. This question was thoroughly investigated by groups of authors, e.g., see “Faster Parallel Multiterminal Cuts” by Henzinger, Noe, and Schulz, and references therein. To the best of our knowledge, no existing method matches these guarantees that Alg 2 provides.\nWe didn’t expand on this in our submission and kept the focus on the DP guarantees of our Alg 2, but we are happy to discuss the complexity implications in more detail in the final version.\n\n\n> Line 39: Can you please sketch an example where there are exponentially many min s-t cuts but only polynomially many min cuts?\n\nTake $n-2$ nodes $v_1,...,v_{n-2}$ in addition to $s$ and $t$, and add $v_i$ to both $s$ and $t$ for all $i$. Suppose the weight of all edges is $1$. There are $2^{n-2}$ min $s$-$t$ cuts, as each min s-t cut should remove exactly one edge from each $s-v_i-t$ path; either $(s, v_i)$ or $(v_i, t)$ is fine. \nIn this example, there are $n-2$ min cuts: for each $i$, remove edges $(v_i,s)$ and $(v_i,t)$ and this would be a cut of size 2. Moreover, one can show that the number of min-cuts is polynomial for any graph, there are at most ${n \\choose 2}$; please see “On the structure of a family of minimum weighted cuts in a graph” by Dinitz et al.\n\n> The discussion after Theorem 1.2 (Line 60 to Line 74) is a bit confusing.\n\nWe will polish this paragraph.\n\n> Line 65: Theorem 1.1 should be Theorem 1.2.\n\nIt is true, and we will fix that.\n\n> Line 89: Can you elaborate a bit on advanced composition?\n\nWe remark that we do not use the advanced decomposition theorem. We only mention that, even if applied to the standard greedy approach for multiway cut, it does not yield the guarantees that Alg 2 has. To be more precise, the folklore greedy splitting multiway $k$-cut algorithm yields $(k \\epsilon, 0)$-DP via direct composition. The advanced decomposition, see [1], improves that to $(\\sqrt{k} \\epsilon, \\delta)$-DP, for some $\\delta > 0$. Note that the advanced decomposition yields to approximate DP instead of a pure one in which $\\delta = 0$.\n[1] Cynthia Dwork, Guy N. Rothblum, and Salil P. Vadhan. “Boosting and differential privacy”\n\n> Line 161: Proof of Lemma 3.2: Can you please add an explanatory figure for the discussion from Line 161 to Line 173?\n\nYes, we are happy to improve that discussion.\n\n> Line 191: I do not understand this math display.\n\nHere is a complete derivation\n $\\Pr[w_{G’}(C_u) < w_{G’}(C_v)\\ \\wedge\\ w_{G’}(C_u) < w_{G’}(C_{u,v})\\ \\wedge\\ w_{G’}(C_u) < w_{G’}(C_{\\emptyset})] =$\n$\\Pr[\\Delta_v + X_{s,v} + X_{t,u} < X_{t, v} + X_{s, u}\\ \\wedge\\ \\Delta_{u, v} + X_{s, v} + X_{t, u} < X_{t, v} + X_{t, u}\\ \\wedge\\ \\Delta_{\\emptyset} + X_{s, v} + X_{t, u} < X_{s, v} + X_{s, u}] =$\n$ \\Pr[\\Delta_v + X_{s,v} + X_{t,u} < X_{t, v} + X_{s, u} \\ \\wedge\\ \\Delta_{u, v} + X_{s, v}  < X_{t, v} \\ \\wedge\\ \\Delta_{\\emptyset} + X_{t, u} < X_{s, u}].$\nNow, we replace $X_{s,v} - X_{t,v}$ by $x$ and $X_{t,u} - X_{s,u}$ by $y$, which leads to the math on Line 191.\nWe will include this derivation in the full version.\n\n> Line 227: Can you please explain this math display a bit better?\n\nWe provided additional explanations within the Official Rebuttal section. Please check there.\n'}}, {'rebuttal': {'value': 'We thank all the reviewers for their constructive comments.\n\nTwo of the reviewers asked for clarification of the analysis in Lemma 3.3, so in addition to our comments below, we provide more explanations that we will include in the final version.\n\nFor intuition and brevity, assume that $\\epsilon = 1$. Observe that showing that Alg 1 has $O(n \\log n)$ additive error is straightforward as a random variable drawn from $Exp(b)$ is upper-bounded by $O(\\log n / b)$ whp. Our Lemma 3.3 proves the $O(n)$ bound. It is instructive to think of the interval $[2, 5 \\log n]$ being partitioned into buckets of the form $[2^i, 2^{i+1})$. Then, the value of each edge added by Alg 1 falls into one of the buckets; we can safely assume that no edge $X_{s, u}$ or $X_{t, u}$ has a weight more than $5 \\log n$. Now the task becomes upper-bounding the number $c_i$ of edges in bucket $i$. That is, we let $Y_{s, u}^i = 1$ iff $X_{s, u} \\in [2^i, 2^{i+1})$, which results in $c_i = \\sum_{u \\in V}(Y_{s, u}^i + Y_{t, u}^i)$. Hence, $c_i$ is a sum of 0/1 independent random variables, and we can use Chernoff bound to argue about its concentration.\nThere are two cases. If $E[c_i]$ is more than $O(\\log n)$, then $c_i \\in O(E[c_i])$ by the Chernoff bound. If $E[c_i] \\in o(\\log n)$, e.g., $E[c_i] = O(1)$, we can not say that with high probability $c_i \\in O(E[c_i])$. Nevertheless, we can still say $c_i \\in O(\\log n)$ whp. This is why there is $\\max$ including $\\log n$ in it.\nFinally, Line 227 simply sums the weights of $X$ random variables over all the buckets, $\\log (5 \\log n)$ of them, where if a random variable $X$ falls into bucket $i$ we upper-bound its weight by $2^{i + 1}$, although it can be smaller by a factor of $2$. Also, to obtain the first inequality on Line 227, we use that $\\max(\\log n, 2n / 2^{2i}) \\le \\log n + 2n / 2^{2i}$.\n\nIn regards to the experiments, we attached a figure containing relative errors as requested by some of the reviewers. This figure shows that the relative errors are very small. Note that the errors are computed with respect to the optimal $s$-$t$-cut which is not private.'}, 'pdf': {'value': '/pdf/1421dac17d27e05fbe2dece7e4e0e825cb9c4349.pdf'}}, {'summary': {'value': 'This paper presents edge-DP algorithms for min s-t cut and multiway k-cut. The s-t cut algorithm injects fake edges with weights drawn from the exponential distribution, then returns the min s-t cut of the modified graph. The k-cut algorithm is based on $O(\\log k)$ calls to the min s-t cut algorithm. They showed that the s-t cut algorithm has $O(n/\\varepsilon)$ additive error, along with a lower bound of $n/20$ for $(\\varepsilon,\\delta)$-DP estimation of the problem, where $\\varepsilon \\le 1$.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""- The paper is generally well-structured.\n- The DP s-t cut algorithm is surprisingly simple, and it's also the first work on this problem.\n- Lower bound is given.\n""}, 'weaknesses': {'value': '- The proof of Lemma 4.1 does not match exactly the steps of Algorithm 2. The algorithm could be modified to fit the descriptions in the proof. In any case, I think Algorithm 2 as described, can also be made DP by expending only $O(\\log k \\cdot \\varepsilon)$ privacy, where on each level one can apply parallel composition, similar to what was done in [a].\n- There is no related work section? I think the greedy partitioning method for multiway cut [b] could be described here, since it is similar to your non-private multiway cut algorithm.\n- The experiments seem uninformative to me. Why compare the error of your s-t cut algorithm to error of a terminal cut? To me, an evaluation of the k-cut algorithm would be more useful, the setup could be: OPT vs. non-private approximation vs. DP algorithm.\n- a few minor typos.\n\n\n[a] Haim Kaplan et al. ""Differentially Private Approximate Quantiles""\n\n[b] Liang Zhao et al. ""Greedy splitting algorithms for approximating multiway partition problems""\n'}, 'questions': {'value': '- The error in Lemma 3.3, I suspect it should be $O(n/\\varepsilon \\cdot \\log n)$? Since the sum of $n$ exponential random variables has gamma distribution with parameters $n$ and $\\varepsilon$. I am not sure how you arrived at the bound in line 224, since only an upper bound on the $E[c_i]$ is given.'}, 'limitations': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper presents differentially private algorithms for the s-t mincut and multiway cut\nproblems under an edge privacy model with weights. It shows that a simple algorithm gives\nan O(n) additive error bound for the s-t mincut problem, and obtain a near tight lower bound.\nThis is used for obtaining a bound for the k-multiway cut problem, which has an additional\nO(\\log{k}) term, which improves over the O(k) term that would result by applying the\ns-t cut algorithm repeatedly. The s-t mincut algorithm is evaluated empirically, and the\nresults are compared with a simple baseline.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'Differentially private algorithms for the s-t mincut problem have been open for a long time, since\nthe global mincut algorithm of Gupta et al. The paper gives tight upper and lower bounds on the\ncomplexity of this problem, and shows that a very simple algorithm gives these bounds. For the\nk-multiway cut problem, the paper shows that a slightly simple modification of the standard\nnon-private approximation algorithm can be adapted to have an error with O(log k) dependence,\ninstead of O(k) dependence. The presentation is good.'}, 'weaknesses': {'value': 'The main ideas in the paper are quite simple. The experiments section is also somewhat limited.\nWhile the presentation is generally good, there is not enough discussion about the related work.\nSo it is not clear if the technical contributions and the paper overall meet the bar for neurips.'}, 'questions': {'value': 'The edge privacy model assumes the weight of an edge changes by at most 1 in neighboring graphs\n(definition 2.3). Suppose this is allowed to be w, do the upper and lower bounds scale accordingly?\n\nAre better accuracy bounds possible when the graphs have some special properties?\n\n\nline 160: the first sentence (""Let G and G\' be two neighboring graphs"") doesn\'t need to be part\nof the Lemma statement\n\nIt would be interesting to show the relative error of the solution computed by Algorithm 1,\ni.e., compare the error of Algorithm 1 with the actual s-t mincut. This could be done for the baseline\nas well. Without that it is hard to really understand how well the algorithms are doing.'}, 'limitations': {'value': 'To some extent. There are no negative social impacts'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors give a novel and simple diferentially private algorithm for the min $s$-$t$ cut and multiway $k$-cut problems.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'Originality:\nWork seems original.\nSimple but novel!\n\nQuality:\nQuality of the paper is high.\nThe authors give interesting upper and lower bounds for the min $s$-$t$ cut and multiway $k$-cut problems.\n\nClarity:\nWriting is clear.\n\nSignificance:\nThe result is significant, as min $s$-$t$ cut and multiway $k$-cut are important problems.'}, 'weaknesses': {'value': 'None significant weakness found.'}, 'questions': {'value': 'What are some computational complexity implications of your work?\n\nLine 39:\nCan you please sketch an example where there are exponentially many min $s$-$t$ cuts but only polynomially many min cuts?\n\nThe discussion after Theorem 1.2 (Line 60 to Line 74) is a bit confusing.\n\nLine 65:\nTheorem 1.1 should be Theorem 1.2.\n\nLine 89:\nCan you elaborate a bit on advanced composition?\n\nLine 161:\nProof of Lemma 3.2:\nCan you please add an explanatory figure for the discussion from Line 161 to Line 173?\n\nLine 191:\nI do not understand this math display.\n\nSection 4.1 is amazing!\n\nLine 227:\nCan you please explain this math display a bit better?\n\nExperiments look OK!'}, 'limitations': {'value': 'Yes.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Nearly Tight Bounds For Differentially Private Multiway Cut'}, 'authors': {'value': ['Mina Dalirrooyfard', 'Slobodan Mitrovic', 'Yuriy Nevmyvaka']}, 'authorids': {'value': ['~Mina_Dalirrooyfard1', '~Slobodan_Mitrovic1', '~Yuriy_Nevmyvaka1']}, 'keywords': {'value': ['Differential Privacy', 'clustering', 'multiway cut', 'min cut', 'graph partitioning']}, 'abstract': {'value': 'Finding min $s$-$t$ cuts in graphs is a basic algorithmic tool, with applications in image segmentation, community detection, reinforcement learning, and data clustering. In this problem, we are given two nodes as terminals and the goal is to remove the smallest number of edges from the graph so that these two terminals are disconnected. We study the complexity of differential privacy for the min $s$-$t$ cut problem and show nearly tight lower and upper bounds where we achieve privacy at no cost for running time efficiency. We also develop a differentially private algorithm for the multiway $k$-cut problem, in which we are given $k$ nodes as terminals that we would like to disconnect.\n    As a function of $k$, we obtain privacy guarantees that are exponentially more efficient than applying the advanced composition theorem to known algorithms for multiway $k$-cut.\n    Finally, we empirically evaluate the approximation of our differentially private min $s$-$t$ cut algorithm and show that it almost matches the quality of the output of non-private ones.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'We provide the first DP algorithm for min s-t cut and multiway k cut.'}, 'pdf': {'value': '/pdf/b9962f68f524ece242cbe1e7fd1224122c4feac0.pdf'}, 'supplementary_material': {'value': '/attachment/38ad5946889dc2c42415737fb2f5de8490beb750.pdf'}, '_bibtex': {'value': '@inproceedings{\ndalirrooyfard2023nearly,\ntitle={Nearly Tight Bounds For Differentially Private Multiway Cut},\nauthor={Mina Dalirrooyfard and Slobodan Mitrovic and Yuriy Nevmyvaka},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=QDByreuQyk}\n}'}, 'paperhash': {'value': 'dalirrooyfard|nearly_tight_bounds_for_differentially_private_multiway_cut'}}]"
"['Andrew Luo', 'Maggie Henderson', 'Leila Wehbe', 'Michael Tarr']",NeurIPS,Brain Diffusion for Visual Exploration_ Cortical Discovery using Large Scale Generative Models,https://neurips.cc/virtual/2023/oral/73872,2023," A long standing goal in neuroscience has been to elucidate the functional organization of the brain. Within higher visual cortex, functional accounts have remained relatively coarse, focusing on regions of interest (ROIs) and taking the form of selectivity for broad categories such as faces, places, bodies, food, or words. Because the identification of such ROIs has typically relied on manually assembled stimulus sets consisting of isolated objects in non-ecological contexts, exploring functional organization without robust a priori hypotheses has been challenging. To overcome these limitations, we introduce a data-driven approach in which we synthesize images predicted to activate a given brain region using paired natural images and fMRI recordings, bypassing the need for category-specific stimuli. Our approach -- Brain Diffusion for Visual Exploration (""BrainDiVE"") -- builds on recent generative methods by combining large-scale diffusion models with brain-guided image synthesis. Validating our method, we demonstrate the ability to synthesize preferred images with appropriate semantic specificity for well-characterized category-selective ROIs. We then show that BrainDiVE can characterize differences between ROIs selective for the same high-level category. Finally we identify novel functional subdivisions within these ROIs, validated with behavioral data. These  results advance our understanding of the fine-grained functional organization of human visual cortex, and provide well-specified constraints for further examination of cortical organization using hypothesis-driven methods.",Oral 3A Neuro,https://openreview.net/pdf?id=9VqMaSjf7U,https://openreview.net/forum?id=9VqMaSjf7U,9VqMaSjf7U,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The paper presents a novel approach to reconstruct images from brain activity that only needs an encoding model that can be trained independently.\nThe main interest is that uses the most recent developments on generative models of vision to perform novel analyses of the visual cortex in humans and obtain non-trivial results on the semantic specialization of visual regions.\nThe method can indeed retrieve subtle differences between ROIs selective for the same class (e.g. OFA and FFA) and highlight functional differences between sub-clusters of existing ROIS.\nThe qualitative observations are validated by behavioral evaluations from human subjects.\n\nThe paper is well-written, and the experiments and visualizations are in good condition and sufficient.\nOn the weakness side, the technical contribution of the paper is overall less impressive.   \n\nThere is a wide consensus among reviewers, hence the paper is certainly well suited for NeurIPS, and certainly for a spotlight presentation.'}}, {'comment': {'value': 'We appreciate the positive evaluation you have given to this paper!'}}, {'comment': {'value': ""I thank the authors for a detailed response and for answering my concerns one by one.\n\n**Q1.1)** : It's true that the problem that you investigate is different from the Takagi et al. [1]. However, the method and model framework you use is much similar to them. Yours and their methods are both in the Latent Diffusion Model scope. As you mentioned in Section 3.1.\n\n**Q1.2)**: Thanks for your comment. This part makes sense to me. Your new technique of performing fMRI-conditioned image synthesis is interesting.\n\n**Interpretability**: I think the results of Section 4 of the supplementary is a characteristic of a normal diffusion model, in which it tends to generate the main features of an image in the first steps and then details in latter steps. I wonder how the gradient guidance of your method contributes to this generation process.\n\nIn conclusion, while there's room for refinement in the methodology, the paper offers significant scientific contribution to neuroscience. I have revised my score in light of these observations.\n\n\n\n[1] High-resolution image reconstruction with latent diffusion models from human brain activity""}}, {'comment': {'value': ""We are very grateful for the positive assessment you've given to our work! \n\nWe would like to again express our appreciation for your suggestions.""}}, {'comment': {'value': 'Thanks for the responses. I have updated my score to “Accept” following the suggestions for the evaluation of a good contribution with impact in a specific field'}}, {'comment': {'value': ""We are deeply grateful for the positive assessment you've given to our paper! Thank you again for your suggestions and comments.""}}, {'comment': {'value': 'Thank you for your responses, which I found clear and satisfactory. In consequence, I have raised my score to 7.'}}, {'comment': {'value': 'We appreciate the request for code. The anonymous github for the paper is now in a publicly visible comment.\n\nAlso reproduced here for convenience: https://anonymous.4open.science/r/BrainDiVE_code-FF0C'}}, {'comment': {'value': 'We appreciate the timely response. \n\nThank you again for the positive evaluation of this paper!'}}, {'title': {'value': 'Thanks for the clarifications'}, 'comment': {'value': 'Dear authors, thank you for your clarifications. I have read the rebuttal and will stand by my evaluation. '}}, {'title': {'value': 'Link to code'}, 'comment': {'value': 'Here is a copy to a fully anonymized version of the core code used in this paper:\nhttps://anonymous.4open.science/r/BrainDiVE_code-FF0C\n\nThe code includes the following:\n* fMRI encoder architecture\n* fMRI encoder training\n* fMRI encoder validation\n* Diffusion architechture\n* Diffusion inference using broad category selective regions; ROIs; and parts of ROIs\n\nWe are fully committed to releasing a complete version of the code at a later point in time.'}}, {'rebuttal': {'value': ""We are strongly encouraged by your evaluation that our work is interesting for neuroscience, it is well-written, and it has good experiments. We appreciate your advice on clarification. We address specific comments below and refer to the general response for results.\n\n> **Scope of the paper**\n\nWe would like to clarify that our work proposes to use diffusion models as a component to elucidate the functional role of different regions of the brain. Our work does not investigate the use of diffusion models for image reconstruction from fMRI or image generation from text. We will clarify this in the upcoming revision.\n\nWe are using diffusion models because they have been demonstrated to be state of the art estimators of the natural image prior [1]. These models have been trained on billions of images (the model we use is trained on LAION-2B), which is three magnitudes larger than BigGAN models trained on ImageNet. We further use the fact that diffusion models can be interpreted as a a score function (gradient of the log-likelihood), and can be combined with a derivative of an energy function (gradient of the brain w.r.t. input) [2].\n\n> **Q1.1) Comparison to Takagi et al.**\n\nThe paper by Takagi et al. [3] is relevant and interesting. It is a work we already cite (Line 67) in our own work. However the problem that we investigate is very different from Takagi et al.\n\nTakagi et al. investigates *reconstructing visual stimuli from a fixed set of voxels* in the brain. Our work explores the synthesis of **novel visual stimuli** that are predicted to activate parts of the visual cortex, not reconstruction of seen stimuli. The method proposed in our paper is intended as a tool for future data-driven investigations of the human visual cortex. \n\nAs our method is gradient based, it is permutation invariant [4] and can be flexibly applied to any subset of visual cortex voxels given a voxel-wise encoding model.\n\n**To our knowledge, our paper is the among the first to explore the synthesis of images predicted to activate higher visual cortex with diffusion models.** There is concurrent work [5] which explores using diffusion models to synthesize images predicted to activate macaque V4. Previous work on diffusion models with fMRI tackle reconstruction.\n\n> **Q1.2) On text-conditioned image synthesis**\n\nTo clarify, **we are not performing text-conditioned image synthesis** using CLIP embeddings as done in [6,7].\n\nOur use of CLIP is purely as a backbone for the visual encoder for fMRI. The use of an pretrained backbone with a linear decoding layer is common in voxel-wise encoding models for fMRI neuroscience, and CLIP models are the best backbone for higher visual cortex in fMRI [8].\n\nThe optimization method proposed in [7] requires knowledge of ground truth images for a given concept, which we do not have.\n\n> **Q1.3) Use of linear combination of S and euler estimation**\n\n* **On a linear combination of S**\n  * A linear combination of voxels (S) activations is accepted in neuroscience investigations for fMRI. In fMRI, voxels are often clustered in regions of interest (ROIs), where voxels have similar selectivity and behavior to visual stimuli. In ROIs, it is common to evaluate the average activations of all voxels using a linear combination (average of S). **This approach has been used in some of the most important papers for visual fMRI [9, 10].**\n\n* **On an euler estimation**\n  * The euler estimate is often used when the gradients of a network are used to guide image synthesis. Concurrent work [5], which uses diffusion models to generate images that are predicted to activate macaque V4 neurons, **also uses an euler estimate to estimate a clean sample that is fed to their encoder (see e.q. 6 in [5])**. This approach is acknowledged in other work ([11] section 2.3 last paragraph; And [12] e.q. 4). We adopt this technique since the euler estimate is in the distribution of natural images, and only use it to modify the image provided to the encoder, not the diffusion output directly.\n\n> **Q2) Theoretical analysis of our work**\n\nWe have included a theoretical analysis of our work in **section 9 of our supplemental.**\n\nIn that section, we show that with an encoder backbone of fixed norm, the brain maximization objective for a single/multiple voxels yields an image where the CLIP image embedding is equal to the normalized voxel weight.\n\n> **Interpretability**\n\nWe show in **section 4 of the supplemental** how the brain and the diffusion model work together. We find that low-level details often emerge first, and that the brain signal and diffusion signal are not always harmonious. \n\n⠀\n\nWe genuinely appreciate the reviewer's commitment to ensuring the rigor of our paper. Their insights have undeniably contributed to its refinement. The clarifications we've provided underscore the innovative aspects of our research and its potential contributions to the field. We respectfully invite the reviewer to approach our work with a more optimistic viewpoint. \n\n⠀\n\n[1] Diffusion Models Beat GANs on Image Synthesis\n\n[2] Reduce, reuse, recycle: Compositional generation with energy-based diffusion models and mcmc\n\n[3] High-resolution image reconstruction with latent diffusion models from human brain activity\n\n[4] Deep Set Prediction Networks\n\n[5] Energy Guided Diffusion for Generating Neurally Exciting Images\n\n[6] High-Resolution Image Synthesis with Latent Diffusion Models\n\n[7] An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion\n\n[8] What can 1.8 billion regressions tell us about the pressures shaping high-level visual representation in brains and machines?\n\n[9] The fusiform face area: a cortical region specialized for the perception of faces\n\n[10] A cortical representation of the local visual environment\n\n[11] GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models\n\n[12] UPainting: Unified Text-to-Image Diffusion Generation with Cross-modal Guidance""}}, {'rebuttal': {'value': 'We are deeply grateful for your excellent suggestions! We will address specific questions below. Please see the PDF in the general response for additional figures. \n\n> **Additional validation**\n\nWe agree with your comments on additional validation. **There is ongoing work to investigate the performance of BrainDiVE synthesized images in humans using fMRI.**\n\nFollowing your suggestion, we train an alternative encoding model using EVA02_CLIP_B_psz16_s8B [1], this is a very recently published backbone model with TrV blocks (in contrast to the ViT B/16 backbone with ViT blocks we use in the paper) jointly trained using mask image modeling and image-text contrastive loss (backbone we use in paper is image-text contrastive loss alone), which has been independently validated to achieve high ImageNet performance. We freeze the model weights, and train a linear probe with bias to estimate the fMRI activations. We validate that the new model can achieve high $R^2$ that is comparable to our current backbone. \n\n**Please see the PDF in the general response for a distribution plot of predicted activations.** We find that our BrainDiVE images can achieve high predicted neural activations when valdiated on a new backbone.\n\n> **Q1) Choice of $\\gamma$**\n\nIndeed, a high $\\gamma$ gives more weight to the brain activation gradient (more activating, less natural), while a low $\\gamma$ gives more weight to the diffusion gradient (more natural, less activating). We set $\\gamma$=130, and this is described in Line 149 of the original paper. There is a typo here and it was represented as $\\eta$, we will update the revision to clarify this value.\n\nWe performed search in increments of 10, exploring values between 10.0 up to values of 300.0, and synthesized 100 images for each of the broad category selective regions and recorded the gradient values at each step and the final synthesized images. We found that values between 110 and 150 yielded gradient magnitudes that largely matched between the brain and diffusion at early time-steps when coarse image structure emerged. The value of 130 was selected as a median value. This is the only hyperparameter that we introduce on top of diffusion models.\n\nApproaches like reflected diffusion [2] or dynamic thresholding from Imagen [3] may enable higher $\\gamma$ values, and remain an avenue for future research.\n\n> **Q2) On concurrent work**\n\nWe were not previously aware of the work by Pierzchlewicz et al. (2023) on ""Energy Guided Diffusion for Generating Neurally Exciting Images"" [4]. After closely reading the paper, we agree that the ideas in our paper and their paper are similar.\n\nBoth works tackle the synthesis of images that are predicted to activate regions of the brain. A broad difference is that our paper targets the higher visual cortex in humans which are believed to encode semantic concepts, while they target V4 in macaques.  This yields differences in the final images, where they primarily target the synthesis of complex visual patterns, while we primarily target the synthesis of compositional visual scenes. \n\nWe thank the reviewer for bringing this interesting paper to our attention, and will include it as a citation in our upcoming revision.\n\n> **Q3) Compute time**\n\nWhen using fp16 diffusion models, with fp32 brain encoders, 50 steps of denoising for images at 512x512 resolution requires around 25 seconds on a Nvidia V100 (from 2017). We briefly discuss this in section 9 of our supplemental, and will clarify this in the main paper in an upcoming revision.\n\nIn practice our experiments were performed on a cluster and consumed 1500 GPU compute hours. Accelerating this processing is a very interesting avenue of research, and we discuss approaches inspired by MagicMix/SDedit [5,6] in section 4 of our supplemental to speed up our work. \n\n⠀\n\nWe hope the clarifications have been insightful. Please don\'t hesitate to comment if there are any additional questions!\n\n⠀\n\n[1] EVA-CLIP: Improved Training Techniques for CLIP at Scale\n\n[2] Reflected Diffusion Models\n\n[3] Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding\n\n[4] Energy Guided Diffusion for Generating Neurally Exciting Images\n\n[5] MagicMix: Semantic Mixing with Diffusion Models\n\n[6] SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations'}}, {'rebuttal': {'value': 'We appreciate your detailed and concrete suggestions! We will incorporate all of your feedback into our paper.\n\n> **Comparisons to prior work**\n\nIndeed, our work builds upon the foundations laid by Ratan Murty et al. (2021),  Ozcelik et al. (2021), and Ozcelik et al. (2023). It was not our intention to imply otherwise. \n\nWe originally included two of these papers in the ""Related Works"" sections of our paper (Murty on Line 35 and 72, Ozcelik on Line 67). In a revised version, we will explicitly highlight the connections between our work and these referenced papers and will additionally cite Ozcelik et al. (2021). \n\nBriefly:\n1. Ratan Murty et al. (2021) builds upon an adversarial trained BigGAN image generator trained on imageNet with category conditioning. Their brain encoder consists of an ImageNet trained frozen ResNet50 backbone, along with a linear decoder layer. \n\n    Our work utilizes a text-conditioned diffusion image model trained on score matching with classifier-free guidance [1] (∇log[p(y|x;t)] = ∇log[p(x|y;t)]-∇log[p(x;t)]; y=text, x=image). This enables our diffusion model to sample from the unconditional image distribution via score function ∇log[p(x;t)] in the absence of text conditioning. Our brain encoder consist of a frozen ViT-B/16 backbone along with a linear probe, which enables brain conditioned image synthesis.\n    \n    A major difference lies in the image synthesis process. As BigGAN is trained on category conditioning (1000 classes in a one-hot vector), Murty et al. perform a joint optimization over c (category) and z (latent). As the category is discrete, they use softmax(c\\) to facilitate gradient optimization. It is not clear that a softmax is suitable, as BigGAN is not trained with non-discrete classes. An alternative could be gumbel-softmax [1], but this has high gradient variance.\n    \n    In contrast, our work performs end-to-end differentiable optimization. So BrainDiVE is not restricted to a particular ImageNet class like NeuroGen by Gu et al., or convex combination of class embeddings as in Murty et al.\n    \n2. The method by Ozcelik et al. (2023) is state of the art for brain based image reconstruction using diffusion models, and is conditioned on a pattern of brain activations. \n\n    In contrast, the primary goal of our work is to generate images that are predicted to maximize a given region of the brain, and not reconstruction. In BrainDiVE, we only need to train an fMRI encoder, and the region can be flexibly defined as any subset of the brain without retraining.\n\n   In Ozcelik et al., when they perform region activation, they set activated voxels to 1, and others to 0. This is followed by manual latent normalization. They achieve intriguing results using this hand-crafted heuristic, but have the implicit assumption that other voxels are zeroed when one region is active.\n\n> **Q1): On top-5 or top-10**\n\nTo clarify, the top-5 and top-10 are for qualitative **visualization only**. Our numerical evaluation follows prior work in image generative models (DALL-E [2]) and brain based activating image synthesis (NeuroGen by Gu et al. 2022, citation 9 in paper), and uses top-20% like NeuroGen unless otherwise noted.\n\nOur top-5/top-10 for visualization is done automatically using the brain encoder, without any manual cherry picking. \n\nFor numerical results, we use the brain encoder without manual cherry picking to evaluate the top 10% and 20% (100 or 200 images) in 4.2, and follow NeuroGen and use the top 20% in 4.3/4.4. Notably this is used for visualization *and* evaluation in OpenAI\'s DALL-E (called reranking) `all samples used for both qualitative and quantitative results ... use reranking with N = 512` [2] where they use `top 32 of 512 after reranking with CLIP, but we do not use any manual cherry-picking` (online post). Like DALL-E, reranking is used in NeuroGen (Gu et al. 2022) where they only analyze the top-100 of 500 images as reranked using their brain encoder (confirmed with author), and only visualize the top-k of 500 images. We also rerank using our brain encoder.\n\nIn general, diffusion models do not always converge during generation. The bottom 1% for the brain generally look like the bottom 1% for text-conditioned, and usually have no recognizable objects. This is an active area of research (see Imagen\'s dynamic thresholding approach).\n\n> **Q2): Optimizing CLIP latent**\n\nThis is indeed an idea we had as well! We believe there are broadly two ideas you are touching upon:\n\n1. Given that we know the optimal fixed CLIP image embedding (512 or 768 dim), in theory it should be easy to condition the diffusion model on this embedding to replace the typical CLIP text embedding. \n\n    In practice high performance diffusion models are text-conditioned, but are not conditioned on a fixed sized (512/768) text embedding, and instead are conditioned on 75 token embeddings (plus start/end tokens) for an entire sentence in order to model visual semantic composition. \n\n    Solving for a fixed sized CLIP image embedding does not give us the full text embedding. In addition, there exists a modality gap between CLIP image and text latents [3], and closing the gap is an active area of research.\n    \n2. An alternative may be to solve for the CLIP text embedding directly via gradient descent. However current work [4] requires a handcrafted text prompt, and has been demonstrated only for single objects. In addition, these approaches require ground truth images for a given concept, which we do not have.\n\n⠀\n\nThank you again for your wonderful suggestions, and we\'re eager to hear your thoughts on our clarifications. Please let us know if you have any additional questions or comments!\n\n⠀\n\n[1] Categorical Reparameterization with Gumbel-Softmax\n\n[2] Zero-Shot Text-to-Image Generation\n\n[3] Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning\n\n[4] An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion'}}, {'rebuttal': {'value': 'Thank you for the excellent suggestions. We address specific questions below, and will include additional details in the general response.\n> **Formatting and presentation**\n\nWe will update our paper to follow other image synthesis papers like OpenAI\'s DALL-E 2 [1] and GigaGAN [2], they similarly select/curate images for the first figure and note this in the caption. We will also update the figure numbering.\n\n> **Q1.1) Validation of effectiveness**\n\nFor within ROI clusters, OPA & food clusters remained stable across random cluster initializations, and showed the highest cosine distance for voxel embeddings among all ROIs we examine. \n\nMore broadly, we agree on the importance of validating and conducting fMRI studies to evaluate BrainDiVE. **We have ongoing work in this area**. \n\nIn the paper we perform validation via two methods:\n1. When we target voxels from widely accepted category selective regions (faces, places, bodies, food, word), we perform CLIP 5-way classification using a natural language probe. The probe sets follow the guidelines detailed in section 3.1.4 of [4]. We provide our full probe set in page 26 of our supplemental. \n\n    We found that images created using BrainDiVE were aligned with scientific consensus for broad category selective visual regions. \n\n2. When voxels from single ROIs (FFA/OFA), and within ROIs (Food/OPA) are targeted, we perform behavioral studies. Ten different subjects were recruited for each region (FFA, OFA, Food, OPA) via Prolific. This yielded 80 evaluations per-subject per-question, for 10 subjects each. We find that BrainDiVE can highlight differences between ROIs (FFA vs OPA) and within ROIs (Color in food voxels, and indoor/outdoor in OPA). This is important as it may facilitate future open-ended data driven exploration of the visual cortex. \n\nWe further validate using an alternative fMRI encoder backbone in the **response PDF**, and find our images can achieve high predicted activations.\n> **Q1.2) Comparisons with existing methods**\n\nWe concur that our work builds upon Gu et al. and Ponce et al. ([9, 10] in text). In particular, the setup of our work is similar to [9], as we both use the NSD dataset and operate offline (no live subject). Our work is not directly comparable to [10] as their experiments use real-time macaque brain feedback, which our work and [9] do not have.\n\nUsing BrainDiVE, we probe the visual cortex selectivity of the brain at three hierarchical stages, and offer new insight on region wise selectivity. Briefly, our work differs from [9] in two important ways:\n\n1. We use a diffusion model trained on billions of internet images, three magnitudes larger than BigGAN (ImageNet), this is important as we are not restricted to single object images that dominate ImageNet. We further leverage the model\'s training with classifier-free guidance [5] (∇log[p(y|x;t)] = ∇log[p(x|y;t)]-∇log[p(x;t)], with y=text, and x=image) to use the model in an unconditional mode, and combine it with our brain encoder to enable brain conditioned sampling. This is in contrast to Gu et al., where they use BigGAN trained on imageNet and condition on class-labels. \n\n2. The brain optimized image generation process is very different. [9] uses search then optimize. They first sample images the 1000 ImageNet classes, and **non-differentiably** select the top-10 classes for each region. Finally they perform brain gradient updates of the GAN latent. This results in images with less diversity, and many of their images are nearly identical. In contrast, our work yields diverse images by using end-to-end differentiable optimization, **and do not restrict the search space to a fixed image category a priori**.\n\nPlease see the **response PDF** for more comparisons.\n\n> **Q1.3) Non-visual cortex results**\n\nPlease see **response PDF** for OFC results. As expected, we find our method does not yield consistent semantics in OFC.\n\n> **Q2) Clarity in methodology**\n\nWe agree that this could be further clarified. We will provide an updated Figure 2 in an upcoming revision.\n\nThe brain encoder predicts fMRI activations from images. Diffusion models predict the score (derivative of log-likelihood) of the image distribution, and can be treated as a special class of energy-based models. A brain encoder that outputs real-numbers can be interpreted as an energy function [6], the derivative of which can be additively combined with the diffusion to enable conditional sampling of naturalistic images that maximize brain response.\n\n> **Q3) Statistical analysis of human evaluation**\n\nEach of the 10 subject performed 80 binary evaluations per question, we collect 8800 total responses (11 questions, 10 splits, 4 NSD subjects, for both BrainDiVE/real images). Due to space constraints, we provided standard error (SE) measurements in section 5 of the supplemental. We will provide further statistical analysis in an upcoming revision.\n\n> **Q4) Ethical Considerations**\n\nFor 30 subjects, they are between age 22~63, 14 women/15 men/1 unknown, 28 white, 2 black, 1 mixed, 1 unknown. We currently have a ""Broader Impacts"" section in the supplemental, we will update this in the revision to discuss the demographics and additional issues.\n\n> **Q5) Code release**\n\nYes, we will release code and human evaluation data upon acceptance. We have also sent the AC a comment linking to an anonymous repo containing our code.\n\n⠀\n\nWe\'re grateful for your clear and helpful suggestions. In light of our response, we hope you might view our work in a more positive light. Please feel free to let us know if you have additional comments! \n\n⠀\n\n[1] Hierarchical Text-Conditional Image Generation with CLIP Latents\n\n[2] Scaling up gans for text-to-image synthesis\n\n[3] Selectivity for food in human ventral visual cortex\n\n[4] Learning transferable visual models from natural language supervision\n\n[5] Classifier-free diffusion guidance\n \n[6] Reduce, reuse, recycle: Compositional generation with energy-based diffusion models and mcmc'}}, {'rebuttal': {'value': 'We are grateful to all reviewers for their constructive suggestions, which we agree will significantly improve the communication of our work.\n\nWe are very encouraged by reviewers’ evaluation on the quality of this paper. All four reviewers find the work interesting (""methodology shows promise in capturing semantic selectivity"" (MC3H); ""The method can retrieve subtle differences between ROIs"" (fpHd); compared to prior works -- ""this approach only needs an encoding model that can be trained independently"" (SV7e); ""The experiments and visualizations are in good condition and sufficient"" (Vg6A)). \n\n\n### General clarifications\n### 1. Scope and experiments\n\n* We propose BrainDiVE -- a method that utilizes diffusion models to investigate functional specialization in the higher visual cortex. \n* Our work relies on end-to-end differentiable optimization with an image-computable voxel-wise fMRI encoder, and leverages an existing large-scale image diffusion model without retraining. It can be flexibly targeted at arbitrary regions in the visual cortex without retraining.\n* We apply BrainDiVE to explore the brain\'s visual cortex selectivity at three hierarchical levels and offer new scientific insight on the selectivity of different regions. \n    * First, we apply it to widely accepted category selective regions -- faces, places, bodies, food, words.\n    * Second, we apply it to ROIs that code for faces at different levels in the feature hierarchy (FFA, OFA). Our results are in line with the widely held belief that OFA responds to lower level face features relative to FFA. \n    * Third, we apply it to splits within food-selective and place-selective (OPA) ROIs, where we identify potentially novel functional subdivisions.\n* Our evaluation is done in two different ways\n    * For category selective regions, we perform CLIP 5-way classification using natural language. The design of our prompts follow the best practices defined in 3.1.4 of [1]. The prompts are available in section 9 of the supplemental. We observe that BrainDiVE images indeed capture the category specificity of these regions.\n    * For FFA and OFA, which both code for face; subregions of food; and subregions of OPA which codes for scenes -- we perform a human behavioral study to validate the fine-grained visual-semantic attributes. We recruit 10 subjects for each set of comparisons. This results in a total of 8800 total responses (11 questions, 10 splits, 4 NSD subjects, for both BrainDiVE and real images). We report standard error metrics in section 5 of the supplemental. We find that BrainDiVE can highlight differences in preferred attributes between visual regions, suggesting that it can be useful for future data driven exploration of the visual cortex.\n\nThe ROI masks are derived from functional localizer results from the official NSD paper (faces, places, bodies, words, OFA, OPA), or obtained from other authors directly (food) [2].\n\nWe include visualizations of the image synthesis process and brain gradients in **section 4** of the supplemental. We perform a theoretical evaluation of our work in **section 9** of the supplemental. \n\nWe agree in the importance of evaluating the images using real humans, and an effort to collect fMRI data is ongoing.\n\n### 2. Relationship to concurrent and prior work\n\nTo our knowledge, we are the first to apply diffusion models to investigate the selectivity of the human higher visual cortex. Unlike prior work, we are not doing image reconstruction. There is concurrent work by Pierzchlewicz et al. [3] which applies diffusion models to investigate the selectivity of macaque V4, we will cite this in an upcoming revision.\n\nIn our work we cite papers which we believe are highly relevant (in-paper citation numbers): Gu et al. [9], Ponce et al. [10], Murty et al. [11], Takagi et al. [46], Ozcelik et al. [47]. We build upon the insights from these works. Our work is most similar to [9], as we use the same dataset, while [10] uses real-time responses of macaque visual cortex neurons for image synthesis.\n\n* Unlike [9, 11], we perform end-to-end gradient optimization, and do not rely on fixed categories identified via search as in [9], or a softmax relaxation of categories as in [11]. In addition, we use a diffusion model trained on billions of images. Due to this, our synthesized images are not restricted to single object images that dominate the 1000 classes from ImageNet as in [9, 11].\n* Different from [46, 47], we are not performing reconstruction of visual stimuli. Instead, we are proposing to use a diffusion model as a component for the synthesis of novel visual stimuli that is predicted to match the selectivity of a region. We do not rely on a fixed sized input, and regions can be flexibly defined without retraining. [47] achieves intriguing results by setting voxels to 0/1 followed by latent normalization, but this relies on the implicit assumption that voxels outside a region are inactive. \n\nWe will include a more extensive discussion of related work in an upcoming revision. \n\n### 3. New figures/results in response PDF\n1. We further validate the BrainDiVE results using an encoder with an alternative pretrained backbone. We find that the results are robust.\n2. There is a more extensive comparison of BrainDiVE and NeuroGen from Gu et al. This highlights the semantic fidelity and diversity of our images.\n3. We apply BrainDiVE to a region outside the visual cortex, which is not known to have visual selectivity. We confirm that the images do not show consistent semantic trends.\n\nAdditional results will be included in an upcoming revision.\n\n⠀\n\nWe genuinely appreciate the suggestions, and believe our paper will be improved with your feedback. Please let us know if you have any additional questions or comments!\n\n⠀\n\n[1] Learning transferable visual models from natural language supervision\n\n[2] Selectivity for food in human ventral visual cortex\n\n[3] Energy Guided Diffusion for Generating Neurally Exciting Images'}, 'pdf': {'value': '/pdf/0fa77441a3770e6347f9d23304ddc7b540902051.pdf'}}, {'summary': {'value': ""This paper introduces Brain Diffusion for Visual Exploration (BrainDiVE) that aimed at exploring the fine-grained functional organization of the human visual cortex. Motivated by the limitations of previous studies that relied on researcher-crafted stimuli, BrainDiVE leverages generative deep learning models trained on large-scale image datasets and brain activation data from fMRI recordings. The proposed method uses brain maps as guidance to synthesize diverse and realistic images, enabling data-driven exploration of semantic preferences across visual cortical regions. By applying BrainDiVE to category-selective voxels and individual ROIs, the authors demonstrate its ability to capture semantic selectivity and identify subtle differences in response properties within specific brain networks. It is also shown that BrainDiVE identifies novel functional subdivisions within existing ROIs, highlighting its potential for providing new insights into the human visual system's functional properties.""}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""The paper's methodology shows promise in capturing semantic selectivity and identifying fine-grained functional distinctions within visual cortical regions. Also, the paper's potential significance lies in applying BrainDiVE to understand the fine-grained functional organisation of the human visual cortex. \nBy providing insights into category selectivity, response properties, and sub-regional divisions, the paper opens avenues for further exploratory neuroscience studies. \nTo achieve this, the authors perform the experiments in the manuscript are extensive, covering:\n1. the semantic specificity of the method by decoding images from task fMRI and literature-obtained ROIs\n2. compared the abstraction of face representation in the brain by comparing images decoded from two regions, the fusiform face area (FFA) and the occipital face area (OFA). \n3. Use the method to extend knowledge of brain function by finding subdivisions in known areas in the cases of food decoding.\nThe authors describe the experimental setting clearly at the beginning of section 4 for all cases.\nThe experiments show that the manuscript has a good balance between the combination of known methodological approaches and addressing interesting questions in neuroscience. Specifically, the authors perform a commendable effort in obtaining quantitative results using human evaluators (cf Tables 3 and 4).\nFinally, the authors show through results evidence that their method is a window into understanding region-specificity hypotheses of brain regions which are knowingly involved in different aspects of visual processing.""}, 'weaknesses': {'value': 'The paper could benefit from comparing its results with previous contributions [e.g. 9 and 10] to highlight its novelty and contributions in relation to existing methods. \nThe methodology part lacks clarity, particularly in explaining key components like the diffusion model architecture and brain-guided synthesis—further clarifying the role of the image-to-brain encoder in influencing the denoising process during inference.\nThe generalisability and reliability of results are hard to asses through a small dataset, specifically just 10 subjects. \nFurthermore, the paper lacks clarity on how the sub-divisions of the visual cortex are being verified or validated. Whether the results are specific to the analysed regions or the algorithm is being too biased by the experimental condition is not clear through the experiments. For instance, what would happen if the authors try to decode an area not specific to visual processing? An example of this would be using subsections of the orbitofrontal gyrus or other brain areas not expected to perform well in reconstructing visual stimuli.\n\nAs a small point authors should review the presentation of images. Figure 1 shows mostly best-case scenarios which are then not as good in Figure 4 (for instance the case of images generated from face voxels). This might bias readers. Second, some details, such as figure 4 appearing before figure 3 make reading the paper confusing.'}, 'questions': {'value': ""1. Validation of BrainDiVE's Effectiveness:\n  a. Can the authors provide more details on the validation process to ensure that BrainDiVE-generated images indeed effectively activate the targeted brain regions? \n  b. Could the authors consider conducting more extensive comparisons with other existing methods [e.g. 9 and 10], to demonstrate the advantages and uniqueness of BrainDiVE in eliciting specific brain activations?\n  c. Could the authors show the results on decoding a baseline region which is not involved in visual processing?\n\n2. Clarity in Methodology: The methodology part could benefit from more clarity and detailed explanations of key components, such as the diffusion model architecture and the exact implementation of brain-guided synthesis. Improving the architecture in Figure-2 might help.\n\n3. Statistical Analysis of Qualitative Evaluation: As the paper relies on qualitative evaluation with 10 subjects, could the authors mention this explicitly and what limitations are expected from this in the limitations section?\n\n4. Ethical Considerations: Could the authors describe the demographics of the population, or acknowledge the lack of this information to inform of wether the results are biased to a specific gender or population group.\n\n5. Reproducibility: Are the authors intending to release the code and not publicly available data such as the scores produced by the human raters upon acceptance of the paper? This is key to guarantee reproducibility""}, 'limitations': {'value': ""Authors have not addressed the negative societal impact of their work, but this can be fixed by adding specific text in the Discussion section. The authors don't mention the demographic characteristics of the small human subject database that they have used not mention any ethical concerns related to decoding images from brain activations. This is fixable so authors should address it.""}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This study proposes BrainDIVE, a system for synthesizing optimal stimuli for any given region of interest in the brain. The model combines a pretrained latent diffusion model for image generation with a linear “brain encoder” trained to map CLIP feature vectors onto the corresponding brain activity. At test time, a gradient-based optimization iteratively produces an image that maximizes the activity of a predefined set of voxels. The technique is validated on well-known ROIs, producing the expected images. It can also highlight subtle differences between ROIs selective to the same broad category, or functional subdivisions of existing ROIs. The functional hypotheses are validated by human subjects evaluating the properties of the generated pictures. The technique appears simple but can provide meaningful information for neuroscience studies.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '* The method can retrieve subtle differences between ROIs selective for the same class (e.g. OFA and FFA).\n* The method can highlight functional differences between sub-clusters of existing ROIS (e.g. food clusters)\n* The qualitative observations are validated by behavioral evaluations from human subjects. \n'}, 'weaknesses': {'value': '* The Related works section tends to overstate the novelty of the technique. It only mentions NeuroGen as prior work, whereas other prior studies had also attempted to generate optimal stimuli for specific ROIs: for instance, Ratan Murty et al (2021), Ozcelik et al (2022), Ozcelik et al (2023). The latter also used a diffusion model for image generation, as done here. Furthermore, you seem to be aware of at least some of these studies, since you criticized one of them in your Methods section for using a “hand-derived” prior. It would be much better to properly acknowledge all these studies in the Related works section, and clarify your method’s advantages/disadvantages (e.g. no hand-derived prior/time-consuming iterative method).'}, 'questions': {'value': '* I do not understand why you systematically need to report the top-5 or top-10 out of 500 generated images? Do I understand correctly that the pool of 500 are all generated for the same objective (ROI maximization)? If yes, then what does this imply about the remaining 99% of images? Are they worse than NeuroGen? Are they actually failure cases? What do the worse 1% of images look like? If they are not representative of the expected category, does that invalidate your optimization method?\n* Appendix, section 9, training objective: this section is useful to understand the image optimization process. One thing I do not understand from this section or from Figure 2 is why the optimization is performed in the diffusion latent space, rather than in CLIP space? Why do the gradients have to flow all the way into the diffusion model? Couldn’t you iteratively optimize the $CLIP_{img}$ vector for the same objective, and then use it to condition the diffusion model in one pass (as you would with a text prompt)? This should be computationally more efficient, and I don’t see any reason why it would be less accurate. \n'}, 'limitations': {'value': 'Limitations are properly acknowledged.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper presents a new algorithm to guide a diffusion model to decode maximally activating images for particular voxel subregions of human fMRI using an encoding model trained to predict brain activity from images. The algorithm identifies stereotypic features for defined ROIs, such as faces or food items. The authors evaluate the specificity of the reconstructed image with CLIP zero-shot classification and human evaluation. They also cluster the encoding model weights and find that the clusters result in perceivable semantic categories in the reconstructed images. This algorithm allows for more fine-grained analysis of preferences across the visual system. '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'There have been many papers that reconstruct images from brain activity. However, all of them require some form of retraining the diffusion model. This approach only needs an encoding model that can be trained independently. \n\nThe extensive human evaluation is great. While this goes beyond what I would ask for a NeurIPS paper, I think it would be great to also verify them by showing them back to human subjects. '}, 'weaknesses': {'value': ""The authors show that the reconstructed images possess stable properties that can be identified by humans and by a CLIP network. However, they don't show that the images also do what they are supposed to do, which is activate a particular subnetwork. While human experiments probably go beyond the scope of this NeurIPS paper, one way to do that would be to take **another** encoding model for the same neural activity, take it as a proxy for the brain and show the images to that. \n""}, 'questions': {'value': ""Q1: As far as I understand $\\gamma$ trades off between the denoising gradient and the maximization gradient. I couldn't find what value you set it too, or how you chose it. \n\nQ2: There is a preprint that describes pretty much the same idea as in the paper but uses it for V4 single neurons:\n\nPawel A. Pierzchlewicz, Konstantin F. Willeke, Arne F. Nix, Pavithra Elumalai, Kelli Restivo, Tori Shinn, Cate Nealley, Gabrielle Rodriguez, Saumil Patel, Katrin Franke, Andreas S. Tolias, Fabian H. Sinz Energy Guided Diffusion for Generating Neurally Exciting Images\nhttps://www.biorxiv.org/content/10.1101/2023.05.18.541176v1\n\nIf one looks at the date, the preprint has been submitted around the NeurIPS deadline, so it's unlikely that the authors were aware of it and I would consider this as a case where two groups had the same idea. However, I think it would be fair to mention/cite them.  \n\nQ3: Can you discuss the compute time required for a single image?\n""}, 'limitations': {'value': 'Limitations are discussed. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes a diffusion-based method for fMRI-guided image synthesis and claims that it can identify the selectivity of various ROIs in the visual cortex. The motivation of this work is well-defined and is of vital importance to the computational neuroscience field. While the method in this work is intuitive and lacks machine learning depth.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'Strengths: \n* Interesting scientific field and question of neuroscience.\n* The paper is well-written and has a smooth and concrete flow.\n* The experiments and visualizations are in good condition and sufficient.'}, 'weaknesses': {'value': ""Weaknesses\n\n* The method used in this paper is heuristic and lacks technical depth. \n    * Generating or reconstructing images from fMRI is not a new idea, as has been proposed in [1], etc.\n    * CLIP is an off-the-shelf large-scale pre-trained model, performing conditional diffusion-based generation with embedding from CLIP or Stable Diffusion is stereotyped [2,3].\n    * In Section 3.3, the domain-specific techniques you designed for this specific task are just some first-order tricks (i.e., linear combination of S, euler approximation). Maybe these tricks are effective enough, but that's overly empirical.\n* The experimental section is empirical and lacks theoretical analysis. Your analysis of the fMRI encoder with ROIs is interesting, but little focus had been put on what's the scientific relationship of neuroscience and diffusion model.\n\n\n\n[1] https://www.biorxiv.org/content/10.1101/2022.11.18.517004v3\n\n[2] https://arxiv.org/abs/2112.10752\n\n[3] https://arxiv.org/pdf/2208.01618.pdf""}, 'questions': {'value': 'Please consider the things listed in the “Weaknesses” section.\n\nAlso please consider providing information regarding the interpretability of the utilization of the diffusion model in your context.'}, 'limitations': {'value': 'To my knowledge and understanding, there is no potential negative societal impact of this work. Other limitations please see “Weaknesses”.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Brain Diffusion for Visual Exploration: Cortical Discovery using Large Scale Generative Models'}, 'authors': {'value': ['Andrew Luo', 'Margaret Marie Henderson', 'Leila Wehbe', 'Michael J. Tarr']}, 'authorids': {'value': ['~Andrew_Luo2', '~Margaret_Marie_Henderson1', '~Leila_Wehbe1', '~Michael_J._Tarr1']}, 'keywords': {'value': ['neuroscience', 'brain', 'fmri', 'generative models', 'diffusion models', 'image synthesis', 'visual cortex']}, 'abstract': {'value': 'A long standing goal in neuroscience has been to elucidate the functional organization of the brain. Within higher visual cortex, functional accounts have remained relatively coarse, focusing on regions of interest (ROIs) and taking the form of selectivity for broad categories such as faces, places, bodies, food, or words. Because the identification of such ROIs has typically relied on manually assembled stimulus sets consisting of isolated objects in non-ecological contexts, exploring functional organization without robust a priori hypotheses has been challenging. To overcome these limitations, we introduce a data-driven approach in which we synthesize images predicted to activate a given brain region using paired natural images and fMRI recordings, bypassing the need for category-specific stimuli. Our approach -- Brain Diffusion for Visual Exploration (""BrainDiVE"") -- builds on recent generative methods by combining large-scale diffusion models with brain-guided image synthesis. Validating our method, we demonstrate the ability to synthesize preferred images with appropriate semantic specificity for well-characterized category-selective ROIs. We then show that BrainDiVE can characterize differences between ROIs selective for the same high-level category. Finally we identify novel functional subdivisions within these ROIs, validated with behavioral data. These  results advance our understanding of the fine-grained functional organization of human visual cortex, and provide well-specified constraints for further examination of cortical organization using hypothesis-driven methods.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/92e3925bf5b5af1eeee5bb0e2ccb57871bce879b.pdf'}, '_bibtex': {'value': '@inproceedings{\nluo2023brain,\ntitle={Brain Diffusion for Visual Exploration: Cortical Discovery using Large Scale Generative Models},\nauthor={Andrew Luo and Margaret Marie Henderson and Leila Wehbe and Michael J. Tarr},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=9VqMaSjf7U}\n}'}, 'paperhash': {'value': 'luo|brain_diffusion_for_visual_exploration_cortical_discovery_using_large_scale_generative_models'}}]"
"['Shibo Hao', 'Tianyang Liu', 'Zhen Wang', 'Zhiting Hu']",NeurIPS,ToolkenGPT_ Augmenting Frozen Language Models with Massive Tools via Tool Embeddings,https://neurips.cc/virtual/2023/oral/73868,2023," Integrating large language models (LLMs) with various tools has led to increased attention in the field. Existing approaches either involve fine-tuning the LLM, which is both computationally costly and limited to a fixed set of tools, or prompting LLMs by in-context tool demonstrations. Although the latter method offers adaptability to new tools, it struggles with the inherent context length constraint of LLMs when many new tools are presented, and mastering a new set of tools with few-shot examples remains challenging, resulting in suboptimal performance. To address these limitations, we propose a novel solution, named ToolkenGPT , wherein LLMs effectively learn to master tools as predicting tokens through tool embeddings for solving complex tasks. In this framework, each tool is transformed into vector embeddings and plugged into the language model head. Once the function is triggered during text generation, the LLM enters a special function mode to execute the tool calls. Our experiments show that function embeddings effectively help LLMs understand tool use and improve on several tasks, including numerical reasoning, knowledge-based question answering and embodied decision-making.",Oral 3B NLP/Tools,https://openreview.net/pdf?id=BHXsb69bSx,https://openreview.net/forum?id=BHXsb69bSx,BHXsb69bSx,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The authors propose ToolkenGPT, an approach to teach language models to use tools that requires no modifications of the underlying parameters of the LLM. Essentially, separate embeddings (tool tokens -> toolkens) are learned in the output layer of  the LLM. These separate embeddings, when used in generation, invoke tool use. The reviewers have a consensus that this paper is innovative, scales well for use with many tools, and they like the efficiency and modularity of the approach. There were some concerns about how the approach fares against fine-tuning, which was addressed by the authors. Essentially, the model outperforms zero-shot and few-shot baselines handily, but is not quite as performant as fine-tuning. This makes sense, given that the underlying LLM parameters are frozen. However, the benefits of ToolkenGPT are that it can be easily extended to new tools, is much cheaper to adapt (since underlying LLM parameters can remain fixed, although their gradients do need to be estimated to update the too lembeddings), and moreover, does not harm the generation quality of the LLM through catastrophic forgetting. All reviewers agree that the paper makes a solid contribution to the field, and we hope that the reviews and discussions during the rebuttal paper make it into the final version of the paper (i.e. more detailed discussion of fine-tuning, terminology change of “massive tools” -> “massive amounts of tools”, clarifications about what is meant by “plug-and-play”, etc.).'}}, {'comment': {'value': ""Thank you for your response. I have reviewed the reply and stick with my original score, which is already quite high.\n\nI think the inclusion of RTable 1 is useful - as this is a parameter-efficient method, it is expected that it doesn't perform quite the same as some more resource-hungry approaches.\n\nHowever, RTable 2 doesn't seem particularly useful. It just shows that Toolformer was trained for longer using more powerful GPUs - something that could be easily done with ToolkenGPT as well. Without knowing the performance, or at least training time, for both systems, there is no real comparison point.""}}, {'comment': {'value': 'Thank you for providing the detailed responses. My concerns are well addressed.'}}, {'title': {'value': ""Response to Author's Rebuttal""}, 'comment': {'value': 'Thank you for providing the detailed responses. I have read it carefully and hope the additional experiments will go into your future version.'}}, {'comment': {'value': 'With respect to (a) I think including this line of experiment into the paper will be important. It seems like based on RTable 1 the conclusion is  that full fine-tuning reaches better accuracy, but at a high computation cost. It would be nice for the final version of the paper to emphasize the computation cost vs accuracy trade-off.\n\nThanks for clarifying (b) and (c). I think including that information in the paper will be useful.\n\nI\'m happy you\'re planning to revise/clarify the ""plug and play"" term (d). While it\'s perhaps a small point, I still find the term ""Massive tools"" a bit misleading. ""Massive tools"" seems to imply the tools are individually complex. But it seems like what you\'re trying to emphasize is that the model can handle many tools (regardless of their individual complexity). Anyways, it\'s a small thing but maybe worth some thought.\n\nOverall, thanks for the additional experiments. I trust the new results/clarifications will be added to the final version of the paper and I have accordingly recommended acceptance of the paper.'}}, {'title': {'value': 'Correction: Computing resource for finetuning (LoRA)'}, 'comment': {'value': 'There is a typo in the RTable 1: finetuning (LoRA) indeed used 8 x A100 (80G), instead of 1 x A100. So it costs much more computing resources than ToolkenGPT.'}}, {'rebuttal': {'value': 'We are grateful to all reviewers for their detailed and constructive feedback! We are encouraged to see that reviewers find:\n- Our proposed ToolkenGPT is an ""innovative, novel and useful"", ""a novel yet elegant way"" (R-C7TV, R-xBHJ, R-QLCo, R-Mpoh), which ""brings up new ideas"", ""fosters more research"" and ""pushes forward the area of research"" on tool-augmented LLMs (R-xBHJ, R-5YmU, R-QLCo);\n- ToolkenGPT is ""efficient, yet to learn and extend"" (R-Mpoh), offers a ""much more efficient"" method (R-5YmU) that ""scales well to a massive number of tools with limited examples"" (R-C7TV);\n- Our ""experimental setup is sound"" with ""well-designed baselines"" (R-QLCo), our ""empirical results on multiple domains"" verify its advantage (R-5YmU), ""the evaluation is comprehensive and convincing"" (R-Mpoh)\n- ToolkenGPT ""is easy to implement and is able to be applied for various domains"" (R-5YmU), and we ""provide enough information for reproducing the experiments"" (R-QLCo)\n\nWe have addressed all the questions raised by reviewers with additional experiments and thorough clarifications via separate responses to each reviewer. There are two common concerns we would like to address in the global response.\n\n(a) **Comparison with full-model fine-tuning**. As shown in Table 1 from the paper, there are many advantages of ToolkenGPT in comparison with full-model fine-tuning, including training efficiency, quick adaptation to new tools, scaling to massive tools with limited examples, etc. While most reviewers agree on the above advantages, it is also interesting to compare with the full-modal fine-tuning, in terms of computation efficiency and performance. We implement different methods with Llama-7B on FuncQA, and show the comparison in RTable 1.\n\nRTable 1: Comparison between ToolkenGPT and finetuning (using LoRA) in terms of training cost and performance on FuncQA dataset (using Llama-7B).\n\n| Model           | One-hop  | Multi-hop | Computing Resource  | Training Time (all) |\n|-----------------|---------|----------| ---|---|\n| Fine-tune w/ LoRA |   0.62 |     0.074 | 1 \\* A100 (80G) | ~40 min |\n| ToolkenGPT |   0.55  |     0.058 |  1 \\* RTX3090 (24G) | ~ 2 min |\n| ReAct | 0.40   |  0.030  | - | -  |\n| Baseline | 0.10  |  0.00    | - | - |\n\nThough finetuning performs better than ToolkenGPT, it\'s significantly more expensive. Even though we use LoRA (parameter-efficient finetuning) and more computing resource (e.g., GPU memories, to increase the batch size), finetuning still costs about 20× more time than training toolken embeddings.\n\nWe also compare ToolkenGPT and Toolformer [1], a recent full-model fine-tuning method, in terms of efficiency on the learning of mathematic tools. Note that it\'s infeasible for us to compare performance, as Toolformer is not open-sourced and is based on GPT-J, a different base LM than ours (Llama). It\'s also computationally infeasible for us to reproduce Toolformer, given the extreme computational cost as shown in the table below.\n\nRTable 2: Comparison between ToolkenGPT and Toolformer (math).\n\n| Method | Computing Resource | Number of Training Examples |Time (per epoch)|\n|---|---|---|---|\n| ToolkenGPT (30B) | 4 \\* RTX3090 (24GB) | 5k | ~16min |\n| ToolkenGPT (13B) | 2 \\* RTX3090 (24GB)| 5k | ~7min |\n| ToolkenGPT (7B) | 1 \\* RTX3090 (24GB)| 5k | ~5min |\n| ToolFormer | 8 \\* A100 (40GB) | 25k (only for math) | Unknown |\n\nRTable 2 presents the comparison of computing resources and time for training our ToolkenGPT and Toolformer. It\'s clearly evident that our ToolkenGPT can be trained with much less computing resources, compared with the full-model fine-tuning method, Toolformer. Note that Toolformer\'s training time is not reported in the original paper.\n\n(b) **Plug-and-play capacity of ToolkenGPT**. As mentioned by R-C7TV and R-QLCo, the definition of ""plug-and-play"" in Table 1 of the paper could be further clarified. By “plug-and-play”, we mean that new toolken embeddings are disentangled with other parameters, and can be enabled/disabled or directly added to an existing tool set effortlessly. The ""plug-and-play"" defined in the paper doesn\'t mean there is no need to train the embedding, but refers to that we are able to reuse the trained toolken embeddings and plug them into any downstream settings flexibly when needed. We will clarify this term in the updated paper.\n\nBesides, it\'s also possible to train toolken embeddings without preparing training data manually. As demonstrated in Section 4.1 (FuncQA) and 4.2 (ToolkenGPT-syn), we can synthesize the training data for new tools. We can observe that ToolkenGPT (syn)---no in-domain training data is used---outperforms strong CoT baselines.\n\n**References**\n\n[1] Schick, Timo, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. ""Toolformer: Language models can teach themselves to use tools."" arXiv preprint arXiv:2302.04761 (2023).\n\n[2] Miao, Shen-Yun, Chao-Chun Liang, and Keh-Yih Su. ""A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers."" In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 975-984. 2020.'}}, {'rebuttal': {'value': ""We thank Reviewer 5YmU for acknowledging that our proposed method is much more efficient, easy to implement, and can be applied to various domains to foster more research in the field of tool-augmented LLMs. We also thank the reviewer for spotting several typos and we will fix them all in the revised version. Below we resolve the reviewer's concerns and questions.\n\n(a) **Baseline of ReAct w/ ChatGPT**. We understand the reviewer's concern regarding the potential limitation of ToolkenGPT in its inability to be applied on closed-sourced LLMs like ChatGPT. From the perspective of the open-sourced community, we agree that a comparison with a baseline of ReAct w/ ChatGPT would provide a broader context and help further validate the efficacy of our method. As shown in Table 2, we already compare our method with ReAct but based on the same based model (LLaMA-30B), mainly for a fair comparison. As ChatGPT is a much stronger base model than LLaMA-30B, applying ReAct to ChatGPT is expected to boost the performance. However, our ToolkenGPT should also be benefited from stronger open-sourced LLMs, like the recent Llama 2 models, which we believe should be an interesting future work to explore.\n\n\n(b) **Ablation study**. Thanks for the great suggestion! To better assess the benefit of each component of ToolkenGPT, we conduct an ablation study for the two main components of our method - toolken embedding and sub-routine of tool call (tool mode) as follows. \n\nRTable 4: Ablation study on tool embeddings and tool mode.\n\n| Method | FuncQA (one-hop) | FuncQA (multi-hop) |\n| -------- | -------- | -------- |\n| ReAct     | 0.57     | 0.06     |\n| ReAct + tool mode     | 0.60     | 0.07     |\n| ToolkenGPT | 0.73 | 0.15 |\n\nRTable 4 is closely related to Table 2 from the paper, where we use a hard math dataset, FuncQA with 13 math tools. We further implement a baseline of combing ReAct prompt and the sub-routine of tool call (tool mode) from our ToolkenGPT. As shown in this table, the tool mode used in ToolkenGPT could help improve the correctness of tool calling and marginally improve the vanilla ReAct prompting method. We also see that ToolkenGPT still outperforms this improved baseline by a large margin, indicating that our toolken embeddings still outperform ReAct greatly in terms of deciding when and which tool to call. We hope these additional results could help provide clear evidence of the contribution of each component to the performance of ToolkenGPT.\n\n\n(c\\) Comparing with fine-tuning approaches. Please refer to the global response (b) for addressing the comparison with full-model fine-tuning methods, like Toolformer.""}}, {'rebuttal': {'value': ""We thank reviewer Mpoh for acknowledging that our proposed method is novel and elegant to learn massive tools efficiently, and makes a good contribution to the field of tool learning. We address the reviewer's comments on the evaluation as follows:\n\n(a) Comparing with full-model fine-tuning. Thanks for the great comment! For the comparison with Toolformer, please see our global response (a).\n\n(b) **Consider different tools simultaneously**. Thanks for the great suggestion and we appreciate the interesting setting pointed out by the reviewer. We initially focused on demonstrating the potential of ToolkenGPT in a scenario where a set of task-specific tools are used to solve one single task. As the reviewer mentioned, we've tried our best to increase the number and the diversity of such tools, i.e., 13 tools in math, 234 tools in KBQA, and 58 tools in VirtualHome. Since these tools are created for similar goals in specific tasks, they somehow are related to each other due to the nature of the evaluated tasks. Considering distinct tools, like QA and calculator, would require creating more challenging scenarios and tasks. We believe that such a set of experiments involving multiple, diverse tool calls could further highlight the flexibility and capability of ToolkenGPT, which serves as a realistic, multi-tool scenario for future works. \n\n(c) **Influence of Toolken on LLM generation**. Thanks for such an interesting comment! The potential influence on language generation is an interesting angle to discuss further. First of all, the training of toolken won't affect the generation capability of LLMs, as it doesn't change any pre-trained parameters for the generation. Second, for some NLG tasks like the summarization task that don't require external tools, the pure generation capacity from LLMs is enough, and thus, we can easily disable the learned tools by masking their toolkens in the output vocabulary, keeping the original generation capacity intact. This serves as a demonstration of the plug-and-play capacity of ToolkenGPT, as explained in the global response (a). \n\nLast but not least, in the most generic setting where we just keep the learned toolken embeddings and simply prompt the LLM for a generation task, we conducted an additional experiment to test the influence of toolken embeddings on NLG tasks. Specifically, we leverage the trained toolkens from math datasets and apply ToolkenGPT to two data-to-text generation datasets, WebNLG [1] and E2E [2]. We performed 10-shot learning (_randomly picked_) on the dev set of the WebNLG dataset (872) and the test set of the E2E dataset (630). We report the traditional NLG metrics, ROUGE-2 score from Huggingface evaluate and use greedy decoding for the generation.\n\nRTable 3: Performance of ToolkenGPT on NLG tasks.\n\n| Dataset      | Llama-30B | Llama-30B w/ toolkens | \\#Func Calls |\n|--------------|----------|-----------------------|------------|\n| WebNLG      | 0.56     | 0.56                  | 0          |\n| E2E       | 0.46     | 0.46                  | 0          |\n\nRTable 3 shows that the inclusion of toolkens does not have any influence on the generation capabilities of LLMs on these two NLG tasks. As we can see from RTable 3, toolkens are not activated during the generation with the number of function calls as zero. However, in rare cases where the generation tasks are very similar to the toolken training text, the LLM may mistakenly call external tools, which is an interesting problem to investigate in the future. Nonetheless, we hope these additional results could further clarify the impact of toolken embeddings on NLG tasks and we will include them in the revised version.\n\n**References**:\n\n[1] Claire Gardent, Anastasia Shimorina, Shashi Narayan, and Laura Perez-Beltrachini. The WebNLG challenge: Generating text from RDF data. ICNL, 2017.\n\n[2] Jekaterina Novikova, Ondřej Dušek, and Verena Rieser. The E2E dataset: New challenges for end-to-end generation. arXiv preprint arXiv:1706.09254, 2017.\n""}}, {'rebuttal': {'value': ""We thank the Reviewer xBHJ for acknowledging that our method is novel and useful, and will push forward the field of tool-augmented LLMs. We appreciate the reviewer's great suggestions and questions. We will further proofread the paper and fix the typos in the final version. Herein, we address the reviewer's questions as follows:\n\n(a) **Choices of baselines**. Thanks for the thoughtful comment! We thank the reviewer for recognizing the coverage of our evaluation and please refer to our global response (a) for following the reviewer's suggestion to compare with Toolformer and fine-tuning a model on similar data. \n\n(b) **Training data generation and filtering**. Thanks for the great clarification question and we apologize if the process of generating training data is not very clear in the experiment section. As shown in the appendix, for math datasets, we prompt ChatGPT to produce questions and their corresponding answers. Instead of giving specific numbers, we instruct the model to use placeholders that follow our particular format. We retain only those cases that are parsable and align with our format requirements. Afterward, we programmatically assign random numbers and compute the results.\n\nFor example, \n```\nQuestion: If the price of a stock increases by 10% every day, by how many times will its initial value increase after [ARG_0] days?\nAnswer: After [ARG_0] days, the value of the stock will increase by a factor of 1.1^[ARG_0]=<power>(1.1, [ARG_0])=[ANSWER] \nArgs: ['int']\n```\n(c) **Number of synthetic data examples**. Regarding the training samples we synthesized, for the math dataset FuncQA, we synthesize 50 examples for each operation; for KAMEL, we synthesize at most 50 examples per relation (some examples are not successfully parsed and removed from the dataset, leading to 40 examples on average per relation).\n\n(d) **In-context learning on 234 tools**. Thanks for the question! It would be infeasible to fit all tool examples into the context. As indicated in Section 4.2 and Figure 2, we tried our best to fit as many tools into the context, reaching the 2048-tokens limit of LLaMA, which is about . The detailed mechanism of this baseline will be clarified in the revised version.\n\n(e) **Discussing potential risks of connecting LLMs with external APIs**. We appreciate this great comment on the potential risks of tool-augmented LLMs. We believe addressing such a potential risk requires community-wide efforts. We will delve deeper into this issue in the future work section of our revised paper.\n""}}, {'rebuttal': {'value': 'We thank the reviewer C7TV for acknowledging that our method is innovative, effective and scales well to massive tools with limited examples. Below we address the reviewer\'s comments and questions point by point.\n\n(a) Computation costs and performance. Thanks for the great comment! We understand the importance of demonstrating computational efficiency and we present additional results on computation resources and performance in global response (a) and we will include such results in the revised version.\n\n(b) Comparing with full-model fine-tuning. Thanks so much for the great suggestion! Please refer to the global response (a) to see a direct comparison with full-model fine-tuning.\n\n\\(c\\) Clarifying Plug-and-play capability. Thanks for this great clarification question! We made an explanation of the term plug-and-play in the global response, and we will update the paper in the final version to make it clearer.\n\n(d) Feasibility of instruction tuning. We appreciate this great suggestion! Based on our understanding, instruction tuning for tools shares a great overlapping with full-model fine-tuning using the same training data, as explained in the previous response (b). Some minor revisions might include mixing multi-tool data together and changing the prompt format a little bit. Therefore, we believe instruction tuning could be feasible with the same training data, although the computation cost may vary depending on the training methods for the instruction tuning. Further investigation into this direction of tuning the full model on a collection of API instructions is a very promising direction for the future research of tool-augmented LLMs.\n\n(e) Zero-shot plug-and-play for new tools. Thanks for the great suggestion! Please refer to our general response (b) for discussing the ""plug-and-play"" capacity of ToolkenGPT.\n'}}, {'rebuttal': {'value': 'We thank reviwer QLCo for acknowledging that our approach is new, innovative and interesting, brining up new and useful ideas to the field. Below we address all the reviewer\'s concerns and questions.\n\n(a) Comparing with full-model fine-tuning. We appreciate that the reviewer acknowledge that our proposed ToolkenGPT allows for more tools with more details than few-shot and is much cheaper than fine-tuning. We agree that a comaprison with full-model fine-tuning would bolster our evaluation and help clarify the unique advantages of our method. We explicitly address such an important comparison in the global response (b). \n\n(b) **Training data for ToolkenGPT (sup) and ToolkenGPT (syn)**. We appreciate the great observation from the reviewer and provide further experiment results to investigate the influence on training sample quantity and quality. Specifically, we sample 10/20/40 training examples of each tool for both ToolkenGPT (sup) and ToolkenGPT (syn), and report the accuracy on the 30-tools testset.\n\nRTable 5: Influence of training quantity and quality on ToolkenGPT.\n\n| # Examples per tool | ToolkenGPT (syn) | ToolkenGPT (sup) |\n| -------- | -------- | -------- |\n| 10     | 0.364     | 0.564     |\n| 20     | 0.464     | 0.896     |\n| 40     | 0.524     | 0.948     |\n\nRTable 5 shows the performance of ToolkenGPT (sup) and ToolkenGPT (syn) under the same amount of training data. As we can see, both the size and source of training data matter here, and the supervised data clearly contribute to the higher performance in the Figure 2 of the paper. We will include such ablation study into the revised version and we hope this could clarify the question from the reviewer. \n\n(c\\) **Tool selection for ICL baseline**. We appreciate the reviewer for mentioning this very important detail. To illustrate this process clearly, let\'s index all the relations from 1 to 234. As explained in Line 273 of the paper, we have 4 datasets that involve the relations 1-30 (30-relation dataset), 1-60 (60-relation dataset), 1-100 (100-relation dataset), 1-234 (234-relation dataset), respectively.\n\n- The prompt for `ICL` includes the descriptions and the demonstrations of relations 1-30.\n- The prompt for `ICL (desc)` inclues the descriptions of relations 1-30 (for the first dataset) or 1-60 (for other datasets), and demonstrations of 8 random relations. \n\nIt\'s worth noting that, even in the cases where `ICL` / `ICL (desc)` has access to every helpful tools for the dataset, i.e., for the 30-relations dataset, the performance is still inferior to ToolkenGPT (see Figure 2, datapoints in the first column). This indicates that even if the context length limit is resolved, in-context learning methods could still struggle to choose from massive tools. We hope this will clarify the question from the reviewer and we will clarify this detail clearly in the revised version.\n\n(d) **Comparison between fine-tuning, few-shot and ToolkenGPT**. We thank the reviewer for brining up this clarification question. First, we refer the reviewer to the global response (a) for a comprehensive comparison with fine-tuning. We also address the comment on the ""plug-and-play"" capaciy of ToolkenGPT in the global response (b). To sum up, we understand the reviewer\'s concern on the overlapping between ""frozen LMs"" and ""plug-and-play"". The aspect of ""frozen LMs"" in our paper focuses on the training efficiency, while ""plug-and-play"" is more challenging and requires more elegant design of parameters/prompts to reuse previous tools and plug them into new tasks. \n\nRegarding the definition of ""Massive tools"", we mean a large collection of tools that our model can learn and utilize. We agree that fine-tuning methods can learn such tools, but the innovation in our work is the ability to learn them with quick adaption and without exhaustive fine-tuning. When massive tools are presented, fine-tuning requires more training data (because we have more parameters to optimize) and more computing resources, which is costly to obtain, while our ToolkenGPT can ""scales well to a massive number of tools with limited examples"" mentioned by R-C7TV. More importantly, an implicit characteristic of ""massive tools"" is the dynamics of tools such that new tools are kept invented and updated every day. Thus, the growing massive tools make fine-tuning prohibitive to update model parameters frequently. We hope such a more detailed explanation could resolve the reviewer\'s concern and we will definitely clarify such a comparison more clearly in the revised version.'}}, {'summary': {'value': ""This study introduces an approach to teach Large Language Models (LLMs) to utilize numerous tools through learning embeddings for these tools. The embeddings are incorporated into the LLMs' output layer, invoking the use of tools at relevant steps. The inference process alternates between reasoning and tool-use modes to tackle novel tasks. Empirical results validate the efficacy of ToolkenGPT in utilizing a massive number of tools across various tasks, including numerical reasoning, knowledge-based question answering, and embodied plan generation.""}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The proposed method is innovative and scales well to a massive number of tools with limited examples.\n- The method is effective across a variety of tasks and demonstrates advanced multi-turn planning capability.\n- The paper is well-structured and clearly written.'}, 'weaknesses': {'value': ""- While the authors assert the training efficiency of ToolkenGPT, empirical results reflecting computation costs and performance comparisons are missing.\n- Given the current feasibility of instruction tuning (e.g., Alpaca, Vicuna), it would be beneficial to compare the proposed method with the fine-tuning of the entire model using the same training data. This comparison could clarify if there's a tradeoff between performance and computation cost.\n- Although the authors claim a plug-and-play capability for ToolkenGPT, this feature hasn't been evaluated in the empirical studies. Additionally, if I understand correctly, we still need to train the embeddings for new tools. The authors should clarify this plug-and-play capability in more detail.""}, 'questions': {'value': '- Is it possible to perform instruction tuning using the same training data?\n- Can ToolkenGPT facilitate the zero-shot plug-and-play utilization of new tools?'}, 'limitations': {'value': 'The authors have discussed the limitations thoroughly.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper presents ToolkenGPT, a framework for extending LMs with tool use. For each new tool, a new token is added to the output vocabulary of the LM and the embedding for that token is trained with annotated or synthetic examples. When the LM generates that token, the model is switched to a different mode and prompted with examples for that particular tool in order to generate the necessary arguments for that tool call. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The method seems novel and useful, pushing forward the area of research on extending LM capabilities by teaching them to call external tools.'}, 'weaknesses': {'value': 'Evaluation on three different types of tasks is great. However, the choice of baselines is the main weakness of the paper. The method seems to use substantial amounts of data for fine-tuning the token embeddings, whereas all the chosen baselines are only restricted to zero-shot or few-shot prompting. Comparison with Toolformer, which fine-tunes the whole model using similar data, would be more fair.\n\nThere are a number of writing errors. Please make sure to proof-read the paper.'}, 'questions': {'value': 'On line 152, ""and does requires the gradients of LLM parameters"" should presumably be ""and does not require the gradients of LLM parameters""?\n\nWhen generating the training data, do you do any filtering to make sure that the tool can actually correctly handle the given query? Seems like that would help.\n\nFor most of the tasks it is unclear how many synthetic data examples you generate. Please clarify.\n\nWith in-context learning and 234 tools to describe, are you actually able to fit all the tool examples or descriptions into the context? Or does some of this information simply get truncated? Please clarify.'}, 'limitations': {'value': 'The potential risks of letting LMs make calls to external APIs, with automatically generated arguments, should also be addressed.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents ToolkenGPT, a novel approach to generalizing LLMs to massive external tools. The key is to represent each tool as a ""token"", such that when LLMs generate the tool token(toolken), the associated tool will be invoked and executed. The learning of toolken is easy and efficient since there is no need to update the whole LLMs or backward the gradients through LLMs. Toolkens are appended at the last layer of the LLMs, making the cost similar to just doing inference. The authors have conducted extensive experiments and compared to proper baselines. The results are convincing.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The proposed method could make a good contribution to tool learning. In particular, the use of toolken is a novel yet elegant way to solve the massive tools adaption and generation problem.\nThe proposed method is efficient, yet to learn and extend. \nThe paper is clearly written and easy to follow.\nThe evaluation is comprehensive and convincing.'}, 'weaknesses': {'value': 'It would make the evaluation stronger if the authors can include some of the following experiments: \n\n1. Lacking comparison with fine-tuning-based methods, e.g., toolformer. In Numerical Reasoning tasks, I believe these methods could work quite well.\n\n2. The target is the massive tool-learning scenario,  it would be great to try some tasks that involve multiple quite different tool calls at the same time, e.g., qa and calculator. Although the experiments on VirturalHome are great, these 58 tools are mostly similar.\n\n3. Testing whether the training and inclusion of toolken will affect the language generation capacity, i.e., adding some NLU tasks to see if there is any performance drop.'}, 'questions': {'value': 'NA'}, 'limitations': {'value': 'NA'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes a new method to help LLM utilize tools. Essentially, the method trains an additional output embedding token (toolken) for each tool. During inference, if LLM outputs a toolken, a special routine of using the corresponding tool is triggered and the returned result of the tool is then replaced with the toolken for continual inference. As a result, the proposed method can accommodate more tools and unfamiliar tools, compared to in-context prompting approaches like ReAct. The author has shown the effectiveness and advantage of the proposed method across multiple domains including math reasoning, knowledge based QA and embodied AI.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""1. Compared to full model finetuning like Toolformer or TALM, the proposed method is much more efficient as it doesn't require gradient of LLM parameters and only tunes an additional output embedding matrix. \n2. Empirical results on multiple domains verified the advantage of ToolkenGPT over ReAct, as it can better accommodate more tools.\n3. ToolkenGPT is easy to implement and is able to be applied for various domains, which can potentially foster more research on the direction of enhancing LLMs with tools.""}, 'weaknesses': {'value': '1. several typos are present: a) line 2, missing period after ""problems""; b) line 92, missing space ""whichhelps""; c) line 204, versatile *and* adaptive; d) line 234, 503.2 --> 50*3.2\n2. One limitation is ToolkenGPT requires access to model activations thus not capable of being applied on closed-sourced LLMs like ChatGPT, while pure prompting method like ReAct doesn\'t have such limitation. As such, it\'s desirable to compare with a baseline of ReAct w/ ChatGPT. However, in the experiments, the author only compare with ChatGPT with 0-shot prompting (Table 2)\n3. There are two parts of the proposed methods: toolken embedding and sub-routine of tool call. It\'s desirable to show some ablation of the latter part. For example, show a baseline of ReAct + sub-routine of tool call with demonstrations. In this way, readers can better assess the benefit of each component of proposed method'}, 'questions': {'value': '1. The paper did not provide empirical comparison between ToolkenGPT with finetuning approach like Toolformer and TALM. Though you mentioned that ToolkenGPT requires much less GPU memory than those methods, is it possible to provide some empirical comparison to those methods?'}, 'limitations': {'value': 'The author has adequately discussed the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors propose ""ToolkenGPT."" This method allows language models to take advantage of external tools without full model fine-tuning, and with the ability to show more tools and with greater detail than in-context learning typically allows. They show that use of ""toolkens"" (tool tokens) improves performance over baselines on arithmetic, knowledge-base QA, and embodied plan generation.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""In terms of originality, the paper introduces a new and innovative approach to external tool access for language models. It seems like a hybrid of fine-tuning and few-shot learning, but uses both in a novel and interesting way. Though there's not much direct comparison to prior work, it is at least acknowledged.\n\nIn terms of quality, the experimental setup is sound. It seems evident that ToolkenGPT performs better than simple (but well designed) baselines.\n\nIn terms of clarity, the paper is well-written and easy to follow. I haven't read the appendix in detail, but it seems to provide enough information for reproducing the experiments.\n\nIn terms of significance, this work brings up new ideas that seem very useful.\n""}, 'weaknesses': {'value': '* The biggest weakness of this paper is in evaluation.\n    * ToolkenGPT is not directly compared to prior work. It is only compared to things along the lines of zero-shot or few-shot baselines. At the end of the paper I\'m left wondering how ToolkenGPT would stack up against e.g., a full model fine-tuning method like Toolformer. I can see that ToolkenGPT allows for demonstrating more tools with more detail than few-shot. It also seems like it\'s probably cheaper to use ToolkenGPT than to fine-tune. But I\'m not really sure of how accuracy for the two tuning methods compare.\n    * In evaluation there are sometimes confounding variables that render results less useful. For example, in Section 4.2 5x more data is used for training ToolkenGPT (sup) than ToolkenGPT (syn). Is the improved performance due to more training samples or higher data quality?\n    * Evaluation sometimes lacks specificity. For example, in Section 4.2 it\'s unclear whether the 30 relations ICL has access to in the e.g., 234 relation case are required to include the correct relation. That seems like a very important detail.\n    * Overall this paper covers an impressive breadth of evaluation, but I wish there was one in-depth evaluation where # of tools, model size, and number of training data points were carefully considered for strong few-shot and fine-tuning (e.g., fine-tuning on all the exact data used to train the toolkens) baselines along with ToolkenGPT while carefully controlling for other variables.\n* I think the comparison between fine-tuning, few-shot, and ToolkenGPT could cleaner\n    * I\'m not sure of the difference between ""plug-and-play"" and ""frozen LM"" in Table 1. I wouldn\'t say ToolkenGPT is ""plug-and-play"" given the model-specific training required for embeddings.\n    * I\'m not sure what is really meant by ""massive tools."" What is stopping a fine-tuning method from learning such tools?'}, 'questions': {'value': 'See weaknesses'}, 'limitations': {'value': 'The authors have a nice discussion of limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings'}, 'authors': {'value': ['Shibo Hao', 'Tianyang Liu', 'Zhen Wang', 'Zhiting Hu']}, 'authorids': {'value': ['~Shibo_Hao1', '~Tianyang_Liu2', '~Zhen_Wang6', '~Zhiting_Hu3']}, 'keywords': {'value': ['large language model', 'tool learning']}, 'TLDR': {'value': 'We propose to use tool embeddings to augment large language models with tools'}, 'abstract': {'value': 'Integrating large language models (LLMs) with various tools has led to increased attention in the field. Existing approaches either involve fine-tuning the LLM, which is both computationally costly and limited to a fixed set of tools, or prompting LLMs by in-context tool demonstrations. Although the latter method offers adaptability to new tools, it struggles with the inherent context length constraint of LLMs when many new tools are presented, and mastering a new set of tools with few-shot examples remains challenging, resulting in suboptimal performance. To address these limitations, we propose a novel solution, named **ToolkenGPT**, wherein LLMs effectively learn to master tools as predicting tokens through **tool embeddings** for solving complex tasks. In this framework, each tool is transformed into vector embeddings and plugged into the language model head. Once the function is triggered during text generation, the LLM enters a special function mode to execute the tool calls. Our experiments show that function embeddings effectively help LLMs understand tool use and improve on several tasks, including numerical reasoning, knowledge-based question answering and embodied decision-making.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/42b5ef479b07ad096eb2045f63a5dd444549c55b.pdf'}, 'supplementary_material': {'value': '/attachment/1460b6696f16562b4018db076399f3ed7d97a330.zip'}, '_bibtex': {'value': '@inproceedings{\nhao2023toolkengpt,\ntitle={Toolken{GPT}: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings},\nauthor={Shibo Hao and Tianyang Liu and Zhen Wang and Zhiting Hu},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=BHXsb69bSx}\n}'}, 'paperhash': {'value': 'hao|toolkengpt_augmenting_frozen_language_models_with_massive_tools_via_tool_embeddings'}}]"
"['Diederik Kingma', 'Ruiqi Gao']",NeurIPS,Understanding Diffusion Objectives as the ELBO with Simple Data Augmentation,https://neurips.cc/virtual/2023/oral/73857,2023," To achieve the highest perceptual quality, state-of-the-art diffusion models are optimized with objectives that typically look very different from the maximum likelihood and the Evidence Lower Bound (ELBO) objectives. In this work, we reveal that diffusion model objectives are actually closely related to the ELBO.Specifically, we show that all commonly used diffusion model objectives equate to a weighted integral of ELBOs over different noise levels, where the weighting depends on the specific objective used. Under the condition of monotonic weighting, the connection is even closer: the diffusion objective then equals the ELBO, combined with simple data augmentation, namely Gaussian noise perturbation. We show that this condition holds for a number of state-of-the-art diffusion models. In experiments, we explore new monotonic weightings and demonstrate their effectiveness, achieving state-of-the-art FID scores on the high-resolution ImageNet benchmark.",Oral 3C Diffusion Models,https://openreview.net/pdf?id=NnMEadcdyD,https://openreview.net/forum?id=NnMEadcdyD,NnMEadcdyD,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'After a thorough evaluation by five reviewers and considering the authors\' detailed rebuttal, I recommend acceptance of this paper as an oral presentation at NeurIPS 2023.\n\n### Summary\nThe paper presents a comprehensive theoretical analysis of diffusion models, elucidating the relationships between the weighted loss and the Evidence Lower Bound (ELBO) objective. By investigating monotonic weighting and introducing new monotonic weightings, the authors establish connections between the weighted loss and ELBO with data augmentation. They demonstrate the effectiveness of their approach through experiments on ImageNet, achieving competitive results.\n\n### Strengths\nImportant Contribution: The work fills a significant gap in the diffusion model research community and provides valuable insights. Reviewer DESf praised it, stating, ""I\'m a big fan of papers like this since their primary aim [is] to build solid understanding [...] and they also present great results for ELBO trained models.""\n\nTheoretical Clarity: The theoretical derivation and insights were appreciated by most reviewers. Reviewer eoU3 noted the contribution as ""excellent.""\n\nExperimentation: The empirical results were seen positively by several reviewers, and the additional high-resolution ImageNet results presented in the rebuttal further strengthened this aspect.\n\n### Concerns\nMathematical Rigor: Concerns were raised about mathematical rigor and notation, particularly by Reviewer Qo9S. However, the authors provided clarifications in their rebuttal, including insights on their use of continuous-time limits and notation.\n\nExperimental Diversity: Reviewer Qo9S expressed concerns about the lack of diversity in datasets, but the authors provided additional experimental results in their rebuttal and explained the relevance to other modalities.\n\n### Conclusion\n\nConsidering the strong theoretical contributions, the efforts to clarify mathematical details, and the effective experimental validation, I believe this paper would make a valuable addition to the conference as an oral presentation. The work builds on existing research in a meaningful way, providing practical insights that could influence the design and understanding of diffusion models. Reviewer DESf\'s comment encapsulates the sentiment well: ""This is a nice paper that provides a comprehensive framework for diffusion objectives, giving the ELBO the driver\'s seat."" The thoughtful rebuttal and additional empirical support further solidify the case for acceptance.'}}, {'title': {'value': 'Reminder from AC'}, 'comment': {'value': ""Dear reviewer,\n\nThe author-reviewer discussion period ends in 2 days. Please review the authors' rebuttal and engage with them if you have additional questions or feedback. Your input during the discussion period is valued and helps improve the paper.\n\nThanks, Area Chair""}}, {'title': {'value': 'Reminder from AC'}, 'comment': {'value': ""Dear reviewer,\n\nThe author-reviewer discussion period ends in 2 days. Please review the authors' rebuttal and engage with them if you have additional questions or feedback. Your input during the discussion period is valued and helps improve the paper.\n\nThanks, Area Chair""}}, {'comment': {'value': 'Dear reviewer,\n\nThank you for raising your score to a 6 (Weak accept) and for explaining why.\n\nCould you perhaps elaborate on what your remaining criticism is, i.e. why you did not give a higher rating? Is there something we could do to further improve your rating?\n\nAgain, thank you for raising your rating.'}}, {'title': {'value': 'Response to Author Rebuttal'}, 'comment': {'value': 'Dear authors, \n\nThank you very much for your thorough response to my comments and questions, it has helped me to gain a better understanding of the paper and has clarified my questions. I plan to keep my current score.'}}, {'title': {'value': 'Thanks for the careful rebuttal to the reviews'}, 'comment': {'value': ""Dear authors,\nthanks a lot for the effort you put in your rebuttal, for all reviews. \n\nOn the theoretical side, concerning my comments on rigor and notation, you addressed all the points and clarified your notation, as well as the continuous-time limit formulation. Thank you.\nI think you managed to identify more clearly what sets apart the submitted paper from [Kingma et al, 2021], namely to extend their results to more general losses. I see now this to be interesting, with some benefits for practitioners who seek high sample quality.\n\nOn the empirical side, I have checked the rebuttal pdf with the new results on higher resolution ImageNet data. These new results illustrate some cases in which the proposed approach does indeed surpass or is well on par with SOTA. Also the general comment to explain why in one experimental setting you didn't obtain the best FID is well detailed and convincing.\nI am still convinced that this work could have included at least one different dataset, even an easier one such as CelebA-HQ or similar, to consolidate our understanding of the generality of the proposed technique.\n\nOverall, I have noticed concrete improvements to the draft, and I am going to raise my score in the official review.\n\nAgain, thank you very much for your work.""}}, {'comment': {'value': 'Dear Reviewer,\n\nThank you again for reviewing our manuscript. We have tried our best to address your questions (see our rebuttal in the top-level comment and above), and revised our paper by following suggestions from all reviewers.\n\nPlease kindly let us know if you have any follow-up questions or areas needing further clarification. Your insights are valuable to us, and we stand ready to provide any additional information that could be helpful.'}}, {'comment': {'value': 'Dear Reviewer,\n\nThank you again for reviewing our manuscript. We have tried our best to address your questions (see our rebuttal in the top-level comment and above), and revised our paper by following suggestions from all reviewers.\n\nPlease kindly let us know if you have any follow-up questions or areas needing further clarification. Your insights are valuable to us, and we stand ready to provide any additional information that could be helpful.'}}, {'comment': {'value': 'Dear Reviewer,\n\nThank you again for reviewing our manuscript. We have tried our best to address your questions (see our rebuttal in the top-level comment and above), and revised our paper by following suggestions from all reviewers.\n\nPlease kindly let us know if you have any follow-up questions or areas needing further clarification. Your insights are valuable to us, and we stand ready to provide any additional information that could be helpful.'}}, {'comment': {'value': 'Dear Reviewer,\n\nThank you again for reviewing our manuscript. We have tried our best to address your questions (see our rebuttal in the top-level comment and above), and revised our paper by following suggestions from all reviewers.\n\nPlease kindly let us know if you have any follow-up questions or areas needing further clarification. Your insights are valuable to us, and we stand ready to provide any additional information that could be helpful.'}}, {'comment': {'value': 'Dear Reviewer,\n\nThank you again for reviewing our manuscript. We have tried our best to address your questions (see our rebuttal in the top-level comment and above), and revised our paper by following suggestions from all reviewers.\n\nPlease kindly let us know if you have any follow-up questions or areas needing further clarification. Your insights are valuable to us, and we stand ready to provide any additional information that could be helpful.'}}, {'rebuttal': {'value': 'Thank you for your detailed review and valuable comments. Please note our top-level comment with additional experimental and theoretical results. Below we address specific questions.\n\n**Q: I couldn\'t find a limitation nor societal impact section, neither a short paragraph on these points.**\n\nA: Please find these sections in the PDF under ""Supplementary Material"" link, specifically Sections H and I. At the time of full-paper submission (one week before supplementary submission deadline), we accidentally appended an incomplete Appendix to the main paper. Please ignore that Appendix, and view the complete Appendix, which includes the relevant Sections, under the link of ""Supplementary Material"".\n\n**Q: Could you please emphasize the main contribution when compared to prior work such as [Kingma et al, 2021] (eq. (19)) and the corresponding section?**\n\nA: Our contributions are:\n1. We explicitly derive the weighting functions and noise schedules for a large number of diffusion objectives used in the literature.\n2. We show that the weighted loss is invariant to the noise schedule, except for its endpoints. This was only shown to hold for the unweighted loss (ELBO) by [Kingma et al, 2021].\n3. We show that if the weighting function is monotonic, then the objective is equivalent to maximizing the ELBO combined with a form of DistAug, i.e., a form of data distribution augmentation. This improves our understanding of weighted diffusion training objectives, where the weighting is essential for best sample quality. We\'d like to emphasize that this derivation (in Section 3.1 and the Appendix B and C) is non-trivial, hasn\'t been derived or stated in previous work, and potentially very valuable for our peers.\n4. We experiment with new monotonic weightings, and demonstrate SOTA FID and Inception scores on high-resolution (128x128, 256x256 and 512x512) ImageNet generation. This demonstrates that we do not need to deviate from the ELBO objective to get good qualitative results, as long as we combine it with DistAug. We hope this could inspire future work along this direction.\n\n**Q: Can you clarify the doubts about mathematical details listed in the weaknesses section of the review?**\n\nA: Recall that for a discrete-time model, we have the forward process forming a conditional joint distribution $q(z_0, z_{\\Delta t}, z_{2\\Delta t}, ..., z_{T\\Delta t}|x)$, and a generative model forming a joint distribution $p(z_0, z_{\\Delta t}, z_{2\\Delta t}, ..., z_{T\\Delta t})$, assuming $T\\Delta t= 1$. Like ""Variational Diffusion Models"" [Kingma et al, 2021] and much of the literature on ODEs and SDEs, we treat the continuous-time model as a discrete-time model, but taken in the limit where the number of timesteps $T$ between 0 and 1 goes to infinity. So, $dt = \\lim_{0 \\leftarrow \\Delta t} \\Delta t = \\lim_{T \\to \\infty} 1/T$. This leads to the continuous-time forward process $q(z_{0,...,1}|x)$ and generative model $p(z_{0,...,1})$.\n\nAnalogously, the KL divergence $D_{\\text KL}(q(z_{0,...,1}|x)||p(z_{0,...,1}))$ is defined the same as the KL divergence of the discrete-time model:\n$$E_q\\left[D_{\\text KL}(q(z_1|x)||p(z_1)) + \\sum_{i=1}^{T}D_{\\text KL}(q(z_{(i-1)\\Delta t}|z_{i\\Delta t}, x))||p(z_{(i-1)\\Delta t}|z_{i\\Delta t}))\\right]$$\nbut taken in the limit where the number of timesteps $T$ between 0 and 1 goes to infinity, and time step size $\\Delta t$ goes to $0$. This approach was also taken by [Kingma et al, 2021].\n\nFor notational brevity we didn\'t include these limits in the notation for the proofs under line 173 and in our Appendix C. However, we can see why this caused unnecessary confusion. We\'ve already improved the notational rigor of our manuscript, and will keep improving for the camera-ready version.\n\n**Q:[...] I find confusing and counterproductive to switch back and forth between different notations (for example dropping or not the dependency on $t$ of $\\lambda$).**\n\nA: In Section 2.2 (line 99), we mentioned *""Below we sometimes denote $\\lambda$ as $\\lambda_t$ to emphasize that it is a bijective function of $t$.""* We agree that it is not ideal to switch between these notations. For the final version we will put more effort in finding a way to minimize the need to use different notations.\n\n**Q: Can you comment on the generality of the experimental results, and how your conclusion could extend to other datasets?**\n\nA: As noted in the top-level comment, we expanded our experiments to high-resolution (256x256 and 512x512) ImageNet generation, and found that weighting functions that performed well in earlier lower-resolution experiments also perform well in these high-resolution settings. In our initial draft, we also have results on ImageNet 128x128 generation (Section 6.2), besides ImageNet 64x64. For high-resolution ImageNet generation (128x128, 256x256, 512x512), we achieved SOTA FID and Inception scores among approaches without guidance, and demonstrated significant improvements compared to the baseline approach Simple Diffusion [Hoogeboom et al, 2023] that we built upon. Please check the top-level comment for more details. \n\nGiven these results, it\'s plausible that the tested weighting functions will also work well on other datasets of images.\n\nIt\'s hard to say a priori which weighting functions would work well for other modalities in practice, like audio. However, in our newest version of our manuscript, we show that VoiceBox [Le et al., 2023], a state-of-the-art model for audio, uses a training objective that is equivalent to the weighted loss with an exponential weighting $w(-\\lambda/2)$. In experiments we found that this weighting works well for images. Therefore, we now know that this weighting function works well for both images and audio.\n\nOn the other hand, all our theoretical results are agnostic to the types of data used, thus our theoretical conclusions naturally extend to other modalities.\n\n**Q: Typo under line 138.**\n\nA: We have fixed it in our latest draft. Thanks for the careful reading!\n'}}, {'rebuttal': {'value': 'Thank you for your detailed review and thoughtful comments. Please note our top-level comment with additional experimental and theoretical results. Below we address specific questions.\n\n**Q: The part of the paper that derives the main conclusion of the paper [...], went a little bit too fast-paced [...].**\n\nA: Thank you for your valuable feedback. We have expanded and clarified this section following your suggestion, and added a detailed derivation to the Appendix.\n\n**Q: The authors mentioned that re-establishing the diffusion objective as an ELBO “allows for a direct apples-to-apples comparison … with other likelihood-based models” (Line 63-64), but it’s unclear on how such comparison can be made. [...].**\n\nA: We will clarify this part of our manuscript. As we mentioned in Section 5 (Related work), the weighted loss in Equation 10 is a type of DistAug [Jun et al., 2020], a powerful method of training data distribution augmentation for generative models. In DistAug, the generative model is conditioned on the data augmentation parameter while training, but conditioned on ""no augmentation"" during sampling. It was shown by [Jun et al., 2020] that DistAug can substantially improve sample quality of autoregressive models on images.\n\nIn our case the augmentation is simple additive noise with noise level $\\lambda_t$, and the model $p(z_t)$ as provided by the score network is conditioned on the noise level $\\lambda_t$. After training, the sampling procedure provides samples from $p(z_t)$ at $t=0$, which has virtually no augmentation. So this is directly analogous to DistAug where the model is trained with various types of augmentation (and conditioned on the augmentation indicator), and sampled by setting the augmentation indicator to ""no augmentation"".\n\nSo, we can optimize other types of models similarly using DistAug, where we train with a distribution $t \\sim p_w(t)$, translating to a distribution over levels $\\lambda_t$, where the generative model is conditioned on the augmentation indicator $\\lambda_t$. After training, we sample from the model with the augmentation indicator set to ""no augmentation"", i.e. $t=0$.\n\n**Q: About minor issues.**\n\nA: All points raised here are great. We appreciate your careful reading of our draft, and we will incorporate the suggestions into our updated draft.\n\n**Q: Line 108-109, ""[...], $p(\\lambda)$ provides the relative amount of time the sampler spends at different noise levels"". It’s not immediately clear what it means, [...].**\n\nA: Since the noise level $\\lambda$ is a nonlinear function of time $t$, sampling $t$ uniformly results in a non-uniform distribution of noise levels $\\lambda$. During sampling, $p(\\lambda)$ provides the density of sampling steps at noise level $\\lambda$.\n\n**Q: Line 179-180, “The probability distribution $p_w(t)$ has Dirac delta peak of typically very small mass $w(0)$ at $t=0$.” Does this mean that the almost noiseless sample contributes very little to the objective computation?""**\n\nA: Yes, that\'s correct. There\'s typically still somewhat non-trivial total probability mass over all low noise levels, but the weight over these noise levels is relatively low, since it corresponds to modeling fine pixel details, which are of relatively lower importance for the quality of samples than the more abstract image information, which is modeled at the higher noise levels. Of all the plotted weighting functions, only the ELBO weighting gives high weight to low noise levels, but it also leads to the worst FID scores.\n\n**Q: Line 262-265: have the authors run experiments for a $v$-prediction model combined with a non-monotonic weighting function?**\n\nA: We have not previously. For $v$-parametrized model, we used the $v$-prediction loss $||{\\textbf v} - \\hat{{\\textbf v}}||^2_2$ widely adopted in the literature as the baseline, which corresponds to a monotonic weighting function $\\exp(\\lambda / 2)$. We are running an experiment using $v$-parametrized model and $\\epsilon$-prediction loss ($L_{\\text simple}$), resulting in a non-monotonic weighting function ${\\text sech}(\\lambda /2)$. We will report the result later. \n\n**Q: In Figure 1 Right, only the “EDM sampling” noise schedule $p(\\lambda)$ has monotonically decreasing as a function of $\\lambda$. Is there any interpretation of that, [...]?**\n\nA: We did notice that the ""EDM sampling"" schedule spends a lot more time at the very high and the very high noise levels, and less time at the intermediate noise levels. The reason might be that the optimal design of training and sampling noise schedules can be very different: for training, the optimal schedule seeks to minimize the variance of the training objective, while for evaluation, the optimal design should minimize the ""truncation error"" accumulated along the discretized reverse-ODE or reverse-SDE trajectory, which is also the intuition of EDM sampling schedule. As noted in Appendix D.1 of [Karras et al, 2022], in practice, the truncation error of Euler\'s method (1st order ODE solver) of the reverse-ODE is monotonically decreasing over $\\lambda$. Therefore, we should allocate more sampling steps in low $\\lambda$ region, to allow for using small step sizes with smaller truncation error. This leads to the monotonically decreasing $p(\\lambda)$.\n\n**Q: It’s a bit confusing on why the noise schedule $p(\\lambda)$ is casted as a probability distribution (besides the importance sampling interpretation); [...]. Why does $p(\\lambda)$ need to be sampled – is it because timesteps need to be sampled during training?**\n\nA: Yes, since time $t$ is sampled randomly during training, the noise level $\\lambda$ has a distribution $p(\\lambda)$ during training. We think the importance sampling interpretation is important, since it allows us to intuitively understand that given a fixed weighting function $w(\\lambda)$, the loss is invariant to the choice of noise schedule $p(\\lambda)$; $p(\\lambda)$ only affects the variance of the Monte Carlo estimator of the loss.'}}, {'rebuttal': {'value': 'Thank you for your constructive comments. We strongly agree with you that understanding weighted diffusion training objectives as ELBO with data augmentation gives us a way to fairly compare diffusion models with other likelihood-based models, and indicates that ELBO objective is still compatible with high sample quality. Please note our top-level comment with additional experimental and theoretical results.'}}, {'rebuttal': {'value': ""Thank you for your valuable comments and kind words to our work. Please note our top-level comment with additional experimental and theoretical results. Below we address specific questions.\n\n**Q: Cite and discuss relationship with “Maximum Likelihood Estimation for Diffusion ODEs” (https://arxiv.org/abs/2305.03935).**\n\nA: We appreciate your pointer to this related work, which also proposes noise schedules with the purpose of reducing the variance of diffusion objectives. They proposed two approaches: 1) design $p(\\lambda)$ such that the coefficient of the mean squared error of normalized v-parametrization is a time-invariant constant; 2) learning a noise schedule network $\\lambda(t)$ by minimizing the variance of the training objective, similar to [Kingma et al, 2021]. While 2) in theory can seek the optimal importance sampling, it introduces extra computational cost with additional gradient operations. We therefore choose a less expensive approach: we maintain the exponential moving average of $w(\\lambda)||\\epsilon - \\hat{\\epsilon}_\\theta||^2_2$, and adaptively update the noise schedule $p(\\lambda)$ to be proportional to that at each iteration. Similar approach was proposed by [Nichol et al, 2021]. \n\nWe will cite this paper and discuss the relationship in our final version, as you suggested.\n\n**Q: Not necessary to address but I'm quite curious which of the invariance and change of variables bits apply for multivariate (augmented) diffusions.**\n\nA: That's a very good point! A more general formulation would be interesting, which we leave open for future work.\n\nThanks for your suggestion on clarifying Eq 3, which we have incorporated to the updated draft. ""}}, {'rebuttal': {'value': ""Thank you for your thoughtful feedback. Please note our top-level comment with additional experimental and theoretical results. Below we address specific questions.\n\n**Q: Adding more experimental results could have been helpful.**\n\nA: Please see our top-level comment and the PDF attached to it. We have added high-resolution ImageNet generation results (i.e. 256x256 and 512x512) to further demonstrate the effectiveness our approach. With our 'EDM-monotonic' function and adaptive noise schedule, we achieved SOTA FID and Inception scores on high resolution ImageNet (i.e., all three resolutions of 128, 256, 512).""}}, {'rebuttal': {'value': 'Dear Reviewers,\n\n**Please see the attached PDF for a one-page PDF with a summary of added experimental results.**\n\nWe would like to thank all reviewers for providing constructive feedback that helped us improved the paper. We are encouraged that reviews think our paper:\n- ""provides a comprensive framework for diffusion objectives"" (Reviewer DESf),\n- ""fills an important gap for the diffusion model research community"" (Reviewer bjDS),\n- provides ""a clearer understanding of sample quality and likelihood of various model classes"" (Reviewer eoU3) and was well-supported by both ""detailed theoretical analysis"" and ""experimental results"" (Reviewer kL4L).\n\nWe have been working diligently on improving the paper on several fronts, addressing your critique. Below, we summarize the changes that we have made in an updated draft.\n\n**1. High-resolution (256x256 and 512x512) ImageNet results**\n\nWe provide new experimental results, with state-of-the-art FID and Inception scores for high-resolution ImageNet generation (256x256 and 512x512). Please see the attached PDF for a table of the summary of quantitative evaluations and a figure for generated samples by our approach. \n\nWith the shifted version of ‘EDM-monotonic’ weighting, we achieved state-of-the-art FID and Inception scores on all three resolutions (i.e., 128x128, 256x256, 512x512) of ImageNet generation among all approaches without any guidance. With classifier-free guidance (CFG) [Ho and Salimans, 2022], our method outperforms all diffusion-based approaches on resolutions 128 and 512. On resolution 256, our method only falls a bit behind Gao et al. [2023] and Hang et al. [2023], both of which were build upon the latent space of a pretrained auto-encoder from Stable Diffusion [Rombach et al., 2022a], that was trained on a much larger image dataset than ImageNet, while our model was trained on the ImageNet dataset only. It is worth noting that we achieve significant improvements on the Simple Diffusion baseline model [Hoogeboom et al., 2023] that we built upon, on all resolutions, with and without guidance. In principle it is possible to apply our proposed weighting functions and adaptive noise schedules to other diffusion-based approaches such as Gao et al. [2023], possibly further improve their performance.\n\nWe will provide additional samples from our trained models in a new section in the updated Appendix.\n\n**2. More weighting functions**\n\nWe expanded Table 1 and the Appendix with more weighting functions used in the literature. Specifically, we added the weighting function corresponding to Flow Matching with Optimal Transport (FM-OT) [Lipman et al., 2022]: $w(\\lambda) = \\exp(-\\lambda/2)$, and the weighting function corresponding to InDI [Delbracio and Milanfar, 2023]: $w(\\lambda) = \\exp(−\\lambda)\\text{sech}^2(\\lambda/4)$. The detailed derivations will be provided in the Appendix. Interestingly, both weighting functions are monotonic.\n\n**3. More helpful visualizations and analysis**\n\n- We added an analysis on the relationship with low-bit training to the Appendix.\n- We added a visualization of integration-by-parts, used in our main proof, to the Appendix.\n\nPlease see our reviewer-specific feedback for more information.'}, 'pdf': {'value': '/pdf/30d0e18bfdb004365e95b9f9255defadb436b23c.pdf'}}, {'summary': {'value': 'The paper tackles the loss function of diffusion models from a theoretical point of view. The paper studies the relationship between the weighted loss and the ELBO objective. The paper shows that the diffusion model objectives can be formulated as a special case of weighted loss. In addition to the theoretical contribution, the authors propose monotonic weightings and provide an empirical study of monotonic and non-monotonic weighting.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The problem studied is important\n- Formulating the different diffusion model loss as weighted loss is interesting\n- The paper presented a detailed theoretical analysis\n- Experimental results support the proposed method'}, 'weaknesses': {'value': '- Adding more experimental results could have been helpful but this is not a major point.'}, 'questions': {'value': 'NA'}, 'limitations': {'value': 'NA'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""This is a nice paper that provides a comprensive framework for diffusion objectives, giving the ELBO the driver's seat.\n\nThe paper shows that all of the axes along which diffusion objectives differ (elbo vs Ho-perceptual weighting, noise schedules, different parameterizations like x vs epsilon vs v) can all be seen under a type of weighted and importance sampled ELBO. Moreover, the paper show that the weightings that don't exactly look like the original ELBO can be made equal to it under the right data augmentation. Finally, the authors also present a few techniques for adaptive/learnable importance sampling distributions to help assemble all the aforementioned ingredients in a computationally efficient manner. Finally, the authors show conveying results for image quality for ELBO trained models, whereas people usually result to non-ELBO trained models to do this.""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'I\'m a big fan of papers like this since their primary aim to build solid understanding for people that already work with diffusions but that may have some doubts about how the common moving parts relate to each other (noise schedules, elbo weighting, parameterizations, etc). \n\nOn top of the above, they also present great results for ELBO trained models, whereas there is some common beliefs that non-elbo ""perceptual weighting"" (what the authors call ""reweighted losses"") are the only ones that can be used for good image quality.'}, 'weaknesses': {'value': 'No comments/weaknesses.\n\nThe adaptive importance sampling also comes up in the following work:\n\nImproved Techniques for Maximum Likelihood Estimation for Diffusion ODEs https://arxiv.org/abs/2305.03935\n\nThis is completely fine since:\n- I can see how both works would arrive at this algorithmic detail independently, given that both dive deeply into related but distinct variance issues in diffusion elbos.\n- both works present a lot of additional insights and techinques beyond this\n\nI do find it appropriate to cite and discuss relationship in either case though, including possible similarities and differences, since it will really help readers of both papers.'}, 'questions': {'value': ""Just a brief suggestion:\n\n- around eq 3 it would be good to mention that the f(x,t)-g^2(t) s_\\theta(x,t) form is a backward time SDE since some other authors use the g^2(T-t)s_\\theta(x,T-t) -f(x, T-t) forward time SDE.\n\n- Not necessary to address but I'm quite curious which of the invariance and change of variables bits apply for multivariate (augmented) diffusions like CLD (https://arxiv.org/abs/2112.07068), MDMs (https://arxiv.org/abs/2302.07261), PSLD (https://arxiv.org/abs/2303.01748), and FP-Diffusion (https://arxiv.org/abs/2206.10365). You can't quite take the g^2/sigma^2 weighting out of the squared error like in the scalar diffusion case, but I'm sure there should be some relevant version of your results.""}, 'limitations': {'value': 'Yes.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents new theoretical insights on denoising diffusion objective. Namely, training a diffusion model with a non-uniform weighting can be expressed as a weighted integral of ELBOs, and monotonic weighting results in training ELBO with additive Gaussian noise augmentation. The authors also propose an adaptive noise schedule to ensure all losses are trained uniformly over time and show the adaptive schedule with a monotonic weighting attains SOTA FID on ImageNet.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'Although not shown in this work, the interpretation that denoising diffusion with monotonic weighting trains ELBO with data augmentation means that the same data augmentation can be applied to other likelihood-based models for a fair comparison to diffusion models. And, we would have a clearer understanding of sample quality and likelihood of various model classes.'}, 'weaknesses': {'value': '-'}, 'questions': {'value': '-'}, 'limitations': {'value': 'Yes, the authors addressed limitations, potential negative societal impact, and mitigation.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper takes a systematic approach to address two important aspects of the implementation of diffusion-based generative models: the objective function and the noise schedule, both of which have been conventionally set in a relatively empirical fashion ($i.e.$, based on sample quality).\n\nThe paper first frames the noise schedule in terms of the log SNR $\\lambda_t$ as a function of time $t$, then writes the diffusion model objective in the form of a weighted denoising score matching objective, Eq. (6). By doing so, the paper unifies the existing works as special cases under a generic form of the objective function with its corresponding noise schedule.\n\nThe paper continues with a theoretical analysis of the diffusion model objective, by first revealing the ELBO objective as one particular realization of the weighted objective, then provides the key theoretical result via Theorem 1, which states that **under the assumption of a monotonically increasing weighting function $w(\\lambda_t)$, the generic diffusion model objective Eq. (6) is equivalent to a negative ELBO objective of noise-perturbed data (a form of data augmentation, controlled by the noise schedule $\\lambda_t$)**. This result has recast the ELBO as the class of objective functions for training diffusion models that are capable of producing high-quality samples.\n\nWith the theoretical results, the paper proposes several new monotonic weighting functions, and demonstrates through experiments that monotonic weighting enables the trained diffusion models to generate high quality samples (competitive with the best diffusion models) for image tasks in terms of FID and IS, including a new SOTA FID score of $1.75$ on class-conditional $128\\times 128$ ImageNet dataset.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '* Among all degrees of freedom for the implementation of a diffusion-based generative model, setting the weights at each noise level for the objective function, and noise scheduling, are two crucial aspects for its success that have traditionally been mainly based on empirical choices. By addressing these two aspects with a systematic and rigorous approach, this work fills an important gap for the diffusion model research community, thus is a well-motivated and potentially very beneficial work.\n* By recasting the diffusion model objective under the restriction of the weighting function as an ELBO objective, the work can bring back this important class of objective functions along with the existing literature on training with an ELBO objective.\n* The paper proposes several new monotonic weighting functions for the weighted diffusion objective.\n* The paper is overall well-organized and clearly written: it can be viewed as a good reference that introduces the diffusion-based generative modeling framework collectively; the color-coding for different components of the objective functions is a good design for presenting derivations.'}, 'weaknesses': {'value': '* The part of the paper that derives the main conclusion of the paper (the diffusion objective is equivalent to the ELBO with data augmentation), specifically Line 181-185, went a little bit too fast-paced and might lack of some details to facilitate understanding; some descriptions don’t exactly match the mathematical expressions:\n    * The KL divergence $D_{KL}(q(z_{t,\\dots,1}\\vert x)\\vert\\vert p(z_{t,\\dots,1}))$ being “the negative ELBO of noise-perturbed data, plus a constant” is not immediately clear. It perhaps would be nice for the authors to provide the derivations, to establish $D_{KL}(q(z_{t,\\\\dots,1}| x)|\\vert p(z_{t,\\\\dots,1})) =-\\\\mathbb{E}_{q(z_t|x)}[\\\\text{ELBO of }\\\\log p(z_t)]-\\\\mathcal{H}(q(z_t|x))$, where\n\n   \t $\\text{ELBO of }\\\\log p(z_t)=\\\\mathbb{E}_{q(y | z_t, x)}[\\\\log p(z_t, y)-\\\\log q(y | z_t, x)],$ in which $y=z\\_{t+\\\\triangle t,\\dots,1},$ and $\\\\triangle t$ is the time increment.\n\n    \tSimilarly, the inequality in Eq. (9), $D_{KL}(q(z_{t,\\\\dots,1}| x)|\\vert p(z_{t,\\\\dots,1})) = D\\_{KL}(q(z_t | x)|\\vert p(z_t)) + \\\\mathbb{E}_{q(z_t | x)}\\big[D\\_{KL} (q(y | z_t,x)||p(y | z_t))\\big]\\\\ \\geq D\\_{KL}(q(z_t | x)|\\vert p(z_t))$.\n\n    \tIt might be helpful to clarify these terms, since Line 181-182 seems to be the very part that constructs the main claim of the paper $s.t.$ the diffusion objective can be viewed as the (negative) ELBO of noise-perturbed data.\n    * Line 184-185 says that minimizing $\\mathcal{L}\\_w(\\\\theta)$ with a monotonic weighting “is equivalent to maximizing the ELBO of noise-perturbed data”. The expression is a bit strange as it indicates there is only one ELBO term to be optimized, while the objective function is shown in this section to be viewed as a collection of different ELBO terms. Therefore, this simplified description might cause some misinterpretation.\n    * The underbracket text for Eq. (9) and (10) are both “Neg. log-likelihood of noise-perturbed data”, while the expressions are different expectations of $-\\\\log p(z_t)$.\n* The authors mentioned that re-establishing the diffusion objective as an ELBO “allows for a direct apples-to-apples comparison … with other likelihood-based models” (Line 63-64), but it’s unclear on how such comparison can be made: \n    * Does it refer to the training loss when the autoregressive transformer is trained *with the same data augmentation scheme*? If so, it would only make sense if the adaptation of the data augmentation scheme would not worsen the autoregressive transformer’s performance in the first place. \n    * Or does it refer to the computation and comparison of the exact likelihood?\n\n    It would be nice for the authors to elaborate more on how such comparisons can be made, as it occurs noticeably at the end of both the Introduction and the Conclusion section.\n\n> Minor Issues\n* Line 10 in the Abstract says that the weighted loss “equals the ELBO”. Based on Section 3.1, would it be more accurately described as “equivalent to optimizing the ELBO”?\n* Line 39 “This has has led”.\n* Line 42 “training objective” might be “training objectives”.\n* Section 2.5 has both forms for the score network,  “$s_{\\theta}(z;\\lambda)$” and “$s_{\\theta}(z,\\lambda)$”.\n* Line 142 comma between “$x$-prediction” and “$v$-prediction”.\n* Eq. (8) 2nd and 3rd line: the expectation has “$t\\sim U(0,1))$”.\n* Table 5 text box ends with two periods.\n* Line 62 & 295 the expression “The newfound equivalence between monotonic weighting and the ELBO with data augmentation” seems odd; do the authors mean “The newfound equivalence between monotonically weighted diffusion objective and the ELBO with data augmentation”?\n* It’s a bit confusing to first define $\\lambda$ as the log SNR (Line 86), then call it the noise level (Line 91): the sentence in Line 93-94, “At timestep t = 0 the noise level … $\\lambda$ is high, meaning very little noise; at t = 1 the noise level $\\lambda$ is low, meaning a lot of noise”, sounds a bit odd.\n* The term “noise schedule” is overloaded: in the paper, it simultaneously means the log SNR term $\\lambda_t$ itself (Line 149), the function $f_{\\lambda}$ (Line 90), and the distribution $p(\\lambda)$ (Line 510). It’s clear to me that each “noise schedule” would result in a particular value of the variance ${\\sigma_{\\lambda}}^2$ at each timestep, but I’m not sure if such overloading would create any issue in the future, thusI’ll just point it out here.\n* Line 179-180 the weighting function $w$ is simultaneously a function of $\\lambda_t$ and of $t$.'}, 'questions': {'value': '* Could the authors provide some explanation for the following sentences:\n    * Line 108-109, “During sampling, $p(\\lambda)$ provides the relative amount of time the sampler spends at different noise levels.” It’s not immediately clear what it means, as it seems that by sampling $t\\sim U(0,1)$, each noise level has an equal chance of being sampled.\n    * Line 179-180, “The probability distribution $p_w(t)$ has Dirac delta peak of typically very small mass $w(0)$ at $t = 0$.” Does this mean that the almost noiseless sample contributes very little to the objective computation?\n* Line 262-265: have the authors run experiments for a $v$-prediction model combined with a non-monotonic weighting function?\n* In Figure 1 Right, only the “EDM sampling” noise schedule has $p(\\lambda)$ monotonically decreasing as a function of $\\lambda$. Is there any interpretation of that, $e.g.$, advantages for the EDM sampling scheme to monotonically decrease?\n* It’s a bit confusing on why the noise schedule is casted as a probability distribution $p(\\lambda_t)$ (besides the importance sampling interpretation): $e.g.$, the cosine schedule has the variance at each timestep as a deterministic function of time. Why does $\\lambda$ need to be sampled – is it because timesteps need to be sampled during training?'}, 'limitations': {'value': 'The authors have discussed both limitations and potential negative social impact via Appendix H and I from Supplementary Material, which speak for the community well.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper studies different weighting schemes of the loss functions of generative diffusion models. In particular, the authors investigate the relationship between a weighted (with respect to noise levels) loss and the proper Evidence Lower Bound (ELBO), discussing how the former can be written as a weighted integral of ELBOs.\n\nIt is further claimed that when the weighting factor is monotonic, there exists an interpretation of the loss as the result of log-likelihood optimization considering data augmentation, in particular noise perturbation.\n\nFinally, the proposed interpretation is leveraged to construct new weighting schemes, corroborating the discussion with empirical validation.\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '* Deepening our understanding of diffusion models is an important endeavour, given the popularity of such methods, and this paper is aligned with research lines on methodological contributions on training such models\n\n* The authors attempted at reproducing the work from Karras et al, and provide an additional insights on the difficulty of obtaining generative performance that is on par with prior work'}, 'weaknesses': {'value': 'On a technical level, the paper has several problems related to mathematical rigor. Overall, a colloquial exposition is preferred over a clear mathematical language.\n\n* Starting with line 76, the ""series of latent variables"" $z_{0,...,1}$ is introduced without specifying whether the set of time indices is uncountable (i.e. a continuous set between 0 and 1) or whether it is the collection of a finite set of time indices (for example an equally spaced grid between 0 and 1). The term ""conditional distribution"" $q(z_{0,...,1} | x)$ introduced at line 77 is very confusing, and requires a proper discussion, in particular for the case of uncountable time indices.\n\n* This is not just a minor stylistic note, but has concrete impact on the derivation and in the discussions: for example, how is the KL divergence introduced at line 126, $D_{\\text{KL}}\\left(  q(z_{0,..1}),p(z_{0,..1}) \\right)$, defined? Are the authors talking about path measures? In this case, a proper characterization needs the formal tools of stochastic calculus, like for example in Huang2021, where the Girsanov Theorem is used to construct the ELBO.\n\n* Furthermore, in the different derivations I find confusing and counterproductive to switch back and forth between different notations (for example dropping or not the dependency on $t$ of $\\lambda$). Why for example in equation (5) would you use lambda both with and without $t$?\n\n* The paper contains typos, like in the equation under line 138 where the term $x_t$ is never defined.\n\n* On a methodological level, I find the contribution of the paper somehow marginal. Until Section 3.1, the authors present known, or easy-to-derive, results from the literature. The correspondence between the weighted loss and the ELBO is even explicitly stated in Kingma2021 (eq. (19) and the corresponding section)\n\n* The derivation under line 173 is not rigorous for the same motivations mentioned above: the set of time indices is never properly defined.  Even the related proofs in Appendix C does not use a proper mathematical language. \nWhile I understand the change of notation between eqs 12 and 13 ($z_t \\to z_\\lambda$) the presentation needs improvements.\n\n* Finally the experimental validation is limited in several aspects. First, for a paper whose main contribution is on the exploration of different weighting schemes, the authors only experiment on a single dataset (ImageNet 64x64). Is this sufficient to draw any general conclusion about such aspect?\n\n* None of the proposed weighting schemes achieve the performance of the existing baseline (EDM, Karras 2022) which has a FID score of 1.36. In general, the improvements are marginal, since we do not have access to the source code it is not possible to verify whether differences between considered schemes and baselines are due to the weighting schemes or other implementation details. \n'}, 'questions': {'value': 'Given the observations in the ""weaknesses"" section:\n\n* Could you please emphasize the main contribution when compared to prior work such as Kingma2021 (eq. (19) and the corresponding section)?\n\n* Can you clarify the doubts about mathematical details listed in the weaknesses section of the review?\n\n* Can you comment on the generality of the experimental results, and how your conclusion could extend to other datasets?\n\n\n\n==== Post rebuttal message, prior to reviewer discussion ====\n\n\nDear Authors, as a post rebuttal message, I am willing to increase my score to a 6: weak accept. I also have changed the scores to what concerns soundness, presentation and contribution. \n\nI will eventually edit again my official review after the reviewer discussion phase, but for now I would like to thank you for your effort in addressing my concerns.'}, 'limitations': {'value': ""I couldn't find a limitation nor societal impact section, neither a short paragraph on these points.""}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Understanding Diffusion Objectives as the ELBO with Simple Data Augmentation'}, 'authors': {'value': ['Diederik P Kingma', 'Ruiqi Gao']}, 'authorids': {'value': ['~Diederik_P_Kingma1', '~Ruiqi_Gao1']}, 'keywords': {'value': ['Diffusion Model', 'Evidence Lower Bound', 'Maximum Likelihood']}, 'TLDR': {'value': 'We develop a theoretical understanding of the training objective of diffusion models as a the ELBOs subject to data augmentation.'}, 'abstract': {'value': 'To achieve the highest perceptual quality, state-of-the-art diffusion models are optimized with objectives that typically look very different from the maximum likelihood and the Evidence Lower Bound (ELBO) objectives. In this work, we reveal that diffusion model objectives are actually closely related to the ELBO.\n\nSpecifically, we show that all commonly used diffusion model objectives equate to a weighted integral of ELBOs over different noise levels, where the weighting depends on the specific objective used. Under the condition of monotonic weighting, the connection is even closer: the diffusion objective then equals the ELBO, combined with simple data augmentation, namely Gaussian noise perturbation. We show that this condition holds for a number of state-of-the-art diffusion models. \n\nIn experiments, we explore new monotonic weightings and demonstrate their effectiveness, achieving state-of-the-art FID scores on the high-resolution ImageNet benchmark.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/d16cfcd14613fc1198cfb086ecf7b31148c34bc7.pdf'}, '_bibtex': {'value': '@inproceedings{\nkingma2023understanding,\ntitle={Understanding Diffusion Objectives as the {ELBO} with Simple Data Augmentation},\nauthor={Diederik P Kingma and Ruiqi Gao},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=NnMEadcdyD}\n}'}, 'paperhash': {'value': 'kingma|understanding_diffusion_objectives_as_the_elbo_with_simple_data_augmentation'}}]"
"['Yuanyuan Liu', 'Fanhua Shang', 'Weixin An', 'Junhao Liu', 'Hongying Liu', 'Zhouchen Lin']",NeurIPS,A Single-Loop Accelerated Extra-Gradient Difference Algorithm with Improved Complexity Bounds for Constrained Minimax Optimization,https://neurips.cc/virtual/2023/oral/73815,2023," In this paper, we propose a novel extra-gradient difference acceleration algorithm for solving constrained nonconvex-nonconcave (NC-NC) minimax problems. In particular, we design a new extra-gradient difference step to obtain an important quasi-cocoercivity property, which plays a key role to significantly improve the convergence rate in the constrained NC-NC setting without additional structural assumption. Then momentum acceleration is also introduced into our dual accelerating update step. Moreover, we prove that, to find an $\epsilon$-stationary point of the function $f$, our algorithm attains the complexity $\mathcal{O}(\epsilon^{-2})$ in the constrained NC-NC setting, while the best-known complexity bound is $\widetilde{\mathcal{O}}(\epsilon^{-4})$, where $\widetilde{\mathcal{O}}(\cdot)$ hides logarithmic factors compared to $\mathcal{O}(\cdot)$. As the special cases of the constrained NC-NC setting, our algorithm can also obtain the same complexity $\mathcal{O}(\epsilon^{-2})$ for both the nonconvex-concave (NC-C) and convex-nonconcave (C-NC) cases, while the best-known complexity bounds are $\widetilde{\mathcal{O}}(\epsilon^{-2.5})$ for the NC-C case and $\widetilde{\mathcal{O}}(\epsilon^{-4})$ for the C-NC case. For fair comparison with existing algorithms, we also analyze the complexity bound to find $\epsilon$-stationary point of the primal function $\phi$ for the constrained NC-C problem, which shows that our algorithm can improve the complexity bound from $\widetilde{\mathcal{O}}(\epsilon^{-3})$ to $\mathcal{O}(\epsilon^{-2})$. To the best of our knowledge, this is the first time that the proposed algorithm improves the best-known complexity bounds from $\mathcal{O}(\epsilon^{-4})$ and $\widetilde{\mathcal{O}}(\epsilon^{-3})$ to $\mathcal{O}(\epsilon^{-2})$ in both the NC-NC and NC-C settings.",Oral 4A Optimization,https://openreview.net/pdf?id=wIlmx4bHrO,https://openreview.net/forum?id=wIlmx4bHrO,wIlmx4bHrO,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper introduces an extra-gradient difference acceleration algorithm for constrained nonconvex-nonconcave minimax problems. The algorithm improves upon the existing best convergence rate. Additionally, the paper offers an extensive comparison with current algorithms and delivers a thorough theoretical analysis. The whole review team believes that the paper makes significant contributions to the field of minimax optimization.'}}, {'comment': {'value': 'Thanks for your positive and valuable comments. We will improve the final version based on your comments.'}}, {'comment': {'value': 'We sincerely appreciate the reviewer for your positive and valuable comments. We are delighted to learn that our response effectively addressed your questions.'}}, {'comment': {'value': 'We sincerely appreciate the reviewer for raising the score. We must carefully corrected these typos on our manuscript before our final camera-ready submission.'}}, {'comment': {'value': 'We sincerely appreciate the reviewer for noticing that we have concrete contribution, and raising the score. We are delighted to learn that our response effectively addressed your questions.'}}, {'comment': {'value': 'Dear authors, thank you for your work on the final version of your paper! The rebuttal has clarified my questions. I decided to keep my overall rating the same.'}}, {'comment': {'value': 'I appreciate the authors for the clarifications in their rebuttal, and I have raised my score from 7 to 8. I do encourage the authors to take more passes on their manuscript for typographical polishing/corrections before their final camera-ready submission.'}}, {'comment': {'value': ""I appreciate your response to my questions. Moreover, the empirical evidences presented are quite compelling. After reviewing the feedback and rebuttals from the other reviewers, I've decided to increase my score.""}}, {'rebuttal': {'value': 'Dear Reviewers and Area Chairs:\n\nThank you very much for the constructive comments. More experimental results in the PDF file, and the details are as follows: \n\n**1**. We have conducted more empirical experiments and compared the performance of all the algorithms over the running time, as shown in Fig. 1 in the PDF file.\n\n**2**. We have conducted more experiments of FEG for the function in Figure 2, and reported empirical results in Fig. 2 in the PDF file.\n\n**3**. More Results for Robust Neural Network in Figure 3: \n\nUnder adversarial attacks including $\\ell_\\infty$-norm FGSM and PGD attacks, the test accuracies of all the algorithms including GDA, MGDA, Smoothed-GDA and our EGDA are reported in Fig.3, where the $\\ell_\\infty$-norm perturbation level $\\varepsilon$ varies from $0.0$ to $0.4$. Note that for EGDA, the parameter $\\tau$ is set to $3/4$, and the parameters $\\alpha$ and $\\beta$ in Smoothed-GDA are set to $0.2$ and $0.8$ as in [51], respectively. And the number of iterations is set to 100 for all the algorithms. All the results show that Smoothed-GDA and EGDA significantly outperform GDA and MGDA in terms of accuracy, and our EGDA also performs better than other algorithms including Smoothed-GDA.\n\n**4**.\tMore Results for Wasserstein GAN in Figure 4\n\nFinally, we apply the stochastic version of the proposed EGDA algorithm to train Wasserstein GAN in [R3] on the MNIST dataset, and verify the effectiveness of our algorithm. Here the architectures of Wasserstein GAN (including its discriminator and generator) are set to be multi-layer perceptrons (MLP). The layer widths of the MLP in generator are 100, 128, 784, and the layer widths of the MLP in discriminator are 784, 128, 1. In addition, the batch size is set to 64, and the learning rate is 1e-4. Moreover, we compare our algorithm against one state-of-the-art method, Stochastic Gradient Descent Ascent (SGDA) by drawing their generated figures after 20k and 100k iterations, as shown in Fig.4. All the results show that our stochastic algorithm performs much better than SGDA and produces higher quality images, which shows the effectiveness of our algorithm.\n\n[R3] M. Arjovsky , et al., “Wasserstein generative adversarial networks,” ICML 2017.\n'}, 'pdf': {'value': '/pdf/25893be4f88b45d9604a21a9a59bcf471ceabc05.pdf'}}, {'rebuttal': {'value': '**Q**: Authors could provide more extensive empirical study, because algorithm seems to be candidate for being widely-accepted in practice and it would be good to have more justifications of its efficiency.\n\n**A**: Thanks for your positive and valuable comments. To address your concerns, we have provided more extensive empirical study, and reported more experimental results, as shown in Figs. 3 and 4 in the PDF file (please see “global” response). That is, we have applied the proposed algorithm to solve some real-world applications, such as robust neural network in Figure 3 and Wasserstein GAN training in Figure 4. All the results show that the proposed algorithm performs much better than other algorithms such as GDA, MGDA and Smoothed-GDA, which also verified our theoretical results. All the results will be included in our final paper. The details are as follows:\n\n1.\tMore Results for Robust Neural Network in Figure 3 in the PDF file (please see “global” response)\n\nUnder adversarial attacks including $\\ell_\\infty$ -norm FGSM and PGD attacks, the test accuracies of all the algorithms including GDA, MGDA, Smoothed-GDA and our EGDA are reported in Fig.3, where the $\\ell_\\infty$ -norm perturbation level $\\varepsilon$ varies from $0.0$ to $0.4$. Note that for EGDA, the parameter $\\tau$ is set to $3/4$, and the parameters $\\alpha$ and $\\beta$ in Smoothed-GDA are set to $0.2$ and $0.8$ as in [51], respectively. And the number of iterations is set to 100 for all the algorithms. All the results show that Smoothed-GDA and EGDA significantly outperform GDA and MGDA in terms of accuracy, and our EGDA also performs better than other algorithms including Smoothed-GDA.\n\n2.\tMore Results for Wasserstein GAN in Figure 4 in the PDF file (please see “global” response)\n\nFinally, we apply the stochastic version of the proposed EGDA algorithm to train Wasserstein GAN in [R3] on the MNIST dataset, and verify the effectiveness of our algorithm. Here the architectures of Wasserstein GAN (including its discriminator and generator) are set to be multi-layer perceptrons (MLP). The layer widths of the MLP in generator are 100, 128, 784, and the layer widths of the MLP in discriminator are 784, 128, 1. In addition, the batch size is set to 64, and the learning rate is 1e-4. Moreover, we compare our algorithm against one state-of-the-art method, Stochastic Gradient Descent Ascent (SGDA) by drawing their generated figures after 20k and 100k iterations, as shown in Fig.4. All the results show that our stochastic algorithm performs much better than SGDA and produces higher quality images, which shows the effectiveness of our algorithm.\n\n[R3] M. Arjovsky , et al., “Wasserstein generative adversarial networks,” ICML 2017.\n\n'}}, {'rebuttal': {'value': '**Q**: The recent work in [1], shows that the computation of an approximate stationary point is PPAD-complete when the action space of the two players is a joint. Notably, the findings in your paper seem to suggest a different outlook when the strategy space of the two players is a product space, which negates the hardness results. A comment from the authors addressing this observation would be greatly appreciated.\n[1] ""The Complexity of Constrained Min-Max Optimization"" by Constantinos Daskalakis, Stratis Skoulakis, and Manolis Zampetakis.\n\n**A**:  Thanks for your positive and constructive comments. To address your concern, we will add this reference, and provide some discussions about [1] in our final paper. \n\n1.\tIn [1], the authors studied a constrained nonconvex-nonconcave problem, $\\min_x\\max_y f(x,y), s.t., g(x,y)<=0$, where the funciton $g$ is a linear funciton so that the constraint set is a polytope. While the constrained sets in our paper are closed, convex and compact sets in domains $X$ and $Y$. That is, the constrained set in our paper is only a special case of [1]. Therefore, the problem used in our work is much simpler than that in [1].\n\n2.\tWe design an extra-gradient difference iteration in our algorithm, which is similar to the forms in [43] (i.e., the difference of gradients) to achieve the approximation of negative curvature of a Hessian matrix. That is, it goes beyond a first-order method，while a first-order method is studied in [1]. The negative curvature method [43] can escape from saddle points for non-convex optimization problems. Thus, we think that our method may escape from the saddle point of lower level nonconcave problem w.r.t. $y$, which is very hard to first-order methods. That is, our method can find a ""better"" solution of lower level nonconcave problem w.r.t. $y$, which is an important reason to reduce the hardness.\n\nAll the discussions will be included in the revised manuscript.\n\n**Q**: Furthermore, the proofs of the propositions and lemmas presented appear to be quite opaque, and verifying them poses a bit of a challenge. It would be truly beneficial if the authors could share some additional insights into the process behind the design and analysis of the algorithm. I think it would be good if the authors could provide a better commentary about the derivations of the proofs.\n\n**A**: To address your concern, we will provide more details about the derivations of the proofs, and add more detailed explanations for the process behind the design and analysis of the proposed algorithm in our final paper.\n\n**Q**: In line 242, I think ""conference"" was meant to be ""convergence"".\n\n**A**: To address your concern, we have corrected in the revised manuscript.\n\n**Q**: When considering the proof of proposition 2 in the appendix, is $\\widehat{u}_{t+1/2}$ identical to the one referred to in line 706? If so, clarifying this might prevent confusion.\n\n**A**: Yes, $\\widehat{u}_{t+1/2}$ is identical to the one referred to in line 706, and we have clarified this in the revised manuscript. \n\n**Q**:  In line 3 in Algorithm 1, do you also need to initialize $y_{-1}$ for the first iteration of the algorithm?\n\n**A**: Yes, we need to initialize $y_{-1}$, and have added such initialization in the revised manuscript.\n\n\n\n\n'}}, {'rebuttal': {'value': ""**Q**:  I suggest the authors to undertake additional analysis of the algorithm's time complexities, both theoretically and empirically. This deeper exploration would provide valuable insights, particularly for potential industrial applications.\n\n**A**:   Thanks for your positive and valuable comments. To address your concern, we will add the time complexity of the proposed algorithm for solving  min-max problems in the final version. In our algorithm, three gradients need to be calculated for each iteration update, the time complexity for constrained NC-NC setting is O((m+n)\\epsilon^{-2}), where m and n denote the dimensions of x and y, respectively. Moreover, we have conducted more empirical experiments and compared the performance of all the algorithms over the running time, as shown in Fig. 1 in the PDF file (please see “global” response). All the results show that the proposed algorithm converges significantly faster than other algorithms, as verified by theoretical and empirical analysis. All the results will be included in our final paper. \n\n**Q**: The absence of experiments conducted on the C-NC problem should be explained within the paper.\n\n**A**: To address your concern, we will add some discussions about the C-NC problem in the revised manuscript. In fact, there are few C-NC minimax problems in real-word applications, such as the convex-nonconcave zero sum game in [R1]. If necessary, we will add some experiments for solving such problem in the revised manuscript. \n\n[R1] G. Su, et al. Secrecy-oriented user association in ultra dense heterogeneous networks against strategically colluding adversaries. IET Commun., 2022.\n\n**Q**: There are some empirical evidences that seem to be inconsistent with the theoretical result, for example, FEG has a fast theoretical rate but is less effective in practice; GDA may not converge to stationary points. The authors may explain more about these in the paper.\n\n**A**:  To address your concern, we will make the following clarifications. In fact, FEG has a fast theoretical rate for the problem with an additional structured assumption. However, the NC-NC function used in Figure 1 in this paper does not satisfy the structured assumption. As a result, FEG has a slow convergence rate. In addition, we have conducted more experiments of FEG for the function in Figure 2 (please see “global” response), and reported empirical results in Fig. 2 in the PDF file. The results show that FEG converges much faster than GDA and EAG.\n\n\n\n""}}, {'rebuttal': {'value': '**Q**： Can you explain more about the ""quasi-cocoercivity"" property and discuss how it improves the convergence rate in the constrained NC-NC setting? Is this an absolutely necessary property for the improved convergence rate to hold?\n\n**A**:  Thanks for your positive and valuable comments. To address your concern, we will add some explanations about the ""quasi-cocoercivity"" property, and discuss how it improves the convergence rate in the constrained NC-NC setting in our final paper. From the perspective of theoretical analysis, we use the ""quasi-cocoercivity"" property to offset some residual terms produced by Propositions 1 and 2. As a result, we can obtain a descent sequence of the potential function, i.e., G_t. From the perspective of algorithmic intuition, the ""quasi-cocoercivity"" property is related to the extra-gradient difference iteration, which can improve the convergence rate. Thus, we think that it is a necessary property to improve the convergence rate.\n\n**Q**：Can your algorithm or its variants be applied to other minimax optimization problems beyond the constrained NC-NC setting?\n\n**A**:   To address your concern, we will make some discussions in the revised manuscript. The proposed algorithm can be extended to some problems beyond the constrained NC-NC setting. For example, for the robust neural network training problem, which does not require the compactness of the domain X (x is the parameter of the neural network), it goes beyond the constrained condition in the domain X. Furthermore, we can also extend the proposed algorithm to the stochastic setting to effectively solve large-scale problems. In addition, we also provide more experimental results  in Figs.3 and 4 in the PDF file for more real-world applications (please see “global” response). \n\n**Q**：There do exist some typos. For example in Eq. (4) in Line 215, missing factor 2 in the denominator. Should be minor but the authors should check more and correct them.\n\n**A**:   To address your concern, we have corrected these typos in the revised manuscript.\n\n'}}, {'summary': {'value': 'This paper discusses a new extra-gradient difference acceleration algorithm for solving constrained nonconvex-nonconcave minimax problems. The algorithm introduces a ""quasi-cocoercivity property"" and momentum acceleration to significantly improve the convergence rate in the constrained NC-NC setting. The algorithm attains a complexity of $O(\\epsilon^{-2})$ for finding an $\\epsilon$-stationary point of the function $f$, which outperforms the best-known complexity bounds. The paper also provides theoretical analysis and comparisons with existing algorithms.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'As a person who works in minimax optimization, I can make a fair judgment of this work. This paper presents a novel extra-gradient difference acceleration algorithm for solving constrained nonconvex-nonconcave minimax problems, which improves the existing convergence rate and outperforms the best-known complexity bounds to $O(\\epsilon^{-2})$. The paper also provides a comprehensive comparison with existing algorithms and a theoretical analysis of the algorithm\'s performance. I understand the ""extra-gradient difference prediction"" step as the key to the success of convergence rate improvements. In addition, I went through the proofs of Theorems 1 and 2 in detail. Overall, this paper provides valuable contributions to the field of minimax optimization and presents a promising algorithm for solving constrained NC-NC problems.'}, 'weaknesses': {'value': 'The paper assumes that the objective function satisfies certain structural assumptions, which may limit its practical applications. Also the writing style might not be as friendly for readers unfamiliar with the topic (I found it sufficiently clear though).'}, 'questions': {'value': '---Can you explain more about the ""quasi-cocoercivity"" property and discuss how it improves the convergence rate in the constrained NC-NC setting? Is this an absolutely necessary property for the improved convergence rate to hold?\n\n---Can your algorithm or its variants be applied to other minimax optimization problems beyond the constrained NC-NC setting?\n\n---There do exist some typos. For example in Eq. (4) in Line 215, missing factor 2 in the denominator. Should be minor but the authors should check more and correct them.'}, 'limitations': {'value': 'This paper is purely theoretical and does not admit negative social impacts to my best knowledge.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work proposes a single-loop extra-gradient difference acceleration algorithm to find an \\epsilon-stationary point for constrained minimax optimization, which pushes forward the best complexity bounds of NC-NC, C-NC, NC-C problems to \\mathcal{O}(\\epsilon^{-2}). The proposed approach can deal with more general problems as it does not require monotone or structural assumption. Moreover, for the NC-C problem, the authors prove that the proposed method has better complexity bound under the stationarity of \\phi. Experiments are conducted to validate the method empirically. The results show that it can achieve better convergence rate when comparing with the related methods.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1.\tThe theoretical contributions are significant. The method employs a novel prediction point scheme to obtain the quasi-cocoercivity property, which relaxes the assumption requirements. Additionally, the paper provides a thorough analysis of the convergence complexity bound, demonstrating its superiority over the current state-of-the-art approaches.\n\n2.\tThe paper is well organized and easy to follow. The logical flow of ideas is well-structured, enhancing the overall readability and comprehension of the presented contents.\n\n3.\tEmpirical studies are conducted to validate the method in both synthetic and real tasks.\n'}, 'weaknesses': {'value': ""There are some possible limitations where the paper could be further improved.\n\n1.\tI suggest the authors to undertake additional analysis of the algorithm's time complexities, both theoretically and empirically. This deeper exploration would provide valuable insights, particularly for potential industrial applications.\n\n2.\tThe absence of experiments conducted on the C-NC problem should be explained within the paper.\n\n3.\tThere are some empirical evidences that seem to be inconsistent with the theoretical result, for example, FEG has a fast theoretical rate but is less effective in practice; GDA may not converge to stationary points. The authors may explain more about these in the paper.\n""}, 'questions': {'value': 'please see above.'}, 'limitations': {'value': 'no negative societal impact'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""The authors have designed a single-loop accelerated algorithm for constrained min-max optimization problems of the form $\\min_{x\\in X}\\max_{y\\in Y} f(x,y)$. The algorithm provably converges in an approximate local stationary point in three particular setting: \n1. Non-convex non-concave min-max optimization, where the stationarity is measured for the function $f(x,y)$.\n2. Convex non-concave min-max optimization, and non-convex concave min-max optimization, where the stationarity is measured for function $\\phi(x)=\\max_{y'\\in Y} f(x,y')$. \n\nThe authors showed that their algorithm computes an $\\epsilon$-stationary point, in $O(1/\\epsilon^2)$ iterations. Finally, they experimentally verify their proposed algorithm.\n\n\n\nThe authors' rebuttal addressed my concerns, and their additional empirical evidence complemented their already compelling results. For these reasons, I decided to increase my score.""}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The design and analysis of algorithms for non-convex non-concave minimax optimization is a fundamental problem, and the convergent results are indeed compelling. Moreover, the authors get the state-of-the-art for convex non-concave, and concave non-convex for the merit function they consider. Furthermore the main paper is well-written and easy to follow, and the algorithm seems to combine several interesting ideas.\n\nI verified the proofs of proposition 1 and 2, and the rest of the statement seems reasonable. I found the proofs of proposition 1 and 2 to be a bit dense, which made verifying them somewhat taxing.'}, 'weaknesses': {'value': 'Overall, I did not find some important weakness in the paper. As a suggestion, improving the readability and verifiability of the proofs could greatly benefit readers. Lastly, I came across a couple of typos:\n- In line 242, I think ""conference"" was meant to be ""convergence"".\n- When considering the proof of proposition 2 in the appendix, is $\\widehat{u}_{t+1/2}$ identical to the one referred to in line 706? If so, clarifying this might prevent confusion.\n- In line 3 in Algorithm 1, do you also need to initialize $y_{-1}$ for the first iteration of the algorithm?'}, 'questions': {'value': 'The recent work in [1], shows that the computation of an approximate stationary point is PPAD-complete when the action space of the two players is a joint. Notably, the findings in your paper seem to suggest a different outlook when the strategy space of the two players is a product space, which negates the hardness results. A comment from the authors addressing this observation would be greatly appreciated.\n\nFurthermore, the proofs of the propositions and lemmas presented appear to be quite opaque, and verifying them poses a bit of a challenge. It would be truly beneficial if the authors could share some additional insights into the process behind the design and analysis of the algorithm. I think it would be good if the authors could provide a better commentary about the derivations of the proofs.\n\n[1] ""The Complexity of Constrained Min-Max Optimization"" by Constantinos Daskalakis, Stratis Skoulakis, and Manolis Zampetakis'}, 'limitations': {'value': 'Any assumptions needed for the theorems to hold are listed. I do not believe this work can have negative societal impact.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'Authors propose method of solving nonconvex-nonconcave saddle point problems with convergence rate O(eps^-2) by using gradient difference prediction and momentum acceleration to improve extragradient descent-ascent method. Proposed method is state-of-the-art in theory and leading in practice, including neural network learning with adversarial attacks task.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'Quite elegant construction of the algorithm, which also allows one to obtain best-known convergence rate guarantees. Algorithms allows practitioners to address the most practically important setting of nonconvex-nonconcave problems efficiently using easy to implement algorithm which will surely replace analogous methods, judging from empirical study.'}, 'weaknesses': {'value': 'No significant weaknesses'}, 'questions': {'value': 'Authors could provide more extensive empirical study, because algorithm seems to be candidate for being widely-accepted in practice and it would be good to have more justifications of its efficiency. '}, 'limitations': {'value': 'Everything is okay'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'A Single-Loop Accelerated Extra-Gradient Difference Algorithm with Improved Complexity Bounds for Constrained Minimax Optimization'}, 'authors': {'value': ['Yuanyuan Liu', 'Fanhua Shang', 'Weixin An', 'Junhao Liu', 'Hongying Liu', 'Zhouchen Lin']}, 'authorids': {'value': ['~Yuanyuan_Liu1', '~Fanhua_Shang2', '~Weixin_An1', '~Junhao_Liu3', '~Hongying_Liu2', '~Zhouchen_Lin1']}, 'keywords': {'value': ['Constrained Minimax Optimization; nonconvex- nonconcave']}, 'abstract': {'value': 'In this paper, we propose a novel extra-gradient difference acceleration algorithm for solving constrained nonconvex-nonconcave (NC-NC) minimax problems. In particular, we design a new extra-gradient difference step to obtain an important quasi-cocoercivity property, which plays a key role to significantly improve the convergence rate in the constrained NC-NC setting without additional structural assumption. Then momentum acceleration is also introduced into our dual accelerating update step. Moreover, we prove that, to find an $\\epsilon$-stationary point of the function $f$, our algorithm attains the complexity $\\mathcal{O}(\\epsilon^{-2})$ in the constrained NC-NC setting, while the best-known complexity bound is $\\widetilde{\\mathcal{O}}(\\epsilon^{-4})$, where $\\widetilde{\\mathcal{O}}(\\cdot)$ hides logarithmic factors compared to $\\mathcal{O}(\\cdot)$. As the special cases of the constrained NC-NC setting, our algorithm can also obtain the same complexity $\\mathcal{O}(\\epsilon^{-2})$ for both the nonconvex-concave (NC-C) and convex-nonconcave (C-NC) cases, while the best-known complexity bounds are $\\widetilde{\\mathcal{O}}(\\epsilon^{-2.5})$ for the NC-C case and $\\widetilde{\\mathcal{O}}(\\epsilon^{-4})$ for the C-NC case. For fair comparison with existing algorithms, we also analyze the complexity bound to find $\\epsilon$-stationary point of the primal function $\\phi$ for the constrained NC-C problem, which shows that our algorithm can improve the complexity bound from $\\widetilde{\\mathcal{O}}(\\epsilon^{-3})$ to $\\mathcal{O}(\\epsilon^{-2})$. To the best of our knowledge, this is the first time that the proposed algorithm improves the best-known complexity bounds from $\\mathcal{O}(\\epsilon^{-4})$ and $\\widetilde{\\mathcal{O}}(\\epsilon^{-3})$ to $\\mathcal{O}(\\epsilon^{-2})$ in both the NC-NC and NC-C settings.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/1e269f46b6083f1d64c56f6193b62244969bddf1.pdf'}, 'supplementary_material': {'value': '/attachment/0d93bd18befd0637b82a35fc9be68f3b9be0e37c.pdf'}, '_bibtex': {'value': '@inproceedings{\nliu2023a,\ntitle={A Single-Loop Accelerated Extra-Gradient Difference Algorithm with Improved Complexity Bounds for Constrained Minimax Optimization},\nauthor={Yuanyuan Liu and Fanhua Shang and Weixin An and Junhao Liu and Hongying Liu and Zhouchen Lin},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=wIlmx4bHrO}\n}'}, 'paperhash': {'value': 'liu|a_singleloop_accelerated_extragradient_difference_algorithm_with_improved_complexity_bounds_for_constrained_minimax_optimization'}}]"
"['Spyridon Kondylatos', 'Ioannis Prapas', 'Gustau Camps-Valls', 'Ioannis Papoutsis']",NeurIPS,Mesogeos_ A multi-purpose dataset for data-driven wildfire modeling in the Mediterranean,https://neurips.cc/virtual/2023/oral/73742,2023," We introduce Mesogeos, a large-scale multi-purpose dataset for wildfire modeling in the Mediterranean. Mesogeos integrates variables representing wildfire drivers (meteorology, vegetation, human activity) and historical records of wildfire ignitions and burned areas for 17 years (2006-2022). It is designed as a cloud-friendly spatio-temporal dataset, namely a datacube, harmonizing all variables in a grid of 1km x 1km x 1-day resolution. The datacube structure offers opportunities to assess machine learning (ML) usage in various wildfire modeling tasks. We extract two ML-ready datasets that establish distinct tracks to demonstrate this potential: (1) short-term wildfire danger forecasting and (2) final burned area estimation given the point of ignition. We define appropriate metrics and baselines to evaluate the performance of models in each track. By publishing the datacube, along with the code to create the ML datasets and models, we encourage the community to foster the implementation of additional tracks for mitigating the increasing threat of wildfires in the Mediterranean.",Oral 4B Datasets & Benchmarks,https://openreview.net/pdf?id=VH1vxapUTs,https://openreview.net/forum?id=VH1vxapUTs,VH1vxapUTs,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (Oral)'}, 'comment': {'value': ""This submission introduces a novel dataset for wildfire modelling in the Mediterranean. \n\nIt consists of historical records for over 17 years of wildfire ignitions and burned areas. It further provides benchmarks for two tasks using the dataset: (i) wildfire danger forecasting and (ii) burned area estimation after ignition. Given the breadth and depth of the dataset and benchmark, the highly important topic, solid baselines, and the reviewers' feedback and excellent ratings, the decision is to recommend this paper for acceptance as oral presentation.""}}, {'comment': {'value': 'I would like to thank for the authors for their responses in the rebuttal and addressing the points raised in my review. I leave my rating for the paper the same.'}}, {'title': {'value': 'Reviewer Comment'}, 'comment': {'value': 'Thank you for the response. This makes sense to me.'}}, {'title': {'value': 'Mesogeos: A multi-purpose dataset for data-driven wildfire modeling in the Mediterranean'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '3: The reviewer is fairly confident that the evaluation is correct'}, 'summary_and_contributions': {'value': 'For the application of ML models collecting and formatting large and disparate datasets is critical but challenging.  The authors have done much of the heavy lifting by creating the Mesogeos dataset for wildfire prediction.  This is a societal beneficial enterprise on a very important hazard, wildffires in the Mediterranean region as exemplified by this summer.'}, 'strengths': {'value': 'Creation of the Mesogeos dataset and accompanying ML models.'}, 'opportunities_for_improvement': {'value': 'Incorporation of more datatsets, which currently heavily relies on ERA5 and MODIS.'}, 'limitations': {'value': 'I thought that the authors did a very good job describing the limitations.'}, 'correctness': {'value': 'This is a well written and constructed submission.'}, 'clarity': {'value': 'Excellent writing, kudos to the authors!'}, 'relation_to_prior_work': {'value': 'Very nice Introduction and contextualization with prior work.'}, 'documentation': {'value': 'Documentation is sufficient.'}, 'ethics': {'value': 'I have no ethical concerns with the study.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'N/A'}}, {'comment': {'value': 'We are glad that the reviewer has updated the score after our response. \n\n> Can the authors explain why the data is significantly more balanced than standard wildfire datasets?\n\nThis has been covered in the global response addressed to all reviewers. In a nutshell:\n- The Mesogeos cube is not balanced, covering the whole Mediterranean. Fire is a ""rare"" phenomenon spatiotemporally and this is evident in the Mesogeos cube.\n- Dataset for Track A is sampled from the Mesogeos cube and is indeed balanced as a choice, similar to related literature (citations 1, 2, 3, 4 in the global response). \n- This split is intended to be used for benchmarking the performance of different ML models and not to demonstrate the real-world performance\n\nMoreover, we would like to highlight that in Track A we sample non-burned cells (aka negatives) alongside fire events (positives) for the classification task, unlike standard wildfire spread literature (43, 44, 45) where datasets typically only consist of fire events and the imbalance occurs from the dominance of small fires.'}}, {'title': {'value': 'Reviewer Comment'}, 'comment': {'value': 'I am happy with the rebuttal and have reflected it in my score. I am still a bit unclear about the data distribution. Can the authors explain why the data is significantly more balanced than standard wildfire datasets?'}}, {'comment': {'value': '> The claim that VIIRS is inconsistent compared to MODIS…is unsubstantiated.\n\nTo the best of our knowledge, we have not made any claims in the paper that VIIRS is inconsistent compared to MODIS. However, we believe this comment arose due to the fact that we had wrongly clustered works 43, 44, 45 stating they all use MOD14A1. Only Huot et al uses that product, while the two other use VIIRS. We have corrected that part (lines 104-106), and we thank the reviewer for raising our attention to this. Additionally, the comment allowed us to reflect on the fact that it is important to discuss the VIIRS and MODIS active fire and burned areas products that most wildfire datasets depend on. This has been expanded in the related work section (lines 68-88). \n\n> 1) I am concerned about how prior work is presented…\n> 2) How does the proposed dataset differ from references 36 and 37 other than the source from which the target variable was obtained?\n\nWe have made significant revisions to the Related Work section. We appreciate the reviewer’s suggestion, as we believe it allowed us to improve the clarity and comprehensiveness of this section. \n\nFor 1), we incorporated information about the VIIRS satellite along with its advantages compared to MODIS and we introduced a discussion about the VIIRS and MODIS products in lines 68-88, declaring also their limitations.\n\nFor 2), we introduced a paragraph, comparing our dataset with the other existing datasets, including datasets 36-37. Specifically for the distinction of our datasets we note (see also lines 110-125):\n\n1) Mesogeos is a multi-purpose dataset that can be used to address several tasks, while the two datasets 36-37 are tailored for predicting wildfire spread. This task cannot be treated with Mesogeos because it contains accurate information on the burned area but no information on the evolution of the wildfire (see lines 355-360).\n2) Mesogeos incorporates a wide range of daily inputs covering fire drivers across the entire region of interest, while 36-37 introduce data points related only to specific fire events.\n3) In Mesogeos, we use the burned areas product from EFFIS as an anchor for a fire event, refining it using the MODIS active fires, while datasets 36 and 37 use an active fire product as the target of the modeling\n4) Mesogeos covers the Mediterranean, while 36-37 the USA \n\nSpecifically for point 3, we would like to provide some more clarifications, as this is also related to question 4. In datasets 36, 37 the active fire product is used as the target. This induces uncertainty regarding when a hotspot corresponds to a specific fire event and when not (as highlighted in the Limitation section in 37). In Mesogeos, a burned area product (EFFIS) is used as a representative for each fire event. Then the MODIS active fire product is used only for the refinement of the date and the declaration of the ignition point (see lines 191-203). Although this choice of target may have limitations in addressing tasks like fire spread prediction as there is a lack of temporal information of the fire evolution (see lines 355-360), it ensures a more reliable target, which is derived from a post-processed burned area product.\n\n> 3) …The data mentioned in this paper is surprisingly balanced\n\nWe have included a complete answer in the global response.\n\n> 4) collecting data about interventions is hard, but I would encourage the authors to mention this and potentially include a discussion…The distinction between whether a fire spread to a neighboring spatial location versus a new fire started in hard to model…how do the authors take this challenge into consideration?\n\nIn response to the first part regarding the actions of firefighters, we would like to highlight that we have already included a small discussion addressing this matter in the Limitations section, specifically in lines 364-367. Following the reviewer’s comment we have further expanded this discussion in lines 361-364. We note, though, that firefighting practices vary across regions and evolve over time, as well as the fact that these data often remain proprietary and inaccessible to the public. Nonetheless, we would like to emphasize that if access to such data is available, they can be easily integrated in the Mesogeos datacube. This is facilitated by the fact that i) the repo contains code to expand the datacube and ii) the datacube itself includes precise metadata such as geographical information for each grid cell.\n\nFor the second part, related to the distinction between fire spread and new fire occurrence, firstly we should highlight that the anchor for defining a fire event in this dataset is the final burned area from EFFIS and not the active fire product. As such, the dataset does not contain any intermediate information about the spread, and each wildfire event is represented by its final burned area (this has been explicitly added in the limitations in lines 358-360, see answers 1, 2 above).'}}, {'comment': {'value': '> The dataset is huge w.r.t. memory usage. \n\nThough the dataset is huge, we facilitate its use: \n- To prevent the need for local downloading, we uploaded the dataset to a public S3 bucket for cloud-access and added instructions in GitHub on how to access it\n- The datacube is shared in a cloud-optimized zarr format that allows users to lazily access parts of it without loading it in memory\n- We provided the 2 ML datasets used for the 2 tracks, which are manageable in size. \n- We shared the code to extract the datasets.\n\n> more explicitly model the level of risk as a more multi-label classification problem?\n\nWildfire danger has been many times tackled as a binary classification task (citations 20, 42, 60). Here, we also incorporate the information from the burned area size (lines 208-218, 230-236), to associate larger fires with higher danger. However, alternative formulations could be explored to model wildfire danger. These include a multi-class approach, where the labels could be extracted based on the size of the fires (lines 300-306).\n\n> consider using the VIIRS AF instead or is the difference in resolutions make this not feasible?\n\nWe do not use the MODIS AF product as a proxy for fire ignitions. Instead, we determine the burned areas from the EFFIS as ""correct"", more reliable products. We then use the MODIS AF ONLY to find the ignition date and point of the fire. \n\nWe did not incorporate VIIRS because:\n- VIIRS started in 2012, whereas the datacube spans from 2006 onwards. This gap would introduce an inconsistency in dataset collection\n- Mesogeos contains satellite variables (NDVI, LST) from MODIS. We want to avoid a wrong ignition date that may leak target data into these variables, aka an ignition date after the actual start of the fire. We ensure that using the MODIS AF to move the ignition date back, in case AF have been detected before the EFFIS-derived start of the fire. \n\nWe expanded the Related Work in lines 68-88 and added a few lines in Section 3 (195-196, 200-202) for this.\n\n> How hard would it be to ""fix"" and or clean-up at least the labels for the test sets?\n\nIn the context of burned areas, we have minimized the noise, using what we consider the best available product in Europe (EFFIS) and by refining it using the MODIS AF product.\n \nFrom an ML perspective, noise is mostly evident in the labels in the negatives. A potential approach for this would be to treat the task as a Noisy Labels problem (citation 75). The noise can also be associated with aleatoric uncertainty (citation 76). We added some lines for this (341 - 344) . \n\n> The training for the predictor in Task 1 is a little confusing\n\nWe weigh the samples’ contribution to the loss according to the final burned area size, assuming that the larger fires are associated with higher danger. This emulates what is done in other works that is closer to importance sampling (citation 42) that uses all the grid cells affected by fire, implicitly weighing fire events by the number of cell grids burned. We use one representative grid cell and weigh it as follows: We multiply its loss with the burned area size that corresponds to the sample. The loss is getting higher, if it corresponds to a larger fire. In practice, in order to prevent the larger fires from dominating the learning process, we multiply with the log of the burned area size. \n\nThis is better explained in lines 232-235.\n\n> ..semantic segmentation metrics... Were other baseline architectures considered for this task…?\n\nThe objective is to estimate the likelihood of neighboring pixels being affected by a fire, following an ignition. Instead of a binary mask, it’s more interesting to differentiate between the more and less probable cells for the fire to expand to. Thus, traditional segmentation metrics were not used. Instead, we used metrics that can capture the skill of this differentiation ability. As this was not clear, we made some revisions (lines 260-261, 263-265, 267-268). \n\nWe have not tried other baselines, as we found it out of scope for this paper to find the best models for the task, but rather a reasonable baseline. However, we encourage other practitioners to develop models that surpass it.\n\n> Would considering spatially neighbouring inputs be beneficial or would it make the training harder?\n\nWe explored this in our prior work (citation 42) and found that spatial context did not significantly enhance the results. Thus, we decided to make it easier for users to work with a smaller dataset rather than creating a much larger dataset that may provide little or no gain. Practitioners can extract such a dataset, using the template extraction code.\n\n> How much harder would this increase in the imbalance between positive and negative samples at test time make the problem…?\n\nWe have included an answer in the global response.\n\n> How much data is missing where?\n\nWe present in the Supplementary Material (Figure 2) the distribution of the number of fires per country in EFFIS. \n'}}, {'comment': {'value': 'We are very glad for the positive feedback and agree with the reviewer’s suggestions that we implemented.\n\nChanges made: We have added colorbars in Figures 2 and 3 as suggested.\n'}}, {'title': {'value': 'Global Response'}, 'comment': {'value': 'We would like to thank all the reviewers for their constructive feedback and suggestions, which have contributed to the enhancement of the quality of the manuscript.\n\nBased on the comments, we have updated the manuscript PDF for revision. Additionally, we have included a version of the manuscript with the changes based on the reviewers’ comments inside the Supplementary Material zip file (the name of the file is revised.pdf). The changes are colored in red.\n\nIn this general response, we present the most important changes that have been implemented after the reviewers’ comments: \n\n- The related work has been expanded with a better description of open satellite-derived data for burned areas and active fires, as well as a better comparison with previous work, highlighting distinctions between our dataset and existing ones.\n- We have refined the Task Formulation and Experimental Setup paragraphs of the two ML tracks to offer a better explanation of the training processes. In Track A, we have also provided a more comprehensive explanation of the weighting scheme employed. \n- We have changed/added the color bars in Figures 2 and 3\n- Clarifying sentences have been added to Ignition Date Calculation paragraph of section 3 to better explain how the cross-reference between the EFFIS product and MODIS AF happens. \n- We have made a slight modification to the Beyond traditional ML paragraph of the Potential Other Tracks to Explore section, to incorporate an approach focusing on Noisy Labels/Uncertainty estimation.\n- We have expanded on the limitations of our study related to the lack of wildfire behavior data and information on fire suppression.\n\nFinally, we would like to address a concern raised by both reviewers vRfc and cj7g regarding the dataset distribution in Track A. The concern of the two reviewers is that in real-world scenarios the data will be much more imbalanced than the 2:1 ratio between negatives and positives that are used in the current study. While we acknowledge that the imbalance is much higher in the real world than in the sampled datasets, our negative/positives split is well-suited to benchmark the performance of different ML models. This is in line with existing wildfire danger literature [1, 2, 3, 4]. Moreover, It is valid to say that the test set may not fully reflect real-world precision, but it does for recall. Using the Mesogeos cube, it is entirely possible to measure real-world precision (e.g. by measuring the performance of the entire region for some days). Furthermore, it is possible to calibrate any models developed with the sampled datasets [5]. Finally, we would like to stress that it is out of the scope of this work to provide operational solutions. To apply ML-based models in an operational context, one would need to measure real-world performance across fire seasons and extensively compare against non-ML baselines. (See lines 369 - 370). In that setup, the Mesogeos dataset can be exploited to investigate the use of ML methods for operational firefighting planning and decision-making. \n\n[1] Bjånes, Alexandra, Rodrigo De La Fuente, and Pablo Mena. “A Deep Learning Ensemble Model for Wildfire Susceptibility Mapping.” Ecological Informatics 65 (August 1, 2021): 101397. https://doi.org/10.1016/j.ecoinf.2021.101397.\n\n[2] Le, Hung Van, Duc Anh Hoang, Chuyen Trung Tran, Phi Quoc Nguyen, Van Hai Thi Tran, Nhat Duc Hoang, Mahdis Amiri, et al. “A New Approach of Deep Neural Computing for Spatial Prediction of Wildfire Danger at Tropical Climate Areas.” Ecological Informatics 63 (April 1, 2021): 101300. https://doi.org/10.1016/j.ecoinf.2021.101300.\n\n[3] Zhang, Guoli, Ming Wang, and Kai Liu. “Forest Fire Susceptibility Modeling Using a Convolutional Neural Network for Yunnan Province of China.” International Journal of Disaster Risk Science 10, no. 3 (September 2019): 386–403. https://doi.org/10.1007/s13753-019-00233-1.\n\n[4] Kondylatos, S., Prapas, I., Ronco, M., Papoutsis, I., Camps‐Valls, G., Piles, M., ... & Carvalhais, N. (2022). Wildfire danger prediction and understanding with Deep Learning. Geophysical Research Letters, 49(17), e2022GL099368.\n\n[5] Pozzolo, Andrea Dal, Olivier Caelen, Reid A. Johnson, and Gianluca Bontempi. “Calibrating Probability with Undersampling for Unbalanced Classification.” In 2015 IEEE Symposium Series on Computational Intelligence, 159–66. Cape Town, South Africa: IEEE, 2015. https://doi.org/10.1109/SSCI.2015.33.'}}, {'title': {'value': 'Review of Mesogeos'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'The paper by Kondylatos et al. introduces a new dataset for data-driven wildfire modelling in the Mediterranean and compares several benchmark performances for two prediction tasks: (a) wildfire danger/risk forecasting and (b) burned area estimation following ignition. \n\nTo the best of my knowledge this dataset in its composition is highly novel, was further enhanced by the authors addressing a few source data limitations (e.g. start dates of fires), and will find many users across multidisciplinary communities.'}, 'strengths': {'value': 'See also above. The paper makes a highly valuable, and - sadly - timely/topical contribution given the current wildfires in the Mediterranean. Studying and forecasting wildfires will become an ever more important task, also to effectively address climate change adapation, for example.\n\nI rarely have as few corrections for any paper. The authors wrote an excellent paper, making the big picture accessible while also reporting important details, e.g. on interpolation methods in the Supplementary. It was really a pleasure to read.'}, 'opportunities_for_improvement': {'value': 'My only concern is the labelling of the colorbars in Figures 2 and 3. While labels low->high would probably suffice in TV broadcasting, it is not clear if this is a linear colorbar varying simply between values 0 and 1...number labels should be added.\n\nEven more so, I am entirely left in the dark concerning the colours in Figure 3, because there is no colorbar, which should be added for scientific rigour.'}, 'limitations': {'value': 'The limitations have been well discussed and addressed by the authors, well beyond what I would consider normal.'}, 'correctness': {'value': 'Yes, that seems very good.'}, 'clarity': {'value': 'The paper is very well and clearly written indeed.'}, 'relation_to_prior_work': {'value': 'This seems appropriate to me.'}, 'documentation': {'value': 'From initial checks, this all seems fine.'}, 'ethics': {'value': 'The are no concerns from my side.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'N/A'}}, {'title': {'value': 'A well written and timely paper introducing a wildfire modelling dataset'}, 'rating': {'value': '7: Good paper, accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'This paper introduces the large-scale spatio-temporal Mesogeos Datacube (1km x 1km x 1day resolution). It consists of weather measurements, vegetation and human activity data from 2006-2022 in the Mediterranean region.  EFFIS and the MODIS active fire product are used to estimate when and where wildfires ignited and the final burnt area created by the wildfire. The wildfire modelling tasks involve the prediction tasks of  ""wildfire danger forecasting"" and ""final burned area prediction"" using input from the datacube. \n\nThe contributions of the paper are:\n - It introduces a ""clean, standardized"" spatio-temporal datacube with relevant data for wildfire prediction tasks. This will save the ML researcher the hassle of interacting with the tangled web of primary sources if they want to work on this important problem.\n - It highlights wildfire modelling tasks to the ML community with its well written introduction and related work sections, and the ""Potential other tracks to explore"" section. In tandem it sets researchers up with a manageable data-structure to experiment with. This is a critically important field as can be seen from recent and current wildfire events and ML conferences should be actively promoting work in this area.\n - The paper defines two standard wildfire tasks and provides reasonable baselines for each.'}, 'strengths': {'value': 'The strengths of the paper are:\n\n- The nicely presented overview of the application domain and the well written nature of the paper.\n- The introduction of two standard but challenging tasks to the ML community within the wildfire modelling community.\n- The datacube is a comprehensive spatio-temporal set of inputs to base wildfire modelling on. '}, 'opportunities_for_improvement': {'value': '- The dataset is huge w.r.t. memory usage. It would be nice to have a smaller but still meaningful version of the dataset to allow it to be used be a broader set of researchers to use locally.\n\n- The training for the predictor in Task 1 is a little confusing. It would be great if this could be made clearer. Also at the moment it is formulated as a binary classification problem, however, it appears the authors consider it as a more fine-grained classification problem that is the ""level of danger"". Would it make sense to more explicitly model the level of risk as a more multi-label classification problem with each class representing a danger level?\n\n- The paper mentions that the MODIS AF product is not so accurate, but then it is still used to find the ignition date (in conjunction with the EFFIF data). Did the authors consider using the VIIRS AF instead or is the difference in resolutions make this not feasible?'}, 'limitations': {'value': '- There is probably noise in the labels both in the training, validation and test splits due to the factors explained in the paper. However, how, hard would it be to ""fix"" and or clean-up at least the labels for the test sets? '}, 'correctness': {'value': '- The training and modelling of the task used in Task 1 is a somewhat confusing:\n\n       In line 193  the authors describe how they weight the CE loss relative to burned area size to ""learn to assign greater danger to larger fires"". This is somewhat confusing as it is stated that Task 1 is treated as a binary classification problem for each cell in the grid:  danger of fire/ no fire. Normally for a weighted CE loss a separate weight is assigned to each class typically to cope with the class imbalance problem. However, instead in the paper each training example is given its own weight. How exactly is this weighting used? Is some form of importance sampling performed so that grid cells associated with larger fires more frequently sampled during training? Some clarification on this point would be great. Also does the weighting imposed make it harder to detect small fires and is this the desired outcome? \n\n      It would appear that formulating the problem as a more fine-grained multi-label (encoding level-of-danger and/or potential area of spread of fire) or as a regression problem would make for a set-up more in keeping with the desired outcome of the authors.\n\nA few minor points:\n\n- Task 2 is considered as a segmentation task. It would be good if the metrics reported in table 2 also included some of the  more common metrics associated with semantic segmentation such as F1 score, IoU etc... Were other baseline architectures considered for this task apart from the U-Net? \n\n- In Task 1 the input to each classifier is a temporal sequence of features from one spatial grid cell. Would considering spatially neighbouring inputs be beneficial or would it make the training harder?\n\n- Also in task 1 at test time the negative samples are somewhat sparsely sampled and there are only twice as many negative samples as positive samples. I would presume in most real world situations the number of negative samples would be far more than positive ones.  How much harder would this increase in the imbalance between positive and negative samples at test time make the problem and would the false positive rate increase a lot? \n\n- Lines 157-160: How much data is missing where?'}, 'clarity': {'value': 'The paper is well-written and very easy to read. '}, 'relation_to_prior_work': {'value': 'Yes this is well described. '}, 'documentation': {'value': 'Yes.'}, 'ethics': {'value': 'No.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'see rest of the comment.'}}, {'title': {'value': 'Important wildfire dataset but several clarifications are needed'}, 'rating': {'value': '7: Good paper, accept'}, 'confidence': {'value': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'summary_and_contributions': {'value': 'The dataset potentially benefits the machine learning, climate science, policy, and fire response communities. However, there are several clarifications needed. I am open to having a discussion in the author response period to change my score/understand the paper better.'}, 'strengths': {'value': 'The dataset is comprehensive, large, and shows several important demonstrations of how it can be used (unlike prior work). The area under coverage is also novel, as other large fire spread databases (e.g., WildfireDB) have mostly focused on North America.'}, 'opportunities_for_improvement': {'value': 'I have the following questions/suggestions:\n\n1. I am concerned about how prior work is presented; e.g., references 36 and 37 are said to have used the ""inconsistent"" MOD14A1 product as the target variable. VIIRS has a higher resolution than MODIS (375 vs. 1000m per pixel) and increased night-time fire detection performance. While MODIS does have its advantages (e.g., crisp background detection that can translate to improved fire detection), this distinction and the advantages and disadvantages of prior work should be clearly highlighted. The claim that VIIRS is inconsistent compared to MODIS (that the current paper uses) is unsubstantiated, especially when a detailed discussion is omitted. \n\n2. On a related note, how does the proposed dataset differ from references 36 and 37 other than the source from which the target variable was obtained?\n\n3. Fire occurrence and spread data are typically extremely imbalanced, which in turn results in poor performance of off-the-shelf predictive models. The data mentioned in this paper is surprisingly balanced, e.g., the final dataset has 33.3% positives as opposed to less than 5% positives in prior wildfire databases (e.g., WildfireDB). Can the authors clarify why this is the case?\n\n4. Two important bottlenecks in modeling data-driven models for fire spread are:\na) Modeling Response: A lot of wildfires are actually stopped from spreading by firefighters, potentially confounding the data about intrinsic fire spread conditional on environmental parameters such as weather, land patterns, etc. How do the authors include this? I acknowledge that collecting data about interventions is hard, but I would encourage the authors to mention this and potentially include a discussion. \nb) Modeling new fires vs spread: The distinction between whether a fire spread to a neighboring spatial location versus a new fire started in hard to model. In predicting spread over large areas such as 64km x 64km, how do the authors take this challenge into consideration?'}, 'limitations': {'value': 'See above.'}, 'correctness': {'value': 'The claims are mostly correct, other than some clarifying questions that I pointed out above.'}, 'clarity': {'value': 'The paper is well-written.'}, 'relation_to_prior_work': {'value': 'Yes, other than clarifying questions mentioned above.'}, 'documentation': {'value': 'Yes.'}, 'ethics': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'N/A.'}}, {'title': {'value': 'Mesogeos: A multi-purpose dataset for data-driven wildfire modeling in the Mediterranean'}, 'authors': {'value': ['Spyros Kondylatos', 'Ioannis Prapas', 'Gustau Camps-Valls', 'Ioannis Papoutsis']}, 'authorids': {'value': ['~Spyros_Kondylatos2', '~Ioannis_Prapas1', '~Gustau_Camps-Valls1', '~Ioannis_Papoutsis1']}, 'keywords': {'value': ['wildfires', 'public dataset', 'machine learning dataset']}, 'abstract': {'value': 'We introduce Mesogeos, a large-scale multi-purpose dataset for wildfire modeling in the Mediterranean. Mesogeos integrates variables representing wildfire drivers (meteorology, vegetation, human activity) and historical records of wildfire ignitions and burned areas for 17 years (2006-2022). It is designed as a cloud-friendly spatio-temporal dataset, namely a datacube, harmonizing all variables in a grid of 1km x 1km x 1-day resolution. The datacube structure offers opportunities to assess machine learning (ML) usage in various wildfire modeling tasks. We extract two ML-ready datasets that establish distinct tracks to demonstrate this potential: (1) short-term wildfire danger forecasting and (2) final burned area estimation given the point of ignition. We define appropriate metrics and baselines to evaluate the performance of models in each track. By publishing the datacube, along with the code to create the ML datasets and models, we encourage the community to foster the implementation of additional tracks for mitigating the increasing threat of wildfires in the Mediterranean.'}, 'venue': {'value': 'NeurIPS 2023 Datasets and Benchmarks Oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Track/Datasets_and_Benchmarks'}, 'TLDR': {'value': 'This paper introduces Mesogeos, a large-scale multi-purpose dataset for wildfire modeling in the Mediterranean.'}, 'pdf': {'value': '/pdf/525f542aa1512d8ddea9f1117ccc2be9845c82b4.pdf'}, 'supplementary_material': {'value': '/attachment/4d56fa9ada118259b640ac5e7e734d1ebf34b357.pdf'}, '_bibtex': {'value': '@inproceedings{\nkondylatos2023mesogeos,\ntitle={Mesogeos: A multi-purpose dataset for data-driven wildfire modeling in the Mediterranean},\nauthor={Spyros Kondylatos and Ioannis Prapas and Gustau Camps-Valls and Ioannis Papoutsis},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\nyear={2023},\nurl={https://openreview.net/forum?id=VH1vxapUTs}\n}'}, 'paperhash': {'value': 'kondylatos|mesogeos_a_multipurpose_dataset_for_datadriven_wildfire_modeling_in_the_mediterranean'}}]"
"['Matthew Jagielski', 'Milad Nasr', 'Katherine Lee', 'Christopher A. Choquette-Choo', 'Nicholas Carlini', 'Florian Tramer']",NeurIPS,Students Parrot Their Teachers_ Membership Inference on Model Distillation,https://neurips.cc/virtual/2023/oral/73842,2023," Model distillation is frequently proposed as a technique to reduce the privacy leakage of machine learning. These empirical privacy defenses rely on the intuition that distilled student'' models protect the privacy of training data, as they only interact with this data indirectly through a teacher'' model. In this work, we design membership inference attacks to systematically study the privacy provided by knowledge distillation to both the teacher and student training sets. Our new attacks show that distillation alone provides only limited privacy across a number of domains. We explain the success of our attacks on distillation by showing that membership inference attacks on a private dataset can succeed even if the target model is never queried on any actual training points, but only on inputs whose predictions are highly influenced by training data. Finally, we show that our attacks are strongest when student and teacher sets are similar, or when the attacker can poison the teacher set.",Oral 5B Privacy/Fairness,https://openreview.net/pdf?id=a2Yg9Za6Rb,https://openreview.net/forum?id=a2Yg9Za6Rb,a2Yg9Za6Rb,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': ""The paper discusses a crucial issue of privacy in the face of model distillation.  Reviewers unanimously agree on the significance of the contributions made. Strengths highlighted by the reviewers include the paper's remarkable clarity and the thoroughness of experiments.\n\nThe reviewers also highlight the paper's contribution by dispelling a misconception that distillation safeguards data privacy. By spotlighting factors such as data duplication, teacher set poisoning, temperature scaling, and distribution shifts, the authors enrich the discourse on the topic.""}}, {'title': {'value': 'Thank you for the clarification'}, 'comment': {'value': 'Thank you for the clarification. My questions were appropriately addressed!'}}, {'title': {'value': 'Answer Rebuttal'}, 'comment': {'value': 'Thank you for your rebuttal.\nAll my questions were appropriately addressed, and I will raise my score from 7 --> 8 to `Strong Accept`.'}}, {'comment': {'value': 'Thank you for the clarifications. Particularly for reporting the accuracy numbers. I think including them in the final version will help the reader the get a better picture of the experimental setting and help reproducibility.'}}, {'title': {'value': 'Addressing the rebuttal #1'}, 'comment': {'value': 'Thank you for your rebuttal!\n\nI am happy with the responses and I have increased my score by another point (7 --> 8). \n\nOn a similar note, I found this paper on `déjà vu memorization` (https://arxiv.org/abs/2304.13850) which might be relevant for quantifying memorization through feature correlations. For future work, it might be nice to explore threat models around how privacy could be compromised by learning sensitive (correlated) features!'}}, {'rebuttal': {'value': 'Thank you for your time and effort in reading our submission and writing your review! \n\n>**Line 94:** Sorry about this! Actually, every point is a small blue plus sign! We will explain this clearly in the caption.\n\n>**Q1:** We follow the evaluation strategy used to evaluate LiRA, where each model is trained on a different 50% split of the dataset. That ensures these models differ in their membership inference behavior.\n\n>**Q2:** The LiRA strategy trains many shadow models on a random 50% subsample of the teacher set. As a result, each teacher example will be present in roughly half of the shadow models, and will not be present in the other half. Then if we train 100 shadow models, we can look at their predictions, on each student example, of the ~50 shadow models containing the teacher, as well as the predictions of the ~50 shadow models without the teacher. We can do this for each student query, because we assume here the adversary sees the student query outputs (but cannot query on arbitrary points, which would be necessary to observe the model outputs for the teacher examples). This attack has the additional assumption that the adversary knows the student queries, as all of our End-to-End attacks do, but otherwise has no extra assumptions beyond LiRA’s. Let us know if this explanation helps, and we can add it to the paper, or help clarify more.'}}, {'rebuttal': {'value': 'Thank you for your time in reading the submission and writing the review!\n\n>**End-to-End LiRA:** We use the same student set as used to train the target student model. This is because distillation can be done on public, nonsensitive data.\n\n>**Figure 3 & Data Processing Inequality:** The data processing inequality bounds the information contained in the student model about the data’s membership on the teacher. Thus, this only bounds the performance of an optimal attack, which LiRA on the teacher model may not be. We also note that the x and y coordinate of each point in Figure 3 is the average over a sample of target models and so are noisy values that can randomly appear above the dotted line.\n\n>**Clarification for Section 5:** The LiRA strategy trains many shadow models on a random 50% subsample of the teacher set. As a result, each teacher example will be present in roughly half of the shadow models, and will not be present in the other half. Then if we train 100 shadow models, we can look at their predictions, on each student example, of the ~50 shadow models containing the target teacher example, as well as the predictions of the ~50 shadow models without the target teacher example. Let us know if this explanation helps, and we can add it to the paper, or help clarify more.'}}, {'rebuttal': {'value': 'Thank you for your time in reading the submission and writing the review!\n\n>**Differential privacy:** This is an interesting question. Part of the goal of our work was to consider distillation *without privacy* because there exist past works that attempt to show distillation can achieve a strong notion of privacy. Thus, our aim was to show this is not the case. Investigating differential privacy’s impact on these attacks is interesting future work.  We also remark that the Mireshghallah et al work considers a slightly different threat model where the teacher and student datasets are identical, which we show in the Supplemental material to be much more vulnerable to attack than the threat model where the teacher is sensitive and the student is public, nonsensitive data. We can also be more clear when we cite the Mireshghallah et al work in Section 2.2 that it would offer a provable guarantee against our attacks.\n\n>**Model utility:** Our CIFAR-10 models reach roughly 88% accuracy. This training setup reaches >94% accuracy on the full CIFAR-10 training set. On Purchase100 the student models reach 74-75% accuracy, and on Texas100 the models reach 54-55% accuracy (note these are 100 class tasks). Unfortunately, we didn’t save test predictions on WikiText, so we need to retrain a model to get its utility, please bear with us. We’ll put these numbers in the paper.\n\n>**Privacy as a worst case:** It’s true that the scenario you propose could offer worst-case privacy protection, but only if this were true for *all very vulnerable points*; we broadly find that this is not the case in Figure 3. We will be more careful about our wording here and ensure we highlight that not all vulnerable data see significant reductions in membership inference vulnerability.\n\n>**Privacy and utility?:** Though utility and vulnerability are often correlated, out attacks significantly outperform what can be inferred by simple attacks based on the accuracy of the model (i.e., the Yeom et al. 2018 attack, see Figure 12). Further, our attacks are not always well correlated with utility: there exist other factors that influence its success. For example, we find that increasing temperature (Figure 5d) does not change utility significantly, but does increase vulnerability. Distilling with CIFAR-100 examples (Figure 6) leads to less utility compared to distilling with CIFAR-10 examples (roughly 85% compared to 88%), but interestingly leads to higher vulnerability. Deduplicating increases utility slightly (88% instead of 87.5% accuracy), but reduces vulnerability (Figure 5b). We can add a discussion of this to the paper.\n'}}, {'rebuttal': {'value': 'Thank you for your time in reading our submission and interesting questions!\n\n>**Feature correlation:** This is an interesting intuition, and we agree that the example in Figure 1 does seem to be due to this “red”ness (and one might draw similar conclusions about the examples in Figure 9 in the supplement). However, it is unclear how to define and quantify correlation for systematic study: we believe this is very interesting future work. This seems to have implications beyond privacy in understanding distillation’s dark knowledge, and we were unable to find related results in this literature.\n\n>**Why use LiRA:** LiRA represents the current state-of-the-art for membership inference. Thus, it represents the strongest baseline and also the strongest starting point for our research. Prior work using distillation as a defense has all predated the LiRA paper and so only evaluated with weaker attacks. This is also a motivation for our work: to understand whether stronger membership inference attacks could challenge this use of distillation. We also see this in Figure 12 in the supplementary material: a simple logit-gap membership inference attack (akin to simpler attacks such as Yeom et al. 2018) is unable to get beyond random guessing on CIFAR-10. '}}, {'summary': {'value': 'The authors in this paper investigate the efficacy of membership inference attacks (MIA) in model distillation. Their novel attack(s) show that MIA is possible even when the teacher model is only queried on the most influential points in the student inputs. Finally, they also demonstrate how their attacks are the strongest when the teacher set is poisoned OR when the student set ~= teacher set.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. The novelty is strong in this paper. No one has previously tackled MIA in model distillation as the authors here do. \n2. The paper is also very easy to read and understand. \n3. I really like the novel idea present in this paper (specifically Figure 1): membership of a target example in the teacher’s training set can be derived through querying the teacher model on various student set examples (and these are entirely different examples from the target!). \n4. Figure 3 is a great result as well. It might not be as obvious as it is, because the data points are essentially “post-processed” and there should be some sense of privacy after the distillation process. The authors here, show that distillation doesn’t show much privacy benefits. \n5. Their investigation on why MIA works well for student models is sound. I really like Figure 5 as well, which shows the MIA effects through duplicates, data poisoning and temperature scaling and the section on student-teacher data drift was an amazing read :-)'}, 'weaknesses': {'value': '1. I don’t really have any major weaknesses to point out!'}, 'questions': {'value': ""1. Could this happen because of correlated features present between the student queries and the target example? Acc to Figure 1, the “red” colour present in the student examples are essential for the MIA to work. My intuition is that a higher correlation in features between the student inputs and the teacher target example, should lead to higher success in MIA. Of course, this may be written down as Future Work and I’m not quite sure if such work has been done in this space. I think it might be nice to investigate such correlation effects between the student and teacher examples. \n2. I noticed that all the attacks mentioned in this paper, were based off LiRA. Is there a specific reason why the authors succumbed to using LiRA and not other attacks. (It's totally okay to use LiRA but I wonder if there could be other attacks you could have tried/did try out and measure the efficacy of such attacks against the LiRA-based ones; provided you have time to run these expts).""}, 'limitations': {'value': '1. Need to run a number of shadow models for running a successful MIA (not really a limitation of this approach, but this is a limitation of MIA itself!). '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""The paper explores the privacy implications of model distillation, a technique used to transfer knowledge from a teacher model to a student model. The authors investigate membership inference attacks on both the teacher and student training sets to evaluate the privacy provided by distillation. \nThe authors extend the LiRA attack to the distillation setting in two ways. The first attack calibrates the attack only on the teacher models and the second attack uses the whole distillation procedure. They find that distillation alone provides limited privacy protection. The attacks on distilled models succeed even though the distilled models have never seen the teacher's data directly.\nFinally, they also highlight the importance of considering factors such as data duplication, teacher set poisoning, temperature scaling and distribution shifts when evaluating the privacy risks of distillation.""}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The authors address an important problem. As machine learning capabilities grow and models are deployed directly to personal devices with limited computing capability, model compression algorithms such as distillation are often used. Understanding the privacy risk of these algorithms is therefore an increasingly important topic.\n- The paper is very easy to read and well motivated. Particularly, the visualizations in figure 3 and 4 are very intuitive and help tell the story\n- The paper considers many experimental evaluation settings (albeit limited detail about the concrete experiments)'}, 'weaknesses': {'value': '- An obvious mitigation of membership inference attacks is Differential Privacy, it would be interesting to see how effective DP mitigates the attack as by Mireshghallah et al [2022].\n- Limited detail of experimental setup. What is the utility of the models?\n- Some conclusions seem not deeply thought through. E.g. Line 213, the authors claim that since there are examples for which vulnerability drops by only  single digit percentage points and since privacy is a worst case guarantee the authors conclude that distillation provides limited privacy. While I agree that distillation provides limited privacy, it is possible that least vulnerable points see the single digit drop in vulnerability whereas the most vulnerable points see a more significant drop.\n\n\n**References**\n\nMireshghallah, Fatemehsadat, et al. ""Differentially private model compression."" Advances in Neural Information Processing Systems 35 (2022): 29468-29483. '}, 'questions': {'value': 'What is the utility of the models? Is privacy simply correlated with utility? Do we see the same percentage point drops in model utility when going from teacher to student?'}, 'limitations': {'value': 'The authors have accurately described limitations albeit only in the appendix.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper examines the effectiveness of model distillation in protecting the privacy of training data. Through the use of membership inference attacks, the authors demonstrate that distillation alone provides limited privacy across various domains. The authors also suggest several design considerations for improving privacy in model distillation, such as deduplicating the teacher set and considering complementary techniques like differentially private training.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- Trendy topic\n- Well-organized paper\n- Extensive experiments'}, 'weaknesses': {'value': '- Attack detail in Section 5 is not clear\n- Additional discussion might be helpful'}, 'questions': {'value': 'This paper provides valuable insights by addressing the misconception that model distillation can effectively protect the privacy of training data. The paper is well-organized and easy to follow, and a thorough examination of potential influencing factors contributes to the strength of the research.\n\nHowever, I have some concerns regarding the details of the attacks and the interpretation of results:\n\n- Regarding the experimental setting for End-to-End LiRA, it would be helpful to clarify how the corresponding student dataset was chosen. This information would enhance the reproducibility and validity of the experiments.\n\n- The paper mentions that attacks on the student model should not be more powerful than those on the teacher model, as implied by the data processing inequality. However, Figure 3 reveals that some samples remain more vulnerable after distillation. It would be beneficial to provide a possible explanation for this observation, as it appears to contradict the expected outcome.\n\n- Section 5, which introduces a new attack that only utilizes the student query dataset, is difficult to understand. The authors claim that “for each teacher example $z^T_j$, we fit a Gaussian distribution to the logits of each student example $z^S_i$, when $z^T_j$ is either IN or OUT.” However, it is unclear how the authors establish a link between student examples and arbitrary teacher examples, and how the student examples can indicate the membership status of the teacher example. Further clarification and additional illustrations would greatly enhance understanding in this section.\n\nOverall, this paper makes significant contributions and offers valuable insights. Addressing the aforementioned concerns would further strengthen the research and improve the clarity of the presented findings.\n'}, 'limitations': {'value': 'The authors have adequately claimed their limitations in Appendix B.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'Multiple previous works have proposed knowledge distillation techniques to distill the knowledge of a teacher trained on sensitive data into a student model which is supposedly protected against membership inference attacks. This paper proposes a new membership inference attack to perform membership inference attacks on the student model. Attacking the student models, it is shown that knowledge distillation provides only limited privacy against membership inference attacks. Having access to the dataset used to train the student model but not the student model itself, it is shown that this suffices to attack the private data of the teacher model.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- **Originality:** The paper is novel and proposes a novel approach for membership inference attacks on student models.\n- **Quality:** The experimental results seem sound and the claims of the paper are well supported.\n- **Clarity:** Overall, the paper is mostly well written and well organized. \n- **Significance:** With previous work having proposed knowledge distillation as a defense technique against membership inference, the results of the paper are important and most likely of high impact to other researchers.'}, 'weaknesses': {'value': '**Clarity:**  \n- The setting and the assumptions made for the proposed attacks are not very clear, and it would be helpful for the reader to explain the assumptions and information available to the attacker in more detail.\n- unfortunately, the code used to run the experiments will not be made public, which hinders reproducibility\n\nMisc:\n- Line 94: ""mitigates prevent"". There seems to be some missing or additional word.\n- maybe you could mention in the captions that “+” in the plots means the positive correlation. Otherwise, it is a bit confusing, if the reader is searching for a blue plus in the plots.'}, 'questions': {'value': ""**Q1:** The per example membership inference attack success rate is calculated over 1000 models. However, how do these models differ? Were they trained on the same data but with different seeds? If so, aren't these models behaving very similar?  \n**Q2:** In line 241 the indirect attack is described. However, the procedure of the attack is not quite clear to me. As far as I understood, the attacker has no knowledge about the teacher model's predictions on the teacher examples (line 231). Could you clarify what the assumptions made for this attack are and on how the attacker is fitting the Gaussians in this case?""}, 'limitations': {'value': '- the limitations are appropriately addressed in the supplementary material'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Students Parrot Their Teachers: Membership Inference on Model Distillation'}, 'authors': {'value': ['Matthew Jagielski', 'Milad Nasr', 'Katherine Lee', 'Christopher A. Choquette-Choo', 'Nicholas Carlini', 'Florian Tramèr']}, 'authorids': {'value': ['~Matthew_Jagielski1', '~Milad_Nasr2', '~Katherine_Lee1', '~Christopher_A._Choquette-Choo1', '~Nicholas_Carlini1', '~Florian_Tramèr1']}, 'keywords': {'value': ['model distillation', 'membership inference', 'privacy', 'dark knowledge']}, 'TLDR': {'value': 'Model distillation is not resistant to strong membership inference attacks, and we investigate why.'}, 'abstract': {'value': ""Model distillation is frequently proposed as a technique to reduce the privacy leakage of machine learning. These empirical privacy defenses rely on the intuition that distilled ``student'' models protect the privacy of training data, as they only interact with this data indirectly through a ``teacher'' model. In this work, we design membership inference attacks to systematically study the privacy provided by knowledge distillation to both the teacher and student training sets. Our new attacks show that distillation alone provides only limited privacy across a number of domains. We explain the success of our attacks on distillation by showing that membership inference attacks on a private dataset can succeed even if the target model is never queried on any actual training points, but only on inputs whose predictions are highly influenced by training data. Finally, we show that our attacks are strongest when student and teacher sets are similar, or when the attacker can poison the teacher set.""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/8c05fc594d00524a53aa379d756be0e28a18e4d1.pdf'}, 'supplementary_material': {'value': '/attachment/3e1b6cc738c6578f4335c1939793e0a7c0633bb7.pdf'}, '_bibtex': {'value': '@inproceedings{\njagielski2023students,\ntitle={Students Parrot Their Teachers: Membership Inference on Model Distillation},\nauthor={Matthew Jagielski and Milad Nasr and Katherine Lee and Christopher A. Choquette-Choo and Nicholas Carlini and Florian Tram{\\`e}r},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=a2Yg9Za6Rb}\n}'}, 'paperhash': {'value': 'jagielski|students_parrot_their_teachers_membership_inference_on_model_distillation'}}]"
"['Ben Prystawski', 'Michael Li', 'Noah Goodman']",NeurIPS,Why think step by step_ Reasoning emerges from the locality of experience,https://neurips.cc/virtual/2023/oral/73821,2023," Humans have a powerful and mysterious capacity to reason. Working through a set of mental steps enables us to make inferences we would not be capable of making directly even though we get no additional data from the world. Similarly, when large language models generate intermediate steps (a chain of thought) before answering a question, they often produce better answers than they would directly. We investigate why and how chain-of-thought reasoning is useful in language models, testing the hypothesis that reasoning is effective when training data consists of overlapping local clusters of variables that influence each other strongly. These training conditions enable the chaining of accurate local inferences to estimate relationships between variables that were not seen together in training. We prove that there will exist a ""reasoning gap"", where reasoning through intermediate variables reduces bias, for the simple case of an autoregressive density estimator trained on local samples from a chain-structured probabilistic model. We then test our hypothesis experimentally in more complex models, training an autoregressive language model on samples from Bayes nets but only including a subset of variables in each sample. We test language models’ ability to match conditional probabilities with and without intermediate reasoning steps, finding that intermediate steps are only helpful when the training data is locally structured with respect to dependencies between variables. The combination of locally structured observations and reasoning is much more data-efficient than training on all variables. Our results illustrate how the effectiveness of reasoning step by step is rooted in the local statistical structure of the training data.",Oral 4C COT/reasoning,https://openreview.net/pdf?id=rcXXNFVlEn,https://openreview.net/forum?id=rcXXNFVlEn,rcXXNFVlEn,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper aims to answer a very fundamental question -- in what situation chain-of-thought reasoning should be helpful. It explores this problem by considering the task of predicting variable values in a Bayes net, where child nodes are a nearly-deterministic function of their parents. The task is giving the values of a set of nodes and predicting the value of a target node. \nIt also compares three approaches: (a) direct prediction, where the target node is predicted immediately (b) scaffolded prediction, where the model is prompted to predict all the nodes between the source node and target node, and (c) free prediction, where the model chooses itself which intermediate nodes to generate. \n\nThe result shows that \n1. if relevant local variables are observed near each other, scaffolded prediction and free generation outperform direct prediction. \n2. If the observations shown are not relevant to the task, all approaches do poorly. \n3. If observations are not locally structured, scaffolded generation does well, but there is no benefit from free generation. Theoretically analysis shows that in this setting ""chain-of-thought"" (i.e. scaffolded generation) produces better predictions and empirical tests also confirms.\n\n\nStrengths:\n1. The result is significant in providing people with intuition about what types of datasets are promising candidates to use with chain of thought. \n2. The approach is novel, and the theory and complementary empirical analysis are solid.\n\nWeaknesses:\n1. lack of a practical way to measure the locality of a dataset\n2. the experiment is based on the case where each variable\'s value is nearly deterministic based on its parents. It is not clear how that generalizes to real datasets (e.g. language tasks)\n3. while theoretical arguments can often be made with smaller model sizes, the connection of these explanations to observed phenomenon on larger models seems like it would require actually experimenting with larger models.'}}, {'title': {'value': 'Concerns addressed!'}, 'comment': {'value': 'Raising to 7.'}}, {'title': {'value': 'Thanks for the rebuttal.'}, 'comment': {'value': ""I appreciate the authors' clarifications. My concerns have been well addressed.""}}, {'title': {'value': 'My main concern has been addressed'}, 'comment': {'value': ""I thank the authors for the thoughtful comments and for addressing my main concern. Now that it has been lifted, I'll be glad to see this paper presented at the conference, so I have raised my rating. ""}}, {'title': {'value': 'Thanks for the rebuttal'}, 'comment': {'value': ""Thanks for the rebuttal, my points are adequately addressed. I think this paper is going to be a valuable insight to the community, and I will argue for its acceptance, but I urge the authors to be more explicit in a final version about the conditions under which this type of intermediate variable generation will be useful (e.g. overlapping clusters) and the distinctions between this setup and natural language. I'll increase my score to an 8.""}}, {'rebuttal': {'value': 'We thank the reviewer for the thoughtful and supportive review. We are glad that the reviewer found our paper to be a pleasure to read and that they feel they understand zero-shot chain-of-thought better having read it.\n\nWe have responded to the main weakness the reviewer identified, about the connection to actual CoT reasoning, in the main author rebuttal, but we also provide more specific responses below, along with responses to other points the reviewer brought up.\n\n> So my question here is; how exactly does your setup relate to real-world language; what kind of data might we find these local structures where variables are connected through intermediate variables but not directly co-occur; what do the variables refer to in language? Can you give an example? And if the example is topics, can you work that example out a bit more clearly? Don\'t get me wrong here, I find the connection convincing, but I think the paper can benefit from some explicit reasoning about the connection of the setup to real-world language. \n\nWe will revise the paper to include more discussion of the connection between real-world reasoning and our setting. We will consider a detailed example to make the effect of topic structure clearer. For example, Wikipedia articles tend to mention the capital cities of countries and the climate of cities, but few articles directly talk about the climate of a country’s capital. If we were to ask a model trained on Wikipedia “What is the climate of France’s capital?” it would likely fail to answer directly. However, “France,” “capital,” and “Paris” co-occur frequently in the training set and “Paris” and “Oceanic climate” co-occur. By working through the intermediate reasoning step “Paris is the capital of France”, the language model should be able to answer the question correctly. It might produce a chain of thought like “The capital of France is Paris. The climate of Paris is oceanic. So the climate of France’s capital is oceanic.”\n\n> In a sense, the setup in the paper works because the model can just generate variables randomly until it encounters the target variable, whereas in real-world reasoning arguably the intermediate reasoning steps are connected through some high-level or abstract similarity. \n\nWe agree with this point: locality is probably not the only factor making reasoning useful in natural language. Seeing examples of reasoning traces in the training corpus might lead the model to learn reasoning strategies that make use of high-level similarities between topics. Even more importantly, few-shot in-context-learning likely helps models generate relevant variables for CoT. (Here we studied only the 0-shot case.) This is an interesting direction for future research.\n\n> Relatedly, it seems like a very important factor for reasoning like presented in the paper here to work is the overlapping clusters; what happens if not every cluster overlaps, or if overlapping variables are dropped out more often? Do you think people can make ""reasoning jumps"" through language between clusters of variables that do not overlap? To put it differently; perhaps when humans (and language models) do not observe some variable as both a part of cluster 1 and cluster 2, they can still ""jump"" between those clusters due to some abstract similarity between the two (e.g. a latent variable connection instead of an actual overlapping cluster).\n\nYes, one major difference between natural language and our setting is that natural language allows us to make abstract statements which can connect concrete facts in novel and unexpected ways. For instance, statistical information about predicates may influence joint probabilities of a variety of propositions that include them. While the focus of this work was to find a minimal case in which outputting extra information between a “question” and “answer” helps to produce better answers, the question of how abstract knowledge might enable better reasoning is an interesting direction for future work. We will update the discussion to mention this direction.\n\n> I think the first control condition can benefit from some more explanation; are the values still from the right Bayes net and only the local structure is wrong?\n\nYes, that is correct. The values of the variables are still taken from the right Bayes net, but the local neighborhoods are based on a different Bayes net with a different structure. We will make this clearer in the paper.\n\n> Random remark: Negative scaffolding intuitively seems to map onto this idea from LLM literature where people tried to test the hypothesis that CoT reasoning only works because it allows the model to output extra tokens. Tested with a control condition where they generate random tokens and then ask for the answer and then show that this works worse than CoT, meaning that the actual information the model outputs in its reasoning traces is important for performance.\n\nGreat point! Simply outputting extra tokens is not helpful in our setting. Step-by-step reasoning only works when the steps are relevant to the prediction task at hand. We will make this connection in the revision.\n'}}, {'rebuttal': {'value': 'We thank the reviewer for raising the important issue of architecture choice. We also appreciate that the reviewer finds the topic of chain-of-thought reasoning important and finds our results convincing.\n\nWe have responded to the reviewer’s point about the choice of architecture, including new results with different architectures, in the main author rebuttal. We respond to other questions below.\n\n> Line 139 - shouldn\'t it be ""adjacent"" instead of ""non-adjacent""?\n\nYes, this was a typo. Thank you for catching it.\n\n> Theorem 3.1 - what is q^hat?\n\n$\\hat{q}$ refers to estimators that are constructed from the raw predictions of the risk minimizer $q$. $\\hat{q}$ alone is not defined, but $\\hat{q}_D$ and $\\hat{q}_S$ are estimators we define. See Section 2.2 for definitions of these different estimators.\n'}}, {'rebuttal': {'value': 'We thank the reviewer for their detailed review. We appreciate that the reviewer found the paper’s result new and exciting, and that they thought it provides useful intuition about when chain-of-thought is useful.\n\nWe respond to the weakness about variable values being nearly deterministic given parents in the general author response, as well as the comment about the experiments averaging over 10 Monte Carlo rollouts. We also respond to the remaining questions below.\n\n> In the theoretical analysis, my intuitive understanding of the result is that if your training data consists of only adjacent pairs, then when you try to evaluate on non-adjacent pairs a perfect estimator will be very wrong (since those samples are never seen, so it will default to a uniform prior). On the other hand, if you predict probabilities of non-adjacent pairs by chaining a set of probabilities for adjacent pairs, then each term in the chain is in-distribution and you’ll get a better estimate. Is that the correct intuition? If so, (a) is there any way to make the intuition behind the result clearer, and (b) could you maybe make a higher analogy with language (e.g. explaining what a “chain” of variables would look like in language, what it means for training data to consist mostly of adjacent pairs, etc.)\n\nYes, that is exactly the right intuition. The perfect estimator, with respect to the risk defined in the paper, will default to the uniform prior for non-adjacent pairs. When we chain the risk minimizer’s estimates of adjacent pairs, we indeed make use of “in-distribution” pairs and therefore can reduce bias.\n\nRegarding improving the clarity of the theoretical result, in the revised version of the paper, we can include a figure that illustrates the theoretical formulation more carefully.\n\n> It seems like reasoning working well consists of two thing: (A) the model must be able to produce a reasoning trace which is relevant to the task at hand, and (B) the model must be able to use the reasoning to produce a better final answer.\n\nWe do not have concrete theoretical results for (A). The intuition behind why (A) happens in practice in free generation is that the relevant variables to reason through tend to be close to the observed variable and the training set consists of local clusters. In practice, free generation generates several variables near the observed variable, only some of which are relevant but which are sufficiently relevant in aggregate. It might be possible to prove analogous theoretical results for (A) but we leave a thorough characterization of free generation for future work. \n'}}, {'rebuttal': {'value': 'We thank the reviewer for the detailed and thoughtful review, and are happy to see that the reviewer found our theoretical analysis and simulation results insightful. \n\nWe describe how we will address the second weakness in the general author rebuttal. We also respond to the question about the choice of architecture by showing that a similar reasoning gap appears for multiple different architectures.'}}, {'rebuttal': {'value': 'We thank the reviewers for their thoughtful comments on this paper. These comments have informed additional analyses and clarifications.\n\n# Architecture\nReviewers Jbx9 and tGUI ask about our choice of architecture. Jbx9 asks why we chose a smaller model given that models smaller than GPT-3 often fail at step-by-step reasoning, while reviewer tGUi identifies our use of only one architecture as a weakness.\n\nTo these points, we first point out that our theoretical analysis applies to any autoregressive empirical risk minimizer. We prove that a reasoning gap should exist between direct prediction and scaffolded generation regardless of the specific architecture (for simple world distributions). We can interpret our learning curve results as evaluating whether a reasoning gap exists at different levels of empirical risk, or equivalently perplexity. The simulated data we trained transformers on is much simpler than natural language, so it is expected that a smaller model is capable of learning the data well enough for reasoning to be beneficial. Figure 1 in the PDF shows the mean perplexity on a validation dataset across Bayes nets vs. the size of the reasoning gap for each checkpoint in the geometrically-sized local neighborhood model. These results show that a model must achieve a certain perplexity before the reasoning gap emerges, but it exists for a range of perplexities achievable by our architecture.\n\nWe have also run additional simulations in which we train different transformer architectures on geometrically-sized local neighborhoods from the same Bayes nets. We use a smaller model (4,473,600 parameters), a larger model (86,628,864 parameters, the base gpt-2 architecture) and model with a similar number of parameters, but larger embeddings and fewer layers (39,887,872 parameters). We also use a tiny model which is too small to learn the distribution of the data (8,644 parameters). All models except for the tiny model exhibit similar reasoning gaps, suggesting that our findings are not specific to one architecture. Performance across architectures and estimators is reported in Figure 2 of the PDF, which we will include in the appendix of the paper.\n\n# Number of samples\nReviewer fiMT was interested in seeing results with a single Monte Carlo sample used in the scaffolded and free generation estimators. We have run this analysis for all numbers of samples between 1 and 10 and reported the results in Figure 3 of the PDF.\n\nWhile we used the mean squared error as a practical measure of the error of a language model, we could decompose MSE into bias and variance. The free and scaffolded generation estimators have lower bias, but higher variance, than direct prediction. Free and scaffolded generation have higher MSE compared to direct prediction with one sample, but averaging over several samples (at least 3 in our setting) leads them to have lower MSE than direct prediction. This finding has bearing on when we should expect generating multiple chains of thought, as is done in confidence methods (e.g. Wang et al., 2022), to be valuable. The specifics of the bias-variance trade-off depend on the underlying stochasticity of the Bayes net, so different environments might call for different numbers of samples. We will discuss this result in the paper.\n\n# Connection to real-world reasoning\nReviewers Jbx9, fiMT, and jyTS mentioned that the connection between our setting and real-world reasoning in humans and language models was not clear in the paper. We are ultimately interested in studying the improvement at answering questions resulting from generating intermediate information between a question and its answer. Our setting of inference for held-out pairs of variables in a Bayes net is a minimal case where this happens. For example, in a simple Bayes net with three variables, A: it rained last night, B: the grass is wet, and C: mowing the lawn will be difficult, reasoning through the intermediate variable B might be necessary if A and C have not been encountered together directly in training data. We will revise the introduction to make the connection clearer.\n\nReviewer fiMT asks about our choice to favor strong dependencies in generating Bayes nets. We chose to generate data this way to ensure that there are non-adjacent pairs of variables with high mutual information. If we sampled probabilities uniformly, mutual information would decay rapidly with distance and conditional probabilities for held-out pairs would be almost identical to marginal probabilities. Still, our Bayes nets have considerable randomness as the Beta distribution we use generates conditional probabilities between 0.1 and 0.9 32.7% of the time. We expect reasoning to be most useful in environments with strong dependencies, like in math word problems where truth values of statements are deterministic. An alternative way of looking at this is that strong long-range dependencies are themselves a precondition for reasoning – otherwise using the marginal frequency of the conclusion is enough.\n\n# Clarifications\nWe will clarify the motivation behind our choice to study locality and how it differs from related ideas like burstiness. While burstiness concerns the distribution of a single class over time, locality is about which classes co-occur with each other. Co-occurrence patterns are relevant because reasoning connects different concepts.\n\nWe also thank reviewers fiMT and tGUi for identifying typos and unclear points in the paper. In particular, we have fixed the typo on line 138/139 where “non-adjacent” should be “adjacent”.\n\nWe once again thank the reviewers for taking the time to give detailed feedback on this work. Their comments have substantially improved this paper.\n\n# References\nWang, X., Wei, J., Schuurmans, D., Le, Q. V., Chi, E. H., Narang, S., ... & Zhou, D. (2022, September). Self-Consistency Improves Chain of Thought Reasoning in Language Models. In The Eleventh International Conference on Learning Representations.'}, 'pdf': {'value': '/pdf/90f1a5052b5ef7935bbf8c89b91d7b43611f2cd4.pdf'}}, {'summary': {'value': 'This work investigates why and how chain-of-thought reasoning works in language models in the aspect of \n**local structure** in the training data. To this end, this work first proves the hypothesis that there exists a reasoning gap where reasoning through intermediate variables improves inference and then tests the hypothesis by training an autoregressive language model on samples from Bayes nets but only including\na subset of variables in each sample, considering the estimators including direct prediction, scaffolded generation, and free generation. The key findings are intermediate steps are only helpful when the training data is locally structured with respect to dependencies between variables and that the combination of locally structured observations and reasoning is much more data-efficient than training on all variables.\n\nThis work begins with the human practice of step-by-step reasoning and reviews the recent progress of a similar mechanism --- the intriguing chain-of-thought reasoning in large language models. Then the paper asks the question of why step-by-step reasoning helps, which may not only help understand how the large language models work but also provide insight into the origins of human reasoning. \n\nThe basic hypothesis is that chain-of-thought reasoning is useful in language models due to the local structure in the training data. Such a hypothesis is intuitive as human reasoning transcends local bounds, supporting plans and conclusions that span in time and space. The meaning of local structure may be interpreted as observations occurring in overlapping neighborhoods of concepts.\n\nTo verify the hypothesis, the authors conduct theoretical analysis and empirical experiments, finding that performing conditional inference by first generating intermediate variables improves the ability of a language model to match true conditional probabilities only when the training data is structured locally with respect to strong dependencies and the intermediate variables are relevant to the relationship between the variables of interest. Finally, the work also provides insights into three aspects: (i) when reasoning helps --- the observation distribution has the correct locality structure; (ii) when reasoning is unnecessary -- the observed and target variables co-occur in the training distribution; (iii) When reasoning fails --- data with the wrong locality structure.\n\nOverall, this work studies an important and timing research topic towards why and when step-by-step works in language models. This work provides comprehensive theoretical and experimental results to support the hypothesis. This work also provides useful insights into solving reasoning tasks, as well as dataset construction to amplify the capacity of large language models to perform step-by-step reasoning.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. The topic studied in this work is very important and has attracted increasing interest in the community. This kind of work is useful to advance our scientific understanding of why the intriguing chain-of-thought reasoning works (or fails on some tasks), and helps facilitate future studies on training dataset construction and prompting techniques to amplify the capacity of large language models to solve complex reasoning tasks.\n\n2. The theoretical part clearly formulates the problem. It also introduces effective approaches for estimation, followed by convincing experiments on a real-world language model (though with the smaller-scale GPT-2 instead of the real large language models).\n\n3. Many great insights can be found in the paper, after taking into account the influence of data complexity, when reasoning works, becomes unnecessary, and even fails. The findings basically align the real-world practice when applying chain-of-thought prompting in different reasoning tasks.'}, 'weaknesses': {'value': '1. The paper can be improved by taking large language models as the backbone and verifying the hypothesis on real-world datasets where chain-of-thought prompting techniques are widely applied. It would be interesting if this work could provide effective ways to identify the locality of a dataset, which may answer the commonly found yet unresolved question of why chain-of-thought techniques work quite well in arithmetic tasks but fail at some standard natural language understanding tasks like simple classification.\n\n2. The connection and the difference with existing studies can be further clarified. In the introduction part, this work mentioned another jargon --- ""burstiness"" which is confusing. It is not clear how burstiness and locality differ from each other. Besides, the motivation for choosing locality as the research topic is not clear, either. It is interesting to see more elaborations on how the hypothesis is derived.'}, 'questions': {'value': 'Why does this work choose a smaller version of GPT-2 for experiments instead of a large language model? Scaling laws affect the step-by-step reasoning ability of language models. Small models may commonly fail at step-by-step reasoning compared with direct reasoning. In contrast, large language models may be the better backbone to verify the hypothesis of this work.'}, 'limitations': {'value': 'The authors have provided thoughtful descriptions of the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper provides a theoretical analysis of situations in which chain-of-thought reasoning should be helpful. They do this by considering the task of predicting variable values in a Bayes net. Specifically, it is a Bayes net where child nodes are a nearly-deterministic function of their parents. During training, the network sees sets of nodes and is asked to predict the value of a target node. At evaluation time, the network is asked to predict a held-out target node based on another held-out node. \n\nThey compare three approaches: (a) direct prediction, where the target node is predicted immediately (b) scaffolded prediction, where the model is prompted to predict all the nodes between the source node and target node, and (c) free prediction, where the model chooses itself which intermediate nodes to generate. \n\nThey find that in Bayes nets where relevant local variables are observed near each other, scaffolded prediction and free generation outperform direct prediction. If the observations shown are not relevant to the task, all approaches do poorly. If observations are not locally structured, scaffolded generation does well, but we don\'t see a benefit from free generation.\n\nThey show theoretically that in this setting ""chain-of-thought"" (i.e. scaffolded generation) produce better predictions and back this up with empirical tests.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'Originality/significance: I am not familiar with theory in this area, but this appears to be a new and exciting result. It could be useful for the field by providing people with intuition about what types of datasets are promising candidates to use with chain of thought.\nQuality/clarity: They present theory and complementary empirical analysis. They consider a few different forms of reasoning and a few different types of observation frequency structures to confirm that their hypotheses hold across these conditions.'}, 'weaknesses': {'value': ""* It took a long time to understand the intuition behind how the theoretical and empirical results relate to the claims about reasoning in sequence models. Possibly this could be made clearer?\n* I wish there was an analysis of how accurate the intermediate reasoning steps were in the different conditions (scaffolded vs free generation).\n* The experiments look at conditions where each variable's value is nearly deterministic based on its parents. I wish there was either an analysis of what happens when this is not true or a discussion of whether the types of natural language tasks where chain of thought is most helpful share this nearly-deterministic property.\n* The experiments average over 10 Monte Carlo rollouts for the scaffolded and free generation cases. I wish there was an analysis of how chain of thought compares to direct prediction in the case of a single rollout, which is often the case being considered in language models.""}, 'questions': {'value': 'In Section 3, line 189, should ""$p_{obs}$ only assigns non-zero probability to non-adjacent variable pairs"" say ""adjacent"" not ""non-adjacent""?\n\nI\'m not sure I fully understood the significance and takeaways of the analysis and experiments. I\'ve summarized my understanding below, but please correct me if I\'m misunderstanding:\n\nIn the theoretical analysis, my intuitive understanding of the result is that if your training data consists of only adjacent pairs, then when you try to evaluate on non-adjacent pairs a perfect estimator will be very wrong (since those samples are never seen, so it will default to a uniform prior).  On the other hand, if you predict probabilities of non-adjacent pairs by chaining a set of probabilities for adjacent pairs, then each term in the chain is in-distribution and you’ll get a better estimate.  Is that the correct intuition? If so, (a) is there any way to make the intuition behind the result clearer, and (b) could you maybe make a higher analogy with language (e.g. explaining what a “chain” of variables would look like in language, what it means for training data to consist mostly of adjacent pairs, etc.)\n\nIt seems like reasoning working well consists of two thing: (A) the model must be able to produce a reasoning trace which is relevant to the task at hand, and (B) the model must be able to use the reasoning to produce a better final answer. \n* It seems like the “scaffolded” condition checks if (B) is true, and the “free generation” condition checks if both (A) and (B) are true. The theoretical results suggest that (B) should is true but don’t touch on (A). Is there any theoretical reason to think (A) should be true primarily for locally-structured data? Or is the intuition just that locally-structured observations will bias the model towards generating intermediate variables easy to predict accurately b/c the model is conditioning on local context and are relevant to the task at hand?\n'}, 'limitations': {'value': 'Limitations are adequately addressed.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The starting point of this paper is the observation that large language model benefit from chain-of-thought reasoning. Namely, when prompt with a reasoning task, LLMs benefit from generating intermediate steps before reaching the final answer. The paper investigates this phenomenon. The authors hypothesize that this is a result of local structures in the training data where variables that often appear together have strong influence on each other, thus a model can generate chains of local connections and by that obtain relations between remote variables that do often appear together in the training data. To explore this hypothesis, the authors train an LLM on samples from randomly generated Bayes nets and task the model with inferring the conditional probability of one variable in the bayes net given another. They show that when the model is trained on samples that only include a subset of local variables then generating a chain of conditional probabilities involving adjacent variables, \npredicts the conditional probability involving two remote variables whith much higher accuracy than a model that is tasked with predicting the remote relation directly. They refer to this phenomenon as the “reasoning gap”.  In contrast, when the model is trained either on the entire set of variables, or on a subset of variables from an irrelevant locality, that reasoning gap vanishes. They also prove a theoretical guarantee in the special case when the Bayes net is a simple chain of variables. \n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The topic of chain-of-thought reasoning in LLMs has garnered a lot of attention in the community recently. It is important both from a theoretical as well as applicable standpoints to investigate the conditions under which chain-of-thought reasoning is useful. The authors suggest an interesting set of experiments to do that as well as some theoretical work. At least for the model that was used in the experiments, the results and the conclusions are convincing. The paper is well written. '}, 'weaknesses': {'value': 'The authors ran extensive experiments, but the evaluation uses only one LLM architecture. To draw conclusions about chain-of-thought reasoning in LLMs in general, I would expect a larger set of model architectures to be part of the experiments. For example, it would be interesting to understand how the performance is influenced by the model’s size. '}, 'questions': {'value': 'Line 139 - shouldn\'t it be ""adjacent"" instead of ""non-adjacent""?\nTheorem 3.1 - what is q^hat?'}, 'limitations': {'value': 'The authors adequately addressed the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper aims to investigate in a control and toy setup why it is that zero-shot chain-of-thought reasoning (e.g. prompting a model with ""let\'s think step by step"" and letting the model output intermediate reasoning traces before generating the final answer) improves downstream performance of language models in reasoning tasks. The authors hypothesise that reasoning is useful (or even necessary) when there is a local structure in the training data. A local structure in the training data here refers to local clusters of variables that directly influence each other in a DAG are observed together. The high-level mapping of this onto real-world experience is that we perceive things that are physically and temporally close, but nonetheless can reason over things that are physically and temporally far away.\n\nThe setup in which the authors investigate this is a Bayes net. Imagine a directed acyclic graph (DAG) of variables, and the task is the predict the probability that one variable (the target) takes a value given that another variable (the input; physically separated from the target variable in the graph) has a certain value. The training setup is such that the learner does not see the target and the input variable together during training, but sees local clusters of variables from the graph. Importantly, these clusters overlap. So for each cluster there is at least one variable that is also in another cluster. The authors then show that a language model that is allowed to freely generate intermediate variables can better predict the target value probability than a model that directly predicts it, but only if the training data is structured in the local way described above. Intuitively, the learner achieves this by generating one of the overlapping variables and then moving between local clusters it has seen from training until it encounters the target variable. The authors also show that the learner\'s performance does not deteriorate with length of the intermediate variables generated, and that a learner that reasons freely is more data-efficient.\n\nThe authors take these results to conclude that we can expect zero-shot CoT reasoning to help when a learner has to make inferences over things (concepts, topics, you name it) that did not co-occur directly in training, but can be connected through things that did co-occur.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'This paper is written in an exceptionally clear way, it\'s a pleasure to read. Additionally, it\'s one of those rare papers that is able to convincingly connect a very theoretical, toy, controlled result to a real-world phenomenon that we, as of yet, understand poorly. I feel like I understand zero-shot CoT better after reading this paper, and am very excited about follow-up work in this direction.\n\nOther strengths:\n- the authors have a simple theoretical result that helps shape intuitions before diving into the experimental section\n- the authors convincingly apply control conditions to isolate the effect of the locality of the training experience, showing the same thing does not show up when there is no locality or the locality is ""wrong"" (clusters are from another DAG, meaning they are not actually local)\n- the results are very clear; there is a reasoning gap for direction prediction versus reasoning when there is a locality in the variables encountered during training\n- the authors additionally show benefits of this type of training data structure; data-efficiency\n- the authors\' conclusion is convincing: reasoning can help when a learner needs to connect concepts that have not directly been seen during training, but those concepts are connected through other concepts that have been seen together'}, 'weaknesses': {'value': 'My main point of weakness with this paper is that the hypothesised connection to actual zero-shot CoT reasoning in SotA LMs, and with it, actual reasoning done by humans is not described explicitly enough. The authors cite Chan et al. (2022) here to be similar to their work (""Data distributional properties drive emergent ..""), but I found the connection between that toy setup and real language slightly more convincing because they use a Zipfian distribution (which the vocabulary in language also follows to trade-off the speaker and listener effort due to ambiguity). So my question here is; how exactly does your setup relate to real-world language; what kind of data might we find these local structures where variables are connected through intermediate variables but not directly co-occur; what do the variables refer to in language? Can you give an example? And if the example is topics, can you work that example out a bit more clearly? Don\'t get me wrong here, I find the connection convincing, but I think the paper can benefit from some explicit reasoning about the connection of the setup to real-world language. In a sense, the setup in the paper works because the model can just generate variables randomly until it encounters the target variable, whereas in real-world reasoning arguably the intermediate reasoning steps are connected through some high-level or abstract similarity.\n\nRelatedly, it seems like a very important factor for reasoning like presented in the paper here to work is the overlapping clusters; what happens if not every cluster overlaps, or if overlapping variables are dropped out more often? Do you think people can make ""reasoning jumps"" through language between clusters of variables that do not overlap? To put it differently; perhaps when humans (and language models) do not observe some variable as both a part of cluster 1 and cluster 2, they can still ""jump"" between those clusters due to some abstract similarity between the two (e.g. a latent variable connection instead of an actual overlapping cluster).'}, 'questions': {'value': 'Most important questions are listed in weaknesses. Other questions that are less important here:\n- Should line 138 say it only assigns non-zero probability to **adjacent** pars and not **non-adjacent** pairs as stated now?\n- I think the first control condition can benefit from some more explanation; are the values still from the right Bayes net and only the local structure is wrong? I.e. is it for example a Bayes net like in Figure 1A but the drawn lines of clusters are not actually local clusters, but the arrows and conditional probabilities are the same?\n- Random remark: Negative scaffolding intuitively seems to map onto this idea from LLM literature where people tried to test the hypothesis that CoT reasoning only works because it allows the model to output extra tokens. Tested with a control condition where they generate random tokens and then ask for the answer and then show that this works worse than CoT, meaning that the actual information the model outputs in its reasoning traces is important for performance.\n\n'}, 'limitations': {'value': 'The limitations are adequately addressed, but I think the authors should be more explicit about about how well this setup maps onto real language models and reasoning, focusing also on the requirement of overlapping clusters, and where the setup simplified things compared to real-world situations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Why think step by step? Reasoning emerges from the locality of experience'}, 'authors': {'value': ['Ben Prystawski', 'Michael Y. Li', 'Noah Goodman']}, 'authorids': {'value': ['~Ben_Prystawski1', '~Michael_Y._Li1', '~Noah_Goodman1']}, 'keywords': {'value': ['chain-of-thought; language models; reasoning']}, 'TLDR': {'value': 'Chain-of-thought reasoning is effective in autoregressive language models because of the local structure of the training data.'}, 'abstract': {'value': 'Humans have a powerful and mysterious capacity to reason. Working through a set of mental steps enables us to make inferences we would not be capable of making directly even though we get no additional data from the world. Similarly, when large language models generate intermediate steps (a chain of thought) before answering a question, they often produce better answers than they would directly. We investigate why and how chain-of-thought reasoning is useful in language models, testing the hypothesis that reasoning is effective when training data consists of overlapping local clusters of variables that influence each other strongly. These training conditions enable the chaining of accurate local inferences to estimate relationships between variables that were not seen together in training. We prove that there will exist a ""reasoning gap"", where reasoning through intermediate variables reduces bias, for the simple case of an autoregressive density estimator trained on local samples from a chain-structured probabilistic model. We then test our hypothesis experimentally in more complex models, training an autoregressive language model on samples from Bayes nets but only including a subset of variables in each sample. We test language models’ ability to match conditional probabilities with and without intermediate reasoning steps, finding that intermediate steps are only helpful when the training data is locally structured with respect to dependencies between variables. The combination of locally structured observations and reasoning is much more data-efficient than training on all variables. Our results illustrate how the effectiveness of reasoning step by step is rooted in the local statistical structure of the training data.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/2164530af75c0b5214c9411be9fa3db26bf3b516.pdf'}, '_bibtex': {'value': '@inproceedings{\nprystawski2023why,\ntitle={Why think step by step? Reasoning emerges from the locality of experience},\nauthor={Ben Prystawski and Michael Y. Li and Noah Goodman},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=rcXXNFVlEn}\n}'}, 'paperhash': {'value': 'prystawski|why_think_step_by_step_reasoning_emerges_from_the_locality_of_experience'}}]"
"['Johanna Immonen', 'Amauri Souza', 'Vikas Garg']",NeurIPS,Going beyond persistent homology using persistent homology,https://neurips.cc/virtual/2023/oral/73876,2023," Representational limits of message-passing graph neural networks (MP-GNNs), e.g., in terms of the Weisfeiler-Leman (WL) test for isomorphism, are well understood. Augmenting these graph models with topological features via persistent homology (PH) has gained prominence, but identifying the class of attributed graphs that PH can recognize remains open.  We introduce a novel concept of color-separating sets to provide a complete resolution to this important problem. Specifically, we establish the necessary and sufficient conditions for distinguishing graphs based on the persistence of their connected components, obtained from filter functions on vertex and edge colors. Our constructions expose the limits of vertex- and edge-level PH, proving that neither category subsumes the other. Leveraging these theoretical insights, we propose RePHINE for learning topological features on graphs. RePHINE efficiently combines vertex- and edge-level PH, achieving a scheme that is provably more powerful than both. Integrating RePHINE into MP-GNNs boosts their expressive power, resulting in gains over standard PH on several benchmarks for graph classification.",Oral 5A GNNs/Invariance,https://openreview.net/pdf?id=27TdrEvqLD,https://openreview.net/forum?id=27TdrEvqLD,27TdrEvqLD,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper and the ensuing discussion was a joy to read and behold. It presents a direly-needed investigation into the theoretical limits of persistent homology in graph learning, while developing new ways to leverage topological information in neural networks. The paper is technically sound and well-written—a fact that was acknowledged by all reviewers—and I fully agree with the reviewers here. It is thus my pleasure to **endorse this paper for presentation at NeurIPS**.\n\nMoving forward, the authors are encouraged to further improve the text by positioning and contextualising their work, with a particular eye towards theoretical or empirical limitations of their work.'}}, {'comment': {'value': 'Thank you for the rebuttal. I hold a favorable view of the supplementary experiment aimed at addressing the initial concerns, even though the enhancement does not show significant statistical difference. I will maintain my original evaluation stance and defer the final judgment to the AC.'}}, {'comment': {'value': 'Thank you for the clarification and I will maintain my supportive score of the paper.'}}, {'comment': {'value': 'Dear AC,\n\nMany thanks for your kind reminder.\n\n\nDear reviewer,\n\nThank you again for your feedback. Given that the author-reviewer discussion deadline is approaching, we would like to highlight additional experiments on real-world benchmarks to alleviate your concerns.\n\nThe first set of experiments compares RePHINE to another PH-based model: PersLay (AISTATS, 2020) (for details, please see x2he W1/Q1). The results are:\n| Method    | NCI109 | PROTEINS | IMDB-B | NCI109 |\n| -------- | ------- | ------- | ------- | ------- |\n| PersLay  |  90.48 $\\pm$ 2.97   | 94.64 $\\pm$ 4.69 | 90.40 $\\pm$ 4.90 | 85.16 $\\pm$ 6.11 |\n| RePHINE+Linear |   **93.97 $\\pm$ 4.42**   | **98.93 $\\pm$ 3.39** |  **94.70 $\\pm$ 7.50** | **93.80 $\\pm$ 4.05** |\n\nAs we observe, RePHINE+Linear outperforms PersLay by a significant margin.\n\nWe also ran experiments regarding the combination of RePHINE and a SOTA GNN: PNA (NeurIPS 2020). We report results on the ZINC dataset. The MAE values are: PNA (0.195 $\\pm$ 0.004) and PNA+RePHINE (**0.189 $\\pm$ 0.006**). Importantly, we did our best to conduct a fair comparison with reproducible results. We will include these and a few others in our revised manuscript.\n\nFinally, we report fundamental theoretical results to uncover the representational limits of PH. These, alongside a provably more expressive topological descriptor, are our main contributions. We expect our work will help the Graph ML and Topological DL communities design better, more nuanced models that are both theoretically well-grounded and practically efficacious.\n\nThank you again for taking the time to review our submission and for your constructive feedback. We would greatly appreciate if you would kindly consider upgrading your score.'}}, {'comment': {'value': 'Dear reviewer,\n\nPlease **briefly acknowledge the rebuttal** by the authors and consider updating your score—we want to avoid borderline scores for reviews, and the discussion phase will close soon. If you have any additional questions to the authors  please ask them **now**.\n\nThanks,\\\nYour AC'}}, {'title': {'value': 'Results using PNA on ZINC'}, 'comment': {'value': 'Thanks for your feedback. We are glad to hear you found the newly added material and experiments convincing.\n\nRegarding experiments with SOTA GNNs, we run a fair comparison between PNA and PNA+RePHINE on the ZINC dataset (public splits). We leverage the topological descriptors as described in the paper (see equations in Section 4). Both methods use the same hyper-parameters (available at the PyTorch-geometric toolbox) and training procedures. **The results obtained over ten independent runs with different seeds are: PNA ($0.195 \\pm 0.004$ MAE) and PNA+RePHINE ($0.189 \\pm 0.006$ MAE)**. In this case, RePHINE improves the performance of PNA, achieving MAE that lies one standard deviation away from that of PNA alone. Moreover, we plan to consider at least a Transformer-based architecture and another OGB dataset in the final paper.'}}, {'comment': {'value': 'Sure. We will include all clarifications in the revised version of the paper. Thanks again for your insightful review and support of our work. '}}, {'comment': {'value': ""We apologize for the confusion. Our idea was to convey that when these multisets differ, there cannot be a bijection between the connected components of G and G' such that each component would be paired with a component having the same component-wise colors. \n\n\nThanks to your comment, we have reformulated this part of the proof in a way that we believe is much more accessible for the readers. Thus, the base case in Lemma 2 now reads: \n\n \n\n---\n\nIf there is only one color, component-wise colors cannot differ for graphs with $\\beta^0_G = \\beta^0_{G'}$. Let us consider two colors (say, $b$ and $w$). For two colors, there are only three possibilities for what $X_h$ \nin $\\\\{\\\\{X_i\\\\}\\\\}_{i=1}^k$ \nmay be: \n\n$\\\\{ b \\\\},\\\\{ w \\\\}$ or $\\\\{b, w \\\\} $.\n\n \n\nNow, let us denote the multiplicities of $\\\\{ b \\\\},\\\\{ w \\\\}$ and $\\\\{b, w \\\\} $ in $\\\\{\\\\{X_i\\\\}\\\\}_{i=1}^k$ by $n_1, n_2$ and $n_3$, respectively. \n\n \n\nFor $G$ and $G'$ with $\\beta^0_G = \\beta^0_{G'}$, we have that $n_1 + n_2 + n_3 = n'_1 + n'_2 + n'_3$. \n\n \n\nThus, when $\\\\{\\\\{X_i\\\\}\\\\}_{i=1}^k \\neq$\n\n $\\\\{\\\\{X_i^\\prime\\\\}\\\\}_{i=1}^k$, there are four cases to consider: \n\n \n\n1. $n_1 \\neq n'_1, n_2 \\neq n'_2,n_3 = n'_3 $: In this case, $n_2 + n_3 \\neq n'_2 + n'_3 $ correspond to multiplicities of real holes $(w,\\infty)$ for $G$ and $G'$ respectively, in a filtration that introduces the color $w$ first.\n\n2. $n_1 \\neq n'_1, n_2 = n'_2,n_3 \\neq n'_3 $ : Again, $n_2 + n_3 \\neq n'_2 + n'_3 $ correspond to multiplicities of real holes $(w,\\infty)$ for $G$ and $G'$ respectively in a filtration that introduces the color $w$ first.\n\n3. $n_1 = n'_1, n_2 \\neq n'_2,n_3 \\neq n'_3 $: Now, $n_1 + n_3 \\neq n'_1 + n'_3 $ correspond to multiplicities of real holes $(b,\\infty)$ for $G$ and $G'$ respectively in a filtration that introduces the color $b$ first.\n\n4. $n_1 \\neq n'_1, n_2 \\neq n'_2,n_3 \\neq n'_3 $: Similarly, $n_1 + n_3 \\neq n'_1 + n'_3 $ correspond to multiplicities of real holes $(b,\\infty)$ for $G$ and $G'$ respectively in a filtration that introduces the color $b$ first.\n\n \n\nNote that cases as $n_1 \\neq n'_1, n_2 = n'_2,n_3 = n'_3 $ are not possible as $n_1 + n_2 + n_3 = n'_1 + n'_2 + n'_3$.\n\n \n\n--- \n\nThanks again for checking the proofs. We genuinely appreciate your contribution to strengthening the paper.""}}, {'title': {'value': 'Answer to rebuttal'}, 'comment': {'value': 'I thank the authors for their response.\n\nOverall, I am satisfied with their answers, and I have raised my score accordingly. My score is not higher mainly due to some unanswered theoretical questions (stability and characterization of the expressivity of RePHINE, and comparison to expressivity of extended persistence).'}}, {'comment': {'value': 'Thank you for addressing my questions.\n\nUpon reading your response to Q4, I have some further questions:\n\nThe authors highlighted that ""when $G$ and $G\'$ have distinct component-wise colors, there must be some connected component $C_h$ in $G$ such that $\\{X_h\\} \\neq \\{X_j\'\\}$ for all $1 \\leq j \\leq k$."" My understanding is that when referring to the distinct component-wise colors of the two graphs, we\'re essentially discussing the differences between two multisets. However, two distinct multisets can still share the same individual elements. Given this, I\'m not entirely convinced about the validity of the aforementioned claim.\n\nCould the authors provide further explanation?'}}, {'comment': {'value': 'Thanks a lot for the detailed response and for the great improvements! Please make sure to include most of these clarifications in the final version of the paper.'}}, {'title': {'value': 'Thanks for the clarification'}, 'comment': {'value': 'Dear Authors, \nthanks for taking the time to answer my doubts. The newly added material and experiments seem convincing. Should you have some preliminary results on the use of your method with SOTA GNNs before the reviewers/authors discussion period, I would be curious to see them.'}}, {'rebuttal': {'value': ""We are grateful to all the reviewers for their time and insightful comments, as well as to the (senior) area, program, and general chairs for their service to the community.\n\nWe are glad to note the positive response of all the reviewers, and specifically, their acknowledgments that our work is **interesting and novel** (x2he, BFX1) and **provides a resolution to the problem of recognizing attributed graphs** based on the persistence of their connected components (oULm). Also, reviewers found that our work can **allow one to understand the limits of standard filtering schemes** and **build new enriched schemes to overcome them** (PDW5). Finally, our **theoretical contributions are said to be well presented and clear** (rXNh, BFX1, PDW5), **relevant in practice** (rXNh, x2he), and **supported by experiments on eight datasets** (rXNh).\n\nTo the best of our efforts, we’ve tried to address all the specific comments, including the minor ones, that have been raised by each reviewer. In particular, some of the main revisions are:\n\n- Additional experimental results on the comparison between RePHINE and Extended Persistence Diagrams (PersLay);\n- Proof that RePHINE is isomorphism invariant (newly added Corollary 1);\n- New subsection about 'Limitations and Future Works';\n- Clarifications regarding the main contributions (newly added Table with an overview of our theoretical results), and exposition of RePHINE diagrams (now as a formal definition);\n- Added visualizations about the graphs and diagrams obtained from the synthetic experiments.\n\nMoreover, we are currently running experiments to show additional results on 1) the combination of RePHINE with SOTA GNNs; 2) more (larger) datasets.\n\nWe believe that acting on reviewers’ feedback has reinforced the many strengths of this work, and we thank them again for their very constructive comments.""}, 'pdf': {'value': '/pdf/4ba3bf4c6432de9fae71f43f5fe547468987dfa3.pdf'}}, {'rebuttal': {'value': 'Thanks for your feedback. We reply to your comments/questions below.\n\n**""There is room for further exploration and validation in real-world experiments. The current evaluation primarily focuses on controlled simulated datasets, limiting our understanding of RePHINE\'s performance in practical scenarios.""**\n\nWhile we agree that there is room for improvements, we would like to highlight that our initials experiments were mainly designed to 1) validate our theoretical findings (synthetic datasets), and 2) show that the proposed diagrams can be easily integrated into GNNs to boost their predictive performance on popular benchmarks on graph classification. Thanks to your comment, we are currently running experiments to investigate further benefits of integrating the RePHINE diagrams into modern GNNs (e.g., PNA, SpecFormer). We will include these results in the revised version of the manuscript.\n\nImportantly, we have now compared RePHINE diagrams with Extended Persistence diagrams used in the PersLay model. Our results demonstrate that RePHINE outperforms PersLay on four real-world datasets by a large margin (please see Table 1 in the attached pdf). Thus, we believe that beyond the theoretical analyses, the empirical benefits of RePHINE can already be demonstrated.\n\n**Are there any specific limitations or challenges when applying RePHINE to real-world applications?**\n\nWe believe that topological descriptors (such as RePHINE) work complementary to existing graph classifiers rather than standalone methods. As a standalone method, we know RePHINE has theoretical limitations. In particular, for unattributed graphs, RePHINE cannot separate graphs of equal size with the same number of components and cycles (please see the example in the attached PDF). \n\nHowever, given RePHINE\'s improved expressivity at the same computational cost as vanilla vertex-color filtrations, RePHINE has the potential to become the default choice for topologically enriched graph models in real-world applications. \n\n**It would be interesting to understand the factors that contribute to the marginal performance gain of RePHINE on most real-world datasets.**\n\nWhile it is hard to provide a definitive explanation for subtle performance differences, we believe that the minor gains come from our specific architectural choices, which isolate persistence diagrams while keeping other components unchanged. We note that in the comparison against the PersLay model, we can observe a significant difference in performance.\n'}}, {'rebuttal': {'value': 'Thanks for your constructive feedback. In the following, we address all your questions. \n\n**W1: ""One weakness of the paper lies in the experimental evaluation section, which could benefit from a more comprehensive comparison with existing methods, such as the method proposed in [28].""**\n\nWe note that our initial experiments mainly focused on corroborating our theoretical analysis (synthetic datasets) and on assessing the benefits of combining RePHINE diagrams with popular GNNs for improved predictive performance. However, thanks to your comment, we have also compared RePHINE with a method that leverages extended persistence diagrams: PersLay. Our new results (please see Table 1 of the attached PDF) demonstrate that RePHINE outperforms PersLay on popular graph classification benchmarks.\n\nWe have opted for PersLay instead of [28] due to the similarity between the evaluation setups and the ease of adaptation --- [28] mainly considers node classification tasks. Moreover, we are currently running experiments to investigate further benefits of integrating the RePHINE diagrams into modern GNNs (e.g., PNA, SpecFormer). We will include these results in the revised version of the manuscript.\n\n**Q1: ""I think there is some syntax issue with the appearance of [Theory], [Methodology] and [Experiments]""**\n\nThanks for pointing this out. We will make sure that there will be no such syntax issues in the revised manuscript.\n\n**Q2: ""disconnect"" should be ""disconnects""**.\n\nYes, thanks for the careful reading.\n\n**Q3: please mention that Q is a color separating set in this sentence.**\n\nWe have modified that in the revised paper. Now the sentence reads: \n\n*We note that when $G$ and $G\'$ have identical component-wise colors, the sets $\\\\{w \\in V | c(w) \\in Q\\\\}$ and $\\\\{w \\in V\' | c\'(w) \\in Q\\\\}$ induced by the color-separating set $Q$ are separating sets for $G$ and $G\'$, respectively.*\n\n**Q4: ""what does ""disjoint union"" here mean? What does ""these sets"" refer to? could you please provide an explicit description of the set you are constructing here?""**\n\nWe agree that the construction was not clear. Thanks for pointing this out.  We meant that when $G$ and $G\'$ have distinct component-wise colors, there must be some connected component $C_h$ in $G$ such that $\\\\{X_h\\\\} \\neq \\\\{X\'_j\\\\} $ for $ \\forall 1 \\leq j \\leq k $. \n\nThen, if assumed $\\beta^0_G = \\beta^0_{G\'}$, the unmatched component-colors come in pairs i.e. $G$ must have as many unmatched component-color sets as $G\'$.  The collection of sets of unmatched component-color pairs is considered in the proof.\n\nWe have clarified the language throughout the proof, and rewritten the mentioned part as follows :\n\n*When $G$ and $G\'$ have distinct component-wise colors [math was ommited here due to markdown issues], there must be at least one connected component $C_h$ in $G$ such that $\\\\{X_h\\\\} \\neq \\\\{X\'_j\\\\} $ for $ \\forall 1 \\leq j \\leq k $. Let us now call such $\\\\{X_h\\\\}$ a set of unmatched component colors*. \n\n**Q5: ""I don\'t think $X_i$ should have $l$ as a superscript. Are you also referring to connected components with $l$\n colors instead of subgraphs?""**\n\nThis is a typo, the superscript should be $k$. We fixed it.\n\n**Q6: line 513: ""l+1 the"" -> ""l+1 th""**. \n\nWe have fixed that typo in the revised paper.\n\n**Q7: ""it is not injective"" should be ""is not injective"".**\n\nYes, thanks for the careful reading.\n\n---\nWe hope our answers have addressed the points you have raised, and improved your view of the manuscript.\n\n'}}, {'rebuttal': {'value': 'Thank you for your detailed and thoughtful review. You have raised very pertinent points. Below, we address your questions/comments.\n\n**W1: ""The related work seems not be detailed enough and is hard to identify.""**\n\nThanks for your comment. In the Introduction, we decided to group references together for conciseness. To alleviate the issue you raised, we will provide a more detailed overview of related works in the supplementary material (in a new section Related Works).\n\n**W2: ""The name RePHINE is clever and nice. However, the word interleaving suggests interleaving distance (esp. relevant in TDA), so it would probably be better to replace this with e.g. interplay or integration.""**\n\nThanks very much for the excellent suggestion. We agree that \'Refined PH by incorporating node-color into edge-based filtration\' is apt for the proposed method, so have accordingly decided to adopt this rephrasing. \n\n**W3: ""Stressing earlier on (already in Section 1) that you calculate PH on edge-based filtration, including so-called missing holes and augmenting it with vertex-color information would be helpful.""**\nWe have reworded descriptions in the Abstract, Introduction, and Section 4 to better reflect how RePHINE works. For instance, the Abstract now reads: ""RePHINE efficiently incorporates vertex-color information into edge-level filtrations, achieving a scheme ..."".\n\n**W4: ""How does you approach compare to concatenated standard 0- and 1-dim PH on edge-based filtration?""**\n\nWe note that RePHINE is more expressive than the union of the multisets of 0- and 1-dim PH on edge-based filtration. In particular, the two graphs in Figure 4(c) of the paper cannot be distinguished by either 0-dim or 1-dim PH. However, we can obtain two different RePHINE diagrams for such a graph as we show in part (3) of the proof of Theorem 4.\n\n**W5: Regarding details and further analysis of the results on synthetic data.**\n\nThe cubic datasets comprise non-isomorphic 3-regular graphs. From these graphs, we create a classification problem by assigning each graph a binary class. Given the partition, we assess if the existing methods can overfit (correctly classify all) the samples. When we compare RePHINE with 0- and 1-dim PH on vertex-color filtration, we mean the union of the 0- and 1-dim diagrams.  \n\nRegarding the analysis, we have only compared RePHINE to vertex-color filtration as it has been used in the reference work (TOGL). Nonetheless, in the revised version of the paper, we will also include results for diagrams obtained from edge-level filtrations. To understand why PH works poorly, we report diagrams (after learning) for two instances of cubic-10-2 in the attached PDF. We noticed that the original code of TOGL for vertex-color filtrations uses $max(f(c))$ instead of infty, which makes it not distinguish almost and real holes in some instances. We will also provide a similar discussion on the reasons for the failure of GCNs and report obtained diagrams for other graphs (and synthetic datasets) in the supplementary material.\n\n**W6: ""Experimental results on real-world data: You write that you compare against standard color-based PH, but what do you mean with this?""**\n\nBy standard color-based PH, we mean 0-dim and 1-dim persistence diagrams obtained from vertex-color filtrations. To the best of our knowledge, edge-color filtrations have not been used in graph learning. We will clarify this in the revised manuscript.\n\n**Q1: ""Is your method more powerful than the two combined, or more powerful than each of them separately?""**\n\nRePHINE is more expressive than the union of the families of node- and edge-color filtrations. In particular, in Theorem 4, saying that RePHINE is strictly more expressive than vertex- *or* edge-level filtration implies that it is more powerful than they combined (union only allows the separation of graphs that can be separated by one of the filtration types).\n\n**Q2: ""What is a suitable metric for the augmented persistence diagrams?""**\n\nThis is an interesting question. In particular, future research could consider the suitability of the bottleneck distance for RePHINE diagrams with necessary changes. \n\n**Q3: ""Which software do you use for calculation of PH?""**\n\nOur code is based on the official repo of Topological GNNs. As such, we have modified their routine to compute our augmented diagrams. It consists of a Torch implementation using a Find-Union data structure.\n\nIn the following, we list the minor suggestions. For conciseness, we mark with $\\checkmark$ the accepted suggestions. \n1. $\\checkmark$ “Experiments ... five real-world datasets.” $\\rightarrow$ “Experiments ... on three synthetic and five real-world datasets.”\n2. $\\checkmark$ Provide a reference for persistence diagram (e.g., in Section 2)\n3. $\\checkmark$ Explicitly mention that all lemmas and theorems are proved in Appendix B.\n4. $\\checkmark$ Lemma 1 Vertex-based filtrations … $\\rightarrow$ Lemma 1 Injective vertex-based filtrations …\n5. It would be good to also have explicit Definitions for separating and disconnecting set. --- **This might be adopted if the page limit allows.**\n6. $\\checkmark$ Improve consistency in naming theoretical results.\n7. $\\checkmark$ A visual or table summary (can be placed in Appendix B) of your theoretical results could really help the readability of Section 3 and the impact of your work.} **See attached PDF.**\n8. $\\checkmark$ \\textbf{What is $\\{\\{$ on line 135, line 160, line 182, line 199?} **We use $\\{\\{$ to represent multisets.**\n9. $\\checkmark$ In Section 3, you denote birth and death values with b and d, but you use a and b in Section 4.} **We are now using $b$ and $d$, as suggested.**\n10. $\\checkmark$ Introduce the augmented PH as an explicit Definition in  Section 4.\n11. $\\checkmark$ Cite specific Appendix (e.g. Appendix B).\n12. $\\checkmark$ Capitalization in References\n\n---\n We\'re grateful for your thoughtful and perceptive comments, and hope our answers have improved your assessment of this work.\n'}}, {'rebuttal': {'value': 'We are grateful for your insightful comments and suggestions to improve the paper. Below we address your concerns.\n\n**W1/Q1: ""the empirical claims about the performance of the RePHINE would be better substantiated with experimental evaluation on more datasets."" / ""How does your main strategy (RePHINE) compare to ... Perslay""**\n\nOur initial experiments aimed to 1) corroborate our analysis (synthetic datasets), 2) show that RePHINE also works in scenarios where topological descriptors are combined with GNNs for tackling real-world problems. In total, we considered eight datasets. To further assess the effectiveness of RePHINE, we are currently running experiments regarding integrating RePHINE into SOTA GNNs, including results on additional datasets. We will report these additional experiments in the revised paper.\n\nBased on your feedback, we have now also conducted experiments to compare PersLay and RePHINE on 4 real datasets. To ensure a fair comparison, we processed extended and RePHINE diagrams similarly. In particular, we followed the design of PersLay, i.e., the vectorizations of the diagrams are combined with graph-level features (same as the one used by PersLay) and treated with a linear classifier. We ensured that both methods use identical data samples and used early stopping with the same patience for both methods. The results are in Table 1 of the attached PDF. Overall, RePHINE outperforms PersLay by a significant margin.  \n\n**W2: ""the limitations of the approach are not discussed in detail...no future work or open questions are mentioned.""**\n\nWhile the complete characterization of the expressivity of RePHINE is an interesting open problem, we can lower-bound its capacity. In particular, if two graphs have one color, RePHINE cannot separate graphs of equal size with the same number of components and cycles. For example, we now show that RePHINE can\'t separate 4-node star/path graphs (details in the attached PDF).\n\nImportantly, there are many relevant open questions regarding RePHINE/PH in graph learning, including generalization capabilities of existing methods, local versions of RePHINE, and the characterization of which graph properties RePHINE (and other PH-based methods) can compute. Comparing RePHINE and extended PH (or assessing the power of an extended variant of RePHINE) from a theoretical perspective is another interesting open problem. We will add this discussion to the subsection \'Limitations/Future Works\' in the revised version of the paper.\n\n**Q2: ""Is it clear that RePHINE is isomorphism invariant?""**\n\nThank you for raising this question that has led us to formally prove that RePHINE is indeed isomorphism invariant as a new Corollary:\n\n*Let $G$ and $G\'$ be isomorphic graphs. Then, any edge-color and vertex-color filtrations produce identical RePHINE diagrams for $G$ and $G\'$.*\n\nWe sketch the essential arguments of the proof here. RePHINE diagram’s isomorphism invariance stems from the fact that it is a function of a filtration on a graph, and this filtration is obtained from isomorphism invariant colorings. Further, when matching a vertex with a diagram element (i.e. deciding which vertex \'died\' at the death of a component), RePHINE uses minimum and maximum -functions, which are invariant with respect to the order of comparisons done. \n\n**Q3: ""Is RePHINE stable in the sense of persistent homology?""**\n\nThank you for the interesting question. We believe analyzing the stability properties of RePHINE could be an interesting follow-up work. We will mention this in the newly added subsection ‘Limitations and Future Works’.\n\n**Q4: ""you mention that you aim to fully characterize graphs that can be distinguished with persistent homology. Was this achieved or are there still open questions?""**\n\nWe analyzed the general case of filtrations based on node and edge colors and indeed provided a complete characterization of attributed graphs that can be distinguished with PH methods that employ these filtrations (using the new notion of color-separating sets). However, there are other types of filtration functions, e.g., based on the spectral decomposition of graph Laplacians, that we have not considered in this paper. Also, there are important open problems, including generalization, stability, and complete characterization of the proposed method, i.e., RePHINE. We believe the novel analyses introduced as part of this work could help in resolving these open problems, and may also foster the rise of other powerful topological descriptors.\n\nBelow, we address the minor issues you pointed out. \n1. **Should the subset inclusion be $\\in$**: Yes.\n2. **the double brace notation has not been introduced**: We introduced the notation for multisets in the revised paper.\n3. **when you say ""graph"" here, you mean a graph together with a vertex coloring function, as well as a filtration defined on those colors ...**: We note that filtration functions do not come with our definition of graphs. We have added the term \'colored (or attributed) graphs\' when we define graphs.\n4. **In Theorem 1..do you mean diagrams in homological degree 0, in homological degree 1, or both?** We meant 0-dim diagrams. We have replaced $\\mathcal{D}_G$ with $\\mathcal{D}_G^0$ for clarity.\n5. **Could you please comment on the relevance of Lemma 7? How can it be used (in theory or in practice)?**\nLemmas 6 and 7 motivate the introduction of color-disconnecting sets and help to characterize the expressivity of almost holes. We have added a reference also to Lemma 7 when introducing color-disconnecting sets.\n6. **Is there a geometric or topological motivation for ""case a=0""?** Case a = 0 corresponds to pairs that are augmented with an independent vertex-color filtration.\n---\nWe hope our answers (including empirical comparison with PersLay, proof of isomorphism invariance, and discussion about open problems and limitations) have sufficiently addressed most of your concerns and that you would kindly consider increasing your score. '}}, {'rebuttal': {'value': 'Thank you very much for your thoughtful feedback. We address all your questions below. \n\n**W1: ""the paper does not position itself with respect to recent methods for graph classification""**\n\nThanks for the opportunity to position our work appropriately.  Persistent homology methods that we consider here provide valuable topological information that can often be integrated into recent graph embedding methods such as variants of (geometric) graph neural networks (GNNs) to boost their performance. Therefore, we believe their role is complementary to the existing graph classification methods, so our initial experiments focused on corroborating the benefits of augmenting popular GNNs with topological descriptors. We are currently running experiments to investigate further benefits of integrating the RePHINE diagrams into modern GNNs (e.g., PNA, SpecFormer). We will include these results in the revised version of the manuscript.\n\nBased on the reviews, we have now also compared the proposed method RePHINE with a state-of-the-art persistent homology method Extended PH (Perslay) on several real datasets such as NCI109, Proteins, IMDB-B, and NCI1. Our results demonstrate that RePHINE performs better on these datasets (please see Table 1 in the attached pdf). Thus, beyond the theoretical analyses, the empirical benefits of RePHINE can already be demonstrated.\n\n**W2: ""is there any particular graph structure in which the proposed method cannot distinguish two non-isometric graphs?""**\n\nThat\'s another excellent question. Indeed, there are non-isomorphic graphs that cannot be separated based on RePHINE diagrams. In particular, if two graphs have one color, RePHINE cannot separate graphs of equal size with the same number of components and cycles. For instance, a 4-node star graph and a 4-node path graph cannot be separated. We\'ve added a visualization in Figure 1 (in the attached pdf) to show this limitation.\n\n**Q1: ""it is not clear which lemmas/theorems are introduced by the authors and which ones are just reported.""**\n\nAll Lemmas/Theorems,  including those in the preliminaries and following sections, are introduced and proven in this paper. To emphasize this, we\'ve now added a Table with a summary of our contributions in the Introduction --- we\'ve also included the Table in the attached PDF. Please note that we have now additionally proved that RePHINE is isomorphism invariant (see our reply to reviewer x2he for details).\n\n**Q2: ""I would add to the comparison soma SOTA method for graph classification.""**\n\nThanks for your comment. As we mentioned in the answer to R1-W1 above, we are running further experiments to substantiate the benefits of integrating RePHINE into SOTA GNNs. We will include these results in the revised version.\n\n**Q3: ""For MOLHIV the ROC-AUC is usually reported.""**\n\nThanks for catching this. Indeed, the numbers in the paper for MOLHIV are ROC-AUC values. We will make this clear in the revised manuscript.\n\n***\nMany thanks again for your constructive feedback. Based on your review, we will update our paper to include additional results regarding the combination of RePHINE + modern GNNs (SOTA) and clarify our contributions (including their limits). We hope our answers have sufficiently addressed your concerns, and the same translates into your stronger support for this work. '}}, {'summary': {'value': 'The paper provides a theoretical analysis of the expressive power of Persistent Homology (PH) features in distinguishing different colored graphs. The paper characterizes the family of graphs that is separable by a 0-dimensional PH using either node filtering or edge filtering and identifies the failure cases. Based on the theoretical analysis, a new PH filtration is proposed that overcomes the previous limitation and is provably strictly more expressive than either node or edge filtering. The new filtering is compared with standard PH filtering on a synthetic dataset and a few graph-classification benchmarks.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The main contribution of the paper lies in the theoretical analysis of the expressive power of PH filtering, which allows one to understand the limits of standard filtering schemes fully and to build a new enriched scheme to overcome them. \nThe paper is generally well-written and drives you through the reasoning that led to the development of the method while introducing all the essential theorems. Fully understanding them and grasping all the implications requires some effort from the reader, and possible to jump forth and backward from the main paper and the supplementary where proofs are given, but this has to be expected in this kind of paper.'}, 'weaknesses': {'value': 'If the paper is well structured for what concerns the theoretical analysis, the experimental one is a bit lacking. In particular, in its current state, the paper does not position itself with respect to recent methods for graph classification, and it is not clear if it is a practical competitive alternative or if the contribution mostly lies on the theoretical analysis and just paves the road to future possible developments.\n\nA felt also that an analysis of the expressive power bounds of the proposed method could have been interesting. For instance, is there any particular graph structure in which the proposed method cannot distinguish two non-isometric graphs?'}, 'questions': {'value': 'Going through the Lemmas introduced in the preliminaries and the following section, it is not clear which lemmas/theorems are introduced by the authors and which ones are just reported (if any). \n\nI would add to the comparison soma SOTA method for graph classification.\n\nFor MOLHIV the ROC-AUC is usually reported.'}, 'limitations': {'value': 'I do not foresee any particular negative societal impact. A discussion on the theoretical and practical (if any) limitations of the proposed method, also w.r.t. SOTA on graph classification, would better help to understand the current and future potential of the method.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The discriminative power of the persistent homology (in certain homological degrees) of vertex- and edge-filtered graphs is characterized in terms of combinatorial structure of the graphs. It is shown that there exist pairs that can be distinguished by the persistent homology of vertex-filtrations but not by the persistent homology of edge-filtrations, and viceversa. This is used to motivate the introduction of a new topological descriptor of graphs which is strictly more discriminative than the persistent homology of both vertex- and edge-filtrations.\nThe performance of this descriptor is evaluated on benchmark datasets.\n\n[Post rebuttal edit] Raised score to 6.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': '1. The theoretical results on the expressiveness of persistent homology of vertex- and edge-filtered graphs are interesting, and they are put to good use in that they motivate the design of a provably stronger topological descriptor of graphs.\n\n2. The fact that the invariant being introduced is strictly more discriminative than the persistent homology of vertex- and edge-filtrations seems to be relevant in practice.'}, 'weaknesses': {'value': '3. The exposition is, at times, not that easy to follow. See, in particular, my comment about line 174, below.\n\n4. The experimental section is interesting, but the empirical claims about the performance of the RePHINE would be better substantiated with experimental evaluation on more datasets.\n\n5. The conclusions are a bit too succinct. In particular, the limitations of the approach are not discussed in detail. Relatedly, no future work or open questions are mentioned.'}, 'questions': {'value': '## Main questions\n\n6. Your approach seems similar to extended persistence (in the sense of your reference [2]).\nHow does your main strategy (RePHINE) compare to extended persistence and in particular to Perslay (both in theory and in practice)?\nCan you substantiate this with theory or experiments?\n\n7. Is it clear that RePHINE is isomorphism invariant? Since this is an important property for the theorical section of this paper, I believe that this should be addressed explicitly.\n\n8. Is RePHINE stable in the sense of persistent homology? Is this relevant in your setup?\n\n9. In line 58 you mention that you aim to fully characterize graphs that can be distinguished with persistent homology.\nWas this achieved or are there still open questions?\n\n## Minor questions and comments\n\n10. Line 61: Should the subset inclusion be $\\in$?\n\n11. Line 135: the double brace notation has not been introduced and is quite important for this paper.\n\n12. Line 174: I understand that, when you say ""graph"" here, you mean a graph together with a vertex coloring function, as well as a filtration defined on those colors.\nHowever, in line 198 (Theorem 1), the graphs $G$ and $G\'$ don\'t come with a filtration.\nThe convention on what exactly is a graph and what extra structure is used in each result should be made more explicit.\nIf graphs are always assumed to be colored, I would also suggest using the term ""colored graph"", or a term to the same effect.\n\n13. Line 198: In Theorem 1, when you write $D_G$, do you mean diagrams in homological degree 0, in homological degree 1, or both?\n\n14. Line 219: Could you please comment on the relevance of Lemma 7? How can it be used (in theory or in practice)?\n\n15. Line 312: Is there a geometric or topological motivation for ""case a=0"" in line 312?'}, 'limitations': {'value': 'The paper would benefit from a discussion about limitations of the approach, even if brief. This will help readers asses how useful is their approach for specific tasks, as well as what remains to be done and what are the current promising avenues in the theoretical front.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors introduce RePHINE, which calculates 0-dimensional persistent homology (PH) with respect to the filtration on edge colors, augmented with so-called missing holes and vertex color information. They establish the necessary and sufficient conditions for distinguishing graphs. RePHINE is shown to be more expressive than both standard 0-dim and 1-dim PH, can be easily integrated into GNNs, and is demonstrated to boost their expressive power on several benchmarks for graph classification.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '(S1) The three questions in the Introduction nicely position and motivate the work, and the presentation of the main contributions is very clear.\n\n(S2) The theoretical results are relevant, as they discuss in detail the expressivity of PH on vertex-color and edge-color filtrations, and expressivity of RePHINE. I do not have a good overview of PH on graphs, so I cannot comment on the novelty of results, and I did not check the supplementary material for proofs.\n\n(S3) Experiments are carried out on 3 synthetic and 5 real-world datasets.\n'}, 'weaknesses': {'value': '(W1) The related work seems not be detailed enough and is hard to identify.\n\n(W2) The name RePHINE is clever and nice. However, the word interleaving suggests interleaving distance (esp. relevant in TDA), so it would probably be better to replace this with e.g. interplay or integration. Also, it is somewhat a misnomer since you are not really using a filtration on nodes (this information does not influence birth and death values), so it might be better to rephrase that part too (e.g. Refined PH by incorporating node-color on edge-based filtration)?\n\n(W3) From the beginning of the paper, I was confused what the particular interplay between vertex- and edge-based PH will be. This was most pronounced in Section 3.3, since your way of edge-coloring definition, if used together with vertex-coloring, does not satisfy the definition of simplicial complex. For example, f(orange)=1, f(blue-orange)=2, f(blue)=3, so that an edge can appear in the filtration before the two incident vertices appear. Stressing earlier on (already in Section 1) that you calculate PH on edge-based filtration, including so-called missing holes and augmenting it with vertex-color information would be helpful. See related comment (W2) on the acronym RePHINE above. \n\n(W4) You write: “We note that missing holes correspond to cycles obtained from 1-dim persistence diagrams.” How does you approach compare to concatenated standard 0- and 1-dim PH on edge-based filtration?\n\n(W5) Experimental results on synthetic data: More information about the data should be included (in Appendix C.1). What exactly is the problem/goal here? What type of graphs results in the same RePHINE representation (in particular for cub12-3)? You write that you compare with 0- and 1-dim PH on vertex-color filtration, but what exactly do you mean by this, is this information concatenated (union of sets is considered)? What about PH on edge-color filtration? Why are standard PH and GNNs performing so poorly?\n\n(W6) Experimental results on real-world data: You write that you compare against standard color-based PH, but what do you mean with this? See related comments in (W4). It would be interesting to look at the results in more detail, in particular to discuss some examples that would be wrongly classified with other approaches, but that are successfully tackled with your method, but also at the examples that cannot be classified properly with your approach (the discussion may be placed in an appendix).\n'}, 'questions': {'value': 'Main questions are formulated in the weaknesses (W1)-(W6) above.\n\n(Q1) Abstract: “… provably more powerful than both”. The word both is confusing here, is your method more powerful than the two combined, or more powerful than each of them separately?\n\n(Q2) What is a suitable metric for the augmented persistence diagrams? A brief comment is sufficient, and can be placed in future research.\n\n(Q3) Which software do you use for calculation of PH?\n\nSome minor suggestions:\n\n-\t“Experiments support our theoretical analysis and show the effectiveness of RePHINE on five real-world datasets.” -> “Experiments support our theoretical analysis and show the effectiveness of RePHINE on three synthetic and five real-world datasets.”\n-\tProvide a reference for persistence diagram (e.g., in Section 2), so that readers can find more information, and to make it clear that this is not defined for the first time here in your work.\n-\tExplicitly mention that all lemmas and theorems are proved in Appendix B, since one might wonder if some or all of these are earlier results.\n-\tLemma 1 Vertex-based filtrations … -> Lemma 1 Injective vertex-based filtrations …\n-\tFor better readability, it would be good to also have explicit Definitions for separating and disconnecting set. Improve consistency in naming theoretical results, e.g., if Lemma 6 (Edge-based almost holes as disconnecting sets), then it is better that Lemma 4 (Vertex-based almost holes as color-separating sets).\n\n-\tA visual or table summary (can be placed in Appendix B) of your theoretical results could really help the readability of Section 3 and the impact of your work. For example, some of the table rows could be the following:\n1) Real holes (d = infty) of 0-dim PH wrt vertex-color filtration --- Component-wise colors --- Lemma 2\n2) Almost holes (b neq d, d < infty) of 0-dim PH wrt vertex-color filtration --- Color-separating sets --- Lemma 3\n3) Birth time of 0-dim persistence interval wrt vertex-color filtration --- Vertex color --- Lemma 5\n4) Almost holes  (b neq d, d < infty) of 0-dim PH wrt edge-color filtration ---- Disconnecting sets --- Lemma 6\n\n-\tWhat is {{ on line 135, line 160, line 182, line 199, …?\n-\tIn Section 3, you denote birth and death values with b and d (I think this is more common and readable), but you use a and b in Section 4.\n-\tIntroduce the augmented PH as an explicit Definition in Section 4, as this is your main contribution.\n-\tCite specific Appendix (e.g. Appendix B), rather than pointing to the general Appendix.\n-\tCapitalization in References: PersLay, Kolmogorov, Rayleigh-Bénard, Leman\n'}, 'limitations': {'value': 'Limitations and future work are not discussed.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'In this paper, the authors discuss the limitations of message-passing graph neural networks (MP-GNNs) in terms of the Weisfeiler-Leman test for isomorphism. They explore the use of persistent homology (PH) to augment graph models with topological features but highlight the challenge of identifying the class of attributed graphs that PH can recognize. To address this problem, they introduce the concept of color-separating sets. They establish necessary and sufficient conditions for distinguishing graphs based on the persistence of their connected components using filter functions on vertex and edge colors. Based on these insights, they propose RePHINE, a method for learning topological features on graphs. RePHINE integrates both vertex-level and edge-level PH, claimed to be more powerful than either category alone. When incorporated into MP-GNNs, RePHINE enhances their expressive power.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': 'The paper presents new theoretical results and introduces a concept of color-separating sets, providing a resolution to the problem of recognizing attributed graphs based on the persistence of their connected components. The authors establish necessary and sufficient conditions for distinguishing graphs using filter functions on vertex and edge colors. They also propose RePHINE, a method for learning topological features on graphs, which integrates both vertex-level and edge-level persistent homology.'}, 'weaknesses': {'value': ""While the theoretical contributions of this paper are new, there is room for further exploration and validation in real-world experiments. The current evaluation primarily focuses on controlled simulated datasets, limiting our understanding of RePHINE's performance in practical scenarios. It is equally important to conduct more comprehensive experiments using real-world data to fully assess the efficacy and applicability of the proposed approach. Addressing these limitations would strengthen the practical relevance of the paper's findings. Are there any specific limitations or challenges when applying RePHINE to real-world applications? Additionally, it would be interesting to understand the factors that contribute to the marginal performance gain of RePHINE on most real-world datasets.""}, 'questions': {'value': 'Please refer to the sections above.'}, 'limitations': {'value': 'Please refer to the sections above.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': '- The paper presents a comprehensive analysis of two types of color filtrations on graphs, focusing on their expressiveness. \n\n- The paper introduces a novel topological summary RePHINE that combines both node and edge persistence diagrams. The proposed summary is proven to be more expressive than either node or edge persistence diagrams alone.\n\n- The authors conduct experiments on synthetic and real-world datasets. They leverage a combination of RePHINE and a GNN structure to evaluate its performance. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The presented method RePHINE for mixing 0- and 1- dim information is interesting and, as far as I know, is novel. \n- A remarkable strength of the proposed method is its theoretical expressiveness, which surpasses the capabilities of utilizing 0- or 1-dimensional information in isolation.\n- The paper is well presented and effectively communicates its ideas, ensuring a high level of clarity and ease of understanding for readers.'}, 'weaknesses': {'value': 'One weakness of the paper lies in the experimental evaluation section, which could benefit from a more comprehensive comparison with existing methods, such as the method proposed in [28]. Specifically, the paper could have included a comparative analysis between the proposed method and the local Persistent Homology (PH) method based on subgraph persistence diagrams included in  [28].'}, 'questions': {'value': '- line 47-52: I think there is some syntax issue with the appearance of [Theory], [Methodology] and [Experiments]\n- line 142: ""disconnect"" should be ""disconnects"".\n- line 172: please mention that Q is a color separating set in this sentence.\n- line 502: what does ""disjoint union"" here mean? What does ""these sets"" refer to? could you please provide an explicit description of the set you are constructing here?\n- line 510: I don\'t think $\\{\\{X_i\\}\\}$ should have $l$ as a superscript. Are you also referring to connected components with $l$ colors instead of subgraphs?\n- line 513: ""l+1 the"" -> ""l+1 th""\n- line 693: ""it is not injective"" should be ""is not injective"".'}, 'limitations': {'value': 'The limitations of the method are not adequately discussed. I think it would be beneficial for the authors to discuss applicability of the proposed method to handle large scale graphs.\n\nThere are no potential negative societal impact of the work.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Going beyond persistent homology using persistent homology'}, 'authors': {'value': ['Johanna Emilia Immonen', 'Amauri H Souza', 'Vikas Garg']}, 'authorids': {'value': ['~Johanna_Emilia_Immonen1', '~Amauri_H_Souza1', '~Vikas_Garg2']}, 'keywords': {'value': ['graph representation learning', 'topological deep learning', 'persistent homology', 'graph neural networks']}, 'abstract': {'value': 'Representational limits of message-passing graph neural networks (MP-GNNs), e.g., in terms of the Weisfeiler-Leman (WL) test for isomorphism, are well understood. Augmenting these graph models with topological features via persistent homology (PH) has gained prominence, but identifying the class of attributed graphs that PH can recognize remains open.  We introduce a novel concept of color-separating sets to provide a complete resolution to this important problem. Specifically, we establish the necessary and sufficient conditions for distinguishing graphs based on the persistence of their connected components, obtained from filter functions on vertex and edge colors. Our constructions expose the limits of vertex- and edge-level PH, proving that neither category subsumes the other. Leveraging these theoretical insights, we propose RePHINE for learning topological features on graphs. RePHINE efficiently combines vertex- and edge-level PH, achieving a scheme that is provably more powerful than both. Integrating RePHINE into MP-GNNs boosts their expressive power, resulting in gains over standard PH on several benchmarks for graph classification.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/3d67c9f007ba314fecac5c0d56a04fd38fd00bcf.pdf'}, '_bibtex': {'value': '@inproceedings{\nimmonen2023going,\ntitle={Going beyond persistent homology using persistent homology},\nauthor={Johanna Emilia Immonen and Amauri H Souza and Vikas Garg},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=27TdrEvqLD}\n}'}, 'paperhash': {'value': 'immonen|going_beyond_persistent_homology_using_persistent_homology'}}]"
"['Jihao Andreas Lin', 'Javier Antorán', 'Shreyas Padhy', 'David Janz', 'José Miguel Hernández-Lobato', 'Alexander Terenin']",NeurIPS,Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent,https://neurips.cc/virtual/2023/oral/73846,2023," Gaussian processes are a powerful framework for quantifying uncertainty and for sequential decision-making but are limited by the requirement of solving linear systems. In general, this has a cubic cost in dataset size and is sensitive to conditioning. We explore stochastic gradient algorithms as a computationally efficient method of approximately solving these linear systems: we develop low-variance optimization objectives for sampling from the posterior and extend these to inducing points. Counterintuitively, stochastic gradient descent often produces accurate predictions, even in cases where it does not converge quickly to the optimum. We explain this through a spectral characterization of the implicit bias from non-convergence. We show that stochastic gradient descent produces predictive distributions close to the true posterior both in regions with sufficient data coverage, and in regions sufficiently far away from the data. Experimentally, stochastic gradient descent achieves state-of-the-art performance on sufficiently large-scale or ill-conditioned regression tasks. Its uncertainty estimates match the performance of significantly more expensive baselines on a large-scale Bayesian~optimization~task.",Oral 5C Probability/Sampling,https://openreview.net/pdf?id=Sf9goJtTCE,https://openreview.net/forum?id=Sf9goJtTCE,Sf9goJtTCE,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper considers the use of stochastic gradient descent to approximately solve linear systems in Gaussian process (GP) modeling tasks, and this method is explored in a number of experiments for prediction and decision making. Overall, reviewers found the contribution to be novel and leading to interesting insights, and reviewers also appreciated presentation of the ideas and clean figures. Understanding a new approach of training GP models in large data settings is a topic of interest to a broad audience from researchers interested in methodology/theory to ones interested in applying scalable GP methods in practice.  \n\nWe encourage the authors to revise the paper to incorporate suggestions from the reviewers and points made during the discussion phase, e.g., emphasizing the connection to broader areas where this work would be impactful, including the additional baselines presented during the rebuttal, and adding more in depth discussion of limitations and potential follow-up directions.'}}, {'comment': {'value': 'Thank you for the further explanations and responses to several questions. I am pretty satisfied with them and will keep the score as is.'}}, {'comment': {'value': 'Thanks to the authors for their response! These additional materials definitely strengthen the paper and would be great to be incorporated into the final version. I have raised my score from 6 to 7.'}}, {'title': {'value': 'Real applicability: BO over molecular properties with Tanimoto kernel and more '}, 'comment': {'value': 'Thank you very much for your reply! We go on to describe our ongoing work on the application of SGD GPs to molecular property prediction as well as how the method can be applied more generally, for instance, to spatiotemporal modeling.\n\n----\n\n1. We are currently working on **applying SGD inference to molecular binding energy prediction** using a dataset of 250k molecules introduced by [1]. We are using the Tanimoto kernel for graphs, which admits random features ([2]). In particular, we are searching for molecules which have a high probability of binding to proteins of interest using Bayesian Optimization. \n\n* The Tanimoto kernel only has 1 hyperparameter, the marginal kernel variance. For this task, the **authors of  [1] provide an optimized kernel hyperparameter** value, which they used in their experiments. Additionally, the **authors of [3] show how marginal kernel variances can be learnt using only GP posterior samples.** Thus, our SGD-based inference can be directly applied to this setting for learning the Tanimoto kernel’s hyperparameter. \n\n* Although there is not enough time to conclude these experiments before the end of the discussion period (the 21st), we would be happy to include them in the camera-ready version of the paper. \n\n\n\n2. **We think that GP inference methods can be useful even without hyperparameter learning.**  A simple but general and effective approach to select hyperparameters is to **maximize the marginal likelihood on clustered subsets of the data**, as we do in our paper (See Appendix A.1). This yields results competitive with, and in some datasets outperforming, the hyperparameters learnt via conjugate gradients of [4]. This approach is particularly well-suited to length scale hyperparameters, which are of key importance in spatiotemporal modeling.\n\n\n3. Next, **ill-conditioning appears consistently for large enough datasets or when the kernel distance between observations is small** (in fact, *often provably so* - see Section 2.3 of [5]), so one does not need to search particularly hard to find examples. The latter is bound to occur in Bayesian optimization, since methods often explore near previously-found well-performing locations. \n\n4. Finally, there is strong precedent in the Gaussian processes where (a) **a novel method with significant advantages but important limitations was introduced**, and (b) **the limitations were addressed through follow-up work**. \n\n* For example, Titsias [6] introduced the variational-inference-based view of sparse Gaussian processes, developing a novel formalism for inducing points, whose complexity is $O(NM^2)$ - larger than for instance certain subset-of-data methods. Then, Hensman et al. [7] reduced this to $O(M^3)$ - a major improvement when $N$ is in the millions - by applying stochastic optimization to the variational inference objective. Achieving this improvement was only possible because the variational viewpoint had been developed previously. \n\n* Mirroring this example, **we expect that follow-up work, using for instance bilevel optimization techniques, can address limitations around hyperparameter learning** (for examples of such techniques in a neural network context, see [8,9]). This would start from the ideas we developed, but would likely introduce enough additional theoretical and methodological contributions, as well as experimental evaluation specific to hyperparameter optimization, to constitute another paper.\n\n[1] *DOCKSTRING: Easy Molecular Docking Yields Better Benchmarks for Ligand Design.*\nMiguel García-Ortegón*, Gregor N. C. Simm, Austin J. Tripp, José Miguel Hernández-Lobato, Andreas Bender, and Sergio Bacallado\n\n[2] *Tanimoto Random Features for Scalable Molecular Machine Learning*.\nAustin Tripp, Sergio Bacallado, Sukriti Singh, José Miguel Hernández-Lobato\n\n[3] *Sampling-based inference for large linear models, with application to linearised Laplace.*\nJavier Antorán, Shreyas Padhy, Riccardo Barbano, Eric Nalisnick, David Janz, José Miguel Hernández-Lobato\n\n[4] *Exact Gaussian Processes on a Million Data Points.*\nKe Alexander Wang, Geoff Pleiss, Jacob R. Gardner, Stephen Tyree, Kilian Q. Weinberger, Andrew Gordon Wilson\n\n[5] *Numerically Stable Sparse Gaussian Processes via Minimum Separation using Cover Trees*.\nAlexander Terenin, David R. Burt, Artem Artemev, Seth Flaxman, Mark van der Wilk, Carl Edward Rasmussen, Hong Ge\n\n[6] *Variational learning of inducing variables in sparse Gaussian processes*. Michalis Titsias\n\n[7] *Gaussian processes for big data*. James Hensman, Nicolò Fusi, Neil Lawrence.\n\n[8] *Scalable One-Pass Optimisation of High-Dimensional Weight-Update Hyperparameters by Implicit Differentiation*. Ross M. Clarke, Elre T. Oldewage, José Miguel Hernández-Lobato\n\n[9] *Generalized Inner Loop Meta-Learning*. Edward Grefenstette, Brandon Amos, Denis Yarats, Phu Mon Htut, Artem Molchanov, Franziska Meier, Douwe Kiela, Kyunghyun Cho, Soumith Chintala'}}, {'comment': {'value': ""I want to thank the authors for their thoughtful response. Most of my questions are touched and addressed. \n\nHowever, my concern on the potential impact of this work is not fully resolved. In the authors response to Reviewer w7c5, two promising applications are (1) large-scale BO (with parallel Thompson sampling), and (2) large-scale spatio-temporal modeling. The paper investigates the first application in a synthetic setting (correct me if I am wrong). While the results seem encouraging, it would be more convincing to conduct the experiments in benchmark BO datasets (ideally also ill-conditioned to demonstrate its advantage). Is there a reason that the authors did not choose to do so? For (2), since the proposed method can only perform posterior sampling given fixed hyper-parameters instead of _learning_ the hyperparameters, how can it be useful for sptaio-temporal modeling? Is there a scenario where the large-scale posterior sampling is of interest in that domain? \n\n\n\nAgain, I wanted to say that I believe the proposed method could potentially shine in many applications. However, I feel the paper and the authors response haven't really touched upon its real applicability. I would be happy to raise my score once this concern is addressed. ""}}, {'title': {'value': 'Thank you!'}, 'comment': {'value': 'Thanks to the authors for addressing my questions. I am very much aware of the BO implications, but I value the references to other use-cases, which points to the potentially substantial impact of the work. \n\nThis paper was a pleasure to read. Once again, I greatly appreciated the clearly addressed limitations, which should not go unnoted. \n\nI have increased my score to a 9.'}}, {'rebuttal': {'value': ""We thank all reviewers for the time taken to read our paper and for their insightful and helpful comments. We are pleased the reviewers unanimously found our paper to be well-written, novel, and interesting.\n\n----\n\nThe two most pressing concerns come from:\n\n* Reviewers Hc1f and w7c5 ask about the **significance of the setting covered**.\n\n\n\nThe technique presented is immediately useful for **large-scale Bayesian optimization**. This problem appears most often in industrial settings and is the focus of our paper's second experiment\n\nOur work also presents a novel approach to deal with **ill-conditioning in GP kernel matrices**. Ill-conditioned systems appear in almost all moderate-to-large-scale GP problems. \n\nFurther details on both of these points are given in the rebuttals for Reviewers Hc1f and w7c5.\n\n----\n\n* Reviewer xja3 is concerned about our **lack of comparison against Subset of Data (SoD) inference and our choice of SVGP hyperparameters**.\n\nWe have run **additional regression experiments using SoD methods**. \n\nWe further illustrate the strengths and weaknesses of SoD in **Figure 1(r) in the attached PDF**: SoD performs strongly only when the data is very redundant.\nWe have also **run the SVGP baseline with the number of inducing points increased to 4096.**\n\nQuantitative results are provided in the individual response to xja3.""}, 'pdf': {'value': '/pdf/143568894ff2d0f9c3b9fc699191f2db3b331acf.pdf'}}, {'rebuttal': {'value': ""Thank you very much for your review! Below we address the key points:\n\n**Comparison with Subset of Data Methods**\n\nThank you for bringing SoD methods to our attention. *We ran SoD on our regression datasets.* We randomly select subsets from the training data and build exact GP models with these points. We use the complete datasets for data normalization. We provide mean results and std. err. across dataset splits and subset seeds. \n\nWe consider 5% and 10% subsets for the small and medium datasets. For the larger datasets, we use 25k and 50k (largest possible on an 80GB A100 GPU) subsets. These represent roughly 5% and 10% of 3droad song and buzz, and 1.25 and 2.5% of houselectric.\n\nDue to the character limit, we do not reproduce the numbers from our paper here but we bold best results across this table and the paper. \n\n**SoD Small & Medium Datasets**\n|      |  SoD |        pol       |    elevators    |       bike      |      protein     | keggdir   |\n|:----:|:----:|:----------------:|:---------------:|:---------------:|:----------------:|-----------|\n|      |      |     N = 15000    |    N = 16599    |    N = 17379    |     N = 45730    | N = 48827 |\n| RMSE |   5%  | 0.20 ± 0.01  | 0.44 ± 0.00 | 0.18 ± 0.01  | 0.71 ± 0.01 | 0.11 ± 0.00  |\n|      |  10%  | 0.16 ± 0.00  | 0.41 ± 0.01 | 0.13 ± 0.00  | 0.66 ± 0.00 | 0.10 ± 0.00  |\n|  NLL |   5%  | -0.43 ± 0.02 | 0.57 ± 0.01 | -0.61 ± 0.09 | 0.99 ± 0.01 | -0.76 ± 0.10 |\n|      |  10%  | -0.66 ± 0.02 | 0.51 ± 0.01 | -1.28 ± 0.07 | 0.91 ± 0.01 | -0.82 ± 0.09 |\n\n**SoD Large Datasets**\n|      |  SoD |      3droad      |       song      |       buzz      |     houseelec    |\n|:----:|:----:|:----------------:|:---------------:|:---------------:|:----------------:|\n|      |      |    N = 434874    |    N = 515345   |    N = 583250   |    N = 2049280   |\n| RMSE |  25k | 0.23 ± 0.00  | 0.82 ± 0.00 | 0.33 ± 0.00 | 0.06 ± 0.01  |\n|      |  50k | 0.16 ± 0.00  | 0.81 ± 0.00 | **0.32 ± 0.00** | **0.06 ± 0.00**  |\n|  NLL |  25k | -0.42 ± 0.01 | 1.22 ± 0.00 | 0.30 ± 0.06 | -0.53 ± 0.33 |\n|      |  50k | **-0.78 ± 0.01** | **1.20 ± 0.00** | **0.26 ± 0.06** | -0.49 ± 0.39 |\n\nIn terms of mean prediction, SoD does not perform best on any small or medium datasets. We also tried higher percentages: the results are similar. On the large datasets, the 50k subset performs best on buzz, where SVGP previously was the best method, and on NLL for 3droad and Buzz. Note that an exact GP on 50k points requires 40 GB of GPU memory; it is not accessible to most practitioners.\n\nIn terms of error bar geometry, SoD performance is heavily dataset dependent: it performs well when the observations are largely redundant. **We graphically illustrate this with Figure 1(r) in the rebuttal PDF attached to the summary post**.\n\nTo conclude, we would like to emphasize that our contribution is presenting a **novel approach for scaling up Gaussian processes**, quite dissimilar from existing ones. This is valuable due to its opportunity to unlock new avenues for GP research, not because our technique outperforms all baselines across all tasks, which it does not - and, *this is not one of our claims*, as Table 1 (in paper) clearly shows instances where SGD is outperformed by CG and SVGP.\n\n\n**SVGP Hyperparameters and optimization algorithm (ADAM)**\n\n* **Hyperparameters.** To facilitate comparisons with prior work, **our paper used the same SVGP and CG  hyperparameters as Wang et. al. 2019** (a very well-cited NeurIPS2019 paper), which studies conjugate-gradient-based Gaussian processes, and whose techniques are now used in GPyTorch. \n\nWe have also trained SVGP with $M=4096$ inducing points on our 4 largest datasets (we will include the rest in the camera ready), which is rather expensive because 10k optimization steps are needed for convergence and each step's cost is cubic in the number of inducing points $\\mathcal{O}(M^3)$. \n\n|   SVGP 4096   |      3droad     |       song      |       buzz      |     houseelec    |\n|:----:|:---------------:|:---------------:|:---------------:|:----------------:|\n| RMSE | 0.49 ± 0.01 | 0.81 ± 0.00 | **0.33 ± 0.00** |  0.11 ± 0.01 |\n|  NLL | 0.67 ± 0.02 | 1.22 ± 0.00 | **0.25 ± 0.04** | -0.90 ± 0.10 |\n\nAlthough increasing the inducing points improves SVGP's performance on all large datasets, SVGP 4096 only performs best on buzz, where the 1024 point version was already best.\n\n* **Adam.** Our understanding is that ADAM is currently the best optimizer for SVGP. It is the default in GPyTorch, GPFlow, and GPJax. We suspect the reviewer may be thinking of *full-batch* methods such as LBFGS, which **cannot be used with stochastic approximation (i.e. minibatching)**. These optimizers are SoTA for full-batch inducing point approaches such as Titsias 2009, but are incompatible with SVGP (namely, *stochastic* variational GP) which is mini-batch based.\n\n**SGD steps in the complexity analysis**\n\nThis is a good question! Our work's key finding is that *SGD does not need to be run to convergence to produce good empirical performance*. On this basis, it makes sense to view the number of SGD steps as a hyperparameter. This is reflected in our paper's language; **We make no claims about the complexity of SGD Inference, only about the cost of a single optimization step** - e.g. in line 106: “(7)[our unbiased estimator] presents O(N) complexity, in contrast with the O(N^2) complexity of one CG step.”\n\n**Empirically, the number of steps needed to obtain a given performance level is, roughly independent of the dataset size**. We use 100k SGD steps across all experiments, except the Bayesian optimization experiment where we vary this parameter as part of the experiment. We find not only that this is sufficient to obtain reasonable results in all cases but also that the convergence plots (Figures 3, 5, 8) present a similar shape for numbers of observations running from 10k to 2M. \n\n**We have added citation of Rasmussen and Williams (2006)**""}}, {'rebuttal': {'value': 'We would like to thank you their time in reading our work! We are thrilled that you found our writing and plots “Clear"" and ""Informative” and agreed that our paper ""Clearly addressed limitations"". We now discuss weaknesses and respond to your questions:\n\n\n**Significance:**\n> ""I ... remain unconvinced on its potential impact due to the relatively small niche (sampling for GPs in large data regime) that is addressed.""\n\n* **Our main motivating setting is large-scale Bayesian optimization**. Sampling from large-data GPs with fixed hyperparameters is a key component in large-scale Bayesian optimization, particularly in industrial settings. Bayesian optimization (whether under this name, or that of GP bandit algorithms) is a strong approach for the optimization of black-box systems. In particular, sampling from GPs is a core element of the Thompson sampling algorithm. Historically, due to the cost of fitting GPs, Bayesian optimization was limited to small—perhaps even toy—systems; however, work undertaken over the last 5-10 years on scaling inference in GPs, which our method is a part of, now allows for its use on an industrial scale (e.g., optimizing stock levels and recommendations at Amazon). The Thompson-sampling-based approach to Bayesian optimization is particularly well suited to parallelization and asynchronous processing, and thus combines well with such large-scale systems. We believe our approach to sampling to be particularly well-suited for Thompson sampling and easy to use due to its robustness to ill-conditioning. Thus, it has the potential to be adopted by industry users at the usual big-name tech companies (which all provide online recommendations to users and tackle other similar bandit problems, well-suited for Bayesian optimization). \n\n* More generally, there is growing interest in applying GPs to **spatiotemporal modeling** (Howes et al., PLOS Global Public Health 2023, ""Spatio-temporal estimates of HIV risk group proportions for adolescent girls and young women across 13 priority countries in sub-Saharan Africa""), applications in the **physical and natural sciences** (Goḿez-Bombarelli et al., ACS Central Science 2018, ""Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules"") and **climate modeling** (Thompson et al., Environmental Data Science 2022, ""A dependent multimodel approach to climate prediction with Gaussian processes)"". Here datasets tend to be large, and as shown by Foster et al. (2009, JMLR, ""Stable and Efficient Gaussian Process Calculations""), and Terenin et al. (2023, arXiv:2210.07893, ""Numerically Stable Sparse Gaussian Processes via Minimum Separation using Cover Trees""), **ill-conditioned systems appear in almost all moderate-to-large-scale GP problems**. Regularization through for instance inducing point choice helps, but at the cost of bias and performance. Our work suggests an orthogonal way to handle instability is to design algorithms that tolerate ill-conditioning well.\n\n\n**Questions:**\n\n1. **Comparison to Pathwise Sampling:**  \n> ""Does the proposed method hold any advantages to pathwise sampling in a low-to-moderate data regime in terms of accuracy or complexity? At which point (in #data points) does SGD start becoming beneficial?""\n\n* This is a great question! Since our approach is an approximation to efficient sampling (namely pathwise conditioning with no approximations except for the prior term) we expect it to perform worse whenever solving the involved linear systems exactly is tractable, for instance in the low-data, well-conditioned regime. From our experiments (Table 1), we estimate that the transition where SGD may start to become better than CG occurs in the 50k-100k datapoint range. Where in that range depends on kernel-matrix conditioning. For very poorly conditioned kernel matrices, SGD can perform better with only a couple of tens of thousands of points.  \n\n2. **Computing the predictive uncertainty:**  \n> ""How is the predictive uncertainty computed when one can only access the posterior mean and samples from the posterior (and not the posterior variance) in Section 4.1?""\n\n* For each test-point, we estimate the scalar predictive variance from 64 0-mean posterior samples $f_i(x)$ as $\\frac{1}{64}\\sum_{i=1}^{64} f_i(x)^2$. We do this for all methods under consideration. This is tucked away in the second paragraph of Section 4.1 - thank you for pointing this out, we will look into making this point easier to find.'}}, {'rebuttal': {'value': 'We wanted to start by thanking you for your time in reading our work and providing very helpful comments! We are thrilled you found our work “well-written and easy to follow” and agreed that our results are interesting because they provide a “stronger alternative in large-scale or ill-conditioned systems”, which as we will argue below include most systems of sufficient scale. \n\n----\n\nBelow we address the weaknesses and questions:\n\n1.  **Significance of setting**\n\n\n* *Significance*: You are correct that our proposed approach can not be used to tune hyperparameters and requires a Gaussian (*but not necessarily isotropic*) likelihood. In our view, presenting a new, scalable, way to perform posterior inference in GPs is a valuable contribution on its own which can pave the path for future work on hyperparameter selection and non-conjugate inference.\n\n\n* *The fixed hyperparameter* setting occurs in large-scale Bayesian optimization, particularly in industrial settings. Here, hyperparameters are often selected using historical (offline) data, and no updates are made online thereafter. Combining online hyperparameter updates and closed-loop systems is very challenging in practice and rigorous theory of these updates is scarce.\n\n\n* *Ill conditioned systems* appear in almost all all moderate-to-large-scale GP problems. See Foster et al. (2009, JMLR), ""Stable and Efficient Gaussian Process Calculations"", or Terenin et al. (2023, arXiv:2210.07893), ""Numerically Stable Sparse Gaussian Processes via Minimum Separation using Cover Trees"". Regularization through for instance inducing point choice helps, but at the cost of bias and performance. Our work suggests an orthogonal way to handle instability is to design algorithms that tolerate ill-conditioning well.\n\n\n\n2. **Benign non-convergence**  \n\n* > “That SGD converges slowly in extrapolation region is a bit concerning. Especially in applications like Bayesian optimization...high interest for exploration.""  \n\n* This is a very good comment; it illustrates why we find this work so exciting: a priori, we expected the same thing.  \nOur empirical results instead showed that SGD can achieve strong performance in spite of non-convergence. In particular, SGD produces error bars in the extrapolation region which are closer to the prior than the true GP, and thus SGD overestimates uncertainty here. This may cause over-exploration, making convergence somewhat slower. We consider this ""benign"" compared to underestimating uncertainty which may cause catastrophic failure in Bayesian optimization (convergence to a local optimum).  \n\n* The distribution-shift setting is hard to make reasoned arguments about, it is a rather ill-posed problem and there is no guarantee that the exact Bayesian model will perform best in such a setting.\n\n\n\n\n3.  **Formal characterization of region-specific error.**  \nA full mathematical characterization of the part of state-space where non-convergence occurs is what we initially aimed for; however, it proved too difficult. Such a characterization would require one to understand where in space do eigenfunctions corresponding to intermediate eigenvalues occur, which is non-trivial because it is a non-asymptotic question. We believe the amount of work required for this would warrant a separate submission. Alike the reviewer, we think the current analysis is insightful.\n\n4. **The suggested extensions** are good ideas! *Non-conjugate inference* can be immediately achieved via the Laplace approximation as in Antorán et al. (2023), ""Sampling-based inference for large linear models, with application to linearized Laplace"". *Hyperparameter optimization* would require bi-level optimization: an outer loop for the hyperparameters and/or variational parameters, along with an inner loop for the linear systems. Since we cannot expect the inner loop to converge, one would need to study how to ensure that the outer loop behaves well even if the inner loop is not at the optimum. \n\n5. **Questions on experiments**\n\n* You are correct:  **SVGP shares model hyperparameters with CG and SGD**, and also has some variational parameters where applicable. \n\n* We would expect **CG run for sufficiently long** to outperform all alternatives on all data sets. However, for houseelectric (2M+ points), this might take weeks. We are unable to commit that much compute. \n\n\n* **We do provide ""RMSE to exact GP""** on our four small datasets in figures 3 and 8. In Table 1 we use test RMSE and NLL since for datasets with more than 50k observations (the focus of our work), we cannot do exact GP inference. In Table 1, for the four smallest datasets, CG converges to $10^{-2}$ tolerance and thus can be thought of as an **exact GP baseline**. \n\n\n\n6. **Question: CG non-monotonicity**.  \nThis is a good question which we also asked ourselves for some time. Our best explanation: CG converges monotonically in the RKHS norm induced by the chosen kernel. For the Matérn kernel, this RKHS norm is (effectively, i.e. with certain parameter choices and up to norm equivalence) a weighted sum of the $L^2$ norms of the first $m$ derivatives plus the $L^2$ norm of the function itself. CG is thus trading off minimizing the norm of the $m$ derivatives of the function at the expense of the 0th order term: the $L^2$ error in the fit. The derivative norms being minimized first yields the divergence when looking at just $L^2$ error. Of course, since the RKHS norm is a sum of said $m+1$ non-negative terms, minimizing it will eventually force the 0th order term (error in $L^2$ norm) to go to zero too.\n\n\n7. **Other**. Thanks for the suggestions! We have reworked Fig 4 and Proposition 1 to address your comments and add all required definitions.\n\n----\n\nWith these responses in mind, we gently and politely request that you please consider increasing your score towards firm acceptance.'}}, {'rebuttal': {'value': '\nThank you very much for your review! We are delighted that you found our descriptions “clear” and our paper “well-written” - thank you for these comments!\n\n> “It would be nice to discuss why the Fourier basis are used for eigen decomposition and how it performs compared to other basis such as wavelets.”* and asks the question *“To control the approximation error below a constant threshold, how does the number of basis L (number of components) needed scales with the data size and dimension? Either theoretical or numerical result could be interesting.”\n\nThank you very much for these two closely-related questions! Due to the use of the terms “Fourier basis” and “spectral basis” in a non-synonymous way in our work, these questions can be interpreted in two ways: either (1) referring to the number of Fourier features, or to (2) the number of spectral basis functions along which we examine the convergence of SGD. Both questions are interesting, including potentially to other referees, so we will answer each of them.\n\n1. **Fourier features.**  \nIn our work, Fourier features are used to (a) approximate the prior samples needed for pathwise conditioning, and (b) to approximate the regularization term $ || \\alpha ||_K$  which appears in the quadratic objective used by SGD. Neither requires Fourier features explicitly: any finite basis function approximation of the prior kernel will work. None of our techniques are limited to Fourier features - we use them because they are convenient and work well for stationary kernels. For other kernels, including potentially non-stationary kernels, other bases such as wavelets or random hashes (Tripp et al. 2023, ""Tanimoto Random Features for Scalable Molecular Machine Learning"") could be used instead of Fourier features. This can be especially interesting for non-stationary kernels and kernels on boundary-constrained domains.\n\n* **On random (Fourier) feature approximation error**: We only use random features to approximate quantities that do not dependent on the targets: (a) prior function samples and (b) norms in the metric induced by the kernel matrix $\\|\\alpha\\|_K$. In (a), the approximation error is also independent of the number of observations. We found this also to be the case empirically in (b).\n\n* Indeed, we use the same number of random features for across all experiments; 2000 for prior sampling and 100 for kernel matrix norms.   \n\n* Crucially, we do *not* approximate any conditional distributions (i.e. matrix inverses) using random features; we use SGD for this. As the reviewer suggests, approximating conditionals with random features requires a number of features increasing in the number of observations and is prone to variance starvation. See Sutherland and Schneider (2015), ""On the Error of Random Fourier Features"" and Wilson et al. (2021), ""Pathwise Conditioning of Gaussian Processes"" for details including explicit error analysis.  \n\n\n\n\n2. **Spectral basis functions.**  \nOne can ask how many spectral basis functions one needs to look at in the convergence bound to ensure good performance. Recall that these are defined as $u^{(i)}(\\cdot) = \\sum_{j=1}^N U_{ji} / \\sqrt{\\lambda_i} k(x_j, \\cdot)$, where $U$ is the U-matrix in the eigendecomposition of $K_{xx}$ and $\\lambda_i$ are the respective eigenvalues. We chose the term “spectral” for these basis functions since they arise from the kernel matrix’s eigendecomposition. They define a “kernel-specific” basis that in some intuitive sense resembles the Fourier basis, but is different because it is data-dependent. As revealed by Proposition 1, the question of how many such basis functions are needed to ensure good performance is central to the performance of SGD in GPs, because it determines how many iterations are needed to ensure convergence. We do not address this question from a theoretical standpoint, because it is very technically difficult - please see our response to Referee Hc1f part (3) for more on this. '}}, {'summary': {'value': 'This paper introduces a method for fast approximating a Gaussian process posterior when the data size is large. Exact computation complexity would be cubic in the data size, while this method is linear. It originates from the idea of pairwise conditioning of Gaussian process, where the law of Gaussian process posterior is expressed in terms of the law of Gaussian process prior. Decomposition into eigenfunctions gives a way of approximating the Gaussian process posterior, so the posterior inference transforms into appropriately choosing the coefficients of decomposition. Objectives are formed quadratic in the coefficients, which can be optimized with SGD for the sake of lower computational complexity compared to conjugate gradient methods. Ideas of inducing points are also discussed for reducing the data size needed. Intuitive discussion of errors in different regions are companied by figure illustrations as well as some theoretical results. Adequate numerical experiments are presented to support the method.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. The paper has clear descriptions and is well written.\n2. The ideas are mostly original and combine the advantages of multiple methods.\n3. Many figure illustrations are present, making the ideas easily understood.\n4. Supportive numerical experiments are conducted.\n5. The problem of reducing the computational complexity of Gaussian process posteriors is itself very important and meaningful.'}, 'weaknesses': {'value': 'It would be nice to discuss why the Fourier basis are used for eigen decomposition and how it performs compared to other basis such as wavelets.'}, 'questions': {'value': 'To control the approximation error below a constant threshold, how does the number of basis L (number of components) needed scales with the data size and dimension? Either theoretical or numerical result could be interesting.'}, 'limitations': {'value': 'See Weaknesses and Questions.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.', 'Ethics review needed: Discrimination / Bias / Fairness Concerns']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work proposes SGD GP, a method based on stochastic gradient descent to efficiently compute the GP posterior samples given fixed hyperparameters. The method relies on the pathwise conditioning GP posterior formulation and random Fourier features (RFF) approximation. The key idea is to express the GP posterior quantities as solutions to quadratic optimization problems whose objective is a sum over data points and hence SGD can be applied. \n\nThe paper shows that SGD GP produce accurate predictions. However, SGD GP can converge slowly or converge to sub-optimum. However, non-convergence behaviors of SGD only occur in region closed to the data boundary. SGD GP performs comparably to SVGP and conjugate gradients (CG) in most settings, and can outperform them in large-scale systems or ill-conditioned problems.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The paper is overall well-written and easy to follow. \n\n- The proposed method is novel and sound. It is shown to provide better predictive performance given the same inference time compared to SVGP and CG. What I found is most compelling is that SGD-GP seems to be a stronger alternative in large-scale or ill-conditioned systems.\n\n- I also find the spectral analysis of SGD convergence of three different regions to be very insightful.'}, 'weaknesses': {'value': '- The major weakness is that the setting the paper considers is quite limited, which is the posterior inference given fixed learned hyperparameter. I would appreciate if the authors can elaborate on the significance of the setting and why the proposed methodology is in particular important. For example, how often would the ill-conditioned systems arise in practice and how common is the case that hyperparameters are known in advance. It also seems like the method is applied to a isotropic Gaussian likelihood (see the question section below). \n\n- The fact that SGD converges slowly in extrapolation region is a bit concerning. Especially in applications like Bayesian optimization, this is the region of high interests for exploration. Or in settings where there are distribution shifts, the under-calibrated uncertainty in this region can be an issue. In general, I found the ""benign non-convergence"" argument in the extrapolation region not convincing. Would appreciate if the authors can elaborate on this issue, and if if there is any potential way to alleviate the non-convergence property? \n\n- The SGD convergence analysis is insightful. But I would appreciate a more formal mathematical characterization of three regions.'}, 'questions': {'value': '- Related to the first point above, can the method be adapted for broader settings where the hyperparameters need to be learned, or the likelihood is not Gaussian? If not, what is the limiting factor there?\n\n- Regarding the experiment evaluation, sec 4.1, is the predictive RMSE and NLL good metrics for evaluation? If I understand it correctly, SGD and CG are based on the same set of learned hyperpararmeters (and SVGP is based on a separately learned variational model). The core goal of the comparison is whether SGD recovers more faithful inference approximation compared to CG as a baseline. So I thought the valuable metric should be a distance against the ""exact"" inference result (e.g. CG with max. number of iterations and with high numeric precision). So I am not sure how to interpret Table 1. \n\n- In Fig 3 and Fig 5, do you have a sense why CG errors first go up and then go down? In Fig 5 last panel (houseelectric) would you expect CG error to match SGD performance eventually if running for more time? In both figures, I think it would be helpful to provide an exact baseline (e.g. CG ran to reach tolerance like1e-3). \n\nMinor comments. \n\n- A few notations and figures are not very clear. E.g. Fig 4. top left panel, indicate the size of error bands (blue shaded area) and dotted black line; top right corner, indicate the black dots (observations). In Proposition 1, define G-sub-gaussian.'}, 'limitations': {'value': ""The limitation discussion is missing. I don't think the paper would have negative societal impact. My main concern on technical limitaiton is weakness point 1.""}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper presents a novel approach for sampling from GP posteriors based on SGD, which bypasses the need to solve the typical linear system of equations that is prevalent in both the exact variant (cubic in the number of query points) or the pathwise approximation (cubic in the number of data points). The SGD approximation is provided for both exact GPs and for inducing point approximations. Moreover, the approximation quality is investigated for three regions of varying data density, and explanations for the (occasionally poor) approximation quality are given.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- __Novel, interesting idea:__ The use of SGD for atypical objectives is interesting, and the analysis of the approach is detailed from both a theoretical and empirical perspective.\n\n- __Clearly addressed limitations:__ The SGD approach is _not_ a silver bullet, and the authors make this clear by highlighting the approximation quality in data-dense regions (good), faraway regions (good), and interpolation regions (not as good). \n\n- __Informative, well-designed figures:__ The various figures are not only visually appealing, but provide . Figure 1 and 4 in particular highlight the strengths and shortcomings of the method nicely, and seamlessly add intuition as to why that is. \n\n- __Diverse Experiments:__ Experiments from both large-scale GP regression and BO are included, which demonstrates that the method is applicable and potent in both domains.\n\n- __Clear writing:__ The paper is consistently well-formulated, pedagogical and as far as I could tell, correct. Moreover, I beieve that there has been substantial effort to provide the reader with additional intuition for why the approach is effective.'}, 'weaknesses': {'value': 'I struggle to find weaknesses with the paper, but remain unconvinced on its potential impact due to the relatively small niche (sampling for GPs in large data regime) that is addressed. However, I am not overly confident in this assessment, and invite the authors to challenge my opinion on this topic. For example, do the authors see opportunities for impactful follow-up work which spans other areas of ML?'}, 'questions': {'value': '- __Comparison to Pathwise Sampling:__ Does the proposed method hold any advantages to pathwise sampling in a low-to-moderate data regime in terms of accuracy or complexity? At which point (in #data points) does SGD start becoming beneficial?\n- __Computing the predicitve uncertainty:__ Perhaps a trivial question, but how is the predicitve uncertainty computed when one can only access the posterior mean and samples from the posterior (and not the posterior variance) in Section 4.1?'}, 'limitations': {'value': 'Limitations are adequately addressed.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'I thank the authors for supplying the additional experiments and making the comparisons. It appears the technique is a novel and competitive method that can perform very well even for difficult datasets in the large-scale regime. \n\nBelow is the initial review, unchanged.\n-------------------------------------------------------------------\n\nThe authors propose to sample from the posterior of a GP via optimisation using SGD. The authors rephrase sampling as a quadratic optimisation problem that allows an efficient approximation of the gradient using random kernel features. Then, SGD is used to find the solution. Theoretical derivations show tht the proposed algorithm gives good variance estimates in densely sampled areas as well as areas far outside the sampled regions. Further, the algorithm performs better than CG and SVGP in certain settings.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The article provides a reltive complete package with an understandable derivation, good theoretical results and experimental evaluations.\n\nThe observations of the good performance of SGD in densely sampled regions is very interesting.'}, 'weaknesses': {'value': 'The article omits subset of data (SoD) methods completely, both in the related work and the experimental section. [1] introduces them as as category, [2] establish them empirically as competitive method in sampling and [3] investigates the size of the subsampling dataset.\n\n[1] A Unifying View of Sparse Approximate Gaussian Process Regression, Qui~nonero-Candela and Rasmussen (2005) \n\n[2] A Framework for Evaluating Approximation Methods for Gaussian Process Regression, Chalupka and Murray and Williams (2013)\n\n[3] Adaptive Cholesky Gaussian Processes, Bartels et al. (2023)\n\nSubsampling methods perform similarly to the proposed method as they work well in densely sampled regions and also well in regions far away from the data distributions with only region of large error in the low sampled tails. This makes comparison mandatory.\n\nThe compairosn with SVGP is unfair due to the small number of inducing points (1024) and a bad optimisation algorithm for them (ADAM). It seems like the authors did not tune the competing methods well, making the resulting baselines weak. \n\nTheoretically, the authors omit in their complexity class evaluations the number of SGD steps, which might become very large. \nFurther, the authors omit the standard work on GP, while refering to standard notation introduced by it:\n\n[4] Gaussian Processes for Machine Learning, Carl Edward Rasmussen and Christopher K. I. Williams (2006)'}, 'questions': {'value': 'Question: Can you provide plots including a parameter study of SVGP including a stronger optimizer?\n\nSuggestion: I would suggest to introduce SoP method in the related work, but also compare them to the proposed method in the experimental section. I would suggest to compare them empirically to the proposed method by given them a dataset size with computation budget the same as the proposed method to allow a fair comparison on wallclock time. '}, 'limitations': {'value': '-'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent'}, 'authors': {'value': ['Jihao Andreas Lin', 'Javier Antoran', 'Shreyas Padhy', 'David Janz', 'José Miguel Hernández-Lobato', 'Alexander Terenin']}, 'authorids': {'value': ['~Jihao_Andreas_Lin1', '~Javier_Antoran1', '~Shreyas_Padhy1', '~David_Janz1', '~José_Miguel_Hernández-Lobato1', '~Alexander_Terenin1']}, 'keywords': {'value': ['Gaussian processes', 'scalable learning', 'posterior sampling', 'Bayesian optimization']}, 'abstract': {'value': 'Gaussian processes are a powerful framework for quantifying uncertainty and for sequential decision-making but are limited by the requirement of solving linear systems. In general, this has a cubic cost in dataset size and is sensitive to conditioning. We explore stochastic gradient algorithms as a computationally efficient method of approximately solving these linear systems: we develop low-variance optimization objectives for sampling from the posterior and extend these to inducing points. Counterintuitively, stochastic gradient descent often produces accurate predictions, even in cases where it does not converge quickly to the optimum. We explain this through a spectral characterization of the implicit bias from non-convergence. We show that stochastic gradient descent produces predictive distributions close to the true posterior both in regions with sufficient data coverage, and in regions sufficiently far away from the data. Experimentally, stochastic gradient descent achieves state-of-the-art performance on sufficiently large-scale or ill-conditioned regression tasks. Its uncertainty estimates match the performance of significantly more expensive baselines on a large-scale Bayesian~optimization~task.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/b0faac4381126bb80e64c7cbfa8abef2bc4696ae.pdf'}, 'TLDR': {'value': 'We sample from GP posteriors using SGD and develop a spectral characterization for why it works, even in cases of non-convergence.'}, '_bibtex': {'value': ""@inproceedings{\nlin2023sampling,\ntitle={Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent},\nauthor={Jihao Andreas Lin and Javier Antoran and Shreyas Padhy and David Janz and Jos{\\'e} Miguel Hern{\\'a}ndez-Lobato and Alexander Terenin},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=Sf9goJtTCE}\n}""}, 'paperhash': {'value': 'lin|sampling_from_gaussian_process_posteriors_using_stochastic_gradient_descent'}}]"
"['Rylan Schaeffer', 'Brando Miranda', 'Sanmi Koyejo']",NeurIPS,Are Emergent Abilities of Large Language Models a Mirage_,https://neurips.cc/virtual/2023/oral/73863,2023," Recent work claims that large language models display \textit{emergent abilities}, abilities not present in smaller-scale models that are present in larger-scale models.What makes emergent abilities intriguing is two-fold: their \textit{sharpness}, transitioning seemingly instantaneously from not present to present, and their \textit{unpredictability}, appearing at seemingly unforeseeable model scales.Here, we present an alternative explanation for emergent abilities: that for a particular task and model family, when analyzing fixed model outputs, emergent abilities appear due the researcher’s choice of metric rather than due to fundamental changes in model behavior with scale. Specifically, nonlinear or discontinuous metrics produce apparent emergent abilities, whereas linear or continuous metrics produce smooth, continuous, predictable changes in model performance.We present our alternative explanation in a simple mathematical model, then test it in three complementary ways: we (1) make, test and confirm three predictions on the effect of metric choice using the InstructGPT/GPT-3 family on tasks with claimed emergent abilities, (2) make, test and confirm two predictions about metric choices in a meta-analysis of emergent abilities on BIG-Bench; and (3) show how to choose metrics to produce never-before-seen seemingly emergent abilities in multiple vision tasks across diverse deep networks.Via all three analyses, we provide evidence that alleged emergent abilities evaporate with different metrics or with better statistics, and may not be a fundamental property of scaling AI models.",Oral 6A LLMs,https://openreview.net/pdf?id=ITw9edRDlD,https://openreview.net/forum?id=ITw9edRDlD,ITw9edRDlD,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This work provides a closer look at the nature of increased capabilities of machine learning models at scale, arguing that prior evidence for unpredictable and qualitative leaps in capability is confounded by the metrics employed to measure such capabilities. This has broad implications on how we describe and evaluate the capabilities of model.\n\nReviewers found the support provided for this claim to be thorough and appreciated the additional nuance resulting from the discussion period. The critical perspective provided by this work is timely and will be of broad interest at the conference, and also just provides an important lesson.'}}, {'comment': {'value': ""Thanks for the response!\n\n> We are hesitant to comment on BLEU because we don't think many authors are claiming emergent abilities under it.\n\nI understand that from [33] only IPA transliterate was featured as emergent, but I don't think it's fair to say that authors aren't considering emergent abilities under it, considering that it is featured in their main figure.\n\n> We indeed find high emergent scores under BLEU. However, despite this, the authors who studied BIG-Bench (Srivastava et al. 2022) do not claim that these are emergent abilities. We do not know why.\n\nI think the fact that you find especially notable emergent scores under BLEU (and because it is only one of five metrics that you observe high scores on) warrants further investigation into the metric, even if prior work does not properly consider the metric. If you're looking for an experiment, one possible idea would be to reproduce something similar to Figure 9 (in A.4) but for the BLEU metric. If BLEU is a sharp metric, great. Even if it is the case that BLEU is not a sharp metric, I don't think this undermines your argument at all, as I understand your argument to be that the appearance of most *but not necessarily all* emergence arises from a particular choice of metric. Nonetheless, I do think that it's important to discuss BLEU in the paper to answer the immediate question that a reader might have when looking at Figure 5 and observing that the most notable metric (tasks with highest emergence scores) is BLEU, and not the other metrics that you do discuss. Considering how notable BLEU appears in Figure 5, I think it also might be worth including at least some discussion of this in the main paper, in addition to your proposed extension of the appendix.\n\nOverall, I think conditional on the added discussion of BLEU (regardless of whether BLEU is a sharp metric or not), I have been convinced that this is a solid paper, and so I will increase my score to a 7.""}}, {'title': {'value': 'Response to Reviewer ccWP'}, 'comment': {'value': '> Any chance you could summarize here the content of the Appendix section you are re-adding?\n\nOf course! A number of changes will be made. These include but are not limited to:\n\n1. In the main text, a new Limitations section\n2. In the Discussion section, a longer commentary on the relation of our work to alternative hypotheses\n3. In the Appendix, a new section ""Relationship between Emergent Abilities & Grokking""\n4. In the Appendix, a new subsection on BLEU as a metric\n\n> Also, regardless of which tasks have been previously claimed as emergent\n\nLet us clearly state that we are uncomfortable disregarding previous claims of emergence. Our paper is an investigation of previous claims, and we strongly do not want to invent & misattribute scientific claims to other researchers.\n\nRegarding BLEU, to the best of our knowledge, 3 out of 4 papers on emergent abilities didn\'t mention BLEU, and the 1 paper that does mention BLEU showed BLEU on 1 task (out of many) and did not emphasize the ability. We are hesitant to comment on BLEU because we don\'t think many authors are claiming emergent abilities under it.\n\n\n> Also, regardless of which tasks have been previously claimed as emergent, it appears that are many tasks that have a high emergence score with the BLEU metric and I was wondering if you could comment on that, as well.\n\nWe indeed find high emergent scores under BLEU. However, despite this, the authors who studied BIG-Bench (Srivastava et al. 2022) do not claim that these are emergent abilities. We do not know why. Srivastava & colleagues briefly discuss this in their main text, but defer discussion to ""Figure App.4"" where they switch from BLEU in the main text to ROUGE-L-Sum in Figure App.4\'s caption. This is why we included our Appendix A4 on ROUGE-L-Sum to demonstrate how it scales. **We will add another appendix A4 discussing how BLEU scales.**\n\nFigure 5\'s X axis (""Emergence Score"", called Breakthrough Score in Srivastava et al. 2022) is a rough proxy for emergent abilities. The authors who introduced the score clearly labeled it a heuristic metric. In our view, the Emergence Score should be viewed as ""This _might_ merit further investigation"" not ""These _are_ emergent abilities."" In our opinion, this Emergence Score is better thought of as a necessary but insufficient criterion.\n\nIf you have specific experiments to suggest regarding BLEU, please do let us know!\n\nLest the point be missed, **the key takeaway from Figure 5\'s left subfigure is that 34 out of 39 BIG-Bench metrics seem to display no possible signs of emergent abilities.**'}}, {'comment': {'value': 'Any chance you could summarize here the content of the Appendix section you are re-adding? Also, regardless of which tasks have been previously claimed as emergent, it appears that are many tasks that have a high emergence score with the BLEU metric and I was wondering if you could comment on that, as well. '}}, {'comment': {'value': ""Thank you for the clarifications and helping me to understand what I missed in my review! With these addressed, I'm happy to raise my score to an 8. Great work! ""}}, {'title': {'value': ""Response to Reviewer ccWP's Response""}, 'comment': {'value': ""> I did not mean to suggest that this paper does not have many valuable contributions! \n\nAh! We are so sorry - we misunderstood your tone. We apologize for the miscommunication. Thank you for clarifying!\n\n> For this reason, I do believe that the work in grokking is relevant to your work (at least this paper, possibly others).\n\nThank you for clarifying! We now better understand what you meant by progress measures, and what relationship you see. We agree that our perspective is similar to Nanda et al. 2023 and we will add an Appendix section relating emergent abilities with grokking, including appropriate citations to the grokking papers you referenced. We will also mention the Appendix section in our Discussion, but we do not foresee having space to discuss the relationship with grokking at length in our Discussion.\n\n> Yes, exactly, thank you for the further discussion.\n\nSounds good. We will discuss Caballero et al. 2023 and Michaud et al. 2023 at greater length in our Discussion.\n\n> My main concern was that in Figure 5, it appears there are many tasks that leverage the BLEU metric with a high emergence score, suggesting that there may be emergence with the BLEU metric. Since there was no discussion of this in the paper, I was wondering how these tasks fit into your argument.\n\nThat's a reasonable thought to ponder! To the best of our knowledge, despite our discovery that many BIG-Bench, tasks appear to score highly on the emergence metric under the BLEU metric, we've only seen one claimed BLEU emergent ability on a single task (IPA transliterate). We will explicitly state this in our paper and add our appendix. We will also clarify that the emergence score was introduced by Srivastava et al. 2022 as an approximate proxy for emergent abilities.\n\n> Overall, I was mostly concerned with the discussion of the BLEU metric. With some added discussion of the BLEU metric, I think that the authors would have addressed my comments and I would raise my score.\n\nWe will also add back in our Appendix section explaining the BLEU metric.\n\n\n**Please consider updating your score if you think our agreed changes merit it!** (FYI: NeurIPS this year doesn't permit uploading a revised manuscript during the review process)""}}, {'title': {'value': ""Response to Reviewer Cfbn's Comment""}, 'comment': {'value': ""Phew! We're so sorry for the dense earlier message and hope that it all made sense! A 6k character response is such a tight limit when a reviewer like yourself provides so much good feedback.\n\n>  I am glad to hear that we are in agreement on several points.\n\nIndeed! We agreed with you on almost all points. I think that being more upfront about our paper's limitations by adding an explicit Limitations section will be an important addition.\n\n> I continue to think that this is an important contribution, but also very hard to get comprehensive data on.\n\nAs a personal comment, an inability to obtain more comprehensive data has been one of the most disheartening aspects of working on this topic. We want to have a better scientific understanding of emergent abilities, but typically, models aren't public, nor are models' text outputs, and obtaining that data ourselves is slow and expensive.\n\n>  I'm saying that even if this is true, we should still expect to be surprised by future model capabilities.\n\nAgreed.\n\nOnce again, thank you so much for your comments & feedback earlier! It was quite obvious to us that you thought deeply about how our paper could be improved, and we very much value your perspective. We will update our manuscript accordingly.\n\n**Please consider updating your score if you think our agreed changes merit it!**  (FYI: NeurIPS this year doesn't permit uploading a revised manuscript during the review process)""}}, {'title': {'value': 'Response to rebuttal'}, 'comment': {'value': ""Thank you for the rebuttal. I am glad to hear that we are in agreement on several points. I continue to think that this is an important contribution, but also very hard to get comprehensive data on. While additional data would always help, I think the existing data is enough for the current paper and it's more important to be upfront about the limitations of the evidence as it stands. Therefore I am pleased to hear that a limitations section will be added.\n\nOn the question of accuracy transitioning from ~1e-12 to ~1, I agree with the authors here. I was being a bit hyperbolic, but I think my point still stands: it's not so unusual for a 10x increase in model size (i.e. 100x increase in training compute, by [1]) to improve accuracy by ~30x (see for example 2-Integer 2-Digit Multiplication in the paper). Since compute spending is growing rapidly (see for example [2], which suggests a 10-month doubling time), that means that an ability could go from essentially undetectable (say 1e-3 accuracy, at which level it's hard to tell if it's a fluke) to useful performance (say 1e-1) over the course of a few years, or perhaps faster in some cases. (This isn't really a technical disagreement, it's more a question of how the result that log accuracy scales smoothly should be framed: I'm saying that even if this is true, we should still expect to be surprised by future model capabilities.)\n\n[1] https://arxiv.org/abs/2203.15556\n\n[2] https://epochai.org/blog/compute-trends""}}, {'comment': {'value': 'Thanks for the response.\n\n> However, respectfully, we feel the reviewer undervalues our paper’s novelty & contributions. \n\nI did not mean to suggest that this paper does not have many valuable contributions! \n\nI wanted only to point out that the idea that the fact that emergence-looking behavior can arise from a choice of metric is not new. In particular, in addition to the hypothesis of Srivastava et al. 2022, the work by Nanda et al. 2023 suggests that grokking arises similarly from the choice of metric, and that under a different metric (e.g., a progress measure, as they call it), the discontinuous jump in performance disappears. For this reason, I do believe that the work in grokking is relevant to your work (at least this paper, possibly others).\n\n> Are you requesting that we discuss the differences in greater depth? We would be happy to expound here, as well as in the paper.\n\nYes, exactly, thank you for the further discussion.\n\n> We would be happy to put the appendix subsection back in if requested. The answer is that BLEU is also a sharp nonlinear metric.\n\nMy main concern was that in Figure 5, it appears there are many tasks that leverage the BLEU metric with a high emergence score, suggesting that there may be emergence with the BLEU metric. Since there was no discussion of this in the paper, I was wondering how these tasks fit into your argument.\n\n\nOverall, I was mostly concerned with the discussion of the BLEU metric. With some added discussion of the BLEU metric, I think that the authors would have addressed my comments and I would raise my score.'}}, {'title': {'value': 'Acknowledgment'}, 'comment': {'value': "" I've read the rebuttal response — thanks for answering my questions!""}}, {'rebuttal': {'value': 'Thanks for time & feedback! You made clear effort to think critically about how to improve our paper! 6k space limited -> dense response; try our best.\n\n> Why few-shot int arithmetic\n\n1. Few-shot int arithmetic featured prominently in multiple prev papers L102-104.\n2. To make point about sufficient resolution, needed to be able to generate more samples; generating samples easier for arithmetic than other tasks, e.g., Persian QA. We’ll add.\n\n> Better to study all tasks from Fig 1\n\nAgreed but not fully feasible: 4/5 models private (LaMDA, Gopher, Chinchilla, PaLM). PaLM2 recently became queryable, but to best of knowledge, PaLM 1 spanning several scales is not. Before submitting, tried obtaining networks’ outputs via priv comms with authors but unsuccessful. Thanks to your comment, we realized we can study GPT-3 fam on IPA Transliterate & Grounded Mappings. Aren’t sure about MMLU since MMLU=57 tasks; may be beyond our budget. How important would collect+analyze IPA Transliterate & Grounded Mappings be?\n\n\n> main direct evidence [...] is somewhat inconclusive\n\nOur work follows ethos: all models are wrong, but some are useful. Role of mathematical model: explain quantitatively what scaling behavior we should qualitatively expect in LLMs & why. As stated, math model relies on approximations (per-token error rates are approximately constant and independent) that are only ~true. Despite, math model usefully predicts effects of: varying length of target string, changing metric, & sampling additional data to incr resolution.\n\n> [BIG-Bench] logical_args seems like there may still be unpredictable jump\n\n> And on the other tasks, emergence is not that sudden even with original metric.\n\nBIG-Bench’s data sometimes confusing. Example: Swahili English Proverbs (red): Multiple Choice Grade improved for largest model, but Brier Score regressed; inconsistent? Data from private model (LaMDA) -> unable to investigate. Unsatisfying answer is claims of emergent abilities involve subjective judgment.\n\n> The induced emergence experiments are also helpful, but [...] this evidence is more indirect.\n\nAgreed. Point: show that metric choices can make well-known networks appear to possess emergent abilities on commonplace tasks.\n\n> There is no guarantee that because validation loss scales smoothly, cross-entropy loss on a specific sub-distribution must also scale smoothly [...] Therefore there is still an important theoretical possibility of sudden emergence\n\nAgree. L218: “We emphasize that nothing in this paper should be interpreted as claiming that large language models _cannot_ display emergent abilities.” **Will add Limitations section** including this. Interesting hypotheses exist & are cited e.g., Michaud et al. 2023.\n\n> It may not be possible to construct a linear metric, e.g., program synthesis\n\nIndeed, linear metric not always possible, but to clarify, we aren’t advocating linear metrics, nor criticizing any metrics. Main point: **if** goal to predict scaling behavior of model family, chosen metric may have effect, so take that effect into account so you aren’t surprised. Corollary: to make accurate scaling forecasts, continuous & linear metrics are probably more advantageous, but if discontinuous & nonlinear metrics preferred, then may need lots of data to have sufficient resolution to accurately measure performance. Choose whichever metric is best for your setting - just make sure to think through consequences of metric choice!\n\nLinear metrics might be more broadly applicable; Program Synthesis: count number of unit tests passed e.g. HackerRank coding interviews\n\n> [log accuracy] is not necessarily feasible.\n\nNot claiming log accuracy necessarily feasible. Rather, claim: if one wishes to use a particular metric when forecasting scaling behavior, then one should consider whether they possess sufficient data to have sufficient resolution to accurately estimate performance under their metric. In some cases, this might be feasible, but in other cases, this might not be. Will clarify.\n\n> Therefore there may be sudden emergence for all practical purposes.\n\nThis involves a hidden step that we think is unlikely. We are skeptical that accuracy could transition from ~1e-12 to ~1 without detectably passing through intermediate orders of magnitude at intermediate model scales. While not impossible, to best of knowledge, such an abrupt transition has not been observed.\n\n> the paper should take more care not to overstate its claims and acknowledge the limitations\n\nAgreed. Will add Limitations sec & replace strong claims e.g., “metric choice is likely wholly responsible for emergent abilities” with measured statements e.g., “metric choice might possibly be responsible for some claimed emergent abilities.”\n\n> p. 4 line 78\n\nDelta = prob simplex. Will clarify.\n\n> p. 9 line 209 - doesn’t contradict broken neural scaling laws\n\nDon’t contradict, but dissimilar. BNSL attributes emergent abilities to changepoint in scaling behavior -> $\\geq$2 scaling law vs  our paper says _even with 1 scaling law_, emergent abilities might be due to the metric.\n\n> suggest changing the title of the paper\n\n> clearer to talk about ""sudden"" & ""gradual emergence""\n\nTerminology tricky & attempts resulted in dissatisfied colleagues. Difficulty with “sudden” vs “gradual emergence” is emergence has rich history in physics, typically at phase transitions; “gradual emergence” could be viewed as oxymoron. We have also been told not to use “phase transition;” one colleague: “Unless you can write down a partition function and show that it\'s non-analytic, I strongly suggest not doing this.” Also tried “Emergent Abilities” in quotation marks to make clear referencing prior terminology; quotation marks interpreted as mocking prior work. Have more stories. After trying repeatedly, we feel current terminology is best available compromise. Tempering our claims & adding Limitations sec will help. Happy to hear additional suggestions.\n\nOther sugg changes will be made.'}}, {'rebuttal': {'value': 'We thank Reviewer ccWP for their time and feedback! Replying to each comment, suggestion and/or question in turn:\n\n> As the authors point out in their related work, the idea that emergence appears due to the metric is not novel, and was proposed by [1], so the novelty of this paper lies in the quantitative evaluation of this hypothesis\n\nSrivastava et al. 2022 indeed questioned whether emergent abilities of LLMs may be due to the metric. However, respectfully, we feel the reviewer undervalues our paper’s novelty & contributions. Our work converts a few sentences into precise conceptual understanding, which in turn generates empirically testable predictions in LLMs, suggests new meta-analyses of previous publications’ results, and inspires new experiments that we implement. Specifically: Firstly, we converted Srivastava et al. 2022’s question into a novel simple mathematical model that is both intuitive and quantitatively testable. Secondly, we used our mathematical model to generate empirically testable predictions and then tested those predictions, confirming them. Thirdly, we proposed and executed a novel meta-analysis of BIG-Bench to reveal additional supporting evidence. Fourthly, we identified a class of metrics that Srivastava et al. did not discuss (i.e., discontinuous metrics such as Multiple Choice Grade). Lastly, we showed how metric choice can induce seemingly emergent abilities in a different modality that had never before been shown, providing an explanation for why emergent abilities have (to the best of our knowledge) not been observed in vision. We also mention additional causes for skepticism, such as previous papers’ possible failure to control for multiple comparisons.\n\n> There has been work on examining emergence and progress measures in similar contexts, e.g. grokking, which should be addressed in the related work [2–5]\n\nWe see several significant differences between grokking and emergent abilities of LLMs:\n1. Grokking is primarily studied within a single model, whereas emergent abilities are studied within a model family\n2. Grokking occurs with increasing gradient steps, whereas emergent abilities occur with increasing model scale typically measured in parameters or effective parameters (although more recently compute).\n3. Grokking explicitly studies a discrepancy between the model’s train and test behavior, whereas emergent abilities (to the best of our knowledge) do not present separate train & test curves.\n4. Grokking is primarily studied on toy tasks in small networks, whereas emergent abilities are studied on benchmark tasks in large language models.\n\nWhile we personally appreciate the grokking literature, and while we may be mistaken, we respectfully feel that grokking is too distant from this work. If requested, we would be happy to add a comparison with grokking to our Appendix.\n\n> There was no discussion of the relationship to alternative hypotheses. The authors mention in the related work multiple papers that suggest that abilities do, in fact, emerge with scale, but the authors should explain how their hypothesis relates.\n\nRespectfully, we do discuss alternative hypotheses and how they relate to our paper on Lines 209-212: “Caballero et al. [4] explain emergence by assuming a piece-wise power law functional form; under this view, emergent abilities are real, caused by a change in the governing power law. In contrast, our work suggests that emergent abilities are induced by the researcher, even under a single power law. Michaud et al. [25] posit that emergent abilities may be real under strong data assumptions.”\n\nAre you requesting that we discuss the differences in greater depth? We would be happy to expound here, as well as in the paper.\n\nCaballero et al. 2023 contrasts with our work in that their hypothesized explanation for emergent abilities is that the governing power law changes at specific break points. Our explanation for emergent abilities is that the researcher’s analyses create the seemingly emergent abilities. Both explanations could be true: some emergent abilities might genuinely be abruptly appearing, whereas some emergent abilities might be attributable to the metric. \n\nMichaud et al. [25] posits that language modeling data might be comprised of discrete subtasks (“quanta”) that networks learn. Larger networks have greater capacity, and thus are more capable of learning more of these quanta. If some downstream task requires a network to learn some combination of quanta, then larger networks are more likely to have all the requisite capabilities and thus are capable of performing this downstream task. We think that this is a very interesting hypothesis. Whether language modeling data can or should be understood from this quantization perspective, and whether these quanta indeed are the origin of emergent abilities, are really exciting questions that we think merit more study! \n\n> There was no discussion of the BLEU score metric, even though there are many tasks that have a very high score with this metric\n\nPrevious papers have not made many claims about emergent abilities under BLEU score; to the best of our knowledge, we know of only one task (IPA transliterate) on which at least one model family exhibits emergent abilities. In contrast, the hand-annotated emergent abilities by https://www.jasonwei.net/blog/emergence almost all seem to occur under other metrics (Multiple Choice Grade, Accuracy, Exact Match). Due to a dearth of claimed emergent abilities under BLEU, we chose to focus on the more prevalent metrics.\n\nThat said, we actually had an appendix subsection on BLEU score that we cut due to the relative rareness of BLEU and due to the subsection’s length (explaining BLEU requires more work than Exact Match). We would be happy to put the appendix subsection back in if requested. The answer is that BLEU is also a sharp nonlinear metric. \n\n> Minor: a lot of the figures are small and therefore hard to read\n\nWe will fix this. Thank you!'}}, {'rebuttal': {'value': 'We thank Reviewer eK8N for their time and feedback! Replying to each comment, suggestion and/or question in turn:\n\n\n> The authors cite the following definition early on -- emergent abilities are ""abilities that are not present in smaller-scale models but are present in large-scale models; thus they cannot be predicted by simply extrapolating the performance improvements on smaller-scale models,” which itself depends on an evaluation metric. Since the definition depends on an evaluation metric, why does changing the metric make emergent abilities a mirage? Shouldn\'t emergent abilities only hold, then, with respect to a metric?\n\n\nThis is a good question! Our view is that the answer is no. An ability is a talent, skill, or proficiency in a particular area, whereas a metric is one way of quantitatively measuring that ability. Many different metrics can be used for measuring a particular ability. For example, if we want to quantify how good someone is at playing basketball in the NBA, there are many metrics we might turn to: number of won championships, true shooting percentage, effective field goal percentage, player efficiency rating, etc.\n\n\nTo explain another way, emergent abilities are discussed as profound changes of a model family with scale. But if indeed fundamental changes are occurring in the model family, then the changes should appear under many metrics. What we show is that this doesn’t seem to appear in the claimed emergent abilities we analyze.\n\n\n> I may have misunderstood parts of the argument, but I am not entirely convinced that emergent abilities might not be real, when it is clear that they are real with respect to discrete metrics (that often have practical interpretations).\n\n\nRespectfully, “real” and “not real” is terminology we try to avoid. Rather, the claim of “emergent abilities” is that as models get larger, their behavior changes sharply and unpredictably. Our paper argues that previously observed sharp and unpredictable changes might be better attributed to the metric than to fundamental changes in the model family with scale. We use the term “mirage” because, from a distance, models appear to be changing abruptly, but upon closer investigation, the abrupt changes can disappear and become more predictable. \n\n\n> However, it still seems that these properties are real with respect to discrete metrics, and these discrete metrics are often desirable.\n\n\nWe agree; indeed, we show this in our Figure 3 Row 1! Our paper is not saying previous papers’ experimental results are wrong or that the metrics they use should not be used. Rather, our point is that previous papers might have been surprised by scaling behavior because of the metrics they used or because of limited data. In addition, we show that even for such discrete metrics, the jump is an expected behavior and provide evidence against labeling this as ""emergence,"" i.e., an unpredictable jump. Furthermore, by changing the metric or increasing the resolution using more data, they might have discovered smoother, more predictable trends with scale.\n\n\n> Or does this render prior analyses incomplete, since they do not consider metrics in which performance does smoothly change?\n\n\nThis statement is closer to what we have in mind, but we think our paper goes beyond merely saying previous papers are “incomplete”. We think a conceptual blind spot existed in multiple papers that our paper identified. To explain, “Emergent abilities” doesn’t mean that bigger models perform better than smaller models. Rather, “emergent abilities” means that bigger models _suddenly and unexpectedly_ perform better than smaller models. To our knowledge, previous papers did not try changing metrics or collecting more data to increase resolution. Our work qualitatively predicts the effects (and interaction!) that metric and sample size should have, then confirms those predictions.\n\n\n> Does this make the choice of metric bad, and emergence a mirage as a result?\n\n> Why are smooth evaluation metrics necessarily desirable if they are sometimes a relaxation of the real objective, which may actually be discrete (e.g. the 0-1 loss)?\n\n\nThank you for giving us a chance to clarify! We are not criticizing any metric, nor recommending one metric over another metric. Our main takeaway is that *if* you want to be able to predict the scaling behavior of a model family, the metric you choose may have an effect on your results, and so you should take into account the effect your chosen metric will have so you aren’t surprised. A corollary is that if you want to make accurate scaling forecasts, continuous & linear metrics might be more advantageous, but if you do want to use discontinuous or nonlinear metrics (which is totally fine!), then you may need lots of data to have sufficient resolution to accurately estimate model performance under your chosen metric. You should of course choose whichever metric is best suited for your setting - just make sure to think through what effects your metric choice will have! We will make these points more clearly in our Discussion. Hopefully that helps!\n\n\n> NOTE: please switch to the NeurIPS 2023 template, I noticed that you are using the 2022 version of the template.\n\nGreat catch - thank you for letting us know! We will fix this!'}}, {'rebuttal': {'value': 'We thank Reviewer GXCv for their time and feedback, and we’re overjoyed to hear you write that the paper was a pleasure to read! Replying to each comment, suggestion and/or question in turn:\n\n> l227: Not sure what is meant by ""multiple controls"" - is the implication that the community should have more aggregate / multi-metric benchmarks like BIG-Bench?\n\nTo confirm, the sentence you’re referring to is “In this particular setting, emergent abilities claims are possibly infected by a failure to control for *multiple comparisons*”? Assuming the answer is yes, thank you for giving us a chance to clarify! Here, “multiple comparisons” doesn’t refer to aggregate (sometimes called holistic) evaluation like BIG-Bench or HELM.\n\n\nRather, “multiple comparisons” refers to a phenomenon where someone can draw an incorrect conclusion after considering many attempts because they forget to normalize by the number of attempts. The point is that if one runs many tests, the probability of at least one false positive increases. XKCD #882 explains this through a parable of jelly beans causing acne.\n\nHere, in the context of emergent abilities, the risk is that if one looks at the scaling behavior of 10^6 task-model family-metric triplets, one probably should expect to find at least a few seemingly unpredictable changes due to random chance alone. The solution to multiple comparisons (oftentimes referred to as “controlling for multiple comparisons”) is to raise one’s threshold for declaring a discovery. For instance, we might say, “Because we’re looking at 10^6 task-model family-metric triplets, in order for us to be confident that emergent abilities are a phenomenon (and not just due to random chance), we need to see emergent abilities on at least 1% of the tests.” The statistical hypothesis testing community has ways of making this precise and statistically justified; a good starting point might be the [family-wise error rate](https://en.wikipedia.org/wiki/Family-wise_error_rate) page. Hopefully, this helps clarify!\n\n> comment: I found myself wanting to compare Fig 4 side-by-side with Fig 3 to understand the change from additional test data, but it was difficult to do so (especially with the diff y-axis scaling).\n\nVery understandable! We need the y-axes to have different scaling to make our point that by changing the y-axis and by using more data to increase the resolution, the seemingly zero-accuracy values are actually non-zero accuracies. Would you recommend visualizing the effect of sample size in a different way? For instance, we could show estimation error at different sample sizes by subsampling the larger dataset at different subsample sizes. We have these plots and could submit them as part of the 1 page PDF addendum.\n'}}, {'summary': {'value': 'The paper shows that the apparent suddenness with which capabilities of language models seem to emerge with scale may be an artifact of the metrics by which they are measured. Theoretically, emergence should be more gradual if the metric scales linearly with log loss on some test set. Three sources of empirical evidence are used to support this claim. First, the authors study the scaling of the GPT-3 family on arithmetic tasks and show directly that emergence is smoother when a linear metric is used. Second, they conduct a meta-analysis of BIG-Bench, and show that gradual emergence only occurs with non-linear metrics, and that the effect is reduced when switching to a linear metric. Third, they artificially induce sudden emergence by using non-linear metrics for autoencoders on CIFAR100 and for transformers on Omniglot.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The basic point made by the paper is an important one that has not been fully appreciated by researchers. It is something that everyone studying scaling laws should understand and incorporate into their future work.'}, 'weaknesses': {'value': 'I think there are notable weaknesses in the empirical evidence given to support the basic point of the paper, and insufficient acknowledgement of the limitations of the evidence and other possibilities that could still give rise to sudden emergence.\n\nOn the empirical evidence:\n- The main direct evidence that previous claims of sudden emergence are an artifact of the metric comes from studying those previous claims directly, which is done in Section 3. However, the evidence here is somewhat inconclusive: for example for 2-digit multiplication with target str len 4 (which is presumably most 2-digit multiplications?) the jumps from 350M->1.3B->6.7B are gradual while there is a much bigger jump from 6.7B->175B. Moreover, this bigger jump is not predicted by the theoretical model. So it seems like there is still some relatively sudden emergence (even though it is reduced by using the right metric).\n- The BIG-Bench analysis is helpful, but again on logical_args it seems like there may still be an unpredictable jump. And on the other tasks, the emergence is not that sudden even with the original metric.\n- The induced emergence experiments are also helpful, but they show that sudden emergence can be induced by using a non-linear metric, not that it is always induced by a using a non-linear metric. So this evidence is more indirect.\n- Overall I think the paper would have come to more correct (and probably more nuanced) conclusions if it had studied all of the tasks from Figure 1, where sudden emergence had previously been claimed, in detail, instead of studying just one of these tasks combined with other, weaker sources of evidence.\n- Nevertheless, for an initial exploration of the topic, I think combining multiple source of evidence, even if somewhat weak, is helpful, and it is reasonable to defer a more careful analysis to future work.\n\nOn other theoretical possibilities:\n- There is no guarantee that because validation loss scales smoothly, cross-entropy loss on a specific sub-distribution must also scale smoothly. This depends on how the model allocates capacity to that sub-distribution. Therefore there is still an important theoretical possibility of sudden emergence, even with a linear metric. Indeed, this may explain why the data did not match the theoretical model in Section 3.\n- In some cases, it may not be possible to construct a linear metric. For example, for program synthesis, whether the program passes the unit tests cannot be easily converted to something like edit distance or log loss.\n- It is argued that log accuracy can be used in this case. But this is not necessarily feasible. For example, if current models pass unit tests with probability 1 in a trillion, it is not feasible to measure this accurately enough to perform any useful extrapolation. Therefore there may be sudden emergence for all practical purposes.\n\nOverall, I thought that the evidence was strong enough to support a conclusion that sudden emergence is partially explained by the choice of metric, and that researchers should prefer metrics that scale linearly with log loss when available. I also think that this conclusion is itself enough for the paper to be an important contribution. But I think the paper should take more care not to overstate its claims and acknowledge the limitations of the evidence and, space permitting, other theoretical possibilities. In particular, claims like ""metric choice is likely wholly responsible for emergent abilities"" (p. 9 line 204) are not justified and should be removed or reworded.\n\nI am recommending acceptance of this paper because of the importance of the contribution, but I think that some effort should be made to revise the paper prior to acceptance. However, I am confident in the ability of the authors to do this.\n\nSome presentation points:\n- I think it would be clearer to talk about ""sudden emergence"" and ""gradual emergence"" rather than ""emergence"" and ""no emergence"", since ""emergence"" can also be interpreted as ""appearing despite not being explicitly trained for"". However, I understand that the current terminology is taken from the existing literature and the paper cannot be blamed for this.\n- I suggest changing the title of the paper, because the current title can be misinterpreted as asking whether the _abilities_ are mirages, rather than whether the emergence (or sudden emergence as I prefer to put it) is a mirage. Any researcher who reads the abstract should not be misled, but unfortunately provocative titles that can easily be misinterpreted can be picked up on by the media and end up misleading the public. However, I acknowledge that choosing titles is hard and no title is perfect.\n\nMore minor points:\n- p. 4 line 78 - I am not familiar with this Delta notation (or I have a vague recollection of it). It is clear from the context so probably fine, but consider alternative notation/clarifying the definition.\n- p. 5 line 115 - Why choose this task from among all the tasks in Figure 1, and why 2-shot / 4-digit? (Would be even nicer to include results on other tasks/other numbers of digits, but absent that, it would be good to clarify how you chose, to make it clear it was not cherry-picked.)\n- Figure 3: Target str len 1: how do you get a 1-digit answer from multiplying two 2-digit numbers? I assume you are counting things like ""01 * 01""? Maybe clarify.\n- Figure 3: I think it would be clearer to include titles at the top of each column saying ""Mathematical Model"", ""2-Integer 2-Digit Multiplication Task"", ""2-Integer 4-Digit Addition Task"", instead of putting this in the caption. That way people can easily see at a glance what each plot is showing, without having to dig into the caption.\n- Figure 4: Same comment.\n- Figure 5: It would be nicer to group the metrics based on their mathematical form. E.g. it is unclear what ""gender_bias_score"" is. This also might help spot if there are more examples with emergence that didn\'t have high emergence score.\n- Figure 5B is a bit redundant. Maybe just point out in figure 5A which of the 5 did not count as emergence. It\'s also a bit unclear why this didn\'t count despite the emergence score.\n- p. 9 line 209 - I don\'t think this work really contradicts broken neural scaling laws. Even if sudden emergence goes away when you change the metric, one might still be interested in forecasting the original metric.'}, 'questions': {'value': 'No questions other than those given above'}, 'limitations': {'value': 'No limitations other than those given above'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper shows that the widely-discussed phenomenon of ""emergent abilities"" in large language models is largely due to the choice of (discontinuous/nonlinear) metrics and underpowered analyses.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- Well-written paper studying an important/commonly discussed phenomenon\n- Comprehensive, well-designed, and convincing experiments + analysis\n'}, 'weaknesses': {'value': 'No major weaknesses - the paper was a pleasure to read!\n'}, 'questions': {'value': '- l227: Not sure what is meant by ""multiple controls"" - is the implication that the community should have more aggregate / multi-metric benchmarks like BIG-Bench?\n- comment: I found myself wanting to compare Fig 4 side-by-side with Fig 3 to understand the change from additional test data, but it was difficult to do so (especially with the diff y-axis scaling).'}, 'limitations': {'value': 'Yes'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper aims to debunk a possibly myth about the emergent properties of language models with regard to scale. The emergent behaviors are defined as abilities that are not demonstrated with smaller models, but emerge suddenly with an increase in the model capacity, and cannot be explained by smoothly extrapolating from the model capacity -- i.e., emergent abilities are sharp and unpredictable. The claim that the authors seek to validate is that emergent abilities are actually artifacts of the fact that the choice of evaluation metric, and that continuous metrics (instead of discrete) show smooth increases in performance with scale -- i.e., that ""emergent"" abilities are in fact smooth and predictable. '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'This paper has many strengths:\n- First off, it is well-written. \n- The paper is timely -- large language models have only become moreso in the center of attention in the past year with abundant claims surrounding emergent abilities. \n- The claim that discrete metrics are a source of so-called ""emergence"" of new abilities is reasonable and makes intuitive sense. \n- The empirical evaluation is thorough, with evaluations of GPT-3/InstructGPT models, a meta-analysis using BigBench, and using discrete metrics to artificially induce ""emergent behavior"" in existing vision models. '}, 'weaknesses': {'value': 'I may have misunderstood parts of the argument, but I am not entirely convinced that emergent abilities might not be real, when it is clear that they are real with respect to discrete metrics (that often have practical interpretations). The paper seems to question the basic premise of emergent abilities, i.e., whether or not they are real. The authors cite the following definition early on -- emergent abilities are ""abilities that are not present in smaller-scale models but are present in large-scale models; thus they cannot be predicted by simply extrapolating the performance improvements on smaller-scale models,” which itself depends on an evaluation metric. Since the definition depends on an evaluation metric, why does changing the metric make emergent abilities a mirage? Shouldn\'t emergent abilities only hold, then, with respect to a metric? \n\nPer my understanding of this work, it seems to me that incorrect conclusions have been drawn in prior work by *only* considering discrete evaluation metrics, which is not the full picture -- pointing this out is the main contribution of this paper, and this is an important point to make. However, it still seems that these properties are real with respect to discrete metrics, and these discrete metrics are often desirable. Does this make the choice of metric bad, and emergence a mirage as a result? Or does this render prior analyses incomplete, since they do not consider metrics in which performance **does** smoothly change? '}, 'questions': {'value': '- Why are smooth evaluation metrics necessarily desirable if they are sometimes a relaxation of the real objective, which may actually be discrete (e.g. the 0-1 loss)? \n- NOTE: please switch to the NeurIPS 2023 template, I noticed that you are using the 2022 version of the template. '}, 'limitations': {'value': 'The authors address this. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors argue that purported emergent abilities of language models are mostly explained by the use of specific metrics, including non-linear or discontinuous scoring, and evaporate when linear or continuous scoring metrics are applied. The authors (1) present a toy model to explain emergence, (2) demonstrate that most abilities previously reported as emergent no longer appear emergent under an alternative metric, and then synthetically cause the appearance of emergence in an image reconstruction task.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- Simply and clearly addresses the enigmatic phenomenon of emergence\n\n- Formalizes and quantitatively tests the hypothesis of [1] that emergence is due in part to metric\n\n- Compelling toy model to illustrate how emergence can appear with non-linear metric (accuracy) but vanishes with linear metric (token edit distance)\n\n- Convincingly demonstrates that emergence is (at least often) a result of the metric'}, 'weaknesses': {'value': '- As the authors point out in their related work, the idea that emergence appears due to the metric is not novel, and was proposed by [1], so the novelty of this paper lies in the quantitative evaluation of this hypothesis\n\n- There has been work on examining emergence and progress measures in similar contexts, e.g. grokking, which should be addressed in the related work [2–5]\n\n- There was no discussion of the relationship to alternative hypotheses. The authors mention in the related work multiple papers that suggest that abilities do, in fact, emerge with scale, but the authors should explain how their hypothesis relates\n\n- There was no discussion of the BLEU score metric, even though there are many tasks that have a very high score with this metric\n\n- Minor: a lot of the figures are small and therefore hard to read\n\n[1] Srivastava, Aarohi, et al. ""Beyond the imitation game: Quantifying and extrapolating the capabilities of language models."" arXiv preprint arXiv:2206.04615 (2022).\n\n[2] Power, Alethea, et al. ""Grokking: Generalization beyond overfitting on small algorithmic datasets."" arXiv preprint arXiv:2201.02177 (2022).\n\n[3] Liu, Ziming, Eric J. Michaud, and Max Tegmark. ""Omnigrok: Grokking beyond algorithmic data."" arXiv preprint arXiv:2210.01117 (2022).\n\n[4] Nanda, Neel, et al. ""Progress measures for grokking via mechanistic interpretability."" arXiv preprint arXiv:2301.05217 (2023).\n\n[5] Barak, Boaz, et al. ""Hidden progress in deep learning: Sgd learns parities near the computational limit."" Advances in Neural Information Processing Systems 35 (2022): 21750-21764.'}, 'questions': {'value': 'See weaknesses'}, 'limitations': {'value': 'The authors adequately address the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Are Emergent Abilities of Large Language Models a Mirage?'}, 'authors': {'value': ['Rylan Schaeffer', 'Brando Miranda', 'Sanmi Koyejo']}, 'authorids': {'value': ['~Rylan_Schaeffer2', '~Brando_Miranda1', '~Sanmi_Koyejo1']}, 'keywords': {'value': ['large language models', 'foundation models', 'natural language processing', 'language modeling', 'emergent abilities']}, 'TLDR': {'value': 'Some have argued that some improvements in model capabilities are unpredictable; we argue that many claimed emergent capabilities are predictable, either using better statistics or alternative metrics'}, 'abstract': {'value': 'Recent work claims that large language models display \\textit{emergent abilities}, abilities not present in smaller-scale models that are present in larger-scale models.\nWhat makes emergent abilities intriguing is two-fold: their \\textit{sharpness}, transitioning seemingly instantaneously from not present to present, and their \\textit{unpredictability}, appearing at seemingly unforeseeable model scales.\nHere, we present an alternative explanation for emergent abilities: that for a particular task and model family, when analyzing fixed model outputs, emergent abilities appear due the researcher’s choice of metric rather than due to fundamental changes in model behavior with scale. Specifically, nonlinear or discontinuous metrics produce apparent emergent abilities, whereas linear or continuous metrics produce smooth, continuous, predictable changes in model performance.\nWe present our alternative explanation in a simple mathematical model, then test it in three complementary ways: we (1) make, test and confirm three predictions on the effect of metric choice using the InstructGPT/GPT-3 family on tasks with claimed emergent abilities, (2) make, test and confirm two predictions about metric choices in a meta-analysis of emergent abilities on BIG-Bench; and (3) show how to choose metrics to produce never-before-seen seemingly emergent abilities in multiple vision tasks across diverse deep networks.\nVia all three analyses, we provide evidence that alleged emergent abilities evaporate with different metrics or with better statistics, and may not be a fundamental property of scaling AI models.'}, 'pdf': {'value': '/pdf/a1d4bae597f26697edc2580f69f44a6ce45a6c98.pdf'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'supplementary_material': {'value': '/attachment/3867bc492a264c38b861a89807bd05eb6d7c07da.pdf'}, '_bibtex': {'value': '@inproceedings{\nschaeffer2023are,\ntitle={Are Emergent Abilities of Large Language Models a Mirage?},\nauthor={Rylan Schaeffer and Brando Miranda and Sanmi Koyejo},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=ITw9edRDlD}\n}'}, 'paperhash': {'value': 'schaeffer|are_emergent_abilities_of_large_language_models_a_mirage'}}]"
"['Haotian Liu', 'Chunyuan Li', 'Qingyang Wu', 'Yong Jae Lee']",NeurIPS,Visual Instruction Tuning,https://neurips.cc/virtual/2023/oral/73817,2023," Instruction tuning large language models (LLMs) using machine-generated instruction-following data has been shown to improve zero-shot capabilities on new tasks, but the idea is less explored in the multimodal field. We present the first attempt to use language-only GPT-4 to generate multimodal language-image instruction-following data. By instruction tuning on such generated data, we introduce LLaVA: Large Language and Vision Assistant, an end-to-end trained large multimodal model that connects a vision encoder and an LLM for general-purpose visual and language understanding. To facilitate future research on visual instruction following, we construct two evaluation benchmarks with diverse and challenging application-oriented tasks. Our experiments show that LLaVA demonstrates impressive multimodal chat abilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and yields a 85.1% relative score compared with GPT-4 on a synthetic multimodal instruction-following dataset. When fine-tuned on Science QA, the synergy of LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make GPT-4 generated visual instruction tuning data, our model, and code publicly available.",Oral 5D Vision,https://openreview.net/pdf?id=w0H2xGHlkw,https://openreview.net/forum?id=w0H2xGHlkw,w0H2xGHlkw,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper introduces LLaVa, an multimodal large language model that visual instructionally fine-tuned.\xa0\xa0LLaVA is first pre-trained on image-text pairwise data to align the image encoder and a pre-trained LLM. In the second step, the authors fine-tune the model using ~150k visual instruction data automatically generated by GPT4. All code and data are all open sourced to the research community.\n\nThe reviewers comment out this paper is one of the first work of multimodal instruction tuning, pioneering on the direction of tuning a pre-trained LLM for a better cross-modal alignment and understanding.\xa0\xa0One major contribution is the 150k multimodal instruction tuning data. The idea of using GPT4 to generate instruction following data for multimodal is interesting and inspiring. The results are also strong and encouraging, indicating the approach of instruction tuning a LLM to accept multimodal information is a promising direction.\xa0Although one weakness, as reviewer A2dU pointed out,  is that the current dataset construction process is largely depend on the closed-source GPT4, and it still remains unclear how this can be fully reproduced using open sourced LLMs. The paper still deserves its merit to pioneering the approach and excellent experience to demonstrate the path is valid.\n\nThe AC carefully reads the submission, comments, and authors’ responses. The paper is also well written and structured well. Authors have been very engaged and answer all reviewers’ question well with reasonable thoughts and numbers. The AC generally agrees the reviewer’s comment and appreciates the fruitful discussions. The paper is an important step towards general purpose multimodal language model. The open sourced data and code will also benefit the community and motivate the research in this direction.\n\nTherefore, the AC recommends to accept this paper.'}}, {'comment': {'value': 'Thank you for answering my questions, I think discussion about the weaknesses of these systems is also very valuable. I continue to be very positive about this paper.'}}, {'comment': {'value': 'Dear reviewer, we would like to thank you for your insightful feedback. We hope that your questions are addressed with our rebuttal. Please let us know if there are any further questions that need clarification.'}}, {'comment': {'value': 'Dear reviewer, we would like to thank you for your insightful feedback. We hope that your questions are addressed with our rebuttal. Please let us know if there are any further questions that need clarification.'}}, {'comment': {'value': 'Dear reviewer, we would like to thank you for your insightful feedback. We hope that your concerns are addressed with our rebuttal. Please let us know if there are any further questions that need clarification.'}}, {'comment': {'value': 'We sincerely appreciate the reviewer\'s insightful comments and the increased rating.\n\nRegarding the missing citations, we would like to clarify that the paper is cited by those publications. We have consulted with the ACs, and they advised us not to include citations of these papers to maintain the anonymity of the review process. We will provide the exact references to the ACs and PCs. Once the reviewing process is concluded, we will post the citations here via an ""Official Comment"" for your reference and for the benefit of the community.'}}, {'title': {'value': 'Thank you for the detailed discussion'}, 'comment': {'value': 'I genuinely thank the authors for their discussion on more scientific and cost-efficient evaluation metrics for MLLMs. I believe such a revision of the paper will make the submission much stronger, and thus I have increased my rating. I also appreciate authors\' detailed response on all my other questions.\n\nThe above response seems to be missing a few references. For example:\n\n1 - *""Some recent works show a clever way to address this. Instead of directly evaluating with GPT-4, one can use ChatGPT to extract the answers, or key aspects that are required to solve the problem.""* -- What are the recent works? \n\n2 - *""A recent study to evaluate LMM shows that the agreement between GPT-4 score and human evaluation is quite consistent (4.2% absolute discrepancy).""* -- What is the recent study?'}}, {'title': {'value': 'Response to follow-up questions'}, 'comment': {'value': '**Q1. ""While prior works such as Vicuna [1] also uses GPT4 to score their responses in a text-only fashion, it is unclear how robust GPT4 is for multimodal reasoning while doing text-only evaluation.""**\n\nBelow, we further clarify some aspects of GPT-4 evaluation, and the measures that we have taken to make sure that the experiments are conducted under a controlled setting.\n\n> It costs money to perform evaluation, which limits the custom test-set in this paper to 30 COCO and 24 in-the-wild images.\n\nWe agree. We have discussed some alternatives above.\n\n> GPT-4 performance is not stable across time\n\nWe find the comment relevant to the release of an iteration of GPT-4 on June 13. We do want to note that the gpt-4-0613 is released after the NeurIPS submission deadline, and we have taken two measures to make sure the experiments are conducted in a controlled setting.\n\nWe fixed the GPT-4 endpoint version to gpt-4-0314, after the release of gpt-4-0613. The same endpoint outputs consistent evaluations as verified in Table 5. This ensures that the evaluation is consistent before the retirement of the gpt-4-0314 endpoint (no earlier than July 5, 2024). We found that the relative rankings of different methods remain consistent as long as the same API is used (across gpt-3.5-turbo-0301, gpt-4-0314, gpt-4-0613, respectively).  We suggest that future researchers should fix the same API and evaluation pipeline throughout their experiments for all the methods, and report API endpoints in the paper.\n\n> As mentioned by authors in response to Q5, the textual annotation of an image may not capture all the details in an image.\n\nWe would like to clarify that when we construct the instructions in the LLaVA-Bench, we make sure that the instruction is answerable by referring to the provided image context.\n\nIn the context of Q5, we want to emphasize that, when the model is generating captions, without the access to the user instruction, it may not capture all details in the image that the user cares about. We believe the instruction-aware property can be of great value to future research.\n\n> While prior works such as Vicuna also use GPT4 to output numerical scores, it is hard to measure how accurate the numerical score is.\n\nMTBench [1] evaluates the agreement between GPT-4 scores and the human evaluation, and shows that there is a strong agreement between them. A recent study to evaluate LMM shows that the agreement between GPT-4 score and human evaluation is quite consistent (4.2% absolute discrepancy).\n\n**Q2.**\nAnswered with the discussion above.\n\n**Q3. Clarification of ""random-guess"" mode.**\n\nWe apologize for the confusion. In the official implementation (`models/run_gpt3.py#L70`), when the model does not output a valid answer, it randomly picks an answer. This improves the GPT-4’s accuracy when it refuses to answer. For fine-tuned LLaVA models, it follows the predefined format, so adding this does not further improve the model’s performance.\nWhen we evaluate zero-shot LLaVA and Vicuna, such cases also happen. We also treat them as incorrect and do not perform random choice.\n\n**Q4. How does the text-only GPT4 and zero-shot/fine-tuned Vicuna baseline utilize the image context? Do they use the image caption from the ScienceQA dataset?""**\n\nWe do not add image captions from the ScienceQA dataset.\nWe made this choice as we find that adding the image caption harms the Vicuna’s zero-shot performance (IMG 56.27 -> 52.95).\nWe hypothesize that it can be due to the fact that the image caption does not always provide accurate context (similar to observations in Fig. 17 and relevant discussions in ScienceQA paper). This can confuse the model and thus make incorrect predictions, after such irrelevant context is incorporated.\n\n[1] Zheng, et al. ""Judging LLM-as-a-judge with MT-Bench and Chatbot Arena.""'}}, {'title': {'value': 'Discussion: the scientific way to benchmark multimodal instruction-following models'}, 'comment': {'value': 'We thank the reviewer for the insightful comments, and we are happy to discuss the evaluation aspect for multimodal models.\n\nFor existing benchmarks, they usually focus on a single aspect. However, what is unique to the recent large multimodal models (LMM), like multimodal GPT-4, is that they can perform visual tasks in the wild that require integrated capabilities. For example, in Supplementary Table I, to correctly complete the user’s request, it requires the model to have: (1) OCR capability to understand the captions; (2) visual recognition capability to understand that it is a pan of nuggets that looks like a world map; (3) reasoning capability to combine the information together and answer why this can be interesting.\n\n**Having a model that excels in each single aspect, does not necessarily guarantee a capability to combine and reason about them in a single answer**. For example, BLIP-2 is one of the best models that ranks top across the board of academic benchmarks, while lacking the complex reasoning capabilities. Further evidence can be found in Table 5, where BLIP-2 is capable at answering short-form “conversational” questions and fails to tackle more complex tasks. Some recent evaluation benchmarks on LMMs also revealed similar results.\n\nAt the time of submission, such a benchmark was lacking. This motivates us to construct such a benchmark that requires the model to leverage different capabilities to correctly complete a user’s task. We tried to utilize the resources we have at the time of submission, to construct such a benchmark, with an aim to create scientific and controlled settings. **We do not cherry-pick test samples based on the performance of LLaVA. We do not tune any model/data design choices, based on any of the results we obtain on LLaVA-Bench-In-the-Wild, and we use that solely for benchmark purposes**.\n\nHowever, we fully agree with the reviewer that to have a more comprehensive and complete understanding of the model’s capability, we would need a benchmark at a larger scale, which we were unable to achieve due to the cost limit.\n\nSome recent works show a clever way to address this. Instead of directly evaluating with GPT-4, one can use ChatGPT to extract the answers, or key aspects that are required to solve the problem. This can allow the model to still answer with natural sentences, while enabling evaluation at scale. We are happy to see such progress in this field. Of course, despite being cheaper, ChatGPT still incurs a cost. During the rebuttal, we find the largest open-source model, LLaMA-2-Chat-70B, elicits impressive capabilities in following complex instructions like ones we used to query GPT-4 to create LLaVA-Instruct-158K (see response to Q1 of MLCz). It can also be a cost-free alternative.\n\nMeanwhile, we believe that it is also important to leverage academic benchmarks, like VQAv2, GQA, etc. The current LLaVA is only trained on natural instruction and responses, making it challenging to evaluate on those standard benchmarks that have ground truth with a single or a few words. Given the large size of these datasets, it is an open research problem to design efficient and effective metrics. We find the recent VisualGPTScore [1] can be considered as an inspiring way to construct a cost-efficient metric. For example, one can evaluate $P(text|image)$ after the model outputs the long-form answer.\n\nWe thank the reviewer for bringing up this important topic for discussion, and we are happy to discuss and clarify any further questions or doubts. We will include these discussions in our revision, and we believe our draft will be stronger by including the insightful suggestions from the reviewers.\n\n[1] Visio-Linguistic Reasoning with Multimodal Generative Pre-Training Scores. Lin et al. 2023.'}}, {'title': {'value': 'Follow-up questions'}, 'comment': {'value': 'Thanks for the detailed response. Some of my questions in the original review were not answered and I would still appreciate a discussion on these topics:\n\n**Q1. ""While prior works such as Vicuna [1] also uses GPT4 to score their responses in a text-only fashion, it is unclear how robust GPT4 is for multimodal reasoning while doing text-only evaluation.""** \n\nAfter reading the response, I am even more concerned about GPT-4 text-only evaluation:\n- It costs money to perform evaluation, which limits the custom test-set in this paper to 30 COCO and 24 in-the-wild images.\n- GPT-4 performance is not stable across time. \n- As mentioned by authors in response to Q5, the textual annotation of an image may not capture all the details in an image.\n- While prior works such as Vicuna also use GPT4 to output numerical scores, it is hard to measure how accurate the numerical score is.\n\n**Q2. ""Are the 24 in-the-wild images cherry-picked?""** \n\nBy cherry-picking I actually meant **selecting test samples based on the performance of LLaVA**. While I would like to believe that the authors did not do this, this evaluation set just seems too small for robust and scientific benchmarking. Although it covers a diverse range of skills, I would like the authors to provide more discussion in the revised paper about **what is the scientific way to benchmark such multimodal instruction-following models.** For example, should one be using larger and standardized benchmarks such as VQA2.0 and GQA (or some more recent multimodal benchmarks)? Are there better and more reproducible evaluation metrics than GPT-4\'s raw numerical scores? Because LLaVA is one of the first works on this trending topic, I believe it is important to answer these questions such that the community can move in the right direction.\n\nAfter reading the response to Q4, I would like the authors to clarify a few things about ScienceQA experiments:\n\n**Q3. What is the ""random-guess"" mode, and why does it help with text-only GPT4? I couldn\'t find the term ""random guess"" in the original ScienceQA paper or their github repo, so I would like a more detailed explanation here.**\n\n**Q4. How does the text-only GPT4 and zero-shot/fine-tuned Vicuna baseline utilize the image context? Do they use the image caption from the ScienceQA dataset?""**'}}, {'rebuttal': {'value': '**Q1. Why do we use a small LLaVA-Bench-COCO split with only 30 images?**\n\nSince we divide the question into three categories, we have 90 questions for COCO and 60 questions for In-the-Wild. The amount of the questions in our test set is similar to Vicuna-Bench [1], which has 80 questions. The reason we consider small evaluation sets is due to the cost using GPT-4 evaluation, the current size allows more accessibility for e.g., university labs to report results.\n\n**Q2. How do we select the 24 in-the-wild images?**\n\nDifferent from exsiting benchmark that evaluates a single specific capablity of multimodal models, we are seeking for a benchmark, where each evaluation sample can measure multiple integrated capabilities of a model. Such capabilities include recognition, OCR, knowledge, language generation, spatial awareness, counting, etc.  To design a benchmark covering a wide range of capabilities, while keeping the evaluation cost affordable, we find 24 samples that require multiple multimodal capabilities. Besides, by using the description-based annotations for each image, we are able to create and extend more questions to improve the capability coverage.\n\n**Q3. Split to train/val splits**\n\nLLaVA-Bench-COCO follows the train/val split in machine learning. LLaVA-Instruct-158K uses COCO train 2014 images and annotations, while it samples 30 validation images from COCO val 2014 (L217). Both follow the same data generation pipeline (Sec. 3). It serves as validation to study model alignment and capabilities with consistent visual inputs (L219-L220). A small size is chosen, similar to minival split practice, for quick evaluation / iteration during development.\n\n**Q4. Language-prior in ScienceQA and zero-shot performance**\n\nScienceQA has three question modes: text, image, and no context (Table 7, TXT/IMG/NO).\n\nThe default evaluation pipeline of ScienceQA includes a ""random guess"" mechanism, which helps text-only GPT-4 but not LLaVA. Without this, GPT-4\'s IMG accuracy drops to 59%, suggesting a more balanced language prior.\n\nAs suggested by the reviewer, we provide two further experiments: (1) zero-shot performance of LLaVA and Vicuna; (2) Vicuna finetuned on ScienceQA.\n\nSince open-source models like Vicuna and LLaVA are still not good at following “format” instructions like ""conclude your answer with `The answer is`"", we use ChatGPT-3.5 to reformat the answer, following the recent practice in multimodal evaluation.\n\nWe show that zero-shot LLaVA outperforms both GPT-4 (+7.5%) and Vicuna (+10.3%) on IMG modality. Besides, zero-shot LLaVA consistently outperforms zero-shot Vicuna, in all categories including text-only questions.\nWe also show that the finetuned LLaVA outperforms the finetuned Vicuna in almost all categories, with an average performance gain of 5.2%.\n\n| ZeroShot| NAT | SOC| LAN| TXT| IMG| NO| G1-6 | G7-12 | AVG|\n|--|--|--|--|--|--|--|--|--|--|\n| GPT-4 | 77.44 | 64.23 | 86.45 | 74.73 | 59.05 | 90.38 | 78.49 | 74.36 | 77.01 |\n| Vicuna | 66.83 | 60.63 | 69.00 | 65.69 | 56.27 | 71.71 | 68.94 | 60.98 | 66.09 |\n| LLaVA  | 71.27 | 74.24 | 70.91 | 70.43 | 66.53 | 72.89 | 75.4 | 65.33 | 71.8 |\n\n| Finetuned | NAT | SOC| LAN| TXT| IMG| NO| G1-6 | G7-12 | AVG|\n|--|--|--|--|--|--|--|--|--|--|\n| Vicuna | 86.9 | 79.3 | 88.55 | 85.58| 76.85 | 91.43 | 85.68 | 85.83 | 85.73 |\n| LLaVA | 90.36 | 95.95 | 88 | 89.49| 88 | 90.66 | 90.93 | 90.9 | 90.92 |\n\nWe\'ll include these results and discussion in the revision.\n\n**Q5. Dense captioning model + LLM vs end-to-end**\n\nThere are two conceptual advantages.\n\n- Completeness of image representations. Dense captioning may not be able to capture all details of an image that the user instruction is concerned with. In contrast, an end-to-end multimodal model can be instruction-aware and only focus on the relevant visual contents via attention mechanism. See Rebuttal Fig. 2 for a qualitative example.\n- Single model. End-to-end models save computational resources and reduce complexity in model serving and request handling, which is beyond the scope of this paper.\n\n**Q6. Sampling Details**\nWe set LLaVA\'s temperature to 0.2, and tuning other hyper-parameters does not further improve the quality. Beam search improves LLaVA-13B output quality (67.3->69.8), while it is not trivially compatible with real-time UI like ChatGPT. We report all numbers without the beam search to make the evaluation consistent with the user interface. For GPT queries, we follow Alpaca to set the temperature and top_p to 1.0. We will include this in revision.\n\n**Q7. Elon Meme: Generalization or bias**\nThis is a great question that is worth further studying. We designed two sets of images in Rebuttal Fig. 1 to verify. We find this study intriguing and it further supports it being a form of generalization of our model.\n\n**Q8. Is CLIP powerful enough for multimodal instruction-following?**\n\nThanks for bringing up this interesting topic. \n\nWe agree with that instruction tuning plays a more important role in guiding capable foundation models to follow human intents, rather than adding new knowledge. In multimodal settings, we leverage the existing capabilities of two models: LLM for language knowledge and CLIP for image-text alignment, rather than making each individual of them stronger. LLaVA tuning largely aligns the capable foundation LLM to understand image-related human intent. Interestingly, new emerging properties occur when combining the two existing capabilities like OCR in the wild.\n\nGrid features or the pooled features on [CLS] token of CLIP on their own may lose spatial information (behave like bag-of-words). However, in LLaVA’s design, we feed the raw image patch features into the LLM, and the positional embeddings of LLM are incorporated into the visual token representations, implicitly maintaining the spatial information of the visual inputs.\n\n[1] Chiang, et al. ""Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality."".'}}, {'rebuttal': {'value': '**Q1. Does the proposed pipeline work with an open-source LLM?**\n\nIn our preliminary study, we find that the capability of the teacher is crucial to the quality of the generated instruction-following data (L128-L130). Until the submission deadline, the largest Vicuna model was 13B. Just as the reviewer’s concern, its complex reasoning and spatial reasoning capability is still limited and is behind proprietary models including ChatGPT and GPT-4. However, the recently released LLaMA-2-70B-Chat appears to have narrowed the gap. Due to the large size of the model, it requires a huge amount of VRAM and has a slow inference speed. We conducted a preliminary study on around 200 samples for each category.\n\nSpecifically, we generate 200 samples for each category (conversation, detailed description, complex reasoning), using LLaMA-2-70B-Chat, ChatGPT, and GPT-4.\n\nAfter generating the response, we find that unlike previous open-source models, LLaMA-2-70B-Chat can start to follow complex instructions like creating multimodal instructions.\n\nHowever, it still fails in the conversation category, as we find that the LLaMA-2-70B-Chat is not correctly following the conversation format. This may be potentially fixed with more sophisticated prompt tuning. However, due to the limited rebuttal period, we do not evaluate on the conversation category. This is also one of the main limitations we find of LLaMA-2-70B-Chat.\n\nWe then quantitatively evaluate the generated instructions using GPT-4 as the judge: (1) the correctness of the answers generated, and (2) the complexity of the instructions generated for complex reasoning questions.\n\n|          | Correctness | Complexity |\n|----------|-------------|------------|\n| LLaMA-2-70B-Chat | 8.7         | 7.4        |\n| ChatGPT  | 9.5         | 9.2        |\n\nThese initial results are promising, and suggest that our pipeline can be potentially applied to open-source models as their capabilities are improved. We look for more comprehensive studies and deeper explorations for future research.\n\n**Q2. Zero-shot VQA**\n\nWe evaluate LLaVA-13B on VQA-v2 and OK-VQA.\n\nNote that for OKVQA, we use a slightly relaxed evaluation protocol for evaluation. Since LLaVA typically outputs a short sentence rather than one or two words, if the generated sentence by LLaVA contains the ground truth answer, we consider it a correct prediction.\nWe find that although LLaVA lags behinds on VQA-v2 (a task where answers can be directly derived from the image), LLaVA performs surprisingly well on OK-VQA (a task where answers require strong knowledge and reasoning) — LLaVA outperforms Flamingo-80B on zero-shot OK-VQA. This is because (1) LLaVA’s advantage lies in its capable LLM; (2) all of the instructions in LLaVA are prompting the model to output a complete sentence, and it thus struggles a bit on those standard benchmarks, which requires answers of one or two words.\n\nWe believe the latter issue can be alleviated by incorporating short-form answers into the instruction tuning data or improving the multimodal in-context learning capabilities, and we leave them to future work.\n\n| Models       | VQAv2 | OKVQA |\n|--------------|-------|-------|\n| PICa (in-context few-shot prompting GPT3-175B) [1]  | --  |48.0  |  \n| Flamingo-80B [2] | 56.3  | 50.6  |\n| LLaVA-13B    | 44.2  | 55.0  |\n\n[1] PICa: An Empirical Study of GPT-3 for Few-Shot Knowledge-Based VQA\n\n[2] Flamingo: a visual language model for few-shot learning\n\n**Q3. Will the data generation pipeline benefit from even more detailed image descriptions?**\n\nThis is a great suggestion. As we show in Table 4, adding detailed image description to conversation data can improve the model’s capability. We believe that more detailed annotations can further improve the detailedness and the quality of the generated instruction dataset, ultimately resulting in an improved model. Annotations, such as region captions, visual narratives, or scene graphs, are definitely valuable for future research.\n\n**Q4. Can LLaVA handle questions about extremely low-level details?**\n\nCurrently, LLaVA is not able to handle low-level details such as the color of the rope, as the rope is currently very thin and is covering only a few pixels after center cropped and resized to 224x224. However, given that LLaVA is capable of correctly identifying the color of those slightly larger regions (e.g. the clothes that the man is ironing), we believe that scaling up the image resolution, and/or incorporating more detailed descriptions, as mentioned by the reviewer in the comment above, could unlock LLaVA’s low-level detail recognition/reasoning capabilities.\n\n> 278: year -> layer\n\nThanks for pointing out the typo. We’ll fix it in the revision.\n\n'}}, {'rebuttal': {'value': '**Q1. Ablations on other LLMs other than Vicuna.**\n\nUntil the paper submission deadline, Vicuna is the most adopted open-source instruction-tuned LLM. There are other great instruction-tuned LLMs coming out after that, including MPT, LLaMA-2-Chat, etc.\n\nWe present initial studies using these other LLMs on LLaVA-Bench-In-the-Wild below. We also include the performance of the base LLM measured by MMLU and MTBench from the Vicuna leaderboard.\n\n| BaseLLM | MMLU | MTBench | LLaVA-Bench-In-the-Wild |\n|------------|------|---------|----------|\n| MPT-7B | 32      | 5.42 | 53.6 |\n| Vicuna-7B | 49.8    | 6.17 | 63.3 |\n| LLaMA-2-7B-Chat      | 45.8    | 6.27 | 63.2 |\n\nThis initial study exhibits a correlation of the capability of the base LLM and the performance of the resulting multimodal model performance. It will be interesting to dig further into the relationship between the base LLMs and multimodal models. It is worth mentioning that MPT-7B and Vicuna-7B is instruction-tuned with supervised finetuning, while LLaMA-2-7B-Chat is additionally finetuned with RLHF. It will also be interesting to see the influence of RLHF in terms of the multimodal capabilities.\n\nWe believe this initial study will be valuable to the research community to better understand the mechanism and capability of the multimodal models. We will release these results and corresponding model checkpoints to the public.\n\n**Q2. Why do we use a 2e-3 learning rate for pretraining?**\n\nSince we pretrain our model on a small 595K dataset, there are only around 4.5K iterations during training. Given the few steps the model is optimized for, we empirically find a larger 2e-3 learning rate is slightly better for fast convergence than lower learning rates like 2e-4.\n'}}, {'rebuttal': {'value': '**Q1. Data Quality**\n\nWe agree that high quality instruction data is critical and have taken measures to ensure the data quality.\n\nFirst, we create image descriptions directly from the well-established manually-annotated MSCOCO dataset, which contains bounding box and caption annotations (L103-L110). This ensures the quality of the visual groundness of our textural context input to GPT-4.\n\nSecond, we perform text-based filtering to remove invalid responses: (1) incomplete responses; (2) GPT refuses to provide the answer; (3) contain words that make the answer not sound like it is looking at the images (e.g. according to the captions). We’ll include the detailed list of keywords in the revised appendix.\n\nThird, we iterate and validate our prompts on a subset of around 1000 samples, to validate the visual groundness of the generated outputs using GPT-4, and find that GPT-4 consistently provides higher quality instruction-following data (L128-L130).\n\nFinally, we ablate using LLaVA-Bench-COCO on the combination of different types of generated instruction-following data (Table 4, L217-L227).\n\nNote that MiniGPT-4 is a concurrent work to LLaVA, while we are more than happy to discuss.\n\n> *From the MiniGPT-4 paper: ...we check if each generated image description **follows our desired format**, and also manually refine the generated captions by **eliminating redundant words or sentences** ....*\n\nAccording to the MiniGPT-4 paper, the manual check is only performed to correct **textual format** errors, without mentioning checking the visual groundness of the generated responses.\n\nFurthermore, the source image description of MiniGPT-4 is generated by the first-stage MiniGPT-4. Besides the textual errors that are mentioned in the paper, the correctness and the visual groundness of the generated descriptions of MiniGPT-4 is unclear.\n\nWe believe that our data is more large-scale, diverse, content-rich, and the quality is more controlled.\n\n**Q2. Is 595K image-text pairs enough for vision-language alignment?**\n\nSince CC3M only has around 2M images available to download from the Internet, we choose the BLIP-captioned LAION-CC-SBU dataset (which is the training dataset of BLIP2). Due to the limitation of both resources and time during the rebuttal period, we have tried two subsets: 600K samples and 6M samples. We ablate this with Vicuna-13B using the same schedule as described in the paper, and evaluate on LLaVA-Bench-In-the-Wild. As shown in the paper, when scaling up the pretraining dataset from 600K to 6M, the overall performance on LLaVA-Bench-In-the-Wild does not vary too much (66.8 vs 66.5).\n\n| Pretrain Samples | Conversation | Detail | Complex | All |\n|--|--|--|--|--|\n| 600K | 56.7±3.9 | 54.2±3.1 | 80.2±1.5 | 66.8±0.8 |\n| 6M | 55.1±3.9 | 56.3±2.6 | 79.6±2.9 | 66.5±0.5 |\n\nWe believe the fast alignment of LLaVA can mainly be attributed to two reasons. First, our vision encoder, CLIP, was pretrained with image-text contrastive loss, and its visual feature is thus already aligned to a text space. It is sufficient to re-align this to a different text space using a linear layer. Second, it is much easier and requires fewer samples to optimize the linear layer (5.2M parameters) than the QFormer from BLIP2, which contains 1.1B parameters, orders of magnitude more than LLaVA’s alignment-stage trainable parameters. We thank the reviewer for bringing up this topic, and will include this discussion in the revision.\n\n**Q3. LLaVA inputs 256 CLIP visual tokens into the LLM, which is much larger than Blip2 and MiniGPT4 (~30 tokens). Such a design will make the training much slower. So, do we really need 256 tokens?**\n\nWe are happy to compare with the concurrent work, MiniGPT-4.\n\n*First, will this make the training slower?*\n\nSince LLaVA uses 256 tokens, it is around 4-5x slower than MiniGPT-4 per training iteration. However, since we only need 600K samples to converge, the total pretraining cost of LLaVA is 4 hours on 8x A100s (Supp. L62). MiniGPT-4 pretrains with ~6M image-text pairs and requires training approximately 10 hours on 4x A100s (which roughly equates to 5 hours on 8x A100s). When considering the total training time, LLaVA is slightly faster.\n\n*Second, do we really need 256 tokens?*\n\nThis is an interesting research question open to discussion. Compressing 256 tokens to 32 tokens is a process of information compression. We find that this is detrimental in terms of OCR capability, which is an interesting emergent capability of LLaVA. For example, on a suite of 27 text recognition related academic datasets,  LLaVA consistently outperforms MiniGPT4 on 23 out of 27 datasets, despite LLaVA being trained with an order of magnitude smaller image-text training data. \nWe also qualitatively show in Fig. 2 of Rebuttal Supplementary, that such compression process may discard information that the user is curious about: LLaVA recognizes the website that the image comes from by reading the text from the watermark, while MiniGPT-4 fails.\n\nFurthermore, having finer patch-level features can allow the model to perform region-level reasoning easier, as the region-level information is better preserved and readily extractable for downstream models.\n\n**Q4. Does full-model finetuning lead to the degradation of LLM’s ability?**\n\nWe show that LLaVA and Vicuna are comparable on MTBench[2], and LLaVA is only slightly worse (-0.8%) on MMLU[1].\n\n| | MTBench | MMLU |\n|---|---|--|\n| Vicuna-13B | 6.57  | 55.8 |\n| LLaVA-13B | 6.63  | 55.0 |\n\nWe find this result encouraging, and this can be partially attributed to the inclusion of complex reasoning questions, and long-form answers in LLaVA-Instruct-158K, which helps maintain the language capabilities of LLaVA. We also show that on ScienceQA, it even slightly outperforms Vicuna, on text-only categories. See detail in R4 to reviewer mhaS.\n\n[1] Hendrycks, et al. ""Measuring massive multitask language understanding."".\n[2] Zheng, et al. ""Judging LLM-as-a-judge with MT-Bench and Chatbot Arena."".\n'}}, {'rebuttal': {'value': 'We sincerely thank all the reviewers for their time and their thoughtful comments and questions. We are encouraged that the reviewers find that:\n\n- Our work is a pioneer in the multimodal instruction tuning field (RuBm, MLCz, A2dU, mhaS). It will inspire a lot to the research community (RuBm) and have a huge impact on this field (MLCz).\n- We have made significant contributions, including\n    - an inspiring pipeline for multimodal instruction data generation (RuBm,MLCz)\n    - one of the first large-scale vision-language instruction-following datasets (mhaS) and a multimodal instruction-following benchmark (RuBm)\n    - LLaVA, a strong visual instruction model (RuBm) with elegant designs (mhaS) and impressive instruction following capabilities for images and text (A2dU).\n    - fully open-sourced assets that are undeniably valuable to the multimodal research community (mhaS).\n- The paper is well written (MLCz), contains some interesting insights (A2dU), and has a detailed set of comparisons and evaluations (MLCz,A2dU).\n\nWe attempted our best to address the questions as time allowed. We believe the comments & revisions have made the paper stronger and thank all the reviewers for their help. Please find individual responses to your questions below.'}, 'pdf': {'value': '/pdf/f1c187bca8c1cd872ad932bb520a3de758e955fa.pdf'}}, {'summary': {'value': 'This paper introduced LLaVA, an effective visual instruction tuning method to turn Large Language Models (LLMs) into multi-modal LLMs. LLaVA is first pre-trained on image-text pairs to connect a visual encoder (CLIP) and a LLM (Vicuna). Then the authors utilize GPT4 to generate ~150K visual instruction data for training visual instruction-following models. LLaVA is evaluated on two diverse and challenging benchmarks, as well as a science question answering dataset. Overall, LLaVA is a very early attempt for enhancing LLMs with multi-modal capacity. I believe it will inspire a lot to the research community.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- Expand instruction tuning to the vision domain. Visual instruction tuning is a new research problem for vision-language models. It endows vision-language models with powerful comprehension and reasoning capabilities.\n- A new pipeline for visual instruction data generation. LLaVA takes image captioning or object detection results as GPT4’s input for visual instruction generation. This is an effective way to quickly generate a large amount of visual instruction data.\n- A strong visual instruction model LLaVA with available pretrained models and demos.\n- Multi-modal instruction-following benchmark.'}, 'weaknesses': {'value': ""- Data quality. The proposed visual instruction data is automatically generated by GPT4. But there seems to be a lack of validation of the data quality. For example, MiniGPT4 [1] will manually verify the correctness of each image description. High quality instruction data is also proved to be important for pure LLMs in LIMA [2].\n- Is 595K image-text data enough for vision-language alignment? Blip2 uses >100M image-text pairs for vision-language alignment, while LLaVA only uses 595K data from CC3M. Have the authors tried to use more pre-training data, and will the model be further improved? Besides, I noticed that LLaVA inputs 256 CLIP visual tokens into the LLM, which is much large than Blip2 and MiniGPT4 (~30 tokens). Such a design will make the training much slower. So, do we really need 256 tokens?\n- The LLM in LLaVA is fully fine-tuned in the second stage. Will this lead to degradation of LLM's ability? Are there verification results on traditional LM tasks?\n[1] Enhancing Vision-Language Understanding with Advanced Large Language Models\n[2] LIMA: Less Is More for Alignment.""}, 'questions': {'value': 'See Weakness'}, 'limitations': {'value': 'Yes. The authors have addressed the limitations and potential negative societal impact.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper studies instruction tuning in the multimodal domain. Instruction tuning has recently drawn a lot of attractions in the large language model (LLM) field, and hence it is interesting and important to study similar capabilities in multimodal models. This paper is a pioneer work in this direction. It constructs the first instruction tuning dataset LLaVA and conducts comprehensive analysis. This is an important step towards general-purpose multimodal language model (MMLM) that can interact with humans using natural languages.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. To the best of my knowledge, this is the first work of multimodal instruction tuning. This is an important direction and hence the impact of this paper is huge.\n2. The dataset constructed in this paper is both useful and inspiring. It constructed an impactful first step for future studies in this field.\n3. The paper is well written and contains a lot of detailed studies.'}, 'weaknesses': {'value': ""I don't see any major weakness of the paper. There are some minor ones that can be improved but I understand they may go beyond the scope of this paper. For example, it will be more comprehensive to conduct ablations on the models used in this paper other than Vicuna etc.""}, 'questions': {'value': 'What did you use 2e-3 lr for pretraining? This seems to be a very large value given the 128 batch size.'}, 'limitations': {'value': 'NA'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This presents a multi-modal instruction following model and evaluates it. The model is trained by using a frozen vision encoder whose features are used an input to a LLM, which is fine-tuned. It is trained first on simple captioning tasks using a large amount of data, and then on a multi-modal instruction following dataset built by having a LLM generate tasks using the captions and bounding boxes of images.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- Presents an impressive model that seems to have advanced instruction following abilities for images and text.\n- Present a detailed set of comparison and evaluation using LLaVA-Bench, and the ScienceQA experiments. I also appreciated the re-use of a qualitative example from the GPT-4 paper.\n- Some interesting insights, such as using the second to last layer and getting a sense of the benefit of each kind of instruction-tuning task.'}, 'weaknesses': {'value': ""- I think it would be valuable to see if this same pipeline could work with an open source LLM, using OpenAI's closed LLMs are not ideal for scientific understanding and reproducibility. I in particular wonder if other LLMs can use the bounding boxes annotation of the images effectively, which I imagine in much harder than the using the captions.\n- Seeing an evaluation on standard vision/language benchmarks would have been interesting, such as zero-shot VQA.\n""}, 'questions': {'value': 'Would the data generation pipeline benefit from even more detail image descriptions? There are other annotation like region captions or visual narratives that could have also been used. \n\nI am also curious if the model can handle very low-level detailed questions, like ""What color is the rope the man is using?"" for Table 3.\n\n278: year -> layer'}, 'limitations': {'value': 'The authors have a detailed section in the appendix.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper introduces the first attempt to extend instruction-tuning paradigm to multimodal domain. This work has several major contributions: (a) the curation of the first vision-language instruction-following dataset by converting public image-text pairs into appropriate format using ChatGPT, resulting in over 100K+ multimodal instruction-following samples, (b) results indicating that a multimodal model (consisting of a CLIP visual encoder, a linear projection layer to convert visual tokens into language prompts, and a LLaMA language decoder) trained on this dataset can achieve robust multimodal chatting abilities. All assets used in their research including datasets and models are open-source. '}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'There are two major novel contributions of this work: (1) it introduces one of the first large-scale instruction-following multimodal datasets by leveraging public image-text pairs, and (2) it releases all training code, pre-trained models, and evaluation benchmarks to the wider public. These assets (outlined in supplemental L64) are undeniably valuable to the multimodal research community. '}, 'weaknesses': {'value': 'I have several major concerns about (a) the evaluation benchmarks and metrics, (b) the lack of simple baselines such as captioning-based approaches, (c) missing implementation details such as the sampling procedure.\n\nA: Issues about quantitative analysis for multi-modal chatting.\n\n- The paper uses rather small evaluation sets (L217-235) to construct the LLaVA-Bench, including 30 randomly selected COCO images and 24 in-the-wild images. Why is this subset is much smaller than the pre-training dataset with 100K+ multimodal instruction-following samples? And how do you select the 24 in-the-wild images? I couldn\'t find evidence in the current draft to suggest that these 24 images are not cherry-picked.\n\n- The evaluation is text-only and the authors use GPT4 to explicitly assign a score. While prior works such as Vicuna [1] also uses GPT4 to score their responses in a text-only fashion, it is unclear how robust is GPT4 for multimodal reasoning while doing text-only evaluation. For more robust quantitative analysis, I would encourage the authors to split the instruction-following datasets into train/val splits and also include the results of classic text-only scoring metrics. Small-scale human evaluation will also be beneficial.\n\nB: Language prior of ScienceQA benchmark.\n\n- I am shocked that a text-only (vision-blind) GPT4 can achieve as high as 82% accuracy on ScienceQA, suggesting that this particular VQA benchmark has severe language prior [2]. Even though prior works also adopt this benchmark in their evaluation, this makes it hard to interpret the progress achieve by LLaVA towards a truly “multimodal” instruction-following agent as this benchmark can be largely addressed by language prior information.\n- Is it possible to report zero-shot LLaVA performance on ScienceQA?\n\nC: Simple baselines such as dense captioning:\n\n- Even though the model architecture of LLaVA looks elegant as it only uses a linear projection to connect CLIP’s visual tokens to soft language prompts, I believe an even simpler baseline is to train a dense captioning model (using the existing rich descriptions generated by prompting ChatGPT with caption+bounding box information). During inference time, the dense captioner can turn an image into a rich textual description, which can be sent to an instruction-following text-only LLM (Vicuna/GPT4).\n\nD: Missing implementation details such as sampling.\n\n- The sampling procedure (e.g., top-k/nucleus sampling/beam search) can have profound impact on the quality of generated texts. However, the current draft does not discuss how to perform sampling for LLaVA. Also, when using GPT4 for text-only evaluation, the exact hyperparameters used such as temperature should also be reported.\n\nE: Generalization or bias?\n\n- Fig. 5 in appendix suggests that LLaVA is able to generalize to unseen domains, i.e., correctly identifying that the person holding a doge coin is Elon Musk, while Elon Musk does not appear in LLaVA’s training dataset. However, it is unclear whether this is a result of generalization or language bias of LLMs. Perhaps your model tends to answer “Elon Musk” when asking about the name of the person, or perhaps it tends to answer “Elon Musk” when there is a doge coin in the image.\n\n\nOne minor typo:\nL99: “and curate such a questions list” -> “to curate such a list of questions”\n\n\nFinally, I have an doubt about ""multimodal instruction-following"" (this is not a weakness but open to discussion): \n\n- Studies in NLP such as [3,9] have suggested that instruction-following is effective mostly because LLMs such as LLaMA are already capable foundation models, and therefore instruction-following can effectively align the model output with human interest. However, it is unclear whether multimodal foundation models such as CLIP (as used in LLaVA) is powerful enough. For example, a wide range of recent works and benchmarks [4,5,6,7,8] suggest that CLIP behaves like bag-of-words and do not have strong vision-language reasoning capabilities. As we do not yet have strong enough vision-language foundation models, it is unclear if the multimodal research community is ready to embrace the instruction-following paradigm. \n\n[1] Vicuna. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality.\n\n[2] Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering. Goyal et al. 2016.\n\n[3] LIMA: Less Is More for Alignment. Zhou et al. 2023.\n\n[4] When and why vision-language models behave like bags-of-words, and what to do about it? Yuksekgonul et al. 2022.\n\n[5] Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality. Thrush et al. 2022.\n\n[6] CREPE: Can Vision-Language Foundation Models Reason Compositionally? Ma et al. 2022.\n\n[7] Equivariant Similarity for Vision-Language Foundation Models. Wang et al. 2023.\n\n[8] Visio-Linguistic Reasoning with Multimodal Generative Pre-Training Scores. Lin et al. 2023.\n\n[9] The False Promise of Imitating Proprietary LLMs. Gudibande et al. 2023.\n'}, 'questions': {'value': ""I summarized my most concerned questions about this work:\n- Why did you not sample train/val splits for evaluating LLaVA's multimodal chatting abilities? Are there specific concerns?\n- Is it possible to extend LLaVA's evaluation to other VQA benchmarks (as reported by GPT4) such as VQA2.0 which has balanced language prior?\n- Why is the architecture design of LLaVA more superior than a dense captioning model + instruction-following LLM, if both are trained on the same dataset?\n- What is the sampling procedure of LLaVA? \n\nGiven that this paper presents a significant dataset contribution, I would be happy to revise my rating if the authors can address my above-mentioned weaknesses and questions.\n\nUpdated in Aug 17th: I have increased my rating based on the author's promise to revise the paper by including more discussion on more scientific evaluation metrics and benchmarks for MLLMs.""}, 'limitations': {'value': 'Yes, the authors discuss about limitations in supplemental material.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Visual Instruction Tuning'}, 'authors': {'value': ['Haotian Liu', 'Chunyuan Li', 'Qingyang Wu', 'Yong Jae Lee']}, 'authorids': {'value': ['~Haotian_Liu1', '~Chunyuan_Li1', '~Qingyang_Wu1', '~Yong_Jae_Lee2']}, 'keywords': {'value': ['visual instruction tuning', 'instruction tuning', 'multimodal', 'LLM', 'GPT']}, 'abstract': {'value': 'Instruction tuning large language models (LLMs) using machine-generated instruction-following data has been shown to improve zero-shot capabilities on new tasks, but the idea is less explored in the multimodal field. We present the first attempt to use language-only GPT-4 to generate multimodal language-image instruction-following data. By instruction tuning on such generated data, we introduce LLaVA: Large Language and Vision Assistant, an end-to-end trained large multimodal model that connects a vision encoder and an LLM for general-purpose visual and language understanding. To facilitate future research on visual instruction following, we construct two evaluation benchmarks with diverse and challenging application-oriented tasks. Our experiments show that LLaVA demonstrates impressive multimodal chat abilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and yields a 85.1% relative score compared with GPT-4 on a synthetic multimodal instruction-following dataset. When fine-tuned on Science QA, the synergy of LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make GPT-4 generated visual instruction tuning data, our model, and code publicly available.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/8ec2de30800edb13f33bf46d3f735b91f7561ce0.pdf'}, '_bibtex': {'value': '@inproceedings{\nliu2023visual,\ntitle={Visual Instruction Tuning},\nauthor={Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=w0H2xGHlkw}\n}'}, 'paperhash': {'value': 'liu|visual_instruction_tuning'}}]"
"['Agrim Gupta', 'Jiajun Wu', 'Jia Deng', 'Fei-Fei Li']",NeurIPS,Siamese Masked Autoencoders,https://neurips.cc/virtual/2023/oral/73813,2023," Establishing correspondence between images or scenes is a significant challenge in computer vision, especially given occlusions, viewpoint changes, and varying object appearances. In this paper, we present Siamese Masked Autoencoders (SiamMAE), a simple extension of Masked Autoencoders (MAE) for learning visual correspondence from videos. SiamMAE operates on pairs of randomly sampled video frames and asymmetrically masks them. These frames are processed independently by an encoder network, and a decoder composed of a sequence of cross-attention layers is tasked with predicting the missing patches in the future frame. By masking a large fraction (95%) of patches in the future frame while leaving the past frame unchanged, SiamMAE encourages the network to focus on object motion and learn object-centric representations. Despite its conceptual simplicity, features learned via SiamMAE outperform state-of-the-art self-supervised methods on video object segmentation, pose keypoint propagation, and semantic part propagation tasks. SiamMAE achieves competitive results without relying on data augmentation, handcrafted tracking-based pretext tasks, or other techniques to prevent representational collapse.",Oral 6C Vision,https://openreview.net/pdf?id=yC3q7vInux,https://openreview.net/forum?id=yC3q7vInux,yC3q7vInux,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'All reviewers find the paper to be novel with impressive experiment results. The rebuttal additionally resolves minor concerns regarding technical details and additional experimental comparisons. The authors are suggested to incorporate constructive feedbacks from the review comments into the finalized version. Based on high quality of this paper and the potential impact to the community, reviewers generally nominated it to be an Oral.'}}, {'title': {'value': 'Response to Reviewer'}, 'comment': {'value': 'Thank you for your comments and suggestions. We hope to include some results on activity recognition benchmarks in the final version.'}}, {'title': {'value': 'Response to Reviewer Comment'}, 'comment': {'value': 'Thank you for your comments and suggestions. We address the reviewer concerns below:\n\n>Confidence intervals\n\nIdeally, we would like to run all our experiments/ablations multiple times. However, we note that this is not a common practice in representation learning literature due high compute requirements per experiment. Nevertheless, we will re-run our base ablation setting 3 times to quantify the variance (if any) and include it in the revised version. \n\n>[CLS] token\n\nWe don’t have a good understanding of why the attention maps for the [CLS] token are meaningful. Exploring this is an interesting research question which we leave to future work. \n\n>Are the query and key projections symmetric?\n\nNo, we don’t use the same query and key weights.'}}, {'comment': {'value': '> Confidence intervals\n\nI was referring to CIs for the distribution induced by the random variables in the training procedure (shuffling of training set, initialisation of model parameters), not inference. It would be best if these could be obtained from at least 3 trials for the final version.\n\n> [CLS] token\n\nThank you for running the experiment without a [CLS] token.\n\nI understand that the [CLS] token may be useful in intermediate layers as a kind of position-agnostic ""place"" to accumulate global information, but it\'s a little unclear to me why the attention maps for the final layer would be meaningful if no loss is applied to the [CLS] token (Section 4.4). Is it possible to shed some light on this? Perhaps because the other tokens ""use"" the global information without necessarily ""adding to it"" in the final layer?\n\nThis reminds me - are the query and key projections symmetric (i.e. $W_Q = W_K$) in the self-attention layers?\n\n> Impact of dataset similarity not investigated\n\nThank you for acknowledging this.\n\n> Larger models\n\nThank you for running initial experiments.\n\n> Future vs past\n\nThank you for running this experiment; I hope it can be included in the final version.\n\n**Overall**\n\nThe paper is intuitive, well-motivated and well-written. The authors have used the rebuttal to strengthen the paper. I do not have any major concerns and keep my initial positive rating.'}}, {'comment': {'value': 'Thanks for the response, I have no further questions and will keep my initial rating.'}}, {'comment': {'value': 'Dear authors, thank you for addressing the comments in my review. I feel you have adequately done so.'}}, {'title': {'value': 'Reply to Authors'}, 'comment': {'value': 'Most of my concerns has been answered. I would expect authors to incorporate some of the changes pointed out (and accepted) by authors to be reflected in the final version of the paper. I would like to maintain my ratings.'}}, {'comment': {'value': 'Most of my concerns are addressed. However, I still feel it is important to demonstrate the effectiveness of the method in the video classification task. HMDB51 is a small-scale dataset with only 3.5k training clips. Evaluating the method on this dataset will not introduce too much computational cost but can further verify the results. '}}, {'rebuttal': {'value': ""Thank you for your comments and suggestions. We address the reviewer concerns below:\n\n>*Emphasis on predicting the future*\n\nWe agree with the reviewer that reversing the temporal order should not significantly alter the results. We conducted two additional ablation studies: one where we always predict the past frame (f1) and another where the order of frame prediction (f1 or f2) is randomized. All the settings for the results below follow Table 2.\n\n| prediction target | J & Fm    |\n| ----------------- | --------- |\n| f1 (past)         | 57.5      |\n| random [f1, f2]   | 57.8      |\n| **f2 (future)**   | **58.1**  | \n\nAll settings perform reasonably well, with our default setting (i.e., predicting the future) performing the best. We emphasize predicting future behavior due to its natural alignment with most real-world applications, which often necessitate the anticipation or prediction of agents' future behavior. We will update the text with this discussion and ablation. \n\n>*Patch-patch similarity calculation*\n\nWe follow prior work on representation learning (e.g. MAE) and use the output of the encoder for calculating patch-patch similarity. The decoder is only used during pre-training. We will update the text to clarify the same.\n\n>*Evaluation methodology* \n\nOur evaluation methodology follows prior work and we provide a reference for the same in the text (please see L-189, references 14-16). For completeness we provide a short description here. \n\nAll evaluation tasks are cast as video label propagation, where the goal is to predict labels for each pixel in the target frames of a video, using only the ground-truth of the initial frame (i.e., the source). We measure the cosine similarity of each pixel, or patch, in the target frame with all the patches within its spatial neighborhood from the preceding m frames. The label assignment is then based on the labels of the top-k patches that have the highest similarity. Please note, the term 'queue' in this context refers to the usage of predicted labels from the past m frames.\n\n>*Code release*\n\nWe will release the code and pre-trained checkpoints upon acceptance. For reproducibility we build on the open source implementation of MAE and provide all the relevant hyper parameters in the appendix. \n\n>*Confidence intervals*\n\nOur inference procedure is fully deterministic given a pre-trained model. We confirmed the same by running our inference with 5 different seeds for our ViT-S/16 models trained for 2000 epochs. \n\n| Model    | Run 1     | Run 2     | Run 3     | Run 4     | Run 5     |\n| -------- | --------- | --------- | --------- | --------- | --------- |\n| ViT-S/16 | 62.0      | 62.0      | 62.0      | 62.0      | 62.0      |\n\n>*Larger models ViT-B & ViT-L*\n\nWe address this in our global response and re-iterate here for convenience.\n\nWe note that ViT-S has approximately the same number of parameters as ResNet-50, enabling us to compare our method across a diverse set of baselines. Moreover, ResNet-50 is the largest backbone explored by prior work [12, 14, 16], all of which aimed at improving representations for correspondence. However, we agree that a systematic investigation into the scalability of our method in terms of model size (refer to L297) would be valuable. Practically speaking, we are constrained by resources. For instance, training a ViT-S/8 model on 8 Titan RTX GPUs for 2000 epochs requires approximately 16 days. Given the compute and time constraints, we trained a ViT-B/16 model for 400 epochs. \n\n| Model      | J & Fm    |\n| ---------- | --------- |\n| ViT-S/16   | 58.1      |\n| ViT-B/16   | 58.6      |\n\nThe improvement in performance is encouraging. To contextualize the magnitude of the improvement, we note that scaling DINO from ViT-S/16 to ViT-B/16 results in an improvement of 0.5 J&Fm. \n\n>*Role of [CLS] token*\n\nFollowing the original ViT paper which appends the [CLS] token during supervised training and uses the output corresponding to the [CLS] token for predicting class labels, almost all follow up work on representation learning using ViTs has followed this practice. Here, the role of [CLS] token is similar and is typically used for evaluation of learnt representation via linear probing. MAEs also included [CLS] token, likely to maintain consistency with existing literature and evaluations. In SiamMAE, much like in MAEs, the [CLS] token doesn't play any role during pre-training. This design choice was inherited from both ViT and MAE. Our ablation study shows that while the [CLS] token isn't crucial for achieving good results, omitting it slightly hurts the performance.\n\n| [CLS] token  | J & Fm    |\n| ------------ | --------- |\n|              | 57.5      |\n| &#10003;     | **58.1**  |\n\n>*General principle/strategy for preventing shortcut learning*\n\nWe agree that a general strategy of preventing shortcut learning would be great and is indeed an open question in the field of representation learning for computer vision. \n\n>*Impact of dataset similarity has not been investigated*\n\nWe agree that the role of dataset similarity between the train and test tasks has not been studied and will add this limitation in the text. However, we would like to point out that most of the prior work we compare with (UVC, VFS, MAE-ST and VideoMAE) were trained on the same dataset i.e. Kinetics-400. \n""}}, {'rebuttal': {'value': ""Thank you for your comments and suggestions. We address the reviewer concerns below:\n\n>*Results on video classification tasks*\n\nWe address this in our global response and re-iterate here for convenience.\n\nWe agree with the general sentiment of the comment, emphasizing the evaluation of a self-supervised representation learning method across a wide array of tasks. While we aim to demonstrate the versatility of our method, following prior work [12, 14, 16], we've limited our claims and experiments to validate our method's effectiveness at learning representations for visual correspondence. A key advantage of current evaluation strategy is its computational efficiency as it requires no training. Evaluation on video recognition benchmarks often involves fine tuning models for 300 epochs (as seen in VideoMAE, MAE-ST), requiring approximately 32-64 industrial-grade GPUs (such as V100, A100).\n\n>*Role of grid masking*\n\nAs suggested, we conducted additional ablations for grid masking with different masking ratios. We find that the performance increases when we increase the grid masking ratio to 0.75. However, it decreases when we further increase the masking ratio to 0.95. An advantage of grid masking is that the masking pattern encourages the network to exploit spatio-temporal correlations. However, with a very high masking ratio the network can no longer rely on temporal correlations, leading to worse performance. \n\nAll the settings for the results below follow Table 2c.\n\n| mask ratio      | pattern      | J & Fm    |\n| --------------- | ------------ | --------- |\n| 0.50 (s)        | grid         | 48.2      |\n| 0.75 (s)        | grid         | 53.8      |\n| 0.95 (s)        | grid         | 49.0      |\n|  **0.95 (a)**   | **random**   | **58.1**  |\n\n>*Results on larger backbones ViT-B*\n\nWe address this in our global response and re-iterate here for convenience.\n\nWe note that ViT-S has approximately the same number of parameters as ResNet-50, enabling us to compare our method across a diverse set of baselines. Moreover, ResNet-50 is the largest backbone explored by prior work [12, 14, 16], all of which aimed at improving representations for correspondence. However, we agree that a systematic investigation into the scalability of our method in terms of model size (refer to L297) would be valuable. Practically speaking, we are constrained by resources. For instance, training a ViT-S/8 model on 8 Titan RTX GPUs for 2000 epochs requires approximately 16 days. Given the compute and time constraints, we trained a ViT-B/16 model for 400 epochs. \n\n| Model      | J & Fm    |\n| ---------- | --------- |\n| ViT-S/16   | 58.1      |\n| ViT-B/16   | 58.6      |\n\nThe improvement in performance is encouraging. To contextualize the magnitude of the improvement, we note that scaling DINO from ViT-S/16 to ViT-B/16 results in an improvement of 0.5 J&Fm. \n""}}, {'rebuttal': {'value': ""Thank you for your comments and suggestions. We address the reviewer concerns below:\n\n>*Experiments on video and image recognition*\n\nWe address this in our global response and re-iterate here for convenience.\n\nWe agree with the general sentiment of the comment, emphasizing the evaluation of a self-supervised representation learning method across a wide array of tasks. While we aim to demonstrate the versatility of our method, following prior work [12, 14, 16], we've limited our claims and experiments to validate our method's effectiveness at learning representations for visual correspondence. A key advantage of current evaluation strategy is its computational efficiency as it requires no training. Evaluation on video recognition benchmarks often involves fine tuning models for 300 epochs (as seen in VideoMAE, MAE-ST), requiring approximately 32-64 industrial-grade GPUs (such as V100, A100).\n\n>*VFS performance*\n\nVFS is a state-of-the-art contrastive self-supervised representation learning method for visual correspondence. VFS learns representations by maximizing similarity across different frames from the same video. This training objective is directly aligned with how the downstream performance is measured i.e., by calculating the similarity of patches for label propagation. \n\nIn this work, our goal was to develop a predictive learning method which can match or outperform contrastive learning approaches for learning visual correspondence. Historically, the performance of predictive learning methods has trailed behind contrastive self-supervised learning approaches. \nThis can be attributed to the training objective of predictive learning methods like SiamMAE, which focuses on low level pixel details and is not directly aligned with the downstream evaluation procedure.\nDespite this shared disadvantage, we significantly outperform prior predictive learning based methods (+22.7 improvement over VideoMAE). Finally, we achieve our stated goal as the ViT-S/8 model improves over VFS by +2.5 J&Fm on DAVIS, +2.7 mIOU on VIP, and +1.0 PCK\\@0.1 on JHMDB. \n""}}, {'rebuttal': {'value': ""Thank you for your comments and suggestions. We address the reviewer concerns below:\n\n>*Frame sampling with overlap analysis*\n\nTo perform overlap analysis, we sampled video frames from the Kinetics-400 validation set with the specified frame gap and calculated two image similarity metrics: mean squared error (mse) and structural similarity index measure (ssim). We observed that either a very high overlap (low frame gap, high ssim, and low mse) or a low overlap (high frame gap, low ssim, and high mse) adversely affects performance. \nSampling with a frame gap of 16 or within a range of [4, 48] yields the best results. Interestingly, the overlap metrics for a frame gap of 16 and [4, 48] are comparable, suggesting that a particular degree of overlap is important for best results. \n\n\n| frame gap  | ssim     | mse     | J & Fm    |\n| ---------- | -------- | ------- | --------- |\n| 4          | 0.6231   | 0.0230  | 56.7      |\n| 8          | 0.5343   | 0.0360  | 57.8      |\n| 16         | 0.4749   | 0.0480  | 58.0      |\n| 32         | 0.4221   | 0.0597  | 56.3      |\n| 4-48       | 0.4548   | 0.0528  | 58.1      |\n\n>*Qualitative analysis & discussion of failures*\n\nWe've included a qualitative failure analysis in a file attached to the global response and will incorporate it into the paper.\n\nWe evaluate the quality of learnt representations using label propagation and consequently inherit its limitations. Specifically, the inference algorithm lacks semantic understanding, leading to globally inconsistent labels (refer to examples in the figure). This limitation can be overcome by fine tuning the learnt representations with task specific architectural changes. Additionally, there are instances where the inference process might miss intricate object details, like the spokes of a tire. While this shortcoming can be mitigated by using a smaller patch size during training and inference, it comes at a higher compute cost.\n\n>*Comparing asymmetric masking with FrameMAE*\n\nThe results in Table 2b include the comparison suggested i.e. FrameMAE with asymmetric masking. We will update the text to clarify this. For completeness the table below compares relevant FrameMAE variations with SiamMAE. The combination of siamese encoder, a cross-self decoder with asymmetric masking works the best. In the table below (a) denotes asymmetric masking and (s) denotes symmetric masking. \n\n| encoder     | decoder        | mask ratio   |  J & Fm   |\n| ----------- | -------------- | ------------ | --------- |\n| joint       | joint          | 0.50 (s)     | 51.8      |\n| joint       | joint          | 0.75 (s)     | 55.4      |\n| joint       | joint          | 0.90 (s)     | 51.9      |\n| joint       | joint          | 0.95 (a)     | 49.7      |\n| **siam**    | **cross-self** | **0.95 (a)** | **58.1**  |\n\n>*Change title of section 4.4 to Further Insights*\n\nWe will update the text to incorporate the suggestion.""}}, {'rebuttal': {'value': 'Thank you for your comments and suggestions. We address the reviewer concerns below:\n\n>*Novelty over MAE*\n\nWe agree that our method is a simple modification of MAE albeit one which has not been explored in the past.  We hope that the simplicity, efficacy and extensive empirical analysis of our method is a valuable contribution to the community.  \n\n>*Application to “in-the-wild” datasets*\n\nPredicting the future frame based on the past frame to learn correspondence is effective because the two frames often have some degree of overlap. We consider a maximum frame gap of 48 frames, equivalent to 1.6s at 30fps. Over such short time horizons, temporal smoothness is a reasonable assumption. However, we agree that ""in-the-wild"" datasets, particularly egocentric datasets like Ego4D, might have frequent sharp scene changes due to head movements. Exploring these datasets is a promising future direction (refer to L298), especially when examining if the current strategy of random sampling remains effective. We will include this discussion in the revised text.\n\n>*Masking input images for downstream tasks to speed-up computation*\n\nTo the best of our knowledge the masking strategy of MAEs is known to speed up the training process as the encoder acts on a small set of unmasked tokens. During inference generally the entire image is processed by the encoder [1, 2]. It is possible that some works have done inference on masked images however we are not aware of such works. \n\n[1] He, Kaiming, et al. ""Masked autoencoders are scalable vision learners."" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022.\n\n[2] Li, Yanghao, et al. ""Scaling language-image pre-training via masking."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\n>*Reason for no temporal position encoding*\n\nTemporal position embeddings (TPE) enable the network in distinguishing between tokens from distinct frames. In SiamMAE, the encoder processes each frame individually and the sole interaction between tokens of different frames occurs through the cross-attention layer in our cross-self decoder. Hence, the network does not need TPEs for achieving good performance. We validated this hypothesis by conducting the proposed ablation study, adding TPEs to the decoder. When using a joint decoder, TPEs improve the performance. Ideally, if position embeddings are redundant, the network should achieve similar performance with zero embedding weights. However, in practice we found that when using a cross-self decoder, the presence of TPEs hurts the performance.\n\n\n| encoder     | decoder        | temporal pos. embed  |  J & Fm   |\n| ----------- | -------------- | :------------------: | --------- |\n| siam        | joint          | &#10003;             | 57.3      |\n| siam        | joint          |                      | 56.7      |\n| siam        | cross-self     | &#10003;             | 57.6      |\n| **siam**    | **cross-self** |                      | **58.1**  |\n\n>*Comparison on additional downstream tasks*\n\nWe address this in our global response and re-iterate here for convenience.\n\nWe agree with the general sentiment of the comment, emphasizing the evaluation of a self-supervised representation learning method across a wide array of tasks. While we aim to demonstrate the versatility of our method, following prior work [12, 14, 16], we\'ve limited our claims and experiments to validate our method\'s effectiveness at learning representations for visual correspondence. A key advantage of current evaluation strategy is its computational efficiency as it requires no training. Evaluation on video recognition benchmarks often involves fine tuning models for 300 epochs (as seen in VideoMAE, MAE-ST), requiring approximately 32-64 industrial-grade GPUs (such as V100, A100).\n'}}, {'rebuttal': {'value': ""We sincerely thank the reviewers for their thoughtful and constructive feedback. We are glad that **all** the reviewers found our method simple, clever and intuitive, our analysis and ablations to be thorough and convincing, and results impressive. The main aim of this rebuttal is to improve this work further by incorporating reviewer suggestions and comments. Specifically, we have conducted all additional ablations and experiments suggested by the reviewers. Here we comment on the feasibility and scope of two suggested avenues of improvement and provide some encouraging preliminary results. \n\n>*Training larger backbones like ViT-B & ViT-L*\n\nWe note that ViT-S has approximately the same number of parameters as ResNet-50, enabling us to compare our method across a diverse set of baselines. Moreover, ResNet-50 is the largest backbone explored by prior work [12, 14, 16], all of which aimed at improving representations for correspondence. However, we agree that a systematic investigation into the scalability of our method in terms of model size (refer to L297) would be valuable. Practically speaking, we are constrained by resources. For instance, training a ViT-S/8 model on 8 Titan RTX GPUs for 2000 epochs requires approximately 16 days. Given the compute and time constraints, we trained a ViT-B/16 model for 400 epochs. \n\n| Model      | J & Fm    |\n| ---------- | --------- |\n| ViT-S/16   | 58.1      |\n| ViT-B/16   | 58.6      |\n\nThe improvement in performance is encouraging. To contextualize the magnitude of the improvement, we note that scaling DINO from ViT-S/16 to ViT-B/16 results in an improvement of 0.5 J&Fm. \n\n>*Evaluation on video action recognition and image recognition tasks*\n\nWe agree with the general sentiment of the comment, emphasizing the evaluation of a self-supervised representation learning method across a wide array of tasks. While we aim to demonstrate the versatility of our method, following prior work [12, 14, 16], we've limited our claims and experiments to validate our method's effectiveness at learning representations for visual correspondence. A key advantage of current evaluation strategy is its computational efficiency as it requires no training. Evaluation on video recognition benchmarks often involves fine tuning models for 300 epochs (as seen in VideoMAE, MAE-ST), requiring approximately 32-64 industrial-grade GPUs (such as V100, A100).""}, 'pdf': {'value': '/pdf/30f07fb099e6a8d970f1cf13c0d2fb2e424f7f3f.pdf'}}, {'summary': {'value': 'This paper considers the problem of using self-supervised learning from video to obtain a representation that is well-suited to the task of estimating correspondence between a pair of images. They propose a significant modification of the MAE training procedure which is adapted for estimating correspondence: one image is not masked at all while the other has most (90%+) of its tokens masked, and the same (i.e. a siamese) encoder is applied to both. This is designed to require the model to internally establish correspondence. The model is trained for pixel prediction on Kinetics-400 and evaluated on several propagation tasks (object mask, part masks, human pose) using kNN inference to establish a dense correspondence field. SiamMAE is shown to greatly outperform existing self-supervised learning procedures with comparable backbone architectures, including methods trained on video. Ablative experiments confirm the importance of combining a siamese encoder with asymmetric masking. Visualization of the attention maps show that the model pays strong attention to object boundaries, seemingly a novel attribute.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. Good motivation and contextualization with respect to past work.\n1. The modification of the MAE procedure is simple but clever, and manages to extract much more information for correspondence from video than past methods.\n1. Visualization of predicted images is quite impressive (Figure 2), despite the main goal being to learn a feature extractor for correspondence.\n1. Comprehensive evaluation with 3 different tasks and wide selection of relevant baselines.\n1. Ablative experiments verify the importance of each component of the design.\n1. Hyper-parameters provided for reproducibility.'}, 'weaknesses': {'value': ""1. I'm not sure about the emphasis on predicting the _future_. It seems that the temporal order could be reversed (i.e. predict the past given the future) or randomized and I would expect similar results. Has this already been tested?\n1. It wasn't abundantly clear how the patch-patch similarity was obtained. It seems to be taken from the cross-attention values within the decoder (line 239). However, this could be more clear since the decoder may contain multiple cross-attention layers with each having multiple heads?\n1. It wasn't clear how k-NN and the queue were used to perform propagation. This should be explained in more detail or a reference provided.\n1. No code provided at this stage.\n1. Lack of confidence intervals (not a major issue - delta is quite large in most cases).\n1. No evaluation of ViT-B and ViT-L (not a major issue - impressive results obtained with smaller model).""}, 'questions': {'value': ""(Please also address or correct weaknesses above.)\n\n1. What is the purpose of the [CLS] tokens? Is the model much less effective without it? (It is surprising that the attention masks for these tokens were so salient given that they are not involved directly in the loss.)\n\nSuggestions:\n1. I wonder whether it's possible to identify a general principle/strategy for preventing shortcut learning, of which this is just one instance?\n\nMinor edits: (no need to respond)\n1. Bold values in Tables 2d and 3b seem incorrect (e.g. 58.4 > 58.1, 56.7 > 56.5).""}, 'limitations': {'value': 'Additional limitation:\n1. Even though Kinetics-400 was used without labels, it is possible that its image distribution is quite similar to that of the downstream tasks. It would be good to discuss this potentialityu, and say that the impact of dataset similarity has not been investigated?\n\nI do not see any negative societal impacts stemming from this individual paper.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper focuses on the self-supervised learning for video representations. The proposed SiamMAE operates on pairs of randomly sampled video frames and asymmetrically masks them, and then predicts the missing patches for visual representation learning. SiamMAE achieves significant performance and outperforms state-of-the-art self-supervised methods on video object segmentation, pose keypoint propagation, and semantic part propagation tasks.\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1 The motivation is clear and strong.\n\n2 The proposed asymmetric masking and cross-self decoder are effective and achieve good performance.\n'}, 'weaknesses': {'value': '1 This paper mainly evaluates the proposed method on tracking problems. How is the performance on video classification tasks, such as UCF101 and HMDB51?\n\n2 In Table 2(c), grid mask achieves better performance than random mask with 0.5 mask ratio. Increasing the mask ratio will improve the performance of random masking. How is the performance when increasing the mask ratio for grid masking?\n\n3 This paper only investigates the ViT-S backbone. It is better to also leverage larger models, such as ViT-B, to verify the effectiveness of the proposed method.\n'}, 'questions': {'value': 'My concerns mainly lie in the experiments. '}, 'limitations': {'value': 'Yes'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': '* This paper propose Siamese Masked Autoencoders for learning visual correspondence from videos called SiamMAE. \n\n* SiamMAE randomly sample a pair of video frames and randomly mask 95% of patches of the future frame, and the pair of video frames are passed into visual encoder(VIT), and cross attention decoder to reconstruct the target.\n\n* The authors conduct several experiments on downstream tasks(vos, human pose propagation), showing superior performance.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '* The paper presents a simple, yet highly effective method for the challenging video self-supervised framework.\n\n* The proposed method is well motivated and intuitive with excellent performance.\n\n* The ablation is sufficient and the writing is excellent.'}, 'weaknesses': {'value': '* Experiments on video recognition experiments should be reported. \n\n* Although SiamMAE is pretraining on video frames, i still think the authors should conduct experiments on image downstream tasks(such coco detection, segmentation) to show image representation capacity.\n\n* In Table1, The previous video ssl method(VPS) is also pretrained on Kinetics with ResNet50，however，the performance of SiamMAE with ViT-S/8 is similar in DAVIS & VIP & JHMDB, any explanation for this?'}, 'questions': {'value': 'please refer to the strength and weakness'}, 'limitations': {'value': 'no limitations'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper proposes to use Siamese Masked Encoders for establishing correspondence for video input data. Uses the concept of predictive learning based on Masked Auto Encoder. Paper proposes to use asymmetric masking for present and future frames. Achieves best results in self-supervised setting for video label propagation tasks.\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'Strengths:\n1) The paper is well written for most of the parts and aptly elucidates the advantage of using a masked auto-encoder-based method for object-based correspondence. \n2) Discusses in detail the architecture design choices for the encoder and decoder, ans uses a final design which is intuitive and simple and  also focuses on relevant ablation studies.\n3) The paper shows and achieves better results for object segmentation, part segmentation, and pose propagation tasks. \n\n'}, 'weaknesses': {'value': 'Weakness:\n1) Frame sampling: Table 3b discusses the effect of frame gap, however, it misses to comment on what could be the minimum frame overlap between the pair of frames for which predictions are out to be done. Apart from asymmetric masking, the degree of overlap between consecutive frames is also an important factor.\n\n2) Fails to discuss the probable failure cases given the limitations from more qualitative results analysis belonging to various tasks.'}, 'questions': {'value': 'Questions:\n1) Ablation experiment: Comparison with FrameMAE. In case of FrameMAE, When we do provide 2 frames to the joint encoder, a better comparison would be comparing the asymmetric masking with FrameMAE, since from Table 2 (b, d) results as presented does not seem too behind for FrameMAE.\n\n3) Section 4.4: This subsection would be more aptly titled as ""Futher Insights"" rather Qualitative Results.'}, 'limitations': {'value': 'Overall the idea presented in the paper is lucid and necessary details regarding reproducing the experiments are mentioned. I think the paper puts a right step in the direction of improving well know correspondence (object level) problem using predictive learning. However I feel what this paper lacks is drawing a complete comparison for an image overlap percentage based study. Presenting zero-shot results for occluded scenes and object parts and discussing failure cases (as seen from qualitative results obtained)'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'In this paper, the authors propose a simple extension to Masked Autoencoders (MAE) to be able to pre-train on videos: SiamMAE. Two frames are sampled, independently encoded, and then asymmetrically masked. A transformer decoder is used to predict the missing patches in the masked image. The authors show that by masking a high proportion of patches (0.95) in the future frame and leaving the past frame unmasked, they are able to encourage the network to learn a more object-centric representation and focus on object motion rather than low-level image details. The authors show that this simple approach outperforms previous methods on many down-stream tasks and perform an extensive ablation to examine the architecture choices.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'Very well written paper. Some results are particularly impressive (e.g. more than 20% gain over VideoMAE)\n\nSimple but effective method and the honesty of presenting this as-is (instead of disguising the method as being more complicated than it needs to be) I think should be appreciated.\n\nGood comparison to other work and a great ablation section explaining many design choices\n'}, 'weaknesses': {'value': 'Can only see two minor weaknesses:\n\n1.\tThe approach adds little over MAE and feels incremental, however it works very well and hasn’t been done before.\n2.\tThis approach relies on the temporal smoothness that is found in many curated datasets, such as Kinetics. However, for in-the-wild videos, with many sharp scene changes, this assumption becomes less likely to hold. However, it should be possible to split long videos into scenes in an unsupervised manner and then sample frames within a scene. It would be nice to a discussion on how this can be applied to large-scale internet datasets (which are becoming very popular for foundation models)\n'}, 'questions': {'value': 'With standard MAE, it is possible to also mask the input images for the downstream tasks to speed-up computation. It seems that this avenue for speed-up would not be possible with this current approach since the previous frame has to be unmasked?\n\nCould the authors clarify the reason for not including temporal positional encoding (was this ablated?)\n\nIt would be interesting to see a bit more how this frame-based method compares to video-based methods on downstream tasks (for example more comparisons like VideoMAE). Perhaps focusing on compute efficiency?\n'}, 'limitations': {'value': 'Yes'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Siamese Masked Autoencoders'}, 'authors': {'value': ['Agrim Gupta', 'Jiajun Wu', 'Jia Deng', 'Li Fei-Fei']}, 'authorids': {'value': ['~Agrim_Gupta1', '~Jiajun_Wu1', '~Jia_Deng1', '~Li_Fei-Fei1']}, 'keywords': {'value': ['Representation Learning', 'Visual Correspondence', 'Self-supervised learning', 'Videos']}, 'TLDR': {'value': 'We propose Siamese Mased Autoencoders to learn visual correspondence from videos.'}, 'abstract': {'value': 'Establishing correspondence between images or scenes is a significant challenge in computer vision, especially given occlusions, viewpoint changes, and varying object appearances. In this paper, we present Siamese Masked Autoencoders (SiamMAE), a simple extension of Masked Autoencoders (MAE) for learning visual correspondence from videos. SiamMAE operates on pairs of randomly sampled video frames and asymmetrically masks them. These frames are processed independently by an encoder network, and a decoder composed of a sequence of cross-attention layers is tasked with predicting the missing patches in the future frame. By masking a large fraction (95%) of patches in the future frame while leaving the past frame unchanged, SiamMAE encourages the network to focus on object motion and learn object-centric representations. Despite its conceptual simplicity, features learned via SiamMAE outperform state-of-the-art self-supervised methods on video object segmentation, pose keypoint propagation, and semantic part propagation tasks. SiamMAE achieves competitive results without relying on data augmentation, handcrafted tracking-based pretext tasks, or other techniques to prevent representational collapse.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/550170d21b196dff6d63fa351910f0f9a2ef94d1.pdf'}, 'supplementary_material': {'value': '/attachment/63b716dbcb6a61f8942e59ae58bcb9168ddee94b.pdf'}, '_bibtex': {'value': '@inproceedings{\ngupta2023siamese,\ntitle={Siamese Masked Autoencoders},\nauthor={Agrim Gupta and Jiajun Wu and Jia Deng and Li Fei-Fei},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=yC3q7vInux}\n}'}, 'paperhash': {'value': 'gupta|siamese_masked_autoencoders'}}]"
"['Tianwei Ni', 'Michel Ma', 'Benjamin Eysenbach', 'Pierre-Luc Bacon']",NeurIPS,When Do Transformers Shine in RL_ Decoupling Memory from Credit Assignment,https://neurips.cc/virtual/2023/oral/73869,2023," Reinforcement learning (RL) algorithms face two distinct challenges: learning effective representations of past and present observations, and determining how actions influence future returns. Both challenges involve modeling long-term dependencies. The Transformer architecture has been very successful to solve problems that involve long-term dependencies, including in the RL domain. However, the underlying reason for the strong performance of Transformer-based RL methods remains unclear: is it because they learn effective memory, or because they perform effective credit assignment? After introducing formal definitions of memory length and credit assignment length, we design simple configurable tasks to measure these distinct quantities. Our empirical results reveal that Transformers can enhance the memory capability of RL algorithms, scaling up to tasks that require memorizing observations $1500$ steps ago. However, Transformers do not improve long-term credit assignment. In summary, our results provide an explanation for the success of Transformers in RL, while also highlighting an important area for future research and benchmark design. Our code is open-sourced at https://github.com/twni2016/Memory-RL.",Oral 6B RL,https://openreview.net/pdf?id=APGXBNkt6h,https://openreview.net/forum?id=APGXBNkt6h,APGXBNkt6h,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': ""This paper aims to understand the success of transformer-based methods for reinforcement learning. In particular, they aim to understand the role of transformers in addressing two challenges (1) credit assignment (understanding how actions influence future rewards), and (2) memory (representing prior observations); both challenges entail modeling long-term dependencies. To separate these challenges, the authors design a suite of experimental benchmarks, and find transformers are effective at enhancing memory, but do not improve credit assignment.\n\nReviewers found the paper's topic to be timely, and found the results to be convincing and likely to be of significant interest to the reinforcement learning community. In addition, they found the paper to be accessible and well-written, and unanimously advocated for its acceptance.""}}, {'comment': {'value': 'Thank you for your responses. I remain positive about the paper.'}}, {'comment': {'value': ""I'd like to thank the authors for the response, my scores are the same. ""}}, {'comment': {'value': 'I greatly appreciate the additional experiments on LSTMs given the limited time window for the rebuttal.\nOverall the response clarified most of my concerns which is why I decided to increase my rating to 6.'}}, {'rebuttal': {'value': ""# General Response\n\nFirst, we would like to thank all four reviewers for their positive and constructive feedback on our work! \nDuring the rebuttal period, we conducted additional experiments to address some of the questions posed by the reviewers.\n\n**mXpQ  (see Figure 1 in the PDF)**\n\n> Can we simply slap on a specific submodule to Transformers to augment their credit assignment capabilities?\n\nWe showed that (single-layer) Transformers cannot help long-term credit assignment. To further confirm this conclusion, we ran *multi-layer* Transformers on these tasks.\nIn both Active T-Maze and Key-to-Door, we find that both 2-layer and 4-layer Transformers greatly outperform 1-layer Transformer in tasks with medium-term credit assignment (length $\\le 200$), while still fail to perform long-term credit assignment (length $\\ge 250$). \nThis finding suggests that it is *unlikely* that simply increasing the size of Transformers will enable them to excel in long-term credit assignment.\n\n**2AdR (see Figure 2 in the PDF)** \n\n> LSTM starts to falter at a memory length of 250 for Passive T-Maze. But Fig 2 shows that LSTM can solve it with a memory length of 750. This suggests that hyperparameter tuning might influence LSTM training. Will the results of LSTM be improved by further tuning?\n\nFirst, we want to clarify that although LSTM reaches returns higher than $0.5$ in Passive T-Maze with a memory length of $750$, it does not *solve* the task, requiring the return to be $1.0$. \n\nYour point on tuning may be valid for medium-term memory lengths. But for long-term memory tasks, our new results show that tuning is unlikely to help LSTM.\nDuring the rebuttal period, we conduct new experiments on LSTM-based agent on the tasks with memory lengths of 1250 and 1500. LSTM-based agent reaches return below 0.5. \nThe results confirm our conclusion that LSTM-based agent cannot solve long-term memory tasks.  \n\n**2AdR**\n\n> Can you do a significance test to show superiority of GPT2 over LSTM in Figure 4?\n\nFollowing the reviewer's suggestion, we did a Welch’s t-test on Passive Visual Match success rates (Figure 4 in the main paper). The p-values for the memory length of 500 and 750 are 0.698 and 0.038, respectively. \nThese results indicate that there is significant evidence to reject the null hypothesis at the 750 memory length, but not at 500. Therefore, we clarify that the advantages observed with GPT at a memory length of 500 predominantly pertain to short-term memory, rather than long-term memory.\n""}, 'pdf': {'value': '/pdf/77ee07ad853c6df79f4f62c58c18a5297ce1d79e.pdf'}}, {'rebuttal': {'value': '> This work explores the impact of memory and credit assignment in decision transformer architectures.\n\nWe would like to clarify that our experiments evaluate the *online model-free RL* setting, not the offline RL setting that is related to Decision Transformers (DT). Nevertheless, extending our evaluation to include DT is an interesting direction for future work!\n\n> Can the authors provide any intuition on the failure of Transformers and LSTM in the long-term credit assignment tasks?\n\nWe find that in Active T-Maze task that has a credit assignment length of 250, the Transformer-based agent does not reach the Oracle (return lower than 1), but still reaches the Junction (return higher than 0). This indicates that Transformer-based agent may fail to explore enough to reach the Oracle, although the exploration should be relatively easy (just taking the initial action to move left). In LSTM-based agent, the return can *sometimes* be negative, indicating that it does not consistently reach the Junction and may face additional issues beyond credit assignment. Similar issues seem to occur in the Key-to-Door tasks where both agents do not reach the key in the initial phase. \n\n> It would be nice to see experimental evaluation of Transformers and LSTM in additional environments other than the toy tasks for better context.\n\nWe agree with this limitation, and we plan to evaluate agents on more complicated environments in future work.'}}, {'rebuttal': {'value': '\n> For policies with memory (i.e. recurrent), the definition seems less relevant since the policy can remember parts of all the information starting from time 0.\n\nRecurrent policies can *take* all the information starting from time 0 as inputs, but not necessarily *remember* it starting from that point.  As mentioned in L88-91, the context lengths of recurrent policies can be infinite, but their memory lengths can be very short, due to training issues such as gradient vanishing or explosion.  In this sense, our definition of memory lengths remains relevant to recurrent policies, with context lengths being infinite.\n\n> Lacking discussion on state and history abstraction, for example, bisimulation and approximate information states. \n\nThank you for pointing it out. This work focuses on the architectural aspect (e.g., LSTMs and Transformers) of RL rather than the objective aspect (e.g., different abstraction methods). We view these two aspects as orthogonal and believe they can complement each other to enhance RL performance. We will include some related work on abstraction and clarify our focus in the camera-ready version.\n\n>  Are Transformers predicting states that truly matter for the task? \n\nWe evaluate model-free RL agents equipped with memory architectures. Unlike model-based RL, which explicitly predicts next states, model-free RL purely aims to maximize returns. Therefore, we do not think Transformer-based RL agents used in our experiments face the issue of predicting irrelevant parts of states, regardless of their memory capability.\n\n> In operations research there are classes of ""submodular functions"", and these have provably efficient greedy algorithms that are quantifiably suboptimal. How is this connected to credit assignment length? \n\nAfter examining the definition of submodular functions, we don\'t see a direct connection between it and credit assignment length.  We are open to further insights or clarification on this connection, as it may lead to an intriguing avenue for future research.'}}, {'rebuttal': {'value': '> What potential solutions could be to the credit assignment problem when using Transformers?\n\nWe think the credit assignment problem might be easier to solve with Transformers by using them to explicitly redistribute reward signals [Liu et al., 2019, Ferret et al., 2020]. Specifically, Transformers can efficiently redistribute distant reward signals to the time step when the corresponding action occurs. Their strength in handling long-term memory makes them suitable for learning such temporal dependencies with appropriate objectives beyond model-free RL.\n\n> Can we simply slap on a specific submodule to Transformers to augment their credit assignment capabilities? Or do you think we need to develop fundamentally new architectures?\n\nWe conduct new experiments on *multi-layer* Transformers in credit assignment tasks. Although they aid in medium-term credit assignment, they do not help with long-term credit assignment. Please see the **general response** for details. This result suggests that simply adding a specific submodule to Transformers is unlikely to improve long-term credit assignment, indicating the potential need for new architectures.\n\nPlease let us know if there are any further questions.'}}, {'rebuttal': {'value': '\n> Does computing memory lengths involve human demonstrations?\n\nWe here clarify that computing these metrics *does not* require any human demonstrations. For some tasks like T-Maze, we obtain the precise numbers with careful analysis of the task structures. For other complex tasks like Memory Maze and proc-gen environments, as written in L576-579, it\'s hard for human experts to determine *exact* lengths by problem definition, although some bounds can still be derived, as shown in Table 1.\nWe will clarify how we compute the metrics in the camera-ready version. \n\n> Will you release code?\n\nYes, we have released our code in the supplementary material. We do not use a program to compute our metrics. \n\n> How does computing memory metrics scale with the task?\n\nThe complexity depends on the history space, which grows exponentially in a finite POMDP. \nThe worst-case complexity for reward and value memory lengths is $O(T (|\\mathcal O| + |\\mathcal A|)^T |\\mathcal A|)$.\nThe transition and policy memory lengths\' complexity is further multiplied by the cardinality of observation and action spaces.\n\n> The MiniGrid-Memory task already shares the same properties as the proposed Active T-Maze. \n\nThank you for pointing this out! We will add MiniGrid-Memory task into Table 1. While this task has the same properties as Active T-Maze, it is easier in terms of memory and credit assignment lengths.\nMiniGrid-Memory (sized $13\\times 13$) has its memory and credit assignment lengths of optimal policies $\\le 3\\times 13 = 39$, much smaller than the lengths of 250 in Active T-Maze.\nIn addition, MiniGrid-Memory\'s $147$-dim observations and sparse rewards add unnecessary complexity to evaluation. \nActive T-Maze simplifies the problem with 2-dim observations and dense penalties.  \nLastly, combined with Passive T-Maze, Active T-Maze can be used to evaluate the bottleneck of memory or credit assignment. These advantages motivate us to propose Active T-Maze. \n\n\n> What is the observation space of T-Mazes? \n\nThese tasks have 2-dim discrete observations indicating the position of an agent: Oracle, Start, Junction, Goal candidates, Corridors. We have revised the paper to include these details.\n\n> Passive T-Maze is useful but minimalistic. It only evaluates if a small bit can be stored and carried across long timespans in memory. \n\nYou are correct, and that was indeed our intention. We chose this minimalistic task to focus on ""memory length"" rather than ""memory capacity"" in terms of bits. With no prior evidence that RL agents can maintain a memory spanning $1500$ steps, this task precisely targets this capability. To avoid confusion, we have updated our abstract to state ""memorizing observations 1500 steps ago"" instead of ""memorizing 1500 observations"".\n\n> How about trying an image-based version of Passive T-Maze?\n\nIn fact, we have conducted experiments on an image-based version of Passive T-Maze, the Passive Visual Match.\n\n> The paper should clarify its focus on long-term memory, not capacity or robustness.\n\nYes, we will do it. \n\n> Missing related work [2,3,4]. If applicable, running these methods?\n\nThanks for pointing them out. We find that the hierarchical chunk attention memory [3] is related and will include it into the camera-ready version. It\'s worth noting that [3] uses observation reconstruction for sparse-reward tasks, unlike our model-free RL. Due to time limit, we cannot run experiments on this method. \n[2] and [4] are remotely related -- [2] focuses on recurrent-based RL  *convergence* and [4] uses pre-trained and frozen language models for RL.\n\n\n> The authors say GPT is less sample-efficient than LSTM in short-term memory tasks, but GPT outperforms LSTM in Passive Visual Match. Could the drop be due to observation/action spaces (continuous vs discrete)?\n\nYes, it is possible. As stated in L278 and L292, we find that GPTs are sample-efficient on Passive Visual Match, but not PyBullet, though both require short-term memory.\n\n>  Any intuition why GPT is less sample-efficient than LSTM on short-term memory tasks?  \n\nOur intuition is that GPTs have fewer inductive bias than LSTMs, thus generally require more data to learn. \n\n> How do long-term memory tasks relate to the SL setup on large datasets? \n\nWe did not relate them. \n\n> Do the authors imply that there are only long-term dependencies in large datasets for SL?  \n\nNo. \n\n> Morad et al. 2023 advises against comparing SL and RL.\n\nWe think **purely long-term memory tasks** in RL and SL are related. For example, Copy task [Arjovsky et al., ICML 2016]  is like an SL version of Passive T-Maze. LSTMs failed to solve the long-term Copy task due to gradient training issue, mirroring our findings in Passive T-Maze. \n\n> In L270 it\'d be good to explain what the actual task is.\n\nWe will add these descriptions in the camera-ready version. \n\n> Fig 5: what is optimal policy that lacks (long-term) credit assignment?\n\nSuch a policy maximizes its actions depending on *immediate* rewards only, according to definition of the credit assignment length. In Active T-Maze task, such a policy happens to be Markovian, but it can have memory in general. \nThis is a good spot, and we will clarify it in the camera-ready. \n\n\n> Do all figures show mean and std dev? This should be mentioned in captions.\n\nAll figures are generated by seaborn.lineplot that shows the mean and its 95\\% confidence interval, but not std dev. We will add these descriptions to the captions. \n\n> The last 3 sentences in Def. 1 can be moved to Def. 2, as they are on memory length and not context length.\n\nWe will separate the last three sentences from the paragraph to create a new paragraph for Def. 2. \n\n> Question on equation in L103?\n\nActually, these two are equivalent. For random variables $X,Y,Z$, $X\\perp Y \\mid Z$ is equivalent to $X \\perp Y,Z \\mid Z$, where $X = a_t$, $Y = h_{t-l_{ctx}(\\pi)+1:t-k}$, and $Z = h_{t-k+1:t}$ in this case. \n\n> The symbol k is reassigned, maybe using other symbols?\n\nWe will rename these symbols. '}}, {'summary': {'value': 'In this paper the authors consider the effectiveness of transformers for solving two kinds of RL problems: credit assignment and memory. To achieve their goal the authors develop rigorous definitions for memory and credit assignment so that different RL tasks can be understood and compared in these terms. The authors then review many well known RL problems from the literature and classify them according to their definitions. Going one step further the authors then propose a new RL task where the role of memory and credit assignment can be disambiguated. Finally, the authors perform empirical experiments on many of the previously analyzed RL tasks to understand when transformers shine and when they fall short.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The paper is accessible, rigorous, and timely. Great work. '}, 'weaknesses': {'value': '1. If I were to name anything it would be I wish the authors could have provided a little more on what they think potential solutions could be to the credit assignment problem when using transformers. The paper stands on its own without this, but the authors have clearly thought about the problem and their insights could be valuable.'}, 'questions': {'value': ""1. I'm curious given the time and thought the authors have put into this problem what they think may be a solution. Can we simply slap on a specific submodule to transformers to augment their credit assignment capabilities? Or do you think we need to develop fundamentally new architectures?""}, 'limitations': {'value': 'The authors have adequately addressed limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work aims to answer how the parametrization of policy in RL affects the performance of sparse-reward tasks that require memory and credit assignment. In particular, the authors are interested in when transformers perform well. The authors define in the POMDP settings their own criteria of how to quantify policy memory, and credit assignment. The authors go through a list of previous benchmarks to clarify which benchmarks require which, and design their own experiment which decouples the two effects. The authors conclude that while transformes do well in pure memory tasks, they do not show better credit assignment capabilities compared to LSTMs.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- The question that was posed was quite unique and interesting.\n- The authors do a convincing empirical study of which settings transformers perform better in, and the conclusions are aligned with empirical intuition.\n- Conducted analysis of previous benchmarks is extensive, and the authors have a good experiment design.\n'}, 'weaknesses': {'value': '- The motivations for memory length is reasonable as a quantiative metric, but I wonder if there are other quantitative criteria for judging memory and credit assignment. For policies with memory (i.e. recurrent), the definition seems less relevant since the policy can remember parts of all the information starting from time 0. On the other hand, the credit assignment length definition was novel and I found it quite relevant.\n'}, 'questions': {'value': '- One of the key discussion that seem to be missing is whether or not the policy has the ability to succesfully abstract states that matter. For example, both in works along the lines of MDP compression with bisimulation, or Approximate Information States, they hypothesize a reduced-order model of the POMDP that the policy could possibly have that is sufficient for predicting rewards.\n- I wonder if aside from credit assignment and history, if transformers are predicting states that truly matter for the task as well (which is partly a question of credit assignment, but less of a question of ""when"" something mattered.) For example, suppose a pixel-domain example that controls an agent, but the background constantly has something going on (e.g. humans may play tennis in the park when ducks are flying in the background). In this case excelling at pure memory is actually disadvantageous because the ducks are completely irrelevant to the task. \n- In operations research there are classes of ""submodular functions"", and these have provably efficient greedy algorithms that are quantifiably suboptimal. I wonder how this is connected to credit assignment length.'}, 'limitations': {'value': 'The authors have adequately addressed limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work explores the impact of memory and credit assignment in decision transformer architectures, presenting several significant claims. Regarding memory, the authors establish an upper bound on the memory length required for an optimal policy. In terms of credit assignment, they provide a lower bound on the number of future steps needed.\n\nMemory length is defined as the number of steps that an action distribution depends on, representing a more recent and shorter dependency than the entire input length. This length, is defined in relation to the value function, transition, and reward. \n\nCredit assignment length of the policy is defined as the number of future steps required for a greedy action to yield a higher discounted sum of rewards compared to a non-greedy action. \n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- This definitions of memory length and credit assignment length appear intuitive and sound.\n- Theorem 1 appears clear and mathematically sound.\n- A toy environment is presented to illustrate scenarios that are either heavily reliant on memory or credit assignment.  This experiment is intuitive and sound. In the memory task, transformers perform optimally in long memory length tasks, while LSTMs struggle with long-term memory. However, in more complex tasks, the results are not as clear-cut.  These results are significant to the DT community.\n- For credit assignment tasks, transformers do not outperform LSTMs and exhibit poor performance at longer credit assignment lengths. They also demonstrate lower sample efficiency compared to LSTMs.  Again, this results is significant to the DT community.\n- Overall, the experiments are well-designed, clear, and straightforward, providing a substantial contribution to the field of decision transformer research.\n\nThis work is highly novel and is the first to specifically investigate the benefits of transformers in either memory or credit assignment.'}, 'weaknesses': {'value': '- Can the authors provide any intuition on the failure of transformers and LSTM and transformers in the long term credit assignment tasks? I find it interesting that they both have the same performance trajectory. \n- It would be nice to see experimental evaluation of Transformers and LSTM in additional environments other than the toy tasks for better context.'}, 'questions': {'value': 'Above'}, 'limitations': {'value': 'Yes'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper proposes a set of metrics to measure and isolate the memory dependency of partially observable environments.\nThe authors illustrate that some currently existing benchmarks do not sufficiently isolate the memory of an agent.\nBased on their analysis they propose two versions of a T-Maze environment, one of which appropriately isolates memory.\nFurther, the authors investigate the effect of memory architecture on tasks that require long- and short-term memory. \nTransformer-based policies outperform recurrent policies on tasks that require long-term memory dependencies, \nwhile there seems to be no benefit on tasks that require short-term memory dependencies.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '**Significance:**\n\nI fully agree with the authors that prior works often conflate different effects and do not sufficiently isolate the memory component.\nTherefore metrics that help disentangle memory from other environmental effects are crucial.\n\n**Originality:**\n\nThe authors propose novel metrics that evaluate and isolate different aspects of POMDPs in RL, such as credit assignment and long-term memory.\nThe proposed metrics provide an important measure on the effect of memory and will be useful to facilitate future benchmark design and evaluation of new algorithms.\n\n**Quality:**\n\nQuality of theoretical contributions is high.'}, 'weaknesses': {'value': ""**Scalability:**\n\nI credit the authors for mentioning the complexity for computing c^M as limitation, but it seems that the computation of other metrics is also limited.\nFor example, l_{mem}(\\pi^\\asterisk) requires access to the optimal policy.\nFor the minimalistic TMazes it is straightforward to obtain this policy, how is it obtained for more complex tasks such as Psychlab? Does it involve human experts?\nHow is it computed for procedurally generated environments, where the optimal policy varies between levels?\nHow would this scale to more complex environments, given that human demonstrations may not necessarily be optimal?\n\n**Relevance of proposed environments:**\n\nThe authors propose two environments, namely Passive T-Maze and Active T-Maze to disentangle credit assignment from memory.\nThe Minigrid benchmark suite already provides a T-Maze environment that should exhibit the same characteristics as the proposed Active T-Maze, namely MiniGrid-Memory [1].\nPassive T-Maze could be useful, but it is very minimalistic and only evaluates whether a small bit of information can be stored and carried across long timespans in an agent's memory.\nThere is no mention of the observation space, but providing, say, image-based observation for Passive T-Maze, would increase its complexity and enable application of vision-based methods.\n\n**Interpretation of results:**\n\nThe authors mention that LSTM starts to falter at a memory length of 250 for Passive T-Maze.\nFigure 2, however, shows that LSTM can solve the same environment with a memory length of 750.\nThis suggests that some other effects might influenced LSTM training, such as hyperparameter tuning.\nMaybe the authors can improve the results of LSTM by further tuning of the method?\n\n**Clarity:**\n\nThe authors should clearly state that the paper focuses on long-term memory and does not consider other aspects, such as memory capacity, or robustness of memory to noise.\n\n**Missing relevant work:**\n\nThere is prior work that derives theoretical bounds on approximation error of history-based methods [2].\nFurther, other history-based approaches such as a hierarchical Transformer memory [3] and pretrained models as a memory module in RL [4], are not cited.\nIf applicable, adding these method in their experiments would strengthen the paper and might yield some more interesting findings.\n\n[1] Maxime Chevalier-Boisvert, Lucas Willems, and Suman Pal. Minimalistic Gridworld Environment for OpenAI Gym, 2018. Publication Title: GitHub repository. https://minigrid.farama.org/environments/minigrid/MemoryEnv/\n\n[2] Gandharv Patil et al., On learning history based policies for controlling markov decision processes. 2022.\n\n[3] Andrew Lampinen et al., Towards mental time travel: a hierarchical memory for reinforcement learning agents. NeurIPS 2021\n\n[4] Fabian Paischer et al., History compression via language models in reinforcement learning. ICML 2022\n""}, 'questions': {'value': '- The authors conclude that Transformers exhibit worse sample efficiency than LSTM on short-term memory tasks.\nIs there an intuition why that would be the case?\nOn Passive Visual Match, which requires short-term memory according to the authors, a GPT reaches higher return compared to LSTM.\nCould it be that the drop in performance is due to different observation/action spaces (continuous vs discrete) instead of long-term vs short-term memory?\n\n- In line 304 the authors claim that the success on long-term memory tasks for GPT2 is consistent with the tendency to perform well in the supervised learning setup on large datasets.\nThe authors draw an analogy here which lacks support.\nHow do long-term memory tasks relate to the supervised learning setup on large datasets?\nDo the authors imply here, that there are only long-term dependencies present in large datasets used for supervised learning?\nAlso, Morad et al. 2023 specifically advises against drawing comparisons between supervised learning and RL.\n\n- What is the observation space for the Active/Passive T-Mazes?\n\n- In line 270 it would be good to explain what the actual task is in Passive Visual Match, prior to discussion on the reward function.\n\n- Figure 4 left shows superiority of GPT2 over LSTM, for Passive Visual Match the difference is not as pronounced, a significance test would benefit the interpretation of these results.\n\n- Figure 5: it would be good to clarify what is meant by ""optimal policies that lack (long-term) credit assignment""\nI assume it refers to a markovian policy, since the return on T-Maze is 0.5.\n\n- Do all figures show mean and standard deviation?\nThis should be mentioned in the figure captions.\n\n- The last three sentences in Definition 1 could be moved to Definition 2, since they are about memory length and not context length.\n\n- Equation in line 103: I think there should be $t - l_{ctx}(\\pi)+1:k$ instead of $t - l_{ctx}(\\pi)+1:t$ in the subscript after the conditional independence, right?\n\n- The symbol k is reassigned repeatedly which is a bit confusing, the authors may consider using different symbols.\n\n- Will the authors make the code for reproducing their results and computing their metrics publicly available?\n'}, 'limitations': {'value': 'The authors have adressed limitations regarding computation of the metrics in more complex environments. \nHowever, it is not clear from the paper, how well the other metrics scale with complexity of the environment, or how the optimal policies are obtained, i.e. does that require human demonstration?\nIn the case of procedurally generated environments (which are commonly used nowadays) would that require extensive ""labeling"" by humans?\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'When Do Transformers Shine in RL? Decoupling Memory from Credit Assignment'}, 'authors': {'value': ['Tianwei Ni', 'Michel Ma', 'Benjamin Eysenbach', 'Pierre-Luc Bacon']}, 'authorids': {'value': ['~Tianwei_Ni1', '~Michel_Ma1', '~Benjamin_Eysenbach1', '~Pierre-Luc_Bacon1']}, 'keywords': {'value': ['Memory-based RL', 'Transformers', 'Credit Assignment', 'Online RL', 'Model-free RL']}, 'abstract': {'value': 'Reinforcement learning (RL) algorithms face two distinct challenges: learning effective representations of past and present observations, and determining how actions influence future returns. Both challenges involve modeling long-term dependencies. The Transformer architecture has been very successful to solve problems that involve long-term dependencies, including in the RL domain. However, the underlying reason for the strong performance of Transformer-based RL methods remains unclear: is it because they learn effective memory, or because they perform effective credit assignment? After introducing formal definitions of memory length and credit assignment length, we design simple configurable tasks to measure these distinct quantities. Our empirical results reveal that Transformers can enhance the memory capability of RL algorithms, scaling up to tasks that require memorizing observations $1500$ steps ago. However, Transformers do not improve long-term credit assignment. In summary, our results provide an explanation for the success of Transformers in RL, while also highlighting an important area for future research and benchmark design. Our code is open-sourced at https://github.com/twni2016/Memory-RL.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'Transformers can help learn long-term memory but not long-term credit assignment in online model-free RL.'}, 'pdf': {'value': '/pdf/4f8f859eec245e8a708d5fb1a058805e0b53f20f.pdf'}, 'supplementary_material': {'value': '/attachment/1f016e9f6bafb483efcdae04ecee28b89ecfb28d.pdf'}, '_bibtex': {'value': '@inproceedings{\nni2023when,\ntitle={When Do Transformers Shine in {RL}? Decoupling Memory from Credit Assignment},\nauthor={Tianwei Ni and Michel Ma and Benjamin Eysenbach and Pierre-Luc Bacon},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=APGXBNkt6h}\n}'}, 'paperhash': {'value': 'ni|when_do_transformers_shine_in_rl_decoupling_memory_from_credit_assignment'}}]"
"['Siliang Zeng', 'Chenliang Li', 'Alfredo Garcia', 'Mingyi Hong']",NeurIPS,When Demonstrations meet Generative World Models_ A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning,https://neurips.cc/virtual/2023/oral/73824,2023," Offline inverse reinforcement learning (Offline IRL) aims to recover the structure of rewards and environment dynamics that underlie observed actions in a fixed, finite set of demonstrations from an expert agent. Accurate models of expertise in executing a task has applications in safety-sensitive applications such as clinical decision making and autonomous driving. However, the structure of an expert's preferences implicit in observed actions is closely linked to the expert's model of the environment dynamics (i.e. the ``world''). Thus, inaccurate models of the world obtained from finite data with limited coverage could compound inaccuracy in estimated rewards. To address this issue, we propose a bi-level optimization formulation of the estimation task wherein the upper level is likelihood maximization based upon a conservative model of the expert's policy (lower level). The policy model is conservative in that it maximizes reward subject to a penalty that is increasing in the uncertainty of the estimated model of the world. We propose a new algorithmic framework to solve the bi-level optimization problem formulation and provide statistical and computational guarantees of performance for the associated optimal reward estimator. Finally,  we demonstrate that the proposed algorithm outperforms the state-of-the-art offline IRL and imitation learning benchmarks by a large margin, over the continuous control tasks in MuJoCo and different datasets in the D4RL benchmark.",Oral 1A RL,https://openreview.net/pdf?id=oML3v2cFg2,https://openreview.net/forum?id=oML3v2cFg2,oML3v2cFg2,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': ""The submitted paper was reviewed by 5 knowledgeable reviewers, all of whom recommended acceptance of the paper. Several initial concerns/questions were answered convincingly by the authors in their rebuttal and discussions with the reviewers. Hence, in line with the reviewers' recommendations, I am recommending acceptance of the paper. The authors are encouraged to further improve their paper by incorporating the feedback of the reviewers and relevant parts of the discussions with them in the final version of their paper.""}}, {'title': {'value': 'Many thanks for your comments and positive feedback'}, 'comment': {'value': 'We truly appreciate your detailed comments and review! We will include these clarifications in our revised version.'}}, {'comment': {'value': 'I thank the authors for responding to my comments and for providing these clarifications. Based on the explanation provided, I am happy to increase my score.'}}, {'title': {'value': 'Many thanks for your positive feedback to our response'}, 'comment': {'value': 'We truly thank you for taking time to review our paper and recognizing the contributions of this work!'}}, {'title': {'value': 'Many thanks for your comments and positive feedback'}, 'comment': {'value': 'We truly appreciate your detailed review and insightful comments! We will include the discussions and the proposed modifications in our revised version.'}}, {'comment': {'value': 'Thanks for the replies. I have adjusted my evaluation based on them.'}}, {'comment': {'value': 'Thank you for your clarifications! I have adjusted my score accordingly, assuming you make the proposed modifications to the text.'}}, {'title': {'value': 'Thank you for your positive evaluations'}, 'comment': {'value': 'We sincerely appreciate you for taking time to review our paper and thank you for recognizing the contributions of this work.'}}, {'title': {'value': 'Many thanks for your comments and positive feedback'}, 'comment': {'value': 'We truly appreciate your detailed review and insightful comments. We will discuss this paper and the translation to policy errors in our revised version.'}}, {'comment': {'value': 'Thank you for the detailed answers and the extra experiments.\nI believe the authors have addressed all my questions or concerns (especially for weakness 2, my understanding is that this will translate to policy error due to [1]), I am happy to increase the score from 6 to 8.\n\n[1]: Xu, Tian, Ziniu Li, and Yang Yu. ""Error bounds of imitating policies and environments."" Advances in Neural Information Processing Systems 33 (2020): 15737-15749.'}}, {'title': {'value': 'Thanks '}, 'comment': {'value': 'Many thanks for these insightful answers, that well confortate the score I assigned to this submission.'}}, {'rebuttal': {'value': 'We thank the detailed review and comments from all reviewers.\n\nIn the global response, we present a conclusion here and we will include it into our final version:\n\nIn this paper, we model the offline Inverse Reinforcement Learning (IRL) problem from a maximum likelihood estimation perspective. We develop a computationally-efficient algorithm that effectively recovers the underlying reward function and its associated optimal policy. We have also established statistical and computational guarantees for the performance of the recovered reward estimator. Through extensive experiments, we demonstrate that our algorithm outperforms existing benchmarks for offline IRL and Imitation Learning, especially on high-dimensional robotics control tasks. One limitation of our method is that we focus solely on aligning with expert demonstrations during the reward learning process. In an ideal scenario, reward learning should incorporate diverse metrics and data sources, such as expert demonstrations and preferences gathered through human feedback. One direction for future work is to broaden our algorithm framework and theoretical analysis for a wider scope in reward learning.\n\n'}, 'pdf': {'value': '/pdf/89df6067faadb91fae502145bc2b98ac0b6b999a.pdf'}}, {'rebuttal': {'value': 'We thank Reviewer 5szs for your positive comments and recognizing the importance of this work. Below, we address the reviewer\'s comments in a point-by-point manner.\n\n**Our Response to Weakness 1:** We appreciate the reviewer for raising this insightful question. In our practical implementation, we utilize a set of ensemble models to construct the penalty function. It\'s important to note that the penalty function is based on heuristic design and relies solely on the estimated dynamics model. Consequently, once the construction of the estimated dynamics model is complete, the associated penalty $U(s,a)$ for each state-action pair $(s,a)$ becomes a fixed constant when using the proposed alternating algorithm for reward/policy update steps. It is essential to differentiate our approach from model-based offline reinforcement learning, where the reward function remains fixed and the penalty function plays a crucial role in alleviating distribution shifts. In contrast, in IRL, the parameterized reward function is kept adjusted and optimized to align with expert demonstrations. Thus, the penalty function $U(s,a)$, being a fixed regularization term added to the parameterized reward function, does not significantly impact the theoretical analysis of our offline IRL method. This characteristic makes model-based offline IRL less sensitive to the construction of the penalty function U, as compared to model-based offline reinforcement learning. \n\nEmpirically, we\'ve observed that the uncertainty-based penalty function effectively mitigates distribution shift effects during policy optimization in the estimated dynamics model, consistent with [R1]. In offline IRL settings, where a suitable initialization for the reward function may be lacking, the agent might suffer from distribution shifts in the initial training stages. Including the penalty function to regularize the agent\'s behavior and guide it to remain in the low-certainty region can facilitate the imitation of expert demonstrations. Furthermore, since the policy optimization subroutine in our proposed algorithm utilizes the practical implementations of model-based RL methods that explicitly incorporates the penalty function, it is natural to include the penalty function in our approach and theoretical analysis. \n\n[R1] Yu, Tianhe, et al. ""Mopo: Model-based offline policy optimization."" Advances in Neural Information Processing Systems 33 (2020): 14129-14142.\n\n**Our Response to Weakness 2:** We appreciate the reviewer for raising this insightful question. To address the reviewer\'s question, we provide a supplementary experiment on three different choices of U. Below, we will elaborate the experiment details.\n\nTo estimate the model uncertainty by ensembles models, we have independently trained an ensemble of $N$ estimated dynamics models $\\\\{ P\\_{\\phi,\\varphi}^i(s\\_{t+1}|s_t,a_t)=\\mathcal{N}(\\mu^i\\_{\\phi}(s_t,a_t), \\Sigma^i\\_{\\varphi}(s_t,a_t)) \\\\}\\_{i=1}^N$ via likelihood maximization over transition samples. Here, each model estimates the location of the next state by gaussian distributions. Three common choices of the penalty function have been considered: 1) Max Aleatoric: $U(s,a)=-\\max\\_{i = 1,\\cdots,N} || \\Sigma^i\\_{\\varphi}(s,a) ||_F$, 2) Ensemble Variance: $U(s,a) = -(\\frac{1}{N} \\sum\\_{i=1}^N (\\Sigma^i\\_{\\varphi}(s,a))^2 + \\frac{1}{N} \\sum\\_{i=1}^N (\\mu^i\\_{\\phi}(s,a))^2 - (\\bar{\\mu}(s,a))^2)$ where $\\bar{\\mu}(s,a) = \\frac{1}{N}\\sum\\_{i=1}^N \\mu^i\\_{\\phi}(s,a)$, 3) Ensemble Standard Deviation: $U(s,a) = -\\sqrt{\\frac{1}{N} \\sum\\_{i=1}^N (\\Sigma^i\\_{\\varphi}(s,a))^2 + \\frac{1}{N} \\sum\\_{i=1}^N (\\mu^i\\_{\\phi}(s,a))^2 - (\\bar{\\mu}(s,a))^2}.$ We evaluate the effect of the three penalty functions in our proposed algorithm on HalfCheetah. We provide 10 expert trajectories and utilize three transition datasets (medium-expert, medium, medium-play) from D4RL. We show the numerical results in the following table:\n\n| HalfCheetah | Ensemble Standard Deviation | Ensemble Variance | Max Aleatoric |  \n|----------|----------|----------|----------|  \n| Medium-Expert | $11137.21 \\pm 872.47$ | $10941.80 \\pm 878.90$ | $10752.50 \\pm 655.96$ |  \n| Medium-Replay | $8214.46 \\pm 491.64$ | $8142.77 \\pm 621.12$ | $8612.29 \\pm 108.25$ |  \n| Medium | $6324.95 \\pm 556.42$ | $6454.43 \\pm 664.95$ | $7973.86 \\pm 108.86$ |\n\nAccording to our supplementary experiments, we observe that these three choices of penalty functions lead to similar final performance in our offline IRL method.\n\n**Our Response to Question 1:** We thank the reviewer for raising this insightful question. As we clarified in the response to Weakness 1, the penalty $U(s,a)$ is a fixed regularization term added on the reward function $r(s,a;\\theta)$ and the reward function $r(s,a;\\theta)$ will be updated every reward optimization step. Given that the reward function will be updated to align with expert demonstrations, the theoretical analysis will not heavily rely on the (fixed) penalty function. \n\nTo better understand the effect of the penalty function, we provide a supplementary experiment on three different choices of U. We observe the final performance of the proposed offline IRL algorithm with different choices of penalty function will not deviate from each other by too much, since the penalty function represents a constant regularization term while the magnitude of the parameterized reward function will continuously update during the reward learning process.. \n\nWe also note that the uncertainty estimation is still an active research problem and the theoretical understanding is limited, especially in the context of neural networks. Hence, we utilize common heuristics design of the penalty function from the literature in model-based offline RL to develop our algorithm. We would like to thank the reviewer’s insightful comments again and we will consider developin theoretical understanding on the impact of penalty function in model-based offline IRL as one of the directions for future work. \n'}}, {'rebuttal': {'value': 'We thank the reviewer for the detailed review of the paper and the valuable feedback. Below, we address the reviewer\'s comments in a point-by-point manner.\n\n**Response to Weakness 1:** We thank the reviewer for this good question. As we discussed in Section. 6, we constructed an ensemble of estimated dynamics models as $ \\\\{ \\hat{P}^{i}\\_{\\phi,\\varphi}(\\cdot|s,a) = \\mathcal{N}( \\mu^{i}\\_{\\phi}(s,a), \\Sigma^{i}\\_{\\varphi}(s,a) ) \\\\}\\_{i=1}^N$ where each one models the location of the next state by Gaussian distribution. Under Gaussian distributions, it is achievable to eventually get from every state to every other state with positive probability. Hence, the ergodicity holds in our estimated dynamics model in practice.\n\n**Response to Weakness 2:** We appreciate the reviewer for raising this insightful question. The general answer is that $\\varepsilon$-error on the MLE implies that the recovered policy $\\pi_{\\hat{\\theta}}$ is $\\varepsilon$-close to the expert policy $\\pi^E$ measured by the KL divergence.\n\nIn our formulation eq (2a) - (2b), the MLE objective follows $L(\\theta) := \\mathbb{E}\\_{\\tau^E \\sim (\\eta,\\pi^E,P)}[ \\sum\\_{t=0}^{\\infty} \\gamma^t \\log \\pi\\_{\\theta}(a_t|s_t) ]$. According to the definition of the state visitation measure $d^E(s)$ under the expert policy $\\pi^E$ where $d^E(s) := (1-\\gamma) \\sum\\_{t=0}^{\\infty} \\gamma^t P^{\\pi^E}(s_t = s|s_0 \\sim \\eta)$, we can rewrite the MLE objective as below: $L(\\theta) := \\mathbb{E}\\_{\\tau^E \\sim (\\eta,\\pi^E,P)}[ \\sum\\_{t=0}^{\\infty} \\gamma^t \\log \\pi\\_{\\theta}(a_t|s_t) ] = \\frac{1}{1-\\gamma}\\mathbb{E}\\_{s \\sim d^E(\\cdot), a \\sim \\pi^E(\\cdot|s)}[ \\log \\pi\\_{\\theta}(a|s) ].$\n\nTherefore, the $\\varepsilon$-error on the MLE implies that $L(\\theta^*) - L(\\hat{\\theta}) = \\frac{1}{1-\\gamma}\\mathbb{E}\\_{s\\sim d^E(\\cdot), a \\sim \\pi^E(\\cdot|s)}[\\log \\pi\\_{\\theta^*}(a|s) - \\log \\pi\\_{\\hat{\\theta}}(a|s)] = \\frac{1}{1-\\gamma}\\mathbb{E}\\_{s\\sim d^E(\\cdot), a \\sim \\pi^E(\\cdot|s)}[\\log  \\frac{\\pi\\_{\\theta^*}(a|s)}{\\log \\pi\\_{\\hat{\\theta}}(a|s)} ] \\leq \\varepsilon.$ When the expert trajectories are consistent with the optimal policy under a ground truth reward parameter $\\theta^*$, we have $\\pi^E = \\pi\\_{\\theta^*}$. Due to this property, we can show $L(\\theta^*) - L(\\hat{\\theta}) = \\frac{1}{1-\\gamma}\\mathbb{E}\\_{s\\sim d^E(\\cdot), a \\sim \\pi^E(\\cdot|s)}[\\log  \\frac{\\pi\\_{\\theta^*}(a|s)}{\\log \\pi\\_{\\hat{\\theta}}(a|s)} ] = \\frac{1}{1-\\gamma}\\mathbb{E}\\_{s\\sim d^E(\\cdot), a \\sim \\pi^E(\\cdot|s)}[\\log  \\frac{\\pi^E(a|s)}{\\log \\pi\\_{\\hat{\\theta}}(a|s)} ] = \\frac{1}{1-\\gamma}\\mathbb{E}\\_{s\\sim d^E(\\cdot)} [ D\\_{KL}( \\pi^E(\\cdot|s) || \\pi\\_{\\hat{\\theta}}(\\cdot|s) ) ] \\leq \\varepsilon.$ Hence, we can show the $\\varepsilon$-error on the MLE implies that the recovered policy $\\pi\\_{\\hat{\\theta}}$ is $\\varepsilon$-close to the expert policy $\\pi^E$ measured by the KL divergence.\n\n**Response to Weakness 3:** We appreciate the reviewer’s comments. Regarding the training of BC, we assess the checkpoints generated throughout the training process and monitor the performance of the resulting policies at every few updates. Once the performance of BC stops to achieve further improvement (in terms of the average rewards in episodes) within 20 training epochs, we will use the updated policy to generate ten rollout episodes and then record the average reward of the rollout episodes as the final performance measure. \n\nMoreover, it is important to note that for benchmark algorithms BC, ValueDice, and CLARE, we have utilized their official implementations, incorporating their default hyper-parameters, which have been fine-tuned beforehand.\n\nBelow, we provide the sources for the official implementations of the benchmark algorithms, which we have mentioned in Appendix A (the section of experiment details):\n\nBC, ValueDice: https://github.com/google-research/google-research/tree/master/value_dice\n\nCLARE: https://openreview.net/forum?id=5aT4ganOd98\n\n**Response to Weakness 4:** We appreciate this suggestion. The numerical results are included in the PDF in global response (see https://openreview.net/forum?id=oML3v2cFg2&noteId=oCZvqhc8PI).\n\n**Response to Question 1:** Yes. When the reward function is $r(\\cdot,\\cdot;\\theta)$, we use $\\pi_{\\theta}$ to denote the optimal policy obtained in the estimated dynamics model.\n\n**Response to Question 2:** We appreciate the reviewer for this good question. The reason we define $\\varepsilon \\in (0,2)$ is because we use $\\varepsilon$ to bound $\\mathbb{E}\\_{(s,a)\\sim d^E(\\cdot,\\cdot)}[|| P(\\cdot|s,a) -  \\hat{P}(\\cdot|s,a)||_1]$ and the maximum dynamics mismatch error under L1 norm is bounded by 2.\n\nBased on the definition of the L1 distance, we have \n$|| P(\\cdot | s,a) - \\hat{P}(\\cdot | s,a) ||_1 = \\sum\\_{s^\\prime \\in \\mathcal{S}} | P(s^\\prime | s,a) - \\hat{P}(s^\\prime | s,a) | \\in [0,2]$. When two distributions perfectly match, their L1 distance is 0, while a complete mismatch between distributions results in an L1 distance of 2.\n\nHence, when analyzing sample complexity, we define $\\varepsilon \\in (0,2)$ to bound the error $\\mathbb{E}\\_{(s,a)\\sim d^E(\\cdot,\\cdot)}[|| P(\\cdot|s,a) -  \\hat{P}(\\cdot|s,a)||_1]$.\n\n**Response to Typo 1:** We will explicitly define $\\gamma \\in (0,1)$ in our paper.\n\n**Response to Typo 2:** We appreciate the comments. There is one typo in the term $P(s_t = s | s_0 \\sim \\eta)$, which should be corrected as $P^{\\pi}(s_t = s | s_0 \\sim \\eta ).$ Under any fixed policy , the term $P^{\\pi}(s_t = s | s_0 \\sim \\eta )$ denotes the probability that $s_t = s$ at time step t when $s_0$ is sampled from $\\eta(\\cdot)$ and the actions in the MDP are sampled from $\\pi$. \n\nHence, the state-action visitation measure $d^{\\pi}\\_{P}(s,a)$ in line 95 follows: $d^{\\pi}_{P}(s,a):= (1 - \\gamma) \\pi(a|s) \\sum\\_{t=0}^{\\infty} \\gamma^t P^{\\pi}(s_t = s | s_0 \\sim \\eta ).$\n\n**Response to Typo 3:** We appreciate the comments. $\\epsilon$ is a typo and we should correct it as $\\varepsilon$.\n\n**Response to Typo 4:** We will include the space after ""2)"".'}}, {'rebuttal': {'value': ""We thank the reviewer for the detailed review of the paper and the valuable feedback. Below, we address the reviewer's questions in a point-by-point manner.\n\n**Response to Question 1:** We appreciate this question raised by the reviewer. This question indeed helps us find a typo in the term $P(s_t=s|s_0\\sim\\eta)$, which should be corrected as $P^\\pi(s_t=s|s_0\\sim\\eta)$. \n\nUnder any fixed policy $\\pi(a|s)$ and transition function $P(s^\\prime | s,a)$, the term $P^\\pi(s_t=s|s_0\\sim\\eta)$ denotes the probability that $s_t = s$ at time step t when $s_0$ is sampled from the initial state distribution $\\eta(\\cdot)$ and the actions $\\{a_0 , a_1, …, a_{t-1}\\}$ in the Markov decision process are sampled from the policy $\\pi$. \n\nTo avoid potential confusion, under any policy $\\pi$ and transition function $P$, let us correct the typo and rewrite the definition of the corresponding state-action visitation measure $d^\\pi\\_{P}(s,a)$ as below: $d^\\pi\\_{P}(s,a) := (1 - \\gamma) \\pi(a|s) \\sum\\_{t=0}^{\\infty} \\gamma^t P^\\pi(s_t = s | s_0 \\sim \\eta)$.\n\nHence, in Eq (5), the state-action visitation measure under the expert policy $\\pi^E$ is defined as below:\n$d^E(s,a) := (1 - \\gamma)  \\pi(a|s) \\sum\\_{t=0}^{\\infty} \\gamma^t P^{\\pi^E}(s_t = s | s_0 \\sim \\eta  )$.\n\n**Response to Question 2:** In (iii), we have shown that the objective function $L(\\theta)$ can be expressed as $L(\\theta)=\\sum\\_{t=0}^{\\infty} \\gamma^t \\mathbb{E}_{(s_t,a_t)\\sim(\\eta,\\pi^E,P)}[ r(s_t,a_t;\\theta) + U(s_t,a_t) + \\gamma \\mathbb{E}\\_{s\\_{t+1} \\sim \\hat{P}(\\cdot|s_t,a_t) }[V\\_{\\theta}(s\\_{t+1})] ] - \\sum\\_{t=0}^{\\infty}\\gamma^t \\mathbb{E}\\_{s_t \\sim (\\eta,\\pi^E,P)}[V\\_{\\theta}(s_t)].$   \n\nBased on the equation in (iii), we can further write down the following equality: $L(\\theta)=(\\sum\\_{t=0}^{\\infty} \\gamma^t \\mathbb{E}_{(s_t,a_t)\\sim(\\eta,\\pi^E,P)}[ r(s_t,a_t;\\theta) + U(s_t,a_t) ]  + \\sum\\_{t=0}^{\\infty} \\gamma^{t+1} \\mathbb{E}\\_{(s_t,a_t)\\sim(\\eta,\\pi^E,P),s\\_{t+1} \\sim \\hat{P}(\\cdot|s_t,a_t)}[V\\_{\\theta}(s\\_{t+1})] ) - (\\mathbb{E}\\_{s_0 \\sim \\eta(\\cdot)}[V\\_{\\theta}(s_0)] + \\sum\\_{t=0}^{\\infty} \\gamma^{t+1} \\mathbb{E}\\_{s\\_{t+1} \\sim (\\eta,\\pi^E,P)}[V\\_{\\theta}(s\\_{t+1})] ).$\n\nThen it leads to the equality below the one labeled (iii) by interchanging terms.\n\n**Response to Question 3:**  In the first equation of eq. (30), we have obtained the following equation of the term T2:\n$ T_2 =  \\sum\\_{t=0}^{\\infty} \\gamma^{t+1} \\mathbb{E}_{(s_t,a_t)\\sim(\\eta,\\pi^E,P)}[\\sum\\_{s\\_{t+1} \\sim \\mathcal{S}} V\\_{\\theta}(s\\_{t+1}) (\\hat{P}(s\\_{t+1} | s_t, a_t) - P(s\\_{t+1} | s_t, a_t))]$\n\nHere, recall that we have defined $P^{\\pi^E}(s_t=s|s_0 \\sim \\eta)$ as the probability that $s_t=s$ when $s_0$ is sampled from the initial state distribution $\\eta(\\cdot)$ and the actions in the MDP are sampled from the expert policy $\\pi^E$. Hence, we can obtain the second equality in (30): $T_2 = \\gamma \\sum\\_{t=0}^{\\infty} \\sum\\_{s \\in \\mathcal{S}, a\\in \\mathcal{A}} \\gamma^t P^{\\pi^E}(s_t = s|s_0\\sim \\eta) \\pi^E(a_t = a|s_t = s)( \\sum\\_{s^\\prime \\in \\mathcal{S}} V\\_{\\theta}(s^{\\prime}) (\\hat{P}(s^{\\prime} | s_t=s, a_t=a) - P(s^{\\prime} | s_t=s, a_t=a)) ).$\n\nThen we can further express the term $T_2$ as below:\n$T_2 = \\gamma \\sum\\_{s \\in \\mathcal{S}, a\\in \\mathcal{A}} ( \\pi^E(a|s) \\sum\\_{t=0}^{\\infty} \\gamma^t P^{\\pi^E}(s_t = s|s_0 \\sim \\eta)) \\cdot ( \\sum\\_{s^\\prime \\in \\mathcal{S}} V\\_{\\theta}(s^{\\prime}) (\\hat{P}(s^{\\prime} | s, a) - P(s^{\\prime} | s, a)) )$.\n\nGiven the expert policy $\\pi^E$, recall that we have defined the corresponding state-action visitation measure as $d^E(s,a) :=(1-\\gamma)\\pi^E(a|s) \\sum\\_{t=0}^{\\infty} \\gamma^t P^{\\pi^E}(s_t =s|s_0 \\sim \\eta).$\nThen we obtain the following expression of the term $T_2$ as below:\n$T_2 = \\frac{\\gamma}{1 - \\gamma} \\sum\\_{s \\in \\mathcal{S}, a\\in \\mathcal{A}} d^E(s,a) \\cdot ( \\sum\\_{s^\\prime \\in \\mathcal{S}} V\\_{\\theta}(s^{\\prime}) (\\hat{P}(s^{\\prime} | s, a) - P(s^{\\prime} | s, a)) ).$\n\nFinally, we can show the last equality in eq (30):\n$T_2 = \\frac{\\gamma}{1 - \\gamma} \\mathbb{E}\\_{(s,a)\\sim d^E(\\cdot, \\cdot)}[ \\sum\\_{s^\\prime \\in \\mathcal{S}} V\\_{\\theta}(s^{\\prime}) (\\hat{P}(s^{\\prime} | s, a) - P(s^{\\prime} | s, a))  ].$\n\n**Response to Question 4:** We thank the reviewer for pointing out this typo. We will correct it in our paper.\n\n**Response to Question 5:** We thank the reviewer for raising the question on the definition of the state-action visitation measure. The question indeed helps us find a typo in the definition of the state-action visitation measure. As we clarified in the response to Question 1, under any policy $\\pi$ and transition function $P$, the corresponding state-action visitation measure $d^{\\pi}\\_{P}(s,a)$ is defined as below: $d^{\\pi}\\_{P}(s,a) := (1 - \\gamma) \\pi(a|s) \\sum\\_{t=0}^{\\infty} P^\\pi(s_t = s | s_0 \\sim \\eta)$.\nHere, $P^\\pi(s_t=s|s_0\\sim\\eta)$ denotes the probability that $s_t = s$ when the actions in the MDP are sampled from the policy $\\pi$ and the initial state $s_0$ is sampled from the initial state distribution $\\eta(\\cdot)$.\n\nWe hope our correction of the typo and the corrected definition of the state-action visitation measure can address the reviewer’s question, and can improve the readability of our paper.""}}, {'rebuttal': {'value': 'We thank the reviewer for the detailed review of the paper and the valuable feedback. Below, we address the reviewer\'s comments in a point-by-point manner.\n\n**Response to Weakness 1:** We will address your comments to improve the readability of the paper. \n\n**Response to Weakness 2:** We appreciate the reviewer’s comments. In our paper, in fact, we have utilized small datasets to evaluate the performance of our proposed algorithm when the coverage of the expert-visited state-action space is limited. To address some potential misunderstanding regarding our experiment, we would like to clarify that **in our work, one expert demonstration corresponds to one transition sample $(s, a, s^\\prime)$ from the expert trajectories.** We have explicitly mentioned this in Appendix A and the caption of Table 2.  In Fig. 2 -4, we respectively report the performance of our proposed algorithm when five trajectories (5,000 transition samples), one trajectory (1,000 transition samples) and ten trajectories (10,000 transition samples) are available.\n\n**Response to Weakness 3:** We appreciate the reviewer’s suggestion. We provide a conclusion section in the global response and we kindly refer the reviewer to check it (see https://openreview.net/forum?id=oML3v2cFg2&noteId=oCZvqhc8PI).\n\n**Response to Question 1:** We appreciate the reviewer for raising this insightful question. The general answer that the discounted log-likelihood objective is derived from the dual problem of the classic formulation maximum entropy (MaxEnt) IRL.\n\nIn the literature of MaxEnt IRL [1], the problem aims to learn a (linearly parameterized) reward that can induce a policy to achieve the same expected reward as the expert trajectories while maximizing its entropy. Under infinite horizon MDP, the existing results have shown that the dual problem of MaxEnt IRL is the maximization of the “discounted” log-likelihood over expert trajectories on an optimal policy which solves an underlying entropy-regularized MDP (see Theorem 1 in [2]). This fundamental result justifies the use of discounting in the log-likelihood term.\n\n**Response to Question 2:** The general answer is that the entropy term in our formulation eq. (2b) is translated from the maximum entropy objective of MaxEnt IRL.\n\nAs we discussed in the response to Question 1, in online IRL with linear parameterized reward, it has been shown that the dual problem of MaxEnt IRL is a maximum likelihood formulation of IRL where the optimal policy is modeled as a solution to a entropy-regularized MDP. Here, in the derivation of maximum likelihood formulation of IRL, the entropy term in the objective of MaxEnt IRL has been translated to the model of agent’s behavior. Hence, in this paper, when we propose the maximum likelihood formulation of IRL with nonlinear reward parameterization in the offline setting, we include the entropy term in the definition of the soft value function and soft Q-function in eq. 3a - 3b.\n\n**Response to Question 3:** We would like to clarify that our theoretical analysis aligns with the algorithmic framework of our practical implementations, since we have taken the approximation error into account in our theoretical analysis. \n\nMore specifically, we have considered the approximation error from the soft actor-critic (SAC) algorithm [3] into our policy optimization subroutine eq. 13 - 14. Our theoretical analysis does not require the policy or the soft Q-function to be optimal at each step, therefore, running a few steps of the soft actor-critic algorithm will be sufficient. At each step k, we first run policy evaluation steps (critic steps) to approximate the corresponding soft Q-function $Q_k$ of the current policy $\\pi_k$ by $\\hat{Q}\\_k$, as shown in eq. 13. Then we run the soft policy iteration (action steps) to obtain the updated policy $\\pi_{k+1}(a|s) \\propto \\exp \\hat{Q}_k(s,a)$, as shown in eq. 14. Note that our policy optimization subroutine matches the practical implementation of SAC. Moreover, the approximation error $||\\hat{Q}_k - Q_k ||\\_{\\infty}$ in estimating the soft Q-function has been explicitly considered in our theoretical analysis (see Theorem 2).\n\n**Response to Question 4:** The general answer is that the maximum likelihood formulation is a broader problem formulation compared with MaxEnt IRL. First of all, as we discussed in the response to Question 1, the MaxEnt IRL is based on the online IRL setting with linear reward. In this case, the maximum likelihood IRL is the dual problem to MaxEnt IRL. Hence, we can find resemblance between the maximum likelihood IRL and MaxEnt IRL. However, since MaxEnt IRL is limited to the online setting with linear reward, its formulation is incompatible with broader problems. Therefore, the maximum likelihood IRL formulation offers greater flexibility to model IRL problems in a broader scope. It can be applied effectively to scenarios involving either linear or nonlinear reward parameterization, as well as online or offline settings.\n\n\n**Response to Reviewer\'s Suggestion:** We appreciate the reviewer’s suggestion. As we clarified in our response to Weakness 2, one expert demonstration in our paper means one transition sample $(s, a, s^\\prime)$ collected from an expert trajectory. In our numerical results, we have considered the setting that only 1 / 5 / 10 expert trajectories are available. \n\n**Response to Limitations:** We have include them in the section of Limitations and broader impacts in Appendix.\n______\n[1] Ziebart, Brian D. Modeling purposeful adaptive behavior with the principle of maximum causal entropy. Carnegie Mellon University, 2010.\n\n[2] Zeng, Siliang, et al. ""Maximum-likelihood inverse reinforcement learning with finite-time guarantees."" Advances in Neural Information Processing Systems 35 (2022): 10122-10135.\n\n[3] Haarnoja, Tuomas, et al. ""Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor."" International conference on machine learning. PMLR, 2018.\n'}}, {'rebuttal': {'value': ""We thank the reviewer for the detailed review of the paper and the valuable feedback. Below, we address the reviewer's comments in a point-by-point manner.\n\n**Response to Weakness 1&Question 1:** We appreciate the reviewer’s comments. However, we do not agree that the proposed alternating optimization algorithm in this work is identical to the one presented in [21]. In this response, we would like to highlight the key difference between our proposed algorithm and the one presented in [21]. \n\nCompared with the online IRL algorithm presented in [21], one key difference is that our proposed offline IRL algorithm solves a **much harder** IRL problem (2a) - (2b) than the one in [21]. This is due to the fact that our outer objective $L(\\theta)$ in eq (2a) is defined on the *ground-truth* dynamics model P while the inner problem in eq (2b) considers policy optimization in the *estimated* dynamics model $\\hat{P}$.  Due to the existence of the dynamics model mismatch, we turn to optimize a novel surrogate objective by developing a *new* algorithm. \n\nTo be more specific, compared with the existing algorithm in [21], there are a few major differences in our proposed algorithm. Indeed, as reviewer has mentioned, we adopt a generic “alternating optimization” scheme, which alternates between one conservative policy improvement step and one reward optimization step. However, the algorithm under the hood of “alternating optimization” is very different. \n* First, compared with the existing algorithm in [21], the proposed algorithm in paper aims to solve a completely different problem – offline IRL. Due to the difference in problem settings and formulations, we need to analyze the gradient expression of the surrogate objective function w.r.t. the reward parameter, which leads to a different reward update step compared to the one in [21]. \n\n* Second, for the policy optimization under each reward estimator, we consider updating the policy under the estimated dynamics model with a regularization term (penalty function) based on the model uncertainty. In contrast, the existing algorithm in [21] only solves the online IRL problem where there is no estimated dynamics model and uncertainty estimation. This difference in algorithm design also leads to new algorithm implementations where we solve the underlying optimal policy in the estimated dynamics model through taking advantage of the recent advances in model-based offline policy optimization and uncertainty estimation. \n\n* Third, in the policy optimization subroutine (13) - (14), we consider a more realistic scheme compared with [21], where we first approximate the current soft Q function $Q_k$ by $\\widehat{Q}_k$ in (13) and then update the policy by an approximate soft policy iteration in (14). Compared with the existing algorithm in [21] which simply assumes the soft Q-function can be accurately estimated without any approximation error, the proposed algorithm in our paper is more practical since the approximation error has been explicitly taken into account. \n\n**Response to Weakness 2&Question 2:** We appreciate the reviewer’s comments. In this response, we would like to highlight the key differences between Theorem 2 in this work and Theorem 5.4 in [21]. \n\nIn the convergence analysis of our proposed algorithm, the previous analysis in [21] does not hold anymore. This is due to the fact that we are optimizing a *surrogate objective function* which is different from [21]. Moreover, as opposed to the analysis considered in [21], the analysis of our proposed algorithm involves two dynamics models: the ground-truth dynamics model $P$ and the estimated dynamics model $\\hat{P}$. Due to the existence of the dynamic model mismatch and regularized penalty function in the setting of offline IRL, it is not clear whether previous properties, such as the Lipschitz continuity proved in [21] can still hold here. Furthermore, as shown in eq (13) - (14) which is different from [21], we do not assume that the soft Q function $Q_k$ can be accurately approximated at each step. In the convergence analysis of [21], the accurate approximation of the soft Q function at each step can guarantee a monotonic improvement for each soft policy iteration step. However, in our work, the approximation error between $\\widehat{Q}_k$ and $Q_k$ in (13) - (14) also makes it more challenging to analyze the stability of our proposed alternating algorithm. To tackle this problem, we develop new proof techniques in the proof of Theorem 2 to guarantee the finite-time convergence analysis of our proposed algorithm.\n\nWe appreciate the reviewer’s comments, which encourages us to discuss the key difference in proof techniques compared with [21]. We will include the discussion above into our paper.\n\n**Response to Weakness 3:** We appreciate the reviewer’s comments. These transition datasets are used to train the dynamics model and further evaluate the effect of the dataset’s coverage over the expert-visited state-action space on the performance of benchmark algorithms. We will explicitly include these details and move the discussion in Appendix into the main paper.\n\n**Response to Weakness 4:** We appreciate the reviewer’s suggestion. We present a conclusion and discuss the limitations in the global response and we kindly refer the reviewer to check it (see https://openreview.net/forum?id=oML3v2cFg2&noteId=oCZvqhc8PI).\n\n**Response to Question 3:** Yes. Indeed, the three types of datasets are gathered from policies with varying performance levels and exhibit different coverage across the expert-visited state-action space. We leverage these three dataset types to assess how their coverage of the expert-visited state-action space influences the algorithm's performance.\n\n**Response to Limitations:** We would like to kindly remind the reviewer that the limitations of this work have been discussed in the section of Limitations and broader impacts in Appendix. We will discuss it in the conclusion section.""}}, {'summary': {'value': 'The paper ""Understanding Expertise through Demonstrations: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning"" proposes an innovative approach of offline inverse reinforcement learning. After a deep theoretical analysis of the inter-dependence between errors arising from dynamics modeling from limited offline data and performance gaps of resulting policies, authors propose an efficient algorithm to practically exploit conclusions for reward/policy learning. A small experimental section validates the approach.    '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- Very well written with every notation well defined and every choice well justified\n- Very interesting problem and strong theoretical analysis\n- A practical algorithm that looks easy to reproduce\n- Good results '}, 'weaknesses': {'value': '- My main concern is that there is very few discussion about model uncertainty U in the paper, and particularly in section 3. I am surprised to not see it involved in the derivations and bounds, with no assumptions about it (except that it is bounded). No real meaning is given to it and it seems that it could be removed without changing anything in the theoretical conclusions. Is it true ? If yes, why introducing it in that part ? Also its impact is therefore not well understood from the theoretical analysis, which is a little be limitative to me (as it looks to have importance). \n- Still on U, I feel that experimental results on the choice of U would have been very useful.      '}, 'questions': {'value': '- Could authors give more insights about U, both theoretically if possible, and by some experimental results that show its impact ? '}, 'limitations': {'value': '. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'In this paper the authors present a two level maximum likelihood based framework for offline inverse reinforcement learning, where both a world model and a reward model are learnt from expert demonstrations. In this two level algorithm the outer level or loop involves estimating the reward function, while the inner loop estimates the optimal policy for the chosen reward function in a conservative MDP setting, where a penalty is added which is loosely proportional to the uncertainty in the learnt model. The authors provide theoretical guarantees for the performance of their algorithm under fairly standard technical assumptions. They also show the numerical performance of their algorithm on 3 MuJoCo environments, comparing them with other state of the art offline RL algorithms.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. The paper is novel, clearly written and is easy to comprehend.\n2. The authors have stated their results formally in the form of Lemmas and Theorems and have proved them in the supplementary material. This analysis proves the validity and utility of their proposed approach.\n3. While model based offline inverse RL has been studied, I think the theoretical guarantees from this paper are novel and important.'}, 'weaknesses': {'value': '1. The authors have demonstrated performance on only 3 environments, in which in one of the cases, their proposed algorithm is not the best.'}, 'questions': {'value': '1. How is the state action visitation measure defined in Eq (5)? Specifically, I did not understand the term $P(S_t = s|s_0 \\sim \\eta)$. Does this imply that the transitions are action independent?\n2. In the proof of Lemmma 1, how is the equation below the one labelled (iii) obtained?\n3. How is the last step in Eq(30) in Proof of Lemma 1 obtained?\n4. [Typo] Line 806 ""bonded"" -> ""bounded"".\n5. I have understood most of the proofs as they are well written with adequate justification, but since I am not sure about the definition of the state-action visitation measure, I was unable to verify some proofs in the supplementary material.'}, 'limitations': {'value': 'The authors address the limitations of this work and also some suggestions to overcome some of these limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'Offline inverse reinforcement learning (IRL) is a method for finding an unknown reward function optimized by an agent from demonstrations using only a finite dataset. The most common framework is maximum entropy (MaxEnt) IRL, which attempts to find a reward function that induces a policy which achieves the same expected reward as the trajectories from the expert demonstrations while maximizing its entropy. Prior work has shown that this is equivalent to finding a policy which maximizes the likelihood of the demonstrations under the constraint that this policy comes from solving a MaxEnt RL problem. This formulation as a bi-level optimization problem reduces the computational burden that results from alternating between finding the policy and updating the reward. However, it requires access to the true dynamics of the environment, which is incompatible with the offline IRL setup. Instead, this work proposes to learn the dynamics model in an uncertainty-aware fashion and incorporate a measure of this uncertainty in the learned reward function. This results in a two-stage procedure: 1) fitting a dynamics model from transition samples in the dataset and 2) recovering the reward function using the maximum likelihood (ML) formulation of the IRL problem. To perform the second step, the authors propose a novel decomposition of the upper-level objective, which consists of a surrogate objective that is more computationally tractable to optimize. The authors provide statistical guarantees about the optimality of the recovered reward function in terms of dataset coverage, a concept common in offline RL. Importantly, their bounds depend on dataset coverage on expert-visited state-action pairs, not the full joint space.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- Offline inverse RL is an important area for tackling challenging sequential decision making problems in potentially safety-critical applications. \n- The paper is well organized and clearly written. It does a good job explaining the novelty and results and provides enough information to support its claims.\n- The paper presents an extensive experimental evaluation on several benchmarks, comparing to both model-based and model-free offline IRL algorithms and existing imitation learning approaches. Their algorithm outperforms these baselines in most cases.\n- The authors provide a nice analysis of surrogate objective and its relation to the true upper-level objective. This provides a nice motivation for optimizing the surrogate instead, which is more computationally tractable.\n- The authors present a nice optimality guarantee of the stationary point of their algorithm in terms of the surrogate objective in the case where the reward function is linear in a feature vector of states and actions. They also relate this stationary point to the true optimal solution of the original problem.\n- The additional reward transfer experiments indicate that the learned reward function may transfer to dynamics models trained on different state-action distributions. This appears to hold even if the state-action coverage used to train the reward function is close to expert-visited states.'}, 'weaknesses': {'value': '- The alternating optimization scheme discussed in this work appears to be identical to that presented in [21]. If true, that is fine, as the main contribution of the work lies in modeling the conservative MDP and providing novel bounds in the offline setting. However, it should be made explicit in the paper and mentioned in the contributions.\n- Theorem 2 seems very similar to Theorem 5.4 in [21], except that the Q function approximation error is considered explicitly. If this is true, it should be discussed that this is the novelty in the text.\n- Section 6 should discuss the differences in the three dataset types used, as the current text does not explain what they entail. This makes it difficult to understand the performance of the proposed algorithm in each setting without carefully looking at the Appendix. It should also talk about the purpose of using these different datasets. From the Appendix, it appears that they are only used to train the dynamics model. Thus, they are evaluating the effect of dataset coverage around the expert on performance. This should be explicitly discussed in the paper. I know space is limited, but these are important details that should be in the main text.\n- A minor comment is that it would be nice for the main paper to end with a conclusion section rather than ending abruptly. And this conclusion should mention limitations of the current method.'}, 'questions': {'value': ""- Is there a difference in the alternating optimization scheme presented here and the one in [21]?\n- How does Theorem 2 in this text relate to Theorem 5.4 in [21]?\n- Am I correct in assuming that the three different datasets are used to evaluate how the coverage of the dataset around expert state-action pairs affects the algorithm's performance?""}, 'limitations': {'value': 'There is no discussion of limitations in the paper. The paper would be made a lot stronger if this was discussed in a conclusion section.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper addressed the issue of covariate shift in offline imitation learning. The authors extended the uncertainty-regularized model-based offline RL to the imitation learning setting. The key idea is to first learn transition dynamics from samples, and then solve an optimization problem that jointly seeks a policy such that it optimizes the learned transition dynamics accompanied by a reward model and maximizes the log-likelihood of actions in data. The authors provide theoretical guarantees for the maximization of action log-likelihood and empirical results for the learned policy.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': '1. The issue of covariate shift is indeed important for offline IRL.\n2. The efficacy of the algorithm is partially supported by empirical results.\n3. Analysis is provided for the model-based part of this algorithm.'}, 'weaknesses': {'value': '1. The paper is somewhat hard to follow. See questions below.\n2. The effect of overcoming the distributional shift is not emphasized in the experiment section. None of the experiments was carried out on small datasets where the coverage of state–action space is limited. In fact, the medium datasets in D4RL contain 1M transitions, and the medium-expert versions contain 2M transitions. The datasets for results in Figure 2 contain 5000 expert demonstrations, which might correspond to 5M transitions if each expert trajectory contains 1000 transitions.\n3. The paper does not have an informative conclusion part.'}, 'questions': {'value': '1. Why do you include discounting in the log-likelihood term?\n2. Why do you include the entropy term in eq. 3a?\n3. The theoretical analysis relies on the relation between optimal policy and optimal soft Q-function (eq.4 and eq. 14). But as mentioned in line 226--230, practical implementations utilize an actor-critic framework to approximate the optimal policy. How does this approximation affect the analysis?\n4. Eq. 15 shows a clear resemblance with the reward maximization part in max-entropy IRL (eq. (1)). It suggests that the proposed algorithm seems to replace the online interaction of max-entropy IRL with sample generation using the learned dynamics. Then, what is the motivation to maximize the log-likelihood of expert actions?\n\nA suggestion.\nOne concern of this approach is that to estimate the transition dynamics we need a sufficient amount of data, but the covariate shift issue occurs when we only have a small amount of data. I would suggest the authors include results on a few expert demonstrations (e.g. 10~100) to verify their claim.'}, 'limitations': {'value': 'No. there is no discussion on limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper focuses on learning from demonstration via offline inverse reinforcement learning (IRL). Offline IRL suffers a similar problem as offline reinforcement learning (RL) and imitation learning (IL), where the policy cannot generalize well on unseen states and actions---this problem is known as distribution shift. To address this problem, this paper proposes to first learn a dynamic model, and formulates a maximum likelihood (ML) objective to simultaneously recovers both the reward function and the policy. Notably, the policy is optimized using a maximum entropy objective along with pessimism based on the uncertainty of the learned dynamic model. This paper provides PAC-style bounds to quantify the amount of samples required to achieve $\\varepsilon$-optimal solution to the MLE objective. The paper further provides an algorithm that obtains such a $\\varepsilon$-optimal solution under specific assumptions. Finally, this paper provides empirical evaluation on the D4RL benchmarks.\n\n## Contributions\n- A new MLE objective for recovering a policy that is close to the expert policy.\n- A theoretical analysis that describes the statistical guarantees of the objective\n- An algorithm that obtains to near-optimal solution under linear parameterization of the reward function\n- An empirical evaluation on standard benchmark, D4RL, that indicates statistically significant improvement over existing baselines in majority of the tasks.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- The paper is well written and easy to follow in general---I particularly appreciate the presentation on providing formal statements followed by the high-level intuitions.\n- The paper proposes a novel formulation for offline inverse reinforcement learning.\n- The paper provides numerous theoretical justifications and an algorithm that is inspired by said analyses.'}, 'weaknesses': {'value': '- In practice, how do we ensure assumption 2 (ergodicity)? It seems like this assumption actually ""hides"" some part of the coverage requirement?\n- I am curious as to how the MLE objective connects to the policy error---I completely understand that if $\\pi_\\theta = \\pi^E$ then the policy error is zero. However, it does not seem to me that achieving $\\varepsilon$-error on the MLE (i.e. $L(\\theta^*) - L(\\hat \\theta) \\leq \\varepsilon$) does not directly tell us the policy error.\n- I think the training description for BC is somewhat vague---on page 8, line 314: what exactly does it mean by ""train the algorithm until convergence""? Do we have some form of validation checking for BC? [1, 2, 3] have results regarding how BC would perform based on specific validation. Secondly, was there any hyperparameter search on BC, ValueDICE, and CLARE?\n- Regarding the experiment on recovered rewards, what is the performance if we were to fix the reward to 0? Isn\'t it better if we were to consider the correlation between the true reward function and the obtained reward function?\n\n## References\n[1]: Hussenot, L., Andrychowicz, M., Vincent, D., Dadashi, R., Raichuk, A., Ramos, S., ... & Pietquin, O. (2021, July). Hyperparameter selection for imitation learning. In International Conference on Machine Learning (pp. 4511-4522). PMLR.  \n[2]: Mandlekar, A., Xu, D., Wong, J., Nasiriany, S., Wang, C., Kulkarni, R., ... & Martín-Martín, R. (2021). What matters in learning from offline human demonstrations for robot manipulation. arXiv preprint arXiv:2108.03298.  \n[3]: Ablett, T., Chan, B., & Kelly, J. (2023). Learning from Guided Play: Improving Exploration for Adversarial Imitation Learning with Simple Auxiliary Tasks. IEEE Robotics and Automation Letters.'}, 'questions': {'value': '- On page 3, equation 2a: $\\theta$ parameterizes only the reward function, and $\\pi_\\theta$ corresponds to the policy obtained when $r$ is parameterized by $\\theta$, correct?\n- On page 5, proposition 1: Is there any result regarding larger $\\varepsilon$? It seems like we may want to sacrifice this approximation error.\n\n## Possible Typos\n- Page 3, line 93: gamma \\in (0, 1)?\n- Page 3, line 95: The $P$ should not be the same as the transition dynamics right? I feel we should be clear that we are either overloading notation or use another symbol.\n- Page 5, equation 11: What\'s $\\epsilon$? Is it the same as $\\varepsilon$?\n- Page 8, line 303: Missing space after ""2)""'}, 'limitations': {'value': ""- The paper's proposed method requires uncertainty estimation which is still an active research problem, especially in the context of neural networks---as far as I understand the paper leverages existing work that lacks theoretical guarantee.""}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'When Demonstrations meet Generative World Models: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning'}, 'authors': {'value': ['Siliang Zeng', 'Chenliang Li', 'Alfredo Garcia', 'Mingyi Hong']}, 'authorids': {'value': ['~Siliang_Zeng1', '~Chenliang_Li3', '~Alfredo_Garcia1', '~Mingyi_Hong1']}, 'keywords': {'value': ['Inverse Reinforcement Learning', 'Model-based Offline Inverse Reinforcement Learning']}, 'abstract': {'value': ""Offline inverse reinforcement learning (Offline IRL) aims to recover the structure of rewards and environment dynamics that underlie observed actions in a fixed, finite set of demonstrations from an expert agent. Accurate models of expertise in executing a task has applications in safety-sensitive applications such as clinical decision making and autonomous driving. However, the structure of an expert's preferences implicit in observed actions is closely linked to the expert's model of the environment dynamics (i.e. the ``world''). Thus, inaccurate models of the world obtained from finite data with limited coverage could compound inaccuracy in estimated rewards. To address this issue, we propose a bi-level optimization formulation of the estimation task wherein the upper level is likelihood maximization based upon a conservative model of the expert's policy (lower level). The policy model is conservative in that it maximizes reward subject to a penalty that is increasing in the uncertainty of the estimated model of the world. We propose a new algorithmic framework to solve the bi-level optimization problem formulation and provide statistical and computational guarantees of performance for the associated optimal reward estimator. Finally,  we demonstrate that the proposed algorithm outperforms the state-of-the-art offline IRL and imitation learning benchmarks by a large margin, over the continuous control tasks in MuJoCo and different datasets in the D4RL benchmark.""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/5effba89baa04d23c51b2a81c216979fb04614ae.pdf'}, 'supplementary_material': {'value': '/attachment/3c367c7acabb836bd0d9b99d66f5b70d651fd421.pdf'}, '_bibtex': {'value': '@inproceedings{\nzeng2023when,\ntitle={When Demonstrations meet Generative World Models: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning},\nauthor={Siliang Zeng and Chenliang Li and Alfredo Garcia and Mingyi Hong},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=oML3v2cFg2}\n}'}, 'paperhash': {'value': 'zeng|when_demonstrations_meet_generative_world_models_a_maximum_likelihood_framework_for_offline_inverse_reinforcement_learning'}}]"
"['Idan Attias', 'Steve Hanneke', 'Alkis Kalavasis', 'Amin Karbasi', 'Grigoris Velegkas']",NeurIPS,Optimal Learners for Realizable Regression_ PAC Learning and Online Learning,https://neurips.cc/virtual/2023/oral/73816,2023," In this work, we aim to characterize the statistical complexity of realizable regression both in the PAC learning setting and the online learning setting. Previous work had established the sufficiency of finiteness of the fat shattering dimension for PAC learnability and the necessity of finiteness of the scaled Natarajan dimension, but little progress had been made towards a more complete characterization since  the work of Simon 1997 (SICOMP '97). To this end,  we first introduce a minimax instance optimal learner for realizable regression and propose a novel dimension that both qualitatively and quantitatively characterizes which classes of real-valued predictors are learnable.  We then identify a combinatorial dimension related to the graph dimension that characterizes ERM learnability in the realizable setting. Finally, we establish a necessary condition for learnability based on a combinatorial dimension related to the DS dimension, and conjecture that it may also be sufficient in this context. Additionally, in the context of online learning we provide a dimension that characterizes the minimax instance optimal cumulative loss up to a constant factor and design an optimal online learner for realizable regression, thus resolving an open question raised by Daskalakis and Golowich in STOC '22.",Oral 6D Theory,https://openreview.net/pdf?id=w116w62fxH,https://openreview.net/forum?id=w116w62fxH,w116w62fxH,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': ""This paper solves an open problem in the learning theory community that is of fundamental importance (i.e. the statistical complexity of realizable regression in both the PAC setting and the online setting), and both introduces novel conceptual quantities and techniques. All reviewers are very enthusiastic about the paper's contributions and supportive of an oral presentation.""}}, {'comment': {'value': 'We are grateful to the reviewer for taking the time to familiarize themselves further with the literature and for appreciating our contributions.'}}, {'comment': {'value': 'I thank the authors for the response. After enriching myself further with the relevant literature, I think the contributions in this paper are solid on fundamental levels and add important progress in the learning theory community. I thus increased my score from 7 to 9, and my confidence from 2 to 4. '}}, {'comment': {'value': ""I would like to thank the authors for their detailed answers to my questions. I don't have further questions and my positive evaluation of the paper is unchanged.""}}, {'comment': {'value': 'Thank you very much for taking the time to read our rebuttal and for appreciating our work. We will make sure to address the questions that you and the rest of the reviewers raised in the next version of our draft.'}}, {'comment': {'value': 'Thank you for answering my question and addressing my concern about the potential weakness. I will be eagerly following the progress on the conjecture regarding $\\gamma$-$\\text{DS}$. \n\nOverall,  the paper tackles a foundational problem of learning theory. The results are significant and the techniques are sound, so I think the paper deserves a highlight at the conference. I am happy to raise the score to 8. '}}, {'rebuttal': {'value': 'We would like to thank the Reviewer for the positive feedback and insightful questions.\n\n> *Although the paper does provide a combinatorial characterization of realizable regression, I am not sure if the OIG-based dimension is very insightful. Theoretically, it is a useful abstraction as it has a finite-character property and thus the learnability of the problem can, at least technically, be determined using finitely many domain points and functions in function classes. However, the practical utility of such dimension is questionable. Can be computed for natural classes such a linear classes, Lipschitz classes, and so forth? Computing upper bounds is generally difficult even for classical dimensions like VC and fat-shattering, but the lower bounds of these dimensions are typically easy to compute for some natural classes because of simplicity of their shattering conditions. Is it also the case for this OIG based dimension?*\n\nIn general, we believe that it is difficult to compute the $\\gamma$-OIG dimension. Nevertheless, $\\gamma$-OIG dimension is the first complexity measure that tightly characterizes realizable regression. More to that, we propose the much more combinatorial $\\gamma$-DS dimension which we conjecture to be the right dimension for this setting. As the reviewer suggests, it would be interesting to compute the OIG-based complexity measure for natural and useful complexity classes. For instance, for the class of linear functions $f(x) = a \\cdot x$, when the features are single-dimensional then $\\mathbb{D}^{\\mathrm{OIG}}_\\gamma = 1$ (one sample suffices; each hyperedge of the OIG is a single hypothesis) and the OIG dimension scales with the dimension of the feature space in higher dimensions. Similar analysis can be done for the affine case. Deriving bounds for other families of functions is an important yet non-trivial question.\n\n> *I assume that fat-shattering dimension upper bounds the OIG based dimension proposed here. Is there a combinatorial proof of this fact? Also, is there a general property of the class that guarantees that the finiteness of OIG based dimension and fat-shattering dimension coincide?*\n\nThe work of Mandelson (2002) provides a sufficient and natural condition that implies finiteness of both measures. In particular, Section 5 of this work shows that classes that contain functions with bounded oscillation (as defined in the aforementioned paper) have finite fat-shattering dimension. This implies that the class is learnable in the agnostic setting and hence is also learnable in the realizable setting. As a result, the OIG-based dimension is also finite. So, bounded oscillations are a general property that guarantees that the finiteness of OIG-based dimension and fat-shattering dimension coincide. For the first part of the question, we are not familiar with a combinatorial proof of this statement. Investigating such connections would be an interesting direction for future work.\n\n[Mandelson, Improving the Sample Complexity Using Global Data, 2002]\n'}}, {'rebuttal': {'value': 'We would like to thank the Reviewer for the positive feedback on the significance and presentation of our results and the interesting questions and suggestions.\n\n> *My only complaint is on the short conclusion and a lack of discussion on future directions (apart from the obvious one of proving Conjecture 1).*\n\nIn the next version of our draft, we will include a more detailed conclusion section where we will summarize the main contributions of our work and the important next steps. Another future direction, that is not directly related to Conjecture 1, is  to better understand the gap between the fat-shattering dimension and the OIG-based dimension. In particular, it would be interesting to come up with examples of ``natural’’ hypothesis classes, other than the one we provide in Example 1, which witness the fact that the fat-shattering dimension does not characterize learnability.\n\n>*Could you elaborate on the obstacle that prevents the approach of [BCD+22] to be applied towards the regression setting?*\n\nIn [Brukhim et al., 2022], the authors start by showing that if the DS dimension of $H$ is bounded by $d$, then using the OIG algorithm they can derive a learner that has error at most $d/(d+1)$. Notice that this learner is very weak, but has non-trivial guarantees. Subsequently, they use non-trivial arguments that go through list-PAC learning and sample-compression schemes to boost this very weak learner. This step is crucial for the multiclass setting since it reduces nontrivially the infinite label space. However, in the realizable regression setting, it is trivial to derive a learner that has error at most $1/2$. Indeed, if we focus on the $\\ell_1$ loss and $Y = [0,1]$, by always predicting $1/2$ we can design such a learner. To the best of our knowledge, using the definition of the $\\gamma$-DS dimension in a similar way as in [Brukhim et al., 2022] does not result in a non-trivial learner in the regression setting. This is the main and crucial difference between classification and regression. \n\n>*Are there any evidence/heuristic arguments that support the conjecture? Are there interesting assumptions under which finite  gamma-DS dimension implies learnability?*\n\nLet us first elaborate on the connection between OIG and the DS dimension. We will focus on the multiclass setting, studied in  [Brukhim et al., 2022]. Our Conjecture 1 essentially claims that this connection extends to the realizable regression task. Interestingly, there is some notion of “duality” between one-inclusion graph algorithms and pseudo-cubes (the combinatorial objects that define the DS dimension). In particular, Lemmas 12 and 13 in [Brukhim et al. 2022] show that there is a certain duality between orientations of OIG and the DS dimension. In particular, let us consider a class $H$ with DS dimension $d$. Then intuitively even if the algorithm is given $d$ labeled examples, then any orientation of the OIG will have large out-degree (which means that it will be a bad learner). More to that, if the algorithm is given $d+1$ labeled examples, then there exists a good orientation (one with small out-degree) which implies the existence of a good learner. These intuitive statements shed light to the connection between the DS dimension and learnability through the OIG structure. \n\nDeriving sufficient conditions is actually an interesting question for future work, and probably easier than proving the conjecture to its full extent. The reason we believe it is true is that, similar to the multiclass classification problem, the $\\gamma$-DS dimension feels more ``natural’’ than the dimensions that have been proposed in the past, and seems to be capturing the learnability problem in a tighter way. Moreover, its definition is closely related to the outdegree of the OIG (as we discussed in the previous paragraphs), which, as we have shown, is the quantity that controls learnability in this setting. '}}, {'rebuttal': {'value': 'We would like to thank the Reviewer for the positive feedback on the significance of our results.\n\n> *The paper might need to discuss the limitations of the results and analysis.*\n\nWe believe that the main limitation of our work is that the OIG-based dimension we propose is more complicated than the dimensions that have been proposed in the past, like the fat-shattering dimension (which, as we explain, does not characterize learnability in the realizable regression setting). Nevertheless, despite its complexity, this is the first dimension that characterizes learnability in the realizable regression setting. More to that, our work leaves as an important next step is to prove (or disprove) our conjecture that the (combinatorial and simpler) $\\gamma$-DS dimension is qualitatively equivalent to the $\\gamma$-OIG dimension. We will add a discussion on the limitations in the first revision of our manuscript.\n'}}, {'rebuttal': {'value': 'We would like to thank the Reviewer for the positive and insightful feedback and questions.\n\n> *The various dimensions are hard to understand. It would be nice to see examples. For instance, lines 188-192 were not particularly helpful to understand Definition 5, since I am not sure what it means for H  to contain a cube. Do you mean there is a hypercube of a certain size embedded in every function in  H ?*\n\nLet us first give some intuition behind the definition of the fat-shattering and $\\gamma$-Natarajan dimensions. The other dimensions follow in a similar manner. The crucial idea is to understand what it means to shatter a set of points in each definition. Then the associated dimension is the maximum size of a set shattered by the hypothesis class.\n\nFat-shattering dimension is a natural way to quantify how well the function class can interpolate (with gap $\\gamma$) some fixed function. Crucially this interpolation contains only inequalities (see Definition 4) and hence (at least intuitively) cannot be tight for the realizable setting, where there exists some function that exactly labels the features. Example 1 gives a natural example of a class with infinite fat-shattering dimension but which can be learned with a single sample in the realizable setting.\n\nBefore explaining the $\\gamma$-Natarajan dimension, let us begin with the definition of the standard Natarajan dimension [Natarajan, 1989]. We say that a set $S = \\\\{x_1,...,x_n\\\\}$ of size $n$ is Natarajan-shattered by a concept class $H \\subseteq \\mathcal{Y}^\\mathcal{X}$ if there exist two functions $f,g : S \\to \\mathcal{Y}$ so that $f(i) \\neq g(i)$ for any $i \\in S$ and\nfor any $b \\in \\\\{0,1\\\\}^n$ there exists $h \\in H$ such that\n$h(x_i) = f(x_i)$ if $b_i = 1$ and\n$h(x_i) = g(x_i)$ if $b_i = 0.$ Note that here we have equalities instead of inequalities (recall the fat-shattering case).\n\nFrom a geometric perspective (see [Brukhim et al., 2022]), this means that the space $H$ projected on the set $S$ contains the set\n$ \\\\{ f(x_1), g(x_1)\\\\} \\times … \\\\{ f(x_n), g(x_n) \\\\} $.\nThis set is ""isomorphic"" to the Boolean hypercube of size $n$ by mapping $f(x_i)$ to 1 and $g(x_i)$ to 0 for any $i \\in [n]$.\nThis means that the Natarajan dimension is essentially the size of the largest Boolean cube contained in $H$.\n\nThe $\\gamma$-Natarajan dimension is the scaled version of the above definition. The only modification is that the two functions $f,g$ map $S$ to $[0,1]$ and we require that not only $f$ and $g$ are everywhere different but we have that the distance between $f(x_i)$ and $g(x_i)$ is at least $\\gamma$. Nevertheless, the geometric perspective is still the same: $\\gamma$-Natarajan dimension is the size of the largest Boolean cube contained in $H$. This is what we mean after Definition 5.\n\nExamples 3 and 4 contain some examples computing $\\gamma$-Graph and Natarajan dimensions. Adding more intuitive examples is an important direction for future revisions. \n\nWe will make the above discussion more clear in the first revision of our work.\n\n\n> *Line 263, is there some typo? maybe you dont mean \\forall i*\n\nThis is indeed a typo, thanks for bringing it up. We meant to say $\\forall j \\in [n] \\setminus \\{ i \\}$, not $\\forall i, j$. We will fix it in the next version of our draft.\n'}}, {'rebuttal': {'value': 'We would like to thank the Reviewer for the positive feedback regarding the importance and the clarity of our results.\n\n\n> *Not a weakness, but can the authors explain why is there a requirement for bounded labels? What happens if the labels are not bounded?*\n\nWe would like to mention that, in general, we do not require that the label space is bounded. In contrast, we have to assume that the loss function takes values in a bounded space. This is actually necessary since having an unbounded loss in the regression task would potentially make the learning task impossible. For instance, having some fixed accuracy goal, one could construct a learning instance (distribution over labeled examples) that would make estimation with that level of accuracy trivially impossible. We will clarify this point in the first revision of our work.'}}, {'summary': {'value': 'This paper provides combinatorial dimensions that characterize realizable regression in both batch as well as online settings. Moreover, it provides minimax optimal learner up to polylog factor in the batch setting and minimax optimal learner in the online setting. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. The paper is well-written, easy to follow, and solves an important open problem of characterizing realizable learnability for real-valued function classes. \n2. The paper uses classical ideas such as Median Boosting algorithm, sample compression schemes as well as some recent developments in PAC learning theory such as partial concept classes, OIG based dimensions, etc. Overall, the paper is technically sound and is definitely an important technical contribution to the field. \n3. In online setting, the paper introduces a novel idea of summing scales along each branch of the tree and defining dimension as the sum of scales. This is a novel and useful technical tool as it provides a new way of defining dimensions that are not parametrized by a scale even though some form of scale is inherent to the problem setting. '}, 'weaknesses': {'value': 'Although the paper does provide a combinatorial characterization of realizable regression, I am not sure if the OIG-based dimension is very insightful. Theoretically, it is a useful abstraction as it has a finite-character property and thus the learnability of the problem can, at least technically, be determined using finitely many domain points and functions in function classes. However, the practical utility of such dimension is questionable. Can be computed for natural classes such a linear classes, Lipschitz classes, and so forth? Computing upper bounds is generally difficult even for classical dimensions like VC and fat-shattering, but the lower bounds of these dimensions are typically easy to compute for some natural classes because of simplicity of their shattering conditions. Is it also the case for this OIG based dimension?\n\n\n\n'}, 'questions': {'value': 'I assume that fat-shattering dimension upper bounds the OIG based dimension proposed here. Is there a combinatorial proof of this fact? Also, is there a general property of the class that guarantees that the finiteness of OIG based dimension and fat-shattering dimension co-incide? \n\n'}, 'limitations': {'value': 'N/A\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work analyzes the realizable regression and connects it with several notions of dimensions. They care about the online learning and the PAC learning. They first show that the $\\gamma$-OIG dimension characterizes the PAC learning and that PAC learning requires finite $\\gamma$-DS. Finally, they show that for the online regression, the authors find a dimension that characterize it. They show that this dimension is an upper bound over the cumulative loss and it is a lower bound up to some constant.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ' The paper provides complexity results for regression in online learning and PAC learning. In binary classification, we have a better understanding of the complexity and how different dimensions connect. In the regression setting, we do not know a lot and this paper provides a very good understanding and nice results. The paper is well written and explains the previous work well. '}, 'weaknesses': {'value': 'Not a weakness, but can the authors explain why is there a requirement for bounded labels? What happens if the labels are not bounded?'}, 'questions': {'value': 'The question in the weaknesses section.'}, 'limitations': {'value': 'no limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper introduce some dimensions that characterize PAC learnability for realizable regression. The authors introduce $\\gamma-$ Graph dimenion which is necessary and sufficient for PAC learnability by ERM, and $\\gamma-$OIG dimension which is necessary and sufficient for PAC learnability. $\\gamma-$DS dimension is introduced which is necessary and conjectured to be sufficient. There are also results for online learning.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'PAC learnability for realizable regression is characterized by an appropriate dimension. This seems to be an important open problem that is resolved.'}, 'weaknesses': {'value': 'The various dimensions are hard to understand. It would be nice to see examples. For instance, lines 188-192 were not particularly helpful to understand Definition 5, since I am not sure what it means for $\\mathcal{H}$ to contain a cube. Do you mean there is a hypercube of a certain size embedded in every function in $\\mathcal{H}$?'}, 'questions': {'value': 'Line 263, is there some typo? maybe you dont mean $\\forall i$.'}, 'limitations': {'value': 'None'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper develops optimal learners and characterizes learnability with new combinatorial dimensions for realizable regression (where the best predictor has zero regret) in PAC and online learning, significantly depicting the landscape of learnability in PAC/online learning. \n\nFor PAC learning, they show that: \n- the PAC learnability in the realizable regression by a worst-case ERM iff the gamma graph dimension is finite \n- learnability in the realizable regression is fully characterized by a finite gamma One-Inclusion dimension \n- finite gamma-DS dimension is a necessary condition for PAC learnability in the realizable regression \n\nFor online learning, they devise a new combinatorial dimension, namely online dimension that is built up on the scaled Littlestone dimension. They show that the online dimension characterizes the minimax instance optimal cumulative loss up to a constant factor and design an optimal online learner. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- Significant results that complete the landscape of learnability of PAC/online learning in realizability regression \n'}, 'weaknesses': {'value': '- None that I know (note that this problem area is not my research domain)'}, 'questions': {'value': 'N/A'}, 'limitations': {'value': 'The paper might need to discuss the limitations of the results and analysis. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper studies the statistical complexity of realizable regression in the PAC learning and online learning setups. The main results are the following combinatorial conditions that characterize the PAC and online learnability:\n- PAC learnability by (worst-case) ERM learner is equivalent to having a finite $\\gamma$-graph dimension for all $\\gamma \\in (0, 1)$.\n- PAC learnability is equivalent to the finiteness of $\\gamma$-one-inclusion graph dimension for all $\\gamma \\in (0, 1)$.\n- The minimax cumulative loss in online learning is characterized (up to a constant factor) by the online dimension.\nThe combinatorial dimensions are above are newly introduced in the paper. The authors also conjectured that the DS dimension in the literature also characterizes PAC learnability.\n\nIn addition, the paper provides several other examples that shed light on the landscape between learnability, uniform convergence, and other complexity measures of the hypothesis class (Figure 1).'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'This paper studies a fundamental problem in learning theory, which has, surprisingly, been left open for several decades. The results are strong and comprehensive, and the authors did a great job in introducing the prior results and presenting the high-level roadmaps behind the technical proofs.'}, 'weaknesses': {'value': 'My only complaint is on the short conclusion and a lack of discussion on future directions (apart from the obvious one of proving Conjecture 1).'}, 'questions': {'value': 'Regarding Conjecture 1:\n- Could you elaborate on the obstacle that prevents the approach of [BCD+22] to be applied towards the regression setting?\n- Are there any evidence/heuristic arguments that support the conjecture? Are there interesting assumptions under which finite $\\gamma$-DS dimension implies learnability?'}, 'limitations': {'value': 'This is a theory paper and its limitations lie in the assumptions on which the validity of the results rely, including the realizability assumption and the focus on PAC and online learning. This has been formally stated in the paper, and also explicitly mentioned in the title and abstract.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Optimal Learners for Realizable Regression: PAC Learning and Online Learning'}, 'authors': {'value': ['Idan Attias', 'Steve Hanneke', 'Alkis Kalavasis', 'Amin Karbasi', 'Grigoris Velegkas']}, 'authorids': {'value': ['~Idan_Attias1', '~Steve_Hanneke1', '~Alkis_Kalavasis1', '~Amin_Karbasi3', '~Grigoris_Velegkas1']}, 'keywords': {'value': ['Learning Theory', 'Regression', 'PAC Learning', 'Online Learning']}, 'TLDR': {'value': 'We provide (almost) optimal learners, in terms of their sample complexity, for realizable regression in the context of PAC learning and in the context of online learning.'}, 'abstract': {'value': ""In this work, we aim to characterize the statistical complexity of realizable regression both in the PAC learning setting and the online learning setting. Previous work had established the sufficiency of finiteness of the fat shattering dimension for PAC learnability and the necessity of finiteness of the scaled Natarajan dimension, but little progress had been made towards a more complete characterization since  the work of Simon 1997 (SICOMP '97). To this end,  we first introduce a minimax instance optimal learner for realizable regression and propose a novel dimension that both qualitatively and quantitatively characterizes which classes of real-valued predictors are learnable.  We then identify a combinatorial dimension related to the graph dimension that characterizes ERM learnability in the realizable setting. Finally, we establish a necessary condition for learnability based on a combinatorial dimension related to the DS dimension, and conjecture that it may also be sufficient in this context. Additionally, in the context of online learning we provide a dimension that characterizes the minimax instance optimal cumulative loss up to a constant factor and design an optimal online learner for realizable regression, thus resolving an open question raised by Daskalakis and Golowich in STOC '22.""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/0e3ef00368f375320e98c79ae6fa8e1dcb02aa2f.pdf'}, 'supplementary_material': {'value': '/attachment/c516fec60973e253824b02ab98c6c00002ee3549.pdf'}, '_bibtex': {'value': '@inproceedings{\nattias2023optimal,\ntitle={Optimal Learners for Realizable Regression: {PAC} Learning and Online Learning},\nauthor={Idan Attias and Steve Hanneke and Alkis Kalavasis and Amin Karbasi and Grigoris Velegkas},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=w116w62fxH}\n}'}, 'paperhash': {'value': 'attias|optimal_learners_for_realizable_regression_pac_learning_and_online_learning'}}]"
"['Sibylle Marcotte', 'Remi Gribonval', 'Gabriel Peyré']",NeurIPS,Abide by the law and follow the flow_ conservation laws for gradient flows,https://neurips.cc/virtual/2023/oral/73829,2023," Understanding the geometric properties of gradient descent dynamics is a key ingredient in deciphering the recent success of very large machine learning models. A striking observation is that trained over-parameterized models retain some properties of the optimization initialization. This ""implicit bias"" is believed to be responsible for some favorable properties of the trained models and could explain their good generalization properties. The purpose of this article is threefold. First, we rigorously expose the definition and basic properties of ""conservation laws"", that define quantities conserved during gradient flows of a given model (e.g. of a ReLU network with a given architecture) with any training data and any loss. Then we explain how to find the maximal number of independent conservation lawsby performing finite-dimensional algebraic manipulations on the Lie algebra generated by the Jacobian of the model. Finally, we provide algorithms to: a) compute a family of polynomial laws; b) compute the maximal number of (not necessarily polynomial) independent conservation laws. We provide showcase examples that we fully work out theoretically. Besides, applying the two algorithms confirms for a number of ReLU network architectures that all known laws are recovered by the algorithm, and that there are no other independent laws. Such computational tools pave the way to understanding desirable properties of optimization initialization in large machine learning models.",Oral 1D DL Theory,https://openreview.net/pdf?id=kMueEV8Eyy,https://openreview.net/forum?id=kMueEV8Eyy,kMueEV8Eyy,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'A fine work proposing a more systematic approach to conservation laws for gradient flows based on concepts and tools from differential topology, in particular ones related to Frobenius theorem.\n\nThe reviewers unanimously agreed that the paper forms a solid contribution to a growing body of work in this topic, appreciating the mathematically compelling perspective it offers on the problem of characterizing continuous conservation laws.'}}, {'comment': {'value': 'I thank the authors for their rebuttal. I will increase my score by 1.'}}, {'comment': {'value': 'Thank you for the response. I appreciate the clarification on the factorization and the Frobenius theorem. I believe the theoretical contributions are significant and have increased my score.'}}, {'comment': {'value': 'I thank the authors for addressing in detail the points I raised in the review.\nIn particular, the authors adequately addressed my main doubts regarding the role of the factorisation introduced in the paper.\nAfter assessing their comments, I recognise that the factorisation is indeed non-trivial and bears non-trivial consequences. \nI decided to update my overall grading to 7 to reflect this.'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the positive comments and constructive suggestions.\n\n**Weaknesses and Questions addressed**\n\n> **L1e** It is not clear to what extent the factorisation property the authors introduce is necessary to their analysis. Said differently, it is not clear whether the analysis could be performed similarly on a concrete example (say fixed dataset) without any mention of a factorisation. The authors could add additional high-level explanations/justifications of this concept.\n\nThank you for the insightful observation. When you fix the dataset and the loss, you\'re essentially dealing with a singular vector field, specifically: $\\theta \\mapsto \\nabla \\mathcal{E} (\\theta)$. In this particular scenario, our framework is directly applicable. Given that we\'re examining a singular vector field, its associated Lie algebra has a dimension of one. This results in $D-1$ conserved quantities. However, it\'s worth noting that these quantities intricately depend on both the chosen dataset and the specified loss. Consequently, the utility of such an analysis, which is inherently data-dependent, may be somewhat limited. We\'ll be sure to include this point as a clarifying remark in our work.\n\n> **Q1e** It is not clear to me whether the requirement in Eq. 2 is vacuous, meaning that any architecture automatically satisfies it. Can\'t I just take $\\phi$ as the identity map, and $f = \\mathcal{E}$? If this trivial factorisation is possible, are the results still non-trivial? Maybe I am losing some very simple nuance. In any case, adding a counter-example, or clarifying better the requirements on $\\phi$ and $f$ could avoid doubts.\n\nThank you for raising this point! If you adopt this simplistic factorization, then $ \\partial \\phi (\\theta) = I_D$, leading to $V_\\phi(\\theta) = \\mathbb{R}^D$. This means that for this particular $\\phi$, there isn\'t any conservation law. In essence, such a parametrization doesn\'t have the requisite ""tightness"" to yield an equivalent of Theorem 2.8. This is a very good remark and we will add it to clarify!\n\n> **Q2e** Example 2.2 provides only a local factorisation for ReLU networks. Of course locality is ok as we are considering gradient flow dynamics, which is local. But I wonder whether something special can happen at the boundaries of the set Ω defined in Example 2.2, i.e. if there is some gluing condition/gluing phenomenon that may affect the results presented by the authors.\n\nIn the case of linear / ReLU networks, our analysis shows that there are no conservation laws beyond existing conservation laws, which are known to be global. This addresses the gluing issue for such cases. For more general settings compatible with our analysis, which is indeed only local, gluing conditions are an interesting but possibly difficult challenge, we will comment a bit on this in the revised version.\n\n> **Q3e** Is there a commonly used loss for which Eq. 7 is not satisfied?\n\nAs mentioned in Remark A.7, Eq. 7 is not satisfied for cross-entropy loss. However, it is possible to envision weaker assumptions on the span involved in Eq. 7 to extend the theory to such a loss. This is an interesting challenge left for further work.\n\n> **Q4e** The authors stress that their results allow for explicit construction of maximal sets of conserved quantities, yet in the manuscript they provide only an a posteriori verification that known conserved quantities in previously studied architectures indeed form maximal sets. Is there an architecture where new conservation laws can be found through the presented techniques?\n\nIn the manuscript, Section 2.4 provides an algorithm (Algo<1>) that constructs directly all polynomial conservation laws. By comparing the number of independent polynomial conservation laws with $D - m$, with $m$ the dimension of the trace of the generated Lie algebra (whose algorithm (Algo<2>) is described in section 3.3), we found that the numbers match and that all polynomial conservation laws found by Algo<1> correspond to the ones already known by the literature. By Algo<2>, we know that there are no other conserved quantities.\n\nThe only “a posteriori” reasoning in our analysis is to say that all conserved quantities are in fact global as discussed in our answer to **Q2e**.\n\nRegarding the *discovery* of new conservation laws: for architectures involving piecewise polynomial activations, we expect that a polynomial $\\phi$ yielding the factorization $f \\circ \\phi$ can again be found, allowing to conduct the same analysis but different (polynomial) conservations laws. The main challenge, left to future work, would be to establish an equivalent of Th 2.8.\n\n> **L1e** The authors briefly discuss limitations in the main text. I would add that the analysis seems to be limited to linear and ReLU architectures 2 layer architectures. It is not clear whether a local factorisation of the form Eq. 2 can be found for other architectures. The authors could maybe add a discussion on this point.\n\nFor deeper architectures, we still have a local factorization $\\phi$ of the form Eq 2, as mentioned in our paper (ll 122-123, appendix A.2, section 4.2). It will be a good challenge to generalize theorem 2.8 to deeper cases, which we will do for further work.'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the positive comments and constructive suggestions.\n\n**Question addressed**\n\n> **Q1d** Do the results stated for ReLU networks hold for any network with homogeneous activation function?\n\nYes, our results also apply to networks using any positively $p$-homogeneous activation function. Specifically, for a 2-layer NN given by $g_{\\theta}(x) = U \\sigma(V^\\top x)$, the conserved quantities are $\\|u_i\\|^2 - \\|v_i\\|^2/p$, where $u_i$ and $v_i$ are the columns of $U$ and $V$, respectively. We plan to include this example in the supplementary material of the final version.'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the positive comments and constructive suggestions.\n\n**Weaknesses and Questions addressed**\n\n> **W1c** Mostly restricted to deep shallow NNs, continuous-time gradient descent, and simple NN architectures. This limits the applications of the theory to practical situations. The continuous-time restriction on the gradient descent training algorithm is perhaps the more\n\nExperiments that display the approximate conservation of these laws during the process of gradient descent (as opposed to gradient flow) can be found in Figure 1 of [7] for a 2-layer linear NN, in Figure 1c of [1] for a 3-layer linear NN, and in Figure 2 of [7] for a 3-layer ReLU NN. We plan to include a more detailed commentary on this observation.\n\nIn addition to the standard multilayer linear/ReLU architectures discussed in this paper, preliminary studies, beyond the confines of this work, suggest that more diverse ReLU architectures, which encompass aspects like residual connections and convolutional layers, adhere to such a factorization with polynomial $\\phi$. With a suitable adaptation of Theorem 2.8, our entire framework should be applicable in these scenarios.\n\n> **W2c** In most situations, the generated Lie algebra is going to be infinite-dimensional. In fact, the two examples in the manuscript are contrived so that the Lie algebra ends up being finite-dimensional. The discussion on the case when the Lie algebra is infinite-dimensional, is only briefly discussed. I would suggest that the author discussed this more. In particular, the stopping criteria are based on the trace of Lie group algebra.\n\nGenerally speaking, the Lie algebra generated can indeed be of infinite dimension. This is particularly the case for deeper linear neural networks where $q > 2$, a point we intend to address in the final version. However, the *trace* of the generated Lie algebra is invariably finite-dimensional—it is bounded by $D$, the total number of parameters—and this trace is our focal point when considering the stopping criterion. As an analogy, the set of all smooth real-valued functions constitutes an infinite-dimensional Lie algebra, yet its trace at any given point corresponds to the finite-dimensional space $\\mathbb{R}$, thus having a dimensionality of one. Given that the trace has a finite dimension, we can deduce a basis for it. Consequently, the stopping criterion will be met in a maximum of $D$ steps. We will emphasize this distinction in our work.\n\n> **W3c**, **Q1c**, **Q2c** The above discussion is particularly important for hoping to apply these techniques on NNs with activation functions that are not piecewise linear. Can you add more discussion on the situation where the Lie algebra is infinite-dimensional?\nCan you add more discussion on what happens when the activation functions of the NN are not piecewise linear?\n\nOur theory readily accommodates an infinite-dimensional Lie algebra, given that its trace remains finite-dimensional. As an illustration, for deeper linear networks (where $q > 2$), the Lie algebra does become infinite-dimensional. Yet, our theory remains applicable, especially since theorem 2.8 is valid for linear networks irrespective of their depth. We will elucidate this point in the final version. When dealing with more intricate activation functions, our results are directly applicable for any positively $p$-homogeneous activation function. Specifically, for a 2-layer NN represented as $g_{\\theta} (x) = U \\sigma(V^\\top x)$, the conserved quantities are given by $\\|u_i\\|^2 - \\|v_i\\|^2/p$, where $u_i$ and $v_i$ denote the columns of $U$ and $V$ respectively. We plan to incorporate this example in the supplementary material of the final version. An intriguing avenue for exploration would be to extend these findings to encompass piecewise linear and piecewise-polynomial activations.\n'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the positive comments and constructive suggestions.\n> **W1b** The paper’s contribution is overall limited in the aspect of applications [...]\n\nFor ReLU/linear networks *of any depth*, explicit conservation laws of $\\phi$ are known (Prop 4.1) and our algorithms allow us to verify on a number of *deep (q>2)* ReLU/linear networks that there are no other ones (section 4.2). The only ingredient of our framework that is not yet extended to deeper (q>2) *ReLU* architectures is Theorem 2.8, which ensures that the conservation laws of $\\phi$ (computable with our algorithms) are indeed exactly the conservation laws shared by all $\\mathcal{E}$, for any dataset and loss. For linear networks, Theorem 2.8 is valid irrespective of their depth.\n\nExperiments showing approximate conservation of these laws during gradient descent (instead of gradient flow) are given in figure 1 of [7] for 2-layer linear NN, figure 1c of [1] for 3-layer linear NN, and figure 2 of [7] for a 3-layer ReLU NN. We will add a more explicit comment on this fact. Regarding other optimization algorithms, while our framework leaves completely open the question of a similar analysis for stochastic algorithms, it seems feasible to adapt it to deterministic algorithms with momentum using their associated ODE. This is however out of scope and left for further work. \n\nBeyond standard multilayer linear/ReLU architectures covered in this work, it seems feasible but technical (and beyond the scope of this paper) to show that more general ReLU architectures covering e.g. residual connections and convolutive layers, satisfy such a factorization with polynomial $\\phi$. The main challenge for a follow-up is then to extend Theorem 2.8, which would make the whole framework applicable in such contexts.\n\nFor more general activation functions, our results directly apply when using any positively $p$-homogeneous activation function. For a 2-layer NN defined as $g_{\\theta} (x) = U \\sigma(V^\\top x)$, the conserved quantities are given by $\\|u_i\\|^2 - \\|v_i\\|^2/p$, where $u_i$ and $v_i$ are the columns of $U$ and $V$ respectively. We plan to incorporate this example in the supplementary material of the final version. A compelling direction for future exploration would be to extend these results to piecewise linear and piecewise-polynomial activations.\n\n> **W2b** The abstract vaguely mentions [...]\n\nIn general terms, ""desirable properties"" of initialization refer to characteristics that ensure convergence, and potentially faster convergence, to an optimal solution. For instance, the utilization of conservation laws in [6] and [*] demonstrates convergence, while [3] illustrates that initializing with certain values of the conserved function can lead to accelerated convergence. We will clarify this further in the final version of the paper. Also, refer to our response to **W1b**.\n\n[*] ""On the Convergence of Gradient Descent Training for Two-layer ReLU-networks in the Mean Field Regime"" by S. Wojtowytsch, 2020, preprint.\n\n> **W3b** The requirement to factor the cost in eq. 2 seems strict [...]\n\nEq. 2 is in fact not very demanding: we can always write $\\mathcal{E} = f \\circ \\phi$ with $f= \\mathcal{E}$ and $\\phi = id$. However the number of conservation laws of $\\phi= id$ is zero, and this trivial factorization fails to capture the existence and number of conservation laws as studied in this paper. This suggests that, among all existing factorizations $\\mathcal{E} = f \\circ \\phi$, there may be a notion of an optimal one, such that an equivalent of Theorem 2.8 holds. This is an interesting challenge for future work. Thanks for this opportunity to clarify this point that will be mentioned explicitly.\n\nRegarding the ability to handle other activation functions: piecewise linearity of $x \\mapsto g_\\theta(x)$ (as in the linear and ReLU cases) is not important, and extensions e.g. to positively $p$-homogeneous activations (e.g. the squared ReLU) can be achieved [see our response to **W1b**]. \n\n> **W4b** There are a few cases [...]\n\nThank you for this suggestion, we will keep it in mind for the final version.\n\n> **Q1b** The factorization for 2-layer ReLU network requires that $\\mathbb{1}(v\\_j^\\top x_i > 0)$ is constant. How likely does this condition hold throughout the gradient flow?\n\nThis condition will *not* be preserved throughout the gradient flow, however as soon as  $\\mathbb{1}(v\\_j^\\top x_i > 0)$ is *locally* constant we can conduct our analysis. Thus, apart from some instants along the trajectory where there are changes in these activations, the whole analysis is valid and allows to characterize the (number of independent) functions that are conserved. \n\n> **Q2b** Would it be possible to include a brief summary of what the Frobenius theorem is about? [...]\n\nThank you for the suggestion! In the final version\'s supplementary material, we\'ll include a summary as you\'ve recommended. Additionally, we\'ll provide a section that clarifies the translation of notations and vocabulary between the theorem mentioned in the given reference and our paper. When we refer to a ""non-singular distribution"", it implies that the dimension of the associated trace remains constant (refer to the definition of ""non-singular"" on page 15 of [10]). Being ""involutively consistent"" directly relates to our second assertion using the Lie bracket (see eq. 1.13 on page 17 of [10]). Lastly, ""completely integrable"" aligns with our first assertion regarding orthogonality conditions (refer to eq. 1.16 on page 23 of [10]).\n\n> **Q3b** Conservation law is also an important concept in physics [...]\n\nOur theorem is indeed related to invariance in the model (each invariance such as scaling in ReLu is associated to a conserved quantity). We will mention and clarify this connexion in the revised version. This being said, we were not able to draw a precise connexion with Noether theorem, and the settings where Noether vs Frobenius apply seem rather different.'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the positive comments and constructive suggestions.\n\n**Weaknesses and Questions addressed**\n\n> **W1a** The paper is highly technical and only provides generic mathematical tools without bringing additional insights over previous findings. Space permitting, it would be helpful to show more examples that go beyond what is already known.\n\nBeyond ReLU and linear networks, which are 1-homogeneous, our results also apply to networks using any positively $p$-homogeneous activation function. Specifically, for a 2-layer NN given by $g_{\\theta}(x) = U \\sigma(V^\\top x) $, the conserved quantities are $\\|u_i\\|^2 - \\|v_i\\|^2/p$, where $u_i$ and $v_i$ are the columns of $U$ and $V$, respectively. We plan to include this example in the supplementary material of the final version. While our framework and its generalization (refer to **W2a**) can cover more architectures, discussing them is beyond the scope of this paper.\n\n> **W2a** There is no comment on the explicit constructions of such quantities in generic cases, and no application cases where these numbers can be helpful.\n\nWe believe that determining this number is a fundamental question in the study of neural networks, as it can put an end to the “quest” for potential additional laws. We disagree with the perception of a “lack of comment on explicit constructions”: we provide explicit algorithms to compute both the number of conservation laws and the laws themselves, particularly when the models are polynomial. One significant application of these conservation laws is their ability to demonstrate that, in certain cases, high-dimensional flows can be recast in lower dimensions, see Section 3.4. Another application, which we will further emphasize in the paper, aids in convergence proofs; for instance, Theorem 5 of [6] and Section 2.5 of [*], utilize balancedness conditions which are conservation laws. While it is beyond the scope of this paper, our theory could easily be applied to other architectures, including residual connections, convolutional layers, and piecewise polynomial activations.\n\n[*] On the Convergence of Gradient Descent Training for Two-layer ReLU-networks in the Mean Field Regime, S. Wojtowytsch, 2020, preprint\n\n> **W3a** The main text lacks experiments, and the ones discussed in supplementary material are not sufficient. Explicit demonstration of conservation laws in simple neural network training might strengthen the paper.\n\nNumerical illustrations of conservation laws can be found, for instance, in Figure 1 of [7] for a 2-layer linear NN, in Figure 1c of [1] for a 3-layer linear NN, and in Figure 2 of [7] for a 3-layer ReLU NN. We will include these references. In the final version of the paper, we will incorporate such a figure into the supplementary material to further emphasize our main message.\n\n> **W4a** The definition of the main algorithm is obscure. A step-by-step implementation might help for clarity.\n\nThank you for the suggestion, we will add a pseudo-code in the final version to clarify it.\n\n> **Q1a** At line 120, if I am not mistaken, the fidelity function should be […] i.e. there is no summation over $k$ and the input is forgotten. Depending on how the authors feel, a subscript $f_{|\\Omega}$ can be added to emphasize locality.\n\nThank you, indeed there was a typo, we will correct this with a simpler (and correct!) expression using\n$ \\phi_j = \\phi_j(\\theta) := u_jv_j^\\top \\in \\mathbb{R}^{n \\times m}$, $\\phi(\\theta) = (\\phi_j )\\_{j}$ and \n$ f(\\phi) = \\sum\\_i \\ell( \\sum\\_j \\epsilon_{j,x_i} \\phi_j x_i, y_i)$.\n\n> **Q2a** In Eq. 3, a more generic expression should include the explicit derivative of the data fidelity function, since gradient flow may take us out the domain $\\Omega$ for which $df / d \\phi = \\partial\\_{\\phi} f$. Or are you implicitly assuming that infinitesimal gradient flow guarantees such deviations (for example in lazy learning regime)?\n\nIndeed it is a good idea to clarify by first writing that the gradient flow on $\\mathcal{E}$ is defined as $\\dot{\\theta}(t) = -\\nabla \\mathcal{E}(\\theta(t))$. Since we assume the factorization $\\mathcal{E} = f \\circ \\phi$ on a neighborhood of $\\theta_0$, for sufficiently small $t$ we deduce that the gradient flow satisfies Eq. 3. Our analysis of conservation laws is *local* to avoid considering what happens when we leave the domain.\n\n> **Q3a** The statement at line 168 is ambiguous to me; do you mean $\\nabla h \\perp \\chi, \\forall \\chi \\in V$?\n\nThe statement that we require is stronger: it means that $\\nabla h(\\theta) \\perp \\chi(\\theta), \\forall \\chi \\in V, \\forall \\theta \\in \\Omega$. In other words, it is a pointwise assumption: at every point $\\theta$, the vector $\\nabla h(\\theta) \\in \\mathbb{R}^D$ is orthogonal to the subspace $V(\\theta) \\subseteq \\mathbb{R}^D$. \n\n> **Q4a** It seems to me that the effect of loss function decouples from the analysis, since the arguments only depend on \\phi. Is it because the number of conserved quantities do not depend on the loss landscape but only the explicit form?\n\nAs summarized in ll 125–129, the main idea is indeed to decouple as much as possible the study of the conserved functions from the particularities of a dataset or a given loss. This is made possible when the factorization $\\mathcal{E} = f \\circ \\phi$ holds, and under some assumptions on the loss (see eq.7).\n\n'}}, {'summary': {'value': 'The paper studies conservation laws for deep neural networks when trained under gradient flow. Here, conservation laws refer to functions of network parameters that are invariant under gradient flow and such laws can potentially help us understand the training dynamics but constraining the manifold of parameters to a low-dimensional space and define robust symmetries of the underlying flow. This line of research had proven to be extremely fruitful for other areas of science, such as physics. The paper studies the number of such conservation laws for generic loss functions and datasets by factorizing the network function. They derive an analytical recipe to derive these numbers and provide explicit examples for simple network architectures. Finally, they provide an algorithm to compute these numbers.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper is mathematically engaging, well-written and the content is presented clearly.\n\nWhile previous work extensively studied conservation laws, these work often restricted to specific architectures such as deep linear networks and shallow ReLU networks. This study, as far as I am aware, is the first to generically study symmetries in training dynamics for arbitrary loss functions and datasets, and can be considered as a first step towards understanding the implicit constraints coming from symmetries of various network architectures.\n\nI believe this line of research may be impactful in many problems in DNN community such as pruning deep neural networks, principled approaches to building DNNs and more efficient training strategies.'}, 'weaknesses': {'value': '1. The paper is highly technical and only provides generic mathematical tools without brining additional insights over previous findings. Space permitting, it would be helpful to show more examples that go beyond what is already known.\n\n2. The main contribution of the paper is to derive the number of conserved quantities of a given neural network. There is no comment on the explicit constructions of such quantities in generic cases, and no application cases where these numbers can be helpful.\n\n3. The main text lacks experiments, and the ones discussed in supplementary material are not sufficient. Explicit demonstration of conservation laws in simple neural network training might strengthen the paper.\n\n4. The definition of the main algorithm is obscure. A step-by-step implementation might help for clarity.'}, 'questions': {'value': '1. At line 120, if I am not mistaken, the fidelity function should be $f(\\phi) = \\sum_i \\ell\\left(\\sum_{j,l} \\varepsilon_{j, x_i} \\phi_{j,k,l}  (x_i)_l, y_i\\right)$, i.e. there is no summation over $k$ and the input is forgotten. Depending on how the authors feel, a subscript $f_\\Omega$ can be added to emphasize locality.\n\n2. In Eq. 3, a more generic expression should include the explicit derivative of the data fidelity function, since gradient flow may take us out the domain $\\Omega$ for which $df/d\\phi = \\partial_\\phi f$. Or are you implicitly assuming that infinitesimal gradient flow guarantees such deviations (for example in lazy learning regime)?\n\n3. The statement at line 168 is ambiguous to me; do you mean $\\nabla h \\perp \\chi, \\forall \\chi \\in V$?\n\n4. It seems to me that the effect of loss function decouples from the analysis, since the arguments only depend on $\\phi$. Is it because the number of conserved quantities do not depend on the loss landscape but only the explicit form?'}, 'limitations': {'value': 'The applicability of the theory to practical neural networks is very restricted at the moment.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper studies the conservation laws, which are quantities that remain constant, in over-parametrized gradient flows. The authors provide a formal definition for independent conserved functions, which are required to have linearly independent gradients. By applying Frobenius theorem, the authors show that the number of independent conservation laws is linked to the dimension of the trace of the Lie algebra generated by the vector fields spanned by the Jacobian. When this vector field is a Lie algebra, Frobenius theorem can be applied directly to obtain the number of independent conservation laws. When the vector field is not a Lie algebra, the generated Lie algebra need to be computed before applying Frobenius theorem. The authors explicitly compute the Lie algebra and its trace for two layer linear networks and certain ReLU networks, obtained the number of independent conservation laws, and prove that the conservation laws discovered in previous literature are complete. They implement their algorithm in SageMath that constructs a basis of polynomial conservation laws for the above examples, and successfully verify the number of independent conservation laws. \n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- This paper is the first to formally define and study the number of independent conservation laws in gradient flow. Previous works mostly focus on finding conserved quantities in different architectures or using them in convergence proofs. This paper provides a new perspective and contributes to a unified framework of conservation laws in gradient flows.  \n- Using Frobenius theorem to characterize the number of independent conservation laws is novel. By linking to the dimension of the trace of the Lie algebra generated by the Jacobian, the authors present the first known method to determine the number of conservation laws. This method yields the interesting result that known conservation laws are complete in 2-layer linear networks.\n- The idea that conserved functions define invariant hyper-surfaces which trap the gradient flow is interesting and useful. Studying the dimension of these surfaces directly leads to the proposed definition of independent conserved functions.\n- The authors provide a condition under which gradient flows can be recast as low-dimensional Riemannian flows (proposition 3.8), which has potential applications on choosing initializations for better convergence.\n'}, 'weaknesses': {'value': '- The paper’s contribution is overall limited in the aspect of applications. Explicit conservations laws are only given for two-layer linear networks and certain two-layer ReLU networks. The analysis is applied to continuous gradient flow only, and there is no discussion or experiment that verify how well the conservation laws hold in gradient descent. Many neural networks today have more complicated architectures, such as residual connections and various activations other than ReLU, and are often trained with different optimization algorithms, such as Adam. Therefore, while this paper is a promising start to understand implicit bias, more work is needed to obtain insights useful for common machine learning tasks.\n- The abstract vaguely mentions “understanding desirable properties of optimization initialization in large machine learning models”, but the paper provides little supporting arguments. It is not clear what the desirable properties are, and whether it is possible to extend the conservation laws to more realistic settings in large models.\n- The requirement to factor the cost in equation 2 seems strict - $f$ cannot depend on $\\theta$ and $\\phi$ cannot depend on the data and the loss $l$. Factorization for two-layer ReLU network (Example 2.2) is a good example that extends beyond linear networks. However, it is not clear whether this is possible with other activation functions, where the pre-activation is not piecewise linear.\n- There are a few cases where definitions and theorems are mentioned well before the formal statement, for example, in line 134-135, 156-157, 168, 270, etc. Perhaps the organization could be improved to reduce the complexity of the logic flow.\n'}, 'questions': {'value': '- The factorization for two-layer ReLU network requires that $\\epsilon_{j,x_i} = \\mathbb{1} (v_j^T x_i) > 0$ is constant. How likely does this condition hold throughout the gradient flow? \n- Would it be possible to include a brief summary of what the Frobenius theorem is about? This theorem appears to be an important foundation, but the form used in this paper (theorem A.12) appears different from the theorem in the given reference [10] (“Theorem 1.4.1. A nonsingular distribution is completely integrable if and only if it is involutive.”)\n- Conservation laws is also an important concept in physics. Is the algorithm that constructs conservation laws related to methods in physics, such as the the Noether’s theorem or conserved quantities from the Killing vector field? Has there been similar analysis on the number of conservation laws for physical systems? '}, 'limitations': {'value': 'The authors included limitations by clearly stating the assumptions. There are no potential negative societal impacts of the work.\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper discusses the geometric properties of gradient descent dynamics in ML models. The authors aim to understand the properties of the optimization initialization that are preserved during the dynamics, which is often referred to as being an ""implicit bias"" of the training algorithm. They also focus on the maximal sets of independent quantities conserved during gradient flows. They have an interesting approach to find the exact number of these conserved quantities by performing algebraic manipulations on the Lie algebra generated by the Jacobian of the model.\n\nThe paper\'s contributions include formalizing the notion of a conservation law in the setting of training neural networks, proposing an algorithm to identify simply expressed (e.g., polynomial) conservation laws on ReLU NNs, and illustrating how these findings can rewrite an over-parameterized flow as an ""intrinsic"" low-dimensional flow. I find it very intriguing that the commonly reported conservation laws in the literature happen to be maximal (at least empirically).'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The manuscript has many strengths and overall I think this is a welcomed contribution to the literature. The manuscript covers various aspects of gradient dynamics, conserved functions, conservation laws, Lie algebra, and their applications in neural networks with illustrative examples. There is also potentially interesting practical consequences of this work. It seems to be a relatively practical approach for determining the number of conservation laws using Lie Group computations, at least on NNs with piecewise linear activation functions. It is interesting that their algorithms confirm (at least empirically) that the conservation laws for ReLU NNs match the laws already known. '}, 'weaknesses': {'value': 'A few weaknesses are: \n\n- Mostly restricted to deep shallow NNs, continuous-time gradient descent, and simple NN architectures. This limits the applications of the theory to practical situations. The continuous-time restriction on the gradient descent training algorithm is perhaps the more \n\n- In most situations, the generated Lie algebra is going to be infinite-dimensional.  In fact, the two examples in the manuscript are contrived so that the Lie algebra ends up being finite-dimensional. The discussion on the case when the Lie algebra is infinite-dimensional, is only briefly discussed. I would suggest that the author discussed this more. In particular, the stopping criteria are based on the trace of Lie group algebra. \n\n- The above discussion is particularly important for hoping to apply these techniques on NNs with activation functions that are not piecewise linear. '}, 'questions': {'value': '- Can you add more discussion on the situation where the Lie algebra is infinite-dimensional? \n\n- Can you add more discussion on what happens when the activation functions of the NN are not piecewise linear? '}, 'limitations': {'value': 'There are no potential negative societal impacts of this work. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper studies the conservation law of gradient flow dynamics for training neural networks. The authors propose a method to determine the number of conservation laws in given gradient flow dynamics using Lie algebra generated by the Jacobian vector fields. It is shown, either theoretically or empirically, that the known conservation laws in training linear networks and ReLU networks are also maximal.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. The paper is well-written and clear. The conversation laws in gradient flow dynamics for training neural networks have facilitated the analysis of convergence and implicit bias, thus deserving formal analysis on finding these conversation laws given any network architecture.\n2. This paper has an in-depth discussion of the conservation law under the gradient flow on a class of loss functions.\n3. Analysis via Lie algebra that determines the maximum number of conservation laws.\n4. Showing existing conservation laws studied for linear and ReLU networks are maximal\n\n'}, 'weaknesses': {'value': 'none'}, 'questions': {'value': 'Do the results stated for ReLU networks hold for any network with homogeneous activation function?'}, 'limitations': {'value': 'authors discussed the limitation.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors study conservation laws in the gradient flow dynamics of neural networks.\nThey introduce a notion of local factorisation of the loss, stating that the loss in the neighbourhood of a given wieght vector can be decomposed in a composition of functions, a data-independent term $\\phi$ followed by a data dependent one $f$.\n\nUnder this decomposition, the authors set out to characterise conserved quantities for fixed $\\phi$ and for all $f$ giving rise to a proper ERM loss.\nThey claim that under some assumption, and for ReLU networks, this is equivalent of characterising conserved quantities for fixed $\\phi$ and for all smooth $f$.\nMore strongly, they claim that this is also equivalent to characterising conserved quantities for fixed $\\phi$ and for a special finite dimensional subspace of function, living in the linear span of the $d$ rows of the Jacobian of $\\phi$, where $d$ is the dimension of the codomain of $\\phi$.\n\nThe authors then notice that the conservation laws of linear and ReLU networks will be polynomial in the weights, and consider the question of characterising maximal sets of conservation laws.\nThey link such number to the dimension of the Lie algebra generated locally by the $d$-dimensional vector field associated to the Jacobian of $\\phi$, and work-out explicitly some examples.\n\nFinally, the authors consider the question whether the known conservation laws for two-layers linear and ReLU networks form a maximal set, and find an affirmative answer.\nThey conjecture, and briefly discuss this point in Appendix 9, that the same results hold for larger depths.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': '- The article is well written, and guides the reader nicely through quite technical results without requiring too much previous knowledge.\n- The results seem novel to the extent of my knowledge of the literature, which is not comprehensive on this subject. They seem to fit nicely into a pre-existing line of works (see ref [13] and [26] for example).\n- The main text provides reasonable justification for most of the formal results, which are proven in the Appendix. While I did not check the correctness of the proofs, the results seem reasonable.'}, 'weaknesses': {'value': '\n- It is not clear to what extent the factorisation property the authors introduce is necessary to their analysis. Said differently, it is not clear wehther the analysis could be performed similarly on a concrete example (say fixed dataset) without any mention of a factorisation. The authors could add additional high-level explanations/justifications of this concept.'}, 'questions': {'value': '\n## Major questions\n\n- It is not clear to me whether the requirement in Eq. 2 is vacuous, meaning that any architecture automatially satisfies it. Can\'t I just take $\\phi$ as the identity map, and $f = \\mathcal{E}$? If this trivial factorisation is possible, are the results still non-trivial? Maybe I am losing some very simple nuance. In any case, adding a counter-example, or clarifying better the requirements on $\\phi$ and $f$ could avoid doubts.\n\n- Example 2.2 provides only a local factorisation for ReLU networks. Of course locality is ok as we are considering gradient flow dynamics, which is local. But I wonder whether something special can happen at the boundaries of the set $\\Omega$ defined in Example 2.2, i.e. if there is some gluing condition/gluing phenomenon that may affect the results presented by the authors.\n\n- Is there a commonly used loss for which Eq. 7 is not satisfied?\n\n- The authors stress that their results allow for explicit construction of maximal sets of conserved quantities, yet in the manuscript they provide only an a posteriori verification that known conserved quantities in previously studied architectures indeed form maximal sets. Is there an architecture where new conservation laws can be found through the presented techniques?\n\n## Suggestions for manuscript improvement\n\nline 50: missing closing bracket\n\nline 106: specifying that $D$ is the number of weigths, and $d$ is the dimension of the ""internal representation"" of the decomposition $\\mathcal{E} = f \\circ \\phi$ would be helpful for the reader.\n\nline 119: in the inlined equation, one has a tensor $\\phi$ with three free indices equal to an expression without the same three free indices. I suggest to clarify this writing somehow. '}, 'limitations': {'value': 'The authors briefly discuss limitations in the main text.\nI would add that the analysis seems to be limited to linear and ReLU architectures 2 layer architectures. It is not clear whether a local factorisation of the form Eq. 2 can be found for other architectures. The authors could maybe add a discussion on this point.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Abide by the law and follow the flow: conservation laws for gradient flows'}, 'authors': {'value': ['Sibylle Marcotte', 'Rémi Gribonval', 'Gabriel Peyré']}, 'authorids': {'value': ['~Sibylle_Marcotte1', '~Rémi_Gribonval1', '~Gabriel_Peyré2']}, 'keywords': {'value': ['Implicit bias', 'conservation laws', 'gradient flow', 'linear neural network', 'matrix factorization']}, 'abstract': {'value': 'Understanding the geometric properties of gradient descent dynamics is a key ingredient in deciphering the recent success of very large machine learning models. A striking observation is that trained over-parameterized models retain some properties of the optimization initialization. This ""implicit bias"" is believed to be responsible for some favorable properties of the trained models and could explain their good generalization properties. The purpose of this article is threefold. First, we rigorously expose the definition and basic properties of ""conservation laws"", that define quantities conserved during gradient flows of a given model (e.g. of a ReLU network with a given architecture) with any training data and any loss. Then we explain how to find the maximal number of independent conservation laws\nby performing finite-dimensional algebraic manipulations on the Lie algebra generated by the Jacobian of the model. Finally, we provide algorithms to: a) compute a family of polynomial laws; b) compute the maximal number of (not necessarily polynomial) independent conservation laws. We provide showcase examples that we fully work out theoretically. Besides, applying the two algorithms confirms for a number of ReLU network architectures that all known laws are recovered by the algorithm, and that there are no other independent laws. Such computational tools pave the way to understanding desirable properties of optimization initialization in large machine learning models.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/7b766b2698788a69d39692e5b346421ae2b4c83e.pdf'}, 'supplementary_material': {'value': '/attachment/bce115bec8e52f5168e05eb8ae1397c1d50bbcb9.pdf'}, '_bibtex': {'value': ""@inproceedings{\nmarcotte2023abide,\ntitle={Abide by the law and follow the flow: conservation laws for gradient flows},\nauthor={Sibylle Marcotte and R{\\'e}mi Gribonval and Gabriel Peyr{\\'e}},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=kMueEV8Eyy}\n}""}, 'paperhash': {'value': 'marcotte|abide_by_the_law_and_follow_the_flow_conservation_laws_for_gradient_flows'}}]"
"['Fabian Zaiser', 'Andrzej Murawski', 'Chih-Hao Luke Ong']",NeurIPS,Exact Bayesian Inference on Discrete Models via Probability Generating Functions_ A Probabilistic Programming Approach,https://neurips.cc/virtual/2023/oral/73866,2023," We present an exact Bayesian inference method for discrete statistical models, which can find exact solutions to a large class of discrete inference problems, even with infinite support and continuous priors.To express such models, we introduce a probabilistic programming language that supports discrete and continuous sampling, discrete observations, affine functions, (stochastic) branching, and conditioning on discrete events.Our key tool is probability generating functions :they provide a compact closed-form representation of distributions that are definable by programs, thus enabling the exact computation of posterior probabilities, expectation, variance, and higher moments.Our inference method is provably correct and fully automated in a tool called Genfer , which uses automatic differentiation (specifically, Taylor polynomials), but does not require computer algebra.Our experiments show that Genfer is often faster than the existing exact inference tools PSI, Dice, and Prodigy.On a range of real-world inference problems that none of these exact tools can solve, Genfer's performance is competitive with approximate Monte Carlo methods, while avoiding approximation errors.",Oral 1C Tractable models,https://openreview.net/pdf?id=FtNruwFEs3,https://openreview.net/forum?id=FtNruwFEs3,FtNruwFEs3,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper introduces probabilistic program inference by means of probability generating functions.\nReviewers agree the analysis is rigorous, and the idea is novel in the probabilistic programming context, even if there are some limitations to the technique. Overall a very solid contribution to the field.'}}, {'comment': {'value': ""Thank you for this very thorough response. The comparison to PSI and Prodigy makes the value of your novel contributions (in particular the AD-based implementation) even clearer, and accordingly I am raising my score to an 8.\n\nI hope that in revision you will find the space to include some of the points from your responses in the paper or appendix. In particular, if you have the space, I'd like to see the ideas from your first two bolded paragraphs in the general response included, as well as the point about why GF semantics for functional languages might be more difficult.""}}, {'title': {'value': 'Read the rebuttals'}, 'comment': {'value': 'To the authors,\n\nThank you for your clear and enlightening rebuttal and for addressing my comments.'}}, {'title': {'value': 'Thanks for the response'}, 'comment': {'value': 'I thank the authors for the response which addressed my concerns. Please add the relevant discussions and clarifications as mentioned in the rebuttal.'}}, {'comment': {'value': ""I have read the authors' response and stand by my score. Will be glad to see the paper accepted.""}}, {'rebuttal': {'value': '> The novel capabilities (and limitations) with respect to the line of work by Klinkenberg et al. could be more clearly described. It would also be good to cite and explain the differences with their recent LAFI abstract\n\nThe ideas alluded to in their LAFI abstract are now available in a more fleshed-out form as a preprint (https://arxiv.org/abs/2307.07314). (Note that this was posted on arXiv after the NeurIPS submission deadline.) The main difference is that their work only supports discrete distributions and yields a symbolic representation of the GF for the posterior distribution. They also have some support for loops, which requires the user to provide a loop invariant template. On the other hand, our approach allows for some continuous distributions and is (usually) much more performant and scalable, because we only evaluate the derivatives of the generating function instead of representing them fully symbolically (cf. the comparison with PSI and Prodigy in the general rebuttal). We will add a discussion of this to the paper.\n\n> It is unclear to what extent the limitations of the language are fundamental limitations of the generating function technique, vs. concessions made to get to a simple first publication/implementation of the idea.\n\nWe give a high-level answer to this in the general rebuttal. Details on your specific questions follow here.\n\n> Could the technique be extended to programs with loops, or does that seem unlikely?\n\nSupporting exact inference for programs with loops seems extremely difficult, unless the inference algorithm is given additional information, e.g. a loop invariant (see the work of Klinkenberg et al.). However, finding such a loop invariant for nontrivial programs seems exceedingly difficult. Furthermore, the variables of looping programs may have infinite expected values, so the generating function may not be definable at the point 1. But in our semantics, evaluating at 1 (for marginalization) is very important. So there are many challenges and opportunities for future research here.\n\n> What about compound distributions with more than one random parameter (e.g., Binomial where both n and p is also random)?\n\nIt is hard to say with certainty (somebody might find a closed form that nobody expected), but we tried very hard to find additional compound distributions that admit a closed form and were unsuccessful. The only additional compound distributions we can support are `Binomial(n, X)` and `Gamma(X, a)`, as mentioned in the general rebuttal.\n\n> What about ‘score statements’ that multiply a non-negative (affine?) expression into the likelihood? It seems this should be possible for scores < 1, because we can observe 1 ~ Bernoulli(X), but can it be made to work for more general scores?\n\nAs mentioned in the general rebuttal, `score a^X` for nonnegative real `a` < 1 and variable `X` should be supportable. (For `a` > 1, this runs into problems: the GF may not be defined at 1 anymore.) Nonnegative affine scoring (or even nonnegative polynomial scoring) should be possible as well, using a similar technique as for observing from `Bernoulli(X)`. We didn’t include this because we did not find any real-world example to use it.\n\n> But it would be nice to understand how the new approach compares to existing methods on the programs that both approaches can handle.\n\nIn the general rebuttal, we attached a comparison with Klinkenberg’s approach to generating functions and the PSI solver.\n\n> L310-312 incorrectly state that WebPPL does not support SMC or particle MCMC\n\nThank you very much for pointing this out. We will of course correct this statement in the paper. It seems that the documentation of WebPPL’s inference algorithms (http://docs.webppl.org/en/master/inference/methods.html) is incomplete and there are more undocumented algorithms available (such as Particle MCMC).\n\n> Are you 100% sure that systems like Hakaru and λPSI cannot handle your examples?\n\nWe tested λPSI and it could not solve any of our examples. We did not test Hakaru because it is quite difficult to get running, requires a Maple license, and benchmarks in the PSI paper indicated that PSI was more performant and able to solve more benchmarks than Hakaru. Even if Hakaru is able to solve small examples, as a fully symbolic tool, it is unlikely to scale to our examples given that even Prodigy (which already exploits the generating function structure) times out.\n\n> What are the prospects for a generating-function semantics of a functional (rather than imperative) source language, such as Anglican (but suitably restricted)?\n\nWe believe it should be possible to define a generating-function semantics for a functional language (after all, a functional program can be translated to an imperative one), but it is highly nontrivial: semantics for functional languages usually rely on composition, but the generating functions describe the joint distribution of all variables in the program at any point – we never reason “locally” about only a subset of the variables because this would lose information. So this is an open research question.\n'}}, {'rebuttal': {'value': '> The paper seems to miss discussions on probabilistic circuits which is a large body of work concerning probabilistic models with tractable inference.\n\nThank you for pointing this out. Probabilistic circuits (Choi et al., 2020) are indeed a family of probabilistic models that allow for efficient and exact inference, unifying and generalizing many previously introduced tractable probabilistic models (e.g. arithmetic circuits, sum-product networks, and cutset networks). Two exact inference systems that we cite are connected to probabilistic circuits: SPPL (Saad et al., PLDI 2021) extends sum-product networks, and Dice (Holtzen et al., OOPSLA 2020) is based on Weighted Model Counting on binary decision diagrams. After the NeurIPS submission deadline we even learned about work applying generating functions to probabilistic circuits, called “Probabilistic Generating Circuits” (Zhang et al., ICML 2021; Harviainen et al., UAI 2023). It should be noted, however, that the latter circuits only support binary random variables, whereas we support variables with infinite support. We will add a discussion of probabilistic circuits, and probabilistic generating circuits in particular, to the related works section of the paper.\n\n> how this can potentially be integrated into/work together with other more general PPLs\n\nPlease refer to the general rebuttal regarding this point.\n\n> The current title and abstract seems slightly misleading, in the sense that the proposed PPL is not generally applicable to any discrete distributions. It would be better to rephrase to make the scope of its applicability clearer, and also emphasize its targeted use case is distributions with variables having infinite support.\n\nIt is true that the title is not a complete description of our setting, but we believe the title is quite long already, so we would prefer not to add extra clarifications. We’ve made an effort to be as transparent about the limitations and restrictions about our approach as possible (paragraph “Limitations” in the introduction and “Restrictions” in Section 2). In the abstract, we are explicit about which language constructs are supported, so we did not feel this was misleading. We could add a sentence listing unsupported constructs, but this would just be a negation of the supported constructs (no continuous observations, no non-affine functions, etc.), so it seems redundant. There are subtleties (such as which compound distributions we support), but we believe that this would be too detailed for an abstract and we discuss it in the above paragraphs in the paper. However, we will clarify in the abstract that we only support observing events involving *discrete* variables and that our method is not applicable to all discrete distributions.'}}, {'rebuttal': {'value': '> making explicit the if-and-only-if conditions that must be met for generating functions to support closed-form inference\n\nPlease refer to our general rebuttal for the “only-if” aspect (whether additional constructs could be added to the programming language while still preserving a closed form). For the “if”-direction, the syntax of our language guarantees that the generating function has a closed form.\n\n> How could the exact inference algorithm in this paper be used in a larger probabilistic programming framework?\n\nPlease refer to the general rebuttal for this point as well.\n\n> When the paper mentions outputting posterior probability masses for certain intervals of integer-valued latent variables, why not also include densities for continuous latent variables?\n\nWhile there are mathematical ways of recovering the probability density function from a generating function via an inverse Laplace transform, this cannot be automated in practice because it requires solving integrals, which is intractable in general. So outputting posterior densities is not possible, as far as we know.\n'}}, {'rebuttal': {'value': ""> The PPL is implemented in Rust, a language which, while it certainly has its merits, less popular for statistical modelling and Bayesian inference, which may make adoption of the approach more difficult.\n\nIt is correct that Rust is not used in Bayesian inference very much. However, it would not be too difficult to implement, say, a Python API calling Rust under the hood. Many Python libraries work that way (e.g. PyTorch calling C++). Developing the Python interface is mostly an engineering problem, whereas we wanted to focus on the research questions and a proof of concept in our work.\n\n> What prevents you from implementing restricted loops in the language?\n\nThere is no particular reason why we couldn’t have implemented bounded loops in our language. But since this does not affect the expressiveness of the language, we preferred the conceptual simplicity of omitting them.\n\n> The syntax in the examples is richer than the BNF in the paper. What is '+~' for example? Can you define the full syntax in the paper, at least briefly?\n\nYou are correct that the examples use syntax that is slightly richer than the one provided in the paper. We introduced additional constructs to reduce the number of temporary variables needed; this does not affect the expressivity of the language. There are three additional constructs:\n\n* `X +~ D;` stands for `TMP ~ D; X := X + TMP`\n* `X += a * Y + b;` stands for `TMP := a * Y + b; X := X + TMP;`)\n* `if n ~ D { … } else { … }` stands for `TMP ~ D; if TMP = n { … } else { … }`\n\nWe will add an explanation of these constructs to the paper.\n\n> Why Rust? Have you considered other options?\n\nThe main reasons were low-level control and performance. The operations on the Taylor polynomials (to evaluate derivatives of the generating function) need to be fast and we have a few optimizations that exploit the structure of GFs arising from probabilistic programs. C or C++ would have satisfied this criterion as well, but Rust’s language features like memory safety, enums (tagged unions), and pattern matching made the implementation a lot more pleasant, robust, and easier to maintain. The first author’s experience with Rust was another contributing factor.\n""}}, {'rebuttal': {'value': 'First of all, we would like to thank the reviewers for their thoughtful reviews and interesting questions about our work. We are delighted that the reviewers think that our approach is “significant” (JaNH), “novel and very useful” (SkQ5), that our analysis is “rigorous” (c91c, JaNH), that our implementation compares favorably”in the experimental evaluation (c91c, hi49), and that our presentation is “well-organized and clearly written” (SkQ5). We will try to answer the reviewers’ questions in the following.\n\nIn this general rebuttal, we will address points that came up in more than one review or are of interest to more than one reviewer. Specific questions will be discussed in the individual responses.\n\n**Integration with more general probabilistic programming systems (reviewers hi49 & SkQ5)**: Given the restrictions on the programs where our method can be applied, it is a natural question to ask how it could be integrated with a more general probabilistic programming system. We believe this should be possible. For example, in a sampling-based inference algorithm, one could imagine using generating functions to solve subprograms exactly if this is possible (rather than sampling the variables in those subprograms as well). Investigating the details and how well such an approach would work in practice is an interesting research question.\n\n**Conditions for closed-form generating functions (reviewers hi49 & JaNH)**: we were asked for exact conditions under which the generating function of a probabilistic program admits a closed form. The answer is that we tried to make the programming language in the paper (SGCL) as expressive as possible while still maintaining a closed form for the generating function. There are only the following possible additions to the language (that we know of) that preserve closed forms for the GFs but that we didn’t include:\n\n* more distributions with constant parameters: as long as its generating function exists and that function and its derivatives can be evaluated, the distribution can be supported.\n* the compound distribution Binomial(n, X), where the success probability is a variable, but this is already expressible as the sum of n independent Bernoulli(X) variables.\n* the compound distribution Gamma(X, a), where X is the shape parameter\n* the constructs `X mod 2 = 0`, `X := max(X - 1, 0);`, `X := sum_iid(D, Y);` where `D` is a primitive distribution and `X`, `Y` nonnegative integer variables, as mentioned in Klinkenberg et al.’s work\n* `score(a^X);` statements for `a` < 1 or `score(q(X));` where `q` is a polynomial with nonnegative coefficients should also be supportable. (A `score` statement multiplies the likelihood by the given expression).\n\nWe did not include these constructs because we could not find a real-world example that can use them. It is obviously impossible to say with certainty that no other constructs preserve closed forms (because there are infinitely many possible constructs we might not have thought of). But we tried very hard to express more concepts (e.g. observations from continuous distributions) in terms of generating functions but could not find anything else that works. We will add these remarks to the appendix of our paper.\n\n**Comparison with existing exact tools (reviewer JaNH)**: Reviewer JaNH said it would be interesting to compare our new approach with existing ones on benchmarks that both methods can handle. Accordingly, we decided to compare the PSI tool for exact symbolic inference with our tool on benchmarks that both can handle (i.e. finite discrete distributions). Furthermore, the Prodigy tool by Klinkenberg et al. (which also uses generating functions, but in combination with computer algebra instead of automated differentiation) recently gained the ability to deal with conditioning as well. (A preprint of this work was posted to the arXiv after the NeurIPS submission deadline: https://arxiv.org/abs/2307.07314.) Thus, we decided to compare PSI, Prodigy, and our tool on the subset of Prodigy’s benchmarks that all three tools can handle. The results can be found in the attached PDF. As you can see, our tool is very much competitive and often fastest on these examples. Furthermore, we tried running Prodigy on our benchmarks, but it either does not support them (because of continuous priors), runs out of memory, or times out after 30 min (whereas our tool finishes in seconds). This confirms our claim about the better scalability of our method compared to fully symbolic approaches.'}, 'pdf': {'value': '/pdf/789c2682f2e321880cbbf359cc20f7d262d1c822.pdf'}}, {'summary': {'value': 'A probabilistic programming framework for exact inference in discrete probabilistic programs with infinite support is introduced. The framework levegares probability generating functions as a first class attribute of discrete distributions. The probabilistic programming language is formally defined, inference is theoretically analysed for correctness. The performance and accuracy are empirically evaluated and compared with baselines on real-world examples.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper brings the idea of using GF as a first-class property of a distribution into a practical implementation as a probabilistic programming language. Formal properties of the language and inference are rigorously analysed. The empirical evaluation demonstrates capabilities of the approach, and favorably compares to alternatives. The submission is accompanied by a working and well organized code based.'}, 'weaknesses': {'value': 'The PPL is implemented in Rust, a language which, while it certainly has its merits, less popular for statistical modelling and Bayesian inference, which may make adoption of the approach more difficult. This is a matter of taste though.'}, 'questions': {'value': ""You apparently unroll loops in your benchmarks (I assume because the language does not support loops). What prevents you from implementing restricted loops in the language?\n\nThe syntax in the examples is richer than the BNF in the paper. What is '+~' for example? Can you define the full syntax in the paper, at least briefly?\n\nWhy rust? Have you considered other options?\n\n""}, 'limitations': {'value': 'The paper adequately discusses limitations of the proposed solution.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper presents a restricted, first-order probabilistic programming language in which inference for infinite-support latent variables, with continuous or discrete sample spaces, admits a closed form.  For experiments they compare against importance sampling, Lightweight M-H, Random Walk M-H (RMH), sequential Monte Carlo, particle Gibbs sampling, and interacting particle MCMC (IPMCMC) in the Anglican universal PPL.  The authors achieve much lower error than Monte Carlo sampling across experiments, typically with significantly less compute.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The paper demonstrates that when latent variables are subject only to affine transformations, a first-order (lacking general recursion) probabilistic programming language can admit tractable exact inference for certain important classes of discrete observations. Even when the resulting exact inference engine takes compute time comparable to the Anglican Monte Carlo inference routines, it tends to run in the middle of the pack while providing much lower approximation error.'}, 'weaknesses': {'value': 'Since the paper focuses on proving and benchmarking something that has an exact answer, it has few weaknesses as such.  It could perhaps have done a better job of making explicit the if-and-only-if conditions that must be met for generating functions to support closed-form inference.\n\nThe authors have addressed this concern in the rebuttal.'}, 'questions': {'value': 'How could the exact inference algorithm in this paper be used in a larger probabilistic programming framework, such as when probabilistic circuits admitting exact density calculations are applied as proposals in a broader family of inference algorithms?  When the paper mentions outputting posterior probability masses for certain intervals of integer-valued latent variables, why not also include densities for continuous latent variables?\n\nThe authors have addressed these questions in their response.'}, 'limitations': {'value': 'The authors have admitted the limitations of their work, and in exchange for those limitations in expressivity they gain performance in both error and compute time.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes a new probabilistic programming language called statistical guarded command language (SGCL) and an exact Bayesian inference method for any discrete statistical model that can be expressed in SGCL. Empirical evaluatios on a variety of different discrete probabilistic models demonstrate the effectiveness of the method, especially for challenging distributions with discrete variables that have infinite support.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The paper is well organized and clearly written.\n- The proposed method seems novel, and is very useful especially for challenging discrete distributions involving variables with infinite support.\n'}, 'weaknesses': {'value': '- The paper seems to miss discussions on probabilistic circuits which is a large body of work concerning probabilistic models with tractable inference.\n- Given the limitations of the proposed PPL and its specialized use cases, it would also be helpful to add some discussions on how this can potentially be integrated into/work together with other more general PPLs to expand the applicability of the proposed method.\n- The current title and abstract seems slightly misleading, in the sense that the proposed PPL is not generally applicable to any discrete distributions. It would be better to rephrase to make the scope of its applicability clearer, and also emphasize its targeted use case is distributions with variables having infinite support.\n'}, 'questions': {'value': 'See weaknesses.'}, 'limitations': {'value': 'The authors adequately addressed the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes a new approach to exact inference in probabilistic programs. Existing approaches to exact inference attempt to compute marginal and normalized probabilities by efficiently computing the necessary (finite) sums, or using computer algebra to recognize and solve tractable integrals. By contrast, the present work constructs the moment-generating function ($G(x) = \\mathbb{E}_{X \\sim \\mu}[x^X]$) for the distribution represented by the program, and takes its (higher-order) derivatives (using AD) to compute exact posterior marginal probabilities, as well as exact moments. This enables automated exact inference in a broader class of models than handled by existing techniques. The approach is implemented in Rust, and experiments in four example models show that their implementation typically computes exact answers in less time than it takes for Anglican’s generic Monte Carlo algorithms (e.g., sequential Monte Carlo with the prior as the proposal) to converge to accurate estimates.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The key strengths I see in this paper are:\n\n- It introduces a significant new approach to PPL inference (automatic differentiation on compositionally constructed moment-generating functions), and I believe it’s important enough that most people working in PPLs will want to understand the new technique. The exposition is clear and should be accessible to a broad probabilistic programming audience.\n- The generating function approach resolves a key limitation of other exact inference methods: it can marginalize latent variables with infinite support.\n- Limitations of the language, and performance concerns, are clearly outlined (e.g., in the Restrictions paragraph on L147, and the Limitations paragraph on L83).\n- The appendix contains rigorous correctness proofs and further exposition of the generating function semantics. There is also a Rust implementation that helps clarify the actual implementation of the technique (e.g., the data representation of Taylor polynomials used by the AD algorithm).'}, 'weaknesses': {'value': 'The key weaknesses I notice are:\n\n- The novel capabilities (and limitations) with respect to the line of work by Klinkenberg et al. could be more clearly described. It would also be good to cite and explain the differences with their recent LAFI abstract, “Exact Probabilistic Inference Using Generating Functions” (https://arxiv.org/pdf/2302.00513.pdf). That workshop abstract is non-archival and much less thorough than the present work, so I don’t mean this as a critique of your work’s novelty. But I think readers will appreciate a clear-eyed description of exactly how their proposed approach differs from yours.\n- It is unclear to what extent the limitations of the language are fundamental limitations of the generating function technique, vs. concessions made to get to a simple first publication/implementation of the idea. Could the technique be extended to programs with loops, or does that seem unlikely? What about compound distributions with more than one random parameter (e.g., Binomial where both $n$ and $p$ is also random)? What about ‘score statements’ that multiply a non-negative (affine?) expression into the likelihood? (It seems this should be possible for scores < 1, because we can `observe 1 ~ Bernoulli(X)`, but can it be made to work for more general scores?)\n- The experiments are all on programs for which existing exact inference methods fail. But it would be nice to understand how the new approach compares to existing methods on the programs that both approaches can handle. (Even if it is much less efficient, I believe the method still warrants publication, but it would be useful to readers to understand the expressiveness / efficiency trade-offs clearly.)\n- L310-312 incorrectly state that WebPPL does not support SMC or particle MCMC. See the SMC and PMCMC implementations here: https://github.com/probmods/webppl/tree/master/src/inference.'}, 'questions': {'value': '1. Are you 100% sure that systems like Hakaru and $\\lambda$PSI cannot handle your examples? I don’t have a great handle on their capabilities, but I expect Maple’s computer algebra simplifications can handle at least some infinite sums and integrals. Have you tried implementing the example programs and seeing what these tools spit out?\n2. What are the prospects for a generating-function semantics of a functional (rather than imperative) source language, such as Anglican (but suitably restricted)?'}, 'limitations': {'value': 'The paper is up-front about both the expressiveness limitations of the probabilistic language they support, and the factors in which their algorithm scales exponentially.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Exact Bayesian Inference on Discrete Models via Probability Generating Functions: A Probabilistic Programming Approach'}, 'authors': {'value': ['Fabian Zaiser', 'Andrzej S Murawski', 'Luke Ong']}, 'authorids': {'value': ['~Fabian_Zaiser1', '~Andrzej_S_Murawski1', '~Luke_Ong1']}, 'keywords': {'value': ['Bayesian statistics', 'probabliistic programming', 'exact inference', 'discrete models', 'probability generating functions']}, 'abstract': {'value': ""We present an exact Bayesian inference method for discrete statistical models, which can find exact solutions to a large class of discrete inference problems, even with infinite support and continuous priors.\nTo express such models, we introduce a probabilistic programming language that supports discrete and continuous sampling, discrete observations, affine functions, (stochastic) branching, and conditioning on discrete events.\nOur key tool is *probability generating functions*:\nthey provide a compact closed-form representation of distributions that are definable by programs, thus enabling the exact computation of posterior probabilities, expectation, variance, and higher moments.\nOur inference method is provably correct and fully automated in a tool called *Genfer*, which uses automatic differentiation (specifically, Taylor polynomials), but does not require computer algebra.\nOur experiments show that Genfer is often faster than the existing exact inference tools PSI, Dice, and Prodigy.\nOn a range of real-world inference problems that none of these exact tools can solve, Genfer's performance is competitive with approximate Monte Carlo methods, while avoiding approximation errors.""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/244ae93dfe1df9844d74b9481f716ba9fdd9689b.pdf'}, 'supplementary_material': {'value': '/attachment/00ae51f659ea1e5585cc2abbc08b316fccfa53d0.zip'}, '_bibtex': {'value': '@inproceedings{\nzaiser2023exact,\ntitle={Exact Bayesian Inference on Discrete Models via Probability Generating Functions: A Probabilistic Programming Approach},\nauthor={Fabian Zaiser and Andrzej S Murawski and Luke Ong},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=FtNruwFEs3}\n}'}, 'paperhash': {'value': 'zaiser|exact_bayesian_inference_on_discrete_models_via_probability_generating_functions_a_probabilistic_programming_approach'}}]"
"['Andreas Köpf', 'Yannic Kilcher', 'Dimitri von Rütte', 'Sotiris Anagnostidis', 'Zhi Rui Tam', 'Keith Stevens', 'Abdullah Barhoum', 'Duc Nguyen', 'Oliver Stanley', 'Richárd Nagyfi', 'Shahul ES', 'Sameer Suri', 'David Glushkov', 'Arnav Dantuluri', 'Andrew Maguire', 'Christoph Schuhmann', 'Huu Nguyen', 'Alexander Mattick']",NeurIPS,OpenAssistant Conversations - Democratizing Large Language Model Alignment,https://neurips.cc/virtual/2023/oral/73741,2023," Aligning large language models (LLMs) with human preferences has proven to drastically improve usability and has driven rapid adoption as demonstrated by ChatGPT.Alignment techniques such as supervised fine-tuning (\textit{SFT}) and  reinforcement learning from human feedback (\textit{RLHF}) greatly reduce the required skill and domain knowledge to effectively harness the capabilities of LLMs, increasing their accessibility and utility across various domains.However, state-of-the-art alignment techniques like \textit{RLHF} rely on high-quality human feedback data, which is expensive to create and often remains proprietary.In an effort to democratize research on large-scale alignment, we release OpenAssistant Conversations, a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 complete and fully annotated conversation trees.The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.Models trained on OpenAssistant Conversations show consistent improvements on standard benchmarks over respective base models.We release our code\footnote{\git} and data\footnote{\data} under a fully permissive licence.",Oral 1B Datasets & Benchmarks,https://openreview.net/pdf?id=VSJotgbPHF,https://openreview.net/forum?id=VSJotgbPHF,VSJotgbPHF,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (Oral)'}, 'comment': {'value': 'This paper includes a large dataset of dialogue conversations and human feedback.  Key strengths of the paper are:\n\nThe dataset was constructed with great care and attention to quality.  Multiple reviewers commented on this: ""construction is discussed in great detail, with excellent explanations of all design choices, of the system and UI for annotations, and of the instructions provided for the annotators"" and ""Rigorous data quality measures, including spam filtering and content moderation on multiple dimensions.""\n\nThe utility of the dataset is demonstrated via training models with the data and open-sourcing the models, demonstrating that the data can improve performance which reviewers believe will be valuable to the community: ""All the code is released and both the training code as well as the provided checkpoints are very valuable for the community.""\n\nThe dataset is diverse and moves towards further democratizing AI: ""scale and diversity of the dataset is impressive"" and ""unique open crowd-sourced dataset with ensured diversity and transparancy.""\n\nPersonally, I think this dataset will foster research both in training better models but also understanding human preference data and setting an example of collecting high quality diverse data.\n\nThere were some weaknesses pointed out by reviewers, including flushing out the related work section, unclear language, and missing details on things like evaluation metrics.  Authors worked to remedy concerns, and on the whole, I think this paper will make an excellent contribution to the Benchmarks track.  \n\nGiven the high scores and potential usefulness of this dataset, I recommend it as an oral.'}}, {'comment': {'value': ""I thank the authors' response. My impression of this paper remains quite postive""}}, {'title': {'value': 'Final revision with the last few updates'}, 'comment': {'value': ""Dear Reviewers\n\nTogether with our previous responses, we've uploaded a revised version of the paper that contained the changes we've referenced in our responses. In those responses, we've promised a few extra improvements. We have now uploaded a new revision containing these extra improvements, plus a few nits. We've added more related work references to the introductory section, specifically more references to work aligning language models to human-collected data, and we've also provided references for the notions of alignment and the prevalence of ChatGPT, which were missing in our original submission. We've also added a paragraph to the appendix giving a brief description of the used evaluation benchmarks.\n\nThank you all for your feedback, this was very fruitful and we think it served to greatly improve the paper.""}}, {'comment': {'value': 'Many thanks for the authors to contribute to the community again. The plan and amendment regarding diveristy looks good to me.'}}, {'title': {'value': 'Thanks for the detailed explanation'}, 'comment': {'value': 'I thank the authors for the thorough explanation. They have effectively addressed my concerns.  As such, I have raised my score to 7.  I believe the work is robust and deserves acceptance. The dataset will provide significant value to the NLP community.'}}, {'comment': {'value': 'Thank you for your response. My concerns were mostly addressed.'}}, {'title': {'value': 'Response to Authors'}, 'comment': {'value': 'Dear Authors,\n\nThank you for your detailed response, additional results, and provided clarifications. I believe both the paper, the released artifacts, and the rebuttal responses are very valuable to the community and therefore I raise my score.'}}, {'comment': {'value': '> Vagueness in the paper\n\nThis is a very valid criticism. We will expand our citing efforts when it comes to ChatGPTs popularity and alignment: This is very much a situation where we assumed readers had sufficient context, but especially vague statements like “alignment” or “prevalence of ChatGPT” should be more well grounded to preserve context for readers from different domains or times.\nChanges are not yet in this update version, but we will include them in the next update.'}}, {'comment': {'value': 'We thank the reviewer for acknowledging the rigorous effort to ensure the high quality of the data.\n\n> the makeup of the people that participated in the data collection\n\nWe have experimented with moving the raw statistics into the main text, but that would need to be done holistically, and we haven\'t found a good way of doing so. However, our limitations section in the main paper goes extensively into this topic and highlights the important dimensions that contribute to imbalance (specifically age and gender, as other dimensions tend to be more spread out). We hope that this tradeoff is at least somewhat satisfactory.\nWe have not undertaken any particular attempts to target specific groups, as we were focusing on getting contributions as such, and then on managing the influx of contributors.\n\n> the RM was trained on human responses to some prompt, rather than model generations\n\nIndeed the reward model for RLHF should in theory be run on rankings collected on outputs generated by an SFT–trained model, not on rankings generated by humans, as we did. We chose to collect these ranking data because it was a low-overhead way to collect ranking data that we felt was important for multiple reasons: It can be used as a quality signal in itself, it helps filtering the data if necessary, it can be used as an additional consideration for content moderation, and - even if suboptimal - it can be used for training a reward model. So initially, it was mostly a matter of practicality: We did not know how much longer we would get this volume high quality contributions, so we tried to collect as much as we can, rather than waiting until we figure out good SFT training recipes. At that time, we did not yet know how large the difference would be for the resulting model performance between the two collection methodologies. Our experience shows that the difference is maybe larger than thought, and while our RLHF models exhibit certain desirable qualities, they are not a clear-cut overall winner. However, they can certainly serve as a lower bound on future RLHF efforts. We have amended the limitations section with a section discussing this. Of course, nothing of this is preventing us from collecting model-based ranking data in the future, which we plan to do.\n\n> expanding on the limitations with more precision\n\nWe agree, many questions are raised and not answered, and perhaps not served to the best possible degree by e.g. just highlighting a difference in contributions. You bring up an excellent question: Is the question ""how do I expect a helpful universal assistant to behave"" answered significantly differently by males and non-males? And if yes, is that difference significantly larger than the variance among the individual groups? Such questions (and many more) would need to be considered to answer definitively whether any imbalance in our contributor makeup does actually constitute an effective limitation on our work. From our (limited) overview of the research landscape, we haven\'t found any conclusive answer to these questions, so we feel that opening this discussion in an academically satisfactory manner might be better left to derivative or complimentary work. We have amended the limitations section and hope that can give at least a small impetus for such work.\n\n> exaggerating the correlations discussed in Section 6.2\n\nThe idea behind these values is slightly double-edged: We aim to show that while human moderation does largely go into the same direction as automated detection systems, such systems are as of yet too limited to cover everything that is necessary to match human judgements. The general direction of the numbers - especially in cells that semantically match - is aiming to show the first part, while the still small absolute values are aiming to show the second part, which we tried to capture in our discussion of these results.\n\n> have the authors more deliberately studied the factual accuracy of the replies to get a sense of how well the volunteers could pick up to inconsistencies?\n\nQuantitative tests of correctness are naturally hard to do due to the intractability of estimating factual accuracy in free-form text. Qualitatively, users seem to be very dedicated to factual correctness, often citing or quoting information from other resources. The random assignment of answering tasks could be a contributor to this as one frequently gets confronted with questions that, while not difficult in the absolute, needs a little bit of research, which people tend to cite to increase the likelihood of “winning” the answer-quality benchmark.\nTo answer the question: We have not systematically studied the factual accuracy of the contributions, but punctually and via reports from other contributors, we have done so deliberately.'}}, {'comment': {'value': '> Ambiguity on open-ended conversations and instruction tuning\n\nThere is indeed a degree of ambiguity here, which we did not sufficiently address. We use the term ""instruction tuning"" broadly to refer to the process of fine-tuning pre-trained language models with instruction-style data. While our collected data is open-ended from a topical perspective, it is not ""conversational data"" per se, as it is not simply a record of a conversation, but specifically a conversation between a prompter with some task, information request, or goal, and a helpful assistant that attempts to fulfill these tasks and requests, which falls into the category of instruction-style data.\nSo while we don\'t rigorously enforce that every input is an instruction, by construction the dataset is naturally instruction-style, rather than plain conversational.\n\n> Lack of clear criteria for evaluating response quality\n\nThe assessment of response quality is determined in our contributor guidelines, which have a set of baseline criteria that users should follow when evaluating responses, these include, but not limited to:\nFactual accuracy and helpfulness are first and foremost.\nDon\'t Judge quality based on personal beliefs\nPenalize replies that fail to provide adequate warnings or caveats\nPenalize replies that are difficult to read due to a lack of formatting, capitalization or other errors.\nPenalize replies if the requested information is obfuscated by superfluous details that make up a large part of the message\nDon’t Rank replies based on how long and short they are - instead, find out which reply best answers the query of the user.\n\n\n\n> Absence of conversation examples in the main paper\n\nThat\'s a good idea. We\'ve experimented with moving things around, but have not found a satisfactory way to do so in the available 9 pages. Should this paper get accepted, we can use part of the additional page for this.'}}, {'comment': {'value': 'We thank the reviewer for their extensive feedback. In the following, we address the concerns made.\n\n> Lack of evaluation metrics in Section 6.1\n> Absence of benchmark explanation used for evaluating the trained models.\n\nEvaluating the performance of LLMs and the degree of the achieved alignment based on values, intentions, and preferences set beforehand is in general challenging. In this work, we have included several benchmarks (BoolQ, PIQA, HellaSwag, WinoGrande, ARC-e, ARC-c, OBQA; all as part of LMEH) that are widely adopted by the community and are commonly used to evaluate LLM performance (see e.g. [1, 2]). For the purposes of this work, we believe that these benchmarks do not wholly capture the capabilities of conversational agents. For this reason, we have included the Vicuna Elo Rank, OpenAI Evals, and HumanEval benchmarks. We agree with the reviewer that a more detailed description of the tasks used will be beneficial for the reader. We will include such a discussion in the Appendix in the next days.\nWe also updated the paper to clarify the meaning of LMEH: It refers to the unweighted average performance on the aforementioned NLU tasks, consisting of BoolQ, PIQA, HellaSwag, WinoGrande, ARC-e, ARC-c and OBQA, and stands for Langue Model Evaluation Harness.\nWe have also clarified the origin and methodology of the evaluations.\n\n[1] Dettmers, Tim, et al. ""Llm. int8 (): 8-bit matrix multiplication for transformers at scale."" arXiv preprint arXiv:2208.07339 (2022).\n\n[2] Frantar, Elias, and Dan Alistarh. ""Massive language models can be accurately pruned in one-shot."" arXiv preprint arXiv:2301.00774 (2023).\n\n> Incomplete comprehensive evaluations\n\nWe agree. We have now included the missing evaluation of the Pythia baseline model.\nNote that the remaining non-filled cells in the table refer to instruction-centric evaluations (VEL, OAIE and HE). Those have been omitted for the base models, as these benchmarks are unsuitable for non-instruction-tuned models and resulting numbers would not be meaningful. The LMEH numbers allow comparison of base models to instruction-tuned models, while the instruction-centric numbers allow for comparison among such instruction-tuned models. We agree that the wording in the paper is ambiguous and have updated the paper to clarify this.\n\n> Absence of human evaluation results for response quality in OpenAssistant models\n\nIndeed, our statements on aspects such as naturalness and topical diversity of the resulting models are anecdotal and subjective, which we point out in the paper. Assessing these qualities of the models trained on OASST1 would certainly be insightful, but it is somewhat out of scope for this work. Our focus is the dataset itself, not the models, and for the dataset we believe that our extensive collection of quality labels (thumbs up/down), labels of specific dimensions (helpful, humorous, etc.), and the additional collection of answer rankings provide a plethora of human-created data on the quality of the collected data, all of which is released as part of OASST1.\n\n> Unclear language context for reported results\n\nWe followed standard procedures for all experiments and carried out the evaluations in the original language of each respective benchmark, which to the best of our knowledge is predominantly English. However, both the evaluation benchmarks and the models are inherently language-agnostic and don\'t require the selection of an explicit language to work in.\n\n> Insufficient related work section\n\nThank you for providing this feedback. Upon suggestion of this and Tg3T\'s feedback, we have extended the related work section and will continue to do so in the next days.'}}, {'comment': {'value': ""We thank the reviewer for the positive feedback and for sharing our enthusiasm for promoting open, inclusive research. We truly believe that only through the open and accessible collaboration of different research communities, LLMs will truly become more useful, while mitigating potential harms.\n\n> Diversity between prompts and replies\n\nWe fully agree, diversity in subdomains is a major factor in providing helpful general assistant models. We have attempted to showcase the topical diversity to a degree in the word clouds in the Appendix, but haven't done a systematic investigation beyond that. As for mitigation, we have several ideas, such as sampling random Wikipedia pages to determine the conversation topic at the outset. We have amended the limitations section by a statement regarding this.\n\n> Plans for the future\n\nWe are really excited about future versions of the datasets and models. We are planning to continue releasing updated versions of the dataset, as more samples are collected. Provided that the need arises, the format of our dataset, i.e. conversational trees, allows for the introduction of other modalities as well, including that of images and videos!\nWe want to point out, however, that we did this during a very unique time in ML history, which presented us an opportunity to motivate this many people for contributions. As we all know, life moves on, and something new will take center stage in people's minds, such as tiny levitating rocks. We expect the volume of contributions to decrease, but we'll adjust and make the best of it. We feel that OASST1 (and its successors) is a contribution that even years from now can still serve as a vital ingredient in training conversation systems, and by that we hope to have extended this brief moment of worldwide excitement to a much longer timespan.""}}, {'comment': {'value': 'We thank the reviewer for the positive feedback and for sharing our enthusiasm about this project. Collecting samples in a plethora of different languages was a direct conclusion of the amazing community that developed around this project. We are particularly excited to expand this set to ever great lengths.\n\n> The reinforcement learning from human feedback (RLHF) experimental validation is limited in utility, as the reward model used for RLHF is not trained on preference rankings collected from the same base model that is then fine-tuned. Using rankings from a different model for the reward signal likely diminishes the effectiveness of RLHF.\n\nThis is definitely true. Our efforts at RLHF are still in very early stages as our focus was primarily on creating a good SFT dataset and SFT model in the first place, to then iterate using e.g. RLHF based methods. One should see the RLHF results as a lower-bound to what could be possible in future versions of OpenAssistant. We have amended the limitations section with a paragraph discussing this further.\n\n> What is the design principle behind Conversation Trees in OpenAssistant compared to thread-like data in sharegpt?\n\nConversation trees are the natural data structure if one considers different users working on independent threads. This is a stricter requirement than the one in sharegpt, where one can assume a single contiguous conversation held between a user and ChatGPT. If we constrained OpenAssistant to a similar “single contiguous conversation” standard, the conversation tree datastructure would have a branching factor of 1 and become a thread-like object just like sharegpt. However, since our objective is getting multiple human answers to the same questions to increase the diversity of opinion and background, a tree like datastructure with dependent conversation flows is the natural choice for our dataset.\nIn general, we have not observed that training on multiple threads from the same tree is bad for the model (as in, the beginning of the threads would be repeated in different samples), rather the single thread subsets often limit themselves to always take the top-ranked thread of any conversation tree, and therefore drastically increase the average quality of the data. Even if that results in the data size being lower than the original data, the increase in quality more than makes up for it. In light of this, collecting multiple answers at each node, combined with the ranking data, is still not superfluous, rather it is the enabling factor to later filter the data for high quality samples. (Although we concede, if that was the only goal, one could definitely go about it in a smarter way)\n\n> Vicuna dataset\n\nThank you for pointing this out. We have updated the text to highlight the differences in the Vicuna dataset.'}}, {'comment': {'value': '> One of important possible limitations of the dataset could be the undetected use of ChatGPT by annotators. What was your quality control approach to making sure that users did not use ChatGPT?\n\nThis is indeed one of our major concerns. Our guidelines https://projects.laion.ai/Open-Assistant/docs/guides/guidelines#dont specifically mention this point as the first item in the list, discouraging contributors from copy-pasting responses generated by other AI models.\nUsers who were found to post ChatGPT-generated responses were banned, and their contributions were deleted. Furthermore, we used multiple automatic tests to catch such cases. For instance, we searched for and removed messages that contained text such as “as a large language model” or “knowledge cutoff after September 2021”.\nMoreover, users were encouraged to up-vote and down-vote responses they came across from other users, which also helped weeding out low-quality, generic, (possibly AI generated) responses.\nWe have added a paragraph discussing this to the appendix.\n\n> Why were the assistant replies in the dataset produced by humans? \n\nThe main objective of our first iteration of open-assistant is to generate high quality reference data to be used in supervised finetuning. In this initial stage the focus is to align a model’s output to what a human would consider a “gold standard”, which is why we focus on human created replies.\nWe plan on future iterations utilizing answers from pre-existing models, which we expect to produce better signals for future reinforcement learning datasets, as the reinforcement learning stage is more focused on specifically penalizing model-induced errors, rather than giving a ground-truth for alignment.\n\n\n> Could you please expand your point: ""The varied evaluation scores demonstrate that by combining different data sources, the nature of the resulting model can be readily influenced.""? \n\nPerhaps this sentence was not well formulated, the intent which is being communicated here is that kinds of data mixed with oasst1 for training had a noticeable effect on the results, which could be seen most prominently in OAIE and VEL evaluation results (Table 1) between the two variants /falcon-40b-sft-top1-560 and /falcon-40b-sft-mix-1226.\n\nAs for the second part of the question: “What would be the recipe for an intentional change of the nature of the model?”, This is still an open question, but from our (subjective) experience, we recommend first collecting fine-tuning data that exhibits the intended change. Based on this, two approaches exist: Either first fine-tune on the task-specific data, then additionally fine-tune on OASST1, or mix the two datasets and run combined fine-tuning. We have found both methods to work, with none of them emerging as the clear winner for all tasks and datasets.\n\n\n\n> what are the main limitations and opportunities for improvement for toxicity detection\n\nWe believe that the correlation data we show indicates that automated and human toxicity detection are aligned to a degree, and therefore, better automated toxicity detection, for example when applied as a tool to assist in content moderation, could be in scope for NLP systems. On the other hand, the absolute numbers of detections are still quite low, which indicates that at the current time, there is still a large volume of data that is classified as inappropriate by humans, but not detected by the automated classifiers. We hope that our dataset can also serve as a basis for the training and/or evaluation of future improved toxicity detectors.\n\n\n> is there a process in place to allow external users and open source community to take part in data filtering so that it does indeed converge to the highest standard?\n\nGood question. We already provide part of this process in the data collection mechanism itself, by collecting ratings, up-/down-votes, etc. which already serves as a highly distributed quality annotation process.\nThe specific sentence quoted is to indicate that by releasing the data in a minimally filtered way (we try to only perform filtering deemed as absolutely necessary), we enable every downstream developer to perform their own filtering, and ultimately the open-source community to develop a (distributed) consensus on methods of filtering. We believe outsourcing such highly non-trivial work to the collective will lead to much greater value than if we were to make the decisions for everyone.'}}, {'comment': {'value': 'We thank the reviewer for the valuable feedback and suggestions to improve our work. We are really excited to share this collaborative effort with the open-source community and are happy to see other people equally excited about it. In the following we address the concerns raised. \n\n> Related work can be improved\n\nThank you for bringing this up. We have added the suggested citations. We will also be looking for more.\n\n> Experimental results with models do not include the Pythia baseline model\n\nWe agree that presenting results for the base pythia model would serve as a baseline to understand differences between finetuned models. For completeness, we present results for the base pythia model, complementary to Table 1 and updated the paper.\n\n\n\n|Task (LMEH)|Performance|\n|-----------|-----------|\n|BoolQ      | 65.87 |\n|PIQA       | 77.04 |\n|HellaSwag  | 68.83 |\n|WinoGrande | 65.59 |\n|ARC-e      | 66.62 |\n|ARC-c      | 38.14 |\n|OBQA       | 40.20 |\n|Average    | 60.33 (<-- this is the LMEH number for the paper) |\n\nAs expected for LMEH tasks, performance between base and finetuned models is very similar. Note that the other benchmarks are specific to instruction-tuned models and are not evaluated for base language models.\n\n> Release of more RLHF-ed models\n\nAs we discuss below, RLHF on our data showed not as much benefit as we expected, thus we did not produce very many RLHF models.\nBut we agree, more should exist, so we have now also made our Pythia-based RLHF model public on the Hugging Face Hub for reference. However, we also encourage people to use our training code and create their own.\n\n> The benefits of RLHF are somewhat unclear\n\nIndeed, that is an observation we made as well. Anecdotally, RLHF models tend to be favored by humans for certain tasks, while minimally affecting the model\'s general knowledge. But we did not find a consistent and significant improvement in the metrics for RLHF models. Further, we found RLHF training to be more brittle than SFT. So, given unclear improvements, combined with unstable training, we largely focused on finding better dataset mixes for SFT runs.\n\nThe natural question is: Why does RLHF seem to help in the original InstructGPT paper and less so in our case? We suspect, at least partially (and as the reviewers here have also noted), while the collection of our conversation data follows the collection of InstructGPT\'s conversation data, the collection of our RLHF data diverges slightly from InstructGPT\'s: They collect rankings on SFT model outputs, while we collect rankings on the human conversation data. (We did this because collecting conversations and rankings allowed us to make optimal use of the influx of volunteers, and gather extra quality labels for the conversation data.) This difference in collection methodology could explain some of the different effects of RLHF. We plan to utilize the feedback we gather from human-model interactions to investigate the direction of RLHF more in the future. We have amended the limitations section by a paragraph discussing this.\n\n> Details on ""sft-mix"" model are missing\n\nReproducibility was and continues to be a high priority. We are continuously researching the effects of dataset composition, of which sft-mix is one instance. We have added its exact composition in the appendix.\n\n> Reward model details\n\nDetails regarding training and models are presented in Appendix G. The reward is derived by adjusting a linear layer on the predictions of a base model, that generates a scalar prediction (see also L877-884 in Appendix G). Performance is measured by measuring the ability to predict the better reply among pairs of replies with different rank, on a held-out validation set. We have amended this in the appendix.\n\n> Could you please comment on stability of RLHF training? How robust were RLHF results?\n\nWe found that RLHF quickly overfitted to the reward model that was used to train with PPO. Different regularization methods are taken into consideration, which are outlined in the open-source code. We are also planning on releasing more w&b runs publicly to offer more insights. Further, we have additionally made a Pythia-based RLHF model public on the Hugging Face hub for reference.'}}, {'title': {'value': 'A very important contribution to the field'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'summary_and_contributions': {'value': 'The paper presents OpenAssistant Conversations -- a large dataset of dialogue conversations with human feedback annotations. The dataset is released under open source license and greatly improves transparency of and access to high quality large-scale LLM research resources. The dataset includes more than 160000 annotated messages with over 10000 fully annotated conversation trees (in 35 languages). OpenAssistant Conversations dataset enables RLHF and novel alignment experiments. The paper details the construction of the dataset including the interface and instructions used for annotation, as well as presents example models trained on the dataset showcasing its promise. This is a unique global collaborative effort of over 13500 volunteers. The dataset and code are released both on Hugging Face and Github.'}, 'strengths': {'value': 'OpenAssistant Conversations being one of the largest open human feedback datasets is clearly a very important contribution to the field and the open LLM research. The dataset opens new avenues for experiments in alignment with human values and for LLM improvement in general. I would like to thank the authors for this incredible work, I very much enjoyed reading this paper.\n\nStrengths:\n1. The authors introduce and release a dataset of conversations with more than 160000 annotated messages, with over 10000 fully annotated conversation trees in 35 languages\n2. The dataset construction is discussed in great detail, with excellent explanations of all design choices, of the system and UI for annotations, and of the instructions provided for the annotators. This is an important contribution in itself as it allows other researchers to replicate and improve the presented approach for their own dataset collection.\n3. The authors also present experiments with models trained on the dataset and release 20 pretrained models including one RLHF-ed model and reward models. All the code is released and both the training code as well as the provided checkpoints are very valuable for the community. \n\nWithout a doubt, this paper is a clear accept.'}, 'opportunities_for_improvement': {'value': 'While the paper is excellent, a few things can be improved. I also have a few questions.\n\nWeaknesses:\n1. Related work can be improved as some other human preference datasets already exist. For example, Anthropic\'s RLHF dataset [1] as well  as Stanford Human Preference Dataset [2] should be mentioned. \n2. Experimental results with models do not include the Pythia baseline model, therefore it is hard to see the improvement provided by fine-tuning the model on OpenAssistant Conversations\n3. While OpenAssistant Conversations is a dataset with human feedback annotations, only a single RLHF-ed model (LLAMA-based) is released and included in experiments. The release of other RLHF-ed models and their inclusion in experiments would be a huge benefit to the community, especially given the research-only license of the first version of LLAMA. \n4. Additionally, even for the LLAMA-based RLHF-ed model the benefits of RLHF are somewhat unclear because of the inconsistency across benchmarks. While the authors say that ""this could indicate the unsuitability of automatic evaluations for language models, or could indicate that different models and datasets lead to different capabilities"", it could be a reflection of biases in different benchmarks. It would be interesting to see a more detailed discussion of the RLHF results compared to the SFT model.\n5. Details on ""sft-mix"" model are missing other than ""it mixes OpenAssistant Conversations with other instruction datasets"". It is important to provide these details in the paper and cite those other datasets.\n6. Reward model architecture details and performance evaluation is not presented in the paper. It is important to provide details on reward model architecture and design choices and present their test performance in ranking assistant responses according to human preferences.\n\nQuestions:\n1. Could you please comment on stability of RLHF training? How robust were RLHF results?\n2. One of important possible limitations of the dataset could be the undetected use of ChatGPT by annotators. What was your quality control approach to making sure that users did not use ChatGPT? \n3. Why were the assistant replies in the dataset produced by humans? Why were LLMs (for example, the LLAMA, Falcon and Pythia baseline models) not used for that purpose?\n4. Could you please expand your point: ""The varied evaluation scores demonstrate that by combining different data sources, the nature of the resulting model can be readily influenced.""? What kind of changes of model nature did you observe in your results? What would be the recipe for an intentional change of the nature of the model?\n5. In the section on toxicity detection, you say: ""The results serve to validate the capabilities and show limitations of AI-driven toxicity detection and may inform future work in this area"". While the promise of automated toxicity detection is clear from this section, what are the main limitations and opportunities for improvement in your view?\n6. In the limitations you mention:""We believe that the open nature of the project allows for data filtering to be conducted in a transparent manner, ultimately converging on the highest possible standards"". While this is an excellent point, is there a process in place to allow external users and open source community to take part in data filtering so that it does indeed converge to the highest standard? \n\n\nReferences:\n[1] Paper: Bai, Y., Jones, A., Ndousse, K., Askell, A., Chen, A., DasSarma, N., Drain, D., Fort, S., Ganguli, D., Henighan, T. and Joseph, N., 2022. Training a helpful and harmless assistant with reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862.\nDataset: https://huggingface.co/datasets/Anthropic/hh-rlhf\n\n[2] Stanford Human Preference Dataset: https://huggingface.co/datasets/stanfordnlp/SHP'}, 'limitations': {'value': 'Limitations and societal impact are addressed.'}, 'correctness': {'value': 'The paper is sound and highly transparent'}, 'clarity': {'value': 'The presentation is excellent'}, 'relation_to_prior_work': {'value': 'Relation to prior work is covered, however, can be improved.'}, 'documentation': {'value': 'The level of detail on dataset construction and documentation is excellent.'}, 'ethics': {'value': 'I do not see any ethical concerns, the paper transparently addresses limitations and societal impact'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'See Questions in Opportunities For Improvement.'}}, {'title': {'value': 'Official Review'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'This paper introduces OpenAssistant Conversations, a large-scale human-generated dataset for training open-domain dialog agents. The dataset contains over 150,000 human-written conversational exchanges in 35 languages, annotated with quality ratings and other metadata. The authors demonstrate the utility of the dataset by training several open-source language models which achieve improved performance compared to their base versions.'}, 'strengths': {'value': '1. The scale and diversity of the dataset is impressive, especially in terms of the number of annotated languages. This helps mitigate demographic biases compared to other existing datasets like Alpaca / Anthropic-HH / sharegpt.\n\n2. Releasing the data and trained models openly is a significant contribution to democratizing research on aligning large language models.\n\n3. The data collection methodology using single-task contributions and a state machine is well-designed.\n\n4. The analysis of the correlation between human and automated toxicity ratings provides valuable insights. The results serve to validate the capabilities and show limitations of AI-driven toxicity detection and may inform future work in this area.'}, 'opportunities_for_improvement': {'value': '1. The reinforcement learning from human feedback (RLHF) experimental validation is limited in utility, as the reward model used for RLHF is not trained on preference rankings collected from the same base model that is then fine-tuned. Using rankings from a different model for the reward signal likely diminishes the effectiveness of RLHF.\n'}, 'limitations': {'value': 'Yes.'}, 'correctness': {'value': 'Yes.'}, 'clarity': {'value': 'Yes.'}, 'relation_to_prior_work': {'value': 'Yes.'}, 'documentation': {'value': 'Yes.'}, 'ethics': {'value': 'No.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'Questions:\n\n1. what is the design principle behind Conversation Trees in OpenAssistant compared to thread-like data in sharegpt? Since many models are only trained on the single-round subset of OpenAssistant data [1], this effectively reduces the number of data that can be used to train a single-round AI assistant.\n\n[1] QLoRA: Efficient Finetuning of Quantized LLMs\n\nTiny problesm:\n\nline 45: Most openly accessible datasets are comprised of synthetic data of instructions automatically generated by querying language models [9, 10, 11, 12, 13]. ==> Vicuna should not be cited here since its instructions are provided by users to ShareGPT.'}}, {'title': {'value': 'Opensourced human-annotated conversation dataset collected for training conversational AI systems. '}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': '- Releases a dataset of 161,443 human-generated dialog messages in 35 languages, annotated with over 460,000 quality ratings. This represents a significant scale of high-quality human feedback data.\n- The data was collected through a worldwide volunteer effort involving over 13,500 contributors, making it a unique open crowd-sourced dataset with ensured diversity and transparancy.\n- Shows experimental results training models with the data, demonstrating improved performance over base models on standard benchmarks. Models and code are also released.\n- Aims to promote more open, inclusive research on aligning large language models.'}, 'strengths': {'value': '- Unique in its open crowd-sourced nature involving thousands of worldwide volunteers. Helps democratize research on aligning large language models by releasing data openly.\n- Rigorous analysis of dataset statistics and contributor demographics. Experimental validation showing performance gains over base models.\n- Attempts to assess and thoughtfully discuss limitations like biases in the data. Overall goal of transparency and democratization has positive implications.'}, 'opportunities_for_improvement': {'value': '- Conversational AI is a huge area - this data may not cover all subdomains. Authors are encouraged to add statements regarding this and explain how diversity among prompts and replies could be achieved.\n\n- While a large dataset, even bigger with more diverse contributors could be more impactful. It is valuable to outline the planning for the next version. \n\n- Additional modalities like image and video could make the conversations richer in the future :-)\n'}, 'limitations': {'value': 'Limitations are adequately discussed and studied.'}, 'correctness': {'value': 'Correct.'}, 'clarity': {'value': 'Yes.'}, 'relation_to_prior_work': {'value': 'Yes.'}, 'documentation': {'value': 'Yes.'}, 'ethics': {'value': 'No.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': ""The key strengths are the significance of releasing this large human-annotated dataset openly to the research community, combined with strong efforts to validate the data's utility and discuss its limitations transparently.""}}, {'title': {'value': 'Promising potential meets challenges: a nice initiative requiring refined evaluation methods and experiment design'}, 'rating': {'value': '7: Good paper, accept'}, 'confidence': {'value': '3: The reviewer is fairly confident that the evaluation is correct'}, 'summary_and_contributions': {'value': 'The paper introduces an ambitious initiative aimed at democratizing research on large-scale alignment by presenting the ""OpenAssistant Conversations"" benchmark. This benchmark consists of a collection of 161K chit-chat style messages, gathered through a worldwide crowd-sourcing effort involving over 13K workers across 35 languages. To ensure data quality, the authors implemented rigorous checks, filtering out spams, and employing content moderation on various dimensions, such as creativity, humorousness, politeness, harmlessness, language adherence, hate speech, and sexual content.\nThe conducted experiments demonstrate the effectiveness of the moderation process in generating high-quality messages. Additionally, the authors fine-tuned LLaMA and Falcon on the collected benchmark and observed significant performance improvements.'}, 'strengths': {'value': ""- Ambitious and democratizing initiative that's of interest to the NLP community.\n- Large-scale dataset with 161K chit-chat style messages across 35 languages.\n- Rigorous data quality measures, including spam filtering and content moderation on multiple dimensions.""}, 'opportunities_for_improvement': {'value': 'Weaknesses (in roughly decreasing order of importance):\n\n- **Lack of evaluation metrics in Section 6.1**: The results in Table 1 lack clarity on how the models trained on collected data were evaluated. The mention of evaluation by ""Til Jasper Ullrich"" lacks explanation and context.\n-  **Absence of benchmark explanation used for evaluating the trained models**: for example, I\'m not sure what LMEH refers to.\n- **Incomplete comprehensive evaluations** due to computational resource shortage: The authors acknowledge missing experiments due to limited computational resources at the time of writing, raising concerns about the paper\'s acceptance without crucial evaluations.\n- **Absence of human evaluation results for response quality in OpenAssistant models**: While the authors mention user reports on positive aspects, such as improved naturalness and diversity compared to ChatGPT, there is no presentation of human evaluation results to substantiate these claims.\n- **Unclear language context for reported results**: The paper does not specify whether the reported results were conducted on English or other languages, leaving room for ambiguity.\n- **Insufficient related work section**: The introduction briefly mentions previous work, but lacks a comprehensive and rigorous analysis of related literature.\n- **Ambiguity on open-ended conversations and instruction tuning**: The paper does not sufficiently clarify how open-ended conversations are relevant to instruction tuning.\n- **Lack of clear criteria for evaluating response quality**: The paper does not provide a clear definition of what ""quality"" entails when assessing responses. It does not specify whether it refers to grammatical correctness or other aspects of response evaluation.\n- **Absence of conversation examples in the main paper**: It would be beneficial to include an example of the conversation early on in the paper, and consider moving some of the data collection details from the appendix to the main paper for better accessibility.'}, 'limitations': {'value': 'Yes, the authors have adequately addressed the limitations and potential negative societal impact of their work.'}, 'correctness': {'value': 'The dataset evaluation lacks correctness. The work does not provide a clear explanation of the evaluation metrics and benchmarks that were used to assess the performance of the models accurately.'}, 'clarity': {'value': 'While the paper maintains a smooth flow, it falls short in providing essential explanations for certain sections.'}, 'relation_to_prior_work': {'value': 'No, the work does not clearly discuss how it differs from previous contributions.'}, 'documentation': {'value': 'Yes'}, 'ethics': {'value': 'No'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'No'}}, {'title': {'value': 'Great and important work, manuscript requires a bit of fine-tuning'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'The authors built a platform and a pipeline to allow collection of crowdsourced, high-quality data for the purpose of aligning LLMs to human preferences w.r.t. digital assistants. Their goal is to democratize both the usage and the research on such models given their contemporary prevalence.'}, 'strengths': {'value': 'The authors took special care to assure spam and fraudulent annotations were filtered out. Many datapoints and different types of labels were collected per document collected. The authors provide a detailed description of the data collection pipeline, enabling interested parties to extend their work. The data and the resulting models have been made freely available (with certain restrictions depending on their existing licenses), and the platform used creates confidence in the continued availability of the data. The data collection is still on-going, so the dataset size is expected to increase.'}, 'opportunities_for_improvement': {'value': 'The limitations w.r.t. the makeup of the people that participated in the data collection need to be emphasized further, and perhaps some of the figures from the supplementary material need to be transported into the main text. Were there any remediation strategies attempted to incentivize participation from other groups, and if so, are there insights as to why they failed?\n\nFurthermore, it looks to me that the RM was trained on human responses to some prompt, rather than model generations. As far as I can tell, this is not the strategy followed by InstructGPT. Are there any particular reasons that the authors deviated from the strategy (apart from the fact that it requires the serialization of the data collection)? I believe this difference is worth explicitly highlighting in the paper. I also think that this is a possible reason the trained models are underperforming compared to ChatGPT, namely that there is some distance between what the RM has seen during training and what the SFT models produce. In effect, the training pipeline tries to successively approximate the desired behavior of the helpful assistant, and the ”domain” mismatch between the two models might be too large of a gap for the models to bridge successfully. Do the authors have any insights on this?'}, 'limitations': {'value': 'The limitations are discussed, but I believe they need to be further highlighted, and perhaps some exploration of their effects rather than vague statements about values and perspectives would serve to improve the discussion. For example, are there any tangible, anticipated implications for the fact that most volunteers are male? Is there any relevant research on human personal assistants, like secretaries, that might elucidate the discussion? This is an interesting topic and some discussion of that in the paper could jumpstart research on the field if necessary.'}, 'correctness': {'value': 'There is no absolute right or wrong way to construct such a dataset, so I think the design is sufficient. However, I highlight above deviations from previous work, which I think are worth discussing.\n\nMoreover, it seems to me that the authors might be exaggerating the correlations discussed in Section 6.2. Is a correlation of .11 (column 3) really that large enough to claim anything? Or .2 in row 3? The readers are not given any context as to what constitutes a high or low correlation to make sense of the values. The toxicity values could be transformed into binary variables, or otherwise binned. What would the accuracy of the Detoxify be in that case, for example? Some sort of further analysis, like the aforementioned one or something else the authors deem more appropriate, to contextualize the results would really be helpful and serve to improve the paper and the validity of study, as well as inspire more trust in the lack of toxicity in the final dataset.\n\nFinally, have the authors more deliberately studied the factual accuracy of the replies to get a sense of how well the volunteers could pick up to inconsistencies?'}, 'clarity': {'value': 'While the paper is comprehensive for the most part, and details are abundant, there is some vagueness in some parts of the manuscript. For example, a lot of things are discussed in the beginning of the introduction (up to line 34), but very few references are included. Specifically, the authors include a definition of “alignment”. Presumably, they are not the first to define the term. Even if it is their definition (which should be explicitly stated, in that case), referring to previous work would be useful to readers. Moreover, they speak of the prevalence of ChatGPT. Aren’t there any resources documenting that? The authors are referring to something that is in the contemporary zeitgeist, which can alienate future readers. Finally (and I hate to be nit-picky), the authors begin by speaking of how the field of NLP within AI has “particularly” seen rapid growth. This is a quantitative statement that again is not backed up. I detect the same vagueness in some other places, such as lines 53, 106, or 275.\n\nSince I agree with the authors on the importance of the task, I expect a lot of attention in their efforts from many disciplines, and so I believe less expert readers would appreciate more resources and concreteness. These can also future-proof the paper.'}, 'relation_to_prior_work': {'value': 'The authors discuss how subsequent work from InstructGPT has not focused on data collection from people, and this work serves to remedy that. However, once again, I have highlighted in previous sections deviations from previous work, which I think are worth explicitly discussing.'}, 'documentation': {'value': 'I see no issues with the documentation and the availability of the dataset in the future.'}, 'ethics': {'value': 'I see no major ethical implications in this specific work. The authors disclose limitations, which are generally applied to LLMs used as assistants, and not solely to their derived models.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'I believe I’ve covered all my suggestions, thoughts and concerns in my previous responses.'}}, {'title': {'value': 'OpenAssistant Conversations - Democratizing Large Language Model Alignment'}, 'authors': {'value': ['Andreas Köpf', 'Yannic Kilcher', 'Dimitri von Rütte', 'Sotiris Anagnostidis', 'Zhi Rui Tam', 'Keith Stevens', 'Abdullah Barhoum', 'Duc Minh Nguyen', 'Oliver Stanley', 'Richárd Nagyfi', 'Shahul ES', 'Sameer Suri', 'David Alexandrovich Glushkov', 'Arnav Varma Dantuluri', 'Andrew Maguire', 'Christoph Schuhmann', 'Huu Nguyen', 'Alexander Julian Mattick']}, 'authorids': {'value': ['~Andreas_Köpf1', '~Yannic_Kilcher1', '~Dimitri_von_Rütte1', '~Sotiris_Anagnostidis1', '~Zhi_Rui_Tam1', '~Keith_Stevens1', '~Abdullah_Barhoum1', '~Duc_Minh_Nguyen2', '~Oliver_Stanley1', '~Richárd_Nagyfi1', '~Shahul_ES1', '~Sameer_Suri1', '~David_Alexandrovich_Glushkov1', '~Arnav_Varma_Dantuluri1', '~Andrew_Maguire1', '~Christoph_Schuhmann1', '~Huu_Nguyen2', '~Alexander_Julian_Mattick1']}, 'keywords': {'value': ['dataset', 'human labels', 'instruction tuning', 'conversation', 'rlhf', 'open-source']}, 'TLDR': {'value': 'We crowd-source a high-quality dataset of human demonstrations for assistant-finetuning of LLMs.'}, 'abstract': {'value': 'Aligning large language models (LLMs) with human preferences has proven to drastically improve usability and has driven rapid adoption as demonstrated by ChatGPT.\nAlignment techniques such as supervised fine-tuning (\\textit{SFT}) and  reinforcement learning from human feedback (\\textit{RLHF}) greatly reduce the required skill and domain knowledge to effectively harness the capabilities of LLMs, increasing their accessibility and utility across various domains.\nHowever, state-of-the-art alignment techniques like \\textit{RLHF} rely on high-quality human feedback data, which is expensive to create and often remains proprietary.\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant Conversations, a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 complete and fully annotated conversation trees.\nThe corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\nModels trained on OpenAssistant Conversations show consistent improvements on standard benchmarks over respective base models.\nWe release our code\\footnote{\\git} and data\\footnote{\\data} under a fully permissive licence.'}, 'venue': {'value': 'NeurIPS 2023 Datasets and Benchmarks Oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Track/Datasets_and_Benchmarks'}, 'pdf': {'value': '/pdf/f13438d9a567d6ff7771c92b01381f4b02b84be6.pdf'}, 'supplementary_material': {'value': '/attachment/79fece771c1251ac2fee56c1101cd664e4e55f44.pdf'}, '_bibtex': {'value': '@inproceedings{\nk{\\""o}pf2023openassistant,\ntitle={OpenAssistant Conversations - Democratizing Large Language Model Alignment},\nauthor={Andreas K{\\""o}pf and Yannic Kilcher and Dimitri von R{\\""u}tte and Sotiris Anagnostidis and Zhi Rui Tam and Keith Stevens and Abdullah Barhoum and Duc Minh Nguyen and Oliver Stanley and Rich{\\\'a}rd Nagyfi and Shahul ES and Sameer Suri and David Alexandrovich Glushkov and Arnav Varma Dantuluri and Andrew Maguire and Christoph Schuhmann and Huu Nguyen and Alexander Julian Mattick},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\nyear={2023},\nurl={https://openreview.net/forum?id=VSJotgbPHF}\n}'}, 'paperhash': {'value': 'köpf|openassistant_conversations_democratizing_large_language_model_alignment'}}]"
"['Tim Dettmers', 'Artidoro Pagnoni', 'Ari Holtzman', 'Luke Zettlemoyer']",NeurIPS,QLoRA_ Efficient Finetuning of Quantized LLMs,https://neurips.cc/virtual/2023/oral/73855,2023," We present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters~(LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information-theoretically optimal for normally distributed weights (b) Double Quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) Paged Optimziers to manage memory spikes. We use QLoRA to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small, high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations, showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to ChatGPT. We release all of our models and code, including CUDA kernels for 4-bit training.",Oral 2A Efficient Learning,https://openreview.net/pdf?id=OUIFPHEgJU,https://openreview.net/forum?id=OUIFPHEgJU,OUIFPHEgJU,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'Meta Review for QLoRA: Efficient Finetuning of Quantized LLMs\n\nAs diligently summarized by reviewer hHMr, this paper proposes a novel way to finetune 4-bit LLMs for efficient finetuning and serving. QLORA, the proposed method, uses a number of innovations to save memory without sacrificing performance. The authors show that QLORA can be used to finetune a 65B parameter model on a single 48GB GPU, and that it performs well in academic and instruction finetune datasets.\n\nReviewers, like pPZQ, agree that the main strength lies in the system this paper provides. Quantization and adapter fine-tuning are both standard techniques when it comes to efficiency. However, this paper opens up the possibility of fine tuning a large language model under reasonable cost. Such a possibility is important for the community to study large language models and pursue new research ideas.\nMost reviewers, including myself, believe QLORA to be a significant contribution to the field of LLM finetuning and quantization, an area that is right at the spotlight of generative AI, especially in the open-source community where such innovation will be highly impactful as we get our models smaller, more efficient, and to have more capabilities with less resources.\n\nThis is a significant work, which deserves to be nominated for an Oral Presentation at NeurIPS.'}}, {'title': {'value': 'Thank you'}, 'comment': {'value': 'Beautiful responses. Increase my score to 9'}}, {'rebuttal': {'value': 'We thank all reviewers for their time and contributions. Instead of uploading a document, we inserted relevant tables in markdown in each rebuttal for better readability.\n\nThe response has been overwhelmingly positive. We thank the reviewers for their encouragement. We, too, believe that our work will have a groundbreaking effect in making large language model fine-tuning vastly more accessible without compromising performance. \n\nPlease let the AC know if you think our work deserves to be highlighted at the conference. We believe many researchers can benefit from learning and using our work, as it enables research even with few GPU resources, which would otherwise be impossible in academic settings. Our work enables research that has not been possible before, particularly for academic researchers with the least resources.'}}, {'rebuttal': {'value': '**Q1: Can the authors re-think the naming convention of double quantization, for example, I had to re-read equations 4 and 5 for better understanding.**\n\n**A1**: Thank you, we got the same feedback after circulating our draft for review after submission. Since then, this section received a major overhaul and should be much more readable. We mainly focused on an easier readable text and brought the equations closer to double quantization. We made the convention slightly clearer by emphasizing the quantization constants as a target for double quantization.\n\n\n**Q2: Can the structure of NF4 data type be directly plugged into 8-bit and higher precision data-types for improved performance, if yes is there any experiment to show the prowess of the NFX data types?**\n\n**A2**: Yes, NormalFloats can easily be defined for any bit-width. However, with 16-bit inputs and 8-bit weights there is little to no degradation with any data type. Degradation starts to happen at around 6-bit weights and then improved data types show their first effect. When we use NF6, we already see some advantages over FP6. These results improve the fewer bits we have. \nSo NF6 advantages over other 6-bit data types are only minor but still significant. These increase with 5 bits, become a sizable advantage at 4-bit (as detailed in the paper), and advantages are very large at 3-bit, but instabilities are a major problem. This means, NF3 has a major advantage over FP3, but for both data types the quantization can fail sporadically leading to random performance. While NF3 certainly is a big improvement over FP3, additional methods are needed to stabilize 3-bit quantizations. We are currently working on this challenging problem.\n'}}, {'rebuttal': {'value': '**Q1: The authors are encouraged to discuss the inference efficiency of QLoRA.**\n\n**A1**: For large models like LLaMA v1 and v2, matrix multiplication accounts for about 95% of all floating point operations. As such, accelerating 4-bit matrix multiplication accelerates inference speed. Since our submission we implemented highly efficient CUDA inference kernels for 4-bit matrix multiplication (any data type) for batch size one and compared it to 16-bit NVIDIA matrix multiplication performance. These implementations are optimized for RTX 4090 and A40 GPUs. Below the speedups for QLoRA inference. We see strong speedups between 3-4x compared to 16-bit, making inference for QLoRA highly efficient. We will add these data to the appendix of the paper. Please see reviewer hHMr (A1) for further information about inference efficiency.\n\n| GPU      | Storage type | Compute type | Size | Speedup vs 16-bit |\n|----------|--------------|--------------|------|-------------------|\n| RTX 4090 |      NF4     |     BF16     |  7B  |       3.51x       |\n| RTX 4090 |      NF4     |     BF16     |  13B |       4.00x       |\n| RTX 4090 |      NF4     |     BF16     |  30B |       3.65x       |\n| RTX 4090 |      NF4     |     BF16     |  65B |       3.81x       |\n| A40      |      NF4     |     BF16     |  7B  |       2.94x       |\n| A40      |      NF4     |     BF16     |  13B |       2.91x       |\n| A40      |      NF4     |     BF16     |  30B |       3.02x       |\n| A40      |      NF4     |     BF16     |  65B |       3.25x       |\n'}}, {'rebuttal': {'value': '**Q1: From Table 3, we observe the performance gap increase the model size increase. This could be concerning, especially when the largest model is 11B.[...] helpful [...] to understand when or to what scale does the proposed method works.**\n\n**A1**: We were not able to run a replication for 11B since it consumed too much memory. Furthermore, we find that our replication results are slightly lower, since we use a validation set rather than optimizing the test set as done with the baseline. Thirdly, we find that the 11B model is particularly unstable and does not train easily. This is a common features for T5 models which is the only huggingface model where attention is fully run in FP32 because otherwise its too unstable. All these features made it difficult to obtain the performance of the base model with QLoRA. From other results, we see that QLoRA scales fine to 65B parameters and as such, the deviation from this result stems mostly from the particular instabilities of the T5 model — in particular the 11B T5 model.\n\n**Q2: Quantization and efficient finetuning are generally speaking orthogonal techniques. Is there any specific reason for the choice of LoRA. Can the proposed method be applied on top of other efficient finetuning method?**\n\n**A2:**  In short, we used LoRA due to its robustness, but any other method could be used with our 4-bit quantized base model.\nOur quantization approach is compatibility with any parameter efficient finetuning (PEFT) method. However, we chose LoRA for two reasons: (1) it has been used in many projects with great results, (2) a colleague ran an extensive evaluation of all different PEFT methods and found LoRA was one of two only methods that worked well for finetuning if rigorously evaluated (most PEFT methods are evaluated on GLUE+RoBERTA which is am experiments setup that has many issues). As such, LoRA was an obvious choice for us. While we wanted to also try other methods, we did not have enough computational resources to investigate other methods.\n\n**Q3: The authors mention paged optimizer as a major contribution. Can the authors provide more details on the improvement resuling from the paged optimizer?**\n\n**A3**: \nPaged optimizers prevent memory spikes from mini-batches with long sequence lengths which can cause out of memory errors. While it is possible to restart a model after it crashed and skip the long mini-batch it is usually very difficult to say how much data will be skipped or how often a model will crash. This is so, because before training, it is often very difficult to calculate the exact training memory footprint of a training run without running the model itself.\n\nPaged optimizers solve this issue by lazily preventing memory spikes through offloading to CPU memory temporarily. This eliminates out of memory errors and also makes sure no data is skipped. As such, with paged optimizers, the user knowns even before training that the model will not crash due to out of memory errors and all data will be seen. This enormously simplifies finetuning under constrained memory settings which are common when researchers with few GPUs need to finetune large models for their research. We think this makes paged optimizers a very significant contribution.\n'}}, {'rebuttal': {'value': '**Q1: I wish the authors had discussed the impact of their work on the serving cost of large language models (LLMs) [...] This work has the potential to significantly reduce the serving cost of LLMs, which would be a major benefit for both the environment and the bottom line.**\n\n**A1**:\n The relationship between serving efficiency and environmental impact and cost/performance is a complicated one. The short answer is, for personal use, we reduce the environmental impact per token by about 3.5x. If 50% LLM deployments are personal and 50% company, we reduce the environmental footprint of inference by 72%.\n\nThe long answer is this: For deployment, there are two options: (1) personal deployment, (2) deployment by companies for many users. (1) uses small batch sizes (usually batch size =1), (2) uses large batch sizes (64-128). Per token, (2) offers about >50x better efficiency because for every weight that is loaded from memory, up to 64-128 tokens can be calculated. The >50x improvement in efficiency stems from the fact memory operations are energy inefficient, and floating point operations are energy efficient. As such,company deployment (2) is a very environmentally friendly and cheap approach.\n\nCurrently, we have efficient 4-bit CUDA kernels for the personal deployment scenario (1) with batch size=1 which are about ~3.5x more efficient (see table below). As such, we reduce the overall footprint for personal deployment (1) significantly. \n\nThe overall cost and footprint is now determined by how many people use (1) vs (2). For example, if 50% of users use personal deployment (1) and 50% company deployments (2) and we assume that (2) is about 50x more efficient then we get the following numbers. Approach (1) accounts for 50%/(50% + 50%/50) = 98% of environmental impact. \nThis means, the more users deploy personal LLMs, the larger benefit of our method. If 50% of people use personally deployed LLMs (phones, laptops etc) then our method will reduce the impact by about 1- (98%/3.5x) =  72%.\n\nThe environmental impact reduction is roughly proportional to energy consumption per token processed which is roughly proportional to the cost of running LLMs. As such, the bottom line is affected in the same proportions.\n\nOverall, our method will have a strong impact on environmental impact and cost reduction for personal LLM deployments.\n\nTable showing increased speedups / efficiency gains of our approach compared to 16-bit inference:\n GPU      | Storage type | Compute type | Size | Speedup vs 16-bit |\n|----------|--------------|--------------|------|-------------------|\n| RTX 4090 |      NF4     |     BF16     |  7B  |       3.51x       |\n| RTX 4090 |      NF4     |     BF16     |  13B |       4.00x       |\n| RTX 4090 |      NF4     |     BF16     |  30B |       3.65x       |\n| RTX 4090 |      NF4     |     BF16     |  65B |       3.81x       |\n| A40      |      NF4     |     BF16     |  7B  |       2.94x       |\n| A40      |      NF4     |     BF16     |  13B |       2.91x       |\n| A40      |      NF4     |     BF16     |  30B |       3.02x       |\n| A40      |      NF4     |     BF16     |  65B |       3.25x       |\n\n**Q2: The authors could estimate the potential savings in energy consumption and carbon emissions that could be achieved by using their method to serve LLMs in 4-bit rather than 8-bit or 16 bit.**\n\n**A2**: Please see A1. The estimation of environmental and cost reduction if 50% of deployments are personal deployments is about 72% using our method.\n\n**Q3: They could also discuss the potential impact of their work on the economics of LLMs. For example, if the serving cost is significantly reduced, it could make LLMs more affordable for businesses and organizations.**\n\n**A3**: A main pain point for businesses is (a) efficient deployment with large batch sizes, (b) deploy many different models. Since with QLoRA we can deploy many different finetuning models with the same quantized base model we increase the cost efficiency of (b) very significantly. The cost reductions in (b) is proportional to the number of different adapters deployed (100x reductions are possible with the right implementations). Currently, we do not offer cost reductions for (a), but this can be achieved with the right CUDA optimizations. See A1 for further discussion.\n\n**Q4: Finally, the authors could discuss the challenges that still need to be addressed in order to make their method practical for large-scale deployment.**\n\n**A4**: The main challenge is to make 4-bit matrix multiplication with NF4 viable for large batch sizes. This is possible, but unlike Int4 matrix multiplication, the main bottleneck is instruction throughput on the GPU. We are currently implementing CUDA kernels for large batch sizes (=16) that overlap memory transfers and computation to alleviate instruction throughput bottlenecks. First results yield speedups of ~1.7 - 2.3x for batch size 16, but further improvements are possible. As such, we are confident that we can achieve efficient large-scale deployments of QLoRA models with the right implementations.\n\n**Q5: Can you please replace figure-3 with the table of numbers for Winogrande, HellaSwag, PiQA, Arc-Easy, and Arc-C?**\n\n**A5**: Thank you for this suggestion. We are currently short on space and will include a table that breaks down performance in the appendix.\n\n**Q6: Can you please include the ablation studies on the learning-rate / schedule /hyperparameters that you have done in the appendix? Do all the finetuning experiments shared the same recipt?**\n\n**A6**: We are happy to include all our ablation studies. To ensure we compare against a very strong baseline for full finetuning we first did an extensive hyperparameter search to find the strongest baseline. We found that these baseline parameters are optimal for most models and only learning rate and batch size need to be changed with scale. We also find 16-bit LoRA baselines have the same “best” hyperparameters as 4-bit and 8-bit QLoRA.\n\n\n\n'}}, {'summary': {'value': 'This article provides a novel way to finetune 4-bit LLMs for efficient finetuning and serving. QLORA, the proposed method, uses a number of innovations to save memory without sacrificing performance. The authors show that QLORA can be used to finetune a 65B parameter model on a single 48GB GPU, and that it performs well in academic and instruction finetune datasets. QLORA is a significant contribution to the field of LLM finetuning and quantization. \n\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. The QLORA paper conducted extensive evaluations on a wide range of datasets, including both academic datasets and the more recent instruction-following datasets.\n2. QLORA introduced a novel data type called 4-bit NormalFloat (NF4) for quantization.\n3. QLORA can finetune 65B parameter models on a single 48GB GPU, which is significantly more efficient than traditional finetuning methods.\n4. QLORA provides good flexibility, as it supports a variety of LLMs, including LLaMA and T5. This suggests that the method can be used to finetune models of different sizes, from small models to large models.\n5. QLORA is open sourced with all of the models and code, making it easy for others to use and reproduce the results.\n\n\n'}, 'weaknesses': {'value': 'I wish the authors had discussed the impact of their work on the serving cost of large language models (LLMs). LLM finetuning is relatively inexpensive, and it is good that this work makes it even more affordable. However, the serving cost (in terms of energy consumption and carbon emissions) is much higher than the pretraining cost, especially when there are hundreds of millions of users. This work has the potential to significantly reduce the serving cost of LLMs, which would be a major benefit for both the environment and the bottom line.\n\nHere are some specific points that could be discussed:\n\na. The authors could estimate the potential savings in energy consumption and carbon emissions that could be achieved by using their method to serve LLMs in 4-bit rather than 8-bit or 16 bit.\nb. They could also discuss the potential impact of their work on the economics of LLMs. For example, if the serving cost is significantly reduced, it could make LLMs more affordable for businesses and organizations.\nc. Finally, the authors could discuss the challenges that still need to be addressed in order to make their method practical for large-scale deployment.\n\n\n'}, 'questions': {'value': '1. Can you please replace figure-3 with the table of numbers for Winogrande, HellaSwag, PiQA, Arc-Easy, and Arc-C?\n\n2. Can you please include the ablation studies on the learning-rate / schedule /hyperparameters that you have done in the appendix? Do all the finetuning experiments shared the same recipt?\n'}, 'limitations': {'value': 'The authors discussed the limitations well in the paper.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes a method for efficient finetuning large language models. To address the main bottleneck from memory, the authors quantize the model to 4-bit along with standard LoRA adapter. With the proposed method, the authors demonstrate the possibility of finetuning large language model on single GPU with competitive performance.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The main strength lies in the system this paper provides. Quantization and adapter fine-tuning are both standard techniques when it comes to efficiency. However, this paper opens up the possibility of finetuning large language model under reasonable cost. Such possibility  is important for the community to study large language model and pursue new research ideas.'}, 'weaknesses': {'value': 'From Table 3, we observe the performance gap increase the model size increase. This could be concerning, especially when the largest model is 11B.  It would be helpful for the community to understand when or to what scale does the proposed method works.'}, 'questions': {'value': '(1) Quantization and efficient finetuning are generally speaking orthogonal techniques. Is there any specific reason for the choice of LoRA. Can the proposed method be applied on top of other efficient finetuning method?\n\n(2) The authors mention paged optimizer as a major contribution. Can the authors provide more details on the improvement resuling from the paged optimizer?'}, 'limitations': {'value': 'The authors provide discussion on the limitation and potentially negative impact.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The problem addressed in this paper is the high cost associated with fine-tuning large models, such as the standard fp16 LLaMA65B model, which requires over 780G of memory for parameter fine-tuning.\n\nThe proposed solution is QLoRA, which consists of three main components: NF4 Quantization (4-bit quantization), Double Quantization, Paged Optimizers.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The authors have open-sourced all the training code, which will benefit the community in further researching Large Language Models (LLMs). This paper will have significant implications for the community.\n\nThe motivation behind this paper is very clear.\n\nThe techniques proposed are innovative.\n\nThis paper is well-written.'}, 'weaknesses': {'value': 'The authors are encouraged to discuss the inference efficiency of QLoRA.'}, 'questions': {'value': 'see Weaknesses'}, 'limitations': {'value': 'See Weaknesses'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work pushes the limit of memory-efficient fine-tuning of LLMs by using LoRA over 4-bit quantized LLM. The authors propose NF4, a new data type for normal data. Additionally, efficiency tricks have been proposed, including double quantization, which promotes the quantization of the quantization constant and paged optimizer for long-sequence mini-batches. Combined, QLoRA is able to fine-tune 65B LLMs on a single GPU. '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. The fine-tuned models are thoroughly evaluated, and the ablations in the appendix complement the main paper.\n2. This work attempts to solve a broader problem in the deep learning community and can do so successfully, unlocking the application of QLoRA on other large-scale deep learning models.\n3. The evaluation is thorough with the exact specifications of the compared methods, dataset, hyperparameters and base models.'}, 'weaknesses': {'value': '1. No serious weakness apart from minor revisions (see questions)'}, 'questions': {'value': '1. Can the authors re-think the naming convention of double quantization, for example, I had to re-read equations 4 and 5 for better understanding.\n2. Can the structure of NF4 data type be directly plugged into 8-bit and higher precision data-types for improved performance, if yes is there any experiment to show the prowess of the NFX data types?'}, 'limitations': {'value': 'Yes'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'QLoRA: Efficient Finetuning of Quantized LLMs'}, 'authors': {'value': ['Tim Dettmers', 'Artidoro Pagnoni', 'Ari Holtzman', 'Luke Zettlemoyer']}, 'authorids': {'value': ['~Tim_Dettmers2', '~Artidoro_Pagnoni1', '~Ari_Holtzman1', '~Luke_Zettlemoyer1']}, 'keywords': {'value': ['finetuning', 'llama', 'instructions', 'quantization']}, 'TLDR': {'value': 'We develop a method that enabling the finetuning of a 65B model on a single GPU without performance degradation achieving ChatGPT-quaity results on the Vicuna benchmark.'}, 'abstract': {'value': 'We present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters~(LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information-theoretically optimal for normally distributed weights (b) Double Quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) Paged Optimziers to manage memory spikes. We use QLoRA to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small, high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations, showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to ChatGPT. We release all of our models and code, including CUDA kernels for 4-bit training.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/2ec2f739340ddea41364c1b8e9c386c36f96da8a.pdf'}, 'supplementary_material': {'value': '/attachment/fd52cb849c593de766b9b189e7de1a4e7eb7df27.pdf'}, '_bibtex': {'value': '@inproceedings{\ndettmers2023qlora,\ntitle={{QL}o{RA}: Efficient Finetuning of Quantized {LLM}s},\nauthor={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=OUIFPHEgJU}\n}'}, 'paperhash': {'value': 'dettmers|qlora_efficient_finetuning_of_quantized_llms'}}]"
"['Royi Rassin', 'Eran Hirsch', 'Daniel Glickman', 'Shauli Ravfogel', 'Yoav Goldberg', 'Gal Chechik']",NeurIPS,Linguistic Binding in Diffusion Models_ Enhancing Attribute Correspondence through Attention Map Alignment,https://neurips.cc/virtual/2023/oral/73870,2023," Text-conditioned image generation models often generate incorrect associations between entities and their visual attributes. This reflects an impaired mapping between linguistic binding of entities and modifiers in the prompt and visual binding of the corresponding elements in the generated image. As one example, a query like ``a pink sunflower and a yellow flamingo'' may incorrectly produce an image of a yellow sunflower and a pink flamingo. To remedy this issue, we propose SynGen, an approach which first syntactically analyses the prompt to identify entities and their modifiers, and then uses a novel loss function that encourages the cross-attention maps to agree with the linguistic binding reflected by the syntax. Specifically, we encourage large overlap between attention maps of entities and their modifiers, and small overlap with other entities and modifier words. The loss is optimized during inference, without retraining or fine-tuning the model. Human evaluation on three datasets, including one new and challenging set, demonstrate significant improvements of SynGen compared with current state of the art methods. This work highlights how making use of sentence structure during inference can efficiently and substantially improve the faithfulness of text-to-image generation.",Oral 2B Objects/ Neuroscience/Vision,https://openreview.net/pdf?id=AOKU4nRw1W,https://openreview.net/forum?id=AOKU4nRw1W,AOKU4nRw1W,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper proposes an approach to improve diffusion-based image generation models with respect to image–text alignment, in particular, improving the correspondence between entity-noun and its modifier (in the text prompt) and the generated object and its attributes (in the image). The reviewers find the experiments comprehensive and the paper is clear. The concern around the design of the human annotation task is discussed and addressed during the rebuttal, and the authors will provide this additional analysis to the final paper. Overall I agree with the reviewers that the paper addresses an interesting problem in a simple but effective way (which is shown through the experiments).'}}, {'comment': {'value': ""I have read the other reviews, and would like to thank the authors for their responses.\n\nWith this information in mind, I will maintain my score.\n\nSome questions have been raised regarding similarity to the Attend-and-Excite paper. My view on this is that Attend-and-Excite is different in that it doesn't address the attribute binding problem (except indirectly by decreasing attribute neglect). Attribute binding seems to be somewhat resistant to being solved by indirect methods, which contributes to my favorable assessment of the more direct approach taken in this paper.""}}, {'title': {'value': 'Thanks for the clarifications'}, 'comment': {'value': 'Thanks, and looking forward to the qualitative examples and categorization of errors! Maintaining the score for now.'}}, {'comment': {'value': 'Thank you so much for the support and trust. We will provide all details of the experiments and make our code public to make experiments easy to replicate.'}}, {'title': {'value': 'Re: Author response'}, 'comment': {'value': ""Thanks for the additional experiments and evaluation! There are lots of details brushed under the rug regarding the full evaluation setup but happy to give the benefit of the doubt that these details will be shared and that the evaluation is robust. I've raised my score to reflect this.""}}, {'title': {'value': 'Thank you'}, 'comment': {'value': 'Thank the authors for addressing my questions. I would like to maintain my score for now. '}}, {'rebuttal': {'value': '**W1: Writing doesn’t highlight the connection to A&E. Especially section 2:** Thank you for pointing out that the connection to A&E did not come across clearly. We will revise section 2 to give just credit and clarify the relation to A&E.\n\n**W2: ""Concept Separation"" is too general. Consider collecting finer-grained scores for: number of objects in the prompt, number of objects from its corresponding generated image, number of objects with correct attribute in the corresponding generated image. This provides more sense of success and allows to compute recall.**  Thank you for this important suggestion. Following this suggestion, we collected finer-grained ratings as requested for 120 images for all four baselines in the DVMP dataset. In the table below, the top row shows the fraction of images where raters stated that an entity was missing from the image (sum of number of objects in the image divided by the actual number of objects in the text). The bottom row shows the fraction of images where raters found the attribute was missing or incorrectly bound (sum of number of attribute errors divided by the actual number of attributes in the text). In this dataset, SynGen is on par with A&E in terms of entity neglect, and better in terms of improper binding. We will provide more analysis in the final version.\n\n|                               | SynGen | A&E  | Structured | Standard SD |\n|-------------------------------|--------|------|------------|-------------|\n| Entity Neglect Rate (lower is better) | **20.45** | 22.94 | 31.67     | 33.78      |\n| Improper Binding (lower is better)    | **46.27** | 57.51 | 66.84     | 64.14      |\n\n\n\n**W3: Is combining the proposed losses with A&E’s global constraint a viable option?**\nYes, we believe that should work well. We note that A&E uses Gaussian Smoothing and ‘Iterative Latent Refinement’ that we find to hurt for our task, but both losses can be used.  We will discuss in the paper together with the response to W1.\n\n**Nits:** We will address the typo noted as well as state more explicitly that no training is needed.\n\n\n**Q1 Why didn’t you include numerical modifiers in the study:**\n\nWe agree that this is an interesting future direction for SynGen. Our preliminary work showed that controlling the number of instances of an object has some fundamental differences with the task discussed here. In terms of attention maps, a numerical modifier behaves very differently than modifiers like color, because it induces different properties of the attention maps. For instance, in an image with “two trees” you expect the attention map to usually have two non-overlapping blobs. \nDue to these differences, we decided to leave numerical modifiers for future work. \n\n**Q2: Are there unexpected side-effects of such constraints on model generalization?**\nAs stated in the Limitations section, we observe that the visual appeal of images generated degrades with the number of modifiers in the prompt. However, SynGen’s decline is remarkably less pronounced compared to existing models (see figure 12 in the appendix). \n\n**The lack of standardized evaluation makes it difficult to track progress:**\nWe agree with the reviewer that this is an important topic. \n\nIn fact, we spent significant effort to develop automated evaluation metrics and our best attempt is recorded in section G and table 4 in the appendix. However, multimodal models notoriously fail in groundedness, and human agreement is low. One such example can be seen in the evaluation of the StructureDiffusion paper. There, in table 1, the automatic measure only agrees with human evaluation ~ 47% of the time, where 33% is random. The automatic measure we devise reaches better human agreement (43.5%, where 25% is random), but it is still low. We thus opted to keep it in the appendix, to provide a way of tracking progress, while not over-emphasizing these results.  We believe that given these limitations, it is futile, at the current state of the research, to rely on automatic evaluation in this task. Rather, we opted for high quality and fine-grained human evaluation.\n\nFollowing this comment, we will discuss the need for automated metrics in the paper, and encourage the community to develop some. We will share the raw data of our experiments so future papers can compute future metrics on our data. '}}, {'rebuttal': {'value': 'Thank you for your supportive review of this work. The reviewer raises an important point in designing future systems using SynGen. Future work will need to take into account failures of the parser and develop ways to handle them.'}}, {'rebuttal': {'value': '**W1: What is the speed SynGen compared to the original SD?** Syngen is about the same speed as A&E (~10% slower). This is about twice slower than vanilla SD. We did not invest in performance tuning, so we assume speed can be improved considerably once we do. We will add this information to the Limitations and appendix.\n\n**W2: ""Using tree-based methods for binding may fail.... However, the contribution of SynGen matters a lot as the community … develops more generalized methods."":**  We agree. Importantly, once better binding is available, it can be easily integrated into the generation process using our SynGen approach.\n\n\n**Q1:Would SynGen work for prompts like ""an apple that is blue"" or ""a red apple on the left and another on the right""?** (1) “An apple that is blue” was not supported in the submitted code, but we already have it working well in the most recent version. Same for “An apple that’s extremely blue” and “An apple that is red and yellow in appearance”. (2) “A red apple on the left and another on the right”: Unfortunately not. There are two issues here. First, regarding ""left of”: Spatial relations are not well handled by SD, and SynGen is not designed to fix that problem. Several recent papers proposed ways to improve spatial relations in SD and we assume that combining them with SynGen may help. Second, regarding ""another”: SynGen will attribute ‘red’ to ‘apple’, but ‘another’ is an implicit mention of a second red apple, which requires commonsense to identify, and is beyond the scope of our work. More generally, we work with a dependency graph, a syntactic scheme which captures some useful aspects of the structure of the prompt, but is limited to syntactic relations. More elaborate semantic graph schemes can be easily incorporated in our pipeline in the future.\n\n**Q2: How do you deal with the padding tokens?** We only extract the cross-attention maps of tokens that are in the prompt. That is, we ignore the start, end, and padding tokens. \n\n**Q3: Does Table 2 imply that positive loss harms visual appeal of images?** The table demonstrates that to address the binding problem we need both, the positive and the negative loss. If we were to only use the negative term, the images would have been more visually appealing, but like the table shows, it would not address improper binding.'}}, {'rebuttal': {'value': '**Provide qualitative examples having uncommon modifiers vs different number:** Following this suggestion. We will show qualitative examples of SynGen and our baselines on prompts with a varying number of modifiers. Specifically, with 2, 3, 4, 5, and 6 modifiers. Note that the DVMP dataset does not contain prompts with just a single modifier. In this context, we note that figure 12 in the appendix quantitatively compares SynGen with A&E over several numbers of modifiers in the DVMP dataset. \n\n**Q1: Should values in Table 1 sum to 100%?** Yes. The current sum of ~ 99.8 was due to a rounding error. We’ll fix it in the final version. \n\n**Q2: What is the Complex Concepts Prompts dataset mentioned in Fig 5?** \nThis was an earlier name we considered for our DVMP data. Thank you for noting this mistake.\n\n**Suggestions 1: Reorganize Figures 4, 5, 6 for chronological reference in the text:**\nWe agree with your suggestion and will rearrange the figures to be congruent with the text describing them. Thank you for helping us improve the paper.  '}}, {'summary': {'value': 'This paper approaches the binding problem in text to image diffusion models that is marked by the inability of the models to appropriately identify which modifiers are attached to which nouns in the input text. This often results either in images that mix up the attributes of the different nouns that are mentioned in the text or in images that completely disregard some of the attributes or fall back to statistically likely combinations that are not mentioned in the text. The paper proposes an inference time optimization based on first identifying which modifiers are associated with which nouns, and then optimizing a loss function that explicitly enforces the cross attention matrices of corresponding (i.e. related by modifier-noun relationship) tokens in the text to be similar, while those of every other pair in the sentence to be dissimilar. This results in a diffusion model that adheres more faithfully to the input text and produces images that are deemed better more often than competing baseline approaches that attack the same problem.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '## Originality, Quality, Significance\n* The paper provides a novel lightweight method using off the shelf syntactic parsers to enforce better binding of modifiers to nouns in text to image diffusion models. The qualitative results seem promising and the human evaluation results suggest that the proposed method outperforms previous approaches to mitigate the binding issue.  \n\n## Clarity\nThe paper is easy to follow. The qualitative examples demonstrate the different kind of issues faced by the baselines and the improvements brought by the proposed approach. '}, 'weaknesses': {'value': '* Some qualitative examples on the collected DVMP dataset with some categorization on failure cases based on having uncommon modifiers vs different number (performance on 1,2,3 and more modifiers) of modifiers would have been good to see. '}, 'questions': {'value': ""## Clarifications\n* The metric used in the human evaluation in Table 1 is not sufficiently clear. Aren't the values in each column supposed to sum to 100? \n* What is the Complex Concepts Prompts dataset mentioned in Fig 5?\n\n## Suggestions\n* It would be easier for the reader to follow if the examples in Figure 4,5,6 are reorganized such that the references to them in the text are chronological. Currently it requires the reader to keep going back and forth across the figures. ""}, 'limitations': {'value': 'Yes'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper focuses on attribute binding/leak/neglect problems in text-to-image models. The authors propose, SynGen, a method that utilizes dependency trees combined with cross-attention map optimization to achieve better attribute binding results. Extensive experiments are conducted to show the effectiveness of SynGen compared to previous methods. '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The paper addresses an important compositional problem in text-to-image generation. \n\n- The method is intuitive and effective. SynGen can obtain stronger attribute-object association using dependency trees compared to Structure Diffusion, the positive loss design is well-motivated for solving the problem, and the negative loss design enforces the cross-attention maps over A&E.  \n\n- The experiment looks comprehensive by considering all sources of datasets and including even more challenging prompts DVMP. The prompts in DVMP are more challenging and realistic than previous ""A and B"" format prompts.'}, 'weaknesses': {'value': ""- I am concerned with the efficiency of incorporating so many negative losses in the diffusion process. What's the speed of SynGen compared to the original SD?\n\n- Using tree-based methods for binding may fail for more complicated and practical prompts. In reality, SD users write much longer prompts that describe the components at different levels. However, I think the contribution of SynGen still matters a lot as the community needs time to develop from methods for short prompts to more generalized methods. \n""}, 'questions': {'value': 'Apart from the question in weaknesses:\n\n1. Would SynGen still work for prompts like ""an apple that is blue"" or ""a red apple on the left and another on the right""?\n\n2. I may have missed this part but how do you deal with the padding tokens?\n\n3. Table 2 shows that positive only and positive+negative have lower visual appeal percentages than negative only. Does that imply that the positive loss will harm the visual appealing of the images?'}, 'limitations': {'value': 'See weaknesses. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'A frequent issue in text-prompted image generation (and in many other grounded language scenarios) is that a model will treat text akin to a bag of words and ignore syntactic relationships, such as which adjective attaches to which noun -- this is referred to as a problem with lingusitic binding. The paper proposes addressing this problem in diffusion models by adding an extra step to the diffusion process that nudges the image in the process of being generated so as to respect modifier relationships extracted from a syntactic parse of the prompt. This intervention operates in terms of cross-attention maps (i.e. attention relationships established between tokens and parts of the image), with the intuition that related tokens should map to the same region of the image, and unrelated tokens to different regions.\n\nThe paper also introduces a new challenge dataset aimed at diagnosing problems with linguistic binding in image generation (the proposed method performs well on this challenge set).'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""The issue of improper linguistic binding is one that plagues not only attempts at image generation, but many other model uses of grounded language. It's an important problem that has not been adequately resolved by prior work, whereas this paper has demonstrated substantial steps to overcoming this issue without sacrificing on generated image quality. All of this speaks to the significance of this work, which has the potential to see broad and immediate application without the need to undertake costly new model training efforts.\n\nThe paper is clearly written, and makes effective use of figures to illustrate the problem and how the proposed method resolves it.\n\nThere is thorough and convincing human evaluation on both existing data, and a new challenge dataset designed specifically to reveal instances of problems with binding.""}, 'weaknesses': {'value': 'There are not many weaknesses to point to. This is not a weakness of the paper per se, but when the method my main remaining (aesthetic) dissatisfaction is the reliance on an external parser, and the possibility of cascading failure that any such pipeline-based system entails. '}, 'questions': {'value': 'none'}, 'limitations': {'value': 'Limitations are well addressed in the paper.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents an approach called “SynGen” to improve attribute binding between nouns and their modifiers for text-to-image latent diffusion models, specifically Stable Diffusion. They propose a two-part loss on attention maps that (1) encourages attention maps of nouns and their modifiers to be similar, and (2) encourages attention maps between the noun/modifier to be different from those of other tokens in the prompt. \n\nDatasets and baselines: They run experiments on three datasets: the attribute binding contrast set (ABC-6K) from the Structured Diffusion (baseline 1) paper, data from the Attend-and-Excite (baseline 2), and a newly proposed challenge set called Diverse Visual Modifier Prompts.\n\nEvaluation:  \n(1) Human evals for concept separation and visual appeal. They find that SynGen outperforms baselines.  \n(2) Qualitative analysis with sample prompts and generations for Syngen and the two baselines, demonstrating that SynGen overcomes failure cases of the other two models.  \n(3) Ablations on the loss components and loss weighting.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. This paper tackles an important and challenging drawback of text-to-image diffusion models struggling to faithfully generate objects with the right attributes. \n2. This paper proposes an interesting two-part loss that imposes localized pairwise constraints on the attention maps between image patches and token embeddings. The first constraint enforces that the same image patches attend to both the noun and its modifiers. The second constraint enforces that image patches attending to these nouns/modifiers do not attend to any other tokens in the prompt. \n3. This paper attempts to evaluate on a large set of prompts including those from prior work as well as proposing their own challenge set.\n4. This paper attempts to better understand the effects and side-effects of the proposed losses via ablations. \n'}, 'weaknesses': {'value': '1. The proposed method appears to be strongly grounded in the framework of the Attend-and-Excite paper. The writing doesn’t highlight this connection while introducing the approach in Section 2, beyond a minor footnote. Section 2 would probably need some revision to better draw this connection.\n2. Considering that the paper is tackling a very specific problem, the general “content separation” rating collected in the human eval seems pretty weak. Why not collect finer-grained scores for: number of objects in the prompt, number of objects from prompt generated, number of objects from prompt generated with the correct attributes? Wouldn’t this give a much better sense of task success and could potentially allow computing recall?\n3. The loss function ablation mentions that sometimes objects are omitted from the generated image. Is combining the proposed losses with global constraint defined in the Attend-and-Excite paper a viable option? Since the framework is identical, wouldn’t combining the losses have mitigated this issue? The Attend-and-Excite paper talks about attribute binding as well, so this appears to be a variant to try. \n\nNits:\n1. Maybe more explicitly state that this is an inference-only guidance procedure?\n2. There’s a typo on line 112 for the equation: $\\\\nabla_{z_t}\\\\mathcal{L}$ not $\\\\nabla z_t\\\\mathcal{L}$. Also $z’_t$ not $z’t$.\n'}, 'questions': {'value': '1. Was there a reason to not include numerical modifiers in the study? \n2. Are there unexpected side-effects of such constraints on model generalization? '}, 'limitations': {'value': 'One limitation that was perhaps overlooked is the lack of standardized evaluation. Having to rely on different crowdsourcing tasks and qualitative comparisons makes it much harder to track progress.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Linguistic Binding in Diffusion Models: Enhancing Attribute Correspondence through Attention Map Alignment'}, 'authors': {'value': ['Royi Rassin', 'Eran Hirsch', 'Daniel Glickman', 'Shauli Ravfogel', 'Yoav Goldberg', 'Gal Chechik']}, 'authorids': {'value': ['~Royi_Rassin1', '~Eran_Hirsch1', '~Daniel_Glickman1', '~Shauli_Ravfogel1', '~Yoav_Goldberg1', '~Gal_Chechik1']}, 'keywords': {'value': ['syntax', 'diffusion', 'stable diffusion', 'attribute', 'attention']}, 'abstract': {'value': ""Text-conditioned image generation models often generate incorrect associations between entities and their visual attributes. This reflects an impaired mapping between linguistic binding of entities and modifiers in the prompt and visual binding of the corresponding elements in the generated image. As one example, a query like ``a pink sunflower and a yellow flamingo'' may incorrectly produce an image of a yellow sunflower and a pink flamingo. To remedy this issue, we propose SynGen, an approach which first syntactically analyses the prompt to identify entities and their modifiers, and then uses a novel loss function that encourages the cross-attention maps to agree with the linguistic binding reflected by the syntax. Specifically, we encourage large overlap between attention maps of entities and their modifiers, and small overlap with other entities and modifier words. The loss is optimized during inference, without retraining or fine-tuning the model. Human evaluation on three datasets, including one new and challenging set, demonstrate significant improvements of SynGen compared with current state of the art methods. This work highlights how making use of sentence structure during inference can efficiently and substantially improve the faithfulness of text-to-image generation.""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/7824195db5ce407189278aa1e85e980e96a43811.pdf'}, 'supplementary_material': {'value': '/attachment/e62ae60400a4bfd6c56f40dad1c6a6453a39dbcc.zip'}, '_bibtex': {'value': '@inproceedings{\nrassin2023linguistic,\ntitle={Linguistic Binding in Diffusion Models: Enhancing Attribute Correspondence through Attention Map Alignment},\nauthor={Royi Rassin and Eran Hirsch and Daniel Glickman and Shauli Ravfogel and Yoav Goldberg and Gal Chechik},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=AOKU4nRw1W}\n}'}, 'paperhash': {'value': 'rassin|linguistic_binding_in_diffusion_models_enhancing_attribute_correspondence_through_attention_map_alignment'}}]"
"['Thomas Steinke', 'Milad Nasr', 'Matthew Jagielski']",NeurIPS,Privacy Auditing with One (1) Training Run,https://neurips.cc/virtual/2023/oral/73837,2023," We propose a scheme for auditing differentially private machine learning systems with a single training run. This exploits the parallelism of being able to add or remove multiple training examples independently. We analyze this using the connection between differential privacy and statistical generalization, which avoids the cost of group privacy. Our auditing scheme requires minimal assumptions about the algorithm and can be applied in the black-box or white-box setting. We demonstrate the effectiveness of our framework by applying it to DP-SGD, where we can achieve meaningful empirical privacy lower bounds by training only one model. In contrast, standard methods would require training hundreds of models.",Oral 2D Privacy,https://openreview.net/pdf?id=f38EY21lBw,https://openreview.net/forum?id=f38EY21lBw,f38EY21lBw,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': ""The authors propose an efficient approach (that uses a single training run) for auditing private ML systems. All of the reviewers are very positive about this paper. This is one of the rare submission where the authors' (neat) theoretical contributions is expected to have practical significance too.""}}, {'title': {'value': 'Thanks!'}, 'comment': {'value': 'I thank the authors for providing clarifications. I am still positive about the paper and will maintain my score!'}}, {'comment': {'value': 'Thanks for the replies! I am keeping my score.'}}, {'comment': {'value': 'Thanks for the reply!\n\nI have read all contents on this page. I will keep my rating.'}}, {'comment': {'value': 'I thank the authors for their response and answering my questions.\n\nAfter having read the comments of the other reviewers, the responses of the authors, and parts of the appendix, I have updated my review. Overall, I think this is a good and very well written paper that deserves to be in NeurIPS.'}}, {'comment': {'value': ""I thank the authors for their response. After having read the rebuttal and the other reviewers' comments, I am more confident that this work constitutes a good paper hat should be accepted.""}}, {'rebuttal': {'value': 'Thank you for your time in reading and reviewing our submission!\n\n**Writing:** We will edit the paper, and especially Section 6 for clarity.\n\n**Why this score function:** This is the same score function as used in the prior work, previous works showed it achieves tight results. Our approach works with any score function and it is an interesting direction for further work to devise new score functions. \n\n**Why abstention:** As shown by Carlini et al. (2022), membership inference attacks frequently perform much better on some “hard” examples than on others. Abstaining allows us to focus on only those “hard” examples which are easiest to perform membership inference on. In addition, the hardness of the examples also has an element of chance due to the noise added for privacy; any given example may be harder or easier depending on how the noise happens to affect its score.\n'}}, {'rebuttal': {'value': 'Thank you for your time and comments. We respond below.\n\n**Not small delta:** Our approach works well for reasonable values of delta. E.g. delta=10^-3 in Figures 1 & 2. Handling larger delta is difficult even with multiple runs.\n\n**Conceptual roadblock:** The fact that multiple examples was previously considered as an unproven heuristic shows that people had the right intuition. The high-level key to analyzing this seems to be framing it in terms of generalization. The DP=>generalization literature provides the right toolkit to analyze multiple examples, but we still needed to do a lot of technical analysis to obtain tight results.\n\n**Comparisons for Figure 6:** Please note that none of the previous works can provide guarantees for the single run setting that we are considering in this work, as a result there are no previous works that we can directly compare to. To attempt a comparison to prior work, we tried auditing the Gaussian mechanism with a single example and multiple runs. To obtain results comparable to Figure 10 (i.e. eps>=2.8 when the sensitivity and standard deviation are equal), we require at least 100 runs using prior methods in comparason to a single run using our method.\n\n**Why n-m:** The main point that we want to mention in these experiments is that by increasing the number of non auditing examples the auditing becomes harder. Therefore, it doesn’t make much difference if we use m/n or n-m. Moreover, machine learning models have limited capacity and the number of examples seems to be more important than the ratio. For example as we see in Figure 7 by increasing the number of auditing example significantly we see worse auditing performance. \n\n**Convergence of lower bound to upper bound:** Figure 9 shows that our empirical lower bound does converge to the theoretical upper bound as the number of examples increases and accuracy is held constant. This simply demonstrates that our main theorem is tight. The gap between the bounds is due to statistical uncertainty, which decreases as we add more samples.\n\n**Lower bound decays in Figure 10:** This simulation shows the effect of abstentions. I.e., abstaining on some examples allows us to focus on the clearest examples, which results in higher accuracy. In Figure 10 we increase the number of guesses by making fewer abstentions, which results in lower accuracy. (In contrast, the accuracy in Figure 9 remains constant as we add more guesses.)\n'}}, {'rebuttal': {'value': 'We thank the reviewer for their comments, particularly the suggestions regarding the related work section.\n\n**1. Line 123:** We will clarify that there may be overlap between the design of attacks and our analysis. But, conceptually, most auditing attack design considerations are the same in our setting and in the setting of prior work. That is, we are focused on creating examples that have a high effect on the training procedure and then detecting that effect. Nevertheless, we will make it clear in the text. \n\n**2. Multiple runs:** Extending our analysis to handle both multiple runs and multiple examples is a very interesting topic for future work and something that should be possible. However, we do want to emphasize that, for large models, training a single model is very expensive, and we think it is also important to improve the single model setting. \n'}}, {'rebuttal': {'value': ""We thank the reviewer for their comments, which we respond to now.\n\n**On comparison with previous works:** Nasr et al. [NHSBTJCT23]  uses multiple runs and, as a result, they achieve tighter bounds than we do for the same algorithm; however, we are not sure if there is any meaningful comparison that we can do here as their method cannot analyze our setting and vice versa. \nAndrew et al. [AKOOMS23] propose an epsilon estimation technique which may not be a lower bound; their results in Table 1 show an estimate of epsilon that is larger that the provable epsilon upper bound. In the version that was available before the NeurIPS deadline their estimated epsilon actually significantly overestimated the true epsilon i.e. the theoretical upper bound was 50 and the estimate was 78. Given that their approach does not produce lower bounds on epsilon, a direct comparison is not very meaningful. An interesting direction for further work is to combine our methods with their approach.\n\n**On weakness of the black-box results:** We agree that in the black-box setting our results are weak, as is the case in all previous work. The black-box setting is very challenging, and there is a need to develop better attacks. We note that our analysis can then be applied to better attacks that are developed in the future.\n\n**On novelty:** The idea of using multiple canaries to audit DP mechanisms has been mentioned for years now; the first paper on auditing DP-SGD by Jagielski et al. [JUO'20] introduced multiple examples and used group privacy to analyze their results. The main novelty of the work is in creating a framework to theoretically analyze the setting and to provide a tight mathematical analysis. \n\n**Experiments with $m>5000$:** We didn’t experiment with more canaries due to memory limitations. In Figures 9 & 10 we simulated results for up to 1,000,000 and 100,000 examples, respectively.\n\n**Cost of the attack:** In the whitebox setting, creating canaries is very simple as they are simple gradient vectors that have large value on a single coordinate. The main cost is computing the score function, which requires comparing each gradient update vector with all of the canaries, which is a dot product between two large vectors. This cost can be reduced in future by only focusing on a specific layer in the network or small set of parameters. In the black-box setting, the canaries are simply examples and we only need to evaluate the final loss, which is much easier than computing inner products.\n\n**Would there be a way to make the method dataset/model specific?** The choice of auditing examples/canaries and the score function can be tailored to the dataset/model. \n\n""}}, {'rebuttal': {'value': 'Thank you very much for your review!'}}, {'summary': {'value': 'The paper studies the problem of auditing differentially private machine learning systems. They propose a procedure which does so in one training run -- the key is the ability to include/exclude multiple data items in the run, as well as a novel analysis via leveraging connections between DP and generalization. They conduct experiments auditing DP-SGD obtaining meaningful empirical privacy lower bounds. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""1. The topic of the paper is important and timely.  As the authors put, a privacy audit allows to assess the tightness of mathematical analysis and detect errors in analysis and implementation. As differentially private machine learning systems are being deployed increasingly, the research has potential to be impactful in these areas.\n\n2. The authors make interesting contributions, with strong theoretical underpinnings which directly lead to improved results in practice. In my limited experience, such results aren't are rather rare and I greatly enjoyed this aspect of the paper. Moreover, the idea of membership inference with multiple inclusion/exclusion of data items, has been used as a heuristic in the past, so this paper gives a mathematical justification for the heuristic.\n\n3. The paper is very well-written -- it is insightful and to the point. The paper also contains an extended discussion (Section 6) on the limitation of this work (and related approaches).""}, 'weaknesses': {'value': '1. In some parts of the paper, I found the writing to be too dense. This is especially true for Section 6. I encourage the authors to revise this part.\n\n2. While the authors provide extensive experimental results testing various aspects of the procedure, I found the section to be poorly organized. I encourage the authors to provide an overview of what is to come in the beginning of the experiments section.'}, 'questions': {'value': '1. Why the particular choice of score function for white-box attacks? Did the authors try other choices before settling on this?\n2. What is the intuition behind allowing abstention? '}, 'limitations': {'value': 'I greatly appreciate that the authors provided an extensive discussion of the limitations. However, as suggested above, the writing is too dense in these parts. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents a one shot approach for auditing privacy. Their approach is as follows: given n independent input samples and a (dp) algorithm to audit, they divide the $n$ input samples into two groups $X$ and $Y$ of size $m$ and $n-m$ respectively. Then they randomly select a partition of the first part $(X_1,X_2)$, and only use $X_1 \\cup Y$ as the input of the dp algorithm. After that, they choose / design an application dependent score function that helps decide if each member of $X$ appeared in the input of the algorithm or not. The accuracy of this decision function implies a lower bound on the privacy of the algorithm. \n\nTheir main technical observation is that if $X$ is partitioned through a poisson sampling procedure, then running the auditing algorithm for one run is as good having $m$ independent runs. Their algorithm works both in the case where the final result of the algorithm is released and in the case where the intermediate steps are also released. In the end they decide whether the algorithm could be $(\\varepsilon, \\delta)$-dp or not by observing that the number correct guesses has to be less than $r \\cdot e^\\varepsilon / (e^\\varepsilon+1) + O(\\sqrt{r})$ with high probability, where $r< m$ is the total number of guesses.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The experiments for gradient space attack suggest that their lower bounds are within constant factor of the theoretical upper bounds, in both the case where the adversary has access to all of the model iterates and in the case where the adversary only has access to the final model.\n\nThe review of related work is very good and well written.\n\nTheir empirical lower bounds converge to analytical bounds in some cases if delta is sufficiently small and the number of examples goes to infinity.'}, 'weaknesses': {'value': 'Their approach does not seem to extend well to the case where delta is not very small.\n\nIn the setting where the adversary only can audit the input space (as opposed to the gradient space), their results do not seem to be very strong. This is important because in practice the algorithm has to be private with respect to the input space and not the gradient space. '}, 'questions': {'value': 'In line 51 to 57, the authors mention that such results were previously unattainable in the setting where only one model could be trained. On a conceptual level, what do you think was the roadblock that previous work could not overcome and is overcome in this work?\n\nIt\'s not clear to me in the experiments whether the ""meaningful"" metric to consider is $n-m$ or $n / m$.\n\nThere\'s no other auditing baseline presented to compare to in Figure 6. How do your results compare to previous work?\n\nYour empirical results suggest that the lower bounds converge to analytical bounds in some cases if delta is sufficiently small and the number of examples go to infinity. Is there an analytical explanation for this?\n\nSomething that\'s a bit confusing to me is that in Figure 10, the empirical lower bound on epsilon decays after some point. Can you explain why this is happening?'}, 'limitations': {'value': 'The authors have discussed the limitations of their work adequately.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors propose a scheme for auditing differentially private machine learning models with a single training run (instead of thousands as have been used so far).'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. limitations clearly explained and illustrated\n2. paper is really well structured (except for related work; see weaknesses)\n3. important impact within DP auditing'}, 'weaknesses': {'value': '1. It would help the reader if the related work was moved to before the empirical evaluation. Methods from the empirical evaluation are adapted from related work so more explanations earlier on might help with understanding\n2. the comparison with related work falls a bit short. it would be nice to whether and when the heuristic proposed by MEMPST21 is not practically applicable. If they provide a better bound that holds true in most scenarios (even if there is no mathematical guarantee for it), it might be preferable to a loose bound with mathematical guarantee.'}, 'questions': {'value': '1.  in ll 123 f., the authors say that the design of the attack is orthogonal to the analysis of the privacy attack. I wonder whether this claim is necessarily always true. Design methodology introduced for attacks with 1000s of runs might suffer from a high variance that could be maybe be highly detrimental for a single training run?\n2. Do the authors believe that the methodology could be extended to multiple training runs to have a tradeoff between either 1000 or 1 runs?'}, 'limitations': {'value': 'the limitations have been adequately addressed and illustrated'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""The paper gives a simple version of a differential privacy (DP) auditing, and the proposed method is related to the recent works (G. Andrew, P. Kairouz, S. Oh, A. Oprea, H. B. McMahan, and V. Suriyaku- mar. “One-shot Empirical Privacy Estimation for Federated Learning”, 2023 and S. Zanella-Beguelin, L. Wutschitz, S. Tople, A. Salem, V. Ruhle, A. Paverd, M. Naseri, and B. Kopf. “Bayesian estimation of differential privacy”, 2022). There is also a theoretically rigorous analysis for the proposed method.\n\nAndrew et al. (2023) work seems very much related (does also one shot auditing) however more heuristic. This paper provides confidence intervals for the epsilons, whereas it seems to be an open problem whether the empirical epsilons by Andrew et al. (2023) can be rigorously connected to the theoretical guarantees.\n\nThe idea in the proposed method is simple: certain amount of data (canaries) is held out for auditing such that each sample is randomly included in the training, and in the end the total number of correct guesses (whether sample was or wasn't in the training data) will give the empirical epsilons (high-probability lower bounds). This ratio can be connected to the theoretical guarantees via Theorem 3.1. The main result is the analysis of the method (Theorem 3.1). The experiments are very similar to those used in the recent auditing paper by Nasr, Hayes, Steinke, Balle, Tram`er, Jagielski, Carlini, and Terzis.\n\nA pathological example in the shows the tightness of the epsilons give by this auditing method, and also includes some discussion about the looseness of the bounds in realistic situations.""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The idea is simple, the analysis sound and the paper is easy to read. All in all I think fits well to NeurIPS\n- The analysis is tight in a sense that there are pathological DP algorithms for which the empirical epsilons are tight.\n- Contribution seems clear: puts one shot auditing on a more rigorous footing (more rigorous than the previously proposed approaches)'}, 'weaknesses': {'value': '\n\n- It remains a bit unclear from the paper, how does it compare to other auditing methods? It would be nice to see how it compares to e.g. to the empirical epsilons given in [NHSBTJCT23]. Especially in case of black box attacks there seems to be a big gap. Also would be interesting to see how the result compare to the results given by the one shot method of [AKOOMS23]. Even if the epsilons reported here are on a more rigorous footing than those of [AKOOMS23], I would guess that in practice one might end up using the method of [AKOOMS23] if it tends to give much more realistic epsilons.\n\n- It still remains a bit unclear how useful this would be in practice. Especially in the black box setting the results look weak: already with 10000 samples (all used for auditing) or small amount of additional samples (not used for auditing), the empirical epsilons are really far from the theoretical ones. \n\n- One small weakness is perhaps certain lack of originality: the main contribution is the mathematical analysis, the main ideas behind this auditing method seem to be laid out already in the recent works [ZBWTSRPNK22] and [AKOOMS23].'}, 'questions': {'value': 'In the white box setting, your experiments show that increasing number of data samples increases the epsilon lower bound. In Figure 3 you have Cifar-10 results up to $m=5000$ samples. Did you try for $m>5000$? How close can you get? Why not to report results for $m>5000$?\n\nIn the white box setting, where you insert the canaries and get the best results:  how expensive is the attack itself? I mean if you construct the canaries at each step, how expensive it is compared to the model training? \n\nThis approach is for auditing an ML system, and then it seems reasonable to use a small amount of samples and report the epsilon lower bounds. What if the protection gets really strong for realistic training data sizes, are those epsilons meaningful anymore? Would there be a way to make the method dataset/model specific?\n\nTypo, p.5:\n""First, we evaluate the effect of the number of the auditing example""'}, 'limitations': {'value': 'Yes, there is an extensive discussion in the end about the limitations of this approach. The extended version (supplements) has also a discussion about possible directions for future work.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""The paper improves the computational efficiency of auditing differentially private machine learning systems by connecting differential privacy and statistical generalization. The authors propose the first 1-round scheme compared to the standard solutions with hundreds of training rounds. \n\nThe auditing procedure operates as follows. 1) Randomly identify $m$ data points to either include or exclude. 2) Run the algorithm on the randomly selected dataset. 3) Given the algorithm's output, the auditor “guesses” whether or not each data point was included or excluded. \n\nThe main theoretical contribution is an improved analysis that is tailored to yield tight bounds. The auditing scheme requires minimal assumptions. The authors theoretically justified the improved efficiency of auditing via membership inference on multiple examples simultaneously. The paper shows that standard membership inference attacks can be used for auditing analysis, i.e., exploiting the parallelism of multiple independent data points in a single run of the algorithm in lieu of multiple independent runs.\n\n\nIn experiments, the authors audited DP-SGD training on a WideResNet model, trained on the CIFAR10 dataset across multiple configurations. The experiments contain both gradient and input attacks. The experimental results confirm the contributions claimed by the authors before.\n""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""+ The paper gives the first scheme of one-round privacy auditing, which is computationally efficient. This is a totally new perspective, jumping out of prior literature.\n+ Theoretical foundation has been well built, i.e., Theorem 3.1. The formulation of privacy auditing bridges guess and privacy, which can be adopted in future instantiations/applications.\n+ The experimental results are convincing, i.e., confirming the paper's contribution.\n+ The writing is excellent. The authors clearly introduce the scheme, and meantime, show their deep insights and creative knowledge. At least, I feel I learned a lot in this paper.\n+ Personally speaking, I think this paper will motivate many future works. \n ""}, 'weaknesses': {'value': 'I did not find the weakness. '}, 'questions': {'value': 'The paper is self-contained. The details in the supplementary are very sufficient.'}, 'limitations': {'value': 'The authors studied the limitation comprehensively.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Privacy Auditing with One (1) Training Run'}, 'authors': {'value': ['Thomas Steinke', 'Milad Nasr', 'Matthew Jagielski']}, 'authorids': {'value': ['~Thomas_Steinke2', '~Milad_Nasr2', '~Matthew_Jagielski1']}, 'keywords': {'value': ['Differential privacy', 'membership inference attacks', 'privacy auditing']}, 'abstract': {'value': 'We propose a scheme for auditing differentially private machine learning systems with a single training run. This exploits the parallelism of being able to add or remove multiple training examples independently. We analyze this using the connection between differential privacy and statistical generalization, which avoids the cost of group privacy. Our auditing scheme requires minimal assumptions about the algorithm and can be applied in the black-box or white-box setting. We demonstrate the effectiveness of our framework by applying it to DP-SGD, where we can achieve meaningful empirical privacy lower bounds by training only one model. In contrast, standard methods would require training hundreds of models.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'We show how to compute lower bounds on the privacy parameters of an algorithm with only one run of that algorithm.'}, 'supplementary_material': {'value': '/attachment/6bf63f60c9f2255c824bb0672c728434fba2547f.pdf'}, 'pdf': {'value': '/pdf/ea8cc13e0d434d255f2042b40f1791762c99ae92.pdf'}, '_bibtex': {'value': '@inproceedings{\nsteinke2023privacy,\ntitle={Privacy Auditing with One (1) Training Run},\nauthor={Thomas Steinke and Milad Nasr and Matthew Jagielski},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=f38EY21lBw}\n}'}, 'paperhash': {'value': 'steinke|privacy_auditing_with_one_1_training_run'}}]"
"['Junhyung Park', 'Simon Buchholz', 'Bernhard Schölkopf', 'Krikamol Muandet']",NeurIPS,A Measure-Theoretic Axiomatisation of Causality,https://neurips.cc/virtual/2023/oral/73819,2023," Causality is a central concept in a wide range of research areas, yet there is still no universally agreed axiomatisation of causality. We view causality both as an extension of probability theory and as a study of what happens when one intervenes on a system, and argue in favour of taking Kolmogorov's measure-theoretic axiomatisation of probability as the starting point towards an axiomatisation of causality. To that end, we propose the notion of a causal space, consisting of a probability space along with a collection of transition probability kernels, called causal kernels, that encode the causal information of the space. Our proposed framework is not only rigorously grounded in measure theory, but it also sheds light on long-standing limitations of existing frameworks including, for example, cycles, latent variables and stochastic processes.",Oral 2C Causality,https://openreview.net/pdf?id=sPLTQSf6GI,https://openreview.net/forum?id=sPLTQSf6GI,sPLTQSf6GI,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': '**This is a very strong paper on the measure theoretic foundation of causality and highly important contribution to the field. Deserves special attention, such as an oral and/or an award (in the theory segment, if there are different categories).**\n\nThere was one negative reviewer (xRcV), but the review was short and rather uninformative. The reviewer also disappeared and did not react, neither to requests from the authors nor the AC. The review should therefore be disregarded.'}}, {'comment': {'value': 'Thanks for the clarifications. I stand by my high rating of this paper.'}}, {'title': {'value': 'Thank you for your response'}, 'comment': {'value': 'Dear reviewer TfjY, \n\nThank you for your thoughtful response to our rebuttal. \n\nWe agree that the word trial does make one think of repeated experiments. We\'ll try to think of some other wording that is more suitable. Perhaps occurrences?\n\nWe also agree with the second point, and we think ""population model"" is a great suggestion, and certainly sounds more fitting than the data generating process, especially if we do not restrict ourselves to the frequentist mindset. We\'ll make this change in the future versions of this work. \n\nThank you for providing further discussion on this important point. We agree that, if one wants to extend a theory of probabilities to a theory of causality, then one must carefully consider the merits of each framework of probability for that goal, and Kolmogorov\'s framework shouldn\'t be the automatic choice purely on the basis of its widespread acceptance. We must admit that we have not given this as much deliberation as we perhaps should have done, and as written in the original rebuttal, we propose to give more of a discussion on this point. Thank you also for reiterating your appreciation of our work, we don\'t take it for granted and we are hugely grateful. '}}, {'title': {'value': 'Thank you for the discussion'}, 'comment': {'value': 'Dear Authors,\n\nThanks for the nice answers and discussion. \n\nAbout the little details:\n\n* P3, L108-113: I would say that the name trial evoke repeated experiments in my mind, and I am not sure it quite fits the proposed framework. However, if this is the vocabulary used in some previous similar settings, I have no strong arguments against it. \n\n* Figure 1: I would say that if one has graphical models and subjective trends of probabilities in mind, one could probably replace data by evidence and data-generating process by knowledge model or something similar (population model?). However, I also have no strong oppinion aobut that, it is just that confining probability and causality to data and data-generation process (which suggest a frequentist flavour) seems a bit limiting (yet sufficient anyway to encompass most if not all ML problems).\n\n* About the measure-theoretic approach and the axiomatic: thank you for the discussion here, and I somehow agree with the points made about the use of axiomatisation and the fact that Kolmogorov measure-theoretic approach is the most used and wide-spred. However, an approach/intrepretation being the main one is not really an argument to support the fact that it is the most relevant one to treat/view a given problem. And I would argue that, in the case of causality, having a clear semantic/interpretation of the probabilities and probabilistic model used seems important, hence my hope for such a discussion. I am quite fine with purely formal/mathematical characterisation theorems, and I do appreciate the work presented here. I guess more philosophical discussions can be postponed to future times. '}}, {'comment': {'value': 'Thanks, the axiomatic discussion is interesting and of course I agree it should be included. To the extent that a completeness proof could be given it might shed light on the question about the rice example (namely, if these principles are complete and the rice distribution obeys them, then there must exist a cyclic SCM modeling the distribution even if it seems difficult to model). I maintain my overall positive rating.'}}, {'comment': {'value': 'Dear reviewer xRcV,\n\nYou have been the most negative reviewer for this paper. Can you please respond to the authors rebuttal, and also take the other reviews into account?\n\nThank you, AC'}}, {'comment': {'value': 'I have read the rebuttal. Thanks for the clarifications!'}}, {'rebuttal': {'value': 'We would like to thank all reviewers for their time and effort in reviewing our paper, and for making many valuable suggestions that are sure to improve the draft. We are very grateful for your time, and do not take it for granted. We are also very grateful for the mostly positive reviews, and kind words. We answer points raised by individual reviewers separately, except those relating to cycles and Example 4.2, which we answer jointly here. \n\n**Do cyclic causal relationships truly exist, or is everything acyclic if we include a time component?**\n\nAs challenged by reviewer TfjY, it is difficult to think of truly instantaneous cyclic causal relationships (unless they are random variables that do not live in separate components of a product $\\sigma$-algebra; see Remark 2.7(i). For example, if $X$ and $Y$ represent the weight of a box in kg and stones respectively, then one could argue that $X$ ""causally"" affects $Y$ and vice versa, and that this causal effect is instantaneous. However, in our opinion, it makes no sense to talk about the causal effect between random variables that do not live in separate components of a product $\\sigma$-algebra. In SCMs, or in any other causal model based on graphs, random variables represented by each node should live in separate components of a product $\\sigma$-algebra. Note that this is different to when two random variables do live in separate components of a product $\\sigma$-algebra but a measure *happens* to be supported on some kind of a diagonal). \n\nWe believe that even in non-cyclic situations, most causal relationships have a hidden time component, although one could argue that some causal effects really are instantaneous, for example, altitude causally affecting temperature, or the picture of a cow causally affecting its label to be ""cow"". Our stance is more aligned with reviewer pcib, in that modelling cyclic causal relationships are useful abstractions of what are in the end non-cyclic causal relationships. We also believe that it is extremely difficult to argue against the necessity of such an abstraction, if researchers are happy to model non-cyclic, time-dependent causal relationships without explicitly modelling the time component (as it is in fact very often done) and if we believe in the necessity of being able to do so. It is in this sense that we wrote ""cyclic causal relationships abound in the real world"", although, as pointed out by reviewer pcib, this sentence may be somewhat misleading. We propose to replace it with something that better reflects the discussion in this paragraph. We also do not want to completely rule out the possibility that one might come across a truly instantaneous and cyclic causal relationship, although we are leaning more towards the belief that such a situation may not exist. \n\nOn the other hand, if one were to insist on modelling the time component explicitly every time it is present (which is not our stance), then we argue that the current tools to model causality within stochastic processes fall short, and we believe that causal spaces make significant contribution in this regard too, as argued in Section 4.3 and as agreed by reviewer aMnb. In answer to reviewer pcib, no, we do not subscribe to causation that goes backwards in time, and it is for this reason that we felt it important to introduce the concept of *time-respecting causal mechanism* in Definition 4.3. \n\n**Example 4.2**\n\nReviewers aMnb and pcib suggested that it would not be difficult to model the situation in Example 4.2 with a solvable cyclic SCM [Bongers et al., 2021]. To us, this was difficult, and we didn\'t manage to do so, both when we were writing the paper and during this rebuttal period. One of the reasons is that the observational measure and the interventional measures are decoupled, and the interventional measure (after intervening on either variable) does not equal the corresponding conditional measure, which means that we must include a common hidden confounding variable. But even apart from this, it seems like a difficult task (at least for us; perhaps we lack the skills or experience for it) to set up the noise variables and their distributions, and to come up with structural equations that yield given desired observational and interventional measures. The example given in [Bongers et al., 2021, Example 3.5] seems like an extremely simple case. We admit that it could still be possible and that we just lack the skills to do it; equally, we did not show that this was *not* possible, and we would be curious to know if the reviewers were able to do this. \n\nBut it should at least serve to illustrate one point - that in SCMs, if we start with noise distributions and structural equations that involve cycles, then it is highly non-trivial to show the existence and uniqueness of a solution, and if we start with the observational and interventional distributions of the endogenous variables, then it is (at least for us) very difficult to find the noise distributions and the structural equations that yield them as a (unique) solution. On the other hand, we argue that causal spaces facilitate a much more natural expression of cyclic causal relationships. \n\nWe would like to thank all reviewers again for their time, and if you have any further questions, or if any of our explanations were unclear, or if we misunderstood any of your points, we would be very grateful if you could let us know. We look forward to engaging in further discussions in the author-reviewer discussion period. '}}, {'rebuttal': {'value': ""We thank the reviewer for the time and effort spent in reviewing our submission, and for the overall positive evaluation. We also thank you for raising interesting points and suggestions for improvements, which we will take into account in future versions of this work. Below, we will try our best to address your concerns and queries. \n\n**Line 49**\n\nThis is a very reasonable citation recommendation. We had of course read the paper during the project, but inexplicably left out its citation in our submission. We will make sure to include it in future versions of this work. Thank you very much for pointing it out. \n\n**Line 296**\n\nAgreed - thank you very much! \n\n**Rice Example**\n\nThank you for making this point - please see author rebuttal to all reviewers. \n\n**Example 4.2**\n\nThank you for pointing this out. We will change one of the $x$'s into a $y$ for better notation. \n\n**Principles of SCMs**\n\nBy effectiveness, composition and reversibility, we assume that the reviewer is referring to the notions introduced under these names in [Galles and Pearl, 1998, An Axiomatic Characterisation of Causal Counterfactuals, Section 3]. This is a very interesting point to consider, and we are very grateful to you for raising it. \n\nFirstly, even though the concepts of effectiveness, composition and reversibility can be carried over to causal spaces, the mathematics through which they are represented needs to be adapted, since the tools that are used in causal spaces are different from those used in causal models of [Galles and Pearl, 1998]. In particular, we work directly with *measures* as the primitive objects, whereas [Galles and Pearl, 1998] use the structural equations as the primitive objects, and the probabilities only enter through a measure on the exogenous variables. Thus, the three properties can be phrased in the causal space language as follows:\n\nEffectiveness: For $S\\subseteq R\\subseteq T$, if we intervene on $\\mathscr{H}_R$ via a measure $\\mathbb{Q}$, then $\\mathscr{H}_S$ has measure $\\mathbb{Q}$ restricted to $\\mathscr{H}_S$. This is indeed guaranteed by interventional determinism (Definition 2.2(ii)), as you said. \n\nComposition: For $S,R\\subseteq T$, denote by $\\mathbb{Q}'$ the measure on $\\mathscr{H}_{S\\cup R}$ obtained by restricting $\\mathbb{P}^{\\text{do}(S,\\mathbb{Q})}$. Then $\\mathbb{P}^{\\text{do}(S,\\mathbb{Q})}=\\mathbb{P}^{\\text{do}(S\\cup R,\\mathbb{Q}')}$. In words, intervening on $\\mathscr{H}_S$ via the measure $\\mathbb{Q}$ is the same as intervening on $S\\cup R$ via the measure that it would have if we intervened on $\\mathscr{H}_S$ via $\\mathbb{Q}$. This is not in general true, as you said. A counterexample can be demonstrated with a simple SCM, where $X_1$, $X_2$ and $X_3$ causally affect $Y$, in a way that depends not only on the marginal distributions of $X_1$, $X_2$ and $X_3$ but their joint distribution, and $X_1$, $X_2$ and $X_3$ have no causal relationships among them. Then intervening on $X_1$ with some measure $\\mathbb{Q}$ cannot be the same as intervening on $X_1$ and $X_2$ with $\\mathbb{Q}\\otimes\\mathbb{P}$, since such an intervention would change the joint distribution of $X_1$, $X_2$ and $X_3$ even if we give them the same marginal distributions. \n\nReversibility: For $S,R,U\\subseteq T$, let $\\mathbb{Q}$ be some measure on $\\mathscr{H}_S$, and $\\mathbb{Q}_1$ and $\\mathbb{Q}_2$ be measures on $S\\cup R$ and $S\\cup U$ respectively such that they coincide with $\\mathbb{Q}$ when restricted to $\\mathscr{H}_S$. Then if $\\mathbb{P}^{\\text{do}(S\\cup R,\\mathbb{Q}_1)}(B)=\\mathbb{Q}_2(B)$ for all $B\\in\\mathscr{H}_U$ and if $\\mathbb{P}^{\\text{do}(S\\cup U,\\mathbb{Q}_2)}(C)=\\mathbb{Q}_1(C)$ for all $C\\in\\mathscr{H}_R$, then $\\mathbb{P}^{\\text{do}(S,\\mathbb{Q})}(A)=\\mathbb{Q}_1(A)$ for all $A\\in\\mathscr{H}_R$. We again agree with you that this does not hold in general in causal spaces. In fact, Example 4.2 in our paper is a counterexample of this, with $S=\\emptyset$. \n\nSo all in all, we agree with your answers of no, yes, yes, as to whether the causal space framework challenges these fundamental properties of SCMs. Composition is an interesting one, because even in the SCM setting, it is very clear that it does not hold if we are interested in the *measure* of the target variable, not just the pointwise evaluation of the structural equations. This is a very interesting discussion, and we propose to include it in future versions of this work. Thank you very much again for raising this point! \n\n**Line 328**\n\nThis is a terrible typo. Thank you very much for pointing it out. \n\nWe thank you again for the review, positive evaluation and valuable suggestions for improvements. We hope to have clarified your questions, and should you have any further questions, or if we misunderstood any of your points, we would be happy to engage in the author-reviewer discussion. ""}}, {'rebuttal': {'value': 'We thank the reviewer very much for the time and effort spent in reviewing our submission, and for the positive evaluation. Thank you also for suggestions for improvements; we will reflect them in future versions of this work. We will do our best below to address your concerns in the Questions section. \n\n1. If we understand correctly, you are referring to Section 3.1, lines 214-215. This is not referring exclusively to hard interventions, it is simply constructing the causal kernels. Once these causal kernels are constructed, by placing a non-Dirac measure on the sub-$\\sigma$-algebra on which we want to intervene, and also by utilising the internal causal mechanisms $L$, we can then formulate soft interventions. For future versions of this work, we propose to spell this out more explicitly. \n\n2. Actually the point we were trying to make was precisely in agreement with your view - that we are most often interested in intervening on subsystems, rather than the whole system. Our causal kernels capture precisely this information, i.e. the effect of intervening on subsystems on the whole system. The point we were trying to make was that in the SCM formulation, the mathematics seems to go in the reverse direction to this philosophy, because each structural equation $f_j$ encodes information about the effect of intervening on the whole system on the subsystem $X_j$. Our causal space formalism does *not* view interventions system-wide - each causal kernel encodes information about intervening on the corresponding subsystem (sub-$\\sigma$-algebra). In this sense, we are in complete agreement in terms of the philosophy (with Woodward, and that behind e.g. the SCM framework), we just differ in how to encode this mathematically. \n\nAs for the decoupling of observational and interventional measures, we maintain that it is an advantage to be able to do this for the sake of generality. In order to be able to couple them, as it is done in SCMs, we have to impose the assumption that all of the variables have been included in the model that are required to do this (see Example 4.1). We do treat the case in which observational measure and the interventional measure (at least partially) match as an important special case - see Appendix D on the concept of sources that we introduce there. \n\n3. Some philosophy behind causal spaces is shared with GSEMs in the sense that GSEMs also encode information about what happens to the whole system when intervening on a subsystem. However, there are some technical hurdles to be overcome if one wants to actually reconstruct a GSEM from a causal space. First of all, they consider power sets of the range rather than $\\sigma$-algebras, which, if the variables are allowed to take uncountably many values, causes measure-theoretic problems. Moreover, as you rightly point out, for a given probability measure on the exogenous variables and an intervention, there seems to be no way of propagating this measure on the exogenous variables to sets of values of the endogenous variables. \n\nIn the sense that GSEMs cannot do probabilities and causal spaces are designed explicitly with probabilities in mind, we believe that causal spaces strictly generalise GSEMs. We also do not believe that they worked with power sets rather than $\\sigma$-algebras for any deep reason, and if we wrote out the GSEM formulation with $\\sigma$-algebras, then indeed, as you suggest, we believe it would be possible to reconstruct GSEMs from causal spaces by letting the function $\\mathbf{F}$ map to the support of each intervention. However, for reasons laid out above, there would be no way of uniquely reconstructing causal spaces from GSEMs. \n\n4. This would be very valuable addition to our work, and we are very grateful to you for this comment. We absolutely propose to add a discussion on this example in future versions of this work. \n\nAs for footnote 2, we agree with you that the variable itself is not meaningless. The variable of course can have meaning as a way of capturing our ignorance, precisely as you said. Our point was that such a variable cannot have numerical values and distributions that represent something meaningful. What does it mean for a variable that we name ""everything in the world that we do not know about"" to have value 1? What does it mean for it to be normally distributed? Properly defined random variables should be more concrete, e.g. height of a student in cm, temperature in Celsius, crop yield in tonnes, etc. \n\n5. Thank you for raising this point. Please see author rebuttal to all reviewers. \n\nWe thank you again for your positive review and suggestions, and should you have any more questions or if we misunderstood any of your points, we would be delighted to engage in the author-reviewer discussions. '}}, {'rebuttal': {'value': ""We thank the reviewer very much for the time and effort spent in reviewing our submission, and for the positive evaluation. Your comments make it clear that you understood and agreed with our motivation behind this project, for which we are humbled and extremely grateful. We are also very grateful for the suggestions for improvements, which we will take into account for future versions of this paper. We will do our best to address your concerns below. \n\n**Motivation**\n\nWe fully agree that, as currently written, the axioms somewhat seem to be pulled out of the hat. In fact, these axioms were a result of over a year of contemplating different ways of axiomatising causality. Given more space, you are absolutely right that more discussion of the motivation and potential alternative axiomatisations would certainly benefit the paper, and we propose to do so in the future versions of this work. \n\n**Lines 137-138**\n\nThe causal kernel $K_S$ is a transition probability kernel from $(\\Omega,\\mathscr{H}_S)$ into $(\\Omega,\\mathscr{H})$, so for a given $A\\in\\mathscr{H}$, the map $\\omega\\mapsto K_S(\\omega,A)$ has to be measurable with respect to $\\mathscr{H}_S$ (see definition of transition kernels in the appendix, lines 568-575). If $K_S$ depended on the $T\\setminus S$ components, it would violate this measurability condition. We hope we understood your point correctly, and that this addresses your concern. \n\n**Minor comments**\n\n1. We give the definition of measurable rectangles in the appendix on line 523. In future versions of this paper, we propose to move this definition to the main body in the camera-ready version. \n\n2. You are right. We propose to change this, so that we make it clear that only the $\\sigma$-algebra is in the form of a product, not the measure. Thank you very much for pointing this out - this is a great spot. \n\n3. Actually (2) is not a product of kernels, because $K_{S\\cup U}$ has the $\\omega_{S\\setminus U}$ component that does not get integrated with respect to the measure $L_{S\\cap U}(\\omega_{S\\cap U},\\cdot)$. In the appendix, Remark C.1(b) treats the special case in which the interventional kernel $K^{\\text{do}(U,\\mathbb{Q},\\mathbb{L})}_S$ is a product of kernels. \n\n**Questions**\n\nI'm guessing you mean something like [Cinlar, 2011, page 151, Theorem IV.2.7]? If so, yes, we agree that this is definitely an interesting question to answer in future research. Thank you very much for the suggestion, we really appreciate it! ""}}, {'rebuttal': {'value': 'Thank you for reviewing our submission. We regret that you have a rather negative view of the paper, and we hope that our clarifications below, as well as the other reviews, can give you a more positive view. \n\n**Definition 2.2**\n\nThis is the main definition of the paper, containing the two axioms of causal kernels. We regret that you were not convinced by these axioms of causal spaces. We\'ll do our best to address your concerns. \n\nFor a given $S$, of course there are many possible causal kernels $K_S$ that satisfy the two axioms, but in the end the causal space will have one $K_S$ specified. This is the same in SCMs, where, given a random variable (or a node), there are many possible functions that can act as the structural equation for this variable, but in the end the SCM will specify one function. Or even just in probability spaces, where of course there are many possible probability measures that satisfy the axioms of a probability measure, but a given probability space will have one measure specified. \n\nFor two subsets $S_1,S_2$ of $T$, there is a priori no relationship between $K_{S_1}$, $K_{S_2}$ and $K_{S_1\\cup S_2}$, and for full generality, this is desirable, since, even in the SCM framework, we can easily construct examples where specifying $K_{S_1}$ and $K_{S_2}$ does not fully determine $K_{S_1\\cup S_2}$. \n\nWe are not sure what you mean by the variables being independent in causal spaces, but it is easy to formulate a two-variable situation in the causal space framework with $X$ causing $Y$. This is precisely what was illustrated in Example 2.5. \n\n**Line 147**\n\nThe fact that we take this view on intervention is not a ""claim"", but the philosophy behind our definition of intervention, and it agrees with most other definitions of intervention in the literature, including the SCM case. We pick a subset of the variables on which we would like to intervene (most often a single variable), and we place a desired measure on those (that) variable(s) (for hard interventions, a Dirac measure). The causal components in the frameworks (the structural equations in SCMs, the causal kernels in our causal spaces) then determine what happens to what we did not intervene on. \n\nIn our causal space framework (and in any other framework), intervention is categorically not the same as conditioning - in fact this is the whole point of having any theory of causality. In examples throughout our submission, there are many instances in which intervention is not the same as conditioning, showing that our causal space framework accommodates this. For example, in Example 2.5, conditioning on temperature is not the same as intervening on temperature, and in Example 4.4 and Figure 5, conditioning on the Brownian motion to have a particular value at a particular time point is not the same as intervening on the Brownian motion to have a particular value at a particular time point. \n\nWe thank you again for your review, and we hope that our rebuttal, along with the opinions of the other reviewers, are sufficient to convince you at least of the validity of causal spaces, and if possible, their merits. Please let us know if you have further questions, or if any of our clarifications were unclear. '}}, {'rebuttal': {'value': 'Thank you for your time and effort in reviewing our submission; we are very grateful for your overall positive evaluation of the paper and your valuable suggestions. We will do our best below to address your concerns and queries. \n\n**Weaknesses**\n\nThank you for this point. We are aware that other theories of probability exist other than Kolmogorov\'s. Of those you mentioned, we are aware of de Finetti\'s approach, and are vaguely aware of Shafer/Vovk\'s game theoretic framework. We were not aware of Walley\'s work - thank you for pointing it out. There is also an approach more amenable to Bayesian probability ([Jaynes and Bretthorst, 2003], or https://en.wikipedia.org/wiki/Cox%27s_theorem). We acknowledge that these works are valuable, and we propose to make more of an effort to acknowledge them. We also propose to water down our language from ""near-undisputed and universally accepted"". However, we believe it is equally unreasonable to treat Kolmogorov\'s framework as simply one out of many on the same level of significance, given that the vast majority of research in probability theory, as well as the vast majority of textbooks and lecture courses on probability theory, is built on it. \n\nWe agree that the two axioms we provide are a priori mathematical properties that are not in themselves causal in nature. However, this is also true for probability spaces - they are simply measure spaces where the whole set happens to have measure 1. Same for densities - they are simply functions that happen to integrate to 1. Yet, we give these objects a probabilistic interpretation. Our axioms of causal kernels should be viewed in the same light.\n\nThank you for raising this point. We agree that in general identification is difficult, if not impossible, with such generality. However, we would like to point out that if measuring temperature is possible, and if it is in our interest to do so (for identification or any other reason), then our causal space framework accommodates that, so in this sense, nothing is ""lost"" compared to the SCM framework. We maintain that this is advantageous in the modelling perspective over SCMs, where the researcher is ""forced"" to include other variables that explain the correlation. For identification from data in our framework, Section D in the Appendix is dedicated to it, via a concept which we call ""sources"".\n\n**Questions**\n\nP6, 240-243: Uniqueness here is meant simply to contrast with SCMs, where, without the acyclicity assumption, there may be many distributions over the endogeneous variables that satisfy the structural equations and the noise variables (see, for example, [Bongers et al., 2021, Foundations of Structural Causal Models with Cycles and Latent Variables]). In causal spaces, the observational and interventional distributions are always uniquely defined.\n\nExample 4.2: Thank you for raising this point. Please see author rebuttal to all authors. \n\nP8, 318: For example, [Peters et al., 2017, Elements of Causal Inference, Remark 6.5]. We agree that we should give some citation here, and we propose to do so in future versions of this work. \n\nComputability: This is not a question that we had thought to address in this submission at all, but we agree that this is a crucial and interesting research direction. We are grateful to you for pointing it out.\n\nP9, 359-360: We agree that the ideas behind the two axioms we give are not inherently measure-theoretic, and that it would probably be possible to endow other frameworks (e.g. graphical models) with these concepts. However, as you point out, the way these axioms represent these concepts are measure-theoretic, since the transition kernels are very much measure-theoretic tools. \n\n**Suggestions**\n\nFigure 1: In terms of what is included in the outcome space, the parameters in Bayesian setting could also be viewed as ""data"". But we see the point you are trying to raise. What would be your suggestion for the left-hand box?\n\nThe focus of this work was not the philosophical discussions around causality on the level of a philosophy paper, which we hope you understand. However, we maintain that calling our proposal an ""axiomatisation"" is justified in the mathematical sense, in that we lay out what we assume to be true about causal spaces, and we build subsequent definitions and results on these axioms. This is precisely in the form of other ""axiomatic frameworks"" in mathematics, not least the probability axioms of Kolmogorov. Moreover, throughout the text we clearly state what philosophical approach behind causality we take, namely that we view it as a study of what happens when we intervene, and in Remark 2.4, we discuss precisely what our axioms encode, so we do not fully agree with your judgment that there is an ""absence of discussions about the philosohical concepts of causality and how these axioms encode them"". \n\nP3, L108-113: Thank you for this suggestion, yes, we agree that ""chain of trials"" is somewhat misleading. The terminology is taken from [Cinlar, 2011, Probability and Stochastics, page 161]. Of course, the mathematics $(E_t,\\mathcal{E}_t)$ allows for distinct variables even here. We propose to change it to ""set of trials"", would you agree that this is better?\n\nP5, L195-196: We would again like to draw parallels with probability spaces, where, of course, it is equally impossible to perfectly specify the probability measure in practice for any given problem, but we still do so in the modelling process. In the same vein, we feel it is justified to assume that for the causal kernels. We will make this point more explicit.\n\nWe thank you again for your positive review, and raising many interesting points. If accepted, your suggestions are sure to improve our paper. If any of our answers were unclear or we misunderstood your point, please let us know. We would be happy to engage in further discussions. '}}, {'summary': {'value': '(Preamble warning: given the amount and time I had to review Neurips papers, and given other duties, I focused solely on the main content of the paper, not consulting the appendices that were actually longer than the paper.) \n\nThe paper proposes and discusses a new framework, based on measure-theoretic probabilities, to encode causal systems, both on the observational and interventional level. \n\nThis is done through the use of probability kernels and probability measures defined over Cartesian products of spaces. The framework generalizes a number previously proposed frameworks,'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '* A unifying framework relying on measure-theoretic probabilities that is well-justified from a mathematical point of view, and can be summed up by two technical constraints on the system. \n\n* A quite well-written paper, with illustrative examples showing how the framework can be applied. '}, 'weaknesses': {'value': '* The authors make bold claims on probability theory: while it is quite okay to rely on measure-theoretic probabilities to derive a framework, I would argue that claiming that this view of probability is ""near-undisputed and universally accepted"" (P1, L24-25) and that ""In ... probability theory, one starts by assuming the existence of a probability space"" (P3, L101-102) is not true in the modern world. For instance and only to mention a few works, De Finetti betting accounts of probabilities allow for finitely additive probabilities, and does start by defining a probability space on a $\\sigma$-algebra. Similarly, Shafer/Vovk account of probabilities from a game-theoretic point of view does not start from a measure-theoretic view point. Finally, one could also argue that causality could be seen through the lense of other uncertainty theories, and that the unversality of probability theory could be challenged itself (see works of Peter Walley on imprecise probabilities extending De Finetti\'s betting argument, and works of followers). So even if I think that the adopted viewpoint here is reasonable, I would avoid suggesting that it is the only one that can be considered, or that it can hardly be questioned. \n\n* Sufficiency of the proposed axioms: the axioms are given as mathematical constraints over the system, and makes sense in a fully probabilistic setting (it is less clear if ones consider more expressive languages than probabilities). However, such kinds of axioms (unchange with respect to no new information + conformity with imposed constraints on the system) can also be found in other settings such as, e.g., Jeffrey\'s updating rule in the presence of uncertain information. I somehow miss a discussion of what makes those axioms peculiar to the situation of causalilty? Or does it follows from the assumptions that the probabilistic kernels DO model an exisiting cause rather than something else? And in this later case, one could imagine a situation where specified kernels do not encode actual causality relationships, while still following the proposed axioms. My feeling is that the axioms concern more mathematical properties ensuring that the system will behave well, rather than axioms ensuring that the encoded concepts and systems will indeed be causal in nature.\n\n* Not clear whether more generality gives a better means to identify causation: In Example 4.1. I appreciate the fact that the proposed model is much more flexible than SCM, however this example raises the question of knowing whether the system is not to general to be able to identify causalities? More precisely, assume we observe the S-I correlation, as well as measure the temperature. If we focus on the SI, we then have two models that perfectly explains the data: one with no causation and observed correlation, and one with causation (where one would have to specify the causation mechanisms). In contrast, SCM would not be able to account for S-I correlation without assuming causaition, and would incitate the modeller to add potential explaining causations. So it is unclear whether the provided generality comes with better capacities of identifying potential causations in practical modelling situations? \n '}, 'questions': {'value': 'Questions:\n\n*  P6, 240-243: what is meant by unique existence? Is it meant that a given observational/interventional system can only be represented by a unique set of measures and kernels? The exact meaning of uniqueness is unclear to me here.\n\n* In example 4.2., I agree that one variable can influence the other (in a causal way), but I would argue that we are also faced here with a dynamical process (rice production can only be impacted by price for the next period of rice harvesting, and vice-versa). Would it be possible to provide an example of cyclicity where we are not faced with time-evolving processes?\n\n* P8, L318: could you give some references to identify ""by some authors""?\n\n* Comutability: one question that arises from the presented framework (but is probably to be adressed in future work) is about the computability of the presented framework? Maybe it would be good to mention a few cases where this is achievable, if authors have already identified such cases. \n\n* P9, L359-360: it is not entirely clear to me how the proposed axiomatization and the measure-theoretic view of probabilities are linked in the proposed framework. To be more precise, my feeling is that the two proposed axioms of no action-no causation and of agreement witht he causal mechanisms are not especially linked to a measure-theoretic view, which offers the technical tools to derive it. For example: to which extent do we really need $\\sigma$-additive measures rather than finitely additive ones to express these two axioms? Of course the first option is technically/pragmatically more simple to deal with, but I am not completely convinced that this is at the heart of the expressed axioms.  \n\nSuggestions:\n\n* Figure 1: suggesting that probability theory is confined to modelling data-generating process is a bit misleading, as a Bayesian setting allows one to put probabilities on any quantity of interested (including those not generated by data). \n\n* Given this absence of discussions about the philosohical concepts of causality and how these axioms encode them, speaking of ""Axiomatization of causality"" seems a bit strong to me. Why not referring in the title to ""Generalised causal model through measure-theory""? \n\n* P3, L108-113: the vocabulary used here as well as the various differentiation made is a bit ambiguous: why speaking of ""chains of trials"" that make one think of repeated experiments when in all further examples all measurable spaces belong to distinct variables? \n\n* P5, L195-196: an underlying assumption here is that the causal kernels are 1. perfectly specified and 2. encode causal relationship. In practice, nothing prevents those two points to be false, and I think it should be mentioned somewhere that those assumptions are made. \n\n'}, 'limitations': {'value': 'Limitations were adequately adressed.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes a measure-theoretical axiomatization of causalality with the notion of causal space and with a collection of causal kernels encoding the causal information. '}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': 'The paper offers an axiomatization of causality which is based on the measure-theoretical foundation of probabaility theory. '}, 'weaknesses': {'value': '(1) It seems that Definiiton 2.2 is not well-defined because, given a subset S of T, we cannot decide the causal mechanism K_S. Also see my questions below. \n(2)  I really could not understand the claim (Line 147) that ""intervention is the process of placing any desired measure,... along with an internal causal mechanism ..."".   Then it seems that intervention can also be treated as conditioning. '}, 'questions': {'value': '(1) I am confused by Definition 2.2 (Causal space).    For a given S, the causal mechanism seems undecided: there are many causal mechanisms satisfying the two axioms.  For two subsets S1 and S2 of the T, What is the relationship among K_{S1}, K_{S2} and K_{S1\\cup S2}?\n(2) It seems that all varaibles are independent in Definition 2.2.   How can one formulate the relationship that variable X causes another variable Y in the causal spapce?'}, 'limitations': {'value': 'yes'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""The paper develops new foundations for causality based on the measure-theoretic foundations of probability pioneered by Kolmogorov. Interventions are formalized as transition kernels and it's shown that the new approach is more general than existing ones in a number of respects.""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper is clearly laid out, sound, and represents a noteworthy (and as far as I know, novel) attempt to do causality in terms of mathematical probability theory. I believe the most promising direction in terms of utility is in being able to handle continuous-time causal stochastic processes, which have so far resisted formalization; the approach here does not even rely on dynamical systems.'}, 'weaknesses': {'value': 'I raise some edits and additional citations below.'}, 'questions': {'value': '- Line 49: Why is there no citation to Ibeling & Icard\'s 2020 ""Probabilistic Reasoning across the Causal Hierarchy""? This paper was (one of the, if not the) first to axiomatize SCMs in a truly *probabilistic* setting. The references [18, 20] there are still only quasi-probabilistic. (Admittedly, the paper I suggest does enforce an acyclicity constraint, but it is no better or worse than the other two references in this regard.)\n- Line 296: Citation 20 probably should also be thrown in here.\n- Can the rice example be modeled within the space of SCMs that always have unique solutions? I can\'t see why not. In this particular case, although the framework here may be more natural, it may not add much that is substantive.\n- Example 4.2: notations K_1(3, x) and K_2(6, x) seem inconsistent with each other since the interventions are on different variables.\n- Can the authors comment on whether the framework given invalidates quintessential principles of SCMs, e.g., effectiveness, composition, and reversibility? I am guessing the answers are no (by interventional determinism, line 158), yes, yes. The broader point is that not only do SCMs require additional assumptions to be well-defined, but that these assumptions may also reverberate in causal reasoning.\n- Line 328: Z = {..., 2, 1, 0, 1, 2, ...} should read Z = {..., -2, -1, 0, 1, 2, ...}'}, 'limitations': {'value': 'Yes, they have.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents a completely novel mathematical description of causal systems, which generalizes the most well-known causal formalisms such as SCMs and potential outcomes. It does so by taking the probability distributions as the foundation, and use this to construct a measure-theoretic approach to causal systems. The result is a very expressive framework, that definitely has its place within the landscape of causal formalisms. \n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The paper is clearly written, but some background in probability theory is required to understand the technical definitions. There is substantial discussion of related work and open questions, illustrations of the framework, and comparisons to SCMs. Overall this is a great paper. \n'}, 'weaknesses': {'value': 'See questions.\n\nTypos:\n\n58: “we have designated” -> “we have a designated”\n\n81: “implications concepts” -> “implications for concepts”\n\n107: “the measurable space are” -> “the measurable space is”\n  '}, 'questions': {'value': 'I do have some conceptual comments about the motivation and supposed superiority of the framework. \n\n1: In your comparison with SCMs, you only consider hard interventions. What about soft interventions? \n\n2: Remark 3.2: \nI find this quite strange. Usually one thinks of an intervention not as an intervention on the system that affects a subsystem, but simply as an intervention on the subsystem itself, and this of course affects the system, just as changes to a part are also changes to a whole. I’m not saying the idea of a “holistic” intervention on an entire system is uninteresting, but merely that this is not usually how causal interventions are understood. In fact, the independent mechanism assumption made by Woodward and taken over by others captures a fundamental modularity that is assumed to hold for causal relations. \n\nSimilarly, the idea of coupling the observational and the interventional distributions is a feature, not a bug: it encodes an assumption about how we take the world to work. \n\nIn sum, although I agree that it is interesting to decouple these distributions and to view interventions as “system-wide”, as your formalism does, I am not sure when and why we would ever want to do so: at heart, the motivation for your framework seems to come with a philosophical theory that is lurking in the background which appears in conflict with the standard interventionist theory of Woodward that causal modellers usually align with. I realize that it would be too much for one paper to introduce both such a rich framework and dive into a philosophical analysis, but my suggestion would then be to here remain more neutral regarding these commitments. \n\n3: footnote 1: do you think your framework is strictly more expressive than GSEMS? They don’t use probabilities, but perhaps you could reconstruct GSEMS by giving positive support to all values, and reasoning about P > 0?\n\n4: Confounders. \nI’m not sure if the authors are aware, but the philosopher Nancy Cartwright has famously argued against the Causal Markov Condition by using a very similar example, the so-called chemical factory. In her case though, she goes even further, stipulating that there is no common cause, not even an unobserved one. If one accepts her stipulation, then CBNs seem indeed unable to express such situations, whereas your framework would have no trouble with it at all. So it might be useful to refer to this discussion. For what it’s worth, the usual reply is similar to the move that you here discuss: simply add a “fictional” exogenous variable that functions as a latent common cause. \n\nThis brings me to footnote 2: I do not agree that such a variable is “completely meaningless”. It simply captures our ignorance. As long as one is committed to the Causal Markov Condition, one is committed to the belief that such a latent variable must exist. Whether we call it one variable or several variables collapsed into one seems merely a matter of terminology.\n\n5: “Of course, cycling relationships abound in the real world.” \nReally? That is quite a controversial claim: do the authors then subscribe to backwards causation? I’d say that cyclic models are useful abstractions of what in the end are non-cyclic systems. Your example is a case in point: it’s not the current price which causes the current amount of rice, and vice versa, it’s the price right now that determines the future amount. \n\nMoreover, although I’m sure the authors are right that SCMs have trouble in representing certain cyclic cases, is this really one of them? It doesn’t seem so hard to model this with an SCM. \n'}, 'limitations': {'value': 'yes'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper builds a rigorous foundation for causal reasoning. It does so by defining causal space, an extension of the concept of probability space by adding stochastic kernels. This richer structure allows the authors to define notions like interventions and causal effects, and generalize the standard frameworks like structural causal models.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""It is easy to take for granted the advantages provided by the measure-theoretic foundations of probability theory, but it is undeniable that Kolmogorov's insight to do so put probability theory in a respectable position and more importantly allowed for rapid progress on otherwise impossibly difficult problems related to stochastic process by Doob and others. No doubt this axiomatization did not happen without resistance, and many early probabilists considered it an offense to probabilistic intuition.\n\nThis paper is a valiant attempt at axiomatization of causal reasoning, and in my opinion it has a done a fairly good job. The idea of using stochastic kernels to enrich the underlying probabilistic structure for the much more difficult (than plain statistics) problem of causal reasoning is very natural while at the same time difficult to effectuate. The authors do a great job defining all the relevant terms and being rigorous in their treatment.""}, 'weaknesses': {'value': 'The authors do a lackluster job in providing enough motivation and examples, and discussing potential alternative axiomatizations. A first read of the paper gives an impression of pulling the definitions ""out of the hat"". This is unfortunate since it is important to encourage as many readers as possible to think in this direction and incorporate it in their research.\n\nOn lines 137-138, it is stated that ""$K_S(\\omega, A) = K_S((\\omega_S, \\omega_{T \\setminus S}), A)$ for any $A \\in \\mathcal{H}$ only depends on the first $\\omega_S$ component of $\\omega$"". I don\'t think it is true (if it is indeed true, please provide a proof). For example, let $T = \\\\{1,2\\\\}, S = \\\\{1\\\\}, E_1 = E_2 = \\\\{0,1\\\\}$ and $\\mathcal{E}_1 = \\mathcal{E}_2 = \\mathcal{P}(\\\\{0,1\\\\})$. Then $\\Omega = E_1 \\times E_2$ and $\\mathcal{H} = \\mathcal{E}_1 \\otimes \\mathcal{E}_2 = \\mathcal{P}(\\Omega)$. Now we could define $K_S$ in such a manner that it depends on the second component of $\\omega \\in \\Omega$. Say:\n$$\nK(\\omega, A) = \\begin{cases}\n0 &\\text{if } \\omega = (0,0), A = \\\\{(0,0)\\\\}\\\\\\\\\n1 &\\text{if } \\omega = (0,1), A = \\\\{(0,0)\\\\}\\\\\\\\\n\\vdots\n\\end{cases}\n$$\n\nA few minor nitpickings:\n1. In section 2, where $\\mathcal{H}_S$ is defined it will be clearer to remind what measurable rectangles are, since it is implicitly being used that for measurable rectangles $A_t$ differs from $\\mathcal{E}_t$ for only finite $t$\'s.\n2. In definition 2.2, it is misleading to say ""(product) probability space"". The word ""product"" when talking about measurable spaces (as opposed to _measure_ spaces) has a connotation of product measures, which is not the case here.\n3. I find the notation in equation (2) confusing. It might be helpful to also say that the kernel $K_S^{\\text{do}(U, \\mathbb Q, \\mathbb L)}$ is simply the product $L_{S \\cap U} K_{S \\cup U}$ of stochastic kernels (as defined by Çinlar on page 39).'}, 'questions': {'value': 'While understanding the definition of causal space, a natural question of what are some sufficient conditions for its existence arises (similar in spirit to the sufficient conditions for the existence of regular conditional distributions). It would be nice to explore this question.'}, 'limitations': {'value': 'Not relevant.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'A Measure-Theoretic Axiomatisation of Causality'}, 'authors': {'value': ['Junhyung Park', 'Simon Buchholz', 'Bernhard Schölkopf', 'Krikamol Muandet']}, 'authorids': {'value': ['~Junhyung_Park1', '~Simon_Buchholz1', '~Bernhard_Schölkopf1', '~Krikamol_Muandet1']}, 'keywords': {'value': ['Causality', 'probability theory', 'causal models']}, 'TLDR': {'value': 'We propose causal spaces, a measure-theoretic axiomatisation of causality.'}, 'abstract': {'value': ""Causality is a central concept in a wide range of research areas, yet there is still no universally agreed axiomatisation of causality. We view causality both as an extension of probability theory and as a study of what happens when one intervenes on a system, and argue in favour of taking Kolmogorov's measure-theoretic axiomatisation of probability as the starting point towards an axiomatisation of causality. To that end, we propose the notion of a causal space, consisting of a probability space along with a collection of transition probability kernels, called causal kernels, that encode the causal information of the space. Our proposed framework is not only rigorously grounded in measure theory, but it also sheds light on long-standing limitations of existing frameworks including, for example, cycles, latent variables and stochastic processes.""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/bb913c5a58f18a26e4513699cbdb6ee9be32a76c.pdf'}, 'supplementary_material': {'value': '/attachment/487f39f59dd098b2244d532c3e84b0aaf9a63216.pdf'}, '_bibtex': {'value': '@inproceedings{\npark2023a,\ntitle={A Measure-Theoretic Axiomatisation of Causality},\nauthor={Junhyung Park and Simon Buchholz and Bernhard Sch{\\""o}lkopf and Krikamol Muandet},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=sPLTQSf6GI}\n}'}, 'paperhash': {'value': 'park|a_measuretheoretic_axiomatisation_of_causality'}}]"
"['Zijiao Chen', 'Jiaxin Qing', 'Juan Helen Zhou']",NeurIPS,Cinematic Mindscapes_ High-quality Video Reconstruction from Brain Activity,https://neurips.cc/virtual/2023/oral/73833,2023," Reconstructing human vision from brain activities has been an appealing task that helps to understand our cognitive process. Even though recent research has seen great success in reconstructing static images from non-invasive brain recordings, work on recovering continuous visual experiences in the form of videos is limited. In this work, we propose Mind-Video that learns spatiotemporal information from continuous fMRI data of the cerebral cortex progressively through masked brain modeling, multimodal contrastive learning with spatiotemporal attention, and co-training with an augmented Stable Diffusion model that incorporates network temporal inflation. We show that high-quality videos of arbitrary frame rates can be reconstructed with Mind-Video using adversarial guidance. The recovered videos were evaluated with various semantic and pixel-level metrics. We achieved an average accuracy of 85% in semantic classification tasks and 0.19 in structural similarity index (SSIM), outperforming the previous state-of-the-art by 45%. We also show that our model is biologically plausible and interpretable, reflecting established physiological processes.",Oral 3A Neuro,https://openreview.net/pdf?id=i913TUOvTK,https://openreview.net/forum?id=i913TUOvTK,i913TUOvTK,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The paper has received positive feedback from the reviewers. There were some concerns that were addressed by the rebuttal. this paper presents a great contribution to the field of computational neuroscience. The authors are encouraged to address the comments in their final paper.'}}, {'comment': {'value': 'Many thanks again for your support! We sincerely appreciate your valuable comments and your precious time and efforts in reviewing our paper!'}}, {'title': {'value': 'Final remarks'}, 'comment': {'value': 'I appreciate your prompt and comprehensive response to my review of your paper. Your detailed answers have better explained various aspects of the paper, and I find them very useful to better understand the approach and direction of the paper.\n\nYour explanation of the challenges in scene reconstruction and activity pattern capture are insightful and aligns with my observations. I appreciate your acknowledgment of this limitation and your plans to address it in future research.\n\nIn regard to the ""Paired fMRI-Video dataset"" limitation, I understand the constraints imposed by the availability of suitable datasets. Your willingness to acknowledge this limitation and incorporate the importance of model generalization in future research revisions is a step in the right direction. I agree that well-designed brain recording experiments and methodological development are necessary to enhance generalization and interpretability.\n\nOnce again, I would like to express my appreciation for your responses to my comments. Your willingness to engage in discussions reflects your dedication to advancing your research and addressing the concerns of the reviewers. I am confident that your efforts will contribute positively to the field of deep learning in medical applications.'}}, {'comment': {'value': 'Thanks again for your time and efforts. We really appreciate your support!'}}, {'comment': {'value': 'Thank you for the updates, responses and further evaluations. My current rating remains valid. '}}, {'comment': {'value': 'Thank you for the additional answer, this has addressed my remaining concern.'}}, {'comment': {'value': 'Many thanks for your support! We truly appreciate your precious time and valuable suggestions.'}}, {'comment': {'value': 'Many thanks for your support! We truly appreciate your precious time and valuable suggestions.'}}, {'title': {'value': ""Response to the Revewer's Comment""}, 'comment': {'value': 'Thanks for your reply! We agree and understand your concern. We discussed the failure cases in the supplementary material of our original submission. In the revision, we will include more failure cases and add a clear notation for the failure cases in the discussion of the results. We will also discuss the failure cases in the limitation section to give a clearer overview and explanation for the failure cases.\n\nIn short, the failure cases can be attributed into two categories.\n\n1. Lack of pixel-level controllability. Due to the probabilistic nature of the diffusion model and the current conditioning method, the generation process lacks strong control from the fMRI latent to generate strictly matching low-level features, such as shapes, color, and geometric information. We believe this would be an important perspective for future research on this task. \n\n2. Uncontrollable factors during the scan. Mind wandering and imagination of the subject are usually inevitable during the scan. It has been shown that imagination is involved and can be decoded to some extent from the visual cortex [4], which can lead to mismatching between the ground truth and the generation results.  \n\nWe would also like to highlight that the quantitative evaluation across all samples reported in our original submission is compared with the reported results from the literature. We also compare with Kupershmidt, 2022 [12] and Wen, 2018 [10] using their released videos (partial testing set), as shown in the table below. We achieved better numeric results in these comparisons. \n\nThanks again for the suggestions, which enhanced the quality of our manuscript! We hope this reply has addressed your concern. \n\n\n|                                            | 50-Way, Top-1 Accuracy     | 50-Way, Top-1 Accuracy   |          \n|------------------------------------ |-------------------------------------|------------------------------------|\n|                                            | Image Identification Tests    | Video Identification Tests | \n| Ours                                   | **0.195 +- 0.016**                | **0.265 +- 0.02**              | \n| Kupershmidt, 2022             | 0.179 +- 0.017                     | 0.238 +- 0.02                    | \n| Wen, 2018                          | 0.07 +- 0.01                         | 0.166 +- 0.016                  | \n\n[4] G. Shen, T. Horikawa, K. Majima, and Y. Kamitani, “Deep image reconstruction from human brain activity,” PLoS computational biology, vol. 15, no. 1, p. e1006633, 2019\n\n[10] H. Wen, J. Shi, Y. Zhang, K.-H. Lu, J. Cao, and Z. Liu, “Neural encoding and decoding with deep learning for dynamic natural vision,” Cerebral cortex, vol. 28, no. 12, pp. 4136–4160, 2018\n\n[12] G. Kupershmidt, R. Beliy, G. Gaziv, and M. Irani, “A penny for your (visual) thoughts: Self-supervised reconstruction of natural movies from brain activity,” arXiv preprint arXiv:2206.03544, 2022\n'}}, {'comment': {'value': 'Thank you to the authors for the additional ablations and for the clarifications.\n\nThank you also for providing the generated videos. I looked through many of them and while there are clear success cases where the generation looks a lot like the stimuli, there are also many examples where the generation appears unrelated to the ground truth category. In some rarer cases the generation even looks like noise or is devoid of any clear semantics. I am concerned that the current figures in the manuscript (Fig. 1, 4 and 5) along with the description of the results and the discussion do not clearly mention or show examples of these failure cases.\n\nAs the approach is novel and the results offer a strong baseline for further work on this topic I keep my current score. However I believe the manuscript should reflect more transparently what a significant portion of the generated videos look like.'}}, {'comment': {'value': 'Thanks for the author\'s elaborate response, and all my concerns have been well addressed. So I raise my rating as ""Weak Accept"".'}}, {'comment': {'value': 'Thanks for the clarification, and it has addressed all my concerns. I will raise my rating.'}}, {'title': {'value': 'Link to Video Files'}, 'comment': {'value': 'Thanks for the time and efforts from the reviewers, ACs, and SACs again. \n\nAs requested by Reviewer tnAn, the link to our **full generated videos** is listed below. As Reviewer tnAn asked for full samples, the link is an anonymous link containing 1.6GB data (~3600 gif files). \n\nhttps://figshare.com/s/5b596aeb6beebd32d2d1\n\nMany thanks again!'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the recognition of our contribution and the invaluable and constructive comments. Our point-by-point response is provided as follows. \n\n> 1. In Figure 4, we can see that Wen (2018) could reconstruct the shape and Kupershmit (2022) could reconstruct the texture. While videos generated by MinD-Video lack shape and texture. So I think previous works could affect more on the Video Generation part of MinD-Video.\n\n**Response:** Thank you for this insightful comment. Pixel level and semantic level decodings recover visual stimuli from two different perspectives, where the trade-off between fidelity and meaningfulness needs to be considered. In this work, **we prioritize the recovery of visual semantics** in fMRI, which is crucial for understanding the complex mechanism of human perception. \n\n**We recognize the significance of pixel and texture level information**, which contributes to generating visually closer results to the ground truth. For instance, leveraging results from previous methods could serve as a valuable guidance or initial starting point for our generative process.\n\nNonetheless, our aim is to establish a foundation for future research that integrates both pixel-level features and visual semantics in this particular task. By doing so, we anticipate that future studies can further refine and enhance the decoding process, leading to even more comprehensive and accurate outcomes.\n\n\n> 2. The quantitative results are not sufficient. The metric values are not compared with other methods, and the gap between some experimental settings is limited.\n\n**Response:** We thank the reviewer for the constructive suggestion. **Limited by the publicly available video samples and codes** for reproduction in the literature, we had some difficulties in comparing numerically with other methods. In the previous literature, Kupershmidt, 2022 [12] and Wen, 2018 [10] **have only released part of their reconstructed videos**. Also, because their released videos are **basead on different frame rates from ours** (1Hz in [12], 0.5Hz in [10], 3Hz in ours), we did not perform the identification tests on those videos, which might not be a fair comparison. Instead, we relied on **a commonly available metric reported in their papers**, SSIM.  This metric was calculated quantitatively **across all testing samples** according to their papers. We did the same for our approach in the original paper. \n\nNevertheless, as recommended, we have now decided to perform the identification test on those **incomplete samples** only (released by previous work) and compare the results across different methods (including ours). Please see the table below. Our method outperformed the two previous methods in identification test accuracy. We will include these results and  **possible limitations in the revised manuscript**. \n\n|                                            | 50-Way, Top-1 Accuracy     | 50-Way, Top-1 Accuracy   |          \n|------------------------------------ |-------------------------------------|------------------------------------|\n|                                            | Image Identification Tests    | Video Identification Tests | \n| Ours                                   | **0.195 +- 0.016**                | **0.265 +- 0.02**              | \n| Kupershmidt, 2022             | 0.179 +- 0.017                     | 0.238 +- 0.02                    | \n| Wen, 2018                          | 0.07 +- 0.01                         | 0.166 +- 0.016                  | \n\nIn order to strengthen our experimental settings, we performed extra ablation studies on different components of our designs on top of the existing ablation experiments. The first experiment involves **excluding the MBM pre-training**, while the second experiment **removes both the MBM pre-training and the contrastive training** from the proposed method. As shown in the table below, both the MBM pre-training and the contrastive training are critical to getting the best results, and removing any of them will incur a significant drop in performance.\n\n\n\n|                                            | 50-Way, Top-1 Accuracy     | 50-Way, Top-1 Accuracy   |          |\n|-------------------------------------|-------------------------------------|------------------------------------|---------|\n|                                            | Image Identification Tests    | Video Identification Tests | SSIM |\n| Full Model                          | **0.172 +- 0.01**                  | **0.202 +- 0.02**              | **0.171** |\n| w/o MBM, w/ Contrastive   | 0.122 +- 0.012                     | 0.169 +- 0.015                  | 0.143 |\n| w/o MBM, w/o Contrastive | 0.076 +- 0.008                     | 0.138 +- 0.013                  | 0.123 |\n\n> 3. Do you think the Video Generation part should have controllability? I mean the current Video Generation part has no ability to reconstruct a video that is the same as source video, which would be the upper bound of the overall performance.\n\n**Response:**  Thank you for your useful comment. Indeed, we agree that incorporating some form of controllability in the Video Generation part of our model could enhance the reconstruction of low-level image features like shape, texture, and location, bringing us closer to the source video. In fact, we believe that **controllability is a critical feature** for this kind of research, which is worth further research. We will include this part as future work in our revision.'}}, {'rebuttal': {'value': ""We thank the reviewer for your time and effort in reviewing our work. We also appreciate your interest in our work and the useful suggestions. Our point-by-point responses are as follows. \n\n> 1. the novelty of this work is limited with respect to diffusion model field.\n> 2. The proposed method is of limited novelty.\n\n**Response:** We would like to take this opportunity to emphasize that though our method builds upon the established techniques, the novelty of our work is not in implementing these techniques per se. Instead, it lies in applying these techniques in a new and challenging domain: learning dynamic brain activities and reconstructing visual stimuli from the brain. Our work is at the intersection of neuroscience and CV, where the focus is not solely on inventing new tricks or structures for the diffusion model. Instead, **the main aim is to tackle the unique challenges of fMRI** and make proper methodological adjustments to adapt state-of-the-art generative models to our specific task. This has been recognized by the other four reviewers. \n\nThanks for providing the additional reference. However, [1] provided a learning method for **scene graphs**, which is **an entirely different modality** from fMRI or any other brain recordings. Even though our method shares a similar philosophy with [1], this does not negate the novelty of our work. **The specific way of problem formulation, data modeling, and problem-solving is also an essential part of research novelty. Besides, the masking, contrastive, and generative objectives are standard techniques in representation learning.**\n\nFurthermore, we would like to highlight a few key differences. \n- We learn features of **dynamic fMRI with masking**, while [1] learns a **static scene graph without masking**. \n- Our work focuses on learning the **biological features** of fMRI, whereas [1] aims to learn the **geometric information** in the scene graph. \n- We must consider the **hemodynamic response**, a unique challenge when matching dynamic fMRI to videos. In contrast, the scene graph in [1] is static and matched to a static image. \n- We used a **3-modality** contrast among fMRI, video, and text to create a shared multi-modality space. While [1] used a **2-modality** contrast between scene graphs and images to discriminate a binary objective. \n\nIn summary, while our method shares high-level similarities with [1] in terms of using generative and contrastive objectives, the comparison should not overlook the **different modalities and unique challenges** each work addresses. [1] deals with scene graphs, a static graphical structure, using an off-the-shelf graph encoder. Our work handles fMRI, a dynamic and biologically complex modality. Our problems involve understanding dynamic data subject to hemodynamic responses and the biological interplay of various brain regions - a quite different beast. \n\nWe hope our work can encourage more research in this field and lead to more novel development in methods and applications. We are confident that with further reflection, the value of our approach will become more apparent.\n\n> 3. two many tricks. no central point \n\n**Response:** We apologize for the confusion. To clarify, all our modules and tricks are **summarized and depicted graphically** in Figure 2. Critical modules and methods are **color-coded and represented by different shapes** in Figure 2. Our technical contributions are summarized on Page 2 of our paper with **5 bullet points**, each containing two short sentences. As suggested, we will revise the paper to make our contributions and method descriptions clearer to improve readability.\n\n> 4. I have reproduced the method, the results seem not as good\n\n**Response:** We thank the reviewer for strong interest in our work and his/her effort to try to reproduce our findings. We are thrilled to see the level of engagement our work has elicited. To clarify, we assure you that we have presented a representative range of qualitative results of the generated videos in our paper. More importantly, we also evaluated the performance based on quantitative metrics and compared with other methods as presented in the original paper. Given this doubt from the reviewer, we have now included full generation samples in the ”Official Comment”.\n\nIt would be great to know if such quantitative evaluations have been reproduced using the same data following the same process. It is worth noting that differences in outcomes could be due to various factors, including whether we are working with full samples or subsamples, data processing approaches, parameter settings, or the specific pretrain checkpoints used. \nOur codes will be made publicly available upon publication to ensure a fair reproduction for the community. \n\nRegarding the style inconsistency, we suspect the reviewer's concern is related to the visually distinct outcomes of generated results for sample inputs at each sampling. We acknowledge that this is a typical characteristic of the probabilistic nature inherent in the diffusion model, which represents one of the limitations of the diffusion-based decoding approach. However, despite these variations, **the semantic contents and evaluation metrics of the generated results remain consistent, as demonstrated in our paper**.""}}, {'rebuttal': {'value': 'We are very grateful for your appreciation of the novelty and potential impact of our work and your important suggestions.  Our point-by-point responses are as follows.\n\n> 1. What is the impact of the masked modelling pretraining? \n\n**Response:** We thank the reviewer for raising this important point. We have now conducted additional ablation studies to thoroughly examine the impact of Masked Brain Modeling (MBM) in our approach. Specifically, we performed two experiments:\n\n1. We conducted an experiment where we **excluded the MBM pre-training** from our proposed model.\n2. We performed another experiment where **both the MBM pre-training and contrastive training were excluded** from our proposed model.\n\nFor evaluation, we employed 50-way, top-1 identification tests, as detailed in the paper, along with Structural Similarity Index (SSIM) metrics. The results are tabulated below.   \n\n| | 50-Way, Top-1 Accuracy| 50-Way, Top-1 Accuracy   |  |\n|-|-|-|-|\n|  | Image Identification Tests    | Video Identification Tests | SSIM |\n| Full Model | **0.172 +- 0.01**                  | **0.202 +- 0.02** | **0.171**|\n| w/o MBM, w/ Contrastive   | 0.122 +- 0.012| 0.169 +- 0.015 | 0.143 |\n| w/o MBM, w/o Contrastive | 0.076 +- 0.008| 0.138 +- 0.013 | 0.123 |\n\nAs you can see from the Table, we observed a significant drop in performance when excluding MBM from our model, and this drop further intensified when both MBM and contrastive learning were excluded. Moreover, the visual quality of the generated results aligned well with these quantitative metrics. We will include both in our revised submission. \n\n> 2. I do not fully understand the idea behind the ""network inflation trick"" mentioned at line 157. \n\n**Response:** The batch here consists of **consecutive fMRI frames from a sliding time window**. The network inflation trick is a technique that enables the model to process an extra dimension by rearranging the input data shapes. For example, the transformer designed in previous work [6] for image reconstructions can only take input with 3 dimensions: n, p, and b, where n is the batch size and the last two dimensions will be used in the attention calculation in the transformer. Now we want to add an extra time dimension without changing the structure of the transformer such that the pre-trained weights provided in [6] can still be used. So to handle an input of shape (n, w, p, b), where w is the extra time dimension (sliding time window size), we can just merge two dimensions of the input into either (nw, p, b) or (np, w, b). When the dimension becomes (nw, p, b), the attention layer in the transformer is learning spatial correlations of the input, thus called spatial attention. When the dimension becomes (np, w, b), it learns the temporal correlations, thus called temporal attention. Combining spatial attention and temporal attention enables our model to learn spatial and temporal information from consecutive fMRI frames.  \n\n\n> 3. I found the description of the inputs at the contrastive learning stage unclear (Q3).\n\n**Response:** We apologize for the confusion. The input to the fMRI encoder at the contrastive learning stage is **a sliding time window of fMRI, i.e., multiple fMRI frames, which are matched to a video clip**. We will provide more details in our response to the next question. The output of the fMRI encoder is an embedding that is learned by considering both the spatial and the temporal features of the fMRI frames. We will revise our manuscript to make this point clearer.  \n\n\n> 4. Question 4\n\n**Response:** We apologize again for the confusion. In line 231 of our paper, we are meant to say each fMRI frame corresponds to 2 seconds of video, as the TR of fMRI scanning is 2 seconds. However, considering the nature of hemodynamic response function of the human brain, a 2-second video may be encoded by fMRI frames at both t and t+1. Therefore, we create a sliding time window that groups multiple consecutive fMRI frames, which is used as input to the fMRI encoder. For example, consider a consecutive fMRI and videos represented by [f1, f2, f3, f4] and [v1, v2, v3, v4]. Assuming a window size of 2, we will use [(f1, f2, v1), (f2, f3, v2), (f3, f4, v3) … ] as the (fMRIs, video) pairs for training and testing. As we can see, the input to our pipeline is actually consecutive fMRI frames from a sliding time window. For consecutive fMRI-based sliding windows, the decoding results will be highly similar if they are matched to a similar groundtruth. However, there could be some style inconsistency between consecutive fMRI windows due to the probabilistic nature of the diffusion model, which we believe could be better improved in future research.   \n\nAnother clarification is that we only reconstructed a 2-second video each time because of memory limitation of our GPU. Longer video generation requires larger GPU memory. Nevertheless, thanks to the sliding time window design, we can theoretically expand our approach and reconstruct longer videos with a larger fMRI window size with enough GPU memory. \n\n> 5. Results of Table 1 show that removing adversarial guidance has a very mild effect.\n\n**Response:** To clarify, without adversarial guidance, most generated videos are visually worse than our full method. In Table 1, it does drop from 0.172 to 0.117 in frame-based semantic level metrics and from 0.171 to 0.152  in the SSIM. However, even though the results are visually worse, **some low-level features are still generated**, such as animal-like moving objects, blue burry water-like objects, etc, with matching motions, which can still be classified into a correct semantic category in the metrics. Overall, adversarial guidance is still helpful. '}}, {'rebuttal': {'value': 'We thank you for the strong support and the positive comments on our work. Your inspiring questions and comments are valuable for our future work. Our point-by-point responses are as follows. \n\n> 1. The work is very interesting, the resulting video resembles the ground true in terms of activity, but in terms of scene there is still a considerable difference.\n\n**Response:**  We appreciate the useful feedback on the generated videos. We agree that while our model captures activity patterns well, scene reconstruction still presents challenges. This stems from the significantly **lower signal-to-noise ratio and increased complexities in the spatial-temporal dynamics** in the paired fMRI-video data compared to the paired fMRI-image data. Furthermore, there is higher inherent variability in **individuals\' imaginations due to the dynamic nature of videos (in contrast to static images)**. In the proposed model, we focused more on the video semantic recovery than the low-level visual features. We are aligned with the reviewer that this limitation should be addressed in future research. \n\n> 2. In the ""Paired fMRI-Video dataset"" part, only three subjects are used, this is a limitation in terms of generalization. It is a limitation, but it would be interesting to use more subjects and have more generalizable results. Nevertheless, it is ahead of several previous works.\n\n**Response:** We appreciate the reviewer sharing his/her valuable perspective on this work.  **We totally agree that utilizing more subjects can help evaluate and potentially enhance the generalizability of our method.** Unfortunately, this is subject to the availability of suitable fMRI-video datasets currently. This is a common problem for this type of neuroscience application. We will acknowledge cross-subject model generalization as a crucial **future work direction** in the revised manuscript. More work is needed to perform well-designed brain recording experiments and methodological development to increase the generalizability and interpretability.  '}}, {'rebuttal': {'value': 'We truly appreciate your recognition of our contributions and novelty.  Our point-by-point responses to the comments are as follows.  \n\n> 1. The differentiating factors between the current work and [6] is better be highlighted.\n\n**Response:** We thank the reviewer for this important point. Our work extends beyond [6] by tackling the fMRI-based video reconstruction problem. Unlike image reconstruction, this adds another level of complexity. The key differences can be summarized in the following. We will revise our paper to highlight this point.\n\n- **Problem formulation**. In [6], dynamic fMRI recordings are averaged to create a “snapshot”. While in this work, **dynamic fMRI time-series** is directly used to recover a video, which requires considering the **spatial features** and the **temporal features** of fMRI. Additionally, the **hemodynamic response** is a significant challenge in our work, making the one-to-one mapping between fMRI and video even more difficult. \n\n- **Architecture**. To address the unique challenges, we made two key improvements. First, we enhanced the fMRI encoder to handle a sliding time window of fMRI, capturing spatial and temporal information with distinct attention heads. Second, we employed **multimodal contrastive learning** to align fMRI with the semantic space of text and images before the co-training. This contrasts [6] in which co-training was performed directly without contrastive learning. \n\n\n> 2. Usage of the ""testing"" set in the training process is not the best design.\n\n**Response:** To clarify, the adversarial guidance was only used in the **inference stage (testing)** to create a stronger condition and to increase the signal-to-noise ratio of the testing fMRI dataset. The averaged testing fMRI data was not involved in any part of the training process. \n\n> 3. Given the complexity of the architecture, the ablation study could have been improved.\n\n**Response:** As recommended, we have now conducted additional ablation studies to examine the impact of two crucial components in our approach: masked brain modeling (MBM) pre-training and contrastive training.\n\nWe performed two new experiments on top of the existing ablation experiments in the table below. The first experiment involves **excluding the MBM pre-training**, while the second experiment **removes both the MBM pre-training and the contrastive training** from the proposed method.\n\nThe results show the importance of MBM and contrastive training for all metrics. The performance drops as much as 55% without both components and 30% without only MBM. The visual quality of the generated videos also follows a similar trend, which will be detailed in our revised manuscript.\n\nAgain, we sincerely appreciate your comment. These additional experiments strengthen the empirical evidence supporting our proposed approach.  \n\n| | 50-Way, Top-1 Accuracy| 50-Way, Top-1 Accuracy| |\n|-|-|-|-|\n| | Image Identification Tests| Video Identification Tests | SSIM |\n| Full Model| **0.172 +- 0.01**| **0.202 +- 0.02**| **0.171**|\n| w/o MBM, w/ Contrastive   | 0.122 +- 0.012| 0.169 +- 0.015| 0.143 |\n| w/o MBM, w/o Contrastive | 0.076 +- 0.008| 0.138 +- 0.013| 0.123 |\n\n> 4.  Assuming the trainable modules require re-training per subject, the proposed design raises concerns around practicality.\n\n**Response:** We acknowledge the practical concern regarding per-subject re-training process. But it is worth noting that almost all the existing methods for this specific neuroscience application, i.e., “brain decoding”, rely on per-subject training due to high inter-subject variability and limited datasets. Cross-subject model generalization remains an **open problem** and an exciting **future work direction** of our group and others.\n\n> 5. What does the ""augmented encoder"" refer to in this context?\n\n**Response:** The fMRI encoder in [6] can only process a single fMRI frame without considering the temporal dynamics of the fMRI recordings (i.e., multiple frames). We changed its architecture to **encode multiple fMRI frames in a sliding time window manner**, considering **spatial and temporal correlations** during feature learning. Thus, it is called an “augmented encoder”.\n\n> 6. How impactful was the addition of ""Then"" keyword in-between the two captions? \n\n**Response**:  We apologize for the confusion. To clarify, ""Then"" concatenation was only used in the augmented stable diffusion training (not the contrastive learning). This stage does not impact the fMRI feature learning process significantly, thus having **minimal influence on the final results**. To improve clarity, we will relocate the captions of the concatenation part to the stable diffusion training subsection in our revision. \n\n> 7. We wonder if the authors monitored attention-maps across transition frames?\n\n**Response:** Yes, we did monitor attention maps across transition frames. However, we **did not observe** that the attention to the previous frames noticeably dissipated during the transitions, which led to frames containing parts of the content from the two scenes. \n\nThis can be attributed to the nature of our generated videos: they span only 2 seconds, mirroring the 2-second TR of the fMRI. Given this brief duration, distinguishing between transition and non-transition frames becomes inherently challenging. However, the scene-changing decoding is an exciting question and an unexplored field worth further research. \n\n> 8. Do all trainable models require re-training for each subject?\n> 9. it is not clear whether the training process was repeated for each subject independently.\n\n**Response:** No. The most resource-consuming part is the large-scale pretraining of the MBM encoder, which **does not require re-training** for each subject. But we do **need to finetune** both the MBM Encoder and the generative model using each subject\'s fMRI. However, this process is **not computationally expensive**. We will make this part clearer in the revision.'}}, {'rebuttal': {'value': 'We are grateful to all five reviewers and AC/SACs for their valuable time, insightful comments, and useful suggestions. We will carefully revise our paper according to the comments. Our point-by-point response to the reviewers’ comments has been added to the individual chat box for each reviewer. We believe that the revised manuscript has been enhanced and the concerns have been well addressed. \n\nDue to the character limitation, citations mentioned in the rebuttal are included below. \n\n[1] Yang L, Huang Z, Song Y, et al. Diffusion-based scene graph to image generation with masked contrastive pre-training[J]. arXiv preprint arXiv:2211.11138, 2022.\n\n[2] Wu J Z, Ge Y, Wang X, et al. Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation[J]. arXiv preprint arXiv:2212.11565, 2022.\n\n[3] Rombach R, Blattmann A, Lorenz D, et al. High-resolution image synthesis with latent diffusion models[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022: 10684-10695.\n\n[6] Z. Chen, J. Qing, T. Xiang, W. L. Yue, and J. H. Zhou, “Seeing beyond the brain: Masked modeling conditioned diffusion model for human vision decoding,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023.\n'}}, {'summary': {'value': 'The authors have developed an fMRI to video model trained using contrastive learning and stable diffusion. The generted videos are evaluated based on the semantics of their content and pixel level metrics at video and frame level, some of which utilize pretrained classifiers trained on ImageNet and VideoMAE. The work builds on top of and shares attributes with the MinD-Vis model including the MBM approach. It constitues of two modules: fMRI encoder and a video generative model, trained separately, and finetuned together.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper proposes a sound architecture constitued of Spatial and Temporal attention, multimodal contrastive learning, adversarial guidance, and diffusion models. The end2end pre-processing and training process, including usage of pretrained models such as BLIP for video captioning have a few introguing novelties. \n'}, 'weaknesses': {'value': 'Eventhough reference [6] is limited to generating images, the differentiating factors between the current work and reference [6] is better be highlighted in more details.\n\nIn the ""Adversarial Guidanc for fMRI"", there is a claim about using the ""average all fMRI in the testing set as the negative guidance"". Usage of the ""testing"" set in the training process, even in its aggregated (averaged) sense is not the best design. \n\nGiven the complexity of the architecture, the ablation study could have been improved to highlight the impact of more components.\n\nAssuming the trainable modules require re-training per subject, the proposed design raises concerns around practicality of the approach.'}, 'questions': {'value': 'In the ""Multimodal Contrastive Learning"" subsection, the idea of {fMRI, video, caption} triplet needs further explanation. If embeddings of fMRI, video and caption encoded via three separate encoders, what does the ""augmented endcoder"" refer to in this context?\n\nIn the same subsection, the idea of concatenating captions with ""Then"" in-between is discussed. How impactful was the addition of ""Then"" keyword in-between the two captions? Did you run an ablation study that demonstrates positive effect?\n\nIn the ""Scene-Dynamic Sparse Causal (SC) Attention"" subsection, with regards to the attention maps, we wonder if the authors monitored attention-maps across transition frames; i.e., did they observe the attention to previous frames (i-2 and i-1) to disipate during transitions?\n\nDo all trainable models (e.g. SC-MBM Encoder, etc.) require re-training for each subject?\n'}, 'limitations': {'value': 'Yes. \nThe intra-subject limitation of the method is highlighted; however, it is not clear whether the training process was repeated for each subject independently. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This research proposes a method called Mind-Video to reconstruct videos from brain activity. By utilizing continuous fMRI data and advanced techniques, Mind-Video can generate high-quality videos with arbitrary frame rates. The model outperforms previous methods in accuracy and structural similarity. \n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The present work contributes with an innovative approach for reconstructing continuous visual experiences from brain activities. By utilizing masked brain modeling, multimodal contrastive learning with spatiotemporal attention, and co-training with an augmented Stable Diffusion model, their method, called Mind-Video, surpasses previous techniques in reconstructing high-quality videos.\n\nThis paper presents a meticulous study of previous work, which is important in the development of the present work. Also, the technical aspects are clearly explained and have also been evaluated using the correct metrics.\n\nThe experimental evaluation of the proposed model demonstrates its superior performance compared with other works.\n\nThe developed methodology provides interpretability, which is a very important factor in medical applications.\n\nThe interpretation of the results is good, which strengthens the results and the paper in general.\n\nIn summary, the work is an interesting application of deep learning in the medical area, and it also has a remarkable novelty.'}, 'weaknesses': {'value': 'The work is very interesting, the resulting video resembles the ground true in terms of activity, but in terms of scene there is still a considerable difference.\n\nIn the ""Paired fMRI-Video dataset"" part, only three subjects are used, this is a limitation in terms of generalization. It is a limitation but it would be interesting to use more subjects and have more generalizable results. Nevertheless, it is ahead of several previous works.'}, 'questions': {'value': 'None'}, 'limitations': {'value': 'The limitations are well explained by the authors.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper presents a pipeline to decode videos from fMRI brain activity data. The pipeline is divided into several consecutive steps. First, a Transformer-based autoencoder is trained on an unsupervised Masked Brain Modelling task to learn fMRI representations on a large corpus of fMRI data. The fMRI encoder is then augmented with a spatial and temporal attention modules to enable the processing of temporal frames. Second, the fMRI encoder is further trained on a contrastive alignment task where fMRI representations are pulled closer to CLIP-based image and text representations of the corresponding video frames. Finally, a Stable Diffusion UNet model is augmented with temporal attention to allow its conditioning on the latents of the two previous frames and is finetuned end-to-end with the fMRI encoder. Experiments on a public dataset of participants watching videos inside an fMRI scanner show better performance (SSIM) as compared to existing baselines. Ablation studies are used to evaluate the impact of windowing hyperparameters and of different design choices. Attention weights from different Transformer layers are projected on a cortical map and visualized to highlight correspondence with different brain networks.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'Originality: The combination of self-supervised learning, contrastive alignment in image/text latent space and conditional video generation for fMRI-to-video decoding is novel. \n\nQuality: Most claims are supported (see below for possible exception to this). Qualitative and quantitative results are convincing. \n\nClarity: The manuscript is overall clearly written and well organized. \n\nSignificance: As one of the first fMRI-to-video approaches, this work is likely to inspire other work in the brain decoding literature. The qualitative and quantitative results suggest this is a clear improvement over existing baselines. '}, 'weaknesses': {'value': 'Quality: The underlying core claim of the submission, i.e. that the dynamic information contained in brain activity data can be used to reconstruct videos, might not be fully supported in the experimental settings presented in the paper (see Question 4). Essentially, it is not clear to me that the presented results prove temporally evolving brain activity can be decoded into videos; rather, it seems to suggest existing video diffusion models can be conditioned on a temporally-fixed (i.e. coming from time t) brain-derived latent representation.\n\nClarity: I found the description of the inputs at the contrastive learning stage unclear (Q3).'}, 'questions': {'value': '1. What is the impact of the masked modelling pretraining on downstream performance? Given the training budget required for this step of the pipeline, it might be important to know the order of performance improvement it can bring.\n2. I do not fully understand the idea behind the ""network inflation trick"" mentioned at line 157. Am I correct in thinking that what is called a batch here is built by taking consecutive fMRI frames, rather than by randomly sampling fMRI frames across e.g. a recording?\n3. At the contrastive learning stage, what are the inputs to the fMRI encoder? Is it multiple fMRI frames, in which case there is a sequence of latent predictions per video segment, or is it still single fMRI frames matched to a single image frame? (The answer to this question might influence the relevance of the next question.)\n4. I understand from line 231 that the decoded videos are generated from a single fMRI frame (yielding 6 video frames at 3 fps). In this particular case, the diffusion model is used in a similar setting as an fMRI-to-image model, i.e. it is conditioned by a unique brain-derived latent collected at time t. The resulting video could therefore be seen as an ""hallucination"" of the diffusion model based on an initial frame, rather than a truly dynamic decoded video, i.e. where temporal changes in brain activity drive changes in video frames. I assume that this might change if longer videos were generated e.g. based on 2 consecutive TRs. Is that something you have tried and if so, do the resulting videos remain temporally consistent when the conditioning is updated to a new fMRI frame?\n5. Results of Table 1 show that removing adversarial guidance has a very mild effect on performance, especially for the video-based semantic metric. However corresponding results in Figure C2 suggests removing adversarial guidance dramatically impacts decoding performance. Does this just happen to be an unrepresentative example?'}, 'limitations': {'value': 'Yes.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper focuses on the task of reconstructing human vision from brain activities. The authors propose MinD-Video that learns spatiotemporal information from continuous fMRI data of the cerebral cortex progressively through masked brain modeling, multimodal contrastive learning with spatiotemporal attention, and co-training with an augmented Stable Diffusion model that incorporates network temporal inflation. And the results are evaluated with semantic and pixel metrics at video and frame levels.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '1 poor'}, 'contribution': {'value': '1 poor'}, 'strengths': {'value': '1. The authors provide both quantitative and qualitative results, and also provide some interpretable visualization results for demonstration.\n2. The proposed method seems to perform better than previous non-diffusion methods.'}, 'weaknesses': {'value': '1. The pre-training of fMRI encoder is composed of generative and contrastive objectives, which is very similar to previous works[1] that use masked contrastive pre-training in diffusion models. And the overall framework is a combination of existing methods or tricks (masked contrastive pretraining[1]+spatio-temporal attention (ST-Attn) mechanism[2]+stable diffusion[3]). Thus the novelty of this work is limited with respect to diffusion model field.\n\n2. The proposed method contains two many tricks and modules, and causes no central point with respect to its technical contributions, the overall presentation is hard to follow.\n\n3. I have reproduced the method, the results seem not as good as the demonstration in the paper and there sometimes exists a style inconsistency between GTs and generated results. The authors seem to cherry-pick the generated videos.\n\n[1] Yang L, Huang Z, Song Y, et al. Diffusion-based scene graph to image generation with masked contrastive pre-training[J]. arXiv preprint arXiv:2211.11138, 2022.\n\n[2] Wu J Z, Ge Y, Wang X, et al. Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation[J]. arXiv preprint arXiv:2212.11565, 2022.\n\n[3] Rombach R, Blattmann A, Lorenz D, et al. High-resolution image synthesis with latent diffusion models[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022: 10684-10695.'}, 'questions': {'value': '1. The proposed method is of limited novelty, the authors need to rethink their main contributions.\n2. The writing needs to be improved, and the central point needs to be emphasized.'}, 'limitations': {'value': 'See weakness part.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper aims to reconstruct high-quality video from brain activity. A novel model called MinD-Video is proposed, which could learn spatiotemporal information from continuous fMRI data.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': ""1. It is quite interesting to reconstruct videos according to human brain regions' actions, Although the task is hard.\n2. I believe all the newest methods are worth being tried to achieve fMRI data reconstruction, including Stable Diffusion and its video version.\n3. The latent alignment and spatiotemporal attention are well-designed in this paper.""}, 'weaknesses': {'value': '1. In Figure 4, we can see that Wen (2018) could reconstruct the shape and Kupershmit (2022) could reconstruct the texture. While videos generated by MinD-Video lack shape and texture. So I think previous works could affect more on the Video Generation part of MinD-Video.\n2. The quantitative results are not sufficient. The metric values are not compared with other methods, and the gap between some experimental settings is limited.'}, 'questions': {'value': '1. Please address my above concerns.\n2. Do you think the Video Generation part should have controllability? I mean the current Video Generation part has no ability to reconstruct a video that is the same as source video, which would be the upper bound of the overall performance.'}, 'limitations': {'value': 'None'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Cinematic Mindscapes: High-quality Video Reconstruction from Brain Activity'}, 'authors': {'value': ['Zijiao Chen', 'Jiaxin Qing', 'Juan Helen Zhou']}, 'authorids': {'value': ['~Zijiao_Chen1', '~Jiaxin_Qing1', '~Juan_Helen_Zhou1']}, 'keywords': {'value': ['Video Reconstruction from Brain Activities', 'Diffusion Model', 'Contrastive Learning']}, 'TLDR': {'value': 'We present Mind-Video for reconstructing continuous video from fMRI data via multimodal contrastive learning and inflated Stable Diffusion model.'}, 'abstract': {'value': 'Reconstructing human vision from brain activities has been an appealing task that helps to understand our cognitive process. Even though recent research has seen great success in reconstructing static images from non-invasive brain recordings, work on recovering continuous visual experiences in the form of videos is limited. In this work, we propose Mind-Video that learns spatiotemporal information from continuous fMRI data of the cerebral cortex progressively through masked brain modeling, multimodal contrastive learning with spatiotemporal attention, and co-training with an augmented Stable Diffusion model that incorporates network temporal inflation. \nWe show that high-quality videos of arbitrary frame rates can be reconstructed with Mind-Video using adversarial guidance. The recovered videos were evaluated with various semantic and pixel-level metrics. We achieved an average accuracy of 85% in semantic classification tasks and 0.19 in structural similarity index (SSIM), outperforming the previous state-of-the-art by 45%. We also show that our model is biologically plausible and interpretable, reflecting established physiological processes.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/05a80f44320caa968972c151a02ab5a8f2341725.pdf'}, 'supplementary_material': {'value': '/attachment/7cc2efc6eac852345ff79d6437293330327aa112.zip'}, '_bibtex': {'value': '@inproceedings{\nchen2023cinematic,\ntitle={Cinematic Mindscapes: High-quality Video Reconstruction from Brain Activity},\nauthor={Zijiao Chen and Jiaxin Qing and Juan Helen Zhou},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=i913TUOvTK}\n}'}, 'paperhash': {'value': 'chen|cinematic_mindscapes_highquality_video_reconstruction_from_brain_activity'}}]"
"['Timo Schick', 'Jane Dwivedi-Yu', 'Roberto Dessi', 'Roberta Raileanu', 'Maria Lomeli', 'Eric Hambro', 'Luke Zettlemoyer', 'Nicola Cancedda', 'Thomas Scialom']",NeurIPS,Toolformer_ Language Models Can Teach Themselves to Use Tools,https://neurips.cc/virtual/2023/oral/73843,2023," Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale. They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller specialized models excel. In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce Toolformer , a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction. This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API. We incorporate a range of tools, including a calculator, a Q&A system, a search engine, a translation system, and a calendar. Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.",Oral 3B NLP/Tools,https://openreview.net/pdf?id=Yacmpz84TH,https://openreview.net/forum?id=Yacmpz84TH,Yacmpz84TH,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper proposes augmenting LLMs with the ability to call ""tools"" (e.g., as a calculator), which is done by providing an initial (small) set of examples, which is then used to augment more examples by leveraging LLM to generate a larger fine-tuning datasets for ""instruction tuning"" for tool-use.\n\nThe proposed technique (cascade of steps) is straightforward, in an elegant way, which also enables the model to generalize showcased by the capability of using a wide range of tools.\n\nAll the reviewers agreed the value this paper adds and acknowledged the potential impact of the paper. Accept as a spotlight.'}}, {'comment': {'value': 'Thank you for your detailed reply. I have no other concerns at this moment.'}}, {'title': {'value': 'Thanks for the response'}, 'comment': {'value': 'I am keeping my initial score.'}}, {'comment': {'value': 'Thank for your response! I have read the response and the other reviews and confirm my original rating.'}}, {'rebuttal': {'value': ""> The experiments are only conducted on GPT-j (a non-instruction tuned model), which I believe is not enough, considering the existence of more powerful open-source LLMs such as LLaMA and Vicuna.\n\nWe completely agree with the reviewer, but at the time during which this work was conducted, neither of the models were available. We are actively working on the experiments with the LLaMA family of models and intend to include those results.\n\n> I actually tested that Vicuna, ChatGPT, and GPT-4 already have excellent capabilities in utilizing the tools mentioned in the paper (almost perfect). These models can skillfully manipulate tools based on very simple prompting, achieving far better performance than the reported number in this paper (I'm not sure why this paper only includes GPT-3 as the baseline, which apparently performs poorer than most of the current LLMs). Hence I doubt whether the proposed method could still benefit well-tuned SOTA LLMs.\n\nIt is challenging to respond fully to this question without details about the specific experiment that the reviewer conducted, but it is plausible that models like GPT-4 are capable of utilizing tools when the specific tool description is included in the prompt (and given that the details of this model are not released, it is not implausible that ChatGPT and GPT-4 have already seen tool usage in the pre-training or alignment stage). However, the very act of mentioning the tool potentially hints to the model that it should use a tool, thereby inadvertently simplifying the problem of tool usage. Our approach aims to enable Toolformer to automatically know when to leverage these tools and how. We conjecture that simple prompting is not sufficient when more, possibly redundant, tools become available: verifying this conjecture is part of our future research plans.\n""}}, {'rebuttal': {'value': '> The use of a threshold based on the likelihood assigned by the LM with and without the tool use is clever, but I also wonder whether this could be misleading in some cases. For instance, the LM may have been trained (?) on some of the CCNet data, so this may lead to an overly optimistic likelihood without tool usage relative to the optimal tool usage at test time, especially for, e.g., temporally-sensitive facts. Were any such limitations related to the filtering process observed in practice?\n\nWe agree that when the LM has been trained on some data, this may lead to an overly optimistic likelihood without tool usage. We actually don\'t see this necessarily as a limitation: for some data/knowledge already in the model\'s weights, it is positive to not call a tool but rely on its weights. Conversely, when the model ""knows it doesn\'t know"", which is the case with well calibrated probabilities, we want it to call the tool. This is quite analogous to humans that would rely on, for example, a calculator, for complex calculus. If the training data covers a sufficiently long time span, temporally-sensitive questions will tend to have more uncertain answers and would fall into this category. We agree that more quantitative analysis would be interesting to measure such behavior.'}}, {'rebuttal': {'value': '> The proposed method has some limitations. First, there\'s a dependency on fine-tuning when adapting the LM to new tools, which could impede broad usage and necessitate additional work.\n\nAt the time this work was conducted there was no evidence that effective tool use could be achieved purely through in-context learning. Indeed, in the absence of reproducible descriptions of how models such as ChatGPT and GPT-4, which do exhibit tool use capabilities, were trained, one has to entertain the possibility that they too were fine-tuned towards tool use in some way. Our work introduces a simple, effective, and reproducible way to endow a model that had no tool training with the capability to use tools, something that we believe is relevant to anyone wishing to train their own model. \n\n> Secondly, the use of square brackets for the ""<API>"" token, without any special escaping mechanism, might present issues when square brackets form part of the original text. Does the use of square brackets as API tokens interfere with the standard usage of square brackets in the text?\n\nThis is an understandable concern, however, an API call requires not only the square bracket but also that the specific tool name follows the square bracket (e.g., <API> Calendar() </API>). Consequently, it would be highly unlikely for parts of the original text to be confused with a true API call, but use cases where usage of the square bracket is common would have to consider this issue, which we have added to the Limitations section.\n\n> Why does Toolformer underperform in comparison to GPT-J+CC in German and Arabic in the MLQA experiment?\n\nOur hypothesis is that the GPT-J+CC model already has some knowledge of other languages so often the model doesn’t need to translate the question into English in order to answer it correctly. In fact, performing the API call can sometimes confuse the model due to the special characters, so the model’s answers may be worse in such cases. However, it is not clear why GPT-J+CC performs better for some languages but not others. \n\nFrom our analysis, the model calls the correct API (MT in this case) with appropriate arguments (either the entire or part of the question) most of the time. The relative poor performance on the MLQA benchmark comes from the inability of answering these questions, even after they’ve been translated into English. However, this is orthogonal to the main goal of the paper which is learning when and how to call a certain API, which we believe our model does to a reasonable extent.   \n\n> Under what circumstances does Toolformer fail to utilize tools effectively?\n\nPlease see the general response for more details.'}}, {'rebuttal': {'value': '> From the writeup, this approach doesn\'t seem to generate multiple API calls in a sentence and also doesn\'t perform well with nested API calls. More discussion on this would be useful.\n\nThis is currently touched upon in the Limitations section: “API calls for each tool are generated independently; as a consequence, there are no examples of chained tool use in the finetuning dataset.” We will make clearer that “chained tool use” encompasses multiple API calls. \n\n> While it is discussed in the limitation section and Table 2, a more thorough analysis of sample efficiency of this approach would be helpful. How many sentences are enough to learn tool-use functionality? Is it possible to collect enough high-quality API augmented sentences easily?\nAblation study: performance as a function of filtering threshold that controls the quality of the API-augmented sentences would give more insight into the learnability of tool-use and sensitivity to the ""correctness"" of the API-augmented dataset.\n\nWhile we agree with the reviewer that it would be valuable to quantify how many examples are necessary for tool-use, this undoubtedly varies according to the specific tool. For some tools like a search engine, this may not need that many samples, but the same is not necessarily true for more complex APIs like scheduling a meeting.  Furthermore, finding good opportunities to generate complex examples in a corpus like CCNet poses yet another challenge. The proposed ablation experiments would also require significant compute (at least ten model training ablations for the five tools) and the results may not generalize.\n\n> A thorough error analysis of failure modes would improve the understanding of the limitations of the proposed approach more clearly.\n\nWhile we did not conduct an extensive and quantitative error analysis, we do have evidence that suggests failure modes are prevalent with some combinations of task and tool. For example, for the DateSet dataset, the Calendar tool is necessary for every example, but we observe that the Toolformer tends to call it less frequently than needed (92.9% of the time). Note however that our evaluation datasets are skewed towards requiring immediate tool use, and that a quantitative error analysis on those would not necessarily shed light on failure patterns in less biased conditions.  Additionally, the task of attributing each incorrect answer across all evaluations to a specific failure mode (failing to call the tool, calling the wrong tool, calling the tool incorrectly, receiving a useless or wrong result from the tool, or failing to come to the wrong conclusion using the tool results) is a major challenge that requires expert human annotation and ideally a broader set of tools.  We leave a general study of failure modes across data sources for future work, and instead include in the camera-ready version a discussion of the different types of failure modes and relevant statistics that we are able to report. Please see the general response for more details.'}}, {'rebuttal': {'value': 'We thank the reviewers for their time and efforts to review, discuss and improve the paper. We have written responses to each reviewer in turn.\n\nTwo of the reviewers asked for more details on the types of errors we have seen in the evaluation. While a detailed and quantitative classification of each failure for each task and tool would require expert human annotation, we do notice broad trends. Namely, we observed that failure can arise from the following: \n\nFailing to call the tool:\n- Our evaluation and finetuning datasets are distributionally different since the former are all ultra-short form QA style tasks while the latter consists of CCNet paragraphs, with only a few tool calls per paragraph.  This difference in distribution likely leads to under-use of the tool in our desired setting.  We correct for this by triggering a tool-use when a start token is in the top 10 tokens for the Toolformer, but this is clearly an example of ‘failing to call the tool’. We note that tools are not called for every question, especially where the answer is strongly in-weights.\n\nCalling the wrong tool:\n- We find Toolformer very often calls an appropriate tool and can often judge the context correctly. In the maths section, we do observe occasional calls to Question Answering and WikiSearch likely because examples using these tools are much more frequent in the fine-tuning dataset than those using the calculator tool.\n\nCalling the tool incorrectly. \n- Many of the tools we use cannot be called ‘incorrectly’, taking either no arguments or strings as inputs - all of which are valid as API calls.\nIn the case of the Calculator tool, at data-augmentation time, we see many incorrect/invalid generations (even with constrained decoding to arithmetic tokens), but since the final dataset contains useful, correct API calls, the fine-tuned model often generates valid calculations. However, these calls are often very simple (often two number +,-, /, *), and have low complexity.  \n\nReceiving the wrong result from the tool or failing to come to the right conclusion\n- In some cases we see that a tool response is either useless or incorrect - most often this can be seen with the WikiSearch tool which uses a naive BM25 information retrieval algorithm on Wikipedia. \n- The model’s response to this varies and sometimes ignores the result of the tool, while at other times incorporates it.  More investigation is needed to understand _when_ or _why_ a tool is ignored.  \nAnecdotally, we observe that the natural continuation requires a highly specific answer, but the tool has not returned it - for instance  “Harry Styles was born in [WikiSearch(Harry styles) -> Harry Styles is an British singer and actor, who has starred in My Policeman] Worcestershire.”'}}, {'summary': {'value': 'This paper proposes a method to finetune pretrained autoregressive language models such that they learn when and how to use external tools to achieve good performance in downstream tasks. Following an in-context learning scheme, humans provide a few examples of inserting API calls at appropriate location in the natural language sentence, which is ised by the trained language model to automatically generate an API-augmented variation of a natural language corpus. These API augmented sentences are filtered via a threshold over a criterion measuring whether adding the API calls and their result as a prefix improves the perplexity of the natural language sentence under the LM. This filtered API augmented dataset is used for further finetuning of the pretrained LM so that it learns to insert API calls at appropriate places. This approach called toolformer is compared against using the LM alone, finetuning the LM on the natural language corpus, using toolformer but aritificially suppressing its ability to call an API, and larger general purpose language models. 5 different APIs are considered in this setting. The model is evaluated on several downstream tasks for which access to the APIs might be beneficial.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '-- The paper is very well motivated. This capability of querying external API while generating text is a natural solution to the pathologies like hallucination that the language models exhibit today. This approach is a step toward endowing a language model with such capabilities reliably.\n\n-- The experimental setup is well designed and the choices of APIs, baselines, and downstream tasks to evaluate on lead to informative analysis.\n\n-- This approach outperforms baselines convincingly on the downstream tasks while not drastically affecting the language modeling capabilities as measured by perplexity on the held-out set.'}, 'weaknesses': {'value': '-- From the writeup, this approach doesn\'t seem to generate multiple API calls in a sentence and also doesn\'t perform well with nested API calls. More discussion on this would be useful.\n\n-- While it is discussed in the limitation section and Table 2, a more thorough analysis of sample efficiency of this approach would be helpful. How many sentences are enough to learn tool-use functionality? Is it possible to collect enough high-quality API augmented sentences easily?\n\n-- Ablation study: performance as a function of filtering threshold that controls the quality of the API-augmented sentences would give more insight into the learnability of tool-use and sensitivity to the ""correctness"" of the API-augmented dataset.\n\n-- A thorough error analysis of failure modes would improve the understanding of the limitations of the proposed approach more clearly.\n\n'}, 'questions': {'value': 'See above'}, 'limitations': {'value': 'See above'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes an innovative method for enabling Language Models (LMs) to utilize tools. The authors prompt the LM to generate API calls based on human demonstrations, which are then executed in tools. Any non-contributing API calls are filtered out. A dataset is then augmented with these API calls, and used to fine-tune the LM. The Toolformer surpasses larger models in many tasks, offering a significant contribution to the field.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'This paper outlines a remarkably simple yet effective strategy for curating a dataset that empowers LMs to utilize tools. The method is well-explained and detailed, boasting a universal applicability across multiple datasets and tools. The authors have carried out extensive, well-designed experiments that showcase the performance boost facilitated by their method. The comparison experiment involving Toolformer, a disabled Toolformer, and GPT-J+CC is particularly commendable, as it eliminates the potential of additional fine-tuning data contributing to performance improvement.\n\nThis research addresses a practical and intriguing topic that is likely to attract considerable interest from both the research and industrial communities. The potential to integrate more sophisticated tools and utilize larger LMs holds promise for advancing LM capabilities.\n'}, 'weaknesses': {'value': 'The proposed method has some limitations. First, there\'s a dependency on fine-tuning when adapting the LM to new tools, which could impede broad usage and necessitate additional work.\n\nSecondly, the use of square brackets for the ""<API>"" token, without any special escaping mechanism, might present issues when square brackets form part of the original text.\n\nLastly, the MLQA experiment raises a few questions. The performance of OPT(66B) and GPT-3(175B) suffers due to their inability to provide answers in English, suggesting a potentially inappropriate evaluation setting. Toolformer also underperforms GPT-J in certain languages, seemingly due to the impact of fine-tuning on CCNet. However, it\'s unclear why Toolformer lags behind GPT-J+CC in German and Arabic. The MLQA experiment fails to convincingly support the paper\'s main claims.\n\nAdditionally, the paper lacks an analysis of cases where the LM fails to use tools effectively during inference. For instance, the reasons behind the LM\'s failure when using a calculator during inference are not investigated. Is it due to the inability to generate the <API> token or the candidate? Or does it fail to provide the correct answers even when the API call is successful? An examination of these failed cases and the issues causing them would be enlightening.\n'}, 'questions': {'value': 'To summarize the inquiries raised in the Weaknesses section:\n\nDoes the use of square brackets as API tokens interfere with the standard usage of square brackets in the text?\n\nWhy does Toolformer underperform in comparison to GPT-J+CC in German and Arabic in the MLQA experiment?\n\nUnder what circumstances does Toolformer fail to utilize tools effectively?\n'}, 'limitations': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes an approach to augment language models with the ability to call ""tools"" during decoding, such as a calculator, retrieval system, or machine translation system. This requires only a few human-written examples, and then uses the LM to generate a larger fine-tuning datasets constructed from raw text. When fine-tuned on this dataset, and augmented with the ability to execute external tools, performance of the LM is improved for a range of downstream tasks, across various model scales.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '* The paper proposes a relatively elegant way to integrate tools with language models in a way that requires only a limited amount of human-written examples of API calls per tool. The proposed method to synthetically construct the fine-tuning dataset appears to work well in practice. \n* By showcasing a variety of tools and their impact across a collection of tasks, this paper showcases the potential impact of integrating such tools and their ability to address some common limitations of LMs. The paper seems likely to influence future work.'}, 'weaknesses': {'value': '* I did not find any significant weaknesses in the proposed approach, execution of the experiments, or technical descriptions in the paper.\n* My only gripe is in the wording of the title claim that LMs can ""teach themselves to use tools"". I can see what the authors mean, as a LM is used to generate the fine-tuning data, but I don\'t find this to be a helpful description of the method and I think the paper would read better without this bit of hype. Additionally, for new tools, the approach still requires a prompt, a handful of examples, and heuristics for selecting relevant subsets of a corpus. Anyways, this gripe shouldn\'t be blocking for publication, and I don\'t expect the authors to change their selected title.\n\n'}, 'questions': {'value': '* The use of a threshold based on the likelihood assigned by the LM with and without the tool use is clever, but I also wonder whether this could be misleading in some cases. For instance, the LM may have been trained (?) on some of the CCNet data, so this may lead to an overly optimistic likelihood without tool usage relative to the optimal tool usage at test time, especially for, .e.g., temporally-sensitive facts. Were any such limitations related to the filtering process observed in practice?'}, 'limitations': {'value': 'Yes'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper explores an interesting area to extend large language models (LLMs) with external tools. The authors show that LLMs can teach themselves to better utilize tools. They tested GPT-j on several tools (calculator, QA system, search engine, translator, and calendar). The experimental results well support the claim, and the model even surpasses GPT-3 despite owning far fewer parameters.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '+ The paper is well-written and easy to follow.\n\n+ The idea is novel and the supporting experimental results are extensive.\n\n+ The authors study a very interesting topic which I believe will be impactful in the LLM era.'}, 'weaknesses': {'value': ""The experiments are only conducted on GPT-j (a non-instruction tuned model), which I believe is not enough, considering the existence of more powerful open-source LLMs such as LLaMA and Vicuna. \n\nI actually tested that Vicuna, ChatGPT, and GPT-4 already have excellent capabilities in utilizing the tools mentioned in the paper (almost perfect). These models can skillfully manipulate tools based on very simple prompting, achieving far better performance than the reported number in this paper (I'm not sure why this paper only includes GPT-3 as the baseline, which apparently performs poorer than most of the current LLMs). Hence I doubt whether the proposed method could still benefit well-tuned SOTA LLMs.""}, 'questions': {'value': 'NA'}, 'limitations': {'value': 'NA'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Toolformer: Language Models Can Teach Themselves to Use Tools'}, 'authors': {'value': ['Timo Schick', 'Jane Dwivedi-Yu', 'Roberto Dessi', 'Roberta Raileanu', 'Maria Lomeli', 'Eric Hambro', 'Luke Zettlemoyer', 'Nicola Cancedda', 'Thomas Scialom']}, 'authorids': {'value': ['~Timo_Schick1', '~Jane_Dwivedi-Yu1', '~Roberto_Dessi1', '~Roberta_Raileanu2', '~Maria_Lomeli2', '~Eric_Hambro1', '~Luke_Zettlemoyer1', 'ncan@meta.com', '~Thomas_Scialom1']}, 'keywords': {'value': ['Language Models', 'Zero-Shot Learning', 'Tool Use', 'APIs']}, 'abstract': {'value': 'Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale. They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller specialized models excel. In this paper, we show that LMs can teach themselves to *use external tools* via simple APIs and achieve the best of both worlds. We introduce *Toolformer*, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction. This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API. We incorporate a range of tools, including a calculator, a Q&A system, a search engine, a translation system, and a calendar. Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.'}, 'pdf': {'value': '/pdf/b2e1ecf89cf4267621b45a071bc6b838f88e3884.pdf'}, 'supplementary_material': {'value': '/attachment/21bae39b339152aac0f41c417befde081b3b7cdd.pdf'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, '_bibtex': {'value': '@inproceedings{\nschick2023toolformer,\ntitle={Toolformer: Language Models Can Teach Themselves to Use Tools},\nauthor={Timo Schick and Jane Dwivedi-Yu and Roberto Dessi and Roberta Raileanu and Maria Lomeli and Eric Hambro and Luke Zettlemoyer and Nicola Cancedda and Thomas Scialom},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=Yacmpz84TH}\n}'}, 'TLDR': {'value': 'We introduce Toolformer, a language model trained in a self-supervised way to know when and how to use external tools, achieving substantially improved zero-shot performance across a variety of downstream tasks.'}, 'paperhash': {'value': 'schick|toolformer_language_models_can_teach_themselves_to_use_tools'}}]"
"['Nikita Gushchin', 'Alexander Kolesov', 'Alexander Korotin', 'Dmitry Vetrov', 'Evgeny Burnaev']",NeurIPS,Entropic Neural Optimal Transport via Diffusion Processes,https://neurips.cc/virtual/2023/oral/73836,2023," We propose a novel neural algorithm for the fundamental problem of computing the entropic optimal transport (EOT) plan between probability distributions which are accessible by samples. Our algorithm is based on the saddle point reformulation of the dynamic version of EOT which is known as the Schrödinger Bridge problem. In contrast to the prior methods for large-scale EOT, our algorithm is end-to-end and consists of a single learning step, has fast inference procedure, and allows handling small values of the entropy regularization coefficient which is of particular importance in some applied problems. Empirically, we show the performance of the method on several large-scale EOT tasks. The code for the ENOT solver can be found at https://github.com/ngushchin/EntropicNeuralOptimalTransport",Oral 3C Diffusion Models,https://openreview.net/pdf?id=fHyLsfMDIs,https://openreview.net/forum?id=fHyLsfMDIs,fHyLsfMDIs,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The paper proposes a novel algorithm for estimating the entropic optimal transport by\nbridging the gap with the Schrödinger bridge problem. The authors propose a saddle-point, maxmin optimization problel\nthat allows to train the neural OT.\n\nAll reviewers agree that the paper proposes a novel approaches with sound theoretical arguments and\nsupported by empirical evidences.'}}, {'comment': {'value': ""I thank the authors for the detailed response. It would be great to add these clarifications into the revision. I'll update my score.""}}, {'title': {'value': 'Thanks for the rebuttal'}, 'comment': {'value': 'Dear Authors,\n\nI would like to thank you for the detailed and very well written rebuttal. It addressed all of my concerns. I update my score.'}}, {'title': {'value': 'Very satisfied with rebuttal and the uploaded comparisons.'}, 'comment': {'value': 'Dear Authors, \n\nI have read the rebuttal and can comment that you have clarified and resolved all the issues I raised. In particular, the stability plots and the further fair comparisons brought everything to a very clean conclusion. Additionally, I have also gone over the other reviews and the provided responses, overall it looks pretty satisfactory, the non-trivial prior results were quite a nice addition and comment to the robustness/flexibility of the proposed approach.\n\nI will increase my score accordingly once the platform allows such, at the time being it seems OpenReview is not allowing this until the discussion period is over, I do agree this work does seem to be the most thorough comparison yet for SBP solvers within the eOT context making this paper a substantial contribution beyond the novel approach that is proposed (which is also a solid and self-contained contribution on its own). '}}, {'rebuttal': {'value': 'Dear reviewers, thank you for taking the time to review our paper.\n\nYour valuable feedback and constructive comments are greatly appreciated. We are particularly pleased that all reviewers found our paper well-written and easy to read (TSgQ, LQN6, WYHi, KyaP). We are also pleased that you find our duality gap analysis and guarantee of the quality of the saddle point solution important (TSgQ, WYHi), that our experiments are extensive and include many related baselines (KyaP), and that the whole work is great and quite complete (WYHi).\n\nPlease, find the answers to your questions below. **Please note that we have added tables and figures in the attached pdf to support our responses to the reviewers WYHi, KyaP, and TSgQ.**'}, 'pdf': {'value': '/pdf/756ed1a14ee304765e8cd12278840eb8216bbace.pdf'}}, {'rebuttal': {'value': 'Dear Reviewer KyaP, thank you for your comments. Here are the answers to your questions.\n\n**(1) Connection to OT for unregulated case $\\epsilon=0$.**\n\n**We emphasize that our work focuses on developing a new algorithm for solving entropic OT and the equivalent SB problem. This implies that $\\epsilon>0$.** We present the empirical results of our algorithm for $\\epsilon=0$ only for completeness since it *technically* allows the use of $\\epsilon=0$ (see lines 226-227). Given your interest in studying this case in detail, we provide **the proof sketch** to show that for $\\epsilon=0$ our saddle-point objective\n$$\n\\sup_{\\beta} \\inf_{T_f} \\mathcal{L}(\\beta,T_f) = \\mathbb{E}_{T\\_f}( \\int\\_0^1 ||f(X_t, t)||^2 dt) - \\int\\_{\\mathcal{Y}} \\beta(y) d\\pi_1^{T_f}(y)+ \\int\\_{\\mathcal{Y}} \\beta(y) d\\mathbb{P}_1(y) ,\n$$\n\n$$\ns.t. \\quad X_0 \\sim \\mathbb{P}_0, \\quad T_f : dX_t = f(X_t, t)dt.\n$$\nis a max-min reformulation of the **Benamou-Brenier** problem (the dynamic OT with $\\ell^{2}$ cost):\n$$\n\\mathcal{L}^*=\\inf_f \\mathbb{E}\\_{T_f}[\\int_0^1 ||f(X\\_t, t)||^2 dt], \\quad s.t. \\quad X\\_0 \\sim \\mathbb{P}\\_0, \\quad  T\\_{f} : dX_t = f(X_t, t)dt, \\quad X_1 \\sim \\mathbb{P}_1.\n$$\nwhich searches for an ODE drift $f$ which moves the mass of $\\mathbb{P}_0$ to $\\mathbb{P}_1$.\n\n**SKETCH OF THE PROOF**:\n\n*Step 1 (Auxiliary functional, analog of Lemma B.3).*\n\nWe introduce an auxiliary functional:\n$$\\widetilde{\\mathcal{L}}(\\beta,H)=\\int\\_{\\mathcal{X}} \\|x-H(x)\\|^{2}d\\mathbb{P}\\_{0}(x)-\\int\\_{\\mathcal{X}} \\beta(H(x))d\\mathbb{P}\\_0(x)+\\int\\_{\\mathcal{Y}} \\beta(y)d\\mathbb{P}\\_1(y),$$\nand consider the following maximin reformulation of OT with the quadratic cost [1, Eq.4]:\n$$\n\\sup_{\\beta}\\inf_{H}\\widetilde{\\mathcal{L}}(\\beta,H) = \\inf\\_{T\\sharp \\mathbb{P}\\_0 = \\mathbb{P}\\_1} \\int\\_{\\mathcal{X}} ||x - T(x)||^2 d\\mathbb{P}\\_0(x) = \\mathcal{L}^{*}.\n$$\n\n*Step 2 (Solution of the inner problem is always an OT map).*\n\nIt can be shown that the minimizer of the inner problem exists ($H^{\\beta}$), i.e.:\n$$\nH^{\\beta}\\in \\text{arg}\\min\\_{H\\sharp\\mathbb{P}_0=\\mathbb{P}\'}\\int\\_{\\mathcal{X}} \\big\\lbrace\\|x-H(x)\\|^{2}- \\beta(H(x))\\big\\rbrace d\\mathbb{P}\\_0(x)\n$$\nMoreover, $H^{\\beta}$ is an OT map between $\\mathbb{P}_0$ and $\\mathbb{P}\'\\stackrel{def}{=}H^{\\beta}\\sharp \\mathbb{P}_0$.\n\n*Step 3 (Equivalence for inner objective values).*\n\nSince $H^{\\beta}$ is the OT map between $\\mathbb{P}\\_0,\\mathbb{P}\' $, it can be represented as an ODE with zero acceleration ($\\frac{df^{\\beta}(x(t), t)}{dt}=0$) solution $T_{f^{\\beta}}$ to the Benamour Brenier problem between $\\mathbb{P}\\_0,\\mathbb{P}\'$, for which $\\|x-H^{\\beta}(x)\\|^{2}=\\int_{0}^1 ||f^{\\beta}(X_t, t)||^2 dt$, i.e.:\n\n$$\\inf_{H}\\tilde{\\mathcal{L}}(\\beta,H) = \\inf_{T_f}\\mathcal{L}(\\beta, T_f).$$\n\n*Step 4 (Equivalence of the saddle point objective).*\n\nTake $\\sup$ over $\\beta\\in\\mathcal{C}\\_{b,2}(\\mathcal{Y})$ and get the final equivalence:\n$$\\sup\\_{\\beta}\\inf\\_{H}\\widetilde{\\mathcal{L}}(\\beta,H)= \\sup\\_{\\beta}\\inf\\_{H}\\mathcal{L}(\\beta,T_{f})= \\mathcal{L}^{*}.$$\n\nWe cannot give the full proof due to the length limit of the answer, but per request, we can provide it. **At the same time, our paper focuses on solving the problem with $\\epsilon > 0$.**\n\n**(2) Comparision with [1].**\n\nWe are aware of [1]. However, since they address the unregularized OT problem, we have not compared our results to theirs. As per your request, we have trained our method with $\\epsilon=0$ using the same image benchmark setup [2] and present our results alongside the results from Table 2 of [1] **in Table 4 of the attached pdf**. Since the method presented in [1] compares with the MMR method from [2], we also present its results.\n\nAs we can see, ENOT with $\\epsilon=0$ works better than the MM-R solver but slightly underperforms compared to [1]. \n\n**(3) Comparison with [3].**\n\nWe do not compare with DiffSB since the authors do not consider unpaired translation for the spaces of images larger than grayscale $32$x$32$. In their official GitHub repository there is no config for unpaired translation at all. Moreover, the authors themselves used not the Wiener prior for SB, see [3, Appendix J.3]. After trying to tune hyperparameters which we used for the Colored MNIST setup on our own and obtaining poor results, we decided not to scale this algorithm further to unpaired Celeba setup.\n\n**(4) Including dual form in Sec 2.**\n\nWe agree that dual form formulation of OT problems also could be discussed in Section 2 since our proofs are based on it. We will add a discussion about dual OT formulation and methods based on it (such as [1] and [2]) to the main text of the final version.\n\n**(5) Comparison of SDE and ODE.**\n\nOur proposed algorithm has a larger gradient variance when $\\epsilon$ is larger, which may affect the final quality. To improve the results, one can use more steps for sampling from SDE or adjust the learning rate. In the paper, we present results for different $\\epsilon$ while keeping all the other hyperparameters the same.\n\n**(6) why is there a ""1/|f|"" term in Alg 1, when computing the KL? And what\'s $f_{n,m}$? I understand tht $f_n$ is the drift output at time step $n$.**\n\nWe use $f_{n, m}$ to denote drift output at time step $n$ for the $m$-th object of the input sample batch. We use the average of the drifts as an estimation of $\\int_{0}^{1} ||f(X_t, t)||^2 dt$ in the training objective.\n\n**Concluding remarks.**\nWe would be grateful if you could let us know if the explanations we gave have been satisfactory in addressing your concerns about our work. If so, we kindly ask that you consider increasing your rating. We are also open to discussing any other questions you may have.\n\n**Additional references.**\n\n[1] Amos,. ""On amortizing convex conjugates for optimal transport.""\n\n[2] Korotin, et al. ""Do neural optimal transport solvers work? a continuous wasserstein-2 benchmark.""\n\n[3] De Bortoli, et al. ""Diffusion Schrödinger bridge with applications to score-based generative modeling.""'}}, {'rebuttal': {'value': 'Dear Reviewer WYHi, Thank you for your comments. Here are the answers to your questions.\n\n**(1) Comparison with MLE-SB.**\n\nComparing entropic OT methods is difficult because they are based on different principles: IPF-based (MLE-SB, DiffSB, FB-SDE), dual form based (LSOT, SCONES), semi-dual form based (ENOT, ours), and each of them has different hyperparameters that need to be tuned. **It seems like our paper is unique in the field which performs such a comprehensive comparison.** We have taken the most similar hyperparameters to those from the authors\' repositories. In our initial results, all the methods (except LSOT and MLE-SB) work well and give good results. LSOT performs poorly because it only learns the barycentric projection, not the EOT plan. At the same time, it was not very clear to us why the results for MLE-SB were bad.\n\nIt appears that [1] is the paper in which MLE-SB was first introduced, as it was the only one that used GP for training. Indeed, to ensure a fair comparison of the methods, rather than the way of solving regression problems, it would be better to use a neural network for all methods. This is because GP can be challenging to scale when used for setups with many time steps ($200$ for high-dimensional Gaussians) and a moderate amount of samples. \n\nWe reran the experiments for MLE-SB using neural network parametrization of the drift function (as well as for other methods) and using $200$ time steps as we used for all SB methods. We use $1000$ IPF iterations and sample $512$ samples from each distribution $\\mathbb{P}_0$ and $\\mathbb{P}_1$ at each IPF iteration. **The updated results are shown in Tables 1, 2, and 3 of the attached PDF file.**\n\nAs we can see, MLE-SB performs similarly or better than the other IPF-based method (DiffSB) and can also solve the problem in this setup. Now all the considered methods that learn the EOT plan work well on the Gaussian setup, and the goal of this experiment is achieved. The small residual error of all methods seems to be related more to hyperparameter tuning than to the nature of the algorithm used.\n\n**(2) Stability of the proposed method.**\n\nWe run our method on the Gaussian setup five times and provide the means and standard deviations in **Tables 1, 2, and 3 of the attached PDF file**. In Figure 1, we also provide the plot of $\\text{BW}_2^2\\text{-UVP}$ (\\%) between the ground truth EOT plan $\\pi^{*}$ and the learned plan $\\pi$ of ENOT and MLE-SB during training for $DIM=128$. Note that the steps on the plots represent different values due to the different nature of the algorithms. There are IPF steps for MLE-SB and outer problem steps for ENOT (ours). As we can see, both methods stably converge.\n\n**Concluding remarks**. \nWe would be grateful if you could let us know if the explanations we gave have been satisfactory in addressing your concerns about our work. If so, we kindly ask that you consider increasing your rating. We are also open to discussing any other questions you may have.\n\n**Additional references.**\n\n[1] Vargas, Francisco, et al. ""Solving schrödinger bridges via maximum likelihood."" Entropy 23.9 (2021): 1134.'}}, {'rebuttal': {'value': 'Dear Reviewer LQN6, thank you for your comments. Here are the answers to your questions.\n\n**(1) p3 ""Hence, one may optimize (5) over processes $T$ for which $T_{|x,y}=W_{|xy}$ for every $x, y$ and set the last term in (6) to zero"". How do you actually do that ? By enforcing gaussian dynamics ?**\n\nWe did not intend to do that in practice. And we do not do it in our algorithm. We just noticed that it can be considered as such a constrained optimisation. In fact, there seems to be no straightforward way to parameterise such a family of processes. However, as we noted in the main text (lines 76-78), if $T^*$ is a solution to SB with prior $W^{\\epsilon}$ for any two distributions $\\mathbb{P}\\_0$ and $\\mathbb{P}\\_1$, then $T^*\\_{|x,y} = W^{\\epsilon}\\_{|x,y}$  [28, Proposition 2.3].\n\n**(2) the paragraph ""continuous OT"" reads a bit weak to me. All the references are just given in a row, without great care for actually discussing them and their connections with the proposed approach.**\n\nSince many recent papers appeared on continuous OT, we focused the discussion only on the most relevant EOT and SB papers and only briefly mentioned the rest. Following your suggestion, we will extend the discussion of methods for solving other types of continuous OT (unregularized OT).\n\n**(3) do you actually need to store the gradients when computing ${X_n, f_n}$ for the computation of $L_\\beta$ ? It looks to me that Eul-Mar($X_0$, $T_{f_\\theta}$) can actually run in some no grad environment, or am I mistaken ? This would mean there is some possibility in strongly parallelizing this or even use some external workers to compute that ?**\n\nWe do not have to store the gradients in the computation of ${X_n, f_n}$ for the computation of $L_\\beta$ in Algorithm 1, and we indeed do not store them in our implementation. However, we have not yet tried to use computational schemes with external workers in our work. We appreciate the idea and will try it.\n\n**(4) On the contrary, in the inner loop (over k), you really need to store the gradients, right ? Is it necessary to use many inner iterations $K_f$ ? Maybe I\'m mistaken but I don\'t see that discussed, although this looks like a key computational burden when I have a look at algorithm 1, right ? Is it feasible to just record gradient for the last k steps ? for some of them ? Some thing that could help going faster ?**\n\nWe have to store them, but we can easily solve the memory problem using gradient checkpointing [1]. We have implemented it in our code. The hyperparameter $K_f$ affects the quality of the solution of the inner problem and can be tuned. We noticed that $K_f=1$ is too small, and the algorithm can easily diverge, but for $K_f=10$, the problem vanishes. We noticed in the limitations section that backpropagations through SDE may be computationally heavy. More efficient SDE solvers can be used to overcome this limitation.\n\nAnother possibility is to consider approaches from stochastic optimal control or reinforcement learning, since with the fixed potential $\\beta$, the inner problem can be formulated as a problem from these fields, as noted by **reviewer KyaP**. For example, one could consider $-||f(X_t, t)||^2\\Delta t$ as a reward in an intermediate step and $\\beta(X_{predicted})$ as an additional reward in the final step. In this case, one could use Q-learning or Actor-Critic approaches to learn from a segment of a trajectory without propagating through the whole trajectory.\n\n**(5) I have no clue what this BW2-UVP metric is. Could you at least give us a hint that would help us avoid checking reference [25] ?**\n\nIt is the Wasserstein-2 distance between distributions $\\mathbb{P}$ and $\\mathbb{Q}$ that are coarsened to Gaussians and normalized by the variance of the distribution $\\mathbb{Q}$:\n$$\n\\text{B}\\mathbb{W}\\_{2}^{2}\\text{-UVP}\\big(\\mathbb{P}, \\mathbb{Q} \\big) = \\frac{100 \\\\%}{\\frac{1}{2}\\text{Var}(\\mathbb{Q})} \\mathbb{W}\\_{2}^{2} (\\mathcal{N}(\\mu\\_{\\mathbb{P}}, \\Sigma\\_{\\mathbb{P}}), \\mathcal{N}(\\mu\\_{\\mathbb{Q}}, \\Sigma\\_{\\mathbb{Q}})).\n$$\n\nWe will add this definition to the main text.\n\n**(6) You must check the references. Most of them are badly formated. You have ""schr""odinger"" everywhere and you are missing many uppercases for proper nouns.**\n\nThanks so much for pointing out this. We will check and correct the references.\n\n**Concluding remarks.** \nWe would be grateful if you could let us know if the explanations we gave have been satisfactory in addressing your concerns about our work. We are also open to discussing any other questions you may have.\n\n**Additional references.**\n\n[1] Chen, Tianqi, et al. ""Training deep nets with sublinear memory cost."" arXiv preprint arXiv:1604.06174 (2016).\n[2] Christian Léonard. A survey of the schr\\"" odinger problem and some of its connections with\noptimal transport.'}}, {'rebuttal': {'value': 'Dear Reviewer TSgQ, thank you for your comments. Here are the answers to your questions.\n\n**(1) In line 223, it is mentioned that the negative entropy is not strongly convex. This is false as the function $p\\mapsto x\\ln(x)$ has second derivate $x \\mapsto \\frac{1}{x}$ which is bounded from below by $1$ on the interval $[0,1]$. See for example Section 4.1 of reference [2]. As a result, the comparison to [1] (reference [5] in the paper) needs to be reconsidered.**\n\nRecall that the negative (differential) entropy of a distribution with density $p(x)$ is given by $-H(p) = \\int p(x)\\log p(x)dx$. The negative entropy is indeed $\\frac{1}{M}$-strongly convex if we only consider distribution $p$ whose density $p(x)$ is bounded by a constant $M>0$ (this follows from your argument). However, we work with general continuous distributions ($\\mathbb{P}_0,\\mathbb{P}_1,\\widehat{\\pi}$, etc.) which may not satisfy this assumption. For example, $\\mathcal{N}(x|0,\\sigma)$ for small $\\sigma$ may have density at $0$, which is greater than any given constant $M$. Therefore, the differential entropy is not $\\frac{1}{M}$-strongly convex for any $M>0$.\n\n**(2) Some experimental section metrics are not introduced.**\n\n*We will add the explanations and definitions of the metrics to Appendix.*\n\n**(3) The parametrization $g(X_t,t) = X_t + f(X_t,t)\\Delta_t $ should have been indicated in the main paper rather than in the appendix as although it is mathematically equivalent to the parametrization presented in the main paper, it allowed better results on the CelebA dataset according to the appendix.**\n\n*We will include a comment regarding the parametrization utilized in the primary text (to Section 4.2).*\n\n**(4) Problem with links: For some reason, the bibliographic references links along with links to equations and sections etc. are not working.**\n\nThank you for pointing this out. We will fix it.\n\n**(5) Minor remarks.**\n\nThank you for your comments. We will fix all the issues and think it will further improve the clarity.\n\n**(6) Computation of $\\mathbb{E}\\left[\\int_0^1\\Vert f(X_t,t)\\Vert^2{\\rm d}t\\right]$ in line 197, it is indicated that the mean of the \n is used. Is this justified by the Riemann integral discrete approximation? If so, does a trapezoidal rule for approximating the integral improve the result?**\n\nYes, we used the mean as a discrete approximation of $\\mathbb{E}\\left[\\int_0^1\\Vert f(X_t,t)\\Vert^2{\\rm d}t\\right]$. We have not tried to use other types of approximation of this integral that might improve the proposed algorithm. Thank you for your suggestion.\n\n**(7) Is it straightforward to generalize the approach to costs other than the squared Euclidean distance? Does it fundamentally change the nature of the associated stochastic process.**\n\nYes, it is quite straightforward. We focus only on EOT with the quadratic cost $c(x,y)=\\frac{1}{2}\\|x-y\\|^{2}$ which coincides with SB with the Wiener prior $W^{\\epsilon}$. However, one could use a different prior $Q_v$, given by the SDE: \n$$\nQ_v: dX_t = v(X_t, t)dt + \\sqrt{\\epsilon}dW_t,\n$$\nand solve the problem\n\n$$\n\\inf_{T_f \\in \\mathcal{D}(\\mathbb{P}_0, \\mathbb{P}_1)} \\text{KL}(T_f || Q_v) = \\inf\\_{T\\_f \\in \\mathcal{D}(\\mathbb{P}\\_0, \\mathbb{P}\\_1)} \\frac{1}{2\\epsilon} \\mathbb{E}\\_{T\\_f}[\\int\\_{0}^1 ||f(X_t, t) - v(X_t, t)||^2 dt].\n$$\n\nHere we just use the known expression to $\\text{KL}(T_f|| Q_v)$ between two diffusion processes through their drift functions as we did in our paper. Using the same derivation as in our paper, it can be shown that this new problem is equivalent to solving the EOT with cost $c(x,y) = -\\log \\pi^{Q_v}(y|x)$, where $\\pi^{Q_v}(y|x)$ is a conditional distribution of the stochastic process $Q_{v}$ at time $t=1$ given the starting point $x$ at time $t=0$. For example, for $W^{\\epsilon}$ (which we used) we have $c(x,y) = -\\log \\pi^{W^{\\epsilon}}(y|x) = \\frac{1}{2 \\epsilon}(y-x)^T(y-x) + \\text{Const}$, i.e., we get the quadratic cost. Thus, using different priors for the Schrodinger bridge problem makes it possible to solve Entropic OT for other costs. \n\nIt seems that all our proofs can be extended to any prior process $Q_v$ just by slightly changing the minimax functional:\n\n$$\n\\sup\\_{\\beta} \\inf\\_{T\\_{f}} (\\frac{1}{2\\epsilon} \\mathbb{E}\\_{T\\_f}[\\int\\_{0}^1 ||f(X\\_t, t) - v(X\\_t, t)||^2 dt] + \\int\\_{\\mathcal{Y}} \\beta\\_{\\phi}(y) d\\mathbb{P}\\_1(y) - \\int\\_{\\mathcal{Y}} \\beta\\_{\\phi}(y) d\\pi\\_1^{T\\_f}(y)). \n$$\n\nWe conducted a toy experiment to support this claim and consider $Q_v$ with $\\epsilon=0.01$ and $v(x, t) = \\nabla \\log p(x)$, where $\\log p(x)$ is a 2D distribution with a wave shape, **see figure 2 of the attached pdf.** Intuitively, it means that trajectories will be concentrated in the regions with a high density of $p$. In Figure 2, There the grey-scale color map represents the density of $p$, start points ($\\mathbb{P}\\_0$) are green, target points ($\\mathbb{P}\\_1$) are red, obtained trajectories are pink and mapped points are blue.\n\n**(8) Did the authors try to apply the method to the domain adaptation (DA) problem as several DA methods rely on optimal transport?**\n\nNo, we did not try.\n\n**Concluding remarks.**\nWe would be grateful if you could let us know if the explanations we gave have been satisfactory in addressing your concerns about our work. If so, we kindly ask that you consider increasing your rating. We are also open to discussing any other questions you may have.\n\n**Additional references.**\n\n[1] Asadulaev, A., Korotin, A., Egiazarian, V., \\& Burnaev, E. (2022). Neural optimal transport with general cost functionals. arXiv preprint arXiv:2205.15403.\n\n[2] Michele Pavon and Anton Wakolbinger. On free energy, stochastic control, and schrödinger\nprocesses. In Modeling, Estimation and Control of Systems with Uncertainty: Proceedings of a\nConference held in Sopron, Hungary, September 1990, pages 334–348. Springer, 1991.\n'}}, {'summary': {'value': ""The main idea of the paper is to estimate a stochastic map for the entropic optimal transport problem using its connection to the dynamic Schrödinger bridge (SDB) problem. The authors formulate the SDB as a saddle point problem of an associated Lagrangian. Then they recover the transport plan as the joint distribution of the solution to the dynamic Schrödinger bridge problem's initial and final values, while the transport is encoded in the drift term of the learned stochastic process that is the solution of the SDB. Compared to previous methods, the method at hand offers more stability for small entropic regularization coefficients. The errors on the drift term solution and on the transport map are quantified given the corresponding duality gaps of the inner and outer optimization problems of the saddle point objective. Finally, the approach is supported by experimental evaluation.""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The paper is extremely well-written and reader-friendly.\n\n- Several remarks are made to facilitate reading and to provide intuition about technical notions.\n- A guarantee on the quality of the saddle point solution is provided.\n- Addressing the small $\\epsilon$ case, which is a source of instability of several other methods.'}, 'weaknesses': {'value': '* In line 223, it is mentioned that the negative entropy is not strongly convex. This is false as the function $p\\mapsto x\\ln(x)$ has second derivate $x \\mapsto \\frac{1}{x}$ which is bounded from below by $1$ on the interval $[0,1]$. See for example Section 4.1 of reference [2]. As a result, the comparison to [1]  (reference [5] in the paper) needs to be reconsidered.\n\n* There is no concluding section.\n\n* Some experimental section metrics are not introduced.\n  \n  * The $\\rm{BW_2^2-UVP}$ is not introduced even in the appendix, although a reference for it is given. \n  \n  * FID: the previous remark applies.\n\n* The parametrization $g(X_t,t) = X_t + f(X_t,t)\\Delta_t $ should have been indicated in the main paper rather than in the appendix as although it is mathematically equivalent to the parametrization presented in the main paper, it allowed better results on the CelebA dataset according to the appendix\n  \n  ## Minor remarks\n\n* Problem with links: For some reason, the bibliographic references links along with links to equations and sections etc. are not working.\n\n* $\\pi^{W^\\epsilon}$ is introduced for the first time in Equation (8) without being defined.\n\n* $W_{|x,y}$ is not explicitly defined, although one can infer its meaning from the definition of $T_{|x,y}$.\n\n* Theorem 4.1: I think it should be ""every pair $(\\beta^*,T_{f^*})$ for (13)"" rather than ""for (12)"" as problem (13) is a saddle point problem.\n\n* Reference to Algorithm 2: in line 195, Algorithm 2 is referenced. However, it is not indicated that it is written in the appendix.\n\n* Suggestion: index $m$ can be removed in the ""$\\widehat{KL} \\leftarrow$"" line of Algorithm 1  since the sum terms are already indicated to be the values of $f_n$, or it is possible to indicate $\\sum_{m=1}^{|f_n|}$.\n\n* Line 158: I think it should be added ""that is bounded from above"" to ""a continuous function"".\n\n## References\n\n[1] Asadulaev, A., Korotin, A., Egiazarian, V., & Burnaev, E. (2022). Neural optimal transport with general cost functionals.\xa0*arXiv preprint arXiv:2205.15403*.\n\n[2] Peyré, G., & Cuturi, M. (2019). Computational optimal transport: With applications to data science.\xa0*Foundations and Trends® in Machine Learning*,\xa0*11*(5-6), 355-607.'}, 'questions': {'value': ""* Computation of $\\mathbb{E}\\left[\\int_0^1\\Vert f(X_t,t)\\Vert^2{\\rm d}t\\right]$ : in line 197, it is indicated that the mean of the $f(x,t)$ is used. Is this justified by the Riemann integral discrete approximation? If so, does a trapezoidal rule for approximating the integral improve the result?\n* Is it straightforward to generalize the approach to costs other than the squared Euclidean distance?  Does it fundamentally change the nature of the associated stochastic process \n* Did the authors try to apply the method to the domain adaptation (DA) problem as several DA methods rely on optimal transport ?\n----------\nI have read the authors's rebuttal. They have addressed my concerns.""}, 'limitations': {'value': 'The impact of the paper and the limitations of the contribution are clearly discussed in Section 6.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper focuses on neural optimal transport  and more particularly through a ""dynamic schrodinger bridge"" approach. I am not an expert in this particular topic, but I must say that the authors manage to make it quite readable and a good introduction to the methodology.\n\nAs far as I can tell, the particularity of the approach is to start from a known key constrained optimization problem in eq (11) that has been presented before and that is progressively explained. Then, departing from previous methods, the authors propose a Lagrangian approach, for which we now have an unconstrained problem and the need to train not only the drift function that allows sampling, but also some ""beta network"" (coined in as the beta network), in a min-max optimization approach, that is similar --but different -- from the usual GAN methodology.\n\nAfter the rigorous theoretical treatment, the authors present some very nice experiment that seem to support their claims and the interesting features of their approach. I think the paper is quite challenging, but that it is also very stimulating and inspiring.\n\n-- \nafter rebuttal, I am still happy with the paper. Maintaining my score.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'I feel slightly uncomfortable in assessing whether the proposed method is new or is not exactly or if the authors miss some particular recent and/or relevant method in their references, mostly because I cannot be considered an expert on the topic. Still, it looks to me that they are doing their best at providing a very objective account of the relevant literature and giving many pointers, so I am assuming they can be trusted when they present their contributions.\n\nThe proposed method seems quite ok to implement (cf Algorithm 1) and the results are very nice. I am not really aware of the appropriate metrics and usual evaluation criteria that should be used, but I felt compelled by the experiments, which made me want to try things out. I guess this is the most important aspect.\n\nTo summarize what I feel are the strengths of the paper:\n- good theoretical overview, motivations and derivations\n- the resulting method seems simple to implement\n- interesting performances'}, 'weaknesses': {'value': ""The paper is a bit difficult to follow, but I don't think it should really be modified to be simpler. I guess it's mostly a matter of myself not being an expert in the topic.\n\nStill, some changes here or clarifications here and there could help. I will mention them below.""}, 'questions': {'value': '- p3 ""Hence, one may optimize (5) over processes T for which T|x,y=W_xy for every x, y and set the last term in (6) to zero"". How do you actually do that ? By enforcing gaussian dynamics ?\n- the paragraph ""continuous OT"" reads a bit weak to me. All the references are just given in a row, without great care for actually discussing them and their connections with the proposed approach.\n\nIn algorithm 1, I have some questions.\n- do you actually need to store the gradients when computing {X_n, f_n} for the computation of L_\\beta ? It looks to me that Eul-Mar(X_0, T_{f_\\theta}}) can actually run in some `no_grad` environment, or am I mistaken ? This would mean there is some possibility in strongly parallelizing this or even use some external workers to compute that ?\n\n- On the contrary, in the inner loop (over k), you really need to store the gradients, right ? Is it necessary to use many inner iterations K_f ? Maybe I\'m mistaken but I don\'t see that discussed, although this looks like a key computational burden when I have a look at algorithm 1, right ? Is it feasible to just record gradient for the last k steps ? for some of them ? Some thing that could help going faster ?\n\n- I have no clue what this BW2-UVP metric is. Could you at least give us a hint that would help us avoid checking reference [25] ?\n\n- You must check the references. Most of them are badly formated. You have ""schr\\""odinger"" everywhere and you are missing many uppercases for proper nouns'}, 'limitations': {'value': 'I would say that the limitations are clearly mentioned'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'Inspired by how Sinkhorn duals are derived the authors adapt said derivation to the path measure and via the disintegration theorem they derive a novel unconstrained min-max objective for solving the Schrodinger bridge problem, the authors then proceed to showcase their method in eOT based tasks, introducing a new gaussian benchmark and displaying competitive results to previous approaches.  Additionally, the authors quantify errors in sampling and transport of approximate minimisers to their proposed schemes.\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. The extension of the Sinkhorn dual to the dynamic setting is rather elegant and certainly novel in the way it is carried out \n2. The paper is excellent on the presentation side in regards to technical ideas, whilst the contributions are novel/creative they are presented in such a way that understanding them was not difficult.\n3. The new formulation allows for a novel duality gap analysis, which is one of the few works analysing learned SBP methods in the approximate setting. \n4. From a purely conceptual viewpoint the work is great and rather complete, just some clarifications/additions on the experimental side and motivations could be enhanced.'}, 'weaknesses': {'value': 'Outside of a concern in how different methods are compared (detailed in the questions), this paper is overall well written and has mostly sound experiments. \n\nFrom the method standpoint, there are several potential weaknesses and lacking ablations which I will detail in the limitations.\n'}, 'questions': {'value': ""1. Some of the methods you compare to are closed form / non-iterative in the way they solve the half bridges e.g. [1] using GPs.  A thing to note is iterative approaches such as SGD can keep resampling from P_0 and P_1 in the toy tasks nonstop, effectively making the dataset set size somewhat proportional to the iterations, this strongly benefits generalisation capabilities, especially in higher dimensions in contrast to a the GP approach in [1] which is likely fitted on a small dataset. If we assume that the dataset is fixed across epochs K_f * batchsize would give a proxy as to the size of the dataset used in the DL approaches , from inspecting the code provided in the supplementary zip in particular the high dim Gaussians and toy examples IPYNB this quantity seems to be above 5000, whilst I suspect for [1] it might be lower. Even then I suspect you resample from the toy distributions (Gaussians) every time as indicated in your pseudocode in which case the dataset sizes are simply not comparable at all and the non-iterative approaches like MLE-SB are prone to be affected significantly by generalisation error (which scales slowly in number of samples for kernel methods, which also don't overcome the curse of dim as well as neural networks)  in particular in high dimensions.\n2. Are the same number of timesteps used across the DL and the GP approaches when training ? computationally it feels unlikely the gram matrix would fit in memory for the given timesteps used with the DL approaches. \n3. A suggestion here would be to compare all approaches in an additional table (e.g. in the appendix) under budgets in the number of steps and number of samples (and fairly ensure these are the same across methods), this can be useful to quantify the data efficiency of each approach. Furthermore, the settings under which [1] was run (steps and dataset size) should be reported.\n""}, 'limitations': {'value': 'Finding saddlepoints / solving min-max problems is typical quite a challenging task and was often a huge challenge in the training stability of GANs (very high variance training results). In contrast to IPF which is much nicer from an objective viewpoint (sequence of regression losses), this approach poses the question of how stable training is.\n\nAs none of the experiments have error bars (on training runs) it is difficult to see if the proposed approach is robust and “easy” to train.  I would suggest to the authors provide such results and in addition maybe comparisons to training loss with Chen 2021 joint or De Bortoli 2021.\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper proposes to solve dynamic entropic optimal tansport (EOT), also known as Schrödinger bridge problem, with nerual solver. Specifically, the authors propose a saddle-point, maximin, formulation of EOT, yielding a GAN-resemble algorithm that can be trained in an end-to-end fashion. Experiments are conducted on 2D toy datasets and images translation. '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': '- The saddle point reformulation of EOT is interesting. The proposed algorithm can be viewed as a stochastic control problem, where the terminal cost function $\\beta$ is learned so that the resulting policy approaches terminal distribution. \n- Writing is generally clear and easy to follow. Sufficient related works and preliminaries are included.\n- Experiment are extensive and include many related baselines.'}, 'weaknesses': {'value': ""- The proposed algorithm aims to minimize (12), which is not well-defined when $\\epsilon$=0, as the KL term will blow up. Even though $\\epsilon$=0 is algorithmically applicable, it makes the current algorithm disconnected from the mathematical framework. I'll be more convinced if the authors can provide additional justification (maybe connection to OT).\n\n- The proposed method is closely related to recent maximim OT [1], which consists of the same two networks (potential + policy) and the same training losses. From my understanding, the two methods coincide when $\\epsilon$=0 and $N=1$. Are the authors aware of [1]? Given that the proposed ENOT seems to work best when $\\epsilon$=0, can the author compare with [1]?\n\n- Given that DiffSB [13] was compared throughout most Sec 5, I suggest the authors to compare in Sec 5.4 to [2], which applies DiffSB to unpaired super-resolution image datasets.\n\n- While Sec 2 has introduced sufficient background and comparison between EOT and SB, which I do appreciate, I think their connection to Sec 4, which is the main content, is rather weak. Given that the proposed algorithm closely relates to dual formulation (e.g. (26) in Appendix), I suggest including those parts in Sec 2.\n\n[1] On amortizing convex conjugates for optimal transport  \n[2] Conditional Simulation Using Diffusion Schrödinger Bridges  \n""}, 'questions': {'value': '- Experiments seem to support that $\\epsilon$=0, where the dynamics reduce to flow, works much better than SDE. This seems to contradict recent insights from diffusion models [1], where SDE usually performs better than ODE on the same tasks. Can the authors comment on that?\n- why is there a ""1/|f|"" term in Alg 1, when computing the KL? And what\'s $f_{n,m}$? I understand tht $f_n$ is the drift output at time step $n$. \n\n[1] Elucidating the Design Space of Diffusion-Based Generative Models'}, 'limitations': {'value': 'Limitations are included in Sec6, where the authors mentioned the potential computational burden caused by simulation and back-prop through the SDE dynamics during training.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Entropic Neural Optimal Transport via Diffusion Processes'}, 'authors': {'value': ['Nikita Gushchin', 'Alexander Kolesov', 'Alexander Korotin', 'Dmitry P. Vetrov', 'Evgeny Burnaev']}, 'authorids': {'value': ['~Nikita_Gushchin1', '~Alexander_Kolesov1', '~Alexander_Korotin2', '~Dmitry_P._Vetrov1', '~Evgeny_Burnaev1']}, 'keywords': {'value': ['Optimal transport', 'Schrödinger Bridge', 'Entropy regularized OT', 'Neural Networks', 'Unpaired Learning']}, 'abstract': {'value': 'We propose a novel neural algorithm for the fundamental problem of computing the entropic optimal transport (EOT) plan between probability distributions which are accessible by samples. Our algorithm is based on the saddle point reformulation of the dynamic version of EOT which is known as the Schrödinger Bridge problem. In contrast to the prior methods for large-scale EOT, our algorithm is end-to-end and consists of a single learning step, has fast inference procedure, and allows handling small values of the entropy regularization coefficient which is of particular importance in some applied problems. Empirically, we show the performance of the method on several large-scale EOT tasks. The code for the ENOT solver can be found at https://github.com/ngushchin/EntropicNeuralOptimalTransport'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/0d912e03c8deec99275ebeb36c142a9c268fb1a2.pdf'}, 'supplementary_material': {'value': '/attachment/8ab8b0283f285f8bfaa4649ddd8841ee9ce9ac57.pdf'}, '_bibtex': {'value': '@inproceedings{\ngushchin2023entropic,\ntitle={Entropic Neural Optimal Transport via Diffusion Processes},\nauthor={Nikita Gushchin and Alexander Kolesov and Alexander Korotin and Dmitry P. Vetrov and Evgeny Burnaev},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=fHyLsfMDIs}\n}'}, 'paperhash': {'value': 'gushchin|entropic_neural_optimal_transport_via_diffusion_processes'}}]"
"['Alex Damian', 'Eshaan Nichani', 'Rong Ge', 'Jason Lee']",NeurIPS,Smoothing the Landscape Boosts the Signal for SGD_ Optimal Sample Complexity for Learning Single Index Models,https://neurips.cc/virtual/2023/oral/73873,2023," We focus on the task of learning a single index model $\sigma(w^\star \cdot x)$ with respect to the isotropic Gaussian distribution in $d$ dimensions. Prior work has shown that the sample complexity of learning $w^\star$ is governed by the information exponent $k^\star$ of the link function $\sigma$, which is defined as the index of the first nonzero Hermite coefficient of $\sigma$. Ben Arous et al. (2021) showed that $n \gtrsim d^{k^\star-1}$ samples suffice for learning $w^\star$ and that this is tight for online SGD. However, the CSQ lower bound for gradient based methods only shows that $n \gtrsim d^{k^\star/2}$ samples are necessary. In this work, we close the gap between the upper and lower bounds by showing that online SGD on a smoothed loss learns $w^\star$ with $n \gtrsim d^{k^\star/2}$ samples. We also draw connections to statistical analyses of tensor PCA and to the implicit regularization effects of minibatch SGD on empirical losses.",Oral 4A Optimization,https://openreview.net/pdf?id=73XPopmbXH,https://openreview.net/forum?id=73XPopmbXH,73XPopmbXH,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper studies the task of learning a single index model, where the covariates follow an isotropic Gaussian distribution. The main goal of the paper is to fill the gap between the sample size complexity of online SGD and CSQ lower bound for learning this model. On the one hand, the existing literature shows that online SGD applied directly to the loss function has a sample complexity of $d^{k^*-1}$. On the other hand, the existing CSQ lower bound shows that $d^{k^*/2}$ samples are necessary to recover the true parameters of the problem. This paper closes this gap in the sample complexity, proving that online SGD applied to the smoothed loss function can recover the true solution with a sample complexity that matches the CSQ lower bound.\n\nFive reviewers have reviewed the paper, and their overall assessment of the paper was extremely positive. I agree with this assessment and believe the paper answers a fundamental and impactful question.'}}, {'title': {'value': 'Thanks for the rebuttal'}, 'comment': {'value': 'Thank you very much to the authors for their detailed response. Regarding the clarification in the general rebuttal, I have confidence in the overall correctness of their proof and would like to increase my score to recommend an accept.'}}, {'comment': {'value': ""Thank you for your quick follow-up on my response. \n\n**About the CSQ lower bound.** I think that the clarification that you provided here is great and definitely worth putting as early as in the introduction.\n\n**Tensor notation.** Indeed, I had missed the definition in the appendix. This is more clear now. Note that in Definition 5, the sum is missing (or you are using Einstein summation convention, but I didn't see written anywhere, and I don't think most readers are familiar with it). \nAlso, there is a small typo l.433. \n\nThank you also for the other answers.\n\n----------------------\n\nTo sum up, the authors have addressed very well my comments, suggesting appropriate updates when necessary. Thus I wish to keep my grade. ""}}, {'comment': {'value': '### Additional Remarks\n\n> is it a suggestion for better practical performances when learning single-index models, or is it an intermediary results towards proving improved convergence bounds for SGD?\n\nOur original inspiration was to understand how the implicit regularization effects of SGD could lead to better sample complexity guarantees. However, there has also been considerable effort in the community to replace the implicit regularization of minibatch SGD by explicit regularization. We believe that directly smoothing the landscape may provide one such avenue.\n\n> How would an algorithm with $\\lambda = \\infty$  (in the first steps) perform?\n\nAll $\\lambda > d^{1/4}$ should perform equally well in the first few steps. In particular, the SNR should not decrease as you increase $\\lambda$ (while $\\alpha$ is still small). However, once $\\alpha$ is large it is necessary to reduce the smoothing to obtain a good $\\epsilon$ dependence (e.g. $d/\\epsilon$ as in Theorem 1).\n\n> When referring to [1], it is written many times that $d^{k^\\star-1}$ samples are necessary (up to log factors), however my understanding is that this assumes $k^\\star \\ge 2$.\n\nThat is correct, the full sample complexity (including the $\\epsilon$ dependence) is $d^{k^\\star - 1} + d/\\epsilon$. Because our paper focuses on the case $k^\\star > 2$ (lines 137-138) we chose to omit the $d/\\epsilon$ term which captures the convergence rate after SGD has escaped the low SNR regime and $\\alpha \\ge \\Omega(1)$. However, as this changes the sample complexity when $k^\\star = 1$, we will amend the discussion to be correct for any $k^\\star$. In particular, dropping the $\\epsilon$ dependency gives that online SGD succeeds when $n \\gtrsim d^{\\max(1,k^\\star-1)}$ and smoothed online SGD succeeds when $n \\gtrsim d^{\\max(1,k^\\star/2)}$.\n\n> I.86 what is $r$?\n\nThank you for catching that –\xa0the cited result applies to multi-index models where $f^\\star(x) = g(x \\cdot u_1,\\ldots,x \\cdot u_r)$ and $r$ is the number of indices. For a single index model, $r = 1$ so the result should just be $n \\gtrsim d^2$. We have corrected this typo.\n\n> Why do you consider the correlation loss rather than the square loss? I think the two would be equivalent; however it is quite unusual to optimize the correlation loss.\n\nBecause our parameters are constrained to the sphere, there is no difference between the correlation and square losses in population. In particular,\n$$\n\\mathbb{E}\\_{x,y}\\left[\\frac{1}{2}(y - f_\\theta(x))^2\\right] = \\mathbb{E}\\_{x,y}\\left[1 - yf_\\theta(x)\\right].\n$$\nThe difference is that the noise structure is changed due to the additional $f_\\theta(x)^2$  term. We believe that if you directly smooth the model, rather than smoothing the loss, our analysis should still go through. However, the correlation loss significantly simplifies the computations.\n\n> Thm 1: maybe it would be good to remind that $w_0 \\cdot w^\\star \\gtrsim d^{-1/2}$ can be guaranteed with probability 1/2.\n\nThank you for the suggestion. We\'ve added this to the discussion immediately after Theorem 1.\n\n> The statement of Thm 1 is a bit confusing. Certainly it is false that all stepsizes satisfying the O(.) bounds do not satisfy the statement (I can take the stepsizes to be 0), but maybe what you mean is that there exists a choice of stepsizes with these bounds that satisfy the statement?\n\nThank you for catching that. We\'ve amended the theorem to read ""There exists a choice of $T_1,\\eta_t$ satisfying ...""'}}, {'comment': {'value': 'We apologize for leaving some remarks unanswered. Please let us know if we missed any additional questions you had or if anything is not clear.\n\n### About the CSQ Lower Bound\n\nWe attempted to make explicit throughout the paper that the lower bound only applies to CSQ algorithms (e.g. lines 6-7 in the abstract and lines 31-32, 52-53 in the introduction). Regarding the claims of optimality, learning single index models falls under the class of problems in which there is a conjectured statistical-computational gap. In particular, the information theoretic lower bound for learning a single index model is $n \\gtrsim d$, independent of $k^\\star$. However, it is widely believed that no computationally efficient algorithm can solve the problem given only $O(d)$ samples for complicated link functions. Similar problems that exhibit a computational-statistical gap are tensor PCA, community detection, sparse PCA, and planted clique [1,2,3,4].\n\nNone of these problems have rigorous lower bounds of the form: no polynomial time algorithm can solve this problem with fewer than $X$ samples. Such rigorous lower bounds are out of reach for current techniques. The strongest lower bounds for such problems generally use either the statistical query, low degree polynomial, or sum-of-squares framework to limit the class of learning algorithms so that a lower bound can be proven. However, it is widely believed that these statistical-computational gaps extend to all computationally efficient algorithms in the presence of mild label noise.\n\nWe will update the introduction to add a discussion of the conjectured computational-statistical gap and to emphasize that $d^{k^\\star/2}$ is the conjectured statistical threshold for this problem among computationally efficient algorithms, although we only prove the lower bound for the class of CSQ algorithms.\n\n[1] Feldman et al., 2012, Statistical Algorithms and a Lower Bound for Detecting Planted Cliques\n\n[2] Diakonikolas & Kane, 2017, Statistical query lower bounds for robust estimation of high-dimensional gaussians and gaussian mixtures\n\n[3] Goel et al., 2020, Statistical-Query Lower Bounds via Functional Gradients\n\n[4] Dudeja & Hsu, 2020, Statistical Query Lower Bounds for Tensor PCA\n\n### Tensor Notation\n\nOur tensor notation is defined in Appendix A –\xa0explicitly, if $T$ is a $k$ tensor and $A$ is a $j$ tensor in $d$ dimensions with $j \\le k$ then\n$$\nT[A] = \\sum\\_{i\\_{k-j+1},\\ldots,i\\_k} T\\_{i_1,\\ldots,i\\_k} A\\_{i\\_{k-j+1},\\ldots,i\\_k}\n$$\nThis can also be interpreted as “flattening” $T$ into a $d^{k-j} \\times d^j$ dimensional matrix, flattening $A$ into a $d^j$ dimensional vector, computing the matrix vector product, then “unflattening” the resulting $d^{k-j}$ dimensional vector into a $k-j$ tensor.\n\nDue to space constraints we cannot add Appendix A to the main paper but we will add a sentence in Section 7 that provides a reference to Appendix A for our tensor notation.\n\n### Additional Remarks\n\nDue to the character limit our response overflowed into the next comment.'}}, {'comment': {'value': 'I thank the authors for their rebuttal. Two points:\n\n**About the CSQ lower bound**. I now understand better the comparison with the CSQ model; in particular, it is a heuristic comparison. In light of this, many phrasings of the paper seem to be overclaiming. For instance, the claim of ""optimality"" in the title corresponds to a CSQ lower bound, but it is only heuristic. Most of the introduction also hides this important subtlety. Do I understand this correctly?\n\nIt might be possible that this is a widespread confusion in the community. However, I would recommend to be much more explicit about this in the paper, especially for non-expert readers. \n\n**Tensor notation**. I\'m not sure I understand. What does it mean to ""contract"" indices? Is there properly defined somewhere in the paper? \n\nAlso, some of my remarks above were left unanswered and could be worth a clarification. '}}, {'comment': {'value': 'Yes – we will update the exposition in Section 4 (Main Results) and we will add reference to a new section in the appendix where we clarify the connection between CSQ and GD with square/correlation loss.'}}, {'title': {'value': 'Read Author Rebuttal'}, 'comment': {'value': 'Thank you for your reply. I appreciate the discussion of the variance term, and this would be great to include if there is space. If there is no space, perhaps the authors could include this sketch in the appendix.\n\nYes, I see that GD with square loss is included in CSQ. Perhaps it was not clear in the paper that this was referring to square loss, could the authors specify that?'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the detailed and thoughtful review. Please let us know if you have any further questions or if anything is still unclear.\n\n> experiments are using an analytic formulation of the smoothed loss, based on the hidden knowledge that the link functions (in the experiments) are hermite polynomials. If I understand correctly, this corresponds to an “infinite synthetic sample” setting where the expectation in the smoothed loss is calculated exactly. This wouldn’t impact the sample complexity in terms of querying the true single index model, but it raises a computational question. Is there any reason to suspect that the analysis would change if, say, at every timestep the smoothed loss was approximated empirically with fresh samples drawn from the appropriate subset of the sphere?\n\nThere are two ways to compute the smoothed gradients. The most naive way is to approximate the expectation in $L_\\lambda$ using Monte Carlo. This requires roughly $d^{k^\\star/2}$ draws of z at every step; however, it does not affect the sample complexity.\n\nThe more efficient method is the one that we used for the experiments in section 6. It uses the observation from Lemma 7 that the smoothed gradient is a function of only two parameters: $w \\cdot x$ and $\\|x\\|$. Explicitly, there exists a $g$ such that $\\nabla L_t = g(w \\cdot x, \\|x\\|)$ where the closed form for $g$ follows from Lemma 7. This $g$ can be efficiently numerically computed for any activation function $\\sigma$ in $O(1)$ time. Furthermore, this computation only needs to be done once after which this $g$ can be reused. When $\\sigma$ is a polynomial, this $g$ has a closed form (see Appendix B.3) which we used for the experiments in section 6. We’ve extended Appendix E to include a discussion of the various methods for computing the smoothed gradients.'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the detailed and thoughtful review. We’ve corrected the typos you identified and we’ll try to clarify the higher level questions below. Please let us know if you have any further questions or if anything is still unclear.\n\n> Running Algorithm 1 requires to be able to compute smoothed gradients. Is it easy to compute these?\n\nThere are two ways to compute the smoothed gradients. The most naive way is to approximate the expectation in $L_\\lambda$ using Monte Carlo. This requires roughly $d^{k^\\star/2}$ draws of z at every step; however, it does not affect the sample complexity.\n\nThe more efficient method is the one that we used for the experiments in section 6. It uses the observation from Lemma 7 that the smoothed gradient is a function of only two parameters: $w \\cdot x$ and $\\|x\\|$. Explicitly, there exists a $g$ such that $\\nabla L_t = g(w \\cdot x, \\|x\\|)$ where the closed form for $g$ follows from Lemma 7. This $g$ can be efficiently numerically computed for any activation function $\\sigma$ in $O(1)$ time. Furthermore, this computation only needs to be done once after which this $g$ can be reused. When $\\sigma$ is a polynomial, this $g$ has a closed form (see Appendix B.3) which we used for the experiments in section 6. We’ve extended Appendix E to include a discussion of the various methods for computing the smoothed gradients.\n\n> Could you detail how stochastic gradient descent is a CSQ algorithm? How rigorous are the claims of ""optimality""?\n\nYou are correct and the CSQ lower bound does not constitute a rigorous lower bound for gradient descent. We’ve included additional discussion in the CSQ section of our rebuttal.\n\n> From the proof sketch, I did not understand what is special about $\\lambda = d^{1/4}$.\n\nThis threshold shows up in the computation for the noise term in the SNR after smoothing. We’ve added an additional section in the proof sketch that computes this variance and derives the $\\lambda = d^{1/4}$ threshold. For now, we’ve added this sketch to the “Computing the Variance” section of the general rebuttal. However, we will include it in the proof sketch section of the next revision of our paper.\n\n> I did not understand how you count the sample complexity in the parallel with the CSQ lower bound.\n\nThe key is that each query can be answered with the same $n$ samples. In particular, any SQ algorithm can be implemented with probability $1-\\delta$ with $n \\ge \\tau^{-2} \\log(\\text{queries}/\\delta)$ samples: for every query $q(x,y)$ return $\\frac{1}{n} \\sum_{i=1}^n q(x_i,y_i)$. For fixed $q$ this will be of order $\\sqrt{\\frac{\\log(1/\\delta)}{n}}$ so the result follows from a union bound. As the query complexity only appears through a log and is generally assumed to be polynomially large in $d$, it is often omitted. See the CSQ section in our general rebuttal for additional discussion.\n\n> Eq. below l.259: what does this tensor notation mean?\n\n$M_n$ is defined by taking the $k$ tensor $T$ and iteratively contracting indices until you are left with a vector or a matrix. This is sometimes written using $\\mathrm{Tr}$ notation, for example if $T$ is a 6-tensor then\n$$\nM_n = \\mathrm{Tr}_{(3,4),(5,6)}(T)\n$$\nmeaning that you contract the third/fourth indices and the fifth/sixth indices of $T$ to get a matrix. For our tensor notation, we use $T[A]$ to denote the contraction of $T$ with $A$ along the last $dim(A)$ dimensions of $T$ (Definition 5). In this case $A = I_d^{\\otimes 2}$ is the tensor product of the identity matrix with itself and $M_n = T[A]$. This is the higher dimensional analogue of $M[I] = \\langle M, I \\rangle = \\mathrm{tr}(M)$ when $M$ is a matrix.'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the detailed and thoughtful review. We’ve corrected the typos you identified and we’ll try to clarify the higher level questions below. Please let us know if you have any further questions or if anything is still unclear.\n\n> Discussion of the analysis of E[|v|^2] which seems a very key part of the proof is lacking in the main body.\n\nWe originally omitted the variance calculation due to space constraints but as this is a crucial part of the proof sketch, we’ve added a brief sketch for the $\\lambda$ dependence. See the “Computing the Variance” section of our rebuttal.\n\n> The paper only studies the correlation loss which is not frequently used in practice. Could the authors at least state why they use this, and if they believe their techniques would extend to the MSE loss?\n\nBecause our parameters are constrained to the sphere, there is no difference between the correlation and MSE losses in population. In particular,\n$$\n\\mathbb{E}\\_{x,y}\\left[\\frac{1}{2}(y - f_\\theta(x))^2\\right] = \\mathbb{E}\\_{x,y}\\left[1 - yf_\\theta(x\\right].\n$$\nThe difference is that the noise structure is changed due to the additional $f_\\theta(x)^2$ term. We believe that if you directly smooth the model, rather than smoothing the loss, our analysis should still go through. However, the correlation loss significantly simplifies the computations.\n\n> The authors say in line 81 that the class of CSQ algorithms contains gradient descent. I am not certain this is true? Could the authors include a citation. Or perhaps it requires some qualifications? \n\nThe key connection is that GD with square loss only interacts with the labels $y$ through correlational queries. For example for GD with model $f_\\theta$ and with square loss you have $$\\nabla L(w;x,y) = (f_\\theta(x) - \\underbrace{y)\\nabla f_\\theta(x)}_{\\text{query}}.$$\nThe other term in the gradient only depends on the distribution of $x \\sim N(0,I_d)$ which is known so it does not enter the sample complexity. See the CSQ section of the general rebuttal for additional discussion.\n\n> In line 89 could the author explain (or at least define) what they mean by ""ERM"" or point to section 7.2\n\nWe used ERM to refer to empirical risk minimization where the goal is to directly minimize the empirical loss $L_n := \\frac{1}{n} \\sum_i L(w;x_i,y_i)$ using an algorithm like gradient descent or minibatch SGD. In this setting, each sample is seen multiple times, in contrast to the online setting studied in the rest of the paper.'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the detailed and thoughtful review. We’ve corrected the typos you identified and we’ll try to clarify the higher level questions below. Please let us know if you have any further questions or if anything is still unclear.\n\n> The main concern is the CSQ lower bound. The gradient-based algorithm for correlation loss is a correlation statistical query learner. But can gradient descent of square loss be fully described by correlation statistical query? There should be some additional term in gradient descent of square loss which is not a correlation query. It would be better to have a clarification on this problem.\n\nYou are correct that there is an extra term, but this extra term does not interact with the labels $y$. As we are in the setting where the distribution over $x \\sim N(0,I_d)$ is known, this extra term can be directly estimated by a CSQ learner. We’ve included additional details in the CSQ section of the rebuttal.\n\n> [Tan and Vershynin, 2019] also studied phase retrieval via online SGD and got a sharp bound similar to [1].\n\nThank you, we will add this reference to the revision.\n\n> How about the misspecification case when the link target function is different from the activation function? Most of the analysis in Section 5 still works well in this case.\n\nOur result naturally extends to the misspecified setting but in a somewhat nontrivial way. Let the target link function be $\\phi$ with information exponent $k^\\star$ and the learner activation be $\\sigma$ with information exponent $s^\\star$. In the SNR calculation, the signal remains unchanged but the noise is equal to $d \\lambda^{-2 s^\\star}$. Going through the rest of the proof gives that the final sample complexity is $d^{k^\\star - \\max(1,s^\\star/2)}$. Therefore when the information exponents of $\\sigma$ and $\\phi$ are equal, the analysis and final result are unchanged. However in the case when $\\sigma$ has a lower information exponent, the sample complexity is strictly worse. We will include this discussion in the next revision of our paper.\n\n> In the analysis below Line 178, how do we ensure that the gradient norm $\\|v_t\\| = O(1)$?\n\nThe derivation in this part of the proof sketch is heuristic so we do not directly track all of the error terms. In fact, $\\|v_t\\| = O(d)$ so this should be $\\eta^3 d$. We believe explicitly tracking these error terms does not add to the proof sketch but to avoid being misleading we’ve replaced the $O(\\eta_t^3)$ with $\\ldots$ to represent the higher order terms which need to be carefully bounded.\n> In Section 6, for the experiments, how do you choose the batch size and learning rate?\n\nWe give explicit formulas that we used to pick $\\eta$ and the batch size (line 231-232) for all of the experiments.\n\n> And in Figure 2, if we use the square loss for minibatch SGD training, do we need a larger sample size? It would be better to compare these two cases in the simulation to visualize the difference.\n\nWe believe that the sample complexity would remain unchanged so long as the smoothing is applied to the function $f$ rather than to the loss.\n\n > Lemma 14, what is $\\mathbb{E}\\_\\mathcal{B}$\n\nOur apologies, $\\mathcal{B} = (x,y)$ denotes the current sample; however, you are correct that this was never defined. We’ve replaced this notation throughout the paper with $\\mathbb{E}\\_{x,y}$.'}}, {'rebuttal': {'value': ""We would like to thank the reviewers for their detailed and thoughtful reviews. We’ve addressed the most common questions in this rebuttal section.\n\n## On the CSQ lower bound\n\nThe connection between the CSQ framework and gradient descent with square loss is that GD only interacts with the labels $y$ through correlational queries. For example if the model is $f_\\theta$, the gradient is equal to $$\\nabla L(w;x,y) = (f_\\theta(x) - \\underbrace{y)\\nabla f_\\theta(x)}_{\\text{query}}.$$\nThe other term in the gradient only depends on the distribution of $x \\sim N(0,I_d)$ which is known so it does not enter the sample complexity. However, we emphasize that this connection is only heuristic as the errors in GD are random while the errors in the SQ/CSQ framework are adversarial. However, such SQ/CSQ bounds have been commonly used to argue the existence of statistical-computational gaps in various learning problems [1,2,3,4].\n\n[1] Feldman et al., 2012, Statistical Algorithms and a Lower Bound for Detecting Planted Cliques\n\n[2] Diakonikolas & Kane, 2017, Statistical query lower bounds for robust estimation of high-dimensional gaussians and gaussian mixtures\n\n[3] Goel et al., 2020, Statistical-Query Lower Bounds via Functional Gradients\n\n[4] Dudeja & Hsu, 2020, Statistical Query Lower Bounds for Tensor PCA\n\n## Computing the Variance and why we need $\\lambda \\le d^{1/4}$.\n\nWe originally omitted the variance calculation due to space constraints but as this is a crucial part of the proof sketch, we’ve added a brief sketch for the $\\lambda$ dependence. This is also the part of the proof that introduces the fundamental constraint $\\lambda \\le d^{1/4}$ which is crucial for the final sample complexity. Here is the sketch:\n\nRecall that $L_\\lambda(w;x,y) = 1-y\\sigma(w \\cdot x)$. Differentiating through the smoothing operator gives:\n$$\n\t\\nabla_w L_\\lambda(w;x,y)\n\t= -y \\nabla_w~ \\mathcal{L}\\_\\lambda(\\sigma(w \\cdot x)) \\approx \\lambda^{-1} x \\mathcal{L}\\_\\lambda(\\sigma'(w \\cdot x)).\n$$\nWe have that $y = O(1)$ and $\\|x\\| = O(\\sqrt{d})$ so it suffices to bound $\\mathcal{L}\\_\\lambda(\\sigma'(w \\cdot x))$. The variance of this term is equal to:\n$$\n\t\\mathbb{E}\\_{x}[\\mathcal{L}\\_\\lambda(\\sigma'(w \\cdot x))^2] = \\mathbb{E}\\_x \\left[ \\mathbb{E}\\_{z \\sim \\mu\\_w} \\left[\\sigma'\\left(\\frac{w + \\lambda z}{\\sqrt{1 + \\lambda^2}} \\cdot x\\right)\\right]^2\\right].\n$$\nTo compute this expectation, we will create an i.i.d. copy $z'$ of $z$ and rewrite this expectation as:\n$$\n\t\\mathbb{E}\\_{x}[\\mathcal{L}\\_\\lambda(\\sigma'(w \\cdot x))^2] = \\mathbb{E}\\_x\\left[\\mathbb{E}\\_{z,z' \\sim \\mu\\_w}\\left[\\sigma'\\left(\\frac{w + \\lambda z}{\\sqrt{1 + \\lambda^2}} \\cdot x\\right)\\sigma'\\left(\\frac{w + \\lambda z'}{\\sqrt{1 + \\lambda^2}} \\cdot x\\right)\\right]\\right].\n$$\nNow we can swap the expectations and compute the expectation with respect to $x$ first using the Hermite expansion of $\\sigma$. As the first nonzero Hermite coefficient of $\\sigma'$ is $k^\\star - 1$, this variance is approximately equal to the correlation between $\\frac{w + \\lambda z}{\\sqrt{1 + \\lambda^2}}$ and $\\frac{w + \\lambda z'}{\\sqrt{1 + \\lambda^2}}$ raised to the $k^\\star-1$ power:\n$$\n\t\\mathbb{E}\\_{x}[\\mathcal{L}\\_\\lambda(\\sigma'(w \\cdot x))^2] \\approx\n\t\\mathbb{E}\\_{z,z' \\sim \\mu_w}\\left[\\left(\n\t\t\\frac{w + \\lambda z}{\\sqrt{1 + \\lambda^2}} \\cdot \\frac{w + \\lambda z'}{\\sqrt{1 + \\lambda^2}}\n\t\\right)^{k^\\star-1}\\right]\n\t= \\mathbb{E}\\_{z,z' \\sim \\mu\\_w}\\left[\\left(\\frac{1 + \\lambda^2 z \\cdot z'}{1 + \\lambda^2}\\right)^{k^\\star-1}\\right]\n$$\nAs $z,z'$ are random unit vectors, their inner product is order $d^{-1/2}$. Therefore when $\\lambda \\le d^{1/4}$, the first term in the numerator is dominant while when $\\lambda \\ge d^{1/4}$, the second term is dominant. Combining these regimes gives that the variance is of order $\\min(\\lambda,d^{1/4})^{k^\\star-1}$ which motivates our optimal choice of $\\lambda = d^{1/4}$. Combining this with the fact that $y = O(1)$ and $\\|x\\| = O(\\sqrt{d})$ gives that the gradient of the smoothed loss has variance $d\\lambda^{-2k^\\star}$ for $\\lambda \\le d^{1/4}$.""}}, {'summary': {'value': 'This paper aims to fill the gap between the sample size complexity of online SGD and CSQ lower bound for learning a single index model. Inspired by implicit regularization of minibatch SGD, the authors show that online SGD on a smoothed correlation loss only needs sample size $n=\\Omega(d^{k^*/2})$ to efficiently learn the feature direction. This smoothed loss helps us to avoid poor local minima of previous unsmoothed loss which reduces the number of samples for learning a single index model and also matches the CSQ lower bound. The authors also present a connection with a partial trace algorithm for tensor PCA.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'Overall, I found the paper well-written and easy to follow. The proof sketch in Section 5 provides a clear relation among SNR of the feature alignment, the smoothed loss, and sample complexity. The paper presents many interesting insights into bridging between smoothed loss landscape and sample complexity. I believe this paper will further help us to understand the training dynamics of minibatch SGD for learning a single-index model in future work.'}, 'weaknesses': {'value': 'The main concern is the CSQ lower bound. The gradient-based algorithm for correlation loss is a correlation statistical query learner. But can gradient descent of square loss be fully described by correlation statistical query? There should be some additional term in gradient descent of square loss which is not a correlation query. It would be better to have a clarification on this problem.'}, 'questions': {'value': '1. [Tan and Vershynin, 2019] also studied phase retrieval via online SGD and got a sharp bound similar to [1].\n2. How about the misspecification case when the link target function is different from the activation function? Most of the analysis in Section 5 still works well in this case.\n3. Footnote 1 on page 3: you should mention $T_w$ is the tangent space at $w$.\n4. Line 125: typo $He_0(x)=1$.\n5. Line 178: should it be $v_t\\perp w_t$? In the analysis below Line 178, how do we ensure that the gradient norm $||v_t||=O(1)$?\n6. Line 212, should it be $z\\perp w$?\n7. Equations below Lines 212 and 214, index $k$ should be changed into $k^*$.\n8. In Section 6, for the experiments, how do you choose the batch size and learning rate? And in Figure 2, if we use the square loss for minibatch SGD training, do we need a larger sample size? It would be better to compare these two cases in the simulation to visualize the difference.\n9. Line 433, typo\n10. Maybe you should provide references for Lemmas 4 and 5 in Section A.2. Similar to the equation below Line 272, you should distinguish Hermite polynomial and Hermite tensor in the multivariate case.\n11. In Lemma 7, you should explain the notion $z\\sim\\mathbb{S}^{d-2}$ and its relationship with $z_1$. Or use $\\text{Unif}(\\mathbb{S}^{d-2})$. Is $z_1$ the first entry of vector $z$? Similar issue for Lemma 25.\n12. Equation below Line 537: should be $\\nabla_w L_\\lambda (w)$\n13. Lemma 14, what is $\\mathbb{E}_{\\mathcal{B}}$?\n14. Below Line 692, what is $m$? It should be $q$ in Theorem 2.\n15. Equation below Line 726, $z$ in the integral should be $z_1$.\n\n=====================================================================================================\n- Tan, Y.S. and Vershynin, R., 2019. Online stochastic gradient descent with arbitrary initialization solves non-smooth, non-convex phase retrieval. arXiv preprint arXiv:1910.12837.'}, 'limitations': {'value': 'The limitations of the work are well addressed by the authors. I do not believe this work has any particular negative social impact.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper studies the sample complexity of learning a single-index function \\sigma(w*^Tx) via SGD on a smoothed correlation loss. The authors show that when k* is the first non-zero Hermite coefficient of \\sigma, with optimally tuned smoothing, defined as averaging the loss over a sphere of radius \\lambda centered at the iterate, the SGD will converge to error epsilon in d^{k*/2} + d/epsilon iterations. This improves over the iteration complexity d^{k* - 1}. This is a tight analysis, since it meets the CSQ lower bound.\n\nThe analysis is based on analyzing a certain signal-to-noise ratio which arises from comparing the alignment of the gradient with the ground truth direction, and the norm of the gradient. The authors show that when the smoothing increases, both of these terms decrease, but the norm decreases more.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- The paper achieves a significant result which enhances our understanding of SGD and achieves a known lower-bound. \n- The paper is written very clearly in a way that highlights the main analysis techniques in the main body. It is useful that the authors first explain the vanilla SGD and then move on to the smoothed case.\n- The paper explains the connection to related work and particularly Tensor PCA very well.'}, 'weaknesses': {'value': '- Discussion of the analysis of E[|v|^2] which seems a very key part of the proof is lacking in the main body. If the authors do not have space for many more details, could they include at least some intuition or a simple example (perhaps in low dimension or for a simple sigma?) for why E[|v|^2] has the stated dependence on lambda? And then if would be helpful if there were some pointers to the appendix for where the real proofs of the main steps can be found.\n- The paper only studies the correlation loss which is not frequently used in practice. Could the authors at least state why they use this, and if they believe their techniques would extend to the MSE loss?'}, 'questions': {'value': '- The authors say in line 81 that the class of CSQ algorithms contains gradient descent. I am not certain this is true? Could the authors include a citation. Or perhaps it requires some qualifications? \n- In line 86, I do not see a definition of r and p.\n- In line 89 could the author explain (or at least define) what they mean by ""ERM"" or point to section 7.2\n- Section 7.2 is somewhat confusing, because it skips from discussion general objectives to the Tensor PCA. The paragraph starting on line 287 is hard to understand (why will GD converge to the expectation over z of the gradient?\n- Line  212 there is a v that should be a z?\n'}, 'limitations': {'value': 'The authors should discuss the limitations of using the correlation loss for learning single index functions. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper considers the problem of learning single index models in high dimensions, i.e., functions of a high-dimensional parameter that only depend on a one-dimensional projection of this parameter. This paper is interested in the case where the link function (the function of the one-dimensional projection) is known to the statistician, but the direction of the projection is unknown. \n\nThis paper studies the sample complexity of stochastic gradient descent (SGD). Its contribution is to show that smoothing the gradients allows to take larger stepsizes, and thus improves the sample complexity. The papers draws the connection with similar results for tensor decomposition. Finally, as previous results suggests that SGD has the effect of locally averaging the gradients, the authors present their work as a first step towards improving the sample complexity bounds for SGD. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'This paper is well-written; in particular, the proof sketch does a good job at explaining the technical contributions of the paper. This paper proves rigorously the remarkable phenomenon that smoothing improves the sample complexity. This is a significant steps towards understanding the benefits of stochasticity in SGD.'}, 'weaknesses': {'value': 'There are a few spots where I would like some clarifications, see questions below. '}, 'questions': {'value': '*Remarks*\n\n(1) Running Algorithm 1 requires to be able to compute smoothed gradients. Is it easy to compute these? Are there closed-form formulas or do we need to use sampling over $z$? It would be nice to make this explicit as it would help to understand the significance of the results: is it a suggestion for better practical performances when learning single-index models, or is it an intermediary results towards proving improved convergence bounds for SGD?\n\n(2) Could you detail how stochastic gradient descent is a CSQ algorithm? We can show that if we use $n$ samples, then $|\\hat{q} - E_{x,y}[q(x,y)]| \\leq \\tau / n^{1/2}$ w.h.p., but not almost surely, right? Relatedly, you write that $\\tau \\approx n^{-1/2}$ is a ""heuristic"" (l.163), thus how rigorous is the CSQ lower bound? How rigorous are the claims of ""optimality""?\n\n(3) From the proof sketch, I did not understand what is special about $\\lambda = d^{1/4}$. My intuition is that smoothing with a diverging $\\lambda$ should be very close to smoothing with $\\lambda = \\infty$. How would an algorithm with $\\lambda = \\infty$ (in the first steps) perform?\n\n\n*Minor remarks.*\n\n- When referring to [1], it is written many times that $n \\geq d^{k^*-1}$ samples are necessary (up to log factors), however my understanding is that this assumes $k^* \\geq 2$.\n- l.86: what is $r$?\n- Why do you consider the correlation loss rather than the square loss? I think the two would be equivalent; however it is quite unusual to optimize the correlation loss. \n- Thm 1: maybe it would be good to remind that $w_0 \\cdot w^* \\geq d^{-1/2}$ can be guaranteed with probability 1/2. \n- The statement of Thm 1 is a bit confusing. Certainly it is false that all stepsizes satisfying the O(.) bounds do not satisfy the statement (I can take the stepsizes to be 0), but maybe what you mean is that there exists a choice of stepsizes with these bounds that satisfy the statement? \n- I did not understand how you count the sample complexity in the parallel with the CSQ lower bound. My understanding is that to get one query with precision $n^{-1/2}$, you need $n$ samples. So the total sample complexity should depend on the number $q$ of queries? In light of this, I did not understand l.163-164. \n- Eq. below l.259: what does this tensor notation mean? \n\n\n*Typo.*\n- ""nad"" -> ""and""'}, 'limitations': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'Summary: The paper closes the gap between the previously established lower bound on learning a single index model with Gaussian inputs, giving a modified learning algorithm that matches the best possible sample complexity.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'Strengths: The alteration to SGD is simple but clever, and the given arguments are quite clear.  I particularly appreciate the proof sketch showing how the choice of smoothing impacts the drift term.  Tightening the gap left by [1] is a considerable contribution.\n\n[1] Arous, Gerard Ben, Reza Gheissari, and Aukosh Jagannath. ""Online stochastic gradient descent on non-convex losses from high-dimensional inference."" The Journal of Machine Learning Research 22.1 (2021): 4788-4838.\n'}, 'weaknesses': {'value': 'Weaknesses: I may be misunderstanding, but it appears the experiments are using an analytic formulation of the smoothed loss, based on the hidden knowledge that the link functions (in the experiments) are hermite polynomials.  If I understand correctly, this corresponds to an “infinite synthetic sample” setting where the expectation in the smoothed loss is calculated exactly.  This wouldn’t impact the sample complexity in terms of querying the true single index model, but it raises a computational question.  Is there any reason to suspect that the analysis would change if, say, at every timestep the smoothed loss was approximated empirically with fresh samples drawn from the appropriate subset of the sphere?\n'}, 'questions': {'value': 'N/A'}, 'limitations': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Smoothing the Landscape Boosts the Signal for SGD: Optimal Sample Complexity for Learning Single Index Models'}, 'authors': {'value': ['Alex Damian', 'Eshaan Nichani', 'Rong Ge', 'Jason D. Lee']}, 'authorids': {'value': ['~Alex_Damian1', '~Eshaan_Nichani1', '~Rong_Ge1', '~Jason_D._Lee1']}, 'keywords': {'value': ['statistical learning', 'learning theory', 'single index model', 'gradient descent', 'stochastic gradient descent']}, 'TLDR': {'value': 'We prove that online SGD on a smoothed loss achieves optimal sample complexity for learning single index models.'}, 'abstract': {'value': 'We focus on the task of learning a single index model $\\sigma(w^\\star \\cdot x)$ with respect to the isotropic Gaussian distribution in $d$ dimensions. Prior work has shown that the sample complexity of learning $w^\\star$ is governed by the information exponent $k^\\star$ of the link function $\\sigma$, which is defined as the index of the first nonzero Hermite coefficient of $\\sigma$. Ben Arous et al. (2021) showed that $n \\gtrsim d^{k^\\star-1}$ samples suffice for learning $w^\\star$ and that this is tight for online SGD. However, the CSQ lower bound for gradient based methods only shows that $n \\gtrsim d^{k^\\star/2}$ samples are necessary. In this work, we close the gap between the upper and lower bounds by showing that online SGD on a smoothed loss learns $w^\\star$ with $n \\gtrsim d^{k^\\star/2}$ samples. We also draw connections to statistical analyses of tensor PCA and to the implicit regularization effects of minibatch SGD on empirical losses.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/a99d3df10743aef943855a7d223d123069ed9acd.pdf'}, 'supplementary_material': {'value': '/attachment/cf6198449546f66315a55be2cce0204934c8ff3b.zip'}, '_bibtex': {'value': '@inproceedings{\ndamian2023smoothing,\ntitle={Smoothing the Landscape Boosts the Signal for {SGD}: Optimal Sample Complexity for Learning Single Index Models},\nauthor={Alex Damian and Eshaan Nichani and Rong Ge and Jason D. Lee},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=73XPopmbXH}\n}'}, 'paperhash': {'value': 'damian|smoothing_the_landscape_boosts_the_signal_for_sgd_optimal_sample_complexity_for_learning_single_index_models'}}]"
"['Sungduk Yu', 'Walter Hannah', 'Liran Peng', 'Jerry Lin', 'Mohamed Aziz Bhouri', 'Ritwik Gupta', 'Björn Lütjens', 'Justus C. Will', 'Gunnar Behrens', 'Julius Busecke', 'Nora Loose', 'Charles Stern', 'Tom Beucler', 'Bryce Harrop', 'Benjamin Hillman', 'Andrea Jenney', 'Savannah L. Ferretti', 'Nana Liu', 'Animashree Anandkumar', 'Noah Brenowitz', 'Veronika Eyring', 'Nicholas Geneva', 'Pierre Gentine', 'Stephan Mandt', 'Jaideep Pathak', 'Akshay Subramaniam', 'Carl Vondrick', 'Rose Yu', 'Laure Zanna', 'Tian Zheng', 'Ryan Abernathey', 'Fiaz Ahmed', 'David Bader', 'Pierre Baldi', 'Elizabeth Barnes', 'Christopher Bretherton', 'Peter Caldwell', 'Wayne Chuang', 'Yilun Han', 'YU HUANG', 'Fernando Iglesias-Suarez', 'Sanket Jantre', 'Karthik Kashinath', 'Marat Khairoutdinov', 'Thorsten Kurth', 'Nicholas Lutsko', 'Po-Lun Ma', 'Griffin Mooers', 'J. David Neelin', 'David Randall', 'Sara Shamekh', 'Mark Taylor', 'Nathan Urban', 'Janni Yuval', 'Guang Zhang', 'Mike Pritchard']",NeurIPS,ClimSim_ A large multi-scale dataset for hybrid physics-ML climate emulation,https://neurips.cc/virtual/2023/oral/73740,2023," Modern climate projections lack adequate spatial and temporal resolution due to computational constraints. A consequence is inaccurate and imprecise predictions of critical processes such as storms. Hybrid methods that combine physics with machine learning (ML) have introduced a new generation of higher fidelity climate simulators that can sidestep Moore's Law by outsourcing compute-hungry, short, high-resolution simulations to ML emulators. However, this hybrid ML-physics simulation approach requires domain-specific treatment and has been inaccessible to ML experts because of lack of training data and relevant, easy-to-use workflows. We present ClimSim, the largest-ever dataset designed for hybrid ML-physics research. It comprises multi-scale climate simulations, developed by a consortium of climate scientists and ML researchers. It consists of 5.7 billion pairs of multivariate input and output vectors that isolate the influence of locally-nested, high-resolution, high-fidelity physics on a host climate simulator's macro-scale physical state.The dataset is global in coverage, spans multiple years at high sampling frequency, and is designed such that resulting emulators are compatible with downstream coupling into operational climate simulators. We implement a range of deterministic and stochastic regression baselines to highlight the ML challenges and their scoring. The data (https://huggingface.co/datasets/LEAP/ClimSim_high-res) and code (https://leap-stc.github.io/ClimSim) are released openly to support the development of hybrid ML-physics and high-fidelity climate simulations for the benefit of science and society.",Oral 4B Datasets & Benchmarks,https://openreview.net/pdf?id=W5If9P1xqO,https://openreview.net/forum?id=W5If9P1xqO,W5If9P1xqO,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (Oral)'}, 'comment': {'value': 'The paper proposes a climate simulation dataset and benchmark. A climate dataset with varying resolutions of climate simulated data is produced. ML models for climate simulation are likely to provide substantial gains. Past work in this area has been on simplified simulations, with limited baselines, and evaluations. The proposed work produces a dataset from a large simulation as well as multiple baselines that are evaluated for their ability to predict the simulation. The authors additionally provide baseline results for five methods and exemplary Python worksheets to get started.\n\nAll reviewers, while not climate experts, see a potential for this benchmark,  due to its size, to enable the advancement of machine learning research for climate model surrogates.\n\nAll reviewers agree for the quality of the paper. Its a well written paper, and a well-organised benchmark dataset, with associated code, documentation, and Python workbooks to compare ML surrogate model performance for climate research. The work is original and stands apart the existing available datasets related to climate research, due to its big size, varying resolutions and comprehensive evaluation setup.\n\nKey strengths include:\n- An impressive 40 TB of data, split into training and test sets\n- Three scenarios at different scales or complexity\n- Baseline results for several ML approaches (MLP, RPN, CNN, HSR, cVAE)\n- Data is hosted on the HuggingFace platform, which is excellent for visibility and ease of access. \n-  A set of Python scripts that were used to produce the baseline results, which can serve as a template for new methods\n\nReviewers did not identify major concerns, and several suggestions for improvements have been a result of in-depth interactions between authors and reviewers, during the review process. Authors further improved this work based on the suggestions of the reviewers.'}}, {'comment': {'value': 'We would like to reiterate our gratitude. Thank you very much again for your invaluable feedback. We anticipate your continued suggestions and feedback whenever they arise. Your input is truly helpful for future releases of ClimSIm.'}}, {'comment': {'value': ""Thank you very much once again for your encouraging message and the invaluable feedback you've provided, which led to the critical improvement of our manuscript. We are committed to maintaining and expanding our dataset through future releases. If you have any further suggestions or feedback in the future, we would be more than grateful to receive them.""}}, {'comment': {'value': ""We would like to extend our gratitude once more for your insightful feedback, which was critical for us to revise our manuscript for better clarity. Please don't hesitate to reach out if you have any further suggestions, feedback, or requirements.""}}, {'title': {'value': 'We have added baseline models that uses full variable set with both low-resolution and high-resolution'}, 'comment': {'value': ""Thank you once again for your constructive feedback that helped us improve our manuscript!\n\nWe would like to bring to your attention an additional update. Building upon your first comment, we have just included MLP baselines that use the comprehensive list of variables in our revised manuscript. For further details, I kindly direct your attention to the authors' shared remark #3.""}}, {'title': {'value': ""Authors' shared remarks [3/3]: Newly added MLP baseline variants""}, 'comment': {'value': 'We have incorporated supplementary experiments involving the MLP baseline that include:\n- MLP using a subset of variables with the low-resolution dataset\n- (*New*) MLP using a subset of variables with the high-resolution dataset\n- (*New*) MLP using the complete variable set with the low-resolution dataset\n- (*New*) MLP using the complete variable set with the high-resolution dataset\n\nPlease refer to newly added Section 4.2 in the main text  (as excerpted below) for details. These additional experiments aim to enhance the comprehensiveness of our Climsim dataset, thus further reinforcing its valuable contribution to the ML community.\n\n""**4.2 Skill Boost from Expanding Features and Targets**   \nWe performed an ablation of our best performing MLP baseline to demonstrate the added value of the expanded inputs and targets available in \\dataset{}, i.e. using inputs $x$ of size $d_i=617$ and targets $y\\in\\mathbb R^{d_o}$ of size $d_o=368$; see Table 1 in SI for the full list of variables. We use the same transformation described in our preprocessing workflow to compute and add condensate (cloud liquid and cloud ice) and momentum (zonal and meridional winds) tendencies to the target vector. We conducted this ablation study with both the low-resolution and the high-resolution datasets (see Section 3.1 in SI for further details regarding these MLP variants). For common elements of the target vector, using all available variables leads to a uniform improvement in prediction accuracy, especially for precipitation, in both resolutions (Figures SI7, SI8 and Table SI4). The larger errors (e.g., MAE and RMSE) observed in the high-resolution emulators are anticipated due to the increased variance of higher-resolution data. Nevertheless, the similarity of their R$^\\text{2}$ values to those of the corresponding low-resolution emulators confirms their adequate performance.""'}}, {'comment': {'value': 'I thank the authors for addressing all of my comments. I also greatly appreciate the improvement in the repo and documentation. I think this paper is definitely in the upper echelon of Dataset and Benchmark papers and I cannot wait to see what the community produces in the future.'}}, {'title': {'value': 'We have updated our figures as suggested.'}, 'comment': {'value': 'Thank you once again for your encouraging comments!\n\nWe agree that the figures (especially the texts in them) were not clear enough. We have re-uploaded both the main document and the Supplementary Information after replacing the original figures with vectorized versions. We hope this adjustment will improve the clarity and readability of our figures.'}}, {'title': {'value': 'Reply'}, 'comment': {'value': ""Thank you for addressing my comments. I'm satisfied that these changes address my points.""}}, {'comment': {'value': ""I thank the authors for their their improvements to the paper. I continue to be very excited about this paper and will argue for its acceptance. I think having these additional details will improve the impact and will update my score accordingly. \n\nOne minor detail that is just me being a bit picky: some of the figures would be much better as a pdf or re-exported with higher dpi (e.g., supplement figures 9-13). Right now, the rasterization is pretty easy to spot and isn't particularly aesthetically appealing. It's up to the authors as to whether they wish to do this though.""}}, {'comment': {'value': 'Thanks for the responses. The authors have addressed my concerns. I have increased my confidence score: 3 -> 4.'}}, {'title': {'value': 'Reply'}, 'comment': {'value': 'Thank you for the detailed answers and the improvements in the paper, appendix and online repo.'}}, {'title': {'value': ""Authors' shared remarks [2/3]: A newly added baseline encoder-decoder (ED)""}, 'comment': {'value': 'In addition to five baseline models included in the initial submission, we have added a new baseline model based on an encoder-decoder (ED) architecture. The figures and tables are updated through the manuscript accordingly (e.g., Main Figure 2; SI Figures 3, 4, 5, 6; Main Table 2; SI Tables 2, 3, 4).'}}, {'title': {'value': ""Authors' shared remarks [1/3]: Repo reorganization and quickstart""}, 'comment': {'value': 'We thank all reviewers for the valuable comments and suggestions on our GitHub Repo [https://github.com/leap-stc/ClimSim/tree/main] and landing page [https://leap-stc.github.io/ClimSim], which has led to a thorough discussion among our team and a plan to reorganize our repo and set up clear guides on quick-start and community contributions. The purpose of this plan is three-fold: 1) to offer easy onboarding workflows for both machine learning and climate science researchers, 2) to build robust structures and policies for long-term data and code maintenance and 3) to enable rigorous version control for research reproducibility.  \n\nWe have added the followings while preparing this response:\n- Automated unit test infrastructure, \n- Standardized code unifying preprocessing and evaluation,\n- Quickstart datasets for non-power users, and\n- Comprehensive introductory YouTube video [https://www.youtube.com/watch?v=M3Vz0zR1Auc].\n\nFurthermore, we have tidied up our GitHub repository (e.g., restructuring code trees and removing unused and redundant files and directories) and added a list of actions as GitHub issues (under “Issues” tab in our repo) to track our progress. Additional issues from community researchers wishing to build off ClimSim or make use of our tools are welcome and can be raised using the GitHub issues page (preferred) or by directly emailing ClimSim maintainers.\n\nFinally, we wish to assure reviewers that ClimSim will be an actively maintained set of data and tools with continued user support and future updates. Plans for the future include, but are not limited to:\n\n- Copying datasets on HuggingFace into zarr-formatted ARCO (Analysis-Ready, Cloud Optimized) versions of the ClimSim dataset,\n- Adding the ClimSim dataset to the UCI Machine Learning Repository,\n- Quickstarts for non-domain-experts who wish to quickly try out their methods on reasonably-sized datasets,\n- An online Kaggle-style competition that makes use of the to-date held-out test set we have for a private leaderboard, and\n- Adding additional unit tests to streamline future refactoring.'}}, {'title': {'value': ""Authors' response to Reviewer pLrq (4/4)""}, 'comment': {'value': '>The baselines aren\'t quite apples to apples. Having done similar projects myself, I recognize that it\'s genuinely hard to do this, but there are some basic gaps. However: (a) the MLP uses RAdam, which does decoupled weight-decay (i.e. following Loshchilov and Hutter) while the CNN uses original Adam and not AdamW; (b) the MLP is trained with a MSE, which is minimized by the conditional expectation and spreads the weights equally across the target outputs; the CNN is trained to minimize a MAE, which is minimized by the conditional median (the weighting here is required for apples-to-apples comparison).\n\nWe apologize for the inconsistencies. Due to difficulties in coordinating across so many authors, it was not feasible to control for all elements such as fully isolating effects of optimizer choice from effects of architecture. We will attempt to standardize more model parameters (including optimization) for baseline models in future ClimSim releases. Meanwhile, we have added the following text to acknowledge the inconsistencies in the beginning of Secion 3 “Baseline Models” in the SI:\n\n[Lines SI 205-211] “This section offers a detailed depiction of six baseline models. Every facet of model designs, excluding the dimensions of the input and output layers, differs among the models. We recognize that while this approach maximizes the differentiation among baseline models, such extensive degrees of freedom complicate the complete isolation of the effects arising from optimization parameter choices and those originating from the model architecture itself. In future ClimSim releases, baseline models will share more constraints (including optimization parameters) to highlight the performance difference due to model architectures.”\n\n\n>The paper would probably benefit from a separated validation and test set.\n\nAs described in Section 3, our dataset comes with a typical train/test split common in machine learning. However, in this paper, we did not use the test set in any model development / evaluation stage and used the validation set for model performance evaluation presented in our manuscript.  We will provide an additional public leaderboard on Huggingface for final performance reporting purposes, to exploit a completely independent test set, which we have held out for this purpose. Only then, the test set will be released publicly. \n\n\n>The claim that most image-to-image problems don\'t have as many outputs isn\'t really true, as many problems are multi-class problems (eg for segmentation or regression-by-classification) and often have as many outputs\n\nWe agree and have removed the text that misleadingly suggested that we have more channels in this problem compared to image-to-image problems. \n\n>Fig 1. The top-most node of the second layer of the MLP doesn\'t connect to the third-from-the-top node in the third layer of the MLP. \n\nWe have edited the schematic in Figure 1 to implement the desired connections.\n\n\n>L135 ""21,600"" comes out of nowhere. I can\'t figure this number out -- the paper suggests the discretization is 1.5 deg x 1.5 deg. If it\'s 1.5x1.5 degree, then a 180x360 degree map should be (180/1.5) * (360/1.5) = 28,000 pixels. \n\nWe agree that this number is not adequately explained in the text. As mentioned in our above responses, we have added more description regarding the “unstructured” grid [Lines 148-158].\n\n[Lines 148-158] “These data were saved at 20-minute intervals (i.e. the time step of the climate model) for 10 simulated years, resulting in 5.7 billion samples for the high-resolution simulation that uses an unstructured ``cube-sphere"" horizontal grid with 21,600 grid columns spanning the globe. This grid yields an \\textit{approximate} horizontal grid spacing of 1.5$^\\circ$, but unlike a traditional climate model that maps points across the sphere using two dimensions aligned with cardinal north/south and east/west directions, unstructured grids use a single dimension to organize the horizontal location of points. The atmospheric columns at each location and time are treated as independent samples. Thus, the total number of samples can be understood by considering that atmospheric columns at each location and time are treated as independent samples, such that 5.7 billion $\\approx$ 21,600 horizontal locations per time step $\\times$ 72-time steps per simulated day $\\times$ 3,650 simulated days).”\n\n\n>Table 2: Table 2 could benefit from re-explanation of what the particular variables are, so that the reader does not have to flip back to Table 1. I think this is feasible in the space, given the extra whitespace. The caption might benefit from more details.\n\nWe agree, and have added the descriptions of each variable to the Table 2 caption along with a more detailed explanation of the contents of the table.'}}, {'title': {'value': ""Authors' response to Reviewer pLrq (3/4)""}, 'comment': {'value': "">Results with the full data. It's surprising, at least to me, that the data doesn't use the full set of variables. I'd understand if the data were spatially-varying too (e.g., HxWx617 tensors), but if it's 1D, then I don't see why 600 inputs is too much: 600 inputs is about the size of a typical feature.\n\nWe concur. A distinctive feature of our dataset is its enhanced input and output vector dimensions, aiming to capture all causatively pertinent factors. The revised manuscript now features an MLP baseline for full vector emulation in Section 4.2 [Lines 242-254].\n\n[Lines 242-254] “4.2 Skill Boost from Expanding Features and Targets  \nWe performed an ablation of our best performing MLP baseline to demonstrate the added value of the expanded inputs and targets available in \\dataset{}, i.e. using inputs $x$ of size $d_i=617$ and targets $y\\in\\mathbb R^{d_o}$ of size $d_o=368$; see Table 1 in SI for the full list of variables. We use the same transformation described in our preprocessing workflow to compute and add condensate (cloud liquid and cloud ice) and momentum (zonal and meridional winds) tendencies to the target vector. We conducted this ablation study with both the low-resolution and the high-resolution datasets (see Section 3.1 in SI for further details regarding these MLP variants). For common elements of the target vector, using all available variables leads to a uniform improvement in prediction accuracy, especially for precipitation, in both resolutions (Figures SI7, SI8 and Table SI4). The larger errors (e.g., MAE and RMSE) observed in the high-resolution emulators are anticipated due to the increased variance of higher-resolution data. Nevertheless, the similarity of their R$^\\text{2}$ values to those of the corresponding low-resolution emulators confirms their adequate performance.”\n\n>Results with even adjacent cells tacked on to analyze spatial information.\n\nWe acknowledge the importance of considering spatial adjacency. However, integrating it can complicate the downstream simulation pipeline due to the parallel domain decomposition challenges of the host climate simulator. To facilitate future exploration in this direction, we've added a git issue to provide examples of how to identify the spatially adjacent grid columns from the simulator’s unstructured mesh, for potential pre-processing enhancements.\n\n>Even a basic integration into a downstream task might be tremendously helpful for impact. A full integration is the type of project deserving a large multi-year, multi-PI program, but even a basic test would be helpful for motivation and for going beyond the current metrics for performance.\n\nWe are glad the reviewer shares our own enthusiasm for pursuing the downstream integration test. Regretfully, even a rudimentary test demands software engineering beyond the constraints of the current review period. We are committed to undertaking this effort in the long term, with intentions to launch a subsequent competition phase centered on tests of the downstream signal. In the interim, for the proactive developers, we've added a git issue to provide necessary references to relevant literature and external code repositories exemplifying hybrid simulation, and have made a plan to generate initial documentation highlighting the distinct approach that our expanded input and output vectors will require.""}}, {'title': {'value': ""Authors' response to Reviewer pLrq (2/4)""}, 'comment': {'value': "">if the data is treating each grid sample as independent, then it's not clear where the 1D CNN comes in. It's mentioned that the inputs are 60x6, but where 60 comes from requires reading the paper carefully, and assuming that the 60 elsewhere is the same 60. Adding a simple signpost that the number of dimensions is the discretization of the atmospheric column would help tremendously.\n\nWe agree this was not adequately explained. We have modified the main text to clearly specify the discretization of the atmospheric column in Lines 158-159\n\n[Lines 158-159] “It is important to note that each sample retains a 1D structure corresponding to the vertical variation across 60 levels.”\n\n\n>Each issue is possible to resolve via some guess-work and understanding of how these sorts of simulations work (albeit in astrophysics, not climate science), but a less interested/invested reader may give up.\n\nWe apologize for this blind spot, and are very grateful for the suggestions that have reduced the barrier this will pose to future readers, and for the time spent making constructive suggestions that have improved clarity.\n\n\n>Given the hope of using ML-based models to improve simulations, I'm surprised that there are no plots of the joint density of the outputs and the ground-truth (i.e., plt.scatter(y,model(x))). I'd assume many of these target variables may be multimodal in terms of output, and many ML models may split the difference, leading to nonsense results.\n\nOur prediction problem's multidimensional and multivariate nature posed concerns about overwhelming readers. However, in alignment with the reviewer's feedback, we have created a new section in the SI (Section 4.3 “Fit Quality”; Lines SI 431-436) to add pertinent hexagonally-binned histograms (Fig. SI9 to SI16). While many variables exhibit consistent fit quality, some show notable variability between baselines, as seen with snow precipitation rate predictions. The multi-variate performance of our optimized deterministic baseline (MLP) suggests these issues are avoidable. We appreciate the reviewer's insight into the challenges that can be revealed in certain vector subsets. Our new scatterplot visualizations in the SI emphasize these and will be helpful to guide future optimization efforts.\n\n[Lines SI 431-436] “4.2 Fit Quality\n Scatter plots of truth versus prediction are shown in this section (Figures SI9 to SI16 in SI Section 8). While many variables exhibit consistent fit quality, some show notable variability between baselines, as seen with snow precipitation rate predictions. The performance of our optimized deterministic baseline (MLP) suggests these issues are avoidable. However, note that our prediction problem has a multi-variate and multi-dimensional nature.”\n\n\n>At a minimum, it may be good to compute bias for over/under prediction. It is true that biases can often be correct post-facto via a calibration factor, but knowing what out of the box performance would be is important. This is important for the non-negative variables, where errors may not be able to average out to zero: e.g., the lower tails of the noise will be truncated at zero. \n\nWe thank the review again for this comment. As answered above, the newly added figures provide the information requested in this comment. Please let us know in through OpenReview comments if you need to see other types of visual presentations. We will be happy to provide more analysis and visualizations.\n\n\n>Error bars would be helpful, especially given that the paper is proposing a dataset + benchmark. Having these would ensure there was public knowledge of the sort of variability expected. This can help identify which gains are real and which ones are likely due to lucky seeds.\n\nWe agree and thank the reviewer for the constructive suggestion. We added a measure of variability in model performance by scoring 160 of the top-performing MLP models selected from our ~8k-member HPO ensemble; the revealed variability was added as error bars and grey shadings to Figure 2, and we hope the reviewer agrees the variability is reassuringly small. New text in the SI elaborates on how the model variability was measured [SI Lines 238-242].\n\n(Quotes to be deleted)\n[SI Lines 238-242] “To provide some context on the amount of variance in model performance that can be attributed to random effects of optimization, the top 160 models were selected from our pool of 8,257 trials and scored on the validation set; the 5th to 95th percentile range of this ensemble is shown by the error bars in Figures 2a and SI3, and by the grey shading in Figures 2b-e, SI4, and SI5.”""}}, {'title': {'value': ""Authors' response to Reviewer pLrq (1/4)""}, 'comment': {'value': 'We extend our heartfelt appreciation to the reviewer for their generous commitment of time in meticulously evaluating our paper and providing us with invaluable feedback.  It is rewarding to hear that the review  “liked this paper a lot and would like to see it accepted.” We have taken the reviewer’s comments seriously and have worked hard to further improve our manuscript. We eagerly welcome ongoing discussions during this open review phase. If any of our responses warrant additional clarification or if new comments and questions come up, please let us know without hesitation. We will try our best to address these matters promptly. Thank you once again for your valuable feedback.\n\nPoint-by-point response:\n\n>Figure 1 suggests that there are 124 inputs and 128 outputs. The text in Section 3 suggests that it\'s 617 inputs and 368 outputs until Section 4 is reached and then it is explained that only 124 inputs and 128 outputs are handled in the paper and benchmark. I think the paper would be stronger if it focused from the start with the smaller number and explained clearly why the larger task couldn\'t be tackled, or perhaps showed one method on the full data.\n\nWe have acted on this by retraining a new  MLP baseline to map the complete 617 inputs to 368 outputs for both low- and high-resolution dataset, including a series of ~10,000 trial hyperparameter sweeps (refer to Section 3.1 in SI for further details). Full vector emulation improves predictions uniformly and especially for precipitation. These results have been incorporated into a new subsection in the main narrative focusing on the effects of expanding features and targets (Section 4.2 “Skill boost from Expanding Features and Targets; See Table SI4 and Figures SI7-8)\n\n\n>Much of the data is suggested to be 2D ""For 2D tensors, the dimensions represent time and horizontal location"". I\'m not sure what horizontal location means. Is this longitude, latitude, the data after lat/lon is flattened into a single vector?\n\nWe admit the original manuscript lacked a clear description on the ‘horizontal location’. We have added more description on the climate simulator’s horizontal grid in “Section 3 - Dataset Collection” [LINES 150-154]. Briefly, the computational grid of the climate simulator uses an “unstructured” cube-sphere mesh, not a regularly gridded latitude-longitude Cartesian grid such that in a 2D tensor [time, ncol], each ncol is mapped to a specific location, e.g, (lat[ncol], lon[ncol]). \n\n[Lines 150-154] “... the high-resolution simulation that uses an unstructured ``cube-sphere"" horizontal grid with 21,600 grid columns spanning the globe. This grid yields an \\textit{approximate} horizontal grid spacing of 1.5$^\\circ$, but unlike a traditional climate model that maps points across the sphere using two dimensions aligned with cardinal north/south and east/west directions, unstructured grids use a single dimension to organize the horizontal location of points.”\n\n\n>The preprocessing steps suggest that data ""collapse horizontal location and time into a single sample dimension"". This was enormously confusing at first. Part of this is perhaps the use of ""horizontal location"" and part of it is confusion as to what sample dimension means–is it a dimension along which the sample index runs? is it the dimensionality of the sample? If I understand correctly, what this actually means is that the atmospheric columns at each location and time are treated as independent samples. So if there are T simulation steps used for training, and each simulation has K grid cells, then there are T*K samples. \n\nWe apologize for the confusion. Your understanding is correct and we have adopted your suggested text to make it clearer. Please see the updated text in Lines 148-158. \n\n[Lines 148-158] “These data were saved at 20-minute intervals (i.e. the time step of the climate model) for 10 simulated years, resulting in 5.7 billion samples for the high-resolution simulation that uses an unstructured ``cube-sphere"" horizontal grid with 21,600 grid columns spanning the globe. This grid yields an \\textit{approximate} horizontal grid spacing of 1.5$^\\circ$, but unlike a traditional climate model that maps points across the sphere using two dimensions aligned with cardinal north/south and east/west directions, unstructured grids use a single dimension to organize the horizontal location of points. The atmospheric columns at each location and time are treated as independent samples. Thus, the total number of samples can be understood by considering that atmospheric columns at each location and time are treated as independent samples, such that 5.7 billion $\\approx$ 21,600 horizontal locations per time step $\\times$ 72-time steps per simulated day $\\times$ 3,650 simulated days).”'}}, {'title': {'value': ""Authors' response to Reviewer ujho (2/2)""}, 'comment': {'value': "">Concerning the previous point, some characteristics of the final goal could be highlighted. Are there any real-world operational constraints to consider? For example, memory and computational budget, fast inference, stability? In general, I think one should we include these into the assumptions and metrics catalogue because often scale and stability/consistency are some determining factors for whether a model gets adopted or not.\n\nTo be operationally useful, ML models should avoid using more memory than the cloud-resolving subcomponents of the MMF they are meant to replace, and should ideally infer one or more orders of magnitude faster (e.g. Rasp et al. 2018 reported 20x speedup). We estimate this memory ceiling at 1 MB per grid column and inference floor at 300 ms per inference. These numbers are based on various performance tests of the climate simulator using GPUs at various HPC centers. Besides, we have included a table summarizing the inference cost (FLOPS) (see Table 2 in SI).\n\n\n>The metrics are complete. However, are there any spectral metrics to consider (as is often done with fields)? In addition, I didn’t see any breakdown of the metrics per region, time period, etc. Optimizing the best metric based on the mean is a “simple task,” but there could also be other spatiotemporal/spectral diagnostic quantities that showcase whether the model did a good job or not.\n\nWe agree those are important but nontrivial to assess at sufficient scope. Thankfully, the published benchmark and diagnostic code repository of Mooers et al. (2021) provides a convenient path to adding regional and spectral metrics with precedent in the literature. We have added a Github issue to build the necessary connector from ClimSim’s metrics to those of Mooers et al. On a related note, in the revised manuscript, we have included comprehensive 2-D global metric (R2) maps to allow some assessment of the horizontal patterns of model performance [Figures SI17 to SI20].\n\n(Ref: Mooers, G., Pritchard, M., Beucler, T., Ott, J., Yacalis, G., Baldi, P., & Gentine, P. (2021). Assessing the potential of deep learning for emulating cloud superparameterization in climate models with real-geography boundary conditions. Journal of Advances in Modeling Earth Systems, 13, e2020MS002385. https://doi.org/10.1029/2020MS002385)\n\n>Limitations: The authors addressed some of the limitations of their work. However, I'm very surprised there was no mention of the societal impact due to the processing power required. There could even be positive ones, for example:\n\\* positive could be the fact that the simulation was done on a very streamlined/efficient system;\n\\* large consortium of interested parties agreed on a dataset to ensure it isn't wasted.\nA brief statement might be worth adding.\n\nWe have added a brief positive statement to Section 3 “ClimSim Data Construction” [Lines 186-193].\n\n[Lines 186-193] “Energy use: The computing and energy costs of generating ClimSim could be viewed as wasteful and having a negative consequence for society through associated emissions. We emphasize that while it can appear large, the compute used is actually orders of magnitude less than what is consumed by operational climate prediction. Associated emissions are minimized given that our integrations were performed on energy-efficient GPU hardware. The cost must also be weighed against the potential social benefit of mitigating future energy consumption by eliminating end users' need for costly physics-based MMF simulations. Meanwhile, a large consortium of interested parties have helped agree on this dataset, to help ensure it is not wasted.” \n\n\n>The benchmark system should be more ML-like, where things are organized in a more ML fashion. While browsing, I found no clear introduction for new users as to what to look at first. For example, a better template could be - https://github.com/ashleve/lightning-hydra-template. The dataset is massive, and the challenge is great, so a more ML-like organization is necessary.\n\nWe have updated the repo and its documentation. For details, please refer to our initial comments to all reviewers on the repo reorganization and quickstart. \n\n\n>I would like to see a more complete introduction on the website posted. I assume there will be more work done (which is fine). However, I want to reiterate that although the paper is quite dense with information that may be helpful conceptually, I think the code base should also exhibit the same completeness and cater to new users.\n\nWe have updated the repo and its documentation. For details, please refer to our initial comments to all reviewers on the repo reorganization and quickstart.""}}, {'title': {'value': ""Authors' response to Reviewer ujho (1/2)""}, 'comment': {'value': 'We want to express our genuine appreciation to the reviewers for taking the time to provide such thorough feedback. We\'re really excited about the review\'s positive note that ""the paper is excellent and meets all the requirements for acceptance."" We have been working hard to tackle the reviewer\'s suggestions and make our manuscript even better in this revision. If any aspect of our response requires clarification (or additional questions or comments arise), please let us know. We\'d be very grateful for any further feedback, and we will promptly address any such inputs to the best of our ability.\n\nPoint-by-point response:\n\n>I understand that the target audience is those interested in specific parameterizations. However, there are some overlapping uses that this dataset can be used for, e.g., surrogates, hybrid model training/exploration, and process understanding. Many authors are on the paper from different fields, so other use cases can be explored using this dataset alone. This is mentioned in the limitations and other applications, but there should be more positive statements (appendix worthy) of the potential applications.\n\nWe agree and have added a new section to the SI (Section 2.4 “Dataset Applications”; Lines SI 178-187), which discusses the potential use of ClimSim dataset beyond our target parameterization problem.\n\n[Lines SI 178-187] “2.4 Data Applications  \nOur data can benefit a broader audience beyond climate modelers wishing to explore ML for sub-grid  parameterization. For climate studies, while high-frequency timestep-level outputs from simulations are rarely archived, they offer insights into convective extremes and diurnal variability. Such data opens the path to explore multi-scale interactions between rapid dynamics and broader weather and climate fluctuations. This includes a detailed examination of variables needed to constrain vertically resolved energy and water budgets and understand their variability. For the machine learning community, this dataset addresses the scarcity of large-scale regression benchmarks, common in the sciences. Such benchmarks are less common compared to prevalent industrial datasets that emphasize classification, computer vision, and NLP tasks.”\n\n\n>Often there is a gap between research and the operational world; thus, many, many ML systems don’t get used in real-world operational systems. A brief statement about who this work is for, I.e., operationally, research only, etc., might be inspirational. While keeping experiments within a self-contained system is excellent, it’s also essential to know the context system and where it will finally be used as it might spark some thought about the overall experimental design (which may sometimes warrant a reformulation of the problem or pivot).\n\nWe have added a new section in SI (Section 2.5 “Target Audiences”; Lines SI 188-203), which is dedicated to discussing the potential pool of Climsim users.\n\n[Lines SI 188-203] “2.5 Target Audiences  \nIn essence, this benchmark aims to democratize and expand access to advanced climate modeling. High-potential architectures will undergo testing in the superparameterized version of the DOE\'s primary climate model, E3SM. Successful integration would substantially reduce computational costs for the DOE when contemplating the deployment of MMF technology in climate prediction. E3SM\'s external user community, typically deterred by the extensive computational demands of superparameterized simulators, also stands to benefit. Currently, only a minority with substantial computing resources can engage with such models. A successful recipe for ClimSim could thus democratize the use of explicit convection for a broader user base. If performant architectures also prove effective in the NCAR Community Earth System Model (CESM) - the world’s most widely used open source climate simulator - the user base could expand significantly. Given its software similarities to E3SM, it is logical to expect that ClimSim\'s learnt parameterizations will be readily adaptable to CESM. Moreover, we anticipate that a successful hybrid machine learning climate simulator will bring benefits to a diverse range of industry sectors, including those vulnerable to climate risks (such as agriculture, energy, and tourism), as well as the climate risk industry itself (such as insurance and risk assessment).”'}}, {'title': {'value': ""Authors' response to Reviewer uz8R (2/2)""}, 'comment': {'value': '>Clarity: The paper is well written. One minor issue: ""10, 3D variables"" -> ""10 3D variables""\n\nWe have corrected the typo as suggested.\n\n>The documentation on github has a section on Preprocessing the Data. I would recommend reformulating it to give a clear guideline on what to do for non-domain-experts.\n\nWe have updated github documentation. For details, please refer to our initial comments on the repo reorganization and quickstart. \n\n>The Readme.txt files on huggingface should at least contain a back-ref to the github page of the benchmark dataset.\n\nWe have added a back-ref on Hugging Face repositories. For details,  please refer to our initial comments on the repo reorganization and quickstart.'}}, {'title': {'value': ""Authors' response to Reviewer uz8R (1/2)""}, 'comment': {'value': ""We appreciate the reviewer's time and insightful feedback on our paper. It's rewarding to see the recognition of key aspects of our ClimSim dataset—volume, complexity hierarchy, baseline models, and Python script repository—which we dedicated time and effort to. Our revision now reflects the reviewer's suggestions. If any points in our response are unclear or if you have new comments or questions, please inform us. We are committed to addressing them promptly.\n\nPoint-by-point response:\n\n>Instructions on how to generate more data with the help of the simulation code that was used would be a valuable add-on for, e.g. active learning. This could be the scope of a further extension.\n\nUnfortunately, the climate simulation code is tailored for specific national supercomputers and requires specialized configuration and domain expertise. Nonetheless, we already plan on providing guidance on generating more data that would benefit practitioners in the ClimSim webpage. We have added this action item to github issues. Besides, in Section 5 “Limitations and Other Applications” [Lines 356-359], we have added active learning and relevance determination as challenges of interest that can be addressed with the current data and metrics provided. \n\n[Lines 356-359] “Relevance determination and active learning: While the climate simulator code offers data generation flexibility, guidance on ideal regimes to target for improved learning would benefit the domain scientists able to run it. This question can be addressed with the current data and metrics of interest provided.”\n\n>Do improvements based on the presented dataset only improve the performance of climate simulations based on the E3SM-MMF multi-scale climate simulator of the authors? I was missing some information on the potential impact and the possibility to use the local sub-model results for other climate simulators.\n\nInsights about which models work will be of interest to other climate modeling centers, such as the effect of stochasticity, spatial dependencies and runtime-efficient architectures. ClimSim's learnt parameterizations should also be directly adaptable to the world’s most widely used open source climate simulator - the NCAR Community Earth System Model (CESM) - given its software similarities to E3SM through common code lineage. We have added this information to the SI under a new subsection on “2.5 Target Audiences” [Lines SI 188-203].\n\n[Lines SI 188-203] “2.5 Target Audiences  \nIn essence, this benchmark aims to democratize and expand access to advanced climate modeling. High-potential architectures will undergo testing in the superparameterized version of the DOE's primary climate model, E3SM. Successful integration would substantially reduce computational costs for the DOE when contemplating the deployment of MMF technology in climate prediction. E3SM's external user community, typically deterred by the extensive computational demands of superparameterized simulators, also stands to benefit. Currently, only a minority with substantial computing resources can engage with such models. A successful recipe for ClimSim could thus democratize the use of explicit convection for a broader user base. If performant architectures also prove effective in the NCAR Community Earth System Model (CESM) - the world’s most widely used open source climate simulator - the user base could expand significantly. Given its software similarities to E3SM, it is logical to expect that ClimSim's learnt parameterizations will be readily adaptable to CESM. Moreover, we anticipate that a successful hybrid machine learning climate simulator will bring benefits to a diverse range of industry sectors, including those vulnerable to climate risks (such as agriculture, energy, and tourism), as well as the climate risk industry itself (such as insurance and risk assessment).” \n\n>It is great to have raw data, including a discussion in Section 4.4. of how preprocessing could improve the performance of predictive models. However, this makes it also difficult to use the data as a benchmark for ML methods. It will be difficult to judge whether performance improvements have been achieved by better ML models or sophisticated preprocessing. Here a clear suggestion of how to use the data set by default would be helpful for the ML community.\n\nWe direct you to our initial comments regarding the repo reorganization and quickstart. While we concur on the value of a user-friendly default dataset for ease of comparison, our work uniquely offers a large-scale regression dataset to fill existing gaps.\n\n>I had to start reading and interpreting the Python scripts provided to get started. An easy access for non-domain experts to just try out their own methods is missing.\n\nWe have added a quickstart. For details, please refer to our initial comments on the repo reorganization and quickstart.""}}, {'title': {'value': ""Authors' response to Reviewer HQ4J""}, 'comment': {'value': 'We thank the reviewer for taking time to assess our manuscript and offering valuable suggestions. We are excited to hear that the reviewer found our ClimSim dataset comprehensive and our manuscript well-written and very detailed. Following the reviewer’s feedback, we have updated our manuscript accordingly. Please let us know if any of our response is unclear or if a new question or comment comes up. We will do our best to clarify any ambiguities and further comments. \n\nPoint-by-point response:\n\n>In Section Experiments, the authors only test on a low-resolution dataset. It would help the readers have a better sense of this climate dataset if the authors could also test on one subset of the high-resolution dataset.\n\nWe fully agree with the review are have been working on building and testing MLP using the high-resolution dataset. We have just finished selecting the best models from a HPO with ~10k trials and are about to evaluate them. Once finishing this task, we will incorporate the results to the manuscript and post updates here on OpenReview. \n\n>In Section 4.2, this paper considers MAE and R2. These metrics measure pixel-wise differences. For climate data, it would be good to consider some multi-scale metrics, e.g., Anomaly Correlation Coefficient (ACC) [1].\n\nACC is a popular metric for evaluating the prediction skill of global weather forecasting models, including FourCastNet, by summarizing the decorrelation of global weather patterns with lead time. However, this metric is not well-suited for ClimSim, which instead focuses on learning a spatially local machine learning parameterization rather than forecasting. To allow some assessment of the horizontal patterns, in lieu of ACC, we have generated global metric (R2) maps that reveal the geospatial structure of model performances. Please refer to Figures SI17 to SI20 in the SI of our revised manuscript.\n\n>On Page 5, line 147, could the authors describe more on the horizontal grid? For the climate dataset, I thought it would be 2D snapshots/images with temporal evolution. I am curious why only 1D signals are extracted and tested. \n\nThe predictor-corrector multi-scale scaffold of the E3SMF is spatially and temporally local with the only remaining degree of freedom being altitude. The default ClimSim experiments are aligned with this (see Fig. 1). We agree that the description of the climate model’s computational grid was not adequately described. We have added more description about the horizontal grid under Section 3 “ClimSim Dataset Construction – Dataset collection” [Lines148-159]:\n\n[Lines 148-159] “These data were saved at 20-minute intervals (i.e. the time step of the climate model) for 10 simulated years, resulting in 5.7 billion samples for the high-resolution simulation that uses an unstructured ``cube-sphere"" horizontal grid with 21,600 grid columns spanning the globe. This grid yields an \\textit{approximate} horizontal grid spacing of 1.5$^\\circ$, but unlike a traditional climate model that maps points across the sphere using two dimensions aligned with cardinal north/south and east/west directions, unstructured grids use a single dimension to organize the horizontal location of points. The atmospheric columns at each location and time are treated as independent samples. Thus, the total number of samples can be understood by considering that atmospheric columns at each location and time are treated as independent samples, such that 5.7 billion $\\approx$ 21,600 horizontal locations per time step $\\times$ 72-time steps per simulated day $\\times$ 3,650 simulated days). It is important to note that each sample retains a 1D structure corresponding to the vertical variation across 60 levels.”\n\n> On Page 5, line 185, the bracket directly goes from (3) to (5).\n\nWe have fixed the typo.'}}, {'title': {'value': ""Authors' response to Reviewer PWUd""}, 'comment': {'value': 'We appreciate the reviewer\'s time and thoughtful feedback on our manuscript. It\'s great to hear that our ClimSim dataset came across as comprehensive and promising for advancing the development of hybrid ML climate simulators. We have taken your feedback into account and made revisions accordingly. If you have any more comments or if something in our response isn\'t clear, feel free to let us know. We are committed to addressing any potential points of ambiguity and providing additional information to the best of our abilities.\n\nPoint-by-point response:\n\n> Clarity: The paper is well-organized and well-written. The results are explained clearly, although some further discussion of Table 2 should be considered in the final version\n\nWe have added some further discussion on the baseline model results in Section 4.4 “Baseline Model Results” [Lines 267-278].\n\n[Lines 267-278] “ For the global mean MAE we see the largest averaged errors for PRECC and NETSW (mean MAE > 15 W/m², Figure 2 and Table 2), where MLP clearly has the best the best skill compared to all other benchmark models. For the other variables, the global mean MAE is considerably smaller and the skill of the benchmarks model appears to be more similar in absolute numbers. While for the global mean R$^\\text{2}$ we find the lowest measurable performance for dT/dt and PRECC (mean R$^\\text{2} <$ 0.7) and in these cases, CNN gives the most skillful predictions. The other variables have larger R$^\\text{2}$ of order 0.8 or higher, which suggests that these quantities are easier to deep-learn (Table 2). For dq/dt and PRECSC global mean R$^\\text{2}$ is not an ideal evaluation metric due to negligible variability in dq/dt in the upper atmosphere and for PRECSC in the tropics in the dataset (Table 2}). \n\nAdditional tables and figures that reveal the geographic and vertical structure of these errors, fit quality, and analysis of stochastic metrics, are included in SI (Sections 4.3, 8.1, and 8.2 in SI).”\n\n> Documentation: The online dataset is available and appears to be easy to access with sufficient explanation to understand how to use it. The code repository is not yet populated.\n\nWe apologize for the inconvenience that the reviewer did not find the way to connect to the repository during the review period. Our code repository has been online (https://github.com/leap-stc/ClimSim/) since the initial submission of our manuscript; however, the code repository weblink was not shown clearly on the landing page due to the small button size (https://leap-stc.github.io/ClimSim/intro.html). We have updated the landing page and the github documentation to fix this issue. For details, please refer to our initial comments on the repo reorganization and quickstart. \n\n>On line 167, change ""24 2D variables and 10, 3D"" to either remove the comma after 10 or insert one after 24 (removing the comma seems correct).\n\nWe have fixed the typo by removing the comma, as suggested.\n\n>On line 213, suggest changing ""1-D"" to ""1D"" for consistency with the rest of the paper.\n\nWe have fixed the typo,  as suggested.'}}, {'title': {'value': 'This paper presents a largest-ever and multi-scale climate simulation dataset designed for ML-physics research.'}, 'rating': {'value': '7: Good paper, accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'This paper introduces a substantial and high-resolution climate dataset that encompasses a comprehensive range of associated factors, both in terms of temporal and spatial dimensions. The primary objective of this dataset is to address the existing gap in macro-scale hybrid-ML climate simulation research, which has been attributed to the limitations in dataset inclusiveness and the necessary expertise within the climate field. The author additionally furnishes baseline experiments of climate prediction with one of their low-resolution subsets, showcasing the versatility and utility of ClimSim.'}, 'strengths': {'value': '- This climate dataset is the largest and most physically comprehensive for hybrid-ML research. Also, a benchmark is provided to serve as a foundation for future research. \n\n- This paper is well-written and very detailed in the context of dataset and benchmark.'}, 'opportunities_for_improvement': {'value': '- In Section Experiments, the authors only test on a low-resolution dataset. It would help the readers have a better sense of this climate dataset if the authors could also test on one subset of the high-resolution dataset.\n\n- In Section 4.2, this paper considers MAE and $R^2$. These metrics measure pixel-wise differences. For climate data, it would be good to consider some multi-scale metrics, e.g., Anomaly Correlation Coefficient (ACC) [1].\n\nReference:\n\n[1] Pathak, J., Subramanian, S., Harrington, P., Raja, S., Chattopadhyay, A., Mardani, M., ... & Anandkumar, A. (2022). Fourcastnet: A global data-driven high-resolution weather model using adaptive fourier neural operators. arXiv preprint arXiv:2202.11214.'}, 'limitations': {'value': 'Yes, the authors have included a comprehensive discussion on limitations.'}, 'correctness': {'value': 'Yes, the claims in this paper are correct.'}, 'clarity': {'value': 'Yes.'}, 'relation_to_prior_work': {'value': 'Yes, this paper clearly discussed the difference between this work and the existing papers.'}, 'documentation': {'value': 'Yes, the data detail is sufficient.'}, 'ethics': {'value': 'No.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': '- On Page 5, line 147, could the authors describe more on the horizontal grid? For the climate dataset, I thought it would be 2D snapshots/images with temporal evolution. I am curious why only 1D signals are extracted and tested.  \n\n- On Page 5, line 185, the bracket directly goes from (3) to (5).'}}, {'title': {'value': 'Review'}, 'rating': {'value': '8: Top 50% of accepted papers, clear accept'}, 'confidence': {'value': '3: The reviewer is fairly confident that the evaluation is correct'}, 'summary_and_contributions': {'value': ""Update: in light of the authors' strong response, I've increased my score to 8.\n\n---------------\n\nThe paper proposes a climate simulation dataset and benchmark. ML models for climate simulation are likely to provide substantial gains. Past work in this area has been on simplified simulations, with limited baselines, and evaluations. The proposed work produces a dataset from a large simulation as well as multiple baselines that are evaluated for their ability to predict the simulation.""}, 'strengths': {'value': ""I see several clear strengths of the paper. My comments on the strengths are brief because there is not much to say. \n\n### Public well-done runs from a simulator\n\nGetting credible simulators to work properly requires expertise that is usually beyond the ML community. I do not work in climate science, but do work in another area with similar characteristic (astrophysics). Having this data available at the given scale and with the given format is incredibly helpful  and a great opportunity for the community.\n\n### Extensive benchmarking\n\nThe authors have tried a variety of flavors of methods for solving the problem and have the results in the paper. These results will be helpful for the community. \n\n### Good analysis and many extra potential directions pointed to\n\nThe paper does a good job of pointing to issues and potential opportunities for researchers. \n- While there are some additional analyses that would improve the work, the current analysis is more than adequate for a paper. \n- There are plenty of ideas for how to extend the the proposed baselines. Sometimes it is claimed that the onus falls on the researchers producing the dataset to run these extensions themselves. I'd preemptively push-back on this point. Simply having a basic version of methods is extremely helpful and often enough to get the community started.""}, 'opportunities_for_improvement': {'value': 'I see three opportunities for improvement with the paper These are longer than my strengths out of an attempt to help the authors understand my points. However, I think the weaknesses are not reasons to reject the paper. The first is a clarity issue that just requires rewriting (which I trust the authors are capable of doing). The second is more thorough analysis, which can be fixed via re-analysis of the existing data. The final ones are things that the authors may wish to do. I do not see them as critical to accepting the paper, but I do think that they would improve the final product or may be useful to provide for the community.\n\n### Clarity about inputs/outputs and precise problems solved\n\nThe paper would be substantially improved by being more direct and clear about input/output-sizes and terminology. \nHere are a few examples:\n- Figure 1 suggests that there are 124 inputs and 128 outputs. The text in Section 3 suggests that it\'s 617 inputs and 368 outputs until Section 4 is reached and then it is explained that only 124 inputs and 128 outputs are handled in the paper and benchmark. I think the paper would be stronger if it focused from the start with the smaller number and explained clearly why the larger task couldn\'t be tackled, or perhaps showed one method on the full data.\n- Much of the data is suggested to be 2D ""For 2D tensors, the dimensions represent time and horizontal location"". I\'m not sure what horizontal location means. Is this longitude, latitude, the data after lat/lon is flattened into a single vector? \n- The preprocessing steps suggest that data ""collapse horizontal location and time into a single sample dimension"". This was enormously confusing at first. Part of this is perhaps the use of ""horizontal location"" and part of it is confusion as to what sample dimension means -- is it a dimension along which the sample index runs? is it the dimensionality of the sample?  If I understand correctly, what this actually means is that the atmospheric columns at each location and time are treated as independent samples. So if there are T simulation steps used for training, and each simulation has K grid cells, then there are T*K samples. \n- if the data is treating each grid sample as independent, then it\'s not clear where the 1D CNN comes in. It\'s mentioned that the inputs are 60x6, but where 60 comes from requires reading the paper carefully, and assuming that the 60 elsewhere is the same 60. Adding a simple signpost that the number of dimensions is the discretization of the atmospheric column would help tremendously.\n\nEach issue is possible to resolve via some guess-work and understanding of how these sorts of simulations work (albeit in astrophsyics, not climate science), but a less interested/invested reader may give up.\n\n### Results could use more thoroughness\n\nThe results would use an increase in thoroughness of the analysis. Here are a few comments:\n- Given the hope of using ML-based models to improve simulations, I\'m surprised that there are no plots of the joint density of the outputs and the ground-truth (i.e., plt.scatter(y,model(x))). I\'d assume many of these target variables may be multimodal in terms of output, and many ML models may split the difference, leading to nonsense results. \n- At a minimum, it may be good to compute bias for over/under prediction. It is true that that biases can often be correct post-facto via a calibration factor, but knowing what out of the box performance would be is important. This is important for the non-negative variables, where errors may not be able to average out to zero: e.g., the lower tails of the noise will be truncated at zero. \n- Error bars would be helpful, especially given that the paper is proposing a dataset + benchmark. Having these would ensure there was public knowledge of the sort of variability expected. This can help identify which gains are real and which ones are likely due to lucky seeds. \n\n### Various experiments would improve the paper\n\nThe paper will, I think, likely to be a strong contribution to the community. There are a few things that I wish had been done, which the authors may wish to do before their release. \n- Results with the full data. It\'s surprising, at least to me, that the data doesn\'t use the full set of variables. I\'d understand if the data were spatially-varying too (e.g., HxWx617 tensors), but if it\'s 1D, then I don\'t see why 600 inputs is too much: 600 inputs is about the size of a typical feature.\n- Results with even adjacent cells tacked on to analyze spatial information. \n- Even a basic integration into a downstream task might be tremendously helpful for impact. A full integration is the type of project deserving a large multi-year, multi-PI program, but even a basic test would be helpful for motivation and for going beyond the current metrics for performance.'}, 'limitations': {'value': 'Yes, the manuscript clearly addresses these, far more so than most papers in my stack.'}, 'correctness': {'value': 'As far as I can tell, yes. However, I am not a climate scientist.'}, 'clarity': {'value': 'Largely yes, apart from input/output sizes as discussed in opportunities for improvement'}, 'relation_to_prior_work': {'value': 'I believe so, but again I am not a climate scientist.'}, 'documentation': {'value': 'Yes, I believe so.'}, 'ethics': {'value': 'No ethics concerns.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'I like this paper a lot and would like to see it accepted. I have a feedback that\'s meant to improve the paper, not meant as a criticism.\n\nVarious experimental quibbles:\n\n- The baselines aren\'t quite apples to apples. Having done similar projects myself, I recognize that it\'s genuinely hard to do this, but there are some basic gaps. However: (a) the MLP uses RAdam, which does decoupled weight-decay (i.e. following Loshchilov and Hutter) while the CNN uses original Adam and not AdamW; (b) the MLP is trained with a MSE, which is minimized by the conditional expectation and spreads the weights equally across the target outputs; the CNN is trained to minimize a MAE, which is minimized by the conditional median (the weighting here is required for apples-to-apples comparison).\n- The paper would probably benefit from a separated validation and test set. \n\nVarious paper suggestions:\n- The claim that most image-to-image problems don\'t have as many outputs isn\'t really true, as many problems are multi-class problems (eg for segmentation or regression-by-classification) and often have as many outputs\n- Fig 1. The top-most node of the second layer of the MLP doesn\'t connect to the third-from-the-top node in the third layer of the MLP. \n- L135 ""21,600"" comes out of nowhere. I can\'t figure this number out -- the paper suggests the discretization is 1.5 deg x 1.5 deg. If it\'s 1.5x1.5 degree, then a 180x360 degree map should be (180/1.5) * (360/1.5) = 28,000 pixels. \n- Table 2: Table 2 could benefit from re-explanation of what the particular variables are, so that the reader does not have to flip back to Table 1. I think this is feasible in the space, given the extra whitespace. The caption might benefit from more details'}}, {'title': {'value': 'A dataset for multi-scale climate simulations with potential impact on the accuracy of (global) climate simulations'}, 'rating': {'value': '10: Top 5% of accepted papers, seminal paper'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'The ClimSim dataset provides data to substitute highly-resolved computationally-expensive spatially-local simulation in climate simulations by ML models. The overall simulation framework is a two-scale simulation, where an ML-based surrogate is sought to replace expensive local simulations. They are required to provide macroscopic input parameters mapping inputs such as temperature fields and humidity distribution to heating tendency and rain rate, e.g.\n\nThe authors additionally provide baseline results for five methods and exemplary Python Worksheets to get started. However, a discussion of the basic performance of the baseline results is missing. The only comment is that MLP, which outperforms the other approaches in pretty much all metrics, has been ""highly tuned"".\n\nWhile I am not a climate expert, I assume that significant improvements in the ML-based surrogate models can really have a real-world impact on the accuracy of climate simulations with a relevant code (E3SM-MMF multi-scale climate simulator).\n'}, 'strengths': {'value': '* An impressive 40 TB of data, split into training and test sets\n* 3 scenarios at different scales or complexity\n* Baseline results for several ML approaches (MLP, RPN, CNN, HSR, cVAE)\n* A set of Python scripts that were used to produce the baseline results, which can serve as a template for new methods\n'}, 'opportunities_for_improvement': {'value': '* Instructions on how to generate more data with the help of the simulation code that was used would be a valuable add-on for, e.g. active learning. This could be scope of a further extension.\n* Do improvements based on the presented dataset only improve the performance of climate simulations based on the E3SM-MMF multi-scale climate simulator of the authors? I was missing some information on the potential impact and the possibility to use the local sub-model results for other climate simulators.\n* It is great to have raw data, including a discussion in Section 4.4. of how preprocessing could improve the performance of predictive models. However, this makes it also difficult to use the data as a benchmark for ML methods. It will be difficult to judge whether performance improvements have been achieved by better ML models or sophisticated preprocessing. Here a clear suggestion of how to use the data set by default would be helpful for the ML community.\n* I had to start reading and interpreting the Python scripts provided to get started. An easy access for non-domain experts to just try out their own methods is missing. \n'}, 'limitations': {'value': 'Limitations of the given approach and data set are discussed in section 5.\n'}, 'correctness': {'value': ""The paper lives up to the claims in the abstract. \n\nThe applied methodology for the creation of the dataset seems to be sound. \nI do not have the knowledge and possibility to reproduce the datasets.\n\nThe benchmark data is explained with helpful details on the datasets' characteristics in Figure 1 and more information in the appendix.\n""}, 'clarity': {'value': 'The paper is well written. \n\nOne minor issue: ""10, 3D variables"" -> ""10 3D variables""\n'}, 'relation_to_prior_work': {'value': 'Information on prior work is provided.\n'}, 'documentation': {'value': 'The documentation is sound.\n\nSuggestions for improvement:\n* The documentation on github has a section on Preprocessing the Data. I would recommend to reformulate it to give a clear guideline on what to do for non-domain-experts.\n* The Readme.txt files on huggingface should at least contain a back-ref to the github page of the benchmark dataset.'}, 'ethics': {'value': 'Not applicable. Synthetic simulation data.\n'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': ""* See the comments above.\n* The review was not a blind one, as all authors' names and affiliations were listed in the submission.\n* The supplementary material as well as the information on the github website are really helpful.""}}, {'title': {'value': 'A Massive Simulation Dataset for Investigating Parameterizations with ML methods'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'The authors present ClimSim, a dataset designed for researchers to train hybrid ML models on high-fidelity climate simulations.\nIn particular, some applications can include training emulators for cloud parameterizations and extreme rainfall physics.\nA considerable effort was made to generate an extensive dataset with over 5.7 billion pairs of physical states of different variables at a global coverage.\nThey also include some benchmark baseline ML regression methods (including some stochastic methods).\nSome standard metrics are provided to assess the performance.\nThe dataset is hosted on and easily accessible from the HuggingFace platform.\nThe code is open-source on a GitHub repo where they feature data loaders, pre-trained models, and getting-started tutorials.'}, 'strengths': {'value': '* The scale of the dataset is massive. They address the biggest problem with training extensive ML methods is the fact that they are data hungry. This is an excellent start to training large-scale models.\n* They target a wide range of relevant variables, which could be helpful for different people involved in climate science applications. There could be an overlap between the variables used and the case studies one wishes to address.\n* There are detailed preprocessing steps (which people may want to modify).\n* The data is hosted on the HuggingFace platform, which is excellent for visibility and ease of access. This is the first climate-based data.\nFrom an ML perspective, it answers some key questions:  1) The problem we are trying to solve, 2) The subsequent toy problem/reduced problem we wish to solve, 3) The training data (and structure) provided, 4) Results comparison.\n* There are some solid benchmark models which span a wide range of assumptions were included. They were evaluated fairly and consistently.\n* The authors include an excellent detailed overview of improving the proposed models based on physics-informed considerations.\n* Lastly, there was a good overview of some of the limitations and potential applications for which this dataset can be used.'}, 'opportunities_for_improvement': {'value': 'I want to preface this by saying that the paper is excellent and completes all of the requirements to be accepted. However, I have a few things to suggest to increase the impact.\n\n* I understand that the target audience is those interested in specific parameterizations. However, there are some overlapping uses that this dataset can be used for, e.g., surrogates, hybrid model training/exploration, and process understanding. Many authors are on the paper from different fields, so other use cases can be explored using this dataset alone. This is mentioned in the limitations and other applications, but there should be more positive statements (appendix worthy) of the potential applications.\n* Often there is a gap between research and the operational world; thus, many, many ML systems don’t get used in real-world operational systems. A brief statement about who this work is for, I.e., operationally, research only, etc, might be inspirational. While keeping experiments within a self-contained system is excellent, it’s also essential to know the context system and where it will finally be used as it might spark some thought about the overall experimental design (which may sometimes warrant a reformulation of the problem or pivot).\n* Concerning the previous point, some characteristics of the final goal could be highlighted. Are there any real-world operational constraints to consider? For example, memory and computational budget, fast inference, stability? In general, I think one should we include these into the assumptions and metrics catalogue because often scale and stability/consistency are some determining factors for whether a model gets adopted or not.\n* The metrics are complete. However, are there any spectral metrics to consider (as is often done with fields)? In addition, I didn’t see any breakdown of the metrics per region, time period, etc. Optimizing the best metric based on the mean is a “simple task,” but there could also be other spatiotemporal/spectral diagnostic quantities that showcase whether the model did a good job or not.'}, 'limitations': {'value': ""The authors addressed some of the limitations of their work. However, I'm very surprised there was no mention of the societal impact due to the processing power required. There could even be positive ones,  for example:\n* a positive could be the fact that the simulation was done on a very streamlined/efficient system\n* a large consortium of interested parties agreed on a dataset to ensure it isn't wasted.\n\nA brief statement might be worth adding.""}, 'correctness': {'value': 'I have some comments above in the opportunities for improvement section.'}, 'clarity': {'value': 'The paper has a good balance of domain expertise and machine learning. \nIt is also easy enough for ML researchers to understand the task.'}, 'relation_to_prior_work': {'value': 'This work covers all of the literature reviews about this work.'}, 'documentation': {'value': 'The authors have a complete overview of the data generation and collection.\nFrom an ML perspective, there are demo notebooks for users to start.\nThey also share the training procedure and resulting weights from their baseline models. \n\n\nA few suggestions for the code base:\n\n* The benchmark system should be more ML-like, where things are organized in a more ML fashion. While browsing, I found no clear introduction for new users as to what to look at first. For example, a better template could be - https://github.com/ashleve/lightning-hydra-template. The dataset is massive, and the challenge is great, so a more ML-like organization is necessary.\n* I would like to see a more complete introduction on the website posted. I assume there will be more work done (which is fine). However, I want to reiterate that although the paper is quite dense with information that may be helpful conceptually, I think the code base should also exhibit the same completeness and cater to new users.'}, 'ethics': {'value': 'To the best of my ability, I see that the authors addressed some of the ethics.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'N/A'}}, {'title': {'value': 'High Resolution Climate Data for Hybrid ML Simulations'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'A climate dataset with varying levels of high-resolution data is produced. One objective is to support the further development of Hybrid ML climate simulations, where ML can be used for the high-resolution data and these results can be fed into a traditional climate simulator. The other objective is to allow training on relatively low-resolution data and then promising models can be tested on higher-resolution data.'}, 'strengths': {'value': 'There are clear advantages to using a hybrid climate simulation, if the ML models can provide sufficient accuracy for the high-resolution data. This work will facilitate the development of such research. The dataset is comprehensive and the multiple levels of resolution allow researchers to develop ML models on a reasonably-sized dataset and then test their model with the  high-resolution dataset.'}, 'opportunities_for_improvement': {'value': 'No suggestions.'}, 'limitations': {'value': 'The limitations are sufficiently described in the paper. The limitations are ones that should be expected at this level of development of the dataset and do not detract from the contribution.'}, 'correctness': {'value': 'The paper appears to be correct.'}, 'clarity': {'value': 'The paper is well-organized and well-written. The results are explained clearly, although some further discussion of Table 2 should be considered in the final version.'}, 'relation_to_prior_work': {'value': 'The relationship between this work and previous work is explained well. The dataset in the paper opens the door for novel research on hybrid climate models.'}, 'documentation': {'value': 'The online dataset is available and appears to be easy to access with sufficient explanation to understand how to use it. The code repository is not yet populated.'}, 'ethics': {'value': 'No concerns.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'On line 167, change ""24 2D variables and 10, 3D"" to either remove the comma after 10 or insert one after 24. (Removing the comma seems correct.)\nOn line 213, suggest changing ""1-D"" to ""1D"" for consistency with the rest of the paper.'}}, {'title': {'value': 'ClimSim: A large multi-scale dataset for hybrid physics-ML climate emulation'}, 'authors': {'value': ['Sungduk Yu', 'Walter Hannah', 'Liran Peng', 'Jerry Lin', 'Mohamed Aziz Bhouri', 'Ritwik Gupta', 'Björn Lütjens', 'Justus Christopher Will', 'Gunnar Behrens', 'Julius Busecke', 'Nora Loose', 'Charles I Stern', 'Tom Beucler', 'Bryce Harrop', 'Benjamin R Hillman', 'Andrea Jenney', 'Savannah Ferretti', 'Nana Liu', 'Anima Anandkumar', 'Noah D Brenowitz', 'Veronika Eyring', 'Nicholas Geneva', 'Pierre Gentine', 'Stephan Mandt', 'Jaideep Pathak', 'Akshay Subramaniam', 'Carl Vondrick', 'Rose Yu', 'Laure Zanna', 'Tian Zheng', 'Ryan Abernathey', 'Fiaz Ahmed', 'David C Bader', 'Pierre Baldi', 'Elizabeth Barnes', 'Christopher Bretherton', 'Peter Caldwell', 'Wayne Chuang', 'Yilun Han', 'YU HUANG', 'Fernando Iglesias-Suarez', 'Sanket Jantre', 'Karthik Kashinath', 'Marat Khairoutdinov', 'Thorsten Kurth', 'Nicholas Lutsko', 'Po-Lun Ma', 'Griffin Mooers', 'J. David Neelin', 'David Randall', 'Sara Shamekh', 'Mark A Taylor', 'Nathan Urban', 'Janni Yuval', 'Guang Zhang', 'Michael Pritchard']}, 'authorids': {'value': ['~Sungduk_Yu1', 'hannah6@llnl.gov', 'liranp@uci.edu', 'jerryl9@uci.edu', '~Mohamed_Aziz_Bhouri1', '~Ritwik_Gupta1', '~Björn_Lütjens1', '~Justus_Christopher_Will1', 'gunnar.behrens@dlr.de', 'julius@ldeo.columbia.edu', '~Nora_Loose1', '~Charles_I_Stern1', 'tom.beucler@unil.ch', 'bryce.harrop@pnnl.gov', 'bhillma@sandia.gov', '~Andrea_Jenney1', 'ferretts@uci.edu', '~Nana_Liu1', '~Anima_Anandkumar1', 'nbrenowitz@nvidia.com', '~Veronika_Eyring1', '~Nicholas_Geneva1', '~Pierre_Gentine1', '~Stephan_Mandt1', '~Jaideep_Pathak1', '~Akshay_Subramaniam1', '~Carl_Vondrick2', '~Rose_Yu1', 'laure.zanna@nyu.edu', '~Tian_Zheng1', '~Ryan_Abernathey2', 'fiaz@ucla.edu', 'bader2@llnl.gov', '~Pierre_Baldi1', 'eabarnes@colostate.edu', '~Christopher_Bretherton1', 'caldwell19@llnl.gov', 'wc2227@columbia.edu', 'hanyilun1993@qq.com', '~YU_HUANG10', '~Fernando_Iglesias-Suarez1', '~Sanket_Jantre1', '~Karthik_Kashinath2', '~Marat_Khairoutdinov1', 'tkurth@nvidia.com', 'nlutsko@ucsd.edu', 'po-lun.ma@pnnl.gov', 'gmooers@uci.edu', '~J._David_Neelin1', '~David_Randall1', 'ss6287@columbia.edu', 'mataylo@sandia.gov', '~Nathan_Urban2', 'yaniyuval@gmail.com', '~Guang_Zhang1', '~Michael_Pritchard1']}, 'keywords': {'value': ['climate', 'climate modeling', 'benchmark', 'dataset', 'baseline', 'emulation', 'superparameterization', 'multi-scale modeling framework', 'physics-informed machine learning']}, 'TLDR': {'value': 'ClimSim is the largest dataset for multi-scale, physics-informed machine learning climate simulations along with a wide range of baselines for the modeling of atmospheric convection and radiation.'}, 'abstract': {'value': ""Modern climate projections lack adequate spatial and temporal resolution due to computational constraints. A consequence is inaccurate and imprecise predictions of critical processes such as storms. Hybrid methods that combine physics with machine learning (ML) have introduced a new generation of higher fidelity climate simulators that can sidestep Moore's Law by outsourcing compute-hungry, short, high-resolution simulations to ML emulators. However, this hybrid ML-physics simulation approach requires domain-specific treatment and has been inaccessible to ML experts because of lack of training data and relevant, easy-to-use workflows. We present ClimSim, the largest-ever dataset designed for hybrid ML-physics research. It comprises multi-scale climate simulations, developed by a consortium of climate scientists and ML researchers. It consists of 5.7 billion pairs of multivariate input and output vectors that isolate the influence of locally-nested, high-resolution, high-fidelity physics on a host climate simulator's macro-scale physical state.\n\nThe dataset is global in coverage, spans multiple years at high sampling frequency, and is designed such that resulting emulators are compatible with downstream coupling into operational climate simulators. We implement a range of deterministic and stochastic regression baselines to highlight the ML challenges and their scoring. The data (https://huggingface.co/datasets/LEAP/ClimSim_high-res) and code (https://leap-stc.github.io/ClimSim) are released openly to support the development of hybrid ML-physics and high-fidelity climate simulations for the benefit of science and society.""}, 'venue': {'value': 'NeurIPS 2023 Datasets and Benchmarks Oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Track/Datasets_and_Benchmarks'}, 'pdf': {'value': '/pdf/5a8458e5cddf281b2b20542465c945efe6871ccf.pdf'}, 'supplementary_material': {'value': '/attachment/39bb8dd7507ab2e5414600532a5317c28039a3ef.pdf'}, '_bibtex': {'value': '@inproceedings{\nyu2023climsim,\ntitle={ClimSim: A large multi-scale dataset for hybrid physics-{ML} climate emulation},\nauthor={Sungduk Yu and Walter Hannah and Liran Peng and Jerry Lin and Mohamed Aziz Bhouri and Ritwik Gupta and Bj{\\""o}rn L{\\""u}tjens and Justus Christopher Will and Gunnar Behrens and Julius Busecke and Nora Loose and Charles I Stern and Tom Beucler and Bryce Harrop and Benjamin R Hillman and Andrea Jenney and Savannah Ferretti and Nana Liu and Anima Anandkumar and Noah D Brenowitz and Veronika Eyring and Nicholas Geneva and Pierre Gentine and Stephan Mandt and Jaideep Pathak and Akshay Subramaniam and Carl Vondrick and Rose Yu and Laure Zanna and Tian Zheng and Ryan Abernathey and Fiaz Ahmed and David C Bader and Pierre Baldi and Elizabeth Barnes and Christopher Bretherton and Peter Caldwell and Wayne Chuang and Yilun Han and YU HUANG and Fernando Iglesias-Suarez and Sanket Jantre and Karthik Kashinath and Marat Khairoutdinov and Thorsten Kurth and Nicholas Lutsko and Po-Lun Ma and Griffin Mooers and J. David Neelin and David Randall and Sara Shamekh and Mark A Taylor and Nathan Urban and Janni Yuval and Guang Zhang and Michael Pritchard},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\nyear={2023},\nurl={https://openreview.net/forum?id=W5If9P1xqO}\n}'}, 'paperhash': {'value': 'yu|climsim_a_large_multiscale_dataset_for_hybrid_physicsml_climate_emulation'}}]"
"['Samuel Dooley', 'Rhea Sukthanker', 'John Dickerson', 'Colin White', 'Frank Hutter', 'Micah Goldblum']",NeurIPS,Rethinking Bias Mitigation_ Fairer Architectures Make for Fairer Face Recognition,https://neurips.cc/virtual/2023/oral/73878,2023," Face recognition systems are widely deployed in safety-critical applications, including law enforcement, yet they exhibit bias across a range of socio-demographic dimensions, such as gender and race.  Conventional wisdom dictates that model biases arise from biased training data.  As a consequence, previous works on bias mitigation largely focused on pre-processing the training data, adding penalties to prevent bias from effecting the model during training, or post-processing predictions to debias them, yet these approaches have shown limited success on hard problems such as face recognition.  In our work, we discover that biases are actually inherent to neural network architectures themselves.  Following this reframing, we conduct the first neural architecture search for fairness, jointly with a search for hyperparameters. Our search outputs a suite of models which Pareto-dominate all other high-performance architectures and existing bias mitigation methods in terms of accuracy and fairness, often by large margins, on the two most widely used datasets for face identification, CelebA and VGGFace2. Furthermore, these models generalize to other datasets and sensitive attributes. We release our code, models and raw data files at https://github.com/dooleys/FR-NAS.",Oral 5B Privacy/Fairness,https://openreview.net/pdf?id=1vzF4zWQ1E,https://openreview.net/forum?id=1vzF4zWQ1E,1vzF4zWQ1E,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper addresses bias mitigation with Neural Architecture Search (NAS) and Hyperparameter Optimization (i.e. finding fairer architectures in contrast to finding a good performing architecture first and then applying bias mitigation strategies). The experiments focus on bias mitigation in face recognition and they are conducted on two popular benchmarks: CelebA and VGGFace2.\u2028\n\nAll the reviewers agreed on the novelty of the approach with respect to previous work on bias mitigation, and valued the extended experiments and the relevance of the results. The reviewers also highlighted some weaknesses and made some questions, which were satisfactorily addressed during the authors feedback (the authors provided new results, clarifications, and further discussions). \n\nOne reviewer flagged the paper for ethical revision, and the paper was reviewed by two ethics reviewers. One of the ethics reviewers found no ethical issues, but recommended extending the discussion on potential social and ethical impacts. The other ethics reviewer considered the paper to have ethical issues because of the use of the CelebA dataset. This dataset has representation bias and was collected without informed consent. The ethics reviewer recommends adding a discussion on the representation bias issue to the paper (the informed consent issue was already discussed in the ethics statement). The authors have already committed to follow these recommendations for the final version of the paper.\n\nThe paper was further discussed with the NeurIPS Ethics Chairs during the AC-SAC discussion period. During this discussion the Ethics Chairs request that the authors address these specific points for follow-up in the camera-ready manuscript:\n1) To discuss if their test datasets (in Table 2, etc.) have similar ethical issues brought up\n2) To discuss the limitations of their work, particularly as it might encourage techno-solutionism in the form of removing the bias and proceeding as usual without deeper considerations.'}}, {'comment': {'value': 'I would like to thank the authors for their detailed response and for conducting the additional experiments. This confirmed my assessment about the utility and the solid results of the presented method.\n'}}, {'title': {'value': 'Response'}, 'comment': {'value': ""I have read the authors' responses and reviewers' comments. The response addresses my concern. I keep my rating. ""}}, {'comment': {'value': 'The response addresses my concerns. I encourage the authors to revise the manuscript and include the updates. I revised my score accordingly.  '}}, {'comment': {'value': 'I have read the authors\' responses and reviewers\' comments. The response addresses my concern. I raise my rating to ""Strong Accept."" I encourage the authors to add the response to the final version.'}}, {'title': {'value': 'S'}, 'comment': {'value': ""some of my concern is resolved, I'll raise my score. good job.""}}, {'rebuttal': {'value': 'We first thank all the reviewers for their insightful feedback and suggestions. Our work shows that bias in face recognition systems is actually inherent to their architectures and hyperparameters, and we can design fairer systems by searching for fair architectures, in fact significantly surpassing previous approaches. We appreciate that the reviewers find our perspective on bias mitigation interesting and fresh (**jfj2**, **kze1**, **Nw7v**, **3GhH**), our presentation clear and well-motivated (**jfj2**, **Nw7v**, **mXr9**, **3GhH**) and our experiments and analysis thorough and extensive ( **mXr9**, **3GhH**, **Nw7v**). Following suggestions made by the reviewers, we conducted further analyses and evaluations, some of which we highlight below:\n\n**New Results**\n\n1. We now conduct an analysis on fairness across age groups on AgeDB and find that our models are **Pareto-dominant**. \n\n| Dataset  | Model       | Accuracy   | Disparity  |\n|----------|-------------|------------|------------|\n| CelebA   | DPN_CosFace | 64.84      | 0.2824     |\n|          | DPN_MagFace | 60.00      | 0.3129     |\n|          | SMAC_000    | 80.23      | 0.2188     |\n|          | SMAC_010    | **82.35**  | **0.1229** |\n| VGGFace2 | DPN_SGD     | 71.866     | 0.2247     |\n|          | DPN_AdamW   | 61.316     | 0.2114     |\n|          | Rexnet_100  | 59.1833    | 0.2892     |\n|          | SMAC_301    | **81.533** | **0.1883** |\n\n2. We now study models discovered by other NAS methods (using a limited time-budget for search), and we observe that SMAC (multi-fidelity+Bayesian Optimization) optimizes compute-efficiency and performance.\n\n|                  |   Accuracy |   Rank Disparity |   Disparity |     Ratio |   Rank Ratio |   Error Ratio |\n|:-----------------|-----------:|-----------------:|------------:|----------:|-------------:|--------------:|\n| MO-ASHA_032 |   0.934739 |         0.390588 |   0.0485621 | 0.0533381 |     0.448144 |     0.542336 |\n| NSGA-II_728 |   0.868105 |         0.599085 |   0.0857516 | 0.103913  |     0.490213 |      **0.490651** |\n| SMAC_301    |  **0.963366** |         **0.230327** |   **0.0300871** | **0.0317269** |     **0.367554** |      0.582215 |\n\n\n3. We now study the effect of pre-training vs. training from scratch (Figure 2 (a) and (b) in rebuttal PDF) for face-recognition using the Dual Path Network architecture which is the basis for our search space definition. Interestingly, we find that the disparity of the pre-trained model is **much** higher compared to the model trained from scratch. Moreover, we observe that while the pre-trained model starts strong in terms of accuracy, the model trained from scratch eventually catches up. This opens up an interesting direction of future work on how to effectively exploit pre-trained models for face-recognition systems without increasing bias.\n\n**Ethical Concerns**\nWe strongly believe that our findings need to be placed into the larger sociotechnical context of facial recognition. The impacts of facial recognition technologies on individuals are well-documented, and our work considers a new way to reduce harms caused by disparities in these systems. We adhered to the [NeurIPS deprecated dataset guidelines](https://neurips.cc/public/deprecated-datasets) for our choice of datasets. MS-Celeb-1M and MegaFace are two datasets widely used by the face recognition community, even today, which we omitted from our experiments due to ethical issues. We have updated our manuscript to reflect these points and to further highlight the representational issues with CelebA as pointed out by reviewers.\n'}, 'pdf': {'value': '/pdf/02e7407946d48c9b07e683b0b69ad99309847564.pdf'}}, {'rebuttal': {'value': 'Thank you for your time and thoughtful feedback on our manuscript. We appreciate that you find our approach well-motivated, our angle of architectures and hyperparameters novel, our experiments extensive, our method reproducible and the paper well-written and easy to follow. We address each of your points below:\n\n**Weakness & Q1: Fairness performance on cross-dataset generalization** \nThank you for raising this point, and we have updated our manuscript to include Rank Disparity in Table 2. We replicate that table here below. We note that the only dataset with usable protected attribute labels is AgeDB so thus, we present that result here. We divide the ages into groups of 0-25 yrs, 25-50yrs, 50-75yrs and 75-100yrs. Further, we report the maximum disparity amongst these groups. We note that the SMAC models are Pareto-*dominant* here showing the lowest error and lowest rank disparity. \n| Dataset  | Model       | Accuracy   | Disparity  |\n|----------|-------------|------------|------------|\n| CelebA   | DPN_CosFace | 64.84      | 0.2824     |\n|          | DPN_MagFace | 60.00      | 0.3129     |\n|          | SMAC_000    | 80.23      | 0.2188     |\n|          | SMAC_010    | **82.35**  | **0.1229** |\n| VGGFace2 | DPN_SGD     | 71.866     | 0.2247     |\n|          | DPN_AdamW   | 61.316     | 0.2114     |\n|          | Rexnet_100  | 59.1833    | 0.2892     |\n|          | SMAC_301    | **81.533** | **0.1883** |\n\n**Q2: Why are these architectures more fair?**\nThank you for your question. We precisely search for a recurring Dual Path Network block in-terms of architecture. The handcrafted DPN block contains a Conv3x3Bn (Conv 3x3 followed by batchnorm), BnConv5x5 (batch norm followed by 5x5 convolution) and BnConv3x3 ( batch norm followed by 5x5 convolution). Amongst the architectures, we find a strong preference for the BnConv3x3 operation (every architecture containing at least one or more of such operations). Furthermore, in terms of the optimal face recognition head, we surprisingly find a strong preference for “CosFace” instead of “MagFace” and “ArcFace”. We find that “ArcFace” has the least preference during search. Moreover, we also discover that the SGD optimizer often with high learning rates > 0.1 is often preferred in comparison to AdamW and Adam optimizers from our search space. \n\nThe proposed multi-objective neural architecture search and HPO simultaneously optimize two objectives, firstly the accuracy and secondly the fairness metric (e.g. rank disparity). Hence, we bias the search toward models which do not exploit the protected attribute (e.g. gender) to make classifications. We hypothesize that the SMAC models learn to use more fine grained facial features to distinguish faces instead of exploiting obvious coarse features like protected attributes (gender, race, age). We leave a more detailed analysis of the properties of learned features for future work.\n'}}, {'rebuttal': {'value': 'We’d like to first thank you for your time and thoughtful feedback on our manuscript. We appreciate that you find our presentation easy to follow, our discussion extensive and interesting. We have conducted new analysis and answer your question below:\n\n**New Results**\n\n**The Effect of Pretraining**\nWe now study the effect of pre-training vs. training from scratch (Figure 2 (a) and (b) in rebuttal PDF) for face-recognition using the Dual Path Network architecture which is the basis for our search space definition. Interestingly, we find that the disparity of the pre-trained model is **much** higher compared to the model trained from scratch.  Moreover, we observe that while the pre-trained model starts strong in terms of accuracy, the model trained from scratch eventually catches up. This opens up an interesting direction of future work on how to effectively exploit pre-trained models for face-recognition systems without increasing bias.\n\n**SMAC Pareto-dominates other NAS Methods**\nWe now study models discovered by other NAS methods (using a limited time-budget for search), and we observe that SMAC (multi-fidelity+Bayesian Optimization) optimizes compute-efficiency and performance.\n\n|                  |   Accuracy |   Rank Disparity |   Disparity |     Ratio |   Rank Ratio |   Error Ratio |\n|:-----------------|-----------:|-----------------:|------------:|----------:|-------------:|--------------:|\n| MO-ASHA_032 |   0.934739 |         0.390588 |   0.0485621 | 0.0533381 |     0.448144 |     0.542336 |\n| NSGA-II_728 |   0.868105 |         0.599085 |   0.0857516 | 0.103913  |     0.490213 |      **0.490651** |\n| SMAC_301    |  **0.963366** |         **0.230327** |   **0.0300871** | **0.0317269** |     **0.367554** |      0.582215 |\n\n\n**Fairness w.r.t. Age Groups on AgeDB**\nWe conducted an analysis on fairness across age groups on AgeDB and find that our models are **pareto-dominant**. \n\n| Dataset  | Model       | Accuracy   | Disparity  |\n|----------|-------------|------------|------------|\n| CelebA   | DPN_CosFace | 64.84      | 0.2824     |\n|          | DPN_MagFace | 60.00      | 0.3129     |\n|          | SMAC_000    | 80.23      | 0.2188     |\n|          | SMAC_010    | **82.35**  | **0.1229** |\n| VGGFace2 | DPN_SGD     | 71.866     | 0.2247     |\n|          | DPN_AdamW   | 61.316     | 0.2114     |\n|          | Rexnet_100  | 59.1833    | 0.2892     |\n|          | SMAC_301    | **81.533** | **0.1883** |\n\n\n**Training on Larger Datasets**\nWe appreciate your point that our learned architectures were not evaluated on additional very large-scale FR datasets. We did not conduct these experiments and leave them for future work since we specifically focused on datasets which have protected attribute labels, unlike Glint360K. During the rebuttal period, we were unable to obtain the WebFace360M dataset given the process and license agreement protocol. Finally, as the ethics reviewer has stated, the use of some of these datasets is controversial, MS-Celeb-1M for example is listed as a [deprecated dataset](https://neurips.cc/public/deprecated-datasets) by NeurIPS itself. \n'}}, {'rebuttal': {'value': 'Thank you for your time and thoughtful feedback on our manuscript. We appreciate that you see the novelty in our work being the first to systematically conduct a large-scale analysis on the problem of fairness face recognition with different architectures and hyperparameters. We address each of your points below.\n\n**W1: The choice of SMAC3**\nThank you for your suggestion. We agree that given the plethora of methods for multi-objective NAS+HPO, there are multiple algorithms one could choose from. Given that SMAC3 supports parallelization across GPUs and multi-fidelity search, we initially restrict ourselves to SMAC3. Following your advice, we now studied two other multi-objective methods, MOASHA [1] and NSGA-II [2] from the syne-tune[3] library, using our search space design. Note that we run the search for a limited time budget of 48 hrs, so the models discovered would likely improve with a longer search budget. We will include an extended experiment in our updated manuscript.  We present the results below:\n\n|                  |   Accuracy |   Rank Disparity |   Disparity |     Ratio |   Rank Ratio |   Error Ratio |\n|:-----------------|-----------:|-----------------:|------------:|----------:|-------------:|--------------:|\n| MO-ASHA_032 |   0.934739 |         0.390588 |   0.0485621 | 0.0533381 |     0.448144 |     0.542336 |\n| NSGA-II_728 |   0.868105 |         0.599085 |   0.0857516 | 0.103913  |     0.490213 |      **0.490651** |\n| SMAC_301    |  **0.963366** |         **0.230327** |   **0.0300871** | **0.0317269** |     **0.367554** |      0.582215 |\n\n\n[1] Schmucker, R., Donini, M., Zafar, M.B., Salinas, D. and Archambeau, C., 2021. Multi-objective asynchronous successive halving. arXiv preprint arXiv:2106.12639\n\n[2] Deb, K., Pratap, A., Agarwal, S. and Meyarivan, T.A.M.T., 2002. A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE transactions on evolutionary computation, 6(2), pp.182-197\n\n[3] Salinas, D., Seeger, M., Klein, A., Perrone, V., Wistuba, M. and Archambeau, C., 2022, September. Syne tune: A library for large scale hyperparameter tuning and reproducible research. In International Conference on Automated Machine Learning (pp. 16-1). PMLR\n\n\n\n**W2: Why is SMAC_301 the best model?**\nIn most of the fair models discovered by NAS+HPO, we see a prevalence of BnConv3x3 operation (every architecture containing at least one or more of such operations). Furthermore, in terms of the optimal face recognition head, we surprisingly find a strong preference for “CosFace” instead of “MagFace” and “ArcFace”. We find that “ArcFace” has the least preference during search. Moreover, we also discover that the SGD optimizer with high learning rates > 0.1 is often preferred in comparison to AdamW and Adam optimizers from our search space. We believe that these are just some of the important characteristics (architectural and hyper-parameter pipeline) for making models more fair.  We will include an extended discussion of these components in our updated manuscript. \n\n**W3: Gender-balanced training**\nWe have employed the training regime for fair face identification as described by [4], which shows the importance of training models with fully balanced datasets (both balanced in identities and number of images per identity). They point out how these two types of imbalances (both at training and testing time) can cause researchers to draw misleading or incorrect conclusions. Thus, balancing the training and testing data as we did in our experiments is an important step to disaggregate the disparity introduced by the model architecture and hyperparameters, from the disparity introduced by the data imbalance.\n\n[4] Cherepanova, V., Reich, S., Dooley, S., Souri, H., Goldblum, M., & Goldstein, T. (2022). A deep dive into dataset imbalance and bias in face identification. Sixth AAAI/ACM Conference on Artifical Intelligence, Ethis, and Soceity, 2023.\n\n\n**W4: Hyperparameter tuning**\nWe conduct our large scale analysis with handcrafted architectures and the hyperparameters as reported in their respective papers. In addition to this, we also study every model with 9-13 different hyperparameter combinations for each model, to allow for more flexibility in terms of optimizers, face-recognition heads, and learning rates (Section 3.2 Experimental Setup). Our goal is to compare these already strong pipelines with ones that can be discovered automatically using joint NAS+HPO. \n\n**W5&6: Clarity of writing**\nWe greatly appreciate your careful read of our paper. We have updated the manuscript to incorporate this feedback, and we will include these edits in our updated manuscript.\n'}}, {'rebuttal': {'value': 'We first thank you for your time and thoughtful feedback on our manuscript. We are glad that you find our approach novel and interesting. We address each of your questions below:\n\n**W1: Rank Disparity Definition**\nThank you for raising this point. Precisely as per the definition of rank disparity, Rank(image) = 0 if and only if Error(image) = 0. This, however, **doesn’t** necessarily imply that decreasing error would correspond to decreasing rank disparity. Unlike the ratio of errors metric, rank disparity is a much richer metric which **doesn’t**  have a strong correlation with error rate. \n\nTo probe this question, we conducted a new analysis (Figure 1 (a) in the PDF) which examines the correlation of each fairness-metric with model statistics. We compute statistics like number of parameters, model latency, number of convolutions, number of linear layers, and number of batch-norms in a model’s definition. Interestingly, we observe very low and non-significant correlations between parameter sizes and different fairness metrics. This observation supports the claim that increases in accuracy and decreases in disparity are very closely tied to the architectures and feature representations of the model, irrespective of the parameter size of the model. Hence, not constraining the parameter size helps our NAS+HPO approach search in a richer search space.\n\n**W2: Table 2 Results**\nTable 2 reports results of transfer learning from the given datasets (VGGFace2 on top and CelebA below) to the given datasets. Thus, the performance will be lower than if each model were fine-tuned or hyperparameters were optimized for each model on each dataset, or if a different pre-training dataset were used. We highlight here that the transfer learning result is strong and indicative that the representations that are learned by our novel architectures are indeed generalizable in a way that the other models are not. We have clarified this point in our updated manuscript.\n'}}, {'rebuttal': {'value': 'We thank you for your time and thoughtful feedback on our manuscript. We appreciate that you see our view on mitigating fairness bias in ML as fresh and interesting, our solution systematically devised, and our experiments straightforward to follow. Further, we are glad that you find our results insightful, inspiring and useful in practice. We address each of your questions below:\n\n**W1: The Effect of Pre-training**\nThank you for raising this important point. Prompted by your feedback, we now fine-tuned a pre-trained DPN model obtained from timm on vggface-2, as DPN is the most representative of our search space. We compare the error trajectory of this model with and without pre-training. Interestingly, we observe that while the pre-trained model starts strong in terms of accuracy, the model trained from scratch catches up quickly. And more importantly, the disparity of the pre-trained model is **much** higher compared to the model trained from scratch. You can find the plot for the same in the attached PDF (Figure 2 (a) and (b)). We have updated our working draft accordingly, and we will perform more experiments to include in the updated manuscript. \n\n**W2: Theoretical Analysis**\nThe proposed multi-objective neural architecture search and HPO simultaneously optimizes two objectives, firstly the accuracy and secondly the fairness metric (e.g. rank disparity). Hence, we bias the search toward models which do not exploit the protected attribute (e.g. gender) to make classifications. This is also reflected in the reduced linear separability of the features of the models discovered by SMAC. We hypothesize that the SMAC models learn to use more fine grained facial features to distinguish faces instead of exploiting obvious coarse features like protected attributes (gender, race, age). We leave a more detailed analysis on the properties of the features learned for future work.\n\n**W3: Visualizations**\nWe appreciate this feedback. We have now conducted a new analysis in accordance with your suggestion in Figure 1 (a) of the attached PDF. Specifically, we visualize a dendrogram of the SMAC\\_301 model as well as three highly performing DPNs. The visualization shows the correlation of the logits for each image in each identity. From this analysis, we observe that SMAC\\_301 and DPN\\_CosFace\\_SGD have smaller cross-logit similarities, pointing to the fact that they do not try to exploit easier image properties like protected attributes to cluster images. The average similarities are lower for these models compared to others and the max similarities are much higher. We hypothesize that this property aids fair classifications. \n\n**Q1 SMAC3 and ParEGO Pareto-dominate other methods**\nWe agree that given the plethora of methods for multi-objective NAS+HPO, there are multiple algorithms one could choose from. Given that SMAC3 supports parallelization and multi-fidelity search, we primarily restricted ourselves to it for compute optimal search. However, following your advice, we now studied two other multi-objective methods: MOASHA [1] and NSGA-II [2] from the syne-tune [3] library, using our search space design. Note that we run the search for a limited time budget of 48 hrs, so the models discovered may improve with a longer search budget. We will include an extended search comparison in our updated manuscript.  The results are found below and indicate that our chosen method Pareto-dominates the other methods for all metrics except for Error Ratio where it is Pareto-optimal.\n\n|                  |   Accuracy |   Rank Disparity |   Disparity |     Ratio |   Rank Ratio |   Error Ratio |\n|:-----------------|-----------:|-----------------:|------------:|----------:|-------------:|--------------:|\n| MO-ASHA_032 |   0.934739 |         0.390588 |   0.0485621 | 0.0533381 |     0.448144 |     0.542336 |\n| NSGA-II_728 |   0.868105 |         0.599085 |   0.0857516 | 0.103913  |     0.490213 |      **0.490651** |\n| SMAC_301    |  **0.963366** |         **0.230327** |   **0.0300871** | **0.0317269** |     **0.367554** |      0.582215 |\n\n\n[1] Schmucker, R., Donini, M., Zafar, M.B., Salinas, D. and Archambeau, C., 2021. Multi-objective asynchronous successive halving. arXiv preprint arXiv:2106.12639\n\n[2] Deb, K., Pratap, A., Agarwal, S. and Meyarivan, T.A.M.T., 2002. A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE transactions on evolutionary computation, 6(2), pp.182-197\n\n[3] Salinas, D., Seeger, M., Klein, A., Perrone, V., Wistuba, M. and Archambeau, C., 2022, September. Syne tune: A library for large scale hyperparameter tuning and reproducible research. In International Conference on Automated Machine Learning (pp. 16-1). PMLR\n'}}, {'summary': {'value': 'The authors offer a fresh view on mitigating fairness bias in ML by leveraging neural architecture (NAS) search and hyperparameter optimization (HPO).\nThe authors demonstrate their idea on the exemplary problem of face identification, where fairness biases have tangible consequences on society. They utilize a wide range of model architectures, and define a NAS+HPO search strategy where multi-objective optimization helps balance the tradeoff between accuracy and fairness (as quantified e.g. by the rank disparity metric) .\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '+ The authors formally describe a new paradigm compared with classical bias mitigation techniques that have traditionally focused on postprocessing/rectifying ML predictions, preprocessing/balancing the datasets, or extending the loss.\n+ The solution is systematically devised and the experiments are straightforward to follow. \n+ The experimental results are insightful and helpful in practice. I find it inspiring that the NAS models generalize to new protected attributes in new datasets.\n+ The authors provide their source code besides a variety of analysis scenarios available to run via notebooks.'}, 'weaknesses': {'value': '- There was no discussion on the impact of pretraining. With the availability of a large number of foundational models, it would be very relevant to shed light into which ones generalize better and why.\n- The theoretical analysis is a. bit lacking. I was expecting more explanation of why the NAS models outperform other bias mitigation strategies and better generalize to other sensitive attributes. Is it because you are forcing the model to work harder and to avoid misusing these sensitive attributes as shortcuts when making predictions? (this would explain the reduced linear separability of protected attributes).\n- The visualization of the results could be more insightful. For example a confusion matrix / similarity matrices might be useful to conduct error analysis and shed light into the improvements facilitated by the NAS paradigm. [Such analysis](https://arxiv.org/abs/2007.06068) has revealed many characteristics of VGGFace, e.g., oftentimes, gender misclassification is due to labeling issue (e.g. the image scrapped is not of the actor, but of their opposite-gender spouse).\n\nMinor and language issues:\n- The figures could be better annotated (e.g. to explain that the two red dots in Figure 2 are two variants of DPN)\n- when comparing to other bias mitigation techniques => compared?\n- at the most extreme low errors => unclear\n- oepration\n- to supports\n- are Pareto-optimal the top performing … => are the Pareto-optimal top-performing …\n- recognititon'}, 'questions': {'value': 'Have you considered other alternatives to SMAC3 or ParEGO? How generalizable are the insights in section 4.2. to possible alternatives? '}, 'limitations': {'value': 'Sufficiently discussed'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents a new perspective on bias mitigation in machine learning models, challenging the conventional belief that one should first find the highest-performing model and then apply a bias mitigation strategy. The authors propose that finding a fairer architecture offers significant gains compared to conventional bias mitigation strategies. To test this hypothesis, they conduct the first neural architecture search for fairness and a search for hyperparameters in face recognition. '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'This paper proposes a new way to mitigate biases in face recognition systems from the perspective of fairer model architectures.\nThis paper conducts the first large-scale analysis of the impact of architectures and hyperparameters on bias in face recognition, demonstrating that the implicit convention of choosing the highest-accuracy architectures is a sub-optimal strategy for fairness.\nThis paper may be the first to apply existing tools from NAS and HPO to design a fair face recognition model automatically.'}, 'weaknesses': {'value': ""（1）According to the definition of rank difference, the smaller the model's error, the fairer the model. Therefore, the difference in model parameters will lead to a difference in model performance. There is a lack of consistent constraints on the magnitude of the model parameters when searching for a fairer structure in this paper.\n（2）Why the results in Table 2 are far worse than those reported in other papers.\n""}, 'questions': {'value': 'Please refer to the WeakNess'}, 'limitations': {'value': 'Yes'}, 'flag_for_ethics_review': {'value': ['Ethics review needed: Discrimination / Bias / Fairness Concerns']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""The paper focuses on Bias Mitigation for face identification, i.e., ensuring that face identification works “well” for different identities: gender, race, etc. Unlike prior work, which focuses on model backbone agnostic methods to mitigate bias, this work explores the relevance of the inductive bias encoded in different Deep Learning model's backbones to the bias issue. In other words, are there model backbones better at learning robust features and ensuring good performance on samples from different identities? The authors uncover model configurations that significantly improve performance over standard model backbones through an extensive empirical analysis based on Neural Architecture Search on two face identification datasets. More surprisingly, the authors prove that these backbones' performance is better or more competitive than when paired with standard bias mitigation methods. Moreover, the authors confirm the generalizability of the configurations uncovered using CelebA and VGGFace2 by testing them on other datasets, further confirming their competitive performance. Finally, the authors analyze the new model configurations and ensure that the features learned by the models are less likely to be discriminative between the biased groups confirming that they learn more diverse and robust features. \n""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""1- The work is well motivated; prior work needs to include an analysis of model architecture relevance to the bias issue. \n\n2-The results are interesting and relevant to fairness/bias community practitioners.  \n\n3-The advantages of newly discovered model configurations are explored by a well-designed empirical analysis that confirms the configurations' more robust learned features.  \n""}, 'weaknesses': {'value': '1- Some choices in the experimental design would benefit from further motivation. For example: \nWhy was the “multi-fidelity Bayesian optimization method SMAC3” chosen in particular? Are there other methods that could also work? \n\n\n2- SMAC_301 was the architecture that works well across datasets. I understand that 301 denotes the operations that constitute the novel architecture. However,  the authors do not discuss the details of these operations or why they think they are meaningful choices compared to other choices ruled out by the NPS. Some discussion here would be helpful. Why do the authors think this configuration is better able to learn non-linearly separable bias features? \n\n3- In Section 3, why are the models trained on a gender-balanced subset of the dataset? Wouldn’t one want to train on a gender-imbalanced split to see which architectures are less likely to be influenced by the imbalance? Is this the same in Section 4? Please clarify. \n\n4- In the analysis in Section 4.2, were the hyper-parameters (learning rate, optimizer) of the timm models tuned too? Or were they the ones used by the original papers? If it is the latter, then it is an unfair comparison to the SMAC models since those hyper-parameters were tuned as outlined in Section 4.1.\n\n5- From reading the paper in detail, I understand now that one of the motivations of Section 3 analysis was to limit the number of architectures explored in Section 4 (only DPN was considered since it achieved Pareto optimal performance on both datasets). However, I did not get that from the first read, so further clarification in the text about that would be helpful. \n\n6- In Section 3, the hyper-parameters of the different models were not optimized. It is likely very computationally expensive. Nevertheless, it does undermine some elements of the analysis, so I would make that clear as limitations.  \n'}, 'questions': {'value': 'I am overall positive about this work. However, I need further clarifications as outlined in the Weakness sections, particularly questions: (2,3,4). I am happy to increase my score upon adequate further clarification. \n'}, 'limitations': {'value': ""I commend the authors for explicitly discussing their work's technical limitations and that while it improves the notion of technical fairness, the advancement could still be harmful in downstream applications. \n""}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper propose a brand new framework (NAS+HPO) to mitigate biases in FR. The discussion is extensive and interesting. But experiments on authoritative face recognition dataset are required, e.g., Ms1m, Glint360 and webface260m.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'a. The presentation is easy to follow.\nb. The discussion is extensive and interesting.\nc. The paper propose a new framework (NAS+HPO jointly) to mitigate biases in FR.'}, 'weaknesses': {'value': 'The reported FR performance of this method should be also verified in large scale FR datasets, since lots of methods just work in small datasets but always fail in large ones. Some authoritative face recognition datasets are suggested, e.g., Ms1m v3[1], Glint360K[2] and webface260m[3].\n\n[1] Lightweight face recognition challenge.\n[2] Killing Two Birds with One Stone:Efficient and Robust Training of Face Recognition CNNs by Partial FC\n[3] WebFace260M: A Benchmark Unveiling the Power of Million-Scale Deep Face Recognition'}, 'questions': {'value': 'null'}, 'limitations': {'value': 'null'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper aims at a fairer face recognition model.\n\nFirst, the authors conduct large-scale experiments to show that architectures and hyperparameters matter for fairness (Section 3). Concretely, a wide range of models in different architectures and hyperparameters are evaluated in terms of performance (metric: “Error”) and fairness (metric: Rank Disparity), showing that some models (e.g., DPN) are indeed Pareto-optimal compared to others.\n\nMotivated by this finding, unlike previous bias mitigation strategies based on a fixed neural architecture and a set of hyperparameters, the paper provides a new angle on bias mitigation by searching for fairer neural architectures and hyperparameters.\n\nThe paper designs a search strategy to satisfy three desiderata: (1) both architectures and hyperparameters are optimized, (2) both accuracy and fairness are used as the objective, and (3) the searching process should be efficient. To this end, the paper uses some existing approaches, such as SMAC, Hyperband, and ParEGO.\n\nThe results show that the proposed method is Pareto-optimal compared to existing methods on two face datasets. Furthermore, the experiments show that the proposed method can also generalize to other datasets and protected attributes.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. The proposed method is well-motivated by the experiments in Section 3 to show that architectures and hyperparameters matter for fairness.\n2. The paper gives a novel angle from architectures and hyperparameters toward bias mitigation.\n3. The paper provides insights into why this method works from the perspective of linear separability of protected attributes (L293).\n4. The experiments are extensive.\n5. In terms of the results, the proposed method is Pareto-optimal, beating existing bias mitigation methods.\n6. The code is provided for better reproducibility.\n7. The paper is well-written and easy to follow.\n'}, 'weaknesses': {'value': '## Generalization of Pareto-optimal results to different datasets\nI appreciate the results of cross-dataset generalization. However, Table 2 only shows the performance results. Therefore, whether or not the proposed method is still Pareto-optimal remains unknown.\n\n\n### Minor Comments:\n\nThe plots in Figure 2-4 are in low resolution. I suggest the authors export the plots in PDF, SVG, or EPS formats instead of image formats (e.g., jpeg).\n\nFonts in Table 1 are in a strange aspect ratio. I suggest the authors use the “adjustbox” package to adjust the table size.\n\nL300: probes[1] -> probes [1]\n\nAppendix, L806, L808: broken \\ref link to the figure. “Figure ??” -> Figure 16\n\nAppendix, Caption of Figure 17: “(b) SMAC model second last layer (b) DPN MagFace on the second last layer” -> “(c) SMAC model second last layer (d) DPN MagFace on the second last layer.”'}, 'questions': {'value': '1. Can the authors add the fairness-performance results of cross-dataset generalization instead of only showing the performance results?\n2. I appreciate the authors’ efforts in explaining why the proposed method work (L293). However, in terms of neural architecture, is there any pattern that makes some architectures more Pareto-optimal than others? This would be interesting because future works may use such a pattern to manually design a fairer architecture.\n'}, 'limitations': {'value': ' The authors have adequately addressed the limitations (L333-348). From my perspective, the paper does not have a potential negative societal impact.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Rethinking Bias Mitigation: Fairer Architectures Make for Fairer Face Recognition'}, 'authors': {'value': ['Samuel Dooley', 'Rhea Sanjay Sukthanker', 'John P Dickerson', 'Colin White', 'Frank Hutter', 'Micah Goldblum']}, 'authorids': {'value': ['~Samuel_Dooley1', '~Rhea_Sanjay_Sukthanker3', '~John_P_Dickerson1', '~Colin_White1', '~Frank_Hutter1', '~Micah_Goldblum1']}, 'keywords': {'value': ['Bias Mitigation', 'Fairness', 'Facial Recognition']}, 'abstract': {'value': 'Face recognition systems are widely deployed in safety-critical applications, including law enforcement, yet they exhibit bias across a range of socio-demographic dimensions, such as gender and race.  Conventional wisdom dictates that model biases arise from biased training data.  As a consequence, previous works on bias mitigation largely focused on pre-processing the training data, adding penalties to prevent bias from effecting the model during training, or post-processing predictions to debias them, yet these approaches have shown limited success on hard problems such as face recognition.  In our work, we discover that biases are actually inherent to neural network architectures themselves.  Following this reframing, we conduct the first neural architecture search for fairness, jointly with a search for hyperparameters. Our search outputs a suite of models which Pareto-dominate all other high-performance architectures and existing bias mitigation methods in terms of accuracy and fairness, often by large margins, on the two most widely used datasets for face identification, CelebA and VGGFace2. Furthermore, these models generalize to other datasets and sensitive attributes. We release our code, models and raw data files at https://github.com/dooleys/FR-NAS.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'We find that bias is inherent to neural network architectures and hyperparameters, yet we can mitigate it by searching for fair ones'}, 'pdf': {'value': '/pdf/723d36802e874dfdfdefe825ed0d02b8764d4369.pdf'}, '_bibtex': {'value': '@inproceedings{\ndooley2023rethinking,\ntitle={Rethinking Bias Mitigation: Fairer Architectures Make for Fairer Face Recognition},\nauthor={Samuel Dooley and Rhea Sanjay Sukthanker and John P Dickerson and Colin White and Frank Hutter and Micah Goldblum},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=1vzF4zWQ1E}\n}'}, 'paperhash': {'value': 'dooley|rethinking_bias_mitigation_fairer_architectures_make_for_fairer_face_recognition'}}]"
"['Shunyu Yao', 'Dian Yu', 'Jeffrey Zhao', 'Izhak Shafran', 'Tom Griffiths', 'Yuan Cao', 'Karthik Narasimhan']",NeurIPS,Tree of Thoughts_ Deliberate Problem Solving with Large Language Models,https://neurips.cc/virtual/2023/oral/73874,2023," Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices.Our experiments show that ToT significantly enhances language models’ problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\% of tasks, our method achieved a success rate of 74\%. Code repo with all prompts: https://github.com/princeton-nlp/tree-of-thought-llm.",Oral 4C COT/reasoning,https://openreview.net/pdf?id=5Xc1ecxO1h,https://openreview.net/forum?id=5Xc1ecxO1h,5Xc1ecxO1h,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': ""I will recommend this paper for acceptance, because reviewers felt the paper proposed an interesting approach (ysyd, fAU5, 3c3c, sEEP), and showed strong improvements over CoT (fAU5).\n\nThere was extensive conversation between reviewers and authors in the rebuttal period. Weak points were raised by reviewers and were predominantly addressed by authors in rebuttal, including (i) more tasks would be nice (ysyd, fAU5, 3c3c) to which rebuttal added more applications (gSM8K and StrategyQA), (ii) efficiency issues (fAU5), (iii) parts of the work aren’t interesting/novel enough (fAU5; “I have no doubt about its influence on the community in the short near future. However, its core novelty of applying (simple) search algorithms to LLM reasoning isn't significant enough.“), (iv) necessity of GPT4 in the pipeline (fAU5, sEEP), which was also addressed in rebuttal. \n\nAdditional baselines were suggested (3c3c, sEEP), but during reviewer and AC discussion, reviewers verified that these were optional, and that the paper meets the bar in their opinions regardless.\n\nRecommendations for the next version of the work: We recommend summarizing discussion from rebuttal in the paper, including regarding the tradeoffs of ToT v. CoT (sEEP) including efficiency trade off of CoT (fAU5), the difficulty of implementing the approach (3c3c, sEEP). The prompt details suggested by 3c3c should also be included in the next version of the paper. It would also be nice to see the results with earlier LMs+ToT included in the final paper.""}}, {'comment': {'value': ""I have carefully read the authors' responses. I would like to keep my rating. Just a quick comment for more potential ablation studies. One way to adopt LLMs to solve the Game of 24 is to ask LLMs to write a Python program -- in that case, we leave the exploration and search tasks to the program rather than LLM itself. The Python program will finish the search for the final solution through BFS or DFS. That could be a very strong baseline for ToT. This can make the comparison with CoT more comprehensive and fair -- CoT is weaker at search and exploration, but it can write programs to finish the search process.""}}, {'title': {'value': 'Thanks for reply'}, 'comment': {'value': 'Thanks for your reply!\n\n1. In both tasks, we\'ve shown GPT-3.5+ToT can outperform GPT-4+CoT, and the proposed method is not specific to GPT-4. We believe it is very possible to better prompt LLMs (e.g. GPT-3.5) or finetune LLMs (e.g. Llama) to achieve better ToT performances in the near future (e.g. while one-shot proposal prompt in game of 24 was good enough for GPT-4, changing it to three-shot helped a lot for GPT-3.5; more prompt tuning can be done to yield low-hanging fruits). \n2. Thanks for endorsing ToT\'s ""influence on the community in the short near future""! Like you said, current (open-source) LLMs might be limited in their capabilities in ToT-style generations and evaluations; also, we don\'t have enough hard tasks that challenge GPT-4+CoT\'s deliberate reasoning. Improving new models and proposing new tasks are long-term community efforts beyond a single paper, and that\'s exactly why we believe ToT\'s influence could be long-term, by pointing out what generation and evaluation capabilities LLMs should improve on, what kind of tasks should be devised to challenge LLMs, and in general, linking frontier LLM research to classic and everlasting insights at the root of AI and CogSci.'}}, {'title': {'value': 'Thanks for the rebuttal'}, 'comment': {'value': ""I appreciate the response and the new experiment results. My score remains the same for the following reasons:\n1. Though one pair of experiment comparison shows that gpt-3.5+ToT outperforms gpr4+IO, in most cases, gpt-3.5+ToT doesn't work, esp, when used as the generation model. Therefore, whether the proposed work will be generalized to other models, esp., open-sourced models, is questionable or unanswered for me. If the proposed method can only work when using GPT-4, its cost will be one of the major obstacles for people to use it, also demonstrated by the new cost-efficiency result. \n2. This paper is a well-polished one with near ideas implemented very well and I have no doubt about its influence on the community in the short near future. However, its core novelty of applying (simple) search algorithms to LLM reasoning isn't significant enough.""}}, {'title': {'value': 'Thanks for responses and look forward to discussions'}, 'comment': {'value': 'We want to thank Reviewers 3c3c and sEEP for responding to our rebuttal, and we look forward to engaging in discussions with Reviewers ysyd and fAU5 and addressing any potential remaining concerns in the remaining 4 days. Thanks in advance!'}}, {'comment': {'value': 'Thank you for the response. I have increased my rating and wish the authors good luck.'}}, {'title': {'value': 'Thanks for the response'}, 'comment': {'value': 'Thanks for providing the additional data. The most interesting and promising is that GPT 3.5 with ToT can outperform GPT4 IO. '}}, {'rebuttal': {'value': '\nThank you for your detailed and constructive feedback!\n\n### 1. Cost and efficiency\nThis is a great point. Please see **General Response (3)**.\n\n### 2. Running IO/CoT baselines many times\n\nWe showed Game of 24 IO/CoT best-of-k results in Table 2 and Figure 3, where CoT best-of-100 has a game success of 49%, which is still much worse than ToT\'s 74%. We also showed iterative refinement approaches for Game of 24 (Table 2) and Creative Writing (Figure 5). These findings suggest ToT might be a better way to spend more resources in hope to get better results for these tasks, compared with parallel sampling or iterative refinement. \n\n\n### 3. Creative Writing Steps\n\nWe note that the ToT for creative writing has two steps: plans are generated and evaluated, then passages are generated and evaluated based on the best plan. \n\n### 4. What tasks need ToT\n\nThis is a great question! Please see **General Response (1)**, where we show how easy it is to adapt ToT to more tasks. We think GPT-4+ToT is more suitable for hard tasks challenging GPT-4+CoT, while weaker LLMs+ToT can be used for simpler tasks.\n\n### 5. ToT with weaker LLMs\n\nPlease see **General Response (2)**.\n\n### 6. Other smaller questions\n\n- Figure 3b: thanks for the suggestion, we will remove last two ""success"" bars. The figure is not intended to contrast the performances of ToT over CoT, but rather to support the point that CoT mostly fails at the first step of Game of 24 due to the inherent problems of autoregressive decoding, thus exploration around initial decisions is crucial.\n\n- Table 2 and Figure 3: we did not include error estimation as the performance gaps are significant and running GPT-4 experiments are expensive. As detailed in **General Response (3)**, running ToT experiments on Game of 24 and Creative Writing cost around 100 dollars.\n\n- We will fix line 186 and 134, thanks for your careful reading!\n\n- DFS pruning: as stated in line 265-266, a state is pruned if LLM deems any remaining clue as ""impossible"" to fill in (e.g. To heap: tm_s_).\n\n- Iterative refine for Game of 24: We tried it, and as shown in Table 2\'s IO + Refine (k=10, which is already very expensive due to the culcumative context), it does help a bit, but the performance of 27% is still poor compared to ToT\'s 74%.'}}, {'rebuttal': {'value': '\nThank you for finding our work ""well-motivated"", ""novel"", ""clearly described"", and ""convincing"".\n\n### 1. Adapt ToT to other tasks.\n\nThis is a great question. Please see **General Response (1)**, where we show a simple scheme that adapts ToT to StrategyQA and GSM8K with near-zero task-specific hand crafting.\n\n### 2. Least-to-most or decomposed prompting\n\nWe think they might not be effective baslines for our studied tasks, where initial decisions (e.g. first step of game of 24, or first filled word in crosswords) are critical and require exploration. Methods like least-to-most or decomposed prompting might help with compositional generalization via task decomposition, but do not have a way to explore and maintain different decomposition plans. So once the first step is generated wrong, they might fail similarly as CoT. \n\n### 3. Arithmetic mistake and tool use\n\nIn Game of 24, numbers are usually within 50, and GPT-4 rarely makes arithmetic mistakes (weaker models like GPT-3.5 make more mistakes). \n\nAs hinted in Page 8\'s footnote, we agree it is a great idea and important future direction to enhence ToT with external tool use! We probably need some better and harder tasks that require exploration of both reasoning and acting.\n\n### 4. Appendix\n\nThank you for the reminder! We will include additioanl experiment details and all prompts used in the appendix.\n'}}, {'rebuttal': {'value': '\nThank you for your thoughtful comments, all of which are very helpful for improving our work!\n\n### 1. Related work and BFS/DFS vs. MCTS\nThank you for pointing out these recent or concurrent papers related to ToT. We will discuss them in our related work section.\n\nWe used BFS and DFS as they are the simplest tree search algorithms that turn out general and effective enough for the studied tasks. Due to the modularity of the ToT framework, application of more advanced algorithms such as MCTS or A* for harder tasks is a clear and promising future direction.\n\n### 2. Cost and potential means to more efficiency\nThese are great points. Please see **General Response (3)**.\n\n### 3. Extend the scope to more CoT tasks\nPlease see **General Response (1)**, where as per your suggestion, we show a very simple scheme to extend ToT to StrategyQA and GSM8K. \n\n### 4. Importance of GPT-4\nPlease see **General Response (2)**.'}}, {'rebuttal': {'value': 'Thank you for endorsing our work!\n\n### 1. More application scenarios\n\nThis is a great point. Please check **General Response (1)**, where we show a very simple scheme to apply ToT in common NLP tasks (StrategyQA, GSM8K). However, such tasks might not need GPT-4 + ToT as GPT-4 + COT suffices --- weaker LLMs + ToT could potentially outperform weaker LLMs + CoT and could be studied on such tasks.'}}, {'rebuttal': {'value': 'We appreciate all reviewer\'s great feedback, which will significantly strengthen our draft!\n\nThe motivation of ToT is simple: **to explore and extend the capability frontier of autoregressive LLMs**. More specifically, given the SoTA LLM (GPT-4) can already solve many existing NLP tasks, what new tasks can raise new challenges? How can we augment LLMs to tackle these challenges? To this end, we contribute three new tasks for LLMs that challenge even GPT-4, and ToT as a framework to augment LLM\'s deliberate reasoning. **Our paper is thus focused on a setup with SoTA LLM (GPT-4) and hard tasks for it.** \n\nHere, we report new experiments with weaker LLM or easier tasks, and discuss cost and efficiency concerns.\n \n### 1. New Experiments on Other (Easier) Tasks (ysyd, fAU5, 3c3c)\n\nWhile more common NLP tasks might be too easy for GPT-4 and do not require ToT (which is why we considered harder new tasks), we believe **applying ToT to new tasks could be straightforward**. \nFor example, we implemented a simple and generic zero-shot ToT-BFS similar to creative writing (sample 5 problem solving strategies then vote for the best one; then sample 5 solutions based on the best strategy then vote for the best one) for GSM8K and StrategyQA with few extra lines of code:\n\n```python\ngsm8k_format = \'""the answer is n"" where n is a number\'\n\nstrategyqa_format = \'either ""the answer is yes"" or ""the answer is no""\'\n\nstandard_prompt = \'Answer the following question with {format}: {input}\'\n\ncot_prompt = \'\'\'\nAnswer the following question: {input}\n\nMake a strategy then write. Your output should be of the following format:\n\nStrategy:\nYour strategy about how to answer the question.\n\nAnswer:\nYour answer to the question. It should end with {format}.\n\'\'\'\n\nvote_prompt = \'\'\'Given an instruction and several choices, decide which choice is most promising. Analyze each choice in detail, then conclude in the last line ""The best choice is {s}"", where s the integer id of the choice.\n\'\'\'\n```\n\nWe evaluated on a subset of 100 random GSM8K test and StrategyQA dev questions. As shown below and as expected, ToT improves over CoT on both tasks (but only slightly, given GPT-4 + CoT is already very good on such tasks, and StrategyQA\'s bottleneck is external knowledge, not reasoning). Considering computational costs, it is more suitable to try smaller LLMs + ToT for traditional NLP tasks, or GPT-4 + ToT for hard tasks that challenge GPT-4 + CoT\'s reasoning.\n\n|     | GSM8k  | StrategyQA |\n| -------- | ------- |------- |\n| IO  | 51    | 73    |\n| CoT | 86     |  82   |\n| ToT | 90    |  83    |\n\n### 2. New Experiments on Other (Weaker) LLM (fAU5, sEEP)\n\nTo understand how ToT works with other LLMs, we also ran GPT-3.5-turbo for creative writing, which was reported in the supplementary material. **We find gpt-3.5+ToT outperform gpt-4+IO, and similar to gpt-4+CoT, which suggests ToT could also work well on weaker LLM.**\n\n|Creative Writing| gpt-4 (in paper) | gpt-3.5 | \n|-----|-----|----|\n| IO | 6.19| 4.47|\n| CoT | 6.93| 5.16|\n| ToT | 7.56| 6.62|\n\nWe also ran GPT-3.5 for Game of 24 (we changed 1-shot proposal prompt to 3-shot to make it work). Here, GPT-3.5+ToT\'s 19% is far worse than GPT-4+ToT\'s 74%.\n\n|  Game of 24  | gpt-4 (in paper) | gpt-3.5 | \n| ---- | ---- |---- |\n| IO  | 7.3    | 6    |  \n| CoT | 4.0     | 3     |    \n| ToT |  74  |  19    |  \n\nTo further understand the importance of generation vs. evaluation, we ran gpt-4 gen + gpt-3.5 eval (64%) and gpt-3.5 gen + gpt-4 eval (31%). This suggests the game\'s bottleneck is thought generation, and different gen/eval LLMs might attain decent results while reducing costs.\n\n|  gen\\eval | gpt-4 | gpt-3.5 | \n| ---- | ---- |---- |\n| gpt-4  | 74    | 64    |  \n| gpt-3.5 | 31     | 19     |    \n\n### 3. Cost and efficiency (fAU5, sEEP)\n\nRunning ToT requires significantly more computations than IO or CoT prompting. For example, in game of 24, solving a problem with ToT requires 5.5k completion tokens, close to 100 CoT trials (6.7k tokens). But the performance of ToT is better than best of 100 CoT trials.\n\n|  Game of 24 | completion tokens | prompt tokens | cost per case | success rate | \n| ---- | ---- |---- | ---- |  ---- |\n| IO (best of 100) | 1.8k    | 1.0k   | $0.13 | 33% |\n| CoT (best of 100) | 6.7k     | 2.2k     | $0.47 | 49%\n| ToT | 5.5k    |  1.4k    | $0.74| 74% |\n\nOn Creative Writing, we found ToT takes around 5x completion tokens and money cost, which is intuitive as $b=5$ and most tokens are generated passages.\n\n| Creative Writing   | completion tokens | prompt tokens | cost per case | \n| ---- | ---- |---- | ---- |\n| IO  | 0.9k    | 0.4k   | $0.06 |  |\n| CoT | 0.9k     | 0.4k     | $0.07 |\n| ToT | 4k    |  2.9k   | $0.32 | \n\nSo completing Game of 24 and Creative Writing\'s main ToT experiments cost around $0.74 * 100 + 0.32 * 100 = 106$ dollars. Unfortunately we did not record the usage for crosswords\' DFS experiments, but it should be within 100 dollars. In general, cost and efficiency of ToT highly depend on the prompts and search algorithms used, and could require 5-100 times more generated tokens than CoT. \n\nSome actionable insights:\n\n- We recommend using ToT on complex tasks requiring deliberate reasoning, on which CoT struggles.\n- Flexibility of ToT allows some performance-cost tradeoff, e.g. change beam size or vote number in BFS, few-shot vs. zero-shot prompting, GPT-3.5 vs. GPT-4, etc. One could configure the setup based on some resource constraints or performance goal.\n- There is much space for improving efficiency --- e.g. BFS could early stop when solution is found, or trim down beam size to $b<5$ when some thoughts are ""impossible"".\n- We believe that more computation is indeed required in order for the model to achieve stronger intelligence, and this should not become a blocking issue as in the long run, (open-source) LLMs will become much cheaper and more efficient. It is also a great direction how to better train/finetune LLMs for thought generation and/or evaluation.\n\n'}}, {'summary': {'value': 'This paper introduces a new method for prompting large language models (LLMs) for multi-step reasoning tasks. Existing prompting methods are confined to the autoregressive generation scheme, making it difficult for LLMs to finish tasks that require exploration and planning. To alleviate this problem, the authors propose Tree of Thought (ToT), which combines the chain-of-thought (CoT) method with tree-based search.  By prompting LLMs to solve the intermediate step and using the self-evaluations as the heuristics, one can effectively leverage LLMs to finish tasks that require exploration and backtracking. Empirical evaluations on three novel tasks demonstrate the effectiveness of the proposed method.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- A novel method to combine LLMs with tree-based search. The proposed method alleviates the shortcoming of directly prompting LLMs to generate answers for some tasks that require explorations and backtracking. Compared to CoT prompting which can only sample one solution path, ToT allows LLMs to explore more potential solutions and find the best one.\n- Automatic and independent reasoning process. ToT fully depends on the LLMs to generate plans, finish intermediate steps, and generate self-evaluation for the current state as heuristics. Without the dependence on external tools or models, ToT enables LLMs to automatically finish complex tasks.'}, 'weaknesses': {'value': 'More application scenarios. The authors mainly evaluate ToT on the three novel tasks that require exploration and backtracking. It would be better to demonstrate whether ToT can help improve LLMs on commonly-used reasoning tasks.'}, 'questions': {'value': 'Please see the weakness above.'}, 'limitations': {'value': 'The authors discussed the limitations and potential negative social impact of their work '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper presents a new framework for language model inference called Tree of Thoughts, which aims to improve the ability of language models to solve complex, multi-step problem-solving tasks. \n\nThe framework involves generating a tree of possible plans for solving a given task, with each node in the tree representing a possible step in the plan. The language model then evaluates each node based on its own self-assessment, and the tree is expanded by sampling external paragraphs to generate new nodes. The framework also includes a voting step to determine the best plan to follow. \n\nThe paper argues that this approach is more effective than previous methods for prompting language models, such as Chain of Thought, and can be seen as a modern rendition of classical search methods for problem-solving. The contributions of the paper include a detailed description of the Tree of Thoughts framework, an evaluation of its effectiveness on a range of problem-solving tasks, and a discussion of its potential limitations and future directions for research.\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': ""1. The idea of upgrading chain-of-thoughts into tree-of-thoughts seems to be an intuitive extension and necessary step. There are many benefits of tree reasoning, including the ability to look ahead and backtrack to search for better traces. \n2. The formulation of heuristics leverages the recent self-evaluation ability of GPT-4 to reuse the LLM to evaluate the quality of states via prompting. This relieves the necessity of training accurate state values and enables approximate estimation.\n3. The empirical results on three tasks demonstrate the effectiveness of ToT compared with GPT-4 based baselines. The improvement gain is quite large on two tasks, considering GPT-4 based CoT methods don't work well on them.""}, 'weaknesses': {'value': '1. Unsurprisingly, the idea of extending linear reasoning to tree reasoning isn\'t a new thing. Specifically, [1] leverages beam search to guide the chain-of-thought to decode a better reasoning path, which is almost the same as the BFS in this paper. [1] also uses self-evaluation to provide heuristics. [2] also formulates the reasoning as a tree reasoning problem. More importantly, the application of BFS and DFS seems to be ad-hoc, and there could be more principled methods to guide the search. For example, [3, 4] applies MCTS to guide the search, which might have better planning abilities.\n2. While ToT improves CoT naturally, it doesn\'t come without cost. One major concern is the efficiency issue for querying the expensive GPT-4 multiple times. The paper should give the audience a clearer idea of how cost ToT is compared with CoT, probably with an efficiency comparison between them. More interestingly, the paper should propose or at least discuss potential means to reduce the inference cost, such as using various smaller models for sampling or state evaluation, etc.\n3. The application scope is largely limited. While the authors say they select the three tasks because they are hard, the selected three tasks are arguably narrow with two text games. One possible reason is that the selected tasks make the thought and state formulation easier and demonstrate improvement significantly. Nonetheless, it would be necessary to extend the scope to be more similar to CoT tasks to demonstrate the broader applicability of the proposed methods. \n\n[1]. Xie, Yuxi, et al. ""Decomposition enhances reasoning via self-evaluation guided decoding."" arXiv preprint arXiv:2305.00633 (2023).\n[2]. Jung, Jaehun, et al. ""Maieutic prompting: Logically consistent reasoning with recursive explanations."" arXiv preprint arXiv:2205.11822 (2022).\n[3]. Zhu, Xinyu, et al. ""Solving math word problem via cooperative reasoning induced language models."" arXiv preprint arXiv:2210.16257 (2022).\n[4]. Hao, Shibo, et al. ""Reasoning with language model is planning with world model."" arXiv preprint arXiv:2305.14992 (2023).\n'}, 'questions': {'value': 'I raised multiple questions in the weakness section, and I hope the authors could further clarify them. Specifically, some can be reformualted as follows:\n1. How hard is it to apply the proposed method to a more general NLP reasoning dataset, like GSM8K or StrategyQA, or other well-known datasets? If possible, I hope the authors could demonstrate one case using the proposed method to solve a more general task. \n2. How necessary the GPT-4 is in the proposed framework? It seems GPT-4 is very powerful for self-evaluation, and how critical is this component for the success of the tasks?'}, 'limitations': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes Tree of Thoughts to promote deliberate problem solving with LLMs. By using a tree-based structure and a four-step process towards problem solving, tree of thoughts successfully address many of the challenges with left-to-right decoding such as looking ahead, backtracking, considering multiple reasoning paths at the same time, and more. Extensive experiments on three reasoning tasks demonstrate the superiority of Tree of Thoughts over ICL, CoT, self consistency, and more.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '+ the Tree of Thoughts approach is well motivated by the limitations of autoregressive decoding\n+ the four-step formulation is novel and clearly described\n+ experiments on three reasoning tasks are extensive and convincing'}, 'weaknesses': {'value': 'Overall I like this work and I only have a few comments.\n\n- I wonder if it might be possible to discuss the efforts required to adapt Tree of Thoughts to other tasks and reasoning formats. To me, it seems like other than the search algorithm (BFS/DFS), the other three parts would require some hand-crafted engineering from scratch for a different task.\n\n- I wonder if least to most [1] or decomposed prompting [2] might be possible baselines for the three tasks: they also discuss some sort of iterative problem solving potential.\n\n- In the ""Game of 24"" task, does the base LLM make arithmetic mistakes? If that\'s the case, would using tool learning strategies [3] further improve Tree of Thoughts in numeric reasoning tasks?\n\n- The supplementary material does not seem to contain an appendix, while some details might be helpful. For example, what is the prompt for GPT-4 zero-shot evaluation in line 213? What are the details of human evaluation for ""Creative Writing""? (annotator head count, compensation, etc.) Also, it is increasingly common to present all the prompt texts in the appendix to facilitate reproducibility. I wonder if the authors might consider having an appendix to systematically document all details about the approach and experiments.\n\n[1] Zhou, Denny, et al. ""Least-to-Most Prompting Enables Complex Reasoning in Large Language Models."" The Eleventh International Conference on Learning Representations. 2022.\n\n[2] Khot, Tushar, et al. ""Decomposed Prompting: A Modular Approach for Solving Complex Tasks."" The Eleventh International Conference on Learning Representations. 2022.\n\n[3] Schick, Timo, et al. ""Toolformer: Language models can teach themselves to use tools."" arXiv preprint arXiv:2302.04761 (2023).'}, 'questions': {'value': 'please see above'}, 'limitations': {'value': 'Limitations are discussed in Section 6.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper introduces an innovative concept of problem-solving that utilizes a tree-like structure of thoughts, constructed and evaluated by the LLM, specifically GPT-4. To illustrate the efficacy of this technique, the authors have incorporated three distinct tasks: the Game of 24, creative writing, and crossword puzzles. These tasks have been chosen as they require different capabilities to be solved. Several iterations of the tree-like structure of thoughts were examined, including those combined with Breadth-First Search (BFS) or Depth-First Search (DFS), along with other variations with different hyperparameters. A comprehensive comparison has been drawn with various other Language Learning Model-based baselines.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': ""The value of examining the tree-like thinking process performed by LLM is evident to the scientific community. Primarily, the Tree of Thoughts (ToT) could be applicable to other tasks when adequately adapted and it provides an intriguing exploration of GPT-4's capabilities.\n\nThe paper intriguingly selects tasks requiring diverse skill sets:\n- The game of 24 demands fundamental mathematical capabilities and the ability to assess whether success is achievable from a partial solution.\n- Creative writing needs the generation of coherent and sound text under strict constraints.\n- Crossword puzzles necessitate linguistic knowledge and the capacity to search across a vast state space (large word sets that meet given constraints).\n\nThe authors have made a commendable effort to objectively assess the results, with blind tests of text coherency serving as a prime example. The elucidation of the method is lucid, with Figure 1 being particularly illuminating. Additionally, most experiments are presented in a comprehensible manner. A significant strength lies in ToT's performance, which significantly surpasses that of the baseline.\n\nI perceive this paper to be a successful proof-of-concept for ToT. Notably, its significance chiefly stems from the ongoing massive efforts aimed at leveraging LLM's capabilities. A prominent challenge in applying LLMs for deliberate problem solving""}, 'weaknesses': {'value': ""The biggest weakness of ToT is that the paper lacks the evaluation of some important properties of ToT. Here I put a list:\n\n1. There is no data about the price of ToT compared with baselines (there is a short mention in the Limitations about the price/success rate trade-off). In the best case, I would like to have a graph where there is a success rate on the y-axis and a price on the x-axis. If you think that such a graphical analysis would be too detailed please put some data in a table. The price of GPT-4 may be different in the future, so alternatively you can add information about the number of tokens used by ToT per solution compared with baselines. Probably the best would be to have both information: price and number of tokens. \n\n2. There is no data about the time execution of ToT compared with baselines.\n\nComment on 1. and 2. : Knowing the average price and time is very important for readers who consider building their own methods on top of ToT or consider applying ToT to their task. \n\n3. Some additional comparisons are missing. We know that a single execution of ToT is significantly more powerful than a single execution of baseline (for example IO). However is it possible that running IO or CoT many times (until it finds a solution) is actually cheaper and faster than ToT? ToT will still have scientific value even in the case where the answer to the previous question is positive, but the scientific community will benefit from knowing it. Currently, it is not really known what are the maximum capabilities of properly used LLM and how to maximize its performance. In a search for the most effective methods, we need to know as many properties of each approach as possible. Knowing more about ToT would add great value to the paper. Here is a list of my suggestions for additional comparisons:\n> How many times on average should I run a baseline to find a solution compared with ToT?\n> Can baseline be cheaper or faster than ToT even though it is weaker?\nIf it is impossible to gather detailed data for this comparison, please provide some estimates.\n\n4. While I see value in the creative writing task, I am not very convinced that a task with just one ToT step is meaningful when evaluating tree search algorithms. More precisely: while formally this task falls under the ToT framework, it's hard to think about it in terms of tree search. \n""}, 'questions': {'value': 'Necessary things (either to address here or in the paper):\n- Figure 3b:  The title of the figure is “Samples failed at each step”, and there last two bars show success not failures (the one named “Correct”). It is misleading, I first thought that ToT failed mainly at the last step. Another problem with this comparison is that ToT with b=5 vs CoT seems unfair to me (ToT has many samples at each state while CoT does not - it is not surprising that CoT stands no chance). The better comparison would be for example: ToT vs  CoT-SC  or ToT vs CoT-best of 100.\n- In Table 2 and Figure 3 there is no information about the error estimation. It should be at least in text somewhere\nThe total cost of the experiments done during the work on this paper should be stated in the paper or in supplementary materials.\n- line 186. I would change ""left"" to ""remaining"" (numbers). For a while, I was wondering if left refers to ""left to do"" or ""left side"".\n- line 134: dot missing at the end of the sentence\n- Algorithm 2 and line 279: how exactly does the pruning work?\n- lines 222 to 225: Here you describe an iterative-refine method as a baseline. Would such a method be reasonable for baselines in Game of 24?\n\nSuggestions, ideas, and comments:\n-All the tasks presented here could be solved without ToT (and two of them even without LLM).  Maybe you have some intuition for what kind of problems ToT would be necessary? I know that this may be hard or even impossible to answer.\n- It would be very interesting to see a comparison of ToT based on GPT3.5 vs IO GPT4 or CoT GPT4. Can weaker LLM with ToT be stronger than Sota LLM? I think such an experiment would add great value to the paper.\n- The comment at the bottom of page 8 is very interesting\n\n\n\n'}, 'limitations': {'value': 'The limitations section is sound.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Tree of Thoughts: Deliberate Problem Solving with Large Language Models'}, 'authors': {'value': ['Shunyu Yao', 'Dian Yu', 'Jeffrey Zhao', 'Izhak Shafran', 'Thomas L. Griffiths', 'Yuan Cao', 'Karthik R Narasimhan']}, 'authorids': {'value': ['~Shunyu_Yao1', '~Dian_Yu2', '~Jeffrey_Zhao1', '~Izhak_Shafran1', '~Thomas_L._Griffiths1', '~Yuan_Cao2', '~Karthik_R_Narasimhan1']}, 'keywords': {'value': ['large language model', 'general problem solving', 'heuristic search', 'reasoning', 'planning', 'decision making']}, 'abstract': {'value': 'Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices.\nOur experiments show that ToT significantly enhances language models’ problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\\% of tasks, our method achieved a success rate of 74\\%. Code repo with all prompts: https://github.com/princeton-nlp/tree-of-thought-llm.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/6498bb3a1f9ede56976650e1008819e246dd979a.pdf'}, 'TLDR': {'value': ""We combine LLM's capabilities of generating and evaluating diverse “thoughts” with search algorithms for robust problem solving.""}, '_bibtex': {'value': '@inproceedings{\nyao2023tree,\ntitle={Tree of Thoughts: Deliberate Problem Solving with Large Language Models},\nauthor={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik R Narasimhan},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=5Xc1ecxO1h}\n}'}, 'paperhash': {'value': 'yao|tree_of_thoughts_deliberate_problem_solving_with_large_language_models'}}]"
"['Veit David Wild', 'Sahra Ghalebikesabi', 'Dino Sejdinovic', 'Jeremias Knoblauch']",NeurIPS,A Rigorous Link between Deep Ensembles and (Variational) Bayesian Methods,https://neurips.cc/virtual/2023/oral/73838,2023," We establish the first mathematically rigorous link between Bayesian, variational Bayesian, and ensemble methods. A key step towards this it to reformulate the non-convex optimisation problem typically encountered in deep learning as a convex optimisation in the space of probability measures. On a technical level, our contribution amounts to studying generalised variational inference through the lense of Wasserstein gradient flows. The result is a unified theory of various seemingly disconnected approaches that are commonly used for uncertainty quantification in deep learning---including deep ensembles and (variational) Bayesian methods. This offers a fresh perspective on the reasons behind the success of deep ensembles over procedures based on parameterised variational inference, and allows the derivation of new ensembling schemes with convergence guarantees. We showcase this by proposing a family of interacting deep ensembles with direct parallels to the interactions of particle systems in thermodynamics, and use our theory to prove the convergence of these algorithms to a well-defined global minimiser on the space of probability measures.",Oral 5C Probability/Sampling,https://openreview.net/pdf?id=eTHawKFT4h,https://openreview.net/forum?id=eTHawKFT4h,eTHawKFT4h,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'There has been a prevailing question as to why seemingly naive deep ensembles have surprisingly good properties for uncertainty quantification.  This paper tackles that question using an analysis through the lens of Wasserstein gradient flow and optimization in the space of measures.  Several variations of ensembling are derived within this framework.\n\nThe reviewers were unanimously in favor of acceptance, saying the work indeed provides a fresh and informative perspective about the behavior of deep ensembles.  The most common criticism amongst reviewers was that the experiments were too small scale and a bit confusing---which I think is a minor flaw (but one that the authors should look to improve, of course, especially wrt clarity).  There were also questions about the appropriateness / usefulness of Theorem 2, since it is an asymptotic result.\n\nNotes for camera-ready version: D’Angelo & Fortuin [2021] also discuss deep ensembles with a repulsive term, obtained through the lens of Stein variational gradient descent / gradient flow in both parameter and function space.  Thus I was surprised to see their work mentioned only once and in passing.  I believe this paper goes beyond their work with a more rigorous treatment; yet I think the draft would be much improved to add more context about the relationship to their work.  This discussion should also be included along with the other related work mentioned in point 1 of the general rebuttal.'}}, {'comment': {'value': 'Thanks for all the detailed clarifications -- I understand now much better Theorem 1 and its assumptions. \n'}}, {'title': {'value': 'Response to the rebuttal'}, 'comment': {'value': ""Thanks to the authors for replying to my questions. I am quite satisfied with their detailed comments to my questions and other reviewers' questions. I recommend a strong acceptance. ""}}, {'title': {'value': 'Brief response to the rebuttal'}, 'comment': {'value': ""I want to thank the authors for their insightful responses and detailed comments on the reviews, including mine.\n\nAfter reading the rebuttals and going over parts of the article again, I'm really happy with what's been presented. I'm now even more convinced that we should accept this submission and I will update my review to reflect this. I consider this submission to be an interesting piece of work with important implications for future research.\n\nThanks again for the good work!""}}, {'title': {'value': 'Thank you'}, 'comment': {'value': 'Thank you for the thorough response. I do not have any additional comments or questions at this time.'}}, {'rebuttal': {'value': '#### Questions\n1. This is indeed an excellent question. It is true that in practice, we will need to replace full gradients by mini-batch versions and for example the kernel mean embedding with its monte carlo estimator. The reviewer correctly observes that the theoretical results in Section 4 do not account for this type of approximation and sub-sampling. However, this is not unique to our analysis, and a rather common simplification. More importantly, we believe that the results built by ignoring this added complication already provide the most important insights into the differences between various algorithms and can be used as a starting point for further theoretical investigations.\nMore precisely, we think of the Wasserstein gradient flow as a powerful and principled tool to derive new inference algorithms for different types of regulariseres (MMD/KL and maybe others in the future). We can then combine it with standard plug-in estimators (like mini-batch gradient estimators) to immediately obtain an algorithm that approximately performs gradient descent in infinite dimensions.\n2. We thank the reviewer for pointing us to these alternatives for VI. We have included references for VI via normalizing flows and SIVI  in the main text. To the more general point: It is indeed true that one can make the class of variational inference more expressive, but this comes with a trade-off: If we use a more expressive approximating family, the KL-divergence term is typically not available in closed form anymore, which means we need to introduce approximations for the regulariser. Furthermore, the resulting optimization problems for the variational parameters are still highly non-convex and therefore often depend heavily on good initialisations. We are not aware of any works in the FD-GVI literature that obtain results competitive with deep ensembles. We believe that this is a direct consequence of the above problems.\n\n#### Limitations\n\nThe reviewer raises an excellent point. Results such as the one presented in Theorem 2 are only asymptotic in nature, and consequently we have no guarantee that the convergence is fast enough. These results should therefore be seen as necessary but not sufficient conditions for a good inference algorithm. Yet, stronger results which quantify the speed of convergence, would require us to make extremely strong assumptions that will be violated for deep learning. For example, we could trivially obtain quantitative results by citing the relevant literature albeit under very strong assumptions that would never be satisfied in the context of deep learning. Section 11.2 of  Ambrosio et al. (2005) shows that if $L$ is lambda-convex along generalized geodesics, we obtain exponentially fast convergence. Lambda-convexity of $L$ can be guaranteed if the potential $V$ is strictly convex (cf. Section 9.3 of Ambrosio et al. (2005)), which is surely never satisfied in deep learning applications. \n\nThe final version will make this difference between qualitative and quantitative results clearer, and discuss the strong assumptions required to obtain quantitative results.\n\nHowever, we want to point out that standard parameterized FD-GVI comes with no guarantees of any type. Although qualitative results have their shortcomings, they at least show that the inference algorithm in principle is powerful enough to solve the optimization problem at hand.\n\n\n\n#### References\n\nAmbrosio, L., Gigli, N., and Savare, G. (2005). Gradient flows: in metric spaces and in the space of probability measures. Springer Science & Business Media.\n'}}, {'rebuttal': {'value': '#### Details on experimental section\n\nAs the reviewer notes themselves, the paper is already rather densely packed. Because of space limitations, we were not able to include all relevant experimental details in the paper. We chose to focus on methodological details, but will move as many details into the main part in accordance with the available space in the final version. \n\n#### Motivation for convexification\n\nWe thank the reviewer for their comment. One needs to distinguish between two questions. The first one relates to the uniqueness of the minimiser of the optimisation problem. The point that we try to make with the footnote is simple: without regularization, the optimization problem can in general not have a unique minimiser. This relates to the bigger question that the reviewer raises: Why should one care about uniqueness? The main problem with non-uniqueness is that this typically translates into undesirable properties of the inference algorithm—for example, unless the solution is unique, it is not even clear which solution (of the many possible ones) an algorithm should target. This is illustrated by Theorem 1: the asymptotic distribution of Deep Ensembles depends strongly on initializations and how large the domain of attraction for a given local minimum is. Therefore, if we initialize poorly, we may end up putting most particles close to a comparatively poor local minimum.\n\nIdentifying a unique target to aim for, which in our case is $Q^*$, is typically seen as the first step in designing an inference algorithm with theoretical guarantees—after all, unless the target is clearly defined, it is not generally possible to assess an algorithm’s performance. Once the target has been identified, the second step is to build an inference algorithm that finds it.\n\nRegarding the interpretation of Figure 2: There may be some confusion about what $Q^*$ is in the plot. The dotted line in the background is the (unique and optimal) $Q^*$ of the optimisation problem; and the histogram clearly shows that DLE and DRLE do generate samples from this global minimiser (in line with our theory). On the other hand, DE does not (!). While it would be possible to find an initialisation distribution $Q_0$ such that DE converges to its global minimum, we would have to know where the global minimum (and its region of attraction) are located to do this—and this is precisely the kind of dependence on initialisation that is undesirable! DLRE and DLE converge to their respective optimal $Q^*$ regardless of initialization, thereby losing this undesirable trait. Importantly, note that this would be impossible to achieve if we hadn’t guaranteed the existence of a unique minimizer through convexification.\n\n#### Motivation for DRLE \n\nWe thank the reviewer for this great question. It is a point that we will discuss more thoroughly in the final version of the manuscript. The MMD is based on the kernel $\\kappa$ which introduces a repulsive effect between different sets of particles. This means that we can essentially choose our own metric that compares different parameter vectors (i.e. particles) with each other. It now depends heavily on the application, which sets of parameters should be considered ‘similar’. We chose a very basic kernel, the squared exponential, which essentially just measures the euclidean distance between the parameter vectors. However, in certain applications one might have a very good understanding of the type of diversity one would want to encourage and this knowledge could be embedded in the kernel $\\kappa$. We considered a thorough investigation of the effects of the kernel to be beyond the scope of this paper, but it is an interesting avenue for future research.\n\n\n#### Questions\n[PDE solvers] We are grateful the reviewer pointed out that this sentence is misleading. We mean the following: Once we have a closed form expression for the Wasserstein gradient (as for example in the KL and MMD case) the PDE in (4) gives us a way to determine the pdf of $Q(t)$ at any time $t$. We can simply apply numerical PDE solvers to find an approximation of $q(t,\\theta)$. However, PDE solvers quickly become computationally infeasible if the input space is larger than 2 or 3. As the parameter space in deep learning is typically at least in the thousands and more often than not in the millions or billions, it is computationally infeasible to deploy numerical PDE solvers. \n\n#### Limitations\nThis is an excellent point. We have written a response to this in the general rebuttal point 3. '}}, {'rebuttal': {'value': '#### Weaknesses\n1.  One of the aims of this paper is to show that the naive strategy of train-and-repat can be understood as Wasserstein gradient flow of the probabilistic lifting of the loss function. Which strategies are covered depends on a case-by-case basis. Weight-decay for example is covered by our theory, as it just means that $\\ell$ is given as MSE+$\\lambda |\\theta|^2$. Batch-normalization is also covered in the sense that an ensemble of neural-networks which implement batch-normalization can be understood through the same WGF-lense. However, we did not want to give the impression that DEs are a bad strategy (even in their most basic form). Quite the opposite: we stress throughout the paper that they can be interpreted as implementing a rather sophisticated version of gradient descent and that especially in the multi-modal loss-landscapes of deep learning it is hard to come up with a better strategy. \n2.  Thank you for pointing this out, we will make a more concerted effort at explaining this in the updated manuscript. As our theory shows, a key difference between DE and D(R)LE is the form the solutions take: with infinitely many particles, D(R)LE produces a unique probability measure that has a continuous density (see Figure 2). In contrast, Theorem 1 shows that DEs produce probability measures that have atomic support: they have probability measure zero almost everywhere—except at a few individual points. In a sense, DEs are an extremely sparse representation of parameterisations of the neural network we care about. This is different for the measures produced by D(R)LEs: (with infinitely many particles) because they are densities, they try to assign probability mass to all regions of the parameter space. It is reasonable to believe that this would lead to a less sparse/better representation of parameterisations of the neural network we care about. Figure 2 supports this idea: in the setting where there are many more particles than minima, we can cover the parameter space of the neural network well—and in these settings, the purely atomic nature of DEs would generally be a drawback. To show this, we sampled the initial values for the parameters for the DE uniformly between -2.5 and 2.5. Since there are two minima in Figure 2 whose basins of attraction for gradient descent are around [-2.5, 0] and [2.5,0], a uniform initialization leads to the exact 50:50 spread. \nHowever, in practice, neural nets don’t look like Figure 2—they have lots and lots of minima, and we have very few particles to try and approximate the densities that look so clean and regular in Figure 2. That’s why we include Figure 4: it shows what actually happens in this scenario. If the number of particles is far lower than the number of minima, the particles in D(R)LE  are not enough to be a good approximation to a density of this type of space. Instead, they drift to the closest minima (exactly like they would in DEs!) and get stuck there for a long time. To show this phenomenon even more clearly, we have attached the original picture in Figure 3 together with a variant of the same experiment that uses only four particles to approximate the D(R)LE measures to this review. As is clear from that picture, when the number of particles is small relative to the number of minima, a naive interpretation of the theory is misguided; and D(R)LE behaves very similar to DEs. This is consistent with how the underlying equations evolve: When we discretise the evolution equations, what we get are basically slightly modified and randomized gradient descent schemes (see e.g. eq (7)). Theory (and experience from Langevin sampling for Bayesian posteriors) shows that as one keeps evolving the particle ensemble long enough, they will eventually escape and behave sufficiently differently from DEs—but in deep learning, we will not have the resources to keep the processes running forever. The naive expectation that we would get the type of behavior we see in Figure 2 in neural networks is therefore voided—instead, we should expect that D(R)LEs will act very similarly to DEs. \n3. Thank you for pointing this out; we will improve the paper and make these points clearer. Specifically we will explain that all integrals are over $R^J$ and all gradients are with respect to $\\theta$.\n\n#### Questions\n1. The number of ensemble members is $N_E$ (e.g. $N_E=10$). This means we train 10 neural networks where each neural network has its own set of parameters. The index $n$ therefore would run from 1 to 10 and denote the set of parameters corresponding to the n-th neural network.\n2. Yes, indeed. In Section 4.2 and Theorem 2 we show that under certain conditions our intuitions are validated and we obtain convergence results.\n3. In Figure 2 we illustrate that the samples we obtain from implementing our method for DLE and D(R)LE are close to the optimal measures.\n4. Yes, this is indeed the same. \n5. See answer to Weakness 1.\n6. Yes. Commonly, ‘non-parametric’ methods refer to the setting where the number of parameters can be arbitrarily high, and where in the limit of infinitely many parameters, one can recover an (infinite-dimensional) truth. In the context of our paper, the non-parametric object is indeed the targeted distribution itself, while the number of particles (of DE or D(R)LE) can be seen as the (arbitrarily large) number of parameters. As our theory shows, if the number of particles/parameters goes to infinity, we can recover the infinite-dimensional object we are targeting. This is different from parametric/parameterised problems, where there is not a natural way of making the parameter space arbitrarily large. E.g., typical variational families such as the family of normal distributions is parametric—but the collection of normal mixture distributions (with arbitrarily many and potentially infinitely many mixture components) would be non-parametric.\n7. See Weakness 1.\n8. See Weakness 2.\n\n#### Limitations\nSee global response point in 4.'}}, {'rebuttal': {'value': '#### Weaknesses\n\n[This is meant as a response to the first 2 bullet points]\nWe thank the reviewer for their helpful suggestions. We will include the suggested references and give a thorough discussion in the final version of the manuscript. It allows us to contrast infinite-dimensional gradient-flow methods with infinite-dimensional parameter-space methods. The functions space literature focuses on a formulation of the problem in infinite-dimensional function spaces—but still uses a finite-dimensional gradient flow based on parameterisations to implement its algorithms. In contrast, our method operates on a finite-dimensional parameter space, but implements an infinite-dimensional gradient flow. The function space view has the benefit that the functional loss  is often convex and consequently the target $Q^*$ can be unimodal. However, the variational stochastic process still requires parameterization to be computationally feasible—and in this sense, function space methods are FD-GVI approaches. The resulting objectives require a good approximation of the functional KL-divergence (which is challenging), and lead to a typically highly non-convex variational optimization problem in the parameterised space. While good initialization strategies may well be able to overcome some of these issues, this type of tuning requirement is common amongst FD-GVI approaches, a direct result of non-convexity, and typically not grounded in theory. Moving away from relying on these types of tuning strategies (whose effect is often poorly understood) serves as another motivation to attempt an infinite-dimensional gradient flow procedure: in principle, it allows us to exploit the convexity in the space of probability measures directly. The derived inference algorithms and the resulting asymptotic guarantees give some evidence to this conjecture: they hold regardless of the chosen initialisation.\n\nThat being said, we want to clarify that it is not our intention to question the validity of FD-GVI procedures or advocate for their abandonment: they are the dominant Bayesian deep learning paradigm for a reason, have considerable practical merits, and often work well in practice. We have mentioned and stressed this point more clearly in the new version of the manuscript. In spite of their practical utility, we do also believe that the mathematical challenges associated with FD-GVI serve as an additional motivation to investigate infinite-dimensional GD procedures. Indeed, doing this reproduced popular competing deep learning algorithms as diverse as DE and DLE—and even allowed us to derive DRLE, which provides a template for how our theory not only draws links btw existing deep learning algorithms, but can also inspire new ones.\n\n#### Questions\n1. LLA relies heavily on a function space perspective, which we did not adopt in our work. It is possible that a thorough investigation of function space methods would lead to further connections but we consider this beyond the scope of this paper. \n2. [This paragraph answers Question 2 and Limitation 1] Thank you for raising this point—this is indeed a very important point. We have included the following in the final version of the manuscript: \n> In essence, the core justification for these generalisations is that the very assumptions justifying application of Bayes’ Rule are violated in modern machine learning. In practical terms, this results in a view of Bayes’ posteriors as one—of many possible—measure-valued estimators $Q^∗$ of the form in (1). Once this vantage point is taken, it is not clear why one should be limited to using only one particular type of loss and regulariser for every possible problem. Seeking a parallel with optimisation on Euclidean domains, one may then compare the orthodox Bayesian view with the insistence on only using quadratic regularisation for any problem. While it is beyond the scope of this paper to cover these arguments in depth, we refer the interested reader to Knoblauch et al. (2022).\n\n3. Again, the reviewer is pointing out a very interesting avenue for future research. In principle, it is possible to use other divergences such as the ones mentioned by the reviewer (and indeed all f-divergences). However, often the implementation of the gradient flow then requires us to have access to the evolved pdf of the samples at time $t$. This can generically be replaced with a kernel density estimator based on the samples available at time $t$. However, it is well-known that kernel density estimators suffer greatly from the curse of dimensionality. Therefore, it is practically infeasible to use them in the context of deep learning (as the parameter space over which we need to compute said kernel density estimators) is huge. \n\n#### Limitations:\n1. See Question 2.\n2. We agree that the paper does not provide a full analysis of empirical performances. One reason for this is the limited amount of space. That being said, the more important reason is that we do not intend the paper to be a thorough study of any particular ‘market-ready’ methodology that can compete with the fine-tuned algorithms prevalent in industrial scale deep learning. Instead, our focus is on theoretical insight into what existing methods for uncertainty quantification in deep learning are actually doing—and this is reflected by our emphasis on connecting Bayesian and non-Bayesian methods through the analytical lens the paper proposes. As part of this, we conducted a range of experiments in the experimental section (incl. on UCI regression tasks) to showcase the limitations of naively adopting the current framework for designing new algorithms. In this sense, we believe that our empirical investigation serves the main purposes of the paper: to highlight how the derived theory aligns with reality, and to explain any divergence between theory and reality to help follow-up research with exploiting our ideas in order to develop more efficient and more effective algorithms.\n'}}, {'rebuttal': {'value': '#### Weaknesses\n\n1. We understand the reviewer’s concern and agree that the paper does not provide a full analysis of empirical performances. One reason for this is the limited amount of space that 9 pages allow in order to comprehensively present our firmly grounded theoretical framework and a number of its technical aspects. That being said, the more important reason is that we do not intend the paper to be a thorough study of any particular ‘market-ready’ methodology that can compete with the fine-tuned algorithms prevalent in industrial scale deep learning. Instead, our focus is on theoretical insight into what existing methods for uncertainty quantification in deep learning are actually doing—and this is reflected by our emphasis on connecting Bayesian and non-Bayesian methods through the analytical lens the paper proposes. As part of this, we conducted a range of experiments in the experimental section (including on UCI regression tasks) to showcase the limitations of naively adopting the current framework for designing new algorithms. In this sense, we believe that our empirical investigation serves the main purposes of the paper: to highlight how the derived theory aligns with reality, and to explain any divergence between theory and reality to help follow-up research with exploiting our ideas in order to develop more efficient and more effective algorithms.\n\n2.  We thank the reviewer for their comment. Indeed, we do not want to exaggerate our proposal’s novelty. While we agree with the reviewer that many of our contribution’s building blocks have been floating around in the literature, we are unaware of any work that has combined them in the way the current manuscript has. Bayesian (and generalized Bayesian) procedures typically focus on justifications that are centered around updating prior to posterior knowledge. Our focus is different: we instead focus on regularization in the space of probability measures, and on algorithms that allow us to solve the resulting problems. On a technical level, we also innovate by introducing WGFs for solving these types of problems. To the best of our knowledge, WGF has not previously been used to study how different regularisers translate into different properties of the inference algorithms; and how this in turn places inference algorithms as different as deep ensembles and variational Bayesian methods under the same overarching framework \n\n\n#### Questions\n1. Thank you for pointing this out; the sentence is indeed misleading in a certain sense: The initial space here is the Euclidean space and the ‘more challenging’ space refers to the space of all probability measures on the Euclidean space. From a point grounded in analysis, the latter is indeed more challenging as it provides less structure: Unlike Euclidean spaces, it is infinite-dimensional, non-linear and does not have an inner-product structure, which makes a thorough analysis more challenging. And yet, the reviewer is also correct to point out that the optimization problem itself is much simpler thanks to its convexity on this (more challenging-to-analyse) space. We intended to describe precisely this trade-off: We trade the simple Euclidean space with the more complicated space of probability measures in order to obtain an ‘easier’ convex objective function. We will slightly rephrase this sentence in the new version of the manuscript to stress this point more clearly.\n\n2. Thank you very much for making us aware of this—you are absolutely correct: this sentence should not have been in the final manuscript. We will ensure that this part of the paper is fixed by providing the adequate context. If you believe there are additional relevant papers related to these types of problems that we should be citing but that are currently not contained in the manuscript, we would be very appreciative of you letting us know so that we can include them.\n\n3. This is an excellent question. Two assumptions prevent this behavior: First, we assume that every saddle point has at least one strictly negative eigenvalue. Second, we assume that the Lojasiewicz inequality is satisfied (Lemma 3 in Appendix). Intuitively, the first assumption guarantees that locally around a saddle-point, the domain of attraction has Lesbegue measure zero. Hence, if our initialisation measure $Q_0$ has a Lesbegue density, we will almost surely not be attracted to the saddle point and leave its domain of attraction. The Lojasiewicz condition then guarantees that once we are in the domain of attraction of a local minimum, we will stay there and converge eventually to it. For more details see [1]. Regarding the reviewer’s specific scenario: A loss with a flat local maximum that has non-zero measure under the initialization would violate the Lojasiewicz inequality—as the reviewer correctly hypothesizes, this setting is therefore not covered by the theory.\n\n\n[1] Lee, J. D., Simchowitz, M., Jordan, M. I., and Recht, B. (2016). Gradient descent only converges to minimizers. In Conference on learning theory, pages 1246–1257. PMLR.\n'}}, {'rebuttal': {'value': ""### General Response: \n\nWe want to thank all the reviewers for taking the time to read our manuscript so carefully and for providing valuable feedback that we believe will significantly improve the manuscript further. Overall, we have obtained a median score of 8, which is a wonderful reward for the countless hours that we have spent on this project and its technical content in the past year.  \nWe summarize the reviewer’s main feedback below, and explain how we have addressed the points in the uploaded and updated version of the manuscript which implements some of the most called-for changes.\n\n1. **Reviewer NdiF** has expressed a wish for a more thorough discussion of FD-GVI in our manuscript, and has raised concerns that our representation of parameterised variational methods may fall short; and **Reviewer 4EE1** raised a similar concern. We thank both reviewers for pointing out this oversight, and have added to the discussion on related literature in Section 2.2, which now includes a paragraph on the state-of-the-art on function-space inference, implicit variational inference strategies, and normalizing flows. We believe this discussion will further highlight that the manuscript’s intent is not to imply that FD-GVI methods are impractical; and that rather, its intent is to thoroughly highlight their conceptual shortcomings relative to ID-GVI methods (which are the main subject of our investigations).\n**Reviewer 6hMj** has rightfully pointed out that a sentence regarding the origin of the studied optimization problem in the introduction needs some reshaping to avoid overstating the contribution in Knoblauch et al. (2022). We agree with the reviewer, and have adjusted this sentence.\n\n2. **Reviewer NdiF** has raised some valid points regarding the interpretability and meaning of the non-Bayesian nature of the measure-valued estimators which we derive. We agree that such a discussion is useful and necessary—we have added it to Section 2.1.\n\n3. Both **Reviewer 9edE and 4EE1** have asked questions regarding a quantitative analysis of the approximation error caused by finite time, finite samples and the use of unbiased estimators. We thank the reviewers for raising this, and have added the following discussion in Section 4.3: \n> A notable shortcoming of Theorem 2 is its asymptotic nature. A more refined analysis would quantify how fast the convergence happens in terms of $N_E$, $T$, the SDE's discretisation error, and potentially even the use of unbiased estimators for the loss based on sub-sampling. \nWhile the existing literature could be adapted to derive the speed of convergence for DRLE in $T$ (Ambrosio et al.,\n2005, Section 11.2), this would require a strong convexity assumption on the potential $V$, which will not be satisfied for any applications in deep learning. \nThis is perhaps unsurprising: even for the Langevin algorithm—probably the most thoroughly analysed algorithm in this literature—no convergence rates have been derived that are applicable to the highly multi-modal target measures encountered in Bayesian deep learning  (Wibisono, 2019; Chewi et al., 2022).\n\n4. **Several reviewers (6hMj, NdiF, AtWA)** pointed out that relative to the rest of the manuscript, its experimental section is comparatively limited. We agree that the paper does not provide a full comparison of empirical performances between different deep learning methods. The most important reason for this is that we do not intend the paper to be a thorough study of any particular ‘market-ready’ methodology that can compete with the fine-tuned algorithms prevalent in industrial scale deep learning. Instead, our focus is on theoretical insight into what existing methods for uncertainty quantification in deep learning are actually already doing. This is reflected by the title and by our emphasis on connecting Bayesian and non-Bayesian methods through the analytical lens the paper proposes. So while we did conduct a range of experiments in the experimental section (including on UCI regression tasks), this was done to showcase the usefulness of our framework as well as the limitations of naively adopting it for designing new algorithms—rather than as evidence that the proposed framework can outcompete prevalent deep learning paradigms. In this sense, we believe that our empirical investigation serves the main purposes of the paper: to highlight how the derived theory aligns with reality, and to explain any divergence between theory and reality to help follow-up research with exploiting our ideas in order to develop more efficient and more effective algorithms.\n\nWe have also included a number of smaller changes listed below:\n\n1. Adding to why the MMD can encode useful properties as a regulariser as contrasted with the KLD (included in 4.3 already; **Reviewer 9edE**).\n\n2. Being more explicit about what we mean by ‘challenging space’ (included in 2 already;  **Reviewer 6hMj**).\n\n3. Explaining that all integrals are over the parameter space $R^J$ of $\\theta$, and that similarly, all gradients are with respect to $\\theta$ (included just before 2.1;  **Reviewer AtWA**)\n\n4. Inclusion of a further setting for one of the experiments (the one for Figure 3) to make the messaging around the number of particles \nrelative to the number of local minima clearer & more explicit (**Reviewer AtWA**; the resulting experiments are can be found in the attached PDF).  \n\nIn addition to changes that are already implemented, we will include further adjustments in the camera-ready version as listed below:\n\n1. Adjustments to make the experimental section more readable and to state the purpose of the experimental section more clearly; with scope depending on space available (**Reviewer 9edE**)\n2. Including a definition of the Wasserstein distance (**Reviewer NdiF, AtWA**), \n3.  Mentioning the two key assumptions required for Theorem 1. (**Reviewer 4EE1**)\n4. More explicitly mention why it is hard to solve the PDE in (4) (**Reviewer 9edE**)\n\n""}, 'pdf': {'value': '/pdf/125f1f118def11bdb3f9e775b0a0dc7d55d90c39.pdf'}}, {'summary': {'value': 'The paper offers a viewpoint on deep ensembles as a (unregularized) Wasserstein gradient flow in the space of probability measures. This viewpoint enables new algorithms for deep ensembles (Langevin and repulsive via MMD), which are evaluated on some small datasets.  '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': '1) The paper is technically sound and well-written. Overall it was easy to follow.\n2) While many similar ideas have been floating around in the literature, the precise presented view on deep ensembles seems novel, and I found Theorem 1 to be interesting. \n3) While experiments on larger neural networks are missing, the effect of the proposed algorithms is clearly demonstrated in some controlled experiments and small data sets. '}, 'weaknesses': {'value': '1) Perhaps the main weakness of the paper is the lack of a comparison of the new methods on large neural networks. \n\n2) Many of the introduced tools (convexification via probabilistic lifting, Bayes with general divergence function, Wasserstein flows, etc.) are well-known.  But I believe Theorem 1 and Theorem 2 offer some new insights (in case they are really correct, see Questions). '}, 'questions': {'value': '1) In section 2, it is written that one lifts the problem to a more ""challenging space"" -- but I would instead say that this space is much simpler.  The problem suddenly has a closed-form solution (Gibbs measure) that can be written down, one has convexity, etc. \n\n2) The claim that the ""infinite-dimensional regularised optimisation problem over the space of probability measures first introduced in Knoblauch et al. (2022)"" seems rather quite bold -- the optimization problem (1) is a very fundamental one -- as discussed later in the paper (Section 2.1) there are many references. So perhaps this sentence in the introduction should be reshaped a bit?  \n\n3) In Theorem 1, is it really local minima or could it also be saddle-points? Couldn\'t a gradient flow in a nonconvex objective also get stuck at a saddle-point or local-maximum (when initialized at the maximum)? Imagine a landscape where we have a very large flat local maximum which has non-zero measure under that initial distribution.  Is this somehow excluded in the assumptions? '}, 'limitations': {'value': 'All limitations are addressed.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'To improve the accuracy of the uncertainty quantification, the authors aim to provide a mathematically rigorous link between Bayesian inference, Variational Bayes methods and ensemble methods. In this work, methods s.a. variational inference, Langevin sampling and deep ensembles can be seen as particular cases of an infinite-dimensional regularised optimization problem formulated via Wasserstein gradient flows. They also provide a novel inference algorithm based on MMD and gradient descent in infinite dimensions plus regularisation.\n\nThe procedure takes place by reframing the usual finite-dimensional loss function problem into an infinite-dimensional one. This is done rewriting the original optimization problem using an infinite-dimensional problem over the set of probability measures $\\mathcal{P}(R^J)$ and introducing a strictly convex regulariser to induce a unique global solution. This solution is assumed to not be too different from the solution to the original problem, which is controlled by a reference measure $P$. This leads to an interpretation of many different inference setups as particular cases of the optimization problem proposed. Therefore, this approach results as a combination of the proposals in Knoblauch et al. (2022) and Ambrosio et al. (2005).  \n\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '* Good idea, could be interesting to the community were it proven in some other contexts. \n\n* The formulation is clear and elegant thanks to the gradient flows and the usage of Wasserstein space. The usage of the thremodynamical formulation of free energy is very attractive as well.\n'}, 'weaknesses': {'value': '* Altough the proposal is interesting and elegant, I think the experimental part of the paper does not provide enough evidence of the benefits related to this framework change. Results such as those present in Figure 3 could, in principle, be rivaled by previous methods s.a. [1] and [4], neither of which are discussed here. The authors maybe could provide a stronger motivation in this regard, and maybe try to encompass these other methods inside their framework.\n\n* Some literature relevant to the topic at hand seems to be missing from the discussion, or at least should be discussed more thoroughly:\n  \n  *  Regarding the definition of infinite-dimensional GVI methods, I consider that other methods based on samples are left out and should be considered, such as [1,2,3]. These works may seem specially relevant due to the interest in implicitly-defined target $Q^*$, and in particular those that make use of the function-space formulation s.a. [1] or [4].\n\n  * I think finite-dimensional GVI methods are misrepresented as they can be much more expressive than the selection made in Section 2.2 may lead to believe. I consider that this point should be addressed, and the discussion must be readjusted accordingly in order to highlight the benefits of the proposed approach without relying on this fact. As examples of this matter, please see references [4,5,6]. \n\n* The writing can be generally improved, since the paper can be at times hard to follow. This is just a consequence of the amount of information provided, which is a positive point, although in sections 3 and 4 could be polished further.\n\n* (minor) The presentation could be improved, for example, by convering images to formulas s.a. in Figure 1 or the layout on the final page. \n\n* (minor) Since Wasserstein spaces are such a crucial point of this, I would suggest devoting a bit more time to explain the basics of the concept in the main text itself and not fully depend on the sources.\n\n(_References included in the ""**Limitations**"" section_)'}, 'questions': {'value': '\n* Can this framework be used to describe methods that obtain an a-posteriori approximation of the predictive distribution via Laplace approximation or similar methods? As examples, please see [7,8]\n\n* Since now inference is conducted without the guarantees provided by the Bayesian method, how should the distributions obtained be interpreted or used? \n  \n* I think other possible interesting regularisation choices would be Renyi divergences and also any proper scoring rule, defined in [9], which may solve issues related to the MMD and KL divergence.    \n\n(_References included in the **""Limitations""** section_)'}, 'limitations': {'value': '\n* Since the Bayesian framework is abandoned, I fear there are no guarantees about the properties for the distributions obtained in the same sense as with Bayesian inference. Although can be somewhat justified by results, a lot more work is needed in this regard in methods that rely on this extensions (which is a problem for this paper, although definitely not exclusive to it). \n\n* The paper is centred on theoretical developments, and as such, the theoretical discussion and argumentation is really interesting. However, and although it is not the core of the paper, the experimental phase leaves a lot to be desired in terms of justifying why this formulation change is needed. \n\n--- \n**References**:\n\n[1] Rodrı́guez-Santana, S., Zaldivar, B., & Hernandez-Lobato, D. (2022, June). Function-space Inference with Sparse Implicit Processes. In International Conference on Machine Learning (pp. 18723-18740). PMLR.\n\n[2] Mescheder, Lars, Sebastian Nowozin, and Andreas Geiger. ""Adversarial variational bayes: Unifying variational autoencoders and generative adversarial networks."" International Conference on Machine Learning. PMLR, 2017.\n\n[3] Santana, S. R., & Hernández-Lobato, D. (2022). Adversarial α-divergence minimization for Bayesian approximate inference. Neurocomputing, 471, 260-274.\n\n[4] Ma, C., Li, Y., and Hernández-Lobato, J. M. (2019). “Variational implicit processes”. In: International Conference on Machine Learning, pp. 4222–4233.\n\n[5] Sun, S., Zhang, G., Shi, J., and Grosse, R. (2019). “Functional variational Bayesian neural networks”. In: International Conference on Learning Representations.\n \n[6] Ma, C., & Hernández-Lobato, J. M. (2021). Functional variational inference based on stochastic process generators. Advances in Neural Information Processing Systems, 34, 21795-21807.\n\n[7] Deng, Z., Zhou, F., & Zhu, J. (2022). Accelerated Linearized Laplace Approximation for Bayesian Deep Learning. Advances in Neural Information Processing Systems, 35, 2695-2708.\n\n[8] Antorán, J., Janz, D., Allingham, J. U., Daxberger, E., Barbano, R. R., Nalisnick, E., & Hernández-Lobato, J. M. (2022, June). Adapting the linearised laplace model evidence for modern deep learning. In International Conference on Machine Learning (pp. 796-821). PMLR.\n\n[9] Gneiting, T., & Raftery, A. E. (2007). Strictly proper scoring rules, prediction, and estimation. Journal of the American statistical Association, 102(477), 359-378.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors propose to unify existing theory on Bayesian (variational) inference (VI) by addressing a generalized objective, which is obtained from standard parameterized loss minimization by “probabilistic lifting” (re-casting in a space of probability measures over the parameter) and “convexification” (ensuring the existence of a global minimizer by regularization), with infinite-dimensional gradient flows in 2-Wasserstein space. A general recipe is provided to implement such a Wasserstein gradient flow (WGF) via an energy objective and a system of interacting particles. In the key contribution of the paper, the authors study WGF with different types of regularization–most notably, the unregularized version corresponding to deep ensembles (DE). It is shown that DE do not conduct a Bayesian learning procedure and systematically fail to generate samples from the optimal distribution, yet perform competitively thanks to the flexibility of the infinite-dimensional inference they realize (as opposed to, e.g., classical parametric VI).'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '* [S1] **Unifying framework**. After much discussion in the past few years, the authors are–to the best of my knowledge–the first to establish a comprehensive theory that encompasses (finite-dimensional) VI and DE.\n* [S2] **Clarity**. Despite the rather abstract subject, the authors present a coherent and easy-to-follow sequence of arguments. Complexity is strictly limited to the necessary extent.\n* [S3] **Rigor**. Mathematical concepts and notation are sound. Extensive proofs and/or references to prior work underline every claim (though I did not check every proof in detail).\n'}, 'weaknesses': {'value': '* [W1] **Analysis of DE behavior** (see Questions)\n  * It is not entirely clear if the paper studies arbitrary variants of DE or only a very narrowly defined version (see Q5). \n  * The authors conjecture that the number of samples being vastly smaller than the number of local minima is responsible for D(R)LE not outperforming DE consistently and point to Fig. 4. This evidence seems rather anecdotal and could benefit from a more detailed investigation. Also see Q7--Q8.\n* [W2] **Omissions in notation**. While the notation is consistent and comprehensible overall, the authors tend to omit integration domains, objects of differentiation etc. (e.g., Eq. 1, l. 150, l. 177, l. 179). With the shifting of integration spaces and various gradients involved, it would be helpful to be as explicit as possible in this regard.\n'}, 'questions': {'value': '* [Q1] Eq. 6: What does the index $j$ relate to?\n* [Q2] l. 218: Are there any convergence results in the respective limits of $T$ and $N_E$?\n* [Q3] l. 223: The experiments are promised to confirm small approximation errors due to finite samples and time, in particular in comparison to finite-dimensional methods. Where, exactly, do I find evidence for this claim?\n* [Q4] l. 236: Just for the sake of clarity, is $\\theta^\\prime_n(t) = - \\nabla \\ell(\\theta_n(t))$ equivalent to $d \\theta_n(t) - \\nabla V(\\theta_n(t)) dt$?\n* [Q5] l. 237: Do I understand correctly that you interpret DE as training with no regularization whatsoever (weight decay, batch normalization etc. – let alone variations with weight sharing and the like)? I doubt that many researchers actually apply such a decidedly naive approach.\n* [Q6] l. 253: Can DE implementing infinite-dimensional GD be understood as taking a non-parametric/functional approach as to what the distribution of the generated samples looks like (as opposed to, e.g., mean-field VI with a finite parameter vector)?\n* [Q7] Fig. 2: Is there an explanation why DE exhibits this precise 50/50 spread of the probability mass?\n* [Q8] Fig. 4: I’m not sure I understand the key message here. Why do the particles end up in the same modes despite different $Q^\\ast$? What would be the expected behavior?\n\n—\n\nMinor remarks\n\n* l. 53: Redundant “i” in “probability”\n* l. 72: Shouldn’t $D$ provide the mapping $(Q, P) \\mapsto D(Q, P)$ according to the stated domain?\n* l. 170: I feel enough space can be freed to include the definition of the 2-Wasserstein metric, it seems an odd choice to omit this arguably relevant information.\n* l. 292: Is there a $d$ missing in front of $Q(\\theta)$ in the first double integral?\n* l. 297: $L^{FE}$ with capitalized superscript ($L^{fe}$ otherwise).\n* l. 329: White space after “minimisers”\n* l. 330: Remove either “which” or “that”\n* l. 337: “matters”\n* Fig. 3 (caption): White space in “FD-GVI”\n* Table 1: I would recommend removing the “Boston” dataset due to its racism issues. Also: “methods… outperform” or “method… outperforms”.\n* l. 355: “lens”'}, 'limitations': {'value': 'Given that the main contribution is a unifying framework for existing theories, this point doesn’t apply as usual. However, the authors should state more clearly that the evidence shown in Section 5 for findings in Section 4 is quite limited.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper established theoretical connections between ensembling an old and established method of deriving uncertainty estimates They use theory from iteraction of particles  in a thermodynamic system to generalise and connect seemingly different ways of ensembling and Variational Bayes(Inference) methods. This is done by formulating the original non-convex optimization problem ubiqitious in ML and stats as infinite dimensional convex optimization problem in the space of probability measures. The addition of a regularization quantity ensures the strict convexity of the problem and by choosing different forms of this quantity lead to derivation of various inference algorithms.   '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. The paper is well written, theory heavy and addresses important topic of deep ensembling and its connection with variational Bayes methods\n2. I am not so good with theory, but the theorems and equations looked ok to me without obvious mistakes.\n3. Although this is a theory paper, the theoretical claims are well supported by the experiments and where they are not the authors they explain it well.\n4. The distinction between IDGVI and FDGVI is well drawn out and explained. Also the limitations with FDGVI that the approximation family is limited by construction serves as a motivation for using IDGVI methods.'}, 'weaknesses': {'value': '1. There is a lot of content that has been compressed in 9 pages which can be challenging for a reader, and a journal might have been more appropriate for this work.'}, 'questions': {'value': '1. in practice, deep networks use stochastic gradients, does the theory hold for stochastic gradients, esp. as Section 2 explicitly uses gradients for motivation. \n2. For case of FDGVI, the authors do not consider normalizing flows or SIVI as methods to overcome the limited capacity of approximating family problem when comparing it with IDGVI. \n'}, 'limitations': {'value': 'The limitations or practical challenges with the derived inference algorithms can be addressed. How practical is the result from Theorem 2, is it something that will only work asymptotically or will this work practically and if so how fast ? '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper provides a theoretical framework based on generalized variational inference [1] and Wasserstein gradient flows (WGF) for analyzing deep ensemble methods and their regularized versions. The authors demonstrate that deep ensembles and other variational Bayesian methods can be cast as instances of an infinite dimensional variational inference problem and the WGF of different instantiations of a free energy functional. The authors additionally use their theoretical framework to derive a new algorithm for generating samples from a target distribution.\n\n[1] Knoblauch, Jeremias, Jack Jewson, and Theodoros Damoulas. ""An optimization-centric view on Bayes’ rule: Reviewing and generalizing variational inference."" Journal of Machine Learning Research 23.132 (2022): 1-109.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The paper is well-organized and written, and the benefits of the unifying theoretical framework are compelling. The discussion of how deep ensemble methods can be viewed through the lens of WGF and the use of this lens to prove theoretical guarantees on the limiting behavior of particle estimations is useful and insightful. This work also holds the promise of deriving new algorithms, as demonstrated by the deep repulsive Langevin ensembles presented in Section 4.3.\n'}, 'weaknesses': {'value': '#### **Experiments section is difficult to follow**\nWhile the details corresponding to the various figures in Section 5 are fully provided in Appendix G, this section is currently difficult to follow as a stand-alone section in the main paper. Without (even high level) details on the experimental setup and the general motivation of each experiment it is difficult to dive right into the results and Figures as they are currently presented. I recommend moving some details from Appendix G into the main text and providing the context for each experiment before diving into the results.\n\n---\n\n#### **Motivation for convexification is unclear**\nWhile the authors prove that convexity of the infinite-dimensional variational form of the learning objective guarantees uniqueness of a minimizer, this is somewhat disconnected from the presented goal of optimizing $\\ell(\\theta)$ via probabilistic lifting. For example, in footnote 1 on page 2, the authors argue that the unregularized variational objective has non-unique optimum. However, the local optima all have equivalent values of the objective and are simply weighted averages of equivalent optima of $\\ell$, hence it is not clear why uniqueness is a desiderata here.\n\nAdditionally, Figure 2 in Section 5 demonstrates how deep ensembles (DE) do not converge to $Q^*$. However, although deep Langevin ensembles (DLE) and deep repulsive Langevin ensembles (DRLE) provable converge $Q^*_{DLE}$ and $Q^*_{DRLE}$, respectively, these optimal distributions are also not equal to $Q^*$.\n\nHence a clearer exposition as to why regularized optima are preferred to the unregularized ones is needed.\n\n---\n\n#### **Motivation for DRLE is lacking**\nWhile DRE / DRLE is indeed interesting as a new algorithm that can be derived from the presented theoretical framework, it would be great if the authors also provided some intuition / motivation as to why MMD is perhaps a better suited divergence regularizer than KL. \n'}, 'questions': {'value': 'In Lines 188-191, the authors state that\n> In theory, the PDE in (4) provides us with a direct way of implementing infinite-dimensional gradient descent for (1): simply follow the WGF. In practice however, this is impossible: **numerical solutions to PDEs become computationally infeasible for the high-dimensional parameter spaces which are common in deep learning applications.**\n\nI am unclear what is meant by this. Why is the high-dimensionality of deep learning parameterizations relevant here? Isn’t this problem simply impossible since it involves an infinite-dimensional space?\n'}, 'limitations': {'value': 'Authors can potentially elaborate on the future directions of this work, specifically around analyzing the approximation errors of approximating WGF with finite number of particles over a finite time horizon.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'A Rigorous Link between Deep Ensembles and (Variational) Bayesian Methods'}, 'authors': {'value': ['Veit David Wild', 'Sahra Ghalebikesabi', 'Dino Sejdinovic', 'Jeremias Knoblauch']}, 'authorids': {'value': ['~Veit_David_Wild1', '~Sahra_Ghalebikesabi1', '~Dino_Sejdinovic1', '~Jeremias_Knoblauch1']}, 'keywords': {'value': ['Wasserstein gradient flow', 'generalised variational inference', 'deep ensembles', 'Bayesian deep learning', 'variational Bayes']}, 'TLDR': {'value': 'We establish the first unified theory connecting Bayesian, variational Bayesian, and ensemble methods for deep learning by leveraging Wasserstein Gradient Flows.'}, 'abstract': {'value': 'We establish the first mathematically rigorous link between Bayesian, variational Bayesian, and ensemble methods. A key step towards this it to reformulate the non-convex optimisation problem typically encountered in deep learning as a convex optimisation in the space of probability measures. On a technical level, our contribution amounts to studying generalised variational inference through the lense of Wasserstein gradient flows. The result is a unified theory of various seemingly disconnected approaches that are commonly used for uncertainty quantification in deep learning---including deep ensembles and (variational) Bayesian methods. This offers a fresh perspective on the reasons behind the success of deep ensembles over procedures based on parameterised variational inference, and allows the derivation of new ensembling schemes with convergence guarantees. We showcase this by proposing a family of interacting deep ensembles with direct parallels to the interactions of particle systems in thermodynamics, and use our theory to prove the convergence of these algorithms to a well-defined global minimiser on the space of probability measures.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/704a823d72ae267fa31197305e03593ac2212acb.pdf'}, 'supplementary_material': {'value': '/attachment/4459723091322ec7c99ec810c28ce419c67babb9.pdf'}, '_bibtex': {'value': '@inproceedings{\nwild2023a,\ntitle={A Rigorous Link between Deep Ensembles and (Variational) Bayesian Methods},\nauthor={Veit David Wild and Sahra Ghalebikesabi and Dino Sejdinovic and Jeremias Knoblauch},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=eTHawKFT4h}\n}'}, 'paperhash': {'value': 'wild|a_rigorous_link_between_deep_ensembles_and_variational_bayesian_methods'}}]"
"['David Ruhe', 'Johannes Brandstetter', 'Patrick Forré']",NeurIPS,Clifford Group Equivariant Neural Networks,https://neurips.cc/virtual/2023/oral/73825,2023," We introduce Clifford Group Equivariant Neural Networks: a novel approach for constructing $\mathrm{O}(n)$- and $\mathrm{E}(n)$-equivariant models. We identify and study the *Clifford group*: a subgroup inside the Clifford algebra tailored to achieve several favorable properties. Primarily, the group's action forms an orthogonal automorphism that extends beyond the typical vector space to the entire Clifford algebra while respecting the multivector grading. This leads to several non-equivalent subrepresentations corresponding to the multivector decomposition. Furthermore, we prove that the action respects not just the vector space structure of the Clifford algebra but also its multiplicative structure, i.e., the geometric product. These findings imply that every polynomial in multivectors, including their grade projections, constitutes an equivariant map with respect to the Clifford group, allowing us to parameterize equivariant neural network layers. An advantage worth mentioning is that we obtain expressive layers that can elegantly generalize to inner-product spaces of any dimension. We demonstrate, notably from a single core implementation, state-of-the-art performance on several distinct tasks, including a three-dimensional $n$-body experiment, a four-dimensional Lorentz-equivariant high-energy physics experiment, and a five-dimensional convex hull experiment.",Oral 5A GNNs/Invariance,https://openreview.net/pdf?id=n84bzMrGUD,https://openreview.net/forum?id=n84bzMrGUD,n84bzMrGUD,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper considers the Clifford Algebra and designs linear and polynomial layers that are equivariant to actions from the Clifford group. This allows designing neural network architecture suitable for different geometric settings including estimation of volume, convex hull, and $E(3)$ equivariant functions. We encourage the authors to make an effort improving the readability and accessibility of the paper to the general GDL community. Making it more self-contained and adding relevant implementation details would be appreciated.'}}, {'title': {'value': 'response'}, 'comment': {'value': ""Thanks for taking the time to address my questions and remarks, but also for providing additional visualisations!\nI acknowledge that it's tricky to strike a good balance between clarity and space constraint, and believe that the submission is doing a pretty good job already.""}}, {'comment': {'value': 'I like to thank the author for answering my queries. I will work through the paper again. Really look forward to any new tutorial materials. I understand there is a deadline for rebuttal and focus of the author should be to discuss here. I look forward to the eventual tutorial materials on arxiv after the whole process of double blinded process is over.'}}, {'comment': {'value': 'Thank you for thoroughly answering my queries!\n\nBased on the quality and content of your rebuttal addressing my concerns about the original manuscript, I am confidently raising your score.'}}, {'comment': {'value': ""Thank you for your thoughtful queries and for giving us the opportunity to further clarify our work.\n\n**Translation equivariance**: In the $n$-body experiment, we have indeed outlined the translation equivariance by mentioning, “The input consists of the mean-subtracted particle positions (to achieve translation equivariance) and…”. To make this clearer, we will explicitly mention in the revised version that we add the subtracted point back onto the prediction. We agree that emphasizing this point will provide better clarity on how our method achieves E(n)-equivariance, and we appreciate your recommendation in this regard.\n\n\n**Neural architecture**: The difference in parameter count between the O(5)-volume (convex hulls) and O(5)-regression experiments is primarily due to the different numbers of hidden dimensions used. The latter uses hidden dimensions of 128 (which is arguably overparameterized) compared to the former's 16 dimensions. For the regression experiment, we intentionally matched the number of parameters to those of the baselines to ensure a fair comparison. We'll ensure that such details are more explicitly mentioned in the revised manuscript.\n\n**Permutation invariance**: In our synthetic experiments, we relax the permutation invariance. Specifically: for the convex hull experiments, our goal was to test our raw feed-forward parameterizations in their most unadorned form against the baselines, among which some were also introduced as feed-forward architectures.\n\n**Dealing with permutation invariance in experiments 5.3 and 5.4**: We employ graph neural networks (GNNs) to address the permutation invariance for these experiments. Although our manuscript was limited in detailing this due to space constraints, we briefly touched upon using graph neural networks in 5.3. Delving deeper, these are straightforward message passing networks wherein both the message and update networks utilize our proposed layers. We acknowledge the omission of some of these details, especially regarding experiment 5.4, in our pursuit to fit the space constraints. We will rectify this by adding these details back in the revised version for a clearer understanding.\n\nWe hope that these explanations successfully addressed your comments. We appreciate the time you spent on this review, which has resulted in an improved revision of the manuscript. If it aligns with your assessment, we'd be grateful if you'd consider promoting our score. As always, we remain at your disposal for any further questions or clarifications.""}}, {'comment': {'value': ""We are grateful for your acknowledgment of the improvements we've made in our rebuttal and are happy to hear that our efforts have enhanced your confidence in our work. Regarding the appendix, we understand and respect your perspective. It's always a balancing act to cater to various communities with varying familiarity with the subject. We'll continue to strive for clarity and accessibility in future iterations. Your feedback has been instrumental in this process.""}}, {'comment': {'value': ""I appreciate the authors' comprehensive rebuttal addressing all of my questions and thank them for that!\n\nI would further like to clarify the following items.\n\n1. *Translation equivariance*\n\n    Is the network configuration used in the $n$-body experiment translation-*equivariant*?  I.e., do the authors add the subtracted point onto the prediction?\n\n    I would recommend that the authors include the translation-equivariance clarification in the paper.  Otherwise, it is not entirely clear how exactly the currently presented method is suitable for constructing *E(n)*-equivariant networks (line 2).\n\n2. *Neural architecture*\n\n      With reference to Table 1 in the rebuttal PDF and comparing the architectures for O(5)-volume (convex hulls) and O(5)-regression experiments, I wonder what causes the difference in the number of parameters.\n\n    In both cases, the authors use a 4-layer feedforward network. However, for the (seemingly simpler) task of O(5)-regression where the input is 2 5D points (vs., I presume, larger input for convex-hull volume prediction), the number of parameters is one order of magnitude higher.\n  \n     -  Is there a typo or how can the authors explain this otherwise? \n     -  Using a feed-forward neural structure in experiments 5.1-5.2, do the authors address the *permutation equi- and invariance* wrt the input points/particles? Or is this requirement relaxed?\n    - Could the authors also clarify this for experiments 5.3-5.4?\n""}}, {'title': {'value': 'Re:Rebuttal'}, 'comment': {'value': ""I thank the authors for their detailed rebuttal. I am mostly satisfied with their answers. I still contend that the Appendix is not an easy introduction to the subject as I might care for but given the scope and divide between the different communities it is still a welcome first step. As such, I'm upgrading my confidence to a 4 and maintaining my original score (7).""}}, {'rebuttal': {'value': 'We extend our gratitude to the reviewers for their efforts in evaluating our paper. The overall positive response we received has been highly encouraging. The feedback has undoubtedly improved the quality of our work, and we sincerely appreciate the insightful comments and suggestions that were provided.\n\nWe endeavored to consider the feedback as comprehensively as possible,  leading to a revision process that significantly honed the paper. We have strived to make all the necessary changes, balancing them with given space constraints. We have addressed every point in our responses and indicated where the paper was adapted based on the feedback.\n\nWe would like to reiterate that our work on Clifford Group Equivariant Neural Networks (CGENNs) sets a distinctive path from the usual geometric deep learning approaches. Unlike typical methods, CGENNs operate directly on an input vector basis compared to, e.g., popular spherical harmonics basis, are more expressive than scalar methods, and apply to inner product spaces of any dimension. \n\nConcluding, we thank the reviewers for recognizing the potential and novelty of our work. It is encouraging to know that our paper is viewed as a significant contribution that provides a direction in the field of geometric deep learning. '}, 'pdf': {'value': '/pdf/0f8523e5ea3cb425e32fed07ba6d60de9b0e6215.pdf'}}, {'rebuttal': {'value': ""We thank the reviewer for the actionable feedback. We address their concerns and questions in the following.\n\n1. *Data embedding?*\n\n    a. The data is embedded by an additional multivector dim in the network tensors (response to reviewer W8CU), whose size depends on the algebra, e.g., 4 or 8 for 2D or 3D algebras. Multivectors, under the geom. product, parameterize bilinear operations similar to tensors. Not all tensors can be expressed as multivectors, but many from physics can. For the inertia tensor example, see Berrondo et al.(2012). \n\n    **Action taken:** we give more intuition now in the paper.\n\n2. *Choice of quadratic form?*\n\n    a. In 3D, the signature is $[1, 1, 1]$, i.e., $p=3, q=0, r=0$. For more specialized problems we use different signatures. E.g., for SU(2), we use $[-1, -1]$, i.e., $p=0, q=2, r=0$ (see response to w3C8). In space-time settings, we use $[1, -1, -1, -1]$, i.e., $p=1, q=3, r=0$. \n\n    **Action taken:** we explain this now in the paper.\n    \n3. *Visualization?*\n\n    a. We added visualizations of the layers to the attached PDF and to the appendix.\n\n4. *Scalability of the method?* \n    a.  Let $\\dim(V)=n$, then the complexity of a fully connected geometric product layer is roughly $O(c _ {out} \\cdot c _ {in}  \\cdot 2^{3n})$, where $c _ {out}$ and $c _ {in}$ are output and input channels.\n    \n    The scalability is worse than scalarization methods, and similar to Clebsch-Gordan based E3NN depending on the highest order of irrep that is chosen.\n\n5. *Performance?*\n\n    a. It is a rather general finding that any polynomial in multivectors is equivariant in any inner-product space. We constructed our layers with this in mind, ensuring that we capture the 0th, 1st, and 2nd-order terms of such a polynomial, leading to flexible parameterizations. In 3D, CGENNs are similar to E3NN based layers, i.e., existing results of E3NN based methods (e.g., TFN, SEGNN) should match the performance (see SEGNNs in the $n$-body experiment). However, depending implementation and optimization specifics, numbers can differ. Clear benefits of CGENNs are found in non-Euclidian (higher-dimensional) cases. \n\n6. *Compare to Cesa et al. (2021)?*\n\n    a. Currently, Cesa et al. support steerable CNNs equivariant to 2D/3D isometries. Other differences: Cesa et al. design equivariant CNNs, where the group acts on the grid (e.g., an image). We operate on the particles directly. Second, Cesa et al. find equivariant bases for linear maps in such CNNs. Our steerable basis is given directly by the input data, and as such we also operate using bilinear layers, which is crucial for expressive GNNs (Finzi et al., 2021).\n    \n7. *Intuition behind the independence of the choice of basis?*\n\n    a. Great question! In general, basis independency goes back to Einstein's covariance principle, stating that one should come to the same conclusions regardless of the chosen frame of reference. More specifically, it means that grade-decomposition is well-defined and not dependent on a change of coordinates. We were unable to find in the literature a proof for this decomposition in the (non-definite, potentially degenerate) general case. As such, we regard it an original contribution of the work. Secondly, it directly allows for the equivariance of the grade projections! \n\n    **Action taken**: we explain the basis independence proof more clearly now.\n\n8. *Layer norm.*\n\n    a. The layer norm is defined as $x \\mapsto \\frac{x - \\mathbb{E}[x]}{\\mathbb{E}[\\sqrt{|q(x)|}}$, where the expectations are taken over channel dims. Intuitively, it re-centers and rescales multivectors according to their average norm.\n\n9. *Nonlinearities?*\n    \n    a. We need a sufficiently flexible, nonlinear function to learn expressive representations. We empirically find that including additional nonlinearities after the linear layers results in improved performances.\n\n    **Action taken**: we mention this in the methodology section now.\n\n10. *Signed-volume a pseudoscalar?*\n    \n    a. Yes.\n\n11. *Scalability regarding space dimension?*\n\n    a. The dimensionality of the algebra scales as $2^n$, where $n=\\dim(V)$. This looks bad at first sight, but usually the dimensionality of geometric spaces is not so large. Further, one can operate using subalgebras, which is typical in geometric algebra literature, or one can simply not consider the highest subspaces. \n\n12. *What are the reasons for EMLP underperforming?* \n    a. For O(5) regression, we took datasets and EMLP results directly from Finzi et al. (2021). We went through the EMLP code and noted that the output irreps of each layer is set equal to the output irrep of the whole task. For the O(5) regression task, whose output irrep is one-dimensional, this means that there will be no vector-valued outputs of the bilinear layers. This is potentially less expressive. Further, it depends highly on the specifics of the implementations and parameterizations. Our polynomials form a rather general basis from which we constructed our layers. \n\n13. *Do all methods have the same number of parameters or compute-time?*\n    \n    a. We kept the number of parameters similar between models. The compute-time however can depend on which method one uses. Steerable methods that use bilinear layers are generally slower than scalarization methods. Compared to existing steerable methods, Clifford layers are not fundamentally less efficient. \n\n14. *Computational overhead, scalability.*\n\n    a. The computations overhead originates from the bilinear geometric product layers. Please also consider our previous responses (4, 13) regarding scalability.\n\n#### Refs\n- Berrondo, M., J. Greenwald, and C. Verhaaren. Unifying the inertia and Riemann curvature tensors through geometric algebra. American Journal of Physics 80.10 (2012): 905-912.\n- Finzi, Marc, Max Welling, and Andrew Gordon Wilson. A practical method for constructing equivariant multilayer perceptrons for arbitrary matrix groups. ICML, 2021.""}}, {'rebuttal': {'value': ""We thank the reviewer for the actionable feedback. We address their concerns and questions in the following.\n\n1. *Accessibility and introductions of notations.*\n\n    a. During our literature research, we quickly found out that there are at least three communities (physicists, mathematicians, computer vision engineers) working with Clifford algebra (aka geometric algebra). These are all interested in different properties and, as such, use different conventions and notations that were not compatible with each-other. For example, different group actions (e.g., equation 348), or restricting themselves to homogeneous multivectors, or restricting the quadratic form to be definite or nondegenerate. One of the contributions of this paper is the study of existing literatures, unifying and generalizing them. We study the action of the orthogonal group on the whole Clifford algebra within the context of equivariant neural networks. We derived and re-derived everything we needed, with generality and group representations for NNs in mind.  \n\n2. *Motivation of operating on multivector representations.*\n\n    a. There are multiple reasons for using multivector representations. First, our theory allows for networks that operate in any inner product space, computing geometrically meaningful interactions (through geometric products). Second, if one takes a different route and goes for more general tensor product representations, one needs either irreps decomposition, which is hard to attain for any quadratic space, or use tensor product representations directly, which will grow intractably. We argue that Clifford algebra layers balances the two approaches, by allowing for a product structure (geometric product vs tensor product), which, due to their fundamental relations, will always remain finite dimensional, and, a way to decompose the whole Clifford algebra in smaller (but not necessarily irreducible) subrepresentations, which allow to reduce computational complexity (similar to the use of smaller irreps), without violating the equivariance properties. Third, there exist several physics problems that contain objects that transform in a non-standard way. For example, Maxwell’s equation treat magnetic fields as pseudovectors which can be represented as bivectors when using Clifford algebras / Clifford equivariant networks.\n    \n    **Action taken:** We elaborate on motivation for multivector representation now in more detail.\n\n3. *Originality of theory.*\n\n    a. While there already exist literature about the Clifford algebra, different notions of the Clifford groups with different actions, non of these sources we could simply cite for our purposes, because they all use their own notations/conventions, and have different corner cases, aspects or applications in mind. So a major and original contribution was to carefully construct/adjust definitions to get all our desired results (like multiplicativity, orthogonality) out and even provide proofs for the most general (non-definite, degenerate) cases.\n\n    **Action taken**: we clarify this now in the main paper.\n\n4. *Preliminary experiments.*\n    \n    a. The reason we chose not to go with molecular dynamics simulations is that the current state-of-the-art methods are highly finetuned and engineered to squeeze out all the features from the data. We felt that the adaptation and inclusion of these techniques to the Clifford layers was out of scope of the current work, and probably deserves a paper on its own. Finally, we would argue that the top-tagging experiment is at a reasonable scale and much less of a toy setting with 1.2M training samples and fully connected graphs with over 200 particles. \n    Note that architectures, such as LorentzNet, were specifically designed for this task in previous works. \n\n5. *Improve the method section by providing runtime complexity.*\n\n    a. We are hesitant with making claims about empirical runtime complexity at the current moment. The geometric product as a bilinear operation can be implemented as efficiently as existing methods that use bilinear (tensor) operations. Even stronger, this implementation would then work for any inner product space. However, comparing the current implementations to existing, highly optimized code-bases would be unfair and cast an undeserved shadow on equivariant Clifford layers. To give an approximate result. Please also consider our response to reviewer jDZi regarding runtime complexity.\n\n6. *Equivariance of projection.*\n\n    a. The equivariance of the projection follows directly from the equivariance of the linear layer. I.e., \n    $$\n    \\rho(w)\\left(T^{lin} _ {\\phi_{c_{out}}}(x _ 1, \\dots, x_\\ell)^{(k)}\\right) = \\rho(w)\\left(\\sum _ {c _ {in}=1}^\\ell \\phi _ {c _ {out}c _ {in} k} \\, x _ {c _ {in}}^{(k)},\\right)=\\sum _ {c _ {in}=1}^\\ell \\phi _ {c _ {out}c _ {in} k} \\, \\rho(w)\\left(x _ {c _ {in}}\\right)^{(k)}\n    $$\n     \n    which follows from the fact that $\\rho(w)$ is linear, commutes with scalar multiplication, and respects grade projections.\n\n7. *Use the Clifford group for other continuous symmetries like $SU(2)$.*\n\n    a. Yes, and this is very much open for exploration! For your $SU(2)$ example, see e.g. Wilson (2020). Specifics of (Clifford) group representations are elusive for now, but we believe that the presented work gives a good starting point for such scientific endeavors. As such, further explorations for Clifford networks operating in (relativistic) quantum mechanics or quantum information theory is a very interesting future direction.\n    \n\nWe are grateful for the reviewer's feedback. We have made an effort to disclose all the changes made to the manuscript as clearly as possible. Given this and our previous discussions, we are hopeful that the reviewer continues to support the paper. Should there be any questions or concerns, we are always ready for further dialogue.\n\n#### References\n- Wilson, Robert A. Subgroups of Clifford algebras. arXiv preprint arXiv:2011.05171 (2020).""}}, {'rebuttal': {'value': 'We thank the reviewer for the actionable feedback. We address their concerns and questions in the following.\n\n1. *Familiarize readers with the Clifford algebra, perhaps with a tutorial.*\n\n    a. Following up with a tutorial is a great suggestion! Indeed, we are already working on a blog post series that explains the subject matter in a less demanding way. We realized, after studying related work, that the orthogonal group acting on the Clifford algebra was not studied in a most general form. Physicists, engineers, and mathematicians usually restricted themselves to, e.g., definite or nondegenerate quadratic forms. In the context of deep learning, we studied this more generally, requiring a more rigorous approach. \n\n2. *How is the data being prepared and processed? Explain with an example.*\n\n    a. We can give you some intuitions here. 2a: The neural network tensor shapes of the Clifford algebra networks are of the form $B \\times C \\times 2^n$, where $n = \\dim(V)$. If we have scalar-valued data, we can use the first component of that last dimension to embed those, since $\\mathrm{Cl}^{(0)}(V, q)=\\mathbb{F}$. For vector-valued data we can use $\\mathrm{Cl}^{(1)}(V, q) = V$. The other components are left at zero at first. 2b: This tensor is then fed into the neural network, which also computes features in the other Clifford subspaces, and as such, we get densely filled multivectors. 2c: At the end of the network, we can project onto the grade $k$ subspace to get a $k$-vector. Usually, this would be the grade $0$ subspace for scalar-valued predictions or grade $1$ for vector-valued predictions. 2d: Regarding your complex numbers example, the tensor shape would be $B \\times C \\times 2$, where we have 2 for the real and imaginary components. You populate the last dimension using your complex-valued data. We hope this helps!\n    \n    **Action taken:** we now give a bit more intuition about these procedures in the experimental section.\n\n\nWe thank the reviewer for their valuable insights. We have strived to be as explicit as possible in tackling the remaining issues. If our responses meet expectations, we hope the reviewer maintains their support for our paper. We are ready for any more discussions or questions the reviewer might have.'}}, {'rebuttal': {'value': ""We thank the reviewer for their highly valuable feedback. We address their concerns and questions in the following. The reviewer has already transformed weaknesses into questions (thanks!), which we answer directly.\n\n1. *How is translation equivariance obtained?*\n\n    a. Translation invariance is obtained through the subtraction of a reference point, like the mean position of the point cloud, which is a typical approach to getting translation invariance. To obtain equivariance, one simply adds the reference point back onto the NN's prediction. Villar et al. (2021) show that this has some universality properties regarding invariant functions. While relative positions are the golden standard for translation equivariance, the Clifford algebra approach can offer an alternative. One of the reasons why we developed the theory for the fully general, potentially degenerate metric case is that we can get $\\rho(w)$ to act as a Euclidean isometry (see Remark D.30). This means we can get translation equivariance without subtracting a reference point. This is what the recent developments in projective geometric algebra (PGA) study, which use the signature $(n, 0, 1)$ (Roelfs \\& de Keninck, (2021)). However, there were some practical technicalities. To give an idea, we have to map the data from the usual vector space V to its dual subspace in a well-defined manner, which is where the Euclidean group acts. However, here the metric is fully degenerate and does not correspond to the metric on the original space V. These difficulties motivated us to leave this for future work.\n2. *How are invariant predictions obtained?*\n\n    a. There are two approaches to obtaining invariance. First, the scalar subspace $\\mathbb{F}=\\mathrm{Cl}^{(0)}(V, q)$ is always invariant with respect to $\\rho(w)$. So, one can take the grade projection of the NNs output onto the scalar subspace to obtain invariant outputs. On top of this, the algebra-extended quadratic form $\\bar{q}: \\mathrm{Cl}(V, q) \\to \\mathrm{Cl}^{(0)}(V, q)=\\mathbb{F}$ is always invariant. So one can concatenate the zero-projection with the quadratic form of the covariant subspaces to get an invariant. One can use typical feed-forward neural networks to project this to an invariant of the dimension the problem requires.\n    \n    **Action taken:** we now clarify this in the invariant tasks.\n\n3. *Clarifications regarding the volume experiments.*\n\n    a. 1. We define a covariant object as a quantity that transforms in a nontrivial but predictable way under a change of coordinates. 2. The reviewer is right that scalar methods such as the default implementation of VNs produce O(3) invariant features, and thus VNs are not able to distinguish a tetrahedron and its reflected copy. We add this for clarity. Of course, we do not claim that such methods cannot be adapted to obtain access to these features. However, one of the merits of the Clifford algebra networks is that the network can readily distinguish these cases. 3. We're sorry that there is an unclarity regarding classification/regression. In Sec. 5.1, we detail that we regress the signed volume against the spatial positions. The number of training samples is then given in Figure 3. The ratio of positive vs. negative volumes is 50/50. The task is thus to predict the volume and not only its orientation.\n\n    **Action taken:** we adjusted section 5 to clarify these matters.\n\n4. *Clarify the neural architecture against baselines for Section 5.1-2. How does the complexity of the method compare against the baselines?*\n\n    a. We use feed-forward networks based on the layers proposed in Section 3. We compare against baselines of similar numbers of parameters, where source codes were taken from original implementations. For 5.2, we took the numbers directly from the source paper, and used networks with similar numbers of parameters. For further details, please consider the attached PDF file.\n\n    **Action taken:** we now elaborate better on model and baseline complexities in the experimental section.\n\n5. *Is the training setup the same for all experiments? Were hyperparameters optimized?*\n    a. We did no exessive hyperparameter tuning for CGENN architectures in experiments 5.1 and 5.2. We rather used design principles (number of parameters, layers from baseline architectures). We searched for learning rates for 5.3 and tried a few architectures and learning rate regimes for 5.4. Reported baseline numbers for experiments 5.2, 5.3, and 5.4 are taking from existing literature. For experiments in 5.1, baselines were optimized for similar parameter counts as CGENNs. We also ran small learning rate searches for them. \n\nWe are very grateful for the reviewer's feedback. Where applicable, we have made an effort to disclose all the changes made to the manuscript. Given this and our previous discussions, we are hopeful that the reviewer is open to promoting the score. Should there be any questions or concerns, we are always ready for further dialogue.\n\n#### References\n- Villar, Soledad, et al. Scalars are universal: Equivariant machine learning, structured like classical physics. Advances in Neural Information Processing Systems 34 (2021): 28848-28863.\n- Roelfs, Martin, and Steven De Keninck. Graded symmetry groups: plane and simple. Advances in Applied Clifford Algebras 33.3 (2023): 30.""}}, {'rebuttal': {'value': 'We thank the reviewer for the encouraging feedback. We address their concerns and questions in the following.\n\n1. *What is being computed in, e.g., equation 11?*\n\n    a. As input data, we consider points in a vector space $V$, for example, $\\mathbb{R}^3$. These can be locations, velocities, forces, etc. Since $\\mathrm{Cl}^{(1)}(V, q)$ is isomorphic to the vector space $V$ that we construct it on, we can treat the data as objects in the Clifford algebra. As such, these will be multivectors where only the vector part is nonzero. However, as we propagate through the network, the other multivector elements will get populated. As such, equation 11 computes at first linear combinations of vector coefficients expressed in a fixed basis. But later in the network, these will be multivectors. Equations 12 and 13 compute geometric products. \n\n    **Action taken**: we have added a few sentences clarifying these matters.\n\n2. *What is the objective function*? \n\n    a. The objective functions in all experiments were mean-squared errors except for the top-tagging experiment. This is a binary classification task and uses the binary cross-entropy loss. \n\n    **Action taken**: we have updated the text to clarify these matters.\n\n3. *In the volume experiments, what are the inputs to the Clifford network*?\n\n    a. Indeed, the input is a point cloud (tetrahedron). The positions are expressed as coefficients in a fixed basis, which get processed by the neural network.\n\n    **Action taken**: we have updated the text to clarify these matters.\n\n4. *Compare to Villar et al., 2021.*\n\n    a. Thanks for bringing up this paper! The crucial difference is that Villar et al.  consider representations of the orthogonal group $O(n)$  acting on $(\\mathbb{R}^{n})^k$ and maps from $(\\mathbb{R}^{n})^k \\to \\mathbb{R}^n$, or, more in our notation, $V^k \\to V$. This is a subset of the spaces that the orthogonal group can act on. There are also maps from other representations of O(n), e.g., tensor product representations, Clifford algebra representations, (irreducible) sub-representations, etc. The signed volume experiment considers a map into the space of scalars that are not invariant to reflections, which is an example of a map not captured by the theory of Villar et al.\n\n    **Action taken**: We have added this paper to the literature list and discuss our findings in comparison with these results.\n\n5. *The universality of the Clifford approach. Do there exist functions equivariant under O(d) but not the ""Clifford group""?*\n\n    a. We show in the paper that there are maps that Clifford layers can represent that scalarization methods cannot. Similarly, we can certainly also construct maps that Clifford methods cannot represent. In our paper, we only consider one fixed action for the Clifford algebra (and their subvector spaces), namely the adjusted twisted conjugation. In this setting, $O(d)$-equivariance is the same as Clifford group equivariance. One can consider maps between spaces outside of the Clifford algebra that the Clifford group does not cover. However, the Clifford algebra offers a closed set of nice, geometrically inspired representations that are more expressive than scalars but still tractable.\n\nWe thank the reviewer again for the valuable feedback. Where applicable, we tried to be as transparent as possible about the adjustments made to the manuscript. Considering these and the above, we hope that the reviewer is open to promoting the score. If any questions or comments arise, we are happy to discuss further.'}}, {'summary': {'value': 'The paper develops a new kind of neural network model based on the Clifford group, which makes the neural network E(n)-equivariant.  The model is tested on a number of datasets, showing that it is capable of recovering the desired structure from the data.\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'This seems like an interesting and important direction.  The results are convincing, in the sense that this approach ""works.""  The method is backed up by nice theory.\n\n'}, 'weaknesses': {'value': 'Although the intro and figure 1 at the beginning are helpful, I think the rest of the paper is hard to follow.  There are some theoretical results, but then when it comes to the methodology, section 4, I am left wondering what is actually being computed.  For example, what is involved in computing equation 11?  it says the x_i are elements of Cl(V,q), ok but what is the input to this system?  same for eqs. 12 and 13.  \nAnd what is the objective function?\nFor the first experiment on signed volumes, this seems like an interesting task, but it is not clear what is the form of the input data - a data cloud of x,y,z points?  What is the input to the Clifford network?\nI am having a hard time picturing concretely what is going on here.  More specifics would be helpful.\n\n'}, 'questions': {'value': 'How would you compare to the following paper: https://proceedings.neurips.cc/paper/2021/file/f1b0775946bc0329b35b823b86eeb5f5-Paper.pdf. \nThis paper develops a universal family of neural networks for O(d)-equivariant functions. This seems to stand in tension with the claims in the Clifford algebra paper that scalar feature-based methods cannot capture certain kinds of information. (I\'m sure that some more thought could explain what\'s going on, but I feel like that\'s work the authors of the submission should do, rather than the reader.) \nRelatedly, I don\'t think I saw any statement about whether or not the Clifford algebra approach is universal (maybe I missed it?).\nAlso, the authors end Section 3 by saying ""equivariance w.r.t. the Clifford group [...] implies equivariance w.r.t. the orthogonal group,"" but this statement, by itself, still leaves a question open: Do there exist functions equivariant under O(d) but not the ""Clifford group,"" which their method then couldn\'t learn?'}, 'limitations': {'value': 'n/a'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper introduces a new method for constructing E(n)-equivariant networks called Clifford Group Equivariant Neural Networks (CGENNs), based on an adjusted definition of the Clifford group, a subgroup of the Clifford algebra. The researchers have shown that the group’s action forms an orthogonal automorphism that extends beyond the typical vector space to the entire Clifford algebra, respecting its multivector grading and multiplicative structure. This leads to non-equivalent subrepresentations corresponding to the multivector decomposition and allows parameterizing equivariant neural network layers. CGENNs operate directly on a vector basis and can be generalized to any dimension.\n\nIncorporating group equivariance in neural networks has proved useful in many areas, including modeling the dynamics of complex physical systems and studying or generating molecules, proteins, and crystals. This paper demonstrates that the CGENNs can handle directional information more accurately and nuancedly than scalarization methods, operating directly in a vector basis rather than alternative basis representations. They can also transform higher-order features carrying vector-valued information, and readily generalize to orthogonal groups of any dimension or metric signature. The authors successfully demonstrated these advantages on various tasks, including three-dimensional n-body experiment, a four-dimensional Lorentz-equivariant high-energy physics experiment, and a five-dimensional convex hull experiment.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""**Originality**\nThis paper has many strengths across multiple dimensions. First, it tackles the problem of building an Equivariant network using a fresh perspective that has not been, as far as I know, used in the literature. Thus the use of the Clifford Group is an exciting direction of technological endeavor. Certainly, the mathematics behind building the Linear, Geometric Product, and Nonlinearities is nontrivial but offers what appears to be greater modeling flexibility.\n\n**Quality**\nIt is abundantly clear that immense care has been taken with the writing of this paper. This is substantiated by the large and extensive appendix which in itself can prove to be a useful reference outside of the main thesis of this paper. Furthermore, it is clear that a computational approach was taken to build the equivariant layers as I appreciated the authors that the authors acknowledged the naive $(n+1)^3$ interactions needed in their geometric layers which could be reduced by first applying a linear projection.\n\n**Clarity**\nThe authors should be given credit for attempting to make this paper clear and accessible. Unfortunately, it is not outside for those who are likely already familiar with geometric algebras. Although the writing and the flow of information are still very clear if one pretends to know what the Clifford group is. \n\n**Significance**\nIn this reviewer's opinion, this work is significant for several reasons. First, it allows for the creation of equivariant networks in a completely different manner and one that appears to be more flexible/expressive. This is due to the Clifford group allowing for non-equivalent subrepresentations. For example,  Clifford group equivariant models can extract covariant quantities which cannot be extracted from scalarization methods. Furthermore, the early empirical results suggest that such an approach also leads to empirical benefits and beats current equivariant models which suggests that this is a ripe direction for continued investigation.""}, 'weaknesses': {'value': 'This paper has a few areas for improvement that I highlight below.\n\n1.) I thank the author for their efforts to make the paper accessible, but the appendix is not a very friendly introduction. For instance, in some places, the authors acknowledge that their definitions depart from existing ones in the literature. But in other places, they claim to follow the format of other works (e.g. C.1). This makes it hard to follow and trust what the authors state.\n\n2. Perhaps what bothers me most is the fact that the motivation for using the Clifford algebra group is lost in all the technical jargon. The importance of being able to use multi-vectors in ML-specific problems is never really motivated in a convincing way. Even at present, I find it difficult to pinpoint exact non-toy applications where these tools might prove useful. Albeit there is no doubt the tools themselves are mathematically interesting.\n\n3. There are parts of the paper where it becomes unclear which part of the theory is an original contribution of the authors versus something that is already present in the math literature on Clifford group/algebra. As far as I can tell the design of the adjusted twisted conjugation is novel and its extension is an original contribution of the authors (and the subsequent ML-specific layers). Can the authors tell me if I missed anything?\n\n4. The experiments are quite preliminary. Perhaps this is by design as the authors note that the computational complexity can partially be resolved with better hardware-specific implementations. I would have loved to see the power of these methods on larger-scale equivariant problems. For instance, I am certain the authors are familiar with molecular dynamics simulations at a larger scale. These would already have the desired symmetries and established baselines to compare against.\n\n5. The authors could improve the method section by providing an empirical investigation of the runtime complexity of their actual experiments in comparison to the baselines. Right now, a reader may intuit that the Clifford group equivariant networks are more computationally expensive but, exactly how much is not immediately clear. '}, 'questions': {'value': ""1. One part that is not clear to me is how equivariance is preserved in the geometric layers if you use a linear map to first project down to $l$. This would appear to break equivariance. Can the authors please comment on this and how it doesn't break the desired symmetry?\n\n2. A limitation of the steerable equivariant literature is that it is heavily reliant on the Wigner-D matrices for $O(3)$. It seems the current effort in the Clifford group also applies to the orthogonal and $E(n)$ group. Can this approach be used to model other continuous symmetries e.g. $SU(2)$ or is this not possible?""}, 'limitations': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""In this submission the authors introduce an equivariant neural network architecture building on the Clifford algebra (defined by a vector space and a quadratic form).\nThey remind that this algebra admits an orthogonal decomposition over sub-vector spaces called grade $m$ where $m$ is the number of basis elements.\nThis is referred as the 'multivector grading of the Clifford algebra'.\nThey identify a (Clifford) subgroup and its (adjusted twisted conjugation) action which not only acts on the original vector space but also on the Clifford algebra whilst satisfy many properties including multiplicatively w.r.t. the geometric product.\nThey show that equivariance w.r.t. this a Clifford group acting on the Clifford algebra implies equivariance w.r.t. the orthogonal group acting on the Clifford algebra.\nThen they propose several layers, including a linear layer and a geometric product layer which they show to be equivariant w.r.t. the action of the Clifford group.\nThen they empirically assess their proposed approach on synthetic tasks with $O(3)$, $O(5)$ or $E(3)$ equivariance and show that it overperform scalar based methods but also steerable NNs.\nFinally, they tackle the task of identifying top quarks from high-energy jets produced in particle collisions at CERN, and show that they are able to perform as well as recent specialised neural networks.\n""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- This is a nice paper that builds on this recent research avenue of equivariant neural networks based on the Clifford/geometric algebra.\n- In find particularly appealing the fact that the methodology applies to any dimension, and more generally than $O(n)$ equivariance via the choice of quadratic form $\\mathfrak{q}$ as per Section 5.4 (if I understood correctly).\n- Additionally, it appears that the method is empirically able to fit well a variety of functions and able to generalise.\n- The paper is pretty well written given the space constraint, although I give some suggestion on improvements below.'}, 'weaknesses': {'value': ""- Likely due to space constraint, yet the methodology would deserve more discussion.\n    - For instance, how is the data embedded into the algebra (e.g. for higher order quantities such as an inertia tensor)?\n    - How is the quadratic form $\\mathfrak{q}$ chosen (e.g. is it the Minkowski product for the Jet tagging experiment)?\n    - I also believe that the linear and geometric layers could benefit from an illustrative diagram. Perhaps it may be useful to draw parallel with tensor product and irreducible representations for readers familiar with this language.\n- What's more the main paper is currently lacking a discussion on scalability of the method, and how this compares to Clebsch-Gordan tensor product approaches, although I understand that the space is limited.\n- Another points which I find slightly frustrating is the lack of ablation study, as generally it is hard to identify why this method overperform tensor product / irreps approaches. Is it more parameter efficient? Does it generalise better? Does it yield a better optimisation landscape? Is it computationally faster? Obviously fully answering this questions would deserve a full paper on its own, yet some elements of answer would be nice :)""}, 'questions': {'value': ""- line 62: 'our method readily generalizes to orthogonal groups regardless of the dimension'. Doesn't the method proposed in [Cesa et al. 2021] also work for any dimension $n$?\n- Eq 1: What is the intuition behind the independence of the choice of orthogonal basis? Is it because by combining elements from one basis (via the geometric product) one could obtain the second basis? How come the limiting factor is really the number $m$ of such basis elements?\n- line 232: Worth saying a bit more about the 'layer-wide normalization' proposed in [70]?\n- line 235: 'However, we still require activation functions after linear layers'. Does this statement come from practical requirements for the method to work well, or from some universal approximation theorem with necessary non-linearity after the linear layer?\n- Section 5.1: Is the 'signed volume' a pseudo-scalar?\n- One of the advantage of this method that it readily works whatever the input space dimension, yet what is the scalability of the method with respect to the dimension of the space?\n- Section 5.2: What are the reasons for EMLP underperforming? It is theoretically a universal approximator.\n- Section 5: Do all methods have the same number of parameters? or same compute time?\n\n\nA PROGRAM TO BUILD E(n)-EQUIVARIANT STEERABLE CNNS, Cesa, Gabriele and Lang, Leon and Weiler, Maurice, 2021""}, 'limitations': {'value': ""- 'CGENNs induce a (non-prohibitive) degree of computational overhead'. Where does this overhead come from? What specific operation would benefit from having a custom GPU kernel? More generally it would be really nice to discuss the scalability of the method. In particular vs other 'steerable' methods which rely on parametrised tensor product via Clebsch-Gordan coefficients.\n""}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'I like to admit that I am not familiar with this area of work. I try my best to review the key contributions of this work. My review is more of clarification than critic.\n\nThe theory part of the paper lies mainly in section 3.1 starting with Eq.(5).\nThe computation part of the paper is given in section 4. The authors introduce two kinds of layers. Linear Layers and Geometric Product Layers. \n\nLinear layer mix the input channels of the same grade (Eq.(11)).\nInteraction layer takes the geometric product of the i and j grade of x1, x2 and project to the k-th grade.\n\nSeveral experiments were performed using this neural network. I will discuss more about the experiments in later part of this review.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. The paper explore a different approach to deep learning. This paper helps in adding a new dimension in the field of deep learning.\n2. The authors provided a huge amount of background and foundations in the supplementary materials. This is important because I presume relatively few readers are familiar with Clifford algebra.\n3. Although I cannot fully understand the theoretical part of this work. It seems to me the authors try to substantiate their work with theories.'}, 'weaknesses': {'value': '1. The strength of this paper may also be ""its weakness"", readers without background on Clifford algebra may struggle to pick up this area of work. It will be good if the authors follow up with a good tutorial. Perhaps a series of online learning materials and provide its link in this paper. For example, make an archive tutorial paper (or online video) and those locations are cited in this paper. The supplementary materials of this paper is good. but it is insufficient to bring people outside of this field up to the level to use this paper.\n2. The output of the neural network is given by Eq.(11) and Eq.(13). I understand that the output is also an element of the Clifford algebra. I struggle to understand how this output is link to the use cases in the experiments. It will be good if the authors help the readers by describing the experiments in detail. Give a step-by-step walk through of :\n2a: how the data is being prepared and in what format\n2b: how the data is being feed into the neural network\n2c: how to link the k-th grade of x to the numerical output.\n2d: perhaps walk through with a simple example, like one example using complex numbers.\n\nI explain 2c a bit more here. For a complex number c1 = 2+3i, the zeroth grade is 3 (or the 1 element). The first grade is 2 (or i). If the author can guide the reader through on how to input c1 into the linear layer and explain what is the output, that will help. Similarly, the author may also give another example c1=1-2i and c2=4+I on how to feed c1 and c2 into Eq.(12) and Eq.(13).'}, 'questions': {'value': 'How to prepare data to feed into the neural network? Perhaps the authors can give a simple example(s) of processing complex numbers and/or quaternions.\n'}, 'limitations': {'value': 'Readers without a background of abstract algebra or Clifford algebra may find it hard to understand this paper.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents a novel approach for creating E(n)-equivariant models based on Clifford (geometric) algebras. \n\nThe authors identify the Clifford group and its action. By extending this action to the entire Clifford algebra, remarkable properties can be obtained enabling the construction of equivariant maps from the Clifford algebra to itself, as well as other equivariant operations, such as grade projection. \nUsing these, an equivariant Clifford group neural network operating on vector fields can be constructed, capable of a more accurate and nuanced interpretation of the underlying structures than the baseline scalar-field networks. \n\nThe proposed method exhibits application versatility across different tasks and dimensionalities of the space.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'S1. The high quality of writing and presentation are two strong features of the paper. The authors succeeded in finding a good balance between the amount of technical detail and the narration clarity. \n\nS2. The paper presents novel theoretical results based on Clifford algebras, enabling an original way of constructing equivariant neural networks, which is a great contribution to the field.  \n\nS3. Experimental validation is versatile and, to a large extent, convincing.'}, 'weaknesses': {'value': 'W1. Missing details in the presentation of the proposed method, including: \n\n(See the questions section for more information.) \n\n- translation equivariance (Q1) \n\n- invariant prediction computation (Q2), \n\n- the architecture of the proposed networks in the experiments (Q4). \n\n \n\nW2. Incomplete comparison with other methods:   \n\n- The support of the claim that the scalar-feature methods are not able to extract some essential geometric properties from input data needs to be elaborated on (Q3). \n\n- Discussion on the complexity of the proposed method vs the baselines is missing (Q4).   \n\n- Some training details are missing (Q5). \n\n\nAddressing these weaknesses will improve the presentation and clarify the support of certain claims. '}, 'questions': {'value': ""Q1. Translations: \n\n- The authors claim to present an E(n)-equivariant method.  \n\n- As discussed in Section 3.2, equivariance w.r.t. the Clifford group implies equivariance w.r.t. the orthogonal group O(n). It is, however, unclear how **translation** equivariance is attained. \nIn fact, all the presented experiments involve only the orthogonal group transformations: in the $n$-body experiment, the authors use mean-subtracted positions of the particles, thereby removing the effect of translation already on the input level. \n\n- Could the authors clarify how translations can be handled using the proposed layers? \n\n \n\nQ2. How are O(n)-**invariant** predictions obtained with the proposed method? \n\n \n\nQ3. The claim of better underlying geometric properties capturing is meant to be supported by the *signed-volume experiment*. I would like for the authors to elaborate on the claim itself and clarify the presented experimental support. \n\n- How do the authors define *covariance*? \n\n- Some of the considered scalar-feature methods extract equivariant features and compute the invariant features from them to perform classification/segmentation requiring this. \nFor instance, in the theory of the VN method [34], there's nothing that restricts the features to only be equivariant under rotations and not reflections. In fact, the invariant features are obtained as the inner product of equivariant features, which also cancels the effect of reflections thus making the method produce O(3)-invariant predictions.\nThis makes the VN method unable to distinguish a tetrahedron and its reflected copy (and thus, their signed volumes will not be distinguished either) by the design of the invariant computation block only, even though the method extracts equivariant features. \nThis should be taken into account in the comparison in Section 5.1. \n\n- Could the authors provide more details of the experimental setup? I want to see the number of samples, the ratio of positive/negative volumes, and the success rates of the predictions given positive/negative volumes for the proposed method and the baselines.\n\n \n\nQ4. Could the authors provide details of their method architecture used in the experiments in Sections 5.1-2? How does the complexity of the method compare to the baselines? \n\n \n\nQ5. Is the training setup the same for all the methods in the experiments? I.e., were the training hyperparameters optimized for the proposed method and used for others? ""}, 'limitations': {'value': 'The limitations and broader impact are adequately addressed by the authors. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Clifford Group Equivariant Neural Networks'}, 'authors': {'value': ['David Ruhe', 'Johannes Brandstetter', 'Patrick Forré']}, 'authorids': {'value': ['~David_Ruhe1', '~Johannes_Brandstetter1', '~Patrick_Forré1']}, 'keywords': {'value': ['Clifford algebras', 'geometric deep dearning', 'Clifford group equivariance', 'E(n)-equivariant neural networks', 'O(n)-equivariant neural networks']}, 'TLDR': {'value': 'A method to construct E(n)- and O(n)-equivariant neural networks using Clifford algebras.'}, 'abstract': {'value': ""We introduce Clifford Group Equivariant Neural Networks: a novel approach for constructing $\\mathrm{O}(n)$- and $\\mathrm{E}(n)$-equivariant models. We identify and study the *Clifford group*: a subgroup inside the Clifford algebra tailored to achieve several favorable properties. Primarily, the group's action forms an orthogonal automorphism that extends beyond the typical vector space to the entire Clifford algebra while respecting the multivector grading. This leads to several non-equivalent subrepresentations corresponding to the multivector decomposition. Furthermore, we prove that the action respects not just the vector space structure of the Clifford algebra but also its multiplicative structure, i.e., the geometric product. These findings imply that every polynomial in multivectors, including their grade projections, constitutes an equivariant map with respect to the Clifford group, allowing us to parameterize equivariant neural network layers. An advantage worth mentioning is that we obtain expressive layers that can elegantly generalize to inner-product spaces of any dimension. We demonstrate, notably from a single core implementation, state-of-the-art performance on several distinct tasks, including a three-dimensional $n$-body experiment, a four-dimensional Lorentz-equivariant high-energy physics experiment, and a five-dimensional convex hull experiment.""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/1be85d922d5108bf72a28a8622c234fbde8e470f.pdf'}, 'supplementary_material': {'value': '/attachment/cf361e5c1c85cdca4f889260cb513999b0a99d93.pdf'}, '_bibtex': {'value': ""@inproceedings{\nruhe2023clifford,\ntitle={Clifford Group Equivariant Neural Networks},\nauthor={David Ruhe and Johannes Brandstetter and Patrick Forr{\\'e}},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=n84bzMrGUD}\n}""}, 'paperhash': {'value': 'ruhe|clifford_group_equivariant_neural_networks'}}]"
"['Guillermo Ortiz-Jimenez', 'Alessandro Favero', 'Pascal Frossard']",NeurIPS,Task Arithmetic in the Tangent Space_ Improved Editing of Pre-Trained Models,https://neurips.cc/virtual/2023/oral/73879,2023," Task arithmetic has recently emerged as a cost-effective and scalable approach to edit pre-trained models directly in weight space: By adding the fine-tuned weights of different tasks, the model's performance can be improved on these tasks, while negating them leads to task forgetting. Yet, our understanding of the effectiveness of task arithmetic and its underlying principles remains limited. We present a comprehensive study of task arithmetic in vision-language models and show that weight disentanglement is the crucial factor that makes it effective. This property arises during pre-training and manifests when distinct directions in weight space govern separate, localized regions in function space associated with the tasks. Notably, we show that fine-tuning models in their tangent space by linearizing them amplifies weight disentanglement. This leads to substantial performance improvements across multiple task arithmetic benchmarks and diverse models. Building on these findings, we provide theoretical and empirical analyses of the neural tangent kernel (NTK) of these models and establish a compelling link between task arithmetic and the spatial localization of the NTK eigenfunctions. Overall, our work uncovers novel insights into the fundamental mechanisms of task arithmetic and offers a more reliable and effective approach to edit pre-trained models through the NTK linearization.",Oral 6A LLMs,https://openreview.net/pdf?id=0A9f2jZDGW,https://openreview.net/forum?id=0A9f2jZDGW,0A9f2jZDGW,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper studies the use of task vectors, i.e. the difference between a fine-tuned model and a pre-trained model, to perform task arithmetic, i.e. adding or removing capabilities to a model. A new theoretical viewpoint is developed that links the success of task vectors to ""weight disentanglement"", and this perspective is used to develop a new method for performing task arithmetic that outperforms prior methods. Reviewers all appreciated the clearly articulated theory and convincing experiments and unanimously voted to accept the paper.'}}, {'comment': {'value': ""I want to thank the authors for their thorough response to every reviewer and for addressing all of my concerns.\n\nHaving closely examined the other reviews and the authors' responses, it's clear they've put in substantial effort to incorporate reviewer feedback and improve their work (which was already of high level). During the rebuttal period, the authors added more experiments and clarifications that strengthened the paper's contributions and impact across fields, significantly extending its applicability to different models and fields. \n\nGiven the unanimous acclaim for the paper's strengths (i.e., exceptional clarity in writing, substantial theoretical and experimental components, and valuable implications) and the authors' diligent revisions, I am confident in upgrading my recommendation to a score of 10.""}}, {'comment': {'value': 'I thank the authors for their detailed feedback. After carefully reading through the clarification as well as the other reviews, most of my concerns have been addressed, and these new experimental results further strengthen the presented analyses. I thus raised my score.'}}, {'title': {'value': 'Acknowledgement of author responses'}, 'comment': {'value': 'I thank the authors for their responses and the further experiments. These results further strengthen what is already a great paper. Well done.'}}, {'title': {'value': 'Updated rating'}, 'comment': {'value': 'The rebuttal addressed my concerns. The new results on a convolutional backbone and NLP tasks empirically confirmed the generality of the analysis. Overall, this work is well-positioned to inspire both the theory and practice of foundation model adaptation. I thus raised my rating from weak accept to strong accept.'}}, {'rebuttal': {'value': 'We appreciate that the reviewer reported that our paper is very interesting and has impressive results, and their engagement to improve it. Below, we address their comments.\n \n**Adding more tasks**\n \nFor the paper, we are using the experimental setting of Ilharco et al. [39], where task arithmetic was introduced. Namely, our task-addition experiments already involve a set of 8 different vision tasks. Yet, while the scalability of task arithmetic across a larger number of tasks is an appealing question, it goes beyond the paper’s objective and is left for future investigations. In the revised version of our manuscript, we will also include results on NLP tasks and using other convolutional architectures.\n \n**Disjoint task support hypothesis**\n \nOur theoretical analysis specifically focuses on non-overlapping scenarios, consistent with the case which is most studied in the empirical literature. In fact, the hypothesis of having disjoint task supports is satisfied in both Ilharco et al. [39] and our work. Encompassing overlapping task supports – which might require a slight change in the definition of weight disentanglement – remains an interesting problem. However, we do not see studying only the non-overlapping case as a weakness. Indeed, in the context of vision-language tasks, the input space is the Cartesian product of all images and captions, which is a high-dimensional space in which the overlap between tasks might be minimal. We will ensure to add this justification in the revised version.\n \n**Previous linearity hypothesis**\n \nWortsman et al. [80] observe in Appendix F that even though averaging weights and averaging output functions in practice are not exactly the same, these two methods are not as different as they appear. In particular, they report that these methods are equivalent in the NTK regime and this regime might be an accurate approximation of fine-tuning. Similarly, in Appendix A of Ilharco et al. [39], the authors justify their results on task arithmetic based on the NTK hypothesis for which they also cite Wortsman et al. [80], sharing many of the same authors.\n\nConcerning the question on the hypothesis introduced in [79], we do not have arguments to refute it. In fact, we believe that weight disentanglement might play a role in this setting as well if different models are specializing to different regions of the input space. In that case, the terms-which-may-be-small would be the disentanglement error.\n \n**Effect of scale on weight disentanglement**\n \nOur results reveal that by scaling the number of model parameters, the performance of linearized fine-tuning becomes closer to the one of standard non-linear fine-tuning. As commented briefly in Appendix D.1, one plausible interpretation is that larger models, which are more over-parameterized, inherently induce a stronger kernel behavior during fine-tuning. Namely, since the models have more parameters, each parameter has to change less to fit the training examples. As a result, they tend to stay closer to the NTK approximation, closing the gap with linearized models and taking benefit of the better weight disentanglement of the models lying in the tangent space. \n\nAs also suggested by Reviewer [DjkZ](https://openreview.net/forum?id=0A9f2jZDGW&noteId=v6Lz3dFhri), we conducted supplementary experiments that visualize how weight disentanglement varies changing the model scale (see Figure R.2 of the *Author Response document* attached [here](https://openreview.net/forum?id=0A9f2jZDGW&noteId=7E6o5YEkJw)). Consistently to our results, larger models exhibit stronger weight disentanglement, as highlighted by the larger light region in the right panel of the first row of Figure R.2. Yet, interestingly, the models linearly fine-tuned are always more weight disentangled than the non-linearly fine-tuned ones, highlighting the strength of linearized models for model editing. We will add this discussion and the new results to the paper.\n\n**Adoption of linearized fine-tuning**\n \nLinearized fine-tuning, as shown in our paper, gives multiple benefits for, e.g., ensembling, composition, and forgetting (negation). Notably, for convex losses, this method also enjoys a convex optimization landscape and could be used to provide further theoretical guarantees in the future. However, we want to remark that studying the performance of linear vs non-linear models is an ongoing line of research (see, e.g., references in Related Works – Linear vs non-linear regime). In fact, linearized fine-tuning may not be uniformly superior in all settings and architectures, although it seems to be the case for the models we studied in the present work. All in all, we hope that our findings will motivate further empirical exploration to discern in which cases linearized fine-tuning competes effectively with standard non-linear fine-tuning.\n \n**Limitations**\n \nOur limitations are clearly reported in the paper. In particular, we had a section in the Appendix to the O(1) computational complexity increase of linearized models and discussed the limitations of Proposition 1 as a remark in the main body of the text. Following the reviewer’s suggestion, we will emphasize those points further in the revised version of our work.\n \nWe thank the reviewer for their valuable feedback and remain available to answer further questions or provide more clarifications regarding the previous points.\n'}}, {'rebuttal': {'value': 'We sincerely appreciate the reviewer’s recognition of our work and their engagement to improve it!  Below, we address their comments.\n \n**Effect of scale on weight disentanglement**\n \nOur results reveal that by scaling the number of model parameters, the performance of linearized fine-tuning becomes closer to the one of standard non-linear fine-tuning. As commented briefly in Appendix D.1, one plausible interpretation is that larger models, which are more over-parameterized, inherently induce a stronger kernel behavior during fine-tuning. Namely, since the models have more parameters, each parameter has to change less to fit the training examples. As a result, they tend to stay closer to the NTK approximation, closing the gap with linearized models and taking benefit of the better weight disentanglement of the models lying in the tangent space. \n\nAs also suggested by Reviewer [DjkZ](https://openreview.net/forum?id=0A9f2jZDGW&noteId=v6Lz3dFhri), we conducted supplementary experiments that visualize how weight disentanglement varies changing the model scale (see Figure R.2 of the *Author Response document* attached [here](https://openreview.net/forum?id=0A9f2jZDGW&noteId=7E6o5YEkJw)). Consistently to our results, larger models exhibit stronger weight disentanglement, as highlighted by the larger light region in the right panel of the first row of Figure R.2. Yet, interestingly, the models linearly fine-tuned are always more weight disentangled than the non-linearly fine-tuned ones, highlighting the strength of linearized models for model editing. We will add this discussion and the new results to the paper.\n \n**Generalization to NLP tasks**\n \nTask arithmetic and our findings on weight disentanglement can be readily generalized to NLP tasks. In order to show the generality of weight disentanglement, we conducted a new experiment on a pre-trained T5 base model from Hugging Face, fine-tuned on two benchmark NLP tasks (sentiment analysis on movie reviews and question answering). The results, illustrated in the right panel in Figure R.1 of the *Author Response document*, show a notable region around the pre-trained checkpoint characterized by low disentanglement error. This finding echoes the ability of T5 to perform task arithmetic as demonstrated in Ilharco et al. [39] (Appendix D.6), thereby reinforcing the robustness of our conclusions. We will report this result in the revised version.\n'}}, {'rebuttal': {'value': ""We really appreciate the reviewer’s enthusiasm and acknowledgment of the significance of our work and their engagement to improve it!  Below, we address their comments.\n \n**Generality of our results beyond CLIP/ViT models**\n \nWe would like to emphasize that all our theoretical results are directly applicable to any model which satisfies Property 1 (Task arithmetic) regardless of pre-training scheme or architecture. Notably, any model satisfies Property 1 if and only if it is weight disentangled. As suggested, in order to show that our results are robust to the architecture choice and input modality, we have replicated our experimental analysis using convolutional neural networks and large language models:\n\n- We have repeated all our experiments using a CLIP ConvNeXt model pre-trained on LAION-400M. Remarkably, also for this architecture weight disentanglement is stronger in the tangent space to the pre-trained checkpoint (see left panels in Figure R.1 of the *Author Response document* attached [here](https://openreview.net/forum?id=0A9f2jZDGW&noteId=7E6o5YEkJw)) and linearized fine-tuning enhances task arithmetic (see Table R.1 of the *Author Response document*). We will present the complete set of new results in the revised version.\n\n- In addition, in order to investigate the effects of pre-training, we are repeating the same analysis for non-contrastively pre-trained (closed-vocabulary) ViT and ConvNeXt models, and we will add these results to the final version as well. As suggested, we will also make explicit what architectures we consider, both in the abstract and in the main text.\n\n- To substantiate the generality of weight disentanglement, we conducted a new experiment on a pre-trained T5-Base model from Hugging Face, fine-tuned on two benchmark NLP tasks (sentiment analysis on movie reviews and question answering). The results, illustrated in the right panel in Figure R.1 of the *Author Response document*, show a notable region around the pre-trained checkpoint characterized by low disentanglement error. This finding echoes the ability of T5 to perform task arithmetic as demonstrated in Ilharco et al. [39] (Appendix D.6), thereby reinforcing the robustness of our conclusions. We will report this strong result in the paper. Finally, while exploring whether linearization improves weight disentanglement and task arithmetic for different modalities – such as language – is undoubtedly captivating, it goes beyond the current scope of the paper, and we reserve it for subsequent investigations.\n \n**Disentanglement and overparameterization**\n \nWe are not aware of any results showing to what extent feature disentanglement is enabled by overparameterization. Intuitively, achieving a distinct disentanglement in feature space, as well as in weight space in the case of weight disentanglement, demands a sufficient number of model parameters. A systematic study of these quantities as the model size scales lies beyond our current scope. However, we concur that this is a fascinating question for future research.\n\n**Linear vs non-linear**\n \nOur intuition for the observation of the diminishing advantage of linearized-model task arithmetic with increasing model size is that larger models tend to stay closer to the NTK approximation. In other words, they tend to behave linearly without being explicitly constrained to do so (see, e.g., Figure 2). One explanation for this is that larger models, being more over-parameterized, inherently induce a stronger kernel behavior during fine-tuning, i.e., having more parameters, each parameter requires smaller adjustments to fit the training examples. As a result, being closer to their linearized counterparts, larger models have better weight disentanglement and can perform task arithmetic similarly to linearized models (see also the answer Effect of Scale on Non-Linear Advantage to reviewer [DjkZ](https://openreview.net/forum?id=0A9f2jZDGW&noteId=PEwcdQxgup) and the new results in Section 3 of the *Author Response document* displaying weight disentanglement as a function of model size).\n \n**Pseudo-code for the weight disentanglement error**\n \nWe thank the reviewer for their suggestion of providing the PyTorch code for computing the disentanglement error in the Appendix. This addition will enhance reproducibility, and we intend to implement it in the revised version.\n \n**Eigenfunction localization**\n \nApproximating the eigenfunctions of the NTK is a costly operation since it requires computing the kernel matrix and diagonalizing it. Hence, in general, measuring localization or other properties of the eigenfunctions is challenging. Moreover, in practice, all these properties are not displayed exactly, so a sound investigation should take into account this fact as well. All in all, this precludes an exhaustive exploration within the confines of this paper. Yet, we agree and believe that studying the spectral properties of the NTK for different datasets, architectures, and modalities holds promise for future research. We will acknowledge the importance of this avenue in our manuscript, reflecting your input.\n \n**Linearization of other architectures**\n \nLinearization readily works with the majority of architectures currently used, encompassing convolutional and transformer architectures with both smooth and non-smooth activation functions (as shown by our new experiments using ConvNeXts). Although our current framework doesn't explicitly address recurrent architectures, we believe that implementing linearization for recurrent architectures is possible We will explicitly outline the range of applicability of our procedure in Appendix B (Implementation aspects of linearized models).\n \nWe thank the reviewer for their valuable feedback and remain available to answer further questions or provide more clarifications regarding the previous points.\n""}}, {'rebuttal': {'value': 'We appreciate that the reviewer recognized that our paper is well-written, our analysis is motivating, and our experiments are convincing and their engagement to improve it. Below, we address their comments.\n \n**Generality of our results beyond CLIP/ViT models**\n \nWe would like to emphasize that all our theoretical results are directly applicable to any model which satisfies Property 1 (Task arithmetic) regardless of pre-training scheme or architecture. Notably, any model satisfies Property 1 if and only if it is weight disentangled. However, in order to show that our results are robust to the architecture choice and input modality, we have replicated our experimental analysis using convolutional neural networks and large language models:\n\n- We have repeated all our experiments using a CLIP ConvNeXt model pre-trained on LAION-400M. Remarkably, also for this architecture weight disentanglement is stronger in the tangent space to the pre-trained checkpoint (see left panels in Figure R.1 of the *Author Response document* attached [here](https://openreview.net/forum?id=0A9f2jZDGW&noteId=7E6o5YEkJw)) and linearized fine-tuning enhances task arithmetic (see Table R.1 of the *Author Response document*). We will present the complete set of new results in the revised version.\n\n- In addition, in order to investigate the effects of pre-training, we are repeating the same analysis for non-contrastively pre-trained (closed-vocabulary) ViT and ConvNeXt models, and we will add these results to the final version as well. As suggested, we will also make explicit what architectures we consider, both in the abstract and in the main text.\n\n- To substantiate the generality of weight disentanglement, we conducted a new experiment on a pre-trained T5-Base model from Hugging Face, fine-tuned on two benchmark NLP tasks (sentiment analysis on movie reviews and question answering). The results, illustrated in the right panel in Figure R.1 of the *Author Response document*, show a notable region around the pre-trained checkpoint characterized by low disentanglement error. This finding echoes the ability of T5 to perform task arithmetic as demonstrated in Ilharco et al. [39] (Appendix D.6), thereby reinforcing the robustness of our conclusions. We will report this strong result in the paper. Finally, while exploring whether linearization improves weight disentanglement and task arithmetic for different modalities – such as language – is undoubtedly captivating, it goes beyond the current scope of the paper, and we reserve it for subsequent investigations.\n\n**Effect of scale on non-linear advantage**\n \nThe reviewer correctly highlights that by scaling the number of model parameters, the performance of linearized fine-tuning becomes closer to the one of standard non-linear fine-tuning. To the best of our knowledge, this is a novel observation.  As commented briefly in Appendix D.1, one plausible interpretation is that larger models, which are more over-parameterized, inherently induce a stronger kernel behavior during fine-tuning. Namely, since the models have more parameters, each parameter has to change less to fit the training examples. As a result, they tend to stay closer to the NTK approximation, closing the gap with linearized models and taking benefit of the better weight disentanglement of the models lying in the tangent space. \n\nIn response to the reviewer’s suggestion, we conducted supplementary experiments that visualize how weight disentanglement varies changing the model scale (see Figure R.2 of the *Author Response document*). Consistently to our results, larger models exhibit stronger weight disentanglement, as highlighted by the larger light region in the right panel of the first row of Figure R.2. Yet, interestingly, the models linearly fine-tuned are always more weight disentangled than the non-linearly fine-tuned ones, highlighting the strength of linearized models for model editing. We will add this discussion and the new results to the paper.\n \n**Open questions**\n \nWe thank the reviewer for raising these stimulating questions, although we agree that these are beyond our current scope. In particular, the disjoint support assumption adopted in our work stems from the way in which task arithmetic was first introduced in Ilharco et al. [39], wherein the datasets are indeed disjoint. Yet, we acknowledge that studying task arithmetic in other settings is an interesting direction (see also the answer Disjoint Task Support Hypothesis to Reviewer [eVrq](https://openreview.net/forum?id=0A9f2jZDGW&noteId=QWXTFZW72i)). Similarly, studying the sparsity of task vectors and the effects of LoRA training are exciting open questions and avenues that warrant separate exploration.\n \nWe thank the reviewer for their valuable feedback and remain available to answer further questions or provide more clarifications regarding the previous points.\n'}}, {'rebuttal': {'value': 'We sincerely appreciate the reviewer’s recognition of our work and their engagement to improve it!  In what follows, we address their comments.\n \n**Generality of our results beyond CLIP/ViT models**\n \nWe would like to emphasize that all our theoretical results are directly applicable to any model which satisfies Property 1 (Task arithmetic) regardless of pre-training scheme or architecture. Notably, any model satisfies Property 1 if and only if it is weight disentangled. However, in order to show that our results are robust to the architecture choice and input modality, we have replicated our experimental analysis using convolutional neural networks and large language models:\n\n- We have repeated all our experiments using a CLIP ConvNeXt model pre-trained on LAION-400M. Remarkably, also for this architecture weight disentanglement is stronger in the tangent space to the pre-trained checkpoint (see left panels in Figure R.1 of the *Author Response document* attached [here](https://openreview.net/forum?id=0A9f2jZDGW&noteId=7E6o5YEkJw)) and linearized fine-tuning enhances task arithmetic (see Table R.1 of the *Author Response document*). We will present the complete set of new results in the revised version.\n\n- In addition, in order to investigate the effects of pre-training, we are repeating the same analysis for non-contrastively pre-trained (closed-vocabulary) ViT and ConvNeXt models, and we will add these results to the final version as well. As suggested, we will also make explicit what architectures we consider, both in the abstract and in the main text.\n\n- To substantiate the generality of weight disentanglement, we conducted a new experiment on a pre-trained T5-Base model from Hugging Face, fine-tuned on two benchmark NLP tasks (sentiment analysis on movie reviews and question answering). The results, illustrated in the right panel in Figure R.1 of the *Author Response document*, show a notable region around the pre-trained checkpoint characterized by low disentanglement error. This finding echoes the ability of T5 to perform task arithmetic as demonstrated in Ilharco et al. [39] (Appendix D.6), thereby reinforcing the robustness of our conclusions. We will report this strong result in the paper. Finally, while exploring whether linearization improves weight disentanglement and task arithmetic for different modalities – such as language – is undoubtedly captivating, it goes beyond the current scope of the paper, and we reserve it for subsequent investigations.\n \n**Robustness of our method**\n \nIn regard to the variability in performance in Tables 1 and 2, it is important to consider that the diverse nature of the tasks results in distinct levels of difficulty. Hence, standard deviations are likely more affected by this variability in task difficulty than the robustness of a given method. Nevertheless, we concur with the reviewer that solely looking at averages might not convey the whole picture. To address this, we showed that the improvements in performance are consistent across tasks in Appendix D.2. This clarification will be further stressed in the revised version.\n \n**Code release**\n \nWe confirm that we will release the complete codebase in a public GitHub repository once the work undergoes deanonymization.\n \nWe thank the reviewer for their valuable feedback and remain available to answer further questions or provide more clarifications regarding the previous points.\n'}}, {'rebuttal': {'value': 'We kindly thank all the reviewers for their time and for providing valuable feedback on our work. We appreciate that reviewers have pointed out that our work is interesting (Reviewer [eVrq](https://openreview.net/forum?id=0A9f2jZDGW&noteId=kbSkLPUU32)), intriguing (Reviewer [qb7d](https://openreview.net/forum?id=0A9f2jZDGW&noteId=MpKbXwmZKw)), and very well written (Reviewers [qb7d](https://openreview.net/forum?id=0A9f2jZDGW&noteId=MpKbXwmZKw), [DjkZ](https://openreview.net/forum?id=0A9f2jZDGW&noteId=v6Lz3dFhri), [sE5a](https://openreview.net/forum?id=0A9f2jZDGW&noteId=CDcYUaXFFc)), and that our results are solid (Reviewer [qb7d](https://openreview.net/forum?id=0A9f2jZDGW&noteId=MpKbXwmZKw)), impressive (Reviewer [9cnX](https://openreview.net/forum?id=0A9f2jZDGW&noteId=CetQ5EK9GW)), and impactful (Reviewers [DjkZ](https://openreview.net/forum?id=0A9f2jZDGW&noteId=v6Lz3dFhri), [qb7d](https://openreview.net/forum?id=0A9f2jZDGW&noteId=MpKbXwmZKw)).\n\nIn response to the reviews, we ran a series of **new experiments** to show the generality of our findings. Specifically,\n- We have replicated our experimental analysis using a **convolutional architecture**. Our new results, reported in Table R.1 and Figure R.1 of the *Author Response document* (see attached pdf) reveal that also for this architecture weight disentanglement is stronger in the tangent space and linearized fine-tuning enhances task arithmetic.\n- We have extended the experimental results on weight disentanglement to language by\ndemonstrating that a T5-Base model, fine-tuned on two distinct **NLP tasks**, exhibits a region around its pre-trained initialization with low weight disentanglement error (Figure R.1, right panel).\n- We have analyzed the **effect of model scale** on weight disentanglement, showing that larger models are more weight disentangled, but not as much as their linearized counterparts (Figure R.2)\n\nWe hope that these new results and the clarifications detailed in the individual comments given to each reviewer will effectively address the concerns raised during the review process. We remain available for engaging in any further discussions that may arise, and we thank you once again for your comments.\n'}, 'pdf': {'value': '/pdf/ae2c3b932867b5ffece2ee6a4e1e5bfb9bd604fb.pdf'}}, {'summary': {'value': 'This work challenges the prevailing belief regarding the origin of task arithmetic in CLIP models. While it is commonly attributed to the linear nature of fine-tuning, the authors argue that the critical factor lies in the ""weight disentanglement"" that occurs between tasks during the fine-tuning process. The paper presents a theoretical analysis and extensive empirical validation to support this claim.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'This paper explores an intriguing topic with promising real-world applications. The authors exhibit strength in establishing a solid theoretical foundation, formulating straightforward research questions, and providing well-justified explanations that strike a remarkable balance between accessibility and rigor.\n\nThe content is commendably clear and understandable, facilitating understanding for readers from diverse backgrounds. Personally, I was able to (at least, I think) grasp portions of the paper (Section 6) which required prerequisite knowledge I was not already familiar with.\n\nNotably, this paper achieves a synergy between its experimental design and the overarching claim that ""Task arithmetic is not merely a result of linear fine-tuning,"" but rather depends on ""weight disentanglement of the model with respect to the fine-tuning task set."" The authors successfully validate the performance of their proposed method through rigorous experiments (and ablations) while simultaneously providing substantial support for key theoretical hypotheses.\n\nOverall, this paper represents a remarkable contribution, embodying the meticulousness, clarity, and scholarly standards I would expect in top-tier NeurIPS submissions.\n\nI’m starting my recommendation with an 8, given my not-high confidence, I’ll adjust it according to the rebuttal discussion.'}, 'weaknesses': {'value': 'One aspect that requires attention is the clarification of the paper\'s applicability beyond CLIP models. Although there are specific references throughout the text (e.g., lines 38-49 in the introduction) emphasizing the focus on CLIP models, the overall messaging may appear too general regarding the broader applicability of the proposed method and study. To address this, I recommend at least modifying the abstract to explicitly state the paper\'s objective as ""… a comprehensive study of task arithmetic in\xa0**CLIP**\xa0models…"" instead of using the term ""vision-language models"" which could be misleading. Furthermore, exploring preliminary tests or investigations concerning the weight disentanglement of different pre-trained models would be valuable. For instance, considering the citation of various architectures in Section 6.2 (lines 301-303), extending the analysis to include some of them (e.g., convolutional neural networks) would be advantageous, strengthening the paper\'s applicability and relevance to a broader range of models and areas.\n\nAdditionally, while Tables 1 and 2 provide average performance across tasks, it would be beneficial to include the standard deviation to provide a more comprehensive understanding of the variability in performance and, therefore, the method\'s robustness.'}, 'questions': {'value': 'I’ve seen that in the supplementary material, there are some code snippets, but do the authors plan to release the full codebase upon acceptance?'}, 'limitations': {'value': 'The authors adequately addressed the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '10: Award quality: Technically flawless paper with groundbreaking impact, with exceptionally strong evaluation, reproducibility, and resources, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents a comprehensive analysis of task arithmetic using pre-trained CLIP models. It challenges the early hypothesis that task arithmetic arises from linear fine-tuning in the NTK regime and introduces weight disentanglement as a necessary condition for enabling task arithmetic.  Further experiments demonstrate that linearized fine-tuning of pre-trained CLIP models exhibits stronger weight disentanglement and improved task arithmetic compared to standard, non-linear fine-tuning. This result is accompanied by an analysis of the NTK spectrum to facilitate the understanding of weight disentanglement in linearized models. Lastly, empirical evidence suggests that weight disentanglement emerges from large-scale pre-training. The findings of the paper may shed new light on the effective adaptation of foundation models for downstream applications.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- This paper advances the theoretical understanding of task arithmetic. In particular, it introduces weight disentanglement as a strong indicator of task arithmetic, and demonstrates that linearized fine-tuning in the tangent space of pre-trained weights promotes weight disentanglement. It further analyzes the NTK spectrum of linearized models and presents a sufficient condition for weight disentanglement.\n\n- In the meantime, the findings of the paper are significant on the practical side. The experiment results justify an emerging fine-tuning scheme for adapting foundation models.\n\n- Overall, this paper strikes a good balance between theory (NTK) and practice (fine-tuning pre-trained models). Embracing a broad audience is a key strength of the paper.\n\n- Finally, the paper is very well-written. The flow of presentation is very easy to follow.'}, 'weaknesses': {'value': '- Overall, I found the theoretical analysis motivating and the experiment results convincing. That said, all conclusions of the paper are drawn from CLIP fine-tuning, which makes me wonder whether the same findings are valid for other pre-trained models that similarly exhibit task arithmetic. To this end, I encourage the authors to report results on a second pre-trained model that differs in network architecture (e.g., ResNet), learning objective (e.g., MAE) or input modality (e.g., natural language), in order to establish the generality of their findings.\n\n- The authors observed that increasing model size (ViT-B/32->ViT-L/14) closes the gap between linearized and non-linear fine-tuning. Is it a consequence of stronger weight disentanglement because the fine-tuning of larger models approaches the NTK regime? Visualization of weight disentanglement throughout the paper only considers the smallest ViT-B/32 model. Similar visualizations for larger models could be informative.'}, 'questions': {'value': 'These questions are likely outside the scope of the paper, yet I think addressing any of them via an empirical analysis could strengthen the work.\n\n- Task arithmetic makes the strong assumption that datasets from different tasks have disjoint support. This is often not true in practice. Does task addition still yield cooperative behavior when datasets overlap? How does linearized fine-tuning compare to standard, non-linear fine-tuning, especially when the assumption of non-overlapping data is violated?\n\n- In linearized fine-tuning, the optimization is restricted to the tangent space of pre-trained weights. Notably, this is conceptually similar to LoRA and adaptor-based fine-tuning, where a task vector exhibits low-dimensional structure. A natural question to ask is whether these fine-tuning approaches also produce favorable weight disentanglement / task arithmetic.'}, 'limitations': {'value': 'The paper discussed two main limitations. First, linearized fine-tuning is currently implemented using the JVP algorithm, which doubles the cost of a forward pass as compared to standard fine-tuning. Second, the spatial localization of NTK eigenfunctions is a sufficient (yet not necessary) condition for enabling task arithmetic. While the linearized models indeed respond to disjoint spatial regions in the experiments, this is not a must for task arithmetic to hold.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper theoretically and emperically investigates the reasons why task arithmetic (an emerging technique for editing pre-trained neural networks) works.\nThe paper shows that, contrary to previous hypotheses [39,79,80], lienarity of the fine-tuning on individual tasks is not sufficient to fully explain the success of task arithmetic (Sec 3).\nInstead, the authors propose the related and straight-forward idea of weight disentaglement (Eq 4) as an explanation (Sec 4), also providing a measure of the disentaglment error for two tasks (Eq 6).\nThis idea is leveraged to improve task arithmetic performance by constraining the fine-tuning to linearized models - which importantly is shown to be an improvement over post-hoc linearlization, with marginal additional computational complexity (Sec 5).\nFinally, an additional connection between task arithmetic and the eigen space of the Neural Tangent Kernel is used to argue that weight disentanglement (and hence the capacity for task artihmetic) are a learned properties during pre-training, not inherent properties of parameterization or architecture (Sec 6).\nThe empirical results focus on the CLIP image-text Vision Transformer model family, and many experimental details are reported, inclduing in the additional material in the appendix.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""This paper is the best kind of NeurIPS paper; Beautifully written and a delight to read, the authors have considered a timely and pertinent problem in an emerging machine learning domain, applied a methodological theoretical investigation; clarified prior hypotheses in the literature; used the theoretical findings to propose a simple novel methodology, and compellingly evidenced the subsequent effectiveness with an appropriate evaluation protocol. As a cherry on the cake, the methodology is a 'drop in' method that can be applied easily to existing approaches, and actual code is provided without breaking review anonymity in the supplementary material. Bravo.\n\n### Originality\n\n * There are multiple practical take-aways that are immediately useful; the task disentanglement error metric (Eq 6), intuition for why task vector coefficients should be << 1 (Ln 181), simple drop-in code in the appendix that enables re-production and immediate application of the ideas (Listing 1 in the appendix).\n\n### Quality\n\n * The work appears to be of high quality, the metrics and emprical appear to support the theoretical findings and claims.\n\n### Clarity\n\n * This paper is superbly well written, and the logical argument and flow is well constructed. This paper was a delight to read and think about.\n\n### Signifigance\n\n * Multiple compelling and genuine avenues for future research are identfidied (Ln 239, Ln 286, Ln 315, Ln354)\n * Provides timely and much-needed (i) overview of the emerging and rapidly evolving technique of task arithmetic with pre-trained models, and (ii) the beginnings of a theoretical grounding and understanding for why this technique is possible.\n""}, 'weaknesses': {'value': ""* The main weakness of the paper in the present form is that the empirical results are limited to ViT models (specifically, CLIP). Within this modality, the empirical results are compelling (e.g. using multiple model families and 8x distinct datasets/tasks), and provide evidence for the theoretical findings, however the paper's authority and strength would be enhanced by demonstrating some of the key findings hold with another architecture or data type. E.g. I would love to see the results in Table 3 (Sec 6.2) replicated, even in a small way, with GPT or BERT on a text dataset. This would provider further strength for the empirical claims around Eigenfunction localization.\n""}, 'questions': {'value': "" 1. Ln 336 on 'Feature disentanglement'; to what degree is feature disentanglement enabled by over-parameterization / very large numbers of parameters? If this is the case, what is the parameter count relative to - i.e. some measure of the complexity of the input space or the function space represented by the data? Is there a way to quantify with a metric the 'capacity' for feature disentaglement of a given NN archiecture? These could be useful areas for investigation.\n 2. Related to the above point, Ln 233 notes that the advantage of the linearized model task arithmetic approach diminishes as the number of model parameters increases. I find this curious and would have expecte the opposite result - do you have any intuition why this is the case?\n 3. Pseudo-code or actual PyTorch code for Eq 6 would be a very helpful (and I assume straight-forward) addition to your supplementary material - this would be of immediate practical help to other researchers working on practical task arithmetic applications.\n 4. Related to the above, Ln 297 - can the degree of local linear independence of the NTK eigenfunctions be measured/computed with a simple metric to test this condition in other models / datasets? This would likewise be a useful contribution of the paper.""}, 'limitations': {'value': "" * It's not clear to me if there are situations where the linerarization technique won't be readily applicable. E.g. are some activation functions or more esoteric neural network architectures (e.g. recurrent NN's; long-term memory components) going to problematic to linearize? Some negative examples of where NTK linearization can't be used and/or approximations or work-arounds could be a useful addition in this regard.""}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents a comprehensive theoretical and empirical analysis of task arithmetic for model editing, where adding different task vectors (obtained by taking the difference between fine-tuned and pretrained model checkpoints) could improve the model’s performance on these tasks and vice versa. The authors propose weight disentanglement to investigate the underlying principles of task arithmetic, which involves decomposing the learned model function into a sum of localized components with disjoint supports. Specifically, the authors compare **regular** and **post-hoc linearized** fine-tuned models and find that weight disentanglement significantly contributes to the ability of task arithmetic. Based on these insights, the authors then propose to directly employ the linearized model for fine-tuning, obtain optimized task vectors, and lead to improved task arithmetic performance. Further analyses are conducted to reveal the connection between task arithmetic and weight disentanglement.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- The paper is clearly written and well organized.\n- This work presents a neat analysis of task arithmetic based on the use of linearization and neural tangent kernels, which is novel to my knowledge and interesting, offering a fresh perspective on understanding the geometry of pre-trained checkpoints’ weights.\n- The proposed method to further improve task arithmetic is simple yet effective, supported by extensive empirical findings.'}, 'weaknesses': {'value': 'As the authors already mentioned, one potential weakness is the introduced computational overhead during training. However, since the main focus of this work is a comprehensive analysis of task arithmetic, this is not a significant issue in the context of this work.'}, 'questions': {'value': '1. How does model scale impact weight disentanglement, and thus the benefits of linearized fine-tuning?\n2. (Minor) Can the findings about task arithmetic be generalized to natural language tasks as well? By intuition, it seems that the setting of natural language texts is more straightforward for weight disentanglement due to the inherent discreteness of text tokens.'}, 'limitations': {'value': 'The authors have adequately addressed the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper studies the ""task vectors"" framework where the weights of models can be perturbed in specified directions corresponding to tasks which result in improvements on those tasks. They attribute the success of this framework to ""weight disentanglement"" which means that adding a task vector for task i does not change how the network behaves when seeing input for task j != i. In addition, their investigation reveals that task vectors are not a consequence of fine-tuning occurring in the NTK regime (post-hoc linearization underperforms), but explicitly linearizing fine-tuning improves the task vectors framework as it ""amplifies"" ""weight disentanglement"".'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""Overall I thought this paper was very interesting, it's claims are mostly precise and thoroughly investigated, and it's results are impressive (+ 5.8 for task addition). I though Figure 5 was particularly nice evidence of the authors hypothesis.""}, 'weaknesses': {'value': '- Limited experiments for many tasks. I would be very curious to see what happens in e.g. table 1 if you scale up the number of tasks.\n- Limited attempt to falsify the hypothesis -- for instance can you consider two tasks which share the same input images? Would task vectors still work? (See question in questions section).\n- Throughout the paper the authors mention variations of ""Specifically, we probe the hypothesis presented in Wortsman et al. [80] that task arithmetic is possible thanks to the fact that models inherently operate in a linear regime"" but I cannot actually find anywhere in [80] where this hypothesis is stated? I thought that Wortsman et al. [79, 80] were observing that ensembles behaved roughly similar to averages in the fine-tuning regime, and simply used the NTK regime as an example of where this would occur, but noted that there was still differences between the two (which is not predicted by the NTK regime). How do the authors feel about the hypothesis that averaging models (~= task vectors) ~= output-ensembling + terms-which-may-be-small (e.g., Section 4 of [79]).'}, 'questions': {'value': '- Do the authors findings point to any ""better"" way of adding task vectors rather than just adding them for all weights in the network?\n- How does weight disentanglement change with scale?\n- Can the authors think of an experiment which might falsify their hypothesis? E.g., do they think that task vectors might still ""work"" if two tasks share the same input space. Here\'s a quick thought: get one task vector which corresponds to the problem ""first 5 classes in CIFAR10 or second 5 classes"" and another corresponding to the task ""traditional CIFAR10"". If you apply both these task vectors then look at CIFAR10 performance on just the first 5 classes I think performance would still be as good as just applying the CIFAR10 task vector?\n- Should the community switch to linearized fine-tuning?'}, 'limitations': {'value': 'Would have been nice to see a limitations section.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Task Arithmetic in the Tangent Space: Improved Editing of Pre-Trained Models'}, 'authors': {'value': ['Guillermo Ortiz-Jimenez', 'Alessandro Favero', 'Pascal Frossard']}, 'authorids': {'value': ['~Guillermo_Ortiz-Jimenez1', '~Alessandro_Favero1', '~Pascal_Frossard1']}, 'keywords': {'value': ['model editing', 'transfer learning', 'neural tangent kernel', 'vision-language pre-training', 'deep learning science']}, 'TLDR': {'value': 'We present a comprehensive study of task arithmetic and find that linearizing models before fine-tuning improves their performance after editing.'}, 'abstract': {'value': ""Task arithmetic has recently emerged as a cost-effective and scalable approach to edit pre-trained models directly in weight space: By adding the fine-tuned weights of different tasks, the model's performance can be improved on these tasks, while negating them leads to task forgetting. Yet, our understanding of the effectiveness of task arithmetic and its underlying principles remains limited. We present a comprehensive study of task arithmetic in vision-language models and show that weight disentanglement is the crucial factor that makes it effective. This property arises during pre-training and manifests when distinct directions in weight space govern separate, localized regions in function space associated with the tasks. Notably, we show that fine-tuning models in their tangent space by linearizing them amplifies weight disentanglement. This leads to substantial performance improvements across multiple task arithmetic benchmarks and diverse models. Building on these findings, we provide theoretical and empirical analyses of the neural tangent kernel (NTK) of these models and establish a compelling link between task arithmetic and the spatial localization of the NTK eigenfunctions. Overall, our work uncovers novel insights into the fundamental mechanisms of task arithmetic and offers a more reliable and effective approach to edit pre-trained models through the NTK linearization.""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/1e605936d9544b6e5e448363572bb06fcdf70f57.pdf'}, 'supplementary_material': {'value': '/attachment/ec080011525ad4f95e9330e9cb3f6a8247a1f132.pdf'}, '_bibtex': {'value': '@inproceedings{\nortiz-jimenez2023task,\ntitle={Task Arithmetic in the Tangent Space: Improved Editing of Pre-Trained Models},\nauthor={Guillermo Ortiz-Jimenez and Alessandro Favero and Pascal Frossard},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=0A9f2jZDGW}\n}'}, 'paperhash': {'value': 'ortizjimenez|task_arithmetic_in_the_tangent_space_improved_editing_of_pretrained_models'}}]"
"['Tushar Nagarajan', 'Santhosh Kumar Ramakrishnan', 'Ruta Desai', 'James Hillis', 'Kristen Grauman']",NeurIPS,EgoEnv_ Human-centric environment representations from egocentric video,https://neurips.cc/virtual/2023/oral/73820,2023," First-person video highlights a camera-wearer's activities in the context of their persistent environment. However, current video understanding approaches reason over visual features from short video clips that are detached from the underlying physical space and  capture only what is immediately visible. To facilitate human-centric environment understanding, we present an approach that links egocentric video and the environment by learning representations that are predictive of the camera-wearer's (potentially unseen) local surroundings. We train such models using videos from agents in simulated 3D environments where the environment is fully observable, and test them on human-captured real-world videos from unseen environments. On two human-centric video tasks, we show that models equipped with our environment-aware features consistently outperform their counterparts with traditional clip features. Moreover, despite being trained exclusively on simulated videos, our approach successfully handles real-world videos from HouseTours and Ego4D, and achieves state-of-the-art results on the Ego4D NLQ challenge.",Oral 5D Vision,https://openreview.net/pdf?id=rybsHQ4DXy,https://openreview.net/forum?id=rybsHQ4DXy,rybsHQ4DXy,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'Reviewers are unanimously enthusiastic about this work -- noting that the approach to environmental representation learning is well-motivated and trainable in simulation. Much of the discussion during the rebuttal phase clarified limitations of the proposed approach which should be integrated with the current text.'}}, {'comment': {'value': 'I have read the author’s rebuttal and my concerns have been fully addressed. This work is a good contribution towards egocentric research and thus, I will maintain my initial rating.'}}, {'comment': {'value': ""Thanks to the author's response. My concerns have been fully addressed. I believe the work is a solid contribution to the community and would like to maintain my initial rating.""}}, {'comment': {'value': 'After reading the rebuttal, I remain confident in my original assessment and will maintain my initial score. I believe this is a solid paper that deserves to be communicated.'}}, {'comment': {'value': 'I have read the rebuttal, and am satisfied with the answers to my concerns. Therefore, I am increasing my rating from Weak Accept to Accept. '}}, {'rebuttal': {'value': '> W1. This work does not consider the influence of motion blur if the person wearing the camera makes sudden movements, making it challenging to apply this work to real environments.\n> Q1. The authors should elaborate on how their models would deal with motion blur and sudden movements of the camera. Is there a motion model that is implicitly learned based on the camera movements or is it assumed that the camera moves at a fixed speed?\n\nAs mentioned in L151, the pose embedding model was intentionally designed to account for missing or unreliable pose estimates in real-world video due to rapid camera-motion and motion blur, however, there is no explicit mechanism in place to filter them out. In terms of inputs to the model, models are trained assuming a fixed speed (i.e., a fixed FPS for the simulated agent trajectories). One of our testbeds, Ego4D, exhibits frequent motion blur; please see the Supp video for examples.\n\n---\n> W2. This work also uses a semantic segmentation model to identify physical objects in the camera wearers’s environment. However, that could be limiting as their approach is restricted to objects that are classified by the segmentation model.\n\nYes, this is an important point. As mentioned in L231, we are limited to the 23 categories present in HM3D, detected by semantic segmentation models; however, these categories capture a broad range of commonly available household objects (TV sets, couches, tools etc.) in our video datasets (Ego4D, HouseTours). Importantly, the object classes are *not* a required output of the model – they are used only as labels in the local state task to train the model to link views across a trajectory. Once trained, the prediction heads are discarded while the encoder is retained to generate the environment feature $h_q$ (L192). In short, a larger set of objects is desirable for training, but does not restrict our approach for generating downstream environment features.\n\n---\n> Q2. Since this method is intended for AR applications, were their any evaluations done to benchmark the real-time inference performance of this method?\n\nNo, real-time inference is an important feature but was not a research focus in this work. \n\n---\n> L1. The authors do not explicitly state the limitations of this work, and should refer to the Weaknesses section of the review and consider stating those limitations in the paper (if applicable).\n\nPlease see the discussion on limitations in the common response.\n\n'}}, {'rebuttal': {'value': '> W1/Q1. In my opinion, the core of this method is a pertaining process that refines a feature into a better one by implicitly seeing its surroundings. In this sense, in all the experiments, EgoEnv features have knowledge about the surroundings however other features do not. Thus, one important experiment needed to be done is allowing other models to access the same amount of information but in a more straightforward manner.\n\nPlease note that we do provide such baselines.  As mentioned in L294, all models have access to the full video, while inference is performed at a particular time-step. Several baselines do already use the entire video context. TRF (scratch) and EPC both use the same inputs as our model (uniformly sampled across the video) and Ego-Topo (which builds a graph over the entire video’s frames). TRF (scratch) is in fact a combination of FrameFeat + the transformer to allow longer temporal range. \n\n---\n> Q2. Per the NeurIPS requirement, I hope the authors can discuss the limitations of the paper.\n> The authors did not state the limitations of this work in the paper.\n\nPlease see the discussion on limitations in the common response.\n'}}, {'rebuttal': {'value': '> W1 The method hugely relies on the surrounding background objects in the 3D scene. When a person navigates in a scene with clean backgrounds, it might be challenging for the method to encode expressive environment features. When dealing with easy real-world instances in the RoomPred task, the method performance is slightly worse than the baselines.\n\nYes, as mentioned in L187 our method builds on learned priors of objects and their layouts and will be equivalent to standard video models in, for example, an empty room. However, empty scenes may not be aligned with the practical relevance of our models (i.e., assistive robots / AR mentioned in L58-62) where objects and cluttered scenes are key.\n\n---\n> W2 The performance gain from the proposed method seems marginal on Ego4D.\n\nWe present a detailed analysis of our approach’s performance on Ego4D in Supp. B. To summarize, Ego4D videos are in-the-wild videos of natural human activity in diverse scenes. This is in contrast to the simulated walkthroughs used for pretraining. We show that our approach performs well on samples that are aligned with the pretraining data – i.e., indoor home scenarios and navigation heavy scenarios, with lower improvements on out-of-distribution scenes like outdoor activities (e.g., golfing, outdoor cooking). Importantly, while the performance improvement is indeed lower than improvements on HouseTours, our method was the top-ranked approach on Ego4D for NLQ at the time of submission, and remains third ranked on the NLQ leaderboard, demonstrating its impact.\n\n---\n> Q1 When incorporating the ground-truth camera poses into the method, I am curious about how to input the pose to EgoEnv+pose since I do not find a network parameter that transfers camera poses to pose embeddings.\n\nThe input poses are directly transformed to the dimension of the pose embeddings ($p_t$ in Fig 3) using a linear layer. \n\n---\n> L1. One potential limitation is that the method has not been tested on dynamic scenes with dynamic background objects or humans such as multi-person interaction scenarios.\n\nFor testing, Ego4D contains videos with dynamic objects, object interactions, and social interactions. For training, yes, these are interesting future directions that will be driven by advances in simulator capabilities. \n'}}, {'rebuttal': {'value': ""> W1. Although the paper is well-written and structured, many important experiments and discussions were excluded and can only be found in the 18-page supplemental material. One example is the full ablation procedure which is solely available in the supplemental material.\n\nWe tried to prioritize the most important information in the main paper, but of course, some experiments had to be moved to Supp. If our paper is accepted, we will move relevant sections to the main paper. For example, the discussion on the limitations of our approach and the ablation experiments mentioned. In the main paper, we point to specific experiments in the supplementary so that a reader knows what is available. \n\n---\n> W2. I couldn't find any information on the limitations of the agent, which is crucial in this work. \n\nPlease see the common response for a discussion on the limitations. Below are responses to specific questions.\n\n> “how well the agent performs in outdoor environments?” \n\nAs mentioned in L220-3 and Supp. B, our approach is best suited to indoor environments that are aligned with training scenes. Supp. Table 1 quantifies this for the NLQ task on Ego4D, where we see the largest improvements in indoor home scenarios (e.g., listening to music, household management) and navigation heavy scenarios (walking indoors and outdoors) and lower improvements in outdoor scenes (e.g., golfing, outdoor cooking). Note that our approach is compatible with outdoor video; however, it is limited by the availability of simulated data for activities in outdoor scenes.\n\n> Additionally, it would be helpful to know how effective the vector embedding is in dynamic scenes where the environment is constantly changing during video acquisition.\n\nInteresting point. Our walkthroughs are generated in static scenes where objects are not moved, while the real world is dynamic. We argue in Supp. C1 that a large part of real-world environments are static (e.g., counter tops, staircases; beds, couches, TV sets) which is valuable to encode even when some objects may have moved around. Our embeddings do perform better where there is primarily camera motion and low scene motion / object interaction – Supp. Table 1 shows increased performance in navigation-heavy videos (e.g., walking indoors and outdoors). Further, the larger improvements across both tasks in HouseTours, where the environment is also static, as compared to Ego4D, also hints at this effect.\n\n---\n> Q1-2. Moreover, it's important to know and if there are any differences in walking patterns between the virtual agent and real people that may affect the results. \n> How was the algorithm the generate the walking pattern of the virtual agent? Were used different speeds or motions (e.g., running, walking, etc.) during the training? Based on the images presented in the paper, it appears that the agent did not look up or down. I am curious if this lack of movement would impact its performance in videos focused on activities such as cooking, where the camera angle is often directed downwards. Has there been any analysis on this topic?\n\nDetails about the simulated agent walkthroughs are in Supp. C1. To summarize, agents follow the shortest-path between two points for a fixed number of steps. The action space is discrete (move forward by 0.25m, turn left/right). The frames were rendered into videos using a fixed FPS (i.e., equivalent to a single speed of walking). The episode length and FPS were selected to approximately match the characteristics of human walkthroughs in HouseTours (i.e., agents move between approximately 20 rooms on average in an episode). We did not experiment with agents looking up/down or in general more “human-like” head motion or navigation policies, though that is an interesting direction for future research.\n\n""}}, {'rebuttal': {'value': '> W1 It would be great to discuss about the accuracy of the pose embedding learning network on the simulated network since the overall model is dependent on it.\n\nThanks for the suggestion. As mentioned in L157, the pose embedding network is trained to predict relative pose discretized into 12 angles and 4 distance ranges. On the validation set, the model achieves accuracies of 48.4% on relative distance prediction and 34.4% on relative orientation prediction. Note that this task is challenging – models must predict relative pose for all possible pairs of observations in a trajectory using their visual features alone – however the goal is to generate pose encodings, not to output perfect pose. In Supp. E.2.1, we highlight the importance of these pose embeddings for local state prediction. In short, including pose embeddings leads to better object class and distance prediction, especially when objects are not immediately visible.\n\n---\n> W2 There can be more discussion as to how the sim-to-real gap gets reduced in the approach.\n\nWe make efforts to minimize the sim-to-real gap in our dataset and task design. First, we opt for photo-realistic environments from HM3D which contain high-fidelity reconstructions of diverse, real-world houses. Second, when creating the simulated trajectories in Sec. 4 (Simulator environments), we try to match the characteristics of simulated agent walkthroughs to camera-wearer movement in video datasets (L233). Specifically, we position cameras at head-level for the simulated agents, and we adjust the episode duration such that the number of rooms visited per episode by simulated agents roughly matches that in HouseTours (approximately 20 room transitions on average). Please see our Supp. video to compare the generated walkthroughs with HouseTours videos. Finally, we design our local state prediction task around capturing object and environment layout that reflects priors of real-world object distributions. We select this over other simpler alternatives like predicting image features directly, which are more susceptible to failures due to sim-to-real visual differences. We compare alternatives in Supp. E.4.\n\nWe discuss the effect of the sim-to-real gap in Supp B. To summarize, we find that our approach works best on scenes that are aligned with our simulated training data (i.e., indoor home scenarios; videos with lots of walking and less object interaction) and naturally performs worse on out-of-distribution activities (e.g., golfing, outdoor cooking).\n\n---\n> Q1. How much time does it take to train the pose embedding network and the rest of the model too in general?\n\nBoth the local state prediction and the pose embedding training is performed for 2.5k epochs (L262). Each training run takes ~24 hours when trained on two Quadro RTX 6000 GPUs. Note that this is a one time pre-training cost – once trained, the model is directly used as a feature extractor in downstream tasks and does not incur any extra training cost. \n'}}, {'rebuttal': {'value': 'Thanks to all the reviewers for their effort and constructive feedback. All five reviewers recommend accepting the paper, with two recommending strong accept (5, 6, 7, 8, 8). We address common concerns shared by reviewers below.\n\n**Limitations of the proposed approach**\n\nWe will emphasize the limitations more in the paper and summarize here.\n\nWe discuss the limitations of our approach in the context of the sim-to-real gap in L328 and Supp. B. Specifically, our model is affected by the type and diversity of pretraining data — videos of simulated agents walking around a house — limiting its generalization to unconstrained real-world video. Similarly, our approach is limited by simulator functionality – HM3D scenes support a small set of objects, which may not overlap with real-world environments, and Habitat does not support fine-grained object-interactions (e.g., chopping vegetables). As a result, we find that our approach works well on videos that are consistent with pretraining (i.e., indoor home scenarios; videos with lots of walking and less object interaction) but contributes less on out-of-distribution scenes and activities (e.g., golfing, outdoor cooking). We expect that future advancements in simulator capabilities (e.g., human motion models for agents, fine grained object interaction simulation) will help address this class of limitations.\n\nBeyond the sim-to-real gap, our approach has other limitations. First, our model does not have specialized modules to aggregate long-term temporal (or pose) information into its representation, compared to, for example, structure from motion methods that can aggregate and re-localize observations over a long video. As a result, our approach does not see benefits from increasing the temporal window from which the memory is constructed (Supp. F3). Next, our local state prediction task is learned in a coarse 2D space – the top-down map of the environment – which does not encode fine-grained geometric relations which may be important for certain tasks (e.g., is the object placed on top of, or inside another?). Finally, our approach is computationally intensive. While pre-training is a one-time cost, generating each augmented clip feature at inference requires the computation of several frame features in the vicinity of the clip, and then aggregating that information using the transformer module. This may be limiting for real-time inference applications in the assistance setting.\n\nDespite these limitations, our approach outperforms state-of-the-art representations for predicting visited rooms and retrieving important moments from natural language queries.\n'}}, {'summary': {'value': 'The work presents an approach to learn spatial environment representations for egocentric videos. Such representations encode the camera-wearer’s (seen and unseen) local surroundings/environment. Previous approaches mostly focus on learning representations over a longer temporal space, however, understanding of the physical spatial space seem to be missing which is addressed in the work via learning of environment-aware features.\n\nThe method define a local environment state having a set of object in a relative direction to the camera wearer. The local state has both geometric information (relative object location) and semantic information (object labels). The model learns this local state by learning two matrices - a direction matrix which represents which object is in front, back, left or right and another metric which represents the distance of the object from the camera wearer in a discretized space. To define the matrices, pose information is needed. Since ground truth pose information is missing from real-world egocentric videos, a model first learns the pose information from simulated environment by minimizing a cross entropy loss between the pose of camera wearer and pose of object. \n\nNext, an environment memory is encoded from a video walkthrough of T frames and a query frame. Pose embeddings are generated for all the T frames and query frame using the learned pose model, and each frame is encoded with this pose embedding. Then, K video frames are sampled to construct an environment memory using a transformer encoder. This representation consists of both temporal and spatial information of the environment. The transformer decoder then uses this environment memory and the query frame to generate a EgoEnv representation which is combined with the original video features (eg. Resnet). These representations are finally used for the video downstream tasks. \n\nThe method is evaluated on the room prediction and NLQ challenge on the datasets - Ego4D, HouseTours, and Matterport3D.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. The paper is well-written and has a detailed supplementary material covering the dataset statistics, model architecture details, and ablation experiments.\n2. The work shows a thorough evaluation with the method being evaluated on multiple datasets and compared with multiple baselines.'}, 'weaknesses': {'value': '1. It would be great to discuss about the accuracy of the pose embedding learning network on the simulated network since the overall model is dependent on it.\n2. There can be more discussion as to how the sim-to-real gap gets reduced in the approach.'}, 'questions': {'value': 'How much time does it take to train the pose embedding network and the rest of the model too in general?'}, 'limitations': {'value': 'No such limitations. The paper is well-written, covers all the implementation details, and discusses about all the aspects of the approach.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""In the paper, a model is introduced to extract vector embeddings of environments using images from a first-person perspective. The model is trained in a simulated environment where a virtual agent moves around and collects images to learn about its surroundings. The model's performance was tested in two different tasks - predicting the layout of a room and remembering sequences of events. The experimental results showed that the proposed model outperforms other baselines in both downstream tasks.""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- The paper is well-structured and easy to follow, with a clear motivation behind it. The tables and figures are helpful in explaining the concepts. Overall, I found the paper to be an enjoyable read.\n\n- The paper tackles the very interesting and relevant problem of scene understanding from first-person images.\n\n- The proposed model is very interesting and the experiments are enlightening and helpful in utilizing environment information of egocentric images to better understand the scene.\n\n- I believe this is a solid paper that deserves to be communicated.'}, 'weaknesses': {'value': ""Although the paper is well-written and structured, many important experiments and discussions were excluded and can only be found in the 18-page supplemental material. One example is the full ablation procedure which is solely available in the supplemental material.\n\nI couldn't find any information on the limitations of the agent, which is crucial in this work. For instance, how well the agent performs in outdoor environments? Moreover, it's important to know and if there are any differences in walking patterns between the virtual agent and real people that may affect the results. Additionally, it would be helpful to know how effective the vector embedding is in dynamic scenes where the environment is constantly changing during video acquisition.\n\nI believe that it would be beneficial to briefly discuss these questions that have been raised.\n""}, 'questions': {'value': '1) How was the algorithm the generate the walking pattern of the virtual agent? Were used different speeds or motions (e.g., running, walking, etc.) during the training?\n\n2) Based on the images presented in the paper, it appears that the agent did not look up or down. I am curious if this lack of movement would impact its performance in videos focused on activities such as cooking, where the camera angle is often directed downwards. Has there been any analysis on this topic?\n'}, 'limitations': {'value': 'I was unable to locate the discussion on limitations either in the paper or the lengthy supplemental material.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper proposes a novel framework to learn environment-aware video representations from egocentric videos. The framework can be trained on synthetic data and incorporated into various existing approaches for real-world downstream tasks including RoomPred and NLQ. Experiments demonstrate that models equipped with the framework achieve superior performances in the two downstream tasks on two real-world egocentric datasets, which demonstrates the value of synthetic data for real-world 3D understanding under egocentric videos.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '(1) The method in the paper releases the need for camera poses, making it more robust to the noise in structure-from-motion algorithms compared to existing pose-based methods.\n\n(2) Experiments fully demonstrate the effectiveness of the method.\n\n(3) Comprehensive ablation studies demonstrate the value of the core designs of the method.\n\n(4) The method is trained on only automatically-generated synthetic data yet performs better than baselines on real-world scenarios, indicating that simulated data could directly benefit real-world egocentric video understanding without techniques of sim-to-real transfer.\n\n(5) The writing is clear and well-organized.'}, 'weaknesses': {'value': '(1) The method hugely relies on the surrounding background objects in the 3D scene. When a person navigates in a scene with clean backgrounds, it might be challenging for the method to encode expressive environment features. When dealing with easy real-world instances in the RoomPred task, the method performance is slightly worse than the baselines.\n\n(2) The performance gain from the proposed method seems marginal on Ego4D.'}, 'questions': {'value': 'When incorporating the ground-truth camera poses into the method, I am curious about how to input the pose to EgoEnv+pose since I do not find a network parameter that transfers camera poses to pose embeddings.'}, 'limitations': {'value': 'One potential limitation is that the method has not been tested on dynamic scenes with dynamic background objects or humans such as multi-person interaction scenarios.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""In this paper, the authors address the limitation of current video understanding methods that only analyze short video clips in isolation, without considering the broader context of the camera-wearer's environment. They propose an approach that establishes a connection between egocentric videos and the surrounding environment by learning predictive representations. To accomplish this, the authors train their models using videos captured by agents in simulated 3D environments, where the environment is fully observable. An interesting finding is that despite being exclusively trained on simulated videos, the proposed approach effectively handles real-world videos from HouseTours and Ego4D datasets. It also achieves state-of-the-art results in the Ego4D NLQ challenge.\n\nI have increased the recommendation after the rebuttal. The rebuttal addressed my concerns.\n\n""}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""Overall, this paper introduces an innovative approach that bridges the gap between egocentric video and the camera-wearer's environment. By leveraging predictive representations, trained on simulated videos, the proposed method demonstrates improved performance over traditional clip-based approaches in various human-centric video tasks and real-world scenarios. The general idea of grounding egocentric video in its underlying world environment is very interesting. The proposed method to learn representations that are predictive of their surroundings and then enhance standard clip-based models is technically sound. \n\n""}, 'weaknesses': {'value': 'In my opinion, the core of this method is a pertaining process that refines a feature into a better one by implicitly seeing its surroundings.\nIn this sense, in all the experiments, EgoEnv features have knowledge about the surroundings however other features do not. Thus, one important experiment needed to be done is allowing other models to access the same amount of information but in a more straightforward manner. \n\nFor example, giving other models not only the current clip as input, but also frames that are uniformly sampled from the whole video.\n\nFrom the Tables, FrameFeat and ObjectFeat baselines are already very useful. I wonder whether a simple extension of these methods that, similarly, allows a longer temporal range as input at a time, would also perform reasonably well.'}, 'questions': {'value': '1. The experiments stated in the weakness section.\n2. Per the NeurIPS requirement, I hope the authors can discuss the limitations of the paper. '}, 'limitations': {'value': 'The authors did not state the limitations of this work in the paper.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work aims to learn human centric environment representations from first person camera views. Their novel approach utilizes a transformer-based approach that encodes the local environment state at each time-step in an egocentric video is defined as a set of objects, along with their approximate distances, located in front, left, right, and behind the camera-wearer. This work claims to outperform state-of-the-art representations in predicting visited rooms and retrieving significant moments when responding to natural language queries.\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '`Significance:` This work takes an important step towards proposing an approach that models the physical surroundings of a camera from a single egocentric perspective. This work could have multiple applications in AR, VR and robot navigation. \n\n`Originality:` Even though there has been a lot of work in the domain of video understanding in 3D environments, most approaches localize the camera-wearer but do not learn representations for the camera-wearer’s surroundings. Therefore, to the best of my knowledge, this work is novel. \n\n`Quality:` The authors provide a good theoretical background to their approach and back up their claims with rigorous experimentation on multiple datasets and tasks.\n \n`Clarity:` The paper and the supplementary materials are clearly written and easy to follow. '}, 'weaknesses': {'value': '- This work does not consider the influence of motion blur if the person wearing the camera makes sudden movements, making it challenging to apply this work to real environments. \n- This work also uses a semantic segmentation model to identify physical objects in the camera wearers’s environment. However, that could be limiting as their approach is restricted to objects that are classified by the segmentation model.\n'}, 'questions': {'value': '- The authors should elaborate on how their models would deal with motion blur and sudden movements of the camera. Is there a motion model that is implicitly learned based on the camera movements or is it assumed that the camera moves at a fixed speed? \n- Since this method is intended for AR applications, were their any evaluations done to benchmark the real-time inference performance of this method?\n'}, 'limitations': {'value': 'The authors do not explicitly state the limitations of this work, and should refer to the Weaknesses section of the review and consider stating those limitations in the paper (if applicable). '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'EgoEnv: Human-centric environment representations from egocentric video'}, 'authors': {'value': ['Tushar Nagarajan', 'Santhosh Kumar Ramakrishnan', 'Ruta Desai', 'James Hillis', 'Kristen Grauman']}, 'authorids': {'value': ['~Tushar_Nagarajan1', '~Santhosh_Kumar_Ramakrishnan1', '~Ruta_Desai1', '~James_Hillis1', '~Kristen_Grauman1']}, 'keywords': {'value': ['egocentric video', '3D environment', 'sim2real', 'sim-to-real', 'episodic memory']}, 'TLDR': {'value': 'We learn ""environment-aware"" ego-video representations that encode not just a short 1-2s clip, but also the local surroundings of the camera-wearer (e.g., what objects are nearby, how far are they).'}, 'abstract': {'value': ""First-person video highlights a camera-wearer's activities in the context of their persistent environment. However, current video understanding approaches reason over visual features from short video clips that are detached from the underlying physical space and  capture only what is immediately visible. To facilitate human-centric environment understanding, we present an approach that links egocentric video and the environment by learning representations that are predictive of the camera-wearer's (potentially unseen) local surroundings. We train such models using videos from agents in simulated 3D environments where the environment is fully observable, and test them on human-captured real-world videos from unseen environments. On two human-centric video tasks, we show that models equipped with our environment-aware features consistently outperform their counterparts with traditional clip features. Moreover, despite being trained exclusively on simulated videos, our approach successfully handles real-world videos from HouseTours and Ego4D, and achieves state-of-the-art results on the Ego4D NLQ challenge.""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/0d65bead5503521456342f7aa37f6075f4b5a8ad.pdf'}, 'supplementary_material': {'value': '/attachment/081de6e53ea6e63d27a71aecaba0a91a17270059.pdf'}, '_bibtex': {'value': '@inproceedings{\nnagarajan2023egoenv,\ntitle={EgoEnv: Human-centric environment representations from egocentric video},\nauthor={Tushar Nagarajan and Santhosh Kumar Ramakrishnan and Ruta Desai and James Hillis and Kristen Grauman},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=rybsHQ4DXy}\n}'}, 'paperhash': {'value': 'nagarajan|egoenv_humancentric_environment_representations_from_egocentric_video'}}]"
"['Michael Tschannen', 'Manoj Kumar', 'Andreas Steiner', 'Andreas Steiner', 'Xiaohua Zhai', 'Neil Houlsby', 'Lucas Beyer']",NeurIPS,Image Captioners Are Scalable Vision Learners Too,https://neurips.cc/virtual/2023/oral/73871,2023," Contrastive pretraining on image-text pairs from the web is one of the most popular large-scale pretraining strategies for vision backbones, especially in the context of large multimodal models. At the same time, image captioning on this type of data is commonly considered an inferior pretraining strategy. In this paper, we perform a fair comparison of these two pretraining strategies, carefully matching training data, compute, and model capacity. Using a standard encoder-decoder transformer, we find that captioning alone is surprisingly effective: on classification tasks, captioning produces vision encoders competitive with contrastively pretrained encoders, while surpassing them on vision & language tasks. We further analyze the effect of the model architecture and scale, as well as the pretraining data on the representation quality, and find that captioning exhibits the same or better scaling behavior along these axes. Overall our results show that plain image captioning is a more powerful pretraining strategy than was previously believed. Code is available at https://github.com/google-research/big_vision .",Oral 6C Vision,https://openreview.net/pdf?id=A7feCufBhL,https://openreview.net/forum?id=A7feCufBhL,A7feCufBhL,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The work received unanimous positive reviews. The work presented a comparison of contrastive and generative approaches in the context of visual representation learning from image-text pairs and demonstrate that when training data, compute, and model capacity are matched, generative approaches are competitive. Further, results on ARO benchmark provide evidence to suggest that generative approaches might have an advantage when representing relations, attributes, and order. \n\nAC agrees with the reviewers and finds the work relevant to the vision-language community. Given the enthusiasm from reviewers and high-quality experiments, the AC is pleased to recommend this work for a **Spotlight**! \n\nThe AC also encourages the authors to continue investigating the advantages of generative approaches over contrastive approaches beyond the single ARO benchmark used in this work.'}}, {'title': {'value': 'Thank you for a thoughtful rebuttal'}, 'comment': {'value': ""I thank the authors for accepting my suggestions and spending effort in running additional experiments! The results in the rebuttal overall look promising, and I encourage the authors to report them in the supplementary material. Please find specific responses below:\n\n**Performance of the exact autoregressive language model used in CLIP paper**\n\nThe authors found this model to perform worse than their `Cap` model. I view this as a positive result — authors state that the observation of Radford et al., 2021 (the captioning models converge slower) mostly holds for a specific configuration they experimented with (ResNet-50 + 12-layer transformer) but disappears when scaling to ViTs and such. The exact autoregressive architecture used by CLIP is one more factor that contributed to their observation which the authors claim to (somewhat) refute in this paper.\n\n**Cap/CapPa with backward captioning or masked language modeling**\n\nI believe this experiment could be better designed — the authors use one set of transformer weights to process forward and reversed captions. Reversed (English) captions are like a different language that is composed of English words, but follow completely opposite sentence structure and grammar rules (e.g. `subject-verb-object` becomes `object-verb-subject`). The model is modeling two essentially different languages that use the same words, which intuitively sounds like a very difficult problem — one may argue it's more difficult than learning a multilingual language model with English and other known languages (with sensible grammar).\n\n> > While VirTex ablates backwards captioning and shows improvements, they use a separate decoder, so the ablated model has fewer parameters and FLOPs (here we control for both factors).\n\nI appreciate the authors' thoughtfulness in controlling for params/FLOPs. Indeed (Desai & Johnson) should have controlled for this by using two transformers intact but performing forward captioning with both. I think the updated experiment is not necessary — the central message of the paper still holds without it. I thank the authors for running this experiment!\n\n**Using multiple parallel decoders:** Thank you for running this experiment, it shows that downstream performance mostly depends on the params/FLOPs of the decoders. Performance is less sensitive to how these parameters are divided across multiple decoders for auxiliary language modeling tasks... perhaps to some extent, I bet having CapPa models with six decoders of one layer each may get weak (??)\n\n**Evaluation on dense prediction tasks:** The authors' argument is persuasive — while I believe that this paper could be enriched by these evaluations, I note that they are not crucial to back the main claims presented in the paper. I would discount this concern in my final assessment.\n\n---------\n\n**Summary:** I recommended acceptance before the rebuttal. I continue to recommend acceptance after the authors' rebuttal. The paper presents a topic that would be of broad interest to the NeurIPS audience and presents it with sound experiments and high-quality presentation. While all reviewers unanimously agree to accept, I am happy to defend this paper for acceptance if needed. Congratulations to the authors!""}}, {'comment': {'value': ""Thanks. I don't have further comments. I will keep my rating.""}}, {'comment': {'value': ""I appreciate the authors' response and the additional experiments. I confirm my original score of strong accept. This paper provides interesting and refreshing observations with strong experimental support.""}}, {'comment': {'value': 'I thank the authors for providing a rebuttal, have read other reviews, and confirm that I am inclined to accept this paper. In particular, it is valuable to see that CapPa has similar memory requirements with CLIP* (8k). I encourage the authors to improve the layout of tables and figures and include this discussion of potential negative societal impact in the paper, and to release the code to improve reproducibility, '}}, {'rebuttal': {'value': '**Minor limitation: Frozen adaption may not justify the advantage of Cap-ViT**\n\nWe actually tried fine-tuning the image encoder along with the decoder for both CLIP* and Cap/CapPa models and did not obtain an improvement for any of the models. This is consistent with prior work which did not observe an improvement either for CLIP-style models when fine-tuning with the same decoder-based setup, see [2, Sec.5.7]. Frozen adaptation is also favorable from a computational perspective as no gradients have to be propagated through the encoder.\n\n\\\n**How does the size of the text decoder affect the representation learning performance?**\n\nAn ablation of the decoder depth for Cap can be found in Table 7 (right). 3 and 12 layer decoders obtain a 1-3 points lower 10-shot classification accuracy across the majority of the eval sets compared with the (default) 6 layer decoder.\n\n\\\n**What if the pre-training is performed using a pre-trained text decoder such as T5, does it improve representation learning?**\n\nThis is an interesting question. We investigated this setup with a pretrained T5-Base decoder (which has 12 instead of 6 decoder layers as Cap/CapPa). First, to enable stable training we needed to reduce the learning rate from 1e-3 to 5e-4 and set the optimizer beta2 parameter to 0.95. Furthermore, training was only stable when unfreezing the cross-attention parameters. We also explored variants where we re-initialized the cross-attention parameters, and another variant where additionally all decoder parameters were trained. For all other design choices we follow the Cap-ViT B/16 setup with the 900M example schedule. None of these variants performs better than Cap overall, and the more we allow the decoder to deviate from its language-pretrained weights the better the vision performance gets.\n\nUsing a pretrained T5 decoder (10-shot linear eval.)\n| model                          |   ImageNet |   CIFAR100 |   Pets |   Cars |\n|:-------------------------------|-----------:|-----------:|-------:|-------:|\n| Cap                            |       49.7 |       56.0 |   72.6 |   74.7 |\n| Cap (12 dec. layers)           |       48.7 |       54.8 |   74.4 |   73.8 |\n| Cap T5                         |       42.8 |       44.9 |   69.3 |   62.3 |\n| Cap T5 (rein. xatt.)           |       43.7 |       45.7 |   68.3 |   66.9 |\n| Cap T5 (rein. xatt., unfreeze) |       48.6 |       55.2 |   72.0 |   75.6 |\n\n\\\n**Would Cap and CLIP have a complementary effect if they are combined as a multi-task pre-training objective such as in BLIP?**\n\nWhile there is anecdotal evidence in the literature that these losses can have complementary effects (see e.g. [32, 33, 52]) these experiments do not take pretraining compute into account and/or do not remove unnecessary network components when ablating losses. By contrast, our experiments control for these factors and show that both Cap/CapPa and CLIP lead to competitive vision encoders. It is therefore unclear how much complementary signal they provide when controlling for model capacity and pretraining compute. We leave analysis of this aspect at scale for future work.\n'}}, {'rebuttal': {'value': '**The layout of the tables and figures is hard to follow**\n\nThank you for bringing this to our attention. We will improve the alignment of tables and figures with the text flow in the next revision.\n\n\\\n**How do the compute requirements (e.g. gpu memory) of the CLIP\\* with 8k/16k batch size compare with CapPa?**\n\nThe default Cap/CapPa model and training setup is chosen such that it closely matches the corresponding CLIP* setup in terms of actual accelerator hours (and examples seen). Table 1 in the paper reports TPUv4 hours per billion examples seen along with parameter count (which is also matched for the two model families). Below are the memory requirements per chip when training the models on 64 TPUv4 chips (the same setup as used to determine TPU hours in Table 1). The memory requirements of CapPa and CLIP* are comparable for the same batch size as well.\n\n| model\t\t\t| TPUv4 mem |\n|:------------------|-----------:|\n| Cap/CapPa B/16\t| 19.62 GiB |\t\t\n| CLIP* (8k) B/16\t| 20.05 GiB |\n| CLIP* (16k) B/16\t| 31.46 GiB |\n\n\\\n**Most experiments use a proprietary dataset (WebLi) for pretraining and the code is not provided, which harms reproducibility.**\n\nThe experiments on the publicly available LAION-400M data set (Sec. 4.4, Fig. 6) show that our most important results transfer to publicly available data. Furthermore, we only perform very simple text-based filtering of the WebLI data (which is from the public web) as done by prior work [4, 25], and we do not use any image-text similarity based filtering or other sophisticated filtering procedures. We are working on a code release and are hopeful to publish code before the conference.\n\n\\\n**Potential negative societal impact is not discussed.**\n\nWe plan to include the following discussion in the paper:\n\nOur models fit in the broader context of large scale vision-language pretraining and as such share many of the benefits and issues of related models such as [40, 21, 52, 33, 50]: They produce versatile vision models which obtain strong performance on natural images, on OCR-related tasks, and also when combined with a generative language decoder. These capabilities enable many useful applications (e.g. assistive technologies, medical imaging), but also potentially harmful ones (e.g. surveillance).\nWe generally recommend either employing the CapPa vision encoder with a new, task-specific prediction head, or using the pretrained decoder for scoring only. We do not recommend the pretrained decoder for downstream image captioning applications without further refinement, as it is trained on a large number of alt-texts from the web. Harmful biases should be carefully assessed in the context of the concrete downstream application and prediction head used. For example, when combining the encoder with a (potentially pretrained) decoder for captioning or VQA, an assessment of hallucinations, attribute binding issues and stereotypical attribution should be done.\n'}}, {'rebuttal': {'value': '**CLIP-style models are convenient for image-text retrieval/computing image-text similarities and offer a more efficient computation.**\n\nThis is indeed a downside of captioning-based approaches. On the upside, Cap and CapPa are much better than CLIP-style models in zero-shot classification tasks where word order, attribution, and relation are important (see Table 6). Furthermore, we show that LiT-tuning [56], where a text encoder is trained to match a frozen image embedding, represents an efficient way to equip Cap/CapPa with these capabilities (Table 4).\n'}}, {'rebuttal': {'value': 'Thank you for suggesting additional experiments, many of which we were able to address.\n\\\n\\\n**Performance of the exact autoregressive language model used in CLIP paper**\n\nWe trained this exact model (with a ResNet-50 encoder as in the CLIP paper) for 900M examples seen and found that it performs somewhat worse than the same encoder model together with the transformer decoder architecture. However, we believe that exploring alternative, potentially simpler decoder architectures at scale is an interesting direction for future work.\n\nComparing prefix decoder with baselines (10-shot linear eval. and scoring)\n| model                         |   ImageNet |   CIFAR100 |   Pets |   Cars |   INet zs. |\n|:------------------------------|-----------:|-----------:|-------:|-------:|-----------:|\n| CLIP* (8k) R50                |       39.8 |       33.5 |   49.2 |   60.9 |       43.6 |\n| Cap R50 (transformer decoder) |       37.8 |       33.3 |   48.6 |   52.4 |       28.5 |\n| Cap R50 (prefix decoder)      |       36.8 |       30.4 |   41.5 |   45.4 |       27.6 |\n\n\\\n**Cap/CapPa with backward captioning or masked language modeling**\n\nWe explored masked language modeling in the context of parallel prediction by masking only a fraction of the tokens, but only observed improvements over pure autoregressive modeling when masking all tokens (see Sec. 4.4, Parallel prediction).\nAs for backward captioning, we trained Cap while randomly reversing the caption with probability 0.5 (with the 900M examples schedule). This ensures that model capacity and pretraining compute remain unchanged. We do not observe improved performance (see below). While VirTex ablates backwards captioning and shows improvements, they use a separate decoder, so the ablated model has fewer parameters and FLOPs (here we control for both factors).\n\nForward vs forward + backward captioning (ViT-B/16 encoder; 10-shot linear eval.)\n| model           |   ImageNet |   CIFAR100 |   Pets |   Cars |\n|:----------------|-----------:|-----------:|-------:|-------:|\n| Cap             |       49.7 |       56.0 |   72.6 |   74.7 |\n| Cap (fwd + bwd) |       49.2 |       56.1 |   71.7 |   73.0 |\n\n\\\n**Using multiple parallel decoders**\n\nTo address this point, we trained a CapPa variant with two parallel decoders, one for autoregressive prediction and another one for parallel prediction, each with 3 layers instead of 6. This model matches the pretraining compute of the default Cap/CapPa models with 6 decoder layers. While this model performs better than Cap with 3 decoder layers in linear 10-shot eval, it does not clearly outperform Cap with 6 decoder layers and performs worse than CapPa on 3 out of 4 eval sets.\n\nComparing separate decoders with baselines (for ViT-B/16 encoder; 10-shot linear eval.)\n| model                  |   ImageNet |   CIFAR100 |   Pets |   Cars |\n|:-----------------------|-----------:|-----------:|-------:|-------:|\n| Cap (3 dec. layers)    |       48.7 |       53.7 |   73.5 |   73.7 |\n| Cap                    |       49.7 |       56.0 |   72.6 |   74.7 |\n| CapPa w/ sep. decoders |       49.5 |       54.9 |   75.8 |   79.0 |\n| CapPa                  |       50.4 |       57.4 |   76.2 |   78.5 |\n\n\\\n**Evaluation on dense prediction tasks**\n\nCLIP and image/text pretrained models more generally seem less popular than supervised/self-supervised vision encoders for such supervised dense prediction tasks. However, vision-language models have become popular recently for open vocabulary semantic segmentation (see e.g. [a, b, c, d]) and the field is evolving rapidly. We believe it might be interesting to explore this direction with captioning models, but we leave this for future work as it would require a substantial extension of the scope.\n\n- [a] Ding et al., Decoupling zero-shot semantic segmentation. CVPR 2022\n- [b] Ma et al., Open-vocabulary Semantic Segmentation with Frozen Vision-Language Models. BMVC 2022\n- [c] Liang et al., Open-vocabulary semantic segmentation with mask-adapted CLIP. CVPR 2023.\n- [d] Mukhoti et al., Open Vocabulary Semantic Segmentation with Patch Aligned Contrastive Learning. CVPR 2023\n\n\n\\\n**Minor issues**\n\nThank you for raising these, we will address them in the next revision of the paper.\n'}}, {'rebuttal': {'value': 'We thank all the reviewers for carefully reading our paper. We appreciate their thoughtful comments and the overall very favorable assessment. In particular, we liked the many suggestions for additional experiments, some of which we were able to run. We believe these experiments will make the paper stronger.\n\nPlease find the detailed responses to each review below.'}}, {'summary': {'value': 'In this paper, the authors more a controlled comparison between two pretraining approaches to learning visual representations from language supervision:\ncontrastive (CLIP-style) and generative (= image captioning, e.g. VirTex, SimVLM, BLIP, CoCa), etc.\nThe goal of this paper is not to advance the state-of-the-art, but rather to observe the model/data scaling behavior of these pretraining tasks.\nExperiments show that captioning-pretrained models can match or outperform CLIP-style contrastive models on several multi-modal tasks.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '**I think this paper, in its current form, already matches the quality of a typical publication at the NeurIPS conference.**\nI strongly recommend acceptance; it is relevant to the conference audience and will spur interesting discussion in the community.\nBelow I highlight the main strengths of the paper to substantially support my assessment:\n\n1. **Paper presents contrary evidence to existing results:**\nThe vision community is making rapid progress with vision-language models as they enable new transfer applications that can be specified using natural language.\nMuch of this progress in the last 2-3 years was catalyzed by the development of CLIP (and concurrent works like ALIGN).\nEver since, the vision community has largely gravitated towards pushing progress on multi-modal contrastive models,\nfollowing the ""image captioning models converge slower on web data"" result from the CLIP paper.\nThis paper presents a piece of contrary evidence that simple captioning-only models can match or outperform their contrastive counterparts.\n\n2. **Promising alternative to poor language understanding of contrastive models:**\nImage captioning as a pretraining task has been studied in previous models (e.g. VirTex, SimVLM, BLIP, CoCa, etc.).\nThe main novelty of this work is a direct comparison of captioning with the contrastive objective at scale,\nwith controlled model capacity and training dataset size.\nHence, I think this is a timely contribution that will force practitioners and researchers to rethink the relevance of text-generative models\nand side-step the embarrassing failures of contrastive models, e.g. their inability to distinguish ""man eating a sandwich"" from ""sandwich eating a man"".\n\n3. **New evaluations with captioning models show practical runtime solutions for classification/retrieval:**\nCaptioning models are known for their slow image/text retrieval runtime since they cannot ""cache"" the text classifier weights once like contrastive models.\nHowever, they are better at language understanding than contrastive models which are known to behave as bag-of-words models.\nAuthors show evaluations related to ""LiT tuning"" to convert a captioning-pretrained image encoder to a contrastive model --\nthis helps overcome the runtime overhead of image captioning-only models.\n\n4. **Experiments are thorough and well presented:**\nThe paper studies a targeted comparison between captioning and contrastive pretraining approaches.\nThe authors present a series of experiments and evaluations to support this study.\nAll comparisons seem fair and controlled to the best of my knowledge, with differences specified wherever relevant.\nModeling ablations and experiments with a different dataset (LAION-400M) make the study more self-contained.\nMany evaluations report error bars wherever appropriate.\n\n5. **Excellent clarity in writing and presentation:**\nThe motivation for this study is precisely stated I the abstract and introduction.\nThe coverage of related work is broad and comprehensive.\nAll technical details for empirical analysis are well-stated and easy to follow.\nThe main paper and supplementary material have adequate implementation details to aid reproducibility.\n'}, 'weaknesses': {'value': ""I have some questions and suggestions that could make the study more comprehensive.\nHave the authors considered the following experiments in their study?\n\n1. **The exact autoregressive language model used in CLIP paper:**\nCLIP paper uses a different autoregressive model, and this particular model is shown to converge slowly.\nHave the authors tried this exact architecture?\nInstead of a transformer decoder with cross-attention to image features (e.g. like VirTex),\nCLIP's autoregressive baseline has a SimVLM-style design wherein image features are pooled into 2x2 grid and passed to the text model as the first four tokens.\nThe model follows the transformer encoder design and predicts caption tokens autoregressively.\n\n2. **Backward captioning or masked language modeling?**\nHave the authors considered auxiliary objectives used by prior works, such as backward captioning (VirTex) or masked language modeling (ICMLM)?\nThese objectives can amortize the cost of forward pass through the image encoder and provide denser gradients to the image encoder.\n\n3. **[Related to above] multiple parallel decoders:**\nThe above suggestion can be extended to enable the use of multiple lightweight text decoders with multiple auxiliary objectives.\nOne can design each decoder head with reduced capacity to make all models have comparable sizes.\nTraining with such multiple objectives should speed up convergence.\n\n4. **Evaluation on dense prediction tasks?**\nIf the goal of this study is to learn high-quality image encoders, then I suggest the authors may include additional evaluations\nwith dense prediction tasks like object detection and segmentation. These tasks are ubiquitous in vision and quite challenging.\nI suggest that authors could train a ViTDet-style model with a frozen/fine-tunable image encoder from Cap/CapPa training.\n""}, 'questions': {'value': 'Minor suggestion:\n\n- This paper references CLIP in many places in the text. However, it is sometimes awkward to read as ""[40] showed..."" or ""released by [40] ..."".\n  Ultimately, it is personal preference, but I may recommend the authors use `citet` format like ""Radford et al. [40] showed that ...""\n  for a better reading experience if they do not have a preference.\n- `Line 84`: GeLU -> GELU. ReLU (""Re"" = ""Rectified"") and GELU (""GE"" -> ""Gaussian Error"") :-)\n- What is the ""(ok:as)"" in section 4.2 title? Seems like a latex macro :-)'}, 'limitations': {'value': 'The authors have included a reasonable discussion about the limitations of this study (and their trained captioning models)\nin the final section of the paper.\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper revisits image captioning as a pretraining task for learning general vision encoders from web image-text pairs. Surprisingly, the empirical study shows that captioning pre-trained vision encoders is competitive or better than contrastively pre-trained ones on image recognition and vision-language tasks.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- The paper presents a novel and interesting finding: using captioning as a pre-training scheme can also achieve strong results compared with contrastive ones. The empirical study is valuable to the community.\n- The paper presents an in-depth analysis of different design factors, such as the use of decoders, encoders, and pre-training data. One can find many insightful discussions in the experiment section.\n'}, 'weaknesses': {'value': '- Although captioning can be a promising scheme for pre-training, it may not be able to replace the existing contrastive pre-trained objective. For many established tasks, such as image-text retrieval or estimating the similarity between a given image-text pair, CLIP-style models are convenient and offer a more efficient computation. '}, 'questions': {'value': ""The paper is well-written and technically flawless. I don't have significant concerns about this paper.""}, 'limitations': {'value': 'No potential negative societal impact.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper shows that the captioning loss is a competitive alternative to pretrain image backbones compared with contrastive loss (CLIP) when using the same training budget and training data. The standard next token prediction objective on the full caption sequence (Cap) is complemented with a parallel prediction loss (CapPa) which is used on a quarter of the training batches. Experiments notably show:\n- the benefit of CapPa over Cap in a variety of settings\n- for classification, CLIP models are better than CapPa models at linear probing but the gap is bridged when using MAP probing. \n- with LiT transfer, CapPa models perform competitively in classification and are better at vision and language tasks like VQA or image captioning.\n- CapPa models scale well with model size and training budget.\n- CapPa models are better at attribute / relation / order prediction.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- Alternating parallel prediction with autoregressive prediction improves downstream transfer.\n- The experimental setup is well described.\n- Extensive experiments with interesting insights, e.g., the CapPa backbones are most competitive when exploiting all the token embeddings (and not merely average pooling them) which makes sense as they are all used for cross-attention.\n'}, 'weaknesses': {'value': '- The layout of the tables and figures is hard to follow: Table 2 appears before Table 1, Table 5 is not discussed anywhere, Figure 3 is placed long after it is discussed, and Table 10 (L238) does not exist. Explaining the CLIP* and 8k/16k meaning in the caption of Table 2 would also help.\n- How do the compute requirements (e.g. gpu memory) of the CLIP* with 8k/16k batch size compare with CapPa?\n- Most experiments use a proprietary dataset (WebLi) for pretraining and the code is not provided, which harms reproducibility.\n'}, 'questions': {'value': 'See weaknesses.'}, 'limitations': {'value': 'Limitations are discussed in Section 5. Potential negative societal impact is not discussed.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper shows that training a ViT with the image-to-text generation (i.e., image captioning) objective is an effective way to learn good visual representations for downstream tasks. The paper systematically compares between the image captioning and the image-text contrastive learning (CLIP) objectives, where image captioning leads to ViTs that are comparable to the CLIP-ViT. Furthermore, the paper proposes parallel decoding as an additional pre-training objective to complement the conventional autoregressive decoding.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The paper systematically demonstrates a refreshing observation: image-to-text generative learning leads to vision encoders as good as contrastive-learned ones. This opens up more research opportunities for visual representation learning using language supervision.\n\n- The pre-training details are well-controlled to ensure a fair comparison between Cap and CLIP.\n\n- The paper performs a comprehensive evaluation on the pre-trained ViT, including both image classification tasks and vision-language tasks. Table 8 is very nice in particular to compare the frozen ViTs.\n\n- It is interesting to see that Cap/CapPa outperforms CLIP on tasks that require fine-grained language understanding.\n\n- The proposed parallel prediction makes sense intuitively as a way to enforce stronger supervision on the ViT.\n'}, 'weaknesses': {'value': 'I do not find major weakness from this paper. There is a minor limitation as detailed below. More questions about the paper are listed in the next section.\n\nMinor limitation: Since Cap-ViT is pre-trained using an encoder-decoder paradigm, its representations would be more suited for similar encoder-decoder tasks (image caption, VQA) compared to CLIP-ViT. Therefore, frozen adaption may not justify the advantage of Cap-ViT on such tasks. It would be good to also report fine-tuning performance.\n'}, 'questions': {'value': '- How does the size of the text decoder affect the representation learning performance?\n\n- What if the pre-training is performed using a pre-trained text decoder such as T5, does it improve representation learning?\n\n- Would Cap and CLIP have a complementary effect if they are combined as a multi-task pre-training objective such as in BLIP? '}, 'limitations': {'value': 'Yes the authors have addressed the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Image Captioners Are Scalable Vision Learners Too'}, 'authors': {'value': ['Michael Tschannen', 'Manoj Kumar', 'Andreas Peter Steiner', 'Xiaohua Zhai', 'Neil Houlsby', 'Lucas Beyer']}, 'authorids': {'value': ['~Michael_Tschannen1', '~Manoj_Kumar1', '~Andreas_Peter_Steiner1', '~Xiaohua_Zhai2', '~Neil_Houlsby1', '~Lucas_Beyer1']}, 'keywords': {'value': ['contrastive learning', 'CLIP', 'CapPa', 'Cap', 'vision-language', 'image captioning', 'visual representation learning', 'weakly supervised learning', 'VLM', 'multimodal learning', 'VQA', 'image classification']}, 'abstract': {'value': 'Contrastive pretraining on image-text pairs from the web is one of the most popular large-scale pretraining strategies for vision backbones, especially in the context of large multimodal models. At the same time, image captioning on this type of data is commonly considered an inferior pretraining strategy. In this paper, we perform a fair comparison of these two pretraining strategies, carefully matching training data, compute, and model capacity. Using a standard encoder-decoder transformer, we find that captioning alone is surprisingly effective: on classification tasks, captioning produces vision encoders competitive with contrastively pretrained encoders, while surpassing them on vision & language tasks. We further analyze the effect of the model architecture and scale, as well as the pretraining data on the representation quality, and find that captioning exhibits the same or better scaling behavior along these axes. Overall our results show that plain image captioning is a more powerful pretraining strategy than was previously believed. Code is available at [https://github.com/google-research/big_vision](https://github.com/google-research/big_vision).'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'We present an extensive comparison of contrastive representation learning and representation learning via image captioning from large image-text data sets.'}, 'pdf': {'value': '/pdf/18336a8f230240542945d7caa9eb84b51a08a0e2.pdf'}, 'supplementary_material': {'value': '/attachment/da008bd7c6976bdc28ac59a1817733bf62cb3e84.pdf'}, '_bibtex': {'value': '@inproceedings{\ntschannen2023image,\ntitle={Image Captioners Are Scalable Vision Learners Too},\nauthor={Michael Tschannen and Manoj Kumar and Andreas Peter Steiner and Xiaohua Zhai and Neil Houlsby and Lucas Beyer},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=A7feCufBhL}\n}'}, 'paperhash': {'value': 'tschannen|image_captioners_are_scalable_vision_learners_too'}}]"
"['Cassidy Laidlaw', 'Stuart J Russell', 'Anca Dragan']",NeurIPS,Bridging RL Theory and Practice with the Effective Horizon,https://neurips.cc/virtual/2023/oral/73859,2023," Deep reinforcement learning (RL) works impressively in some environments and fails catastrophically in others. Ideally, RL theory should be able to provide an understanding of why this is, i.e. bounds predictive of practical performance. Unfortunately, current theory does not quite have this ability. We compare standard deep RL algorithms to prior sample complexity bounds by introducing a new dataset, BRIDGE. It consists of 155 MDPs from common deep RL benchmarks, along with their corresponding tabular representations, which enables us to exactly compute instance-dependent bounds. We find that prior bounds do not correlate well with when deep RL succeeds vs. fails, but discover a surprising property that does. When actions with the highest Q-values under the random policy also have the highest Q-values under the optimal policy—i.e., when it is optimal to act greedily with respect to the random's policy Q function—deep RL tends to succeed; when they don't, deep RL tends to fail. We generalize this property into a new complexity measure of an MDP that we call the effective horizon , which roughly corresponds to how many steps of lookahead search would be needed in that MDP in order to identify the next optimal action, when leaf nodes are evaluated with random rollouts. Using BRIDGE, we show that the effective horizon-based bounds are more closely reflective of the empirical performance of PPO and DQN than prior sample complexity bounds across four metrics. We also show that, unlike existing bounds, the effective horizon can predict the effects of using reward shaping or a pre-trained exploration policy. Our code and data are available at https://github.com/cassidylaidlaw/effective-horizon.",Oral 6B RL,https://openreview.net/pdf?id=Lr2swAfwff,https://openreview.net/forum?id=Lr2swAfwff,Lr2swAfwff,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The reviewers unanimously agree that this is a very interesting work that takes a refreshing perspective on how and why deep RL works, and combines strong empirical evidence with theoretical explanation.'}}, {'comment': {'value': 'Thank you for the comments! I stick to my score and recommend the paper for acceptance.'}}, {'title': {'value': 'Thanks'}, 'comment': {'value': 'Thanks for running these experiments. I have updated my ratings correspondingly. '}}, {'title': {'value': 'Results with SB3 implementations'}, 'comment': {'value': ""Thank you for your response to our rebuttal. We agree that deep RL is brittle and that it is important to make sure that our main results are robust to implementation details and hyperparameters.\n\nSince the rebuttal period, we have now been able to re-run our main experiments with the Stable Baselines 3 implementations of PPO and DQN. That is, we have trained PPO and DQN agents for 5 million steps across 5 random seeds on all the environments in BRIDGE using the Atari hyperparameters from the `rl-zoo` repository [here](https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams). We did tune the hyperparameters somewhat to each environment—we tuned $\\text{n\\\\_steps} \\in \\\\{128, 1280\\\\}$ for PPO and tuned $\\text{exploration\\\\_fraction} \\in \\\\{0.1, 1\\\\}$ for DQN.\n\nHere are our main results from Table 2 when using the results from the SB3 implementations instead of RLlib:\n\n| Bound                                  | PPO: Correl. | Median ratio         | AUROC    | Acc.     | DQN: Correl. | Median ratio         | AUROC    | Acc.     |\n|----------------------------------------|-------------|----------------------|----------|----------|-------------|----------------------|----------|----------|\n| Worst-case ($T \\lceil A^T / 2 \\rceil$) | 0.18        | $1.3 \\times 10^{10}$ | 0.62     | 0.61     | 0.18        | $5.5 \\times 10^{10}$ | 0.67     | 0.75     |\n| Covering length ($T L$)                | 0.29        | $4.5 \\times 10^{6}$  | 0.78     | 0.73     | 0.31        | $3.9 \\times 10^{6}$  | 0.81     | 0.83     |\n| EPW ($T^2 A^W$)                        | 0.67        | $4.7 \\times 10^{4}$  | 0.80     | 0.73     | 0.61        | $8.0 \\times 10^{4}$  | 0.87     | 0.84     |\n| UCB ($S A T$)                          | 0.22        | **20**               | 0.67     | 0.65     | 0.34        | **31**               | 0.64     | 0.76     |\n| Effective horizon ($T^2 A^H$)          | **0.80**    | **20**               | **0.91** | **0.85** | **0.75**    | 60                   | **0.90** | **0.85** |\n| *Other algorithm*                      | 0.75        | 2.0                  | 0.84     | 0.83     | 0.75        | 2.0                  | 0.74     | 0.98     |\n| *GORP*                                 | 0.77        | 5.7                  | 0.76     | 0.79     | 0.65        | 9.4                  | 0.81     | 0.93     |\n\nWe find that the main conclusions of the paper are unchanged when using the SB3 implementations. The effective horizon-based bounds still correlate the best out of any of the provable bounds with the empirical performance of deep RL algorithms (in fact, the correlation is slightly better with SB3 than RLlib). The UCB bounds are a bit closer in median ratio to the empirical performance of DQN, but the correlation is so poor that we believe the effective horizon remains the best explanation for deep RL's performance.\n\nComparing directly between the RLlib and SB3 implementations of PPO, we found that:\n * In 37% of environments, the SB3 implementation outperforms the RLlib one (i.e., either the final return is higher or it achieves the optimal return in fewer timesteps).\n * In 23% of environments, the SB3 implementation performs equally to the RLlib one (i.e., they both achieve the same final return, and if it is optimal, then they achieve it in the same number of timesteps).\n * In 40% of environments, the SB3 implementation performs worse than the RLlib one.\n\nWe also found a Spearman correlation of 0.94 between the empirical sample complexities of the two implementations. This suggests that the RLlib and SB3 implementations are relatively similar.\n\nWe have not yet had the chance to re-run the long-horizon Atari experiments using SB3 (Appendix H.1). However, the fact that we were able to closely replicate our original results using the SB3 implementations—showing that the effective horizon closely correlates with deep RL performance—strongly suggests that our results are robust to the exact implementations of the RL algorithms.""}}, {'title': {'value': 'We will update the paper'}, 'comment': {'value': 'Thanks for your response. We will definitely incorporate explanations of both points into the paper. We appreciate the feedback to make our exposition more clear.'}}, {'comment': {'value': 'Thank you for your response! I like the paper a lot and my score remains unchanged.'}}, {'title': {'value': 'Reply to authors'}, 'comment': {'value': ""I thanks the author for the detailed reply.\n\n> We also plan to rerun our experiments with the SB3 implementations of PPO and DQN to make sure that they are robust to the exact implementations of the RL algorithms. We will include these results in the final paper if accepted.\n\nThat sounds like a good plan, and thanks for entertaining this thought. I really like the writing and ideas of the paper and think having the SB3 experiments can make the paper more solid.\n\n> We believe that the difference in returns is because we limit agents to a single life in the Atari games, as described in Appendix F.1.\n\nThis is a perfectly reasonable explanation. My reservation is that DRL is brittle, and there is a non-zero chance that \n1. you experiment with SB3's PPO and DQN and find the claims are no longer supported by the experiments, or\n2. you align the Atari and hyperparameter setting with the RLlib's codebase and find RLlib's PPO still underperforms, which causes a reproducibility issue, making it difficult to attribute and interpret the paper's claims.\n\n\nTo give an example of the second issue, [Luo et al., 2020](https://arxiv.org/pdf/1912.00167.pdf) claim their proposed approach IMPACT outperforms IMPALA because their IMPACT gets ~550 score in Breakout whereas their IMPALA baseline gets ~500 score. However, the [original IMPALA](https://arxiv.org/pdf/1802.01561.pdf) reported 640.43 for IMPALA (shallow) and 787.34 for IMPALA (deep). This is clearly a reproducibility issue on their IMPALA, and it's unclear whether IMPACT can still outperform a more aligned IMPALA baseline.\n\n\n> RLlib’s PPO implementation has been benchmarked here (https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#ppo) in several Atari environments and performs quite similarly to SB3, so we do not think that the RLlib implementation is the reason for the difference in results.\n\nThanks for sharing the RLlib's benchmark results. However, the benchmark results are concerning for several reasons.\n\n1. The benchmark results are almost 5 years old (benchmarked on 2018-09 (https://github.com/ray-project/rl-experiments#2018-09)). I could not find a benchmark on their more recent codebase.\n2. The benchmark results are not sufficient (only tested on 4 envs); also, it appeared only to use 1 random seed.\n3. The benchmark showed RLlib's PPO underperforms `openai/baselines`' PPO, SB3 ppo, and CleanRL PPO (JAX) in **4 out of the 4 tasks** reported.\n\n\n|                             | openai/baselines PPO   | SB3 ppo            | CleanRL PPO (JAX)   | RLlib's PPO @ 10M steps |\n|:----------------------------|:-----------------------|:-------------------|:--------------------|:------------------------|\n| BeamRiderNoFrameskip-v4     | 2835.71 ± 387.92       | 3844.13 ± 266.71   | 3133.78 ± 293.02    | 2807.00           |\n| BreakoutNoFrameskip-v4      | 405.73 ± 11.47         | 307.39 ± 118.27    | 465.90 ± 14.30      | 104.00            |\n| EnduroNoFrameskip-v4        | 986.69 ± 25.28         | 745.19 ± 139.98    | 1178.37 ± 90.34     | -                |\n| PongNoFrameskip-v4          | 20.45 ± 0.81           | 20.69 ± 0.33       | 20.62 ± 0.18        | -                 |\n| QbertNoFrameskip-v4         | 15228.25 ± 920.95      | 13167.47 ± 1066.11 | 17318.50 ± 385.80   | 11085 |\n| SeaquestNoFrameskip-v4      | 1518.33 ± 400.35       | 1538.04 ± 389.55   | 1203.30 ± 364.07    | -                |\n| SpaceInvadersNoFrameskip-v4 | 1019.75 ± 49.08        | 911.16 ± 96.51     | 1164.26 ± 176.96    | 671.00            |""}}, {'title': {'value': 'Reviewer response'}, 'comment': {'value': 'Thanks for the clarification and answering the questions. It would be great if you can incorporate parts of the response above to make clear (1) differences from model-based methods mentioned above and how you bridge the gap from them to dqn/ppo (2) stress that effective horizon is not just k, possibly giving an intuition for the same.'}}, {'rebuttal': {'value': 'We thank the reviewer for their careful and comprehensive review. We are glad that they found our results on acting greedily with respect to the random policy’s Q-function “extraordinary and quantitatively verified.” Below are responses to questions and comments.\n\n**Our PPO results vs. benchmarks:** We appreciate the reviewer’s thorough comparison of our PPO results in Appendix H.1 to previous benchmarks. We believe that the difference in returns is because *we limit agents to a single life* in the Atari games, as described in Appendix F.1. We do this in order to align the Atari games more precisely with the theoretical framework for episodic RL, where episodes always start in states drawn from the same distribution. In typical Atari training, episodes are truncated when a life is lost but then a new episode is started in the state following the lost life. This actually makes the starting state distribution policy-dependent, which is quite different from the theoretical RL setting. Note that this also introduces a difference between training, when Atari agents’ episodes are truncated on loss of life, versus testing, when the agents’ rewards are summed over all lives. To avoid these problems, we simply end episodes entirely after one life during both training and testing.\n\nWe believe that this accounts for the difference between our results and those from other RL libraries. RLlib’s PPO implementation has been benchmarked [here](https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#ppo) in several Atari environments and performs quite similarly to SB3, so we do not think that the RLlib implementation is the reason for the difference in results. Most of these environments have 3-5 lives, which could explain why the reward is often 3-5x lower for our setting.\n\nWe also plan to rerun our experiments with the SB3 implementations of PPO and DQN to make sure that they are robust to the exact implementations of the RL algorithms. We will include these results in the final paper if accepted.\n\n**More information about the surprisingly common property:** One of the motivations for examining the Q-values of the random policy was an analysis of policy gradient algorithms. When initialized with the random policy, the policy gradient can be exactly expressed in terms of the Q-values of the random policy:\n\n$$\\\\nabla\\_\\\\theta J(\\\\theta) = \\\\mathbb{E}\\_{\\\\pi^\\\\text{rand}}\\\\left[ Q^{\\\\pi^\\\\text{rand}}(s, a) \\\\nabla\\_\\\\theta \\\\pi\\_\\\\theta(a \\\\mid s) \\\\right]$$\n\nThus, one might expect policy gradient algorithms to (at least initially) move towards a policy which chooses actions with the highest Q-values under the random policy. This motivated us to examine the performance of simply acting greedily with respect to the random policy’s Q-function.\n\nTo calculate $\\\\Pi(Q^{\\\\pi^\\\\text{rand}})$ for an environment, we first run value iteration on the tabular representation to precisely calculate the Q-function $Q^{\\\\pi^\\\\text{rand}}$ at every state-action pair. Then, we can easily compute the set of policies which are greedy according to that Q-function as policies which take one of the actions with the highest Q-value at each state. For instance, suppose at the first state there are three actions with Q-values of 1, 1, and ½. Then a policy which takes either of the first two actions is greedy with respect to the Q-function. Often, there are multiple actions with the highest Q-value, since in many environments multiple actions may have the same effect.'}}, {'rebuttal': {'value': 'We thank the reviewer for their comprehensive review. We appreciate that they found our results “extensive” and that they think the tabular representations in our BRIDGE dataset “can be very useful for future research on tighter theoretical bounds.” Below are responses to individual comments and questions.\n\n**Optimal policy in short-horizon environments:** As the reviewer noted, the environments in the BRIDGE dataset have relatively short horizons compared to many typical RL benchmarks. We found that it was intractable to compute the tabular representations for long-horizon environments since the number of states reachable over long horizons was too large. Thus, we use horizon-limited environments for most of the results in the paper. We define the optimal policy as the policy which achieves the highest return over the limited horizon $T$ of the environment.\n\nNote that we run the deep RL algorithms and GORP in the horizon-limited environments too such that they are exactly equivalent to the tabular representations. Thus, the maximum possible return achievable by PPO, DQN, and GORP is exactly the same as the return of the optimal policy in the tabular representation. We only use the normal Atari settings (frameskip=4, horizon=27,000) for the experiments in Appendix H.1. We will clarify this in the paper.\n\n**Values of $k$ for empirical GORP sample complexity:** For the results in Table 2, we swept over values of $k$ and chose the value with the smallest sample complexity. However, even if we restrict GORP to using $k = 1$, we find a Spearman correlation of 0.69 for PPO and 0.69 for DQN between the GORP sample complexity and the deep RL sample complexity. This is still about as well as PPO or DQN correlate with each other, indicating that GORP is quite similar to PPO/DQN even when $k$ is not tuned. We will include these results in the final version of the paper if accepted.\n\n**Values of horizon $T$ in Table 2:** We use the horizons for the horizon-limited versions of these environments. As described above, these are the versions that PPO, DQN, and GORP are trained in as well, so there is no arbitrary selection of horizon—it is based on the environment that the RL algorithms are interacting with. If we made the frameskip smaller, it might change the theoretical bounds, but it could also significantly change the empirical sample complexity of PPO and DQN since they will also need to interact with the environment for more timesteps to see rewards.\n\nOur results in Appendix H.1 show that GORP is also quite similar to PPO/DQN over much longer horizons like those normally used for benchmarking deep RL algorithms. Since the effective horizon is based on GORP, we also expect that the effective horizon-based bounds would closely reflect deep RL performance with longer horizons and smaller frameskip (although we can’t test this exactly since it is intractable to compute tabular representations of the long-horizon environments).\n\n**References to tables and figures in the appendix:** We thank the reviewer for pointing out that these references are confusing as they are now. We will make it more clear when references are made to the appendix.\n\n**Application to algorithms with additional exploration strategies:** We agree that this is a limitation of our analysis and will mention it in the paper as a direction for future work.'}}, {'rebuttal': {'value': 'We thank the reviewer for their thorough and thoughtful review. Below are responses to questions and comments raised in the review.\n\n**Effective horizon vs $k$:** First, we noticed that there may have been some confusion between the value of $k$ for which an MDP is $k$-QVI-solvable versus the effective horizon $H$. $k$ relates to the number of steps of value iteration that need to be applied to the random policy’s Q-function before one can act greedily to solve the MDP (Definition 5.1). The effective horizon (Definition 5.2) combines $k$ with $m_k$, which is the number of random rollouts collected for each action sequence in GORP (see Figure 1 or Algorithm 1). We will clarify the difference between these two values in the paper.\n\n**Requiring oracle information to compute the effective horizon:** While it is true that one needs access to the tabular representation of the MDP to compute the effective horizon, in practice this is true for UCB and EPW bounds too. UCB bounds depend on the number of states in an environment, which is often unknown. The number of states can sometimes be upper-bounded, but so can the effective horizon (since $H \\leq T$ always). Exploring every state to count them may be as hard or harder than solving the MDP. EPW bounds also require access to the optimal policies for an MDP, since one needs to know which actions are optimal to know if those actions can be found by only considering rewards in the planning window. We will clarify this in the paper.\n\n**Claim that GORP achieves an optimal policy in many environments:** We refer the reviewer to Appendix H in the supplementary material for the full results of our experiments on GORP. Appendix H.5 lists the effective horizon for each environment; Appendix H.7 lists the final reward achieved by each algorithm, including GORP; and Appendix H.8 has learning curves for PPO, DQN, and GORP in all environments.\n\n**Novelty of GORP:** We thank the reviewer for the references to related work on Monte Carlo planning. We note that GORP may be similar to Monte Carlo planning algorithms, but is novel because it is actually *not* a planning algorithm—instead, it is a model-free RL algorithm. It does not use a learned or specified world model, unlike all the given references. One of our key contributions with GORP is to show that model-free RL algorithms like PPO and DQN may implicitly be doing something similar to Monte Carlo planning despite appearing quite different.\n\n**Does GORP with a particular effective horizon outperform PPO/DQN:** Again, we note that $k$ is different from the effective horizon $H$. However, we will include results for GORP constrained to $k=1$ in the final paper. For instance, GORP with $k=1$ has a lower sample complexity than DQN in 67 of the 99 environments in BRIDGE where DQN converges; with any $k$, this rises to 81 of 99. GORP with $k = 1$ also outperforms PPO in 39 of 98 environments where PPO converges, compared to 56 with any value of $k$. Finally, note that we compared GORP against PPO and DQN on long-horizon Atari games in Figure 5; we used only $k = 1$ for those experiments (see Line 1571).\n\n**Line 7 in Algorithm 1:** In Line 7 of the GORP algorithm, the argmax action is chosen based on the estimated Q values for each $k$-action sequence, which are calculated inside the loop on Line 5. Each loop consists of several rollouts following the existing learned policy up to timestep $i - 1$, then following a particular action sequence $a_{i : i + k - 1}$ for timesteps $i$ to $i + k - 1$, and then acting randomly; the mean of the rewards across rollouts is computed and saved as the approximate Q-value $\\\\hat{Q}\\_i(s\\_i, a\\_{i : i + k - 1})$  for that action sequence. On Line 7, the sequence with the highest estimated Q-value is found and its first action is selected as the policy’s action for timestep $i$. None of these steps uses a model, so the algorithm is model-free.'}}, {'rebuttal': {'value': 'We thank the reviewer for their careful and thoughtful review. We appreciate that the reviewer found that our work offered “an interesting and non-trivial way to think about RL.”\n\n**Difference between random policy’s Q-function and randomly initialized Q network:** In this work, we only focus on the Q-function of the random policy; we never analyze the Q function corresponding to a Q network with randomly initialized parameters. We would not expect a randomly initialized Q network to provide any useful information about which actions to take. We will clarify this point in the paper.\n\nThe Policy Churn paper is quite interesting and could help explain properties of deep RL algorithms related to their use of neural networks. However, in this paper we show that (in deterministic environments) deep RL performs quite similarly to GORP, an algorithm which does not use neural networks at all. This suggests that one can gain significant understanding of deep RL without understanding its neural network components. We hope that future work like the Policy Churn paper will further explore how neural networks interact with deep RL.\n\n**Limitations on the practical use of the effective horizon:** We agree that in many cases it is intractable to explicitly calculate the effective horizon. We argue in the Limitations section on line 408 that “despite this, [the effective horizon] serves as a useful perspective for understanding RL’s effectiveness and potential improvement areas.” We hope that practitioners can gain an intuitive understanding of the effective horizon from our paper that helps them use deep RL more effectively.\n'}}, {'summary': {'value': 'The paper aims at addressing the gap between RL theory and deep RL practice. \nThe central finding of the paper is a property that correlates well with the performance of PPO and DQN algorithms on a set of 155 environments (such as Atari, Procgen, and MiniGrid).\nThe property looks at whether the argmax action of the action-value function under the random policy coincides with the argmax action of the optimal action-value function. \nInspired by the property, the authors propose a complexity measure called the effective horizon that corresponds to the number of lookahead search steps needed to identify an optimal action, given that the leaf nodes are evaluated under the random policy.\nBounds that utilize the measure correlate with empirical sample complexity of PPO on the collection of 155 games (r = 0.79 for PPO and r = 0.65 for DQN).\nLastly, the paper demonstrates the predictive power of the effective horizon when using reward shaping and pre-training.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The paper is well-written and easy to follow.\n- Motivation is solid: the paper makes a step certainly in the right direction as the gap between RL theory and practice is tremendous.\n- The personal experience of the reviewer with the submission started from ""That\'s surprising"", followed by ""It can\'t be true"", finally reaching ""Ah, it makes sense"", implying that the paper offers an interesting and non-trivial way to think about RL. One of the take-aways for the reviewer is that if the policy evaluation is done perfectly, there might be a need only for just a few (sometimes zero) policy improvement steps.\n\nThe reviewer is inclined to recommend the paper for acceptance because it is likely to generate a fruitful discussion in the community.\n'}, 'weaknesses': {'value': ""There might be certain weaknesses that the reviewer didn't notice but as of now there are none that feel worthwhile mentioning; having said that, the reviewer has limited experience with complexity bounds in RL and maybe more experienced RL theory person will be able to identify the limitations of the analysis.\nThe reviewer is looking forward for the discussion phase.\n""}, 'questions': {'value': 'Could you quantify the agreement between the (exact) action-value function corresponding to a random policy and a Q-network with randomly initialized parameters? If the agreement is high, it\'d somewhat imply that for many domains the weights are initialized at a point that is almost an optimal solution; such a finding would be even more surprising.\n\nThe reviewer would suggest to take a look at the Policy Churn paper [1] that observes that the argmax of the learned action-value function in DQN-based methods changes in 10% of the states after each parameter update. The observation might be related to the high predictive power of the measure the authors observe.\n\n[1] Schaul, Tom, André Barreto, John Quan, and Georg Ostrovski. ""The phenomenon of policy churn."" Advances in Neural Information Processing Systems 35 (2022): 2537-2549.\n\n\n'}, 'limitations': {'value': '\nPerhaps the main limitation is that the effective horizon could be used for analysis purposes only; from the practical viewpoint, it is unclear how for a large MDP estimate efficiently the effective horizon (and thus obtain the sample complexity for the MDP).\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper investigates the question of what finding an explanation for the performance of deep RL algorithms. To accomplish this, the authors propose the notion of effective horizon. It is found that this notion is better able to answer questions about sample complexity and effect of reward shaping or policy initialization in RL than all prior theoretical bounds.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'Strengths:\n1. The first great part about the paper is the writing. Reading the paper is easy and flows well. \n2. The authors present a surprising finding - on a large fraction of environment just evaluating random policy with one step of policy improvement leads to optimal policy. For the rest if the environments, a few steps of value iteration usually leads to optimal policy. This is in contrast to previous ideas and theory in RL which are unable to explain when RL fails in certain environments and when it will work. \n3. Authors propose a new method GORP (Greedy over random policies), which performs a few step of policy improvements over a random policy and is shown to be a competitor to PPO and DQN algorithms even for long horizon.\n4. The experiments demonstrate that the theoretical bounds for GORP neatly explains empirical bounds obtained by DQN/PPO on complex environments by measuring quantities like correlation, medium ratio, etc. \n5. The analysis in the paper is also the first to explain the effect of reward shaping and initializing RL with a policy using the GORP bound.  The effective horizon bound has a correlation of around 0.4 in both of these settings (reward shaping and policy initialization) which is more than other bounds which are agnostic to reward or do not consider the effect of policy past the horizon.\n'}, 'weaknesses': {'value': 'Weaknesses:\n1. Unlike prior bounds using UCB and EPW, GORP seems to require oracle information to compute the effective horizon. Can the authors comment on the implication of this in the paper? For example, we can’t use GORP bounds to compute sample efficiency without having an algorithm that solves the task first. \n2. It is claimed that GORP achieves an optimal policy in almost all the environment when a effective horizon > 1 is used (Line 77), but the experiments for this seem to be missing. Learning curves and final performance along with effective horizon used would be important to support this claim.\n3. Novelty of GORP: It would be important to do a more thorough literature review with prior works in the area which proposed an algorithm very similar to GORP in order to clarify the novelty there:\na. MCTS\nb. Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm, Silver et al\nc. Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model, Schrittwieser et al\nd. Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control, Lowrey et al\ne. Learning Off-Policy with Online Planning, Sikchi et al\nf. Model-Based Offline Planning, Argenson et al'}, 'questions': {'value': '1. Does GORP with a particular effective horizon outperform DQN/PPO? This experiment seem to be missing in Figure 5 and figure 10 where k is fixed to be 1.\n2. How is line 7 in Algorithm 1 performed in practice? Is the whole list of possible actions enumerated to find the best one? If so, does the method assume known model of the environment? In that case, why does comparing to only model-free methods make sense for sample complexity bounds?\n'}, 'limitations': {'value': 'Authors address the limitation in Section 7 of the paper.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes a new complexity metric, denoted as effective horizon, for deterministic MDPs. It is defined as the number of full value iteration updates starting from an initial policy, plus a logarithmic factor for concentration bounds, needed to reach an optimal policy. A corresponding algorithm, GORP, is also suitably defined. The bound is calculated for a set of 155 deterministic MDPs, and compared with empirical sample complexity of PPO and DQN, and is shown to correlate decently well compared to other sample complexity bounds. It is also shown how the effective horizon can be applied to shaped rewards or different initial policies to get a better problem-dependent estimate of sample complexity.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'There are extensive results and analyses in the paper and appendix, with good comparisons to other sample complexity measures. The task of converting many large MDPs to tabular representations and computing bounds can be very useful for future research on tighter theoretical bounds.\n\nThe proposed measure of effective horizon does seem to have good correlation with empirical algorithms, and intuitively makes sense, as the number of value iteration steps can correlate with the number of gradient updates to a value network.\n\nThe biggest strength of effective horizon is that it is policy and reward dependent, which makes it much easier to apply (as the paper points out) to shaped rewards and better initialized policies.\n'}, 'weaknesses': {'value': 'There are many references to tables or figures in the appendix without marking them as being in the appendix, which can be confusing.\n\nAs mentioned in the paper, there are several limitations such as being only for deterministic MDPs, and hard to compute in general for large MDPs. Nevertheless, the initial results do demonstrate the viability of this type of bound, which future work can take and build upon.\n\nAnother downside is that the effective horizon can be hard to apply to algorithms with additional exploration built-in, such as using an intrinsic reward. This is due to the fact that the intrinsic reward is non-stationary and changes over time, so the effective horizon would only give a bound for a specific snapshot of intrinsic reward, rather than the entire training process. How to handle non-stationarity could be an interesting future direction.\n\nSome concerns about the experiments are brought up in the questions section below.\n'}, 'questions': {'value': 'How do you define optimal policy across your environments since your episodes are relatively short? Many Atari games go on for thousands if not hundreds of thousands of timesteps, so what does it mean to reach optimality?\n\nFor the empirical GORP results in table 2, what value of k and m were used? Did you sweep over k to find the best k? Or use the smallest k that reaches optimal?\n\nFor table 2, for the horizon T, were you using the horizon of the tabular representation (i.e. after frameskip)? If so, there is a degree of arbitrary choice here, as many of the Atari environments had large frameskips of 30, which greatly reduces the T needed to see reward. If frameskips were smaller, such as 4, and horizon increased accordingly to accommodate, then all theoretical bounds would be even more orders of magnitude off from empirical sample complexity.\n'}, 'limitations': {'value': 'Are addressed in the paper.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""The authors aim to improve the theoretical understanding of RL. The contributions of the paper are as follows:\n1. The authors curated a dataset called BRIDGE consisting of 155 deterministic MDPs along with their tabular representations\n1. The authors found that, for a given deterministic MDP, deep RL is more likely to succeed **if the policy acting greedily w.r.t to the random policy's Q function (which can be obtained via dynamic programming) is optimal**.\n1. Motivated by the property in the last bullet point, the authors propose a complexity measurement metric called **effective horizon** that roughly measures the number of steps of look-ahead search needed to identify the next optimal action.\n   * The authors show effective horizon is more reflective of PPO and DQN's empirical performance than prior complexity bound metrics\n""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""The paper proposes a highly useful benchmark of deterministic MDPs, which is helpful for more theoretical analysis instead of relying merely on results on black-box algorithms. The finding that deep RL is more likely to succeed if the policy acting greedily w.r.t to the random policy's Q function (which can be obtained via dynamic programming) is optimal is extraordinary and quantitatively verified. Furthermore, the effective horizon bound is highly efficient and predictive of the agent's performance, which is useful for future theoretical studies. Last but not least, the paper is well written. ""}, 'weaknesses': {'value': ""The paper is well-written, and it is good to see that the authors have released the training code. However, I do have a concern about the PPO training results with Atari. \n\nFigure 5 on page 44 shows the training results of Atari with 50M steps (200M frames). However, the scores obtained by PPO are considerably lower than those from popular RL libraries. Below is a table summarizing the performance difference between the results reported in this paper compared to the results reported for `openai/baselines` in the [openrlbenchmark project](https://github.com/openrlbenchmark/openrlbenchmark/blob/8a1248b63daef6b4bab78467a2d7356038b87042/README.md#compare-cleanrls-ppo-with-openaibaseliness-ppo2-on-atari-games). **The PPO in this paper used 5x more samples and produced only 1/3 to 1/15 of the scores of  `openai/baselines`.** While the settings are clearly different in some ways (e.g., I noticed the authors did not use frame stacking in the Atari preprocessing), the performance discrepancy is large enough that I think warrants further investigation. \n\n| Environment | this paper's RLLib PPO @ 50M steps | `openai/baselines`' PPO @ 10M steps |\n| --- | --- | --- |\n| Beam Rider | ~700 | 2835.71 ± 387.92 |\n| Breakout | ~30 | 405.73 ± 11.47 |\n| Enduro | ~200 | 986.69 ± 25.28 |\n| Pong | 20 | 20.45 ± 0.81 |\n| Qbert | ~1000 | 15228.25 ± 920.95 |\n| Seaquest | ~400 | 1518.33 ± 400.35 |\n| Space Invaders | ~200 | 1019.75 ± 49.08  |\n\nPPO has many implementation details ([Engstrom, Ilyas, et al., 2020](https://openreview.net/forum?id=r1etN1rtPB); [Andrychowicz, et al., 2021](https://openreview.net/forum?id=nIAxjsniDzg); [Huang et al., 2022](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/)) which may cause subtle issues. For sanity checks, maybe it's worthwhile conducting a PPO RLLib experiment with SB3's [Atari wrappers](https://github.com/DLR-RM/stable-baselines3/blob/master/stable_baselines3/common/atari_wrappers.py) for 10M steps. \n\nIf the performance is on par with  `openai/baselines` PPO results, then the PPO results of this paper can be attributed to different environment preprocessing. If PPO RLLib significantly underperforms, it could mean that PPO RLLib is not a proper PPO implementation, and the PPO results of this paper should be re-done with SB3's PPO, `openai/baselines`' PPO, or CleanRL's PPO, all of which are more well-benchmarked. \n\n\n\n\nP.S. According to https://github.com/openrlbenchmark/openrlbenchmark's documentation, you can retrieve the data above by running \n\n\n```bash\npip install openrlbenchmark==0.2.0\nwandb login\npython -m openrlbenchmark.rlops \\\n    --filters '?we=openrlbenchmark&wpn=baselines&ceik=env&cen=exp_name&metric=charts/episodic_return' \\\n        'baselines-ppo2-cnn?cl=openai/baselines PPO' \\\n    --filters '?we=openrlbenchmark&wpn=sb3&ceik=env&cen=algo&metric=rollout/ep_rew_mean' \\\n        'ppo?cl=SB3 ppo' \\\n        'dqn?cl=SB3 dqn' \\\n    --filters '?we=openrlbenchmark&wpn=envpool-atari&ceik=env_id&cen=exp_name&metric=charts/avg_episodic_return' \\\n        'ppo_atari_envpool_xla_jax_truncation?cl=CleanRL PPO (JAX)' \\\n    --env-ids BeamRiderNoFrameskip-v4 BreakoutNoFrameskip-v4  EnduroNoFrameskip-v4 PongNoFrameskip-v4  QbertNoFrameskip-v4 SeaquestNoFrameskip-v4 SpaceInvadersNoFrameskip-v4 \\\n    --env-ids BeamRiderNoFrameskip-v4 BreakoutNoFrameskip-v4  EnduroNoFrameskip-v4 PongNoFrameskip-v4  QbertNoFrameskip-v4 SeaquestNoFrameskip-v4 SpaceInvadersNoFrameskip-v4 \\\n    --env-ids BeamRider-v5 Breakout-v5  Enduro-v5 Pong-v5  Qbert-v5 Seaquest-v5 SpaceInvaders-v5  \\\n    --no-check-empty-runs \\\n    --pc.ncols 4 \\\n    --pc.ncols-legend 4 \\\n    --rliable \\\n    --rc.score_normalization_method atari \\\n    --rc.normalized_score_threshold 8.0 \\\n    --rc.sample_efficiency_plots \\\n    --rc.sample_efficiency_and_walltime_efficiency_method Median \\\n    --rc.performance_profile_plots  \\\n    --rc.aggregate_metrics_plots  \\\n    --output-filename figures/0compare \\\n    --scan-history\n```\n\n\n|                             | openai/baselines PPO   | SB3 ppo            | SB3 dqn           | CleanRL PPO (JAX)   |\n|:----------------------------|:-----------------------|:-------------------|:------------------|:--------------------|\n| BeamRiderNoFrameskip-v4     | 2835.71 ± 387.92       | 3844.13 ± 266.71   | 5774.61 ± 408.73  | 3133.78 ± 293.02    |\n| BreakoutNoFrameskip-v4      | 405.73 ± 11.47         | 307.39 ± 118.27    | 251.67 ± 15.92    | 465.90 ± 14.30      |\n| EnduroNoFrameskip-v4        | 986.69 ± 25.28         | 745.19 ± 139.98    | 493.08 ± 69.14    | 1178.37 ± 90.34     |\n| PongNoFrameskip-v4          | 20.45 ± 0.81           | 20.69 ± 0.33       | 20.44 ± 0.17      | 20.62 ± 0.18        |\n| QbertNoFrameskip-v4         | 15228.25 ± 920.95      | 13167.47 ± 1066.11 | 11502.93 ± 487.54 | 17318.50 ± 385.80   |\n| SeaquestNoFrameskip-v4      | 1518.33 ± 400.35       | 1538.04 ± 389.55   | 2936.30 ± 941.92  | 1203.30 ± 364.07    |\n| SpaceInvadersNoFrameskip-v4 | 1019.75 ± 49.08        | 911.16 ± 96.51     | 778.57 ± 46.76    | 1164.26 ± 176.96    |""}, 'questions': {'value': 'The finding on the ""surprisingly common property"" is very interesting to me. I would be interested in more content on it. For example, how did you find this property? What is the motivation for finding the Q values of the random policy? Is there an example of how $\\prod(Q^{\\pi^{rand}})$ is constructed for a simple MDP?'}, 'limitations': {'value': 'Yes.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Bridging RL Theory and Practice with the Effective Horizon'}, 'authors': {'value': ['Cassidy Laidlaw', 'Stuart Russell', 'Anca Dragan']}, 'authorids': {'value': ['~Cassidy_Laidlaw1', '~Stuart_Russell1', '~Anca_Dragan1']}, 'keywords': {'value': ['reinforcement learning', 'RL theory', 'theory of reinforcement learning', 'instance-dependent bounds', 'empirical validation of theory']}, 'TLDR': {'value': 'We prove new sample complexity bounds for reinforcement learning (RL) and demonstrate they closely reflect the performance of deep RL algorithms.'}, 'abstract': {'value': ""Deep reinforcement learning (RL) works impressively in some environments and fails catastrophically in others. Ideally, RL theory should be able to provide an understanding of why this is, i.e. bounds predictive of practical performance. Unfortunately, current theory does not quite have this ability. We compare standard deep RL algorithms to prior sample complexity bounds by introducing a new dataset, BRIDGE. It consists of 155 MDPs from common deep RL benchmarks, along with their corresponding tabular representations, which enables us to exactly compute instance-dependent bounds. We find that prior bounds do not correlate well with when deep RL succeeds vs. fails, but discover a surprising property that does. When actions with the highest Q-values under the *random* policy also have the highest Q-values under the *optimal* policy—i.e., when it is optimal to act greedily with respect to the random's policy Q function—deep RL tends to succeed; when they don't, deep RL tends to fail. We generalize this property into a new complexity measure of an MDP that we call the *effective horizon*, which roughly corresponds to how many steps of lookahead search would be needed in that MDP in order to identify the next optimal action, when leaf nodes are evaluated with random rollouts. Using BRIDGE, we show that the effective horizon-based bounds are more closely reflective of the empirical performance of PPO and DQN than prior sample complexity bounds across four metrics. We also show that, unlike existing bounds, the effective horizon can predict the effects of using reward shaping or a pre-trained exploration policy. Our code and data are available at https://github.com/cassidylaidlaw/effective-horizon.""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/88e0462b8cdd62956600699fc9b27a5ab72c01e0.pdf'}, '_bibtex': {'value': '@inproceedings{\nlaidlaw2023bridging,\ntitle={Bridging {RL} Theory and Practice with the Effective Horizon},\nauthor={Cassidy Laidlaw and Stuart Russell and Anca Dragan},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=Lr2swAfwff}\n}'}, 'paperhash': {'value': 'laidlaw|bridging_rl_theory_and_practice_with_the_effective_horizon'}}]"
"['Gellert Weisz', 'András György', 'Csaba Szepesvari']",NeurIPS,Online RL in Linearly $q^_pi$-Realizable MDPs Is as Easy as in Linear MDPs If You Learn What to Ignore,https://neurips.cc/virtual/2023/oral/73864,2023," We consider online reinforcement learning (RL) in episodic Markov decision processes (MDPs) under the linear $q^\pi$-realizability assumption, where it is assumed that the action-values of all policies can be  expressed as linear functions of state-action features. This class is known to be more general than  linear MDPs, where the transition kernel and the reward function are assumed to be linear functions of the feature vectors. As our first contribution, we show that the difference between the two classes is the presence of states in linearly $q^\pi$-realizable MDPs where for any policy, all the actions have  approximately equal values, and skipping over these states by following an arbitrarily fixed policy in those states transforms the problem to a linear MDP. Based on this observation, we derive a novel (computationally inefficient) learning algorithm for linearly $q^\pi$-realizable MDPs that simultaneously learns what states should be skipped over and runs another learning algorithm on the linear MDP hidden in the problem. The method returns an $\epsilon$-optimal policy after $\text{polylog}(H, d)/\epsilon^2$ interactions with the MDP, where $H$ is the time horizon and $d$ is the dimension of the feature vectors, giving the first polynomial-sample-complexity online RL algorithm for this setting. The results are proved for the misspecified case, where the sample complexity is shown to degrade gracefully with the misspecification error.",Oral 1A RL,https://openreview.net/pdf?id=HV85SiyrsV,https://openreview.net/forum?id=HV85SiyrsV,HV85SiyrsV,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': ""This paper resolves one of the major open problems in RL with function approximation: Linearly $q^\\pi$-Realizable MDPs in the online setting. The paper gives structural lemmas by connecting $q^\\pi$-Realizable MDPs with a seemingly significant broader class: linear MDP. All reviewers believe this paper makes significant contributions to the community. The AC agrees and recommends acceptance.\nPlease revise the writing according the reviewers' suggestions in the final version.""}}, {'comment': {'value': ""I thank the authors for addressing many of my questions, and proposing plans of improvement. I reiterate that I think the contribution is significant, and the techniques are novel and inspiring. All my complaints are about the readability. Still, readability is an important part of a paper, and it is hard to see the overall picture of the paper after the authors implement the proposed modification. Therefore, I'm leaving my score as it is, with the hope that the paper can be sufficiently revised and reviewed again. ""}}, {'comment': {'value': 'Thanks for this additional clarification.\n\nI think that this discussion would fit the paper well because it is a nice discussion on a natural follow up research question which is designing a computationally efficient algorithm for the same setting.\n\nKnowing which are the problems in adapting LSVI-UCB is certainly interesting.\n\nMy assessment of the paper improved after discussion therefore I would like to increase my score to 8.'}}, {'comment': {'value': 'Thank you, we will include the reduction in the appendix.'}}, {'comment': {'value': 'We think LSVI-UCB may fail altogether, at least we are unable to prove that it produces a good policy, since the linear MDP assumption is not met and the argument that shows that LSVI-UCB produces a good policy appears to rely on this assumption in a crucial way.\nWe currently do not have a counterexample that shows that LSVI-UCB will indeed fail. However, we believe the following argument could be used to create a counterexample: one could start from a linear MDP and add states with zero range (motivated by the theory in this paper), and extend the features of such states with arbitrary “nuisance” features. Then one would show that the “nuisance” features can be chosen in a way so that the optimistic targets of LSVI-UCB are not realizable, leading to an estimator that is totally misguided, leading to no learning.\n\nWe originally interpreted the question as whether LSVI-UCB could be modified to work for $q^\\pi$-realizable MDPs (the way our paper modified ELEANOR). In summary, we were not able to computationally efficiently do this in a way that leads to a polynomial sample complexity. We expand on this further below.\n\nWe need to introduce a mechanism that iteratively refines the target functions so that they are eventually realizable under the $q^\\pi$-realizability assumption. For our method presented in the paper, this mechanism is optimistically guessing (with $\\hat G$) and refining the range-estimates (via Optimization Problem 4.12). Without such a mechanism, the LSVI-UCB (or indeed even vanilla ELEANOR) targets may be unrealizable, invalidating a crucial prerequisite of their least-squares analyses. Our attempts to add such a mechanism to an LSVI-UCB style algorithm resulted in either (i) having a global optimization routine over $\\hat G$, like in the current version of the paper, or (ii) introducing a computationally efficient approximator, but the approximation error of this was too large and scaled exponentially in $H$. (ii) and (i) lead to the two undesirable outcomes you mentioned, respectively.'}}, {'title': {'value': 'Thank you for the comments'}, 'comment': {'value': 'Thank you for the response. After reading the responses, my rating remains the same, and I would recommend the authors include the reduction (even informally) in the paper upon revision.'}}, {'title': {'value': 'Thanks'}, 'comment': {'value': 'Dear authors,\n\nThanks for your response !\n\nFrom your previous answer, I am still not sure to understand the problem that would have been encountered with a LSVI-UCB type of algorithm.\n\nWould it lead to an exponential sample complexity due to the approximation error exponential in the horizon that you mentioned ?\n\nOr it would lead to a polynomial sample complexity but again with a computationally inefficient algorithm ?\n\n'}}, {'rebuttal': {'value': 'Please see our individual responses to the reviewers. We use this space to address a comment made by multiple reviewers that the exposition of the results could be improved (thank you for this feedback). We provide below a high-level explanation of our method and proof compared to ELEANOR (such a description is also added the the revised version of the paper).\n\nWhen setting up least-squares targets for the state-action pair $(S_t, A_t)$, ELEANOR uses $R_t + predicted \\textunderscore value \\textunderscore for(S_{t+1})$.\nWith this target we only require one on-policy rollout for each episode in order to get the least squares parameter estimate for all $H$ stages. In contrast, our least-squares targets are of the form of $R_t + … + R_{t+i} + predicted \\textunderscore value \\textunderscore for( S_{t+i+1})$, where $i$, the number of stages “skipped”, depends on the guess $\\hat G$. The guess $\\hat G$ is selected only in Optimization Problem 4.10, and we do not know its value at the time of data collection, so we cannot know which stages will have to be skipped. Therefore, (i) we need access to the rewards of the current policy at any stage (similarly to ELEANOR), and hence we run the current policy to any stage (including the last one); and (ii) perform rollouts with the fixed policy $\\pi^0$ (from any stage) to be able to estimate the rewards $R_{t+1},...,R_{t+i}$ collected while skipping over $i$ stages (for any $i$). To ensure this happens for every stage, we start phase II from every stage $k$, resulting in the additional for loop in Algorithm 1 compared to ELEANOR. (Finally, the randomization in Phase I is applied to make the optimization problem smooth, as described from line 160.)\n\nOne could analyze this algorithm similarly to the analysis of ELEANOR if it were not for the fact that the least-squares targets we just introduced are not realizable in general. We can, however, prove the realizability of certain components of the matrix-valued version of these targets, $F$ (Lemma 4.9 and Corollary 4.11). This enables us to detect when the realizability of our least-squares targets fail, measure the direction (component) of the largest error, and learn from that. This is the job of Optimization Problem 4.12: \n$\\hat{F}^{ki}_{\\hat{G}\\bar{\\theta}}$ corresponds to the matrix-valued empirical measurements of $F$, \n\nwhile $y^{ki}_{\\hat{G}\\bar{\\theta}}$ \nare the average predictions of the same quantities. If realizability were to hold, these matrices would be very close; if not, the direction of their largest discrepancy tells us something about $\\bot(Q, i)$, and allows us to learn.\n\nOptimism ties all this together: either there is no shortfall between predicted and measured $q$-values (and we are done) or we grow the elliptical potential of $X$ (the two cases present in ELEANOR), or we grow the elliptical potential of $Q$ (the new case due to the lack of realizability guarantees).\n'}}, {'rebuttal': {'value': 'We thank the reviewer for their helpful comments. We answer their questions below:\n\nComputational complexity and Q4: Regrettably, we eliminated our discussion on computational complexity when shortening the initial submission -- thank you for pointing this out. We will include it in the final submission, as summarized below (also mentioning the inefficiency of the algorithm in the abstract).\nIn our opinion significant challenges remain to determine whether a computationally efficient solution exists, and this remains an interesting open problem.\nOur method (Optimization Problem 4.10) includes a guess of G, which impacts the optimization quantities in a non-linear way. Computationally efficient approximations tend to lead to the approximation error growing exponentially in H. This is the main reason we could not show the computational efficiency of our method. As such, we opted to use an ELEANOR-style algorithm instead of one of LSVI-UCB-style, as the LSVI-UCB-style method would not present any advantages but (with our proof) would in fact result in worse sample complexity and would also make the presentation (even) more complex.\n\nQ1. SkippyPolicy is a policy in the MDP (with no return value). In line 7 of Algorithm 1, $\\pi^{mk}$ is the policy defined by SkippyPolicy$(\\hat{G},\\bar\\theta,k)$. We realized this was unclear and changed line 7 in the revised version to “Let $\\pi^{mk}$ be the policy defined by $\\text{SkippyPolicy}(\\hat{G},\\bar\\theta,k)$”.\n\nQ2. Yes (in the case that $i=t+1$). We drop the subscripts of $E$ when not needed (line 265) and introduce the $s_i \\rightarrow$ notation in line 268 to clean the notational clutter. We refer to states in a fixed trajectory with lower-case $s_i$ for the explanation in line 275 (and elsewhere), and denote random variables by upper-case in the least-squares target (and elsewhere). Please let us know if this is not presented well and we will improve it.\n\nQ3. You are right that the realizability of $E_{G\\theta}^{\\rightarrow}(S_{t+1}^{lkj}, \\dots R_H^{lkj})$ does not follow from Corollary 4.11 (and is not even true in general). In fact, we can only prove the realizability of this for the true guess (a fact we use to establish the optimism property of Optimization Problem 4.10). Once the optimism property is established, similarly to ELEANOR’s proof, we only need to learn (and make progress) whenever there is a discrepancy (i.e., a difference in the predicted and measured value for the optimistic policy). For ELEANOR, learning is always implemented in the form of an elliptical potential growth of the covariate-matrix, because the underlying least-squares targets are realizable. \nFor us, as we do not have realizability of $E_{G\\theta}^{\\rightarrow}(S_{t+1}^{lkj}, \\dots R_H^{lkj})$, the discrepancy can be either (as with ELEANOR) due to the elliptical potential growth of the covariate-matrix, but it could also be the result of our least-squares targets not being realizable.\nCorrespondingly, we need another component of the proof/algorithm to learn from these cases (Section 4.4, Checking consistency). This is why we introduce matrix-form versions of $E_{G\\theta}^{\\rightarrow}(S_{t+1}^{lkj}, \\dots R_H^{lkj})$, denoted by $F$. The guarantee of Corollary 4.11 can be used to show that projections of the matrix-form of the discrepancy (see Optimization Problem 4.12) align well with the $\\bot(Q, i)$ subspace. Consequently, we learn (and make progress) from the discrepancies that do not grow the elliptical potential of the covariate-matrix, as these stem from the non-realizability of $E_{G\\theta}^{\\rightarrow}(S_{t+1}^{lkj}, \\dots R_H^{lkj})$, an error we can learn from (Line 12 of Algorithm 1). For more information, please see the [“global” response](https://openreview.net/forum?id=HV85SiyrsV&noteId=26AjXdraOA), which includes an explanation of related ideas that we added to the paper.\n'}}, {'rebuttal': {'value': 'We thank the reviewers for their helpful comments. We address their concern mentioned in “weaknesses” in the [“global” response](https://openreview.net/forum?id=HV85SiyrsV&noteId=26AjXdraOA) and answer their questions below:\n\nQ1. We do not show a formal reduction of $q^\\pi$-realizable MDPs to linear MDPs in this work. Though such a reduction is part of the intuition of our method, it is not strictly part of the proof sadly. The reason for this is that the skipping oracle mentioned is hard to learn, and instead of a direct approach we argue that learning about this oracle happens whenever there is a need (performance shortfall) for it.\nA formal reduction, while tangential to our proof, is fairly straight-forward but cumbersome, with the caveat that the linear MDP will end up with $dH$ (instead of $d$) dimensional features to account for the technicality about the stage mapping that you mention.\nOne would proceed by copying the features of each state $s$ in stage $h$ into the $h^{th}$ chunk of size $d$ of this vector of size $dH$ (the rest of the vector remains zero). A similar transformation is applied to all $\\theta_h(\\pi)$. Then, $H$ copies are made of each high-enough-range state, with all possible stages (but keeping the feature vectors). These will be the states of the new MDP we construct. When a transition from state $s$ leads to skipped states, the linear MDP returns with the copy of the first non-skipped state that has a stage counter of stage($s$)+1, so that in this linear MDP the stage numbers are consecutive (as required by our definitions). $q^\\pi$-realizability of this modified MDP is easy to show, and – as it has no low-range states – Proposition 3.4, can be used to show that the modified MDP is linear. To account for the fact that this new MDP may finish an episode in fewer than H steps due to the skips, we add a special, zero-reward, self-transitioning state called “episode-over”. To ensure that the MDP stays linear, we extend the feature vectors of each state by a scalar 1, and a scalar indicator of being in this state, with all original features of the “episode-over” state defined to be zero. It is easy to see that this construction leads to a linear MDP with the desired action-value functions.\n\nQ2. Yes, thank you for pointing out this typo.\n\nQ3. $S_h$ is the (random) $h^{th}$-stage state when an MDP trajectory is started from state-action $(s, a)$, and policy $\\pi$ is followed. Note the preceding expectation operator; this notation is introduced in Line 76.\n'}}, {'rebuttal': {'value': 'We thank the reviewer for their helpful comments, based on which we have added a table to the revised version of our paper containing the summary of how our work fits in the wider literature. In short, (i) for linear MDPs, Jin et al. [2020] provide algorithms with both polynomial sample and computational complexity for the online RL setting, and hence also for the planning with a simulator setting; (ii) for the case of linearly $q^\\pi$-realizable MDPs, Yin et al. [2022] provide a computationally efficient algorithm with polynomial sample complexity for planning (with simulator access), but no prior work has provided algorithms with polynomial sample complexity for online RL; (iii) we provide a computationally inefficient method for this case with polynomial sample complexity (the first such result in the literature), but whether this is achievable with an efficient algorithm remains an intriguing open problem. We also added a discussion to conclude the paper clearly pointing out directions for future work. Due to space limitations we focused our literature review to the strictly most relevant works that provide a sufficient context to fully understand our new results. We are more than happy to include discussions on any works we might have missed out; please share any suggestions with us in a reply.\n\nQ1. We are not aware of any lower bounds beyond those that apply to linear MDPs. This lower bound is $d^2H^4/\\epsilon^2$ (from converting Remark 9 of Zhou et al., 2021, “Nearly Minimax Optimal Reinforcement Learning for Linear Mixture Markov Decision Processes” to our setting, in the latter of which  parameters are not shared across the stages). This bound matches the upper bound of ELEANOR (Zanette et al., 2020) up to logarithmic factors.\nWhile we therefore have the optimal dependence on $\\epsilon$, our exponents of $d$ and $H$ may be far from optimal, though we were unable to improve upon them. That said, our result is the first one establishing that this problem is polynomial-sample-complexity solvable, resolving an open problem of Du et al., [2019]. In our opinion this is the first and most important question to resolve, as it tends to establish a dividing line between tractable and intractable problems: polynomial-complexity bounds often can (and tend to) be improved upon, while problems shown to be exponentially hard tend to remain intractable even despite technological advances.\n\nQ2. Thank you, we will make sure our citation format complies with the formatting requirements.\n\nRe Figure 1, the sides of the figure are correct: The right MDP is obtained from the left one by removing (skipping) the states marked by red (and showing the cumulative rewards for the corresponding transitions). E.g., the two possible 2-step transition in the left MDP from $s_1$ to $s_4$ through $s_3$ with reward 0.5 for each transition is replaced in the right MDP with a single-step transition from $s_1$ to $s_4$ with reward 1 (for action 2, the action leading from $s_1$ to $s_3$ in the left MDP). Note that, as mentioned in the review of Wpjh, there is a typo in the caption and the feature of all other states should be $(0)$ not $(0.5)$.\n'}}, {'rebuttal': {'value': 'We thank the reviewer for bringing these presentational issues to our attention, and a special thanks for taking the time to provide useful concrete suggestions for improvement! The proof of our result uses many novel ideas and techniques, and we strived hard to present it well despite its inherent complexity (e.g., by introducing our definitions in a conceptually sensible order, accompanied by high-level descriptions). It was very useful to read where this presentation fell short, and we have correspondingly carried out the following improvements (which will appear in the revised/final version):\n\n- All instances of super/subscript of super/subscript were eliminated with a notational shorthand to remove the clutter (most notably, $p^{...}(.)$ becomes $p(...)$).\n- Clarifications and reminders were added to aid understanding, addressing (among others) all concrete confusion points noted in the review.\n- Added a high-level explanation for the decomposition of $E^\\to$ first into $E$, before decomposing $E$ into matrix-valued $F$ functions that will be used for Optimization Problem 4.12: “Since our realizability results in Section 4.2 only apply to functions defined at a given stage (as only memoryless policies are $q^\\pi$ -realizable), to be able to show that the least-squares targets are linearly realizable, we first decompose $E^\\to$ to directly express the effect of each stage in the trajectory (backwards).”\n- See [“global” response](https://openreview.net/forum?id=HV85SiyrsV&noteId=26AjXdraOA) that adds high-level explanation to the paper and addresses the reviewer’s point 5 and both questions.\n\nminor comments:\n- To point 4 of the weaknesses, the reviewer possibly misread this as $Proj_{Z(Q,h)}$ is defined as the (orthogonal) projection onto $Z(Q,h)$, not its orthogonal space (Definition 4.2). We fixed the confusing “skipping probability” terminology for $\\tau$.\n- $B_i$ is a Bernoulli random variable and is defined in Appendix B (in the revised version we added this to Algorithm 2), and $\\otimes$, defined in Appendix A, denotes a tensor product. We added the necessary pointers to make this clear.\n'}}, {'summary': {'value': 'The paper addresses online RL in episodic MDPs under linear $q^\\pi$-realizability, where policy action values are expressed as linear functions of state-action features. This class is shown to be more general than linear MDPs, where only the transition kernel and reward function are linear functions of feature vectors. The key contribution is identifying states in linearly $q^\\pi$-realizable MDPs where actions have approximately equal values, enabling transformation into a linear MDP. A novel learning algorithm is derived to determine which states to skip and apply another learning algorithm to the linear MDP. The proposed algorithm achieves an $\\varepsilon$-optimal policy after $\\operatorname{polylog}(H, d) / \\varepsilon^2$ interactions, representing the first online RL algorithm for linearly $q^\\pi$-realizable MDPs with polynomial sample complexity. Notably, the results hold in the misspecified case, where sample complexity gracefully degrades with the misspecification error.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. This paper offers a comprehensive exploration of Linearly $q^{\\pi}$-Realizable MDPs, making a significant contribution to the field of reinforcement learning with feature learning.\n\n2. The paper exhibits a clear and concise mathematical exposition with a well-structured presentation that is easy to follow.'}, 'weaknesses': {'value': '1. The current form of the paper lacks a Conclusion section, rendering it incomplete.\n\n2. It would enhance clarity if the authors presented a comparative analysis in tabular form, providing a clearer understanding of the different studies involving MDPs with $q^{\\pi}$-realizability and linear structure.\n\n3. The paper has relatively few references, and the discussion of this line of work appears somewhat limited. It would be beneficial for the authors to discuss more related work in this area.\n\n4. The left and right sides of Figure 1 seem to be reversed.'}, 'questions': {'value': '1. What is the lower bound for MDPs with $q^{\\pi}$-realizability? It appears to have significant dependencies on both the time H and d.\n\n2. There seems to be an issue with the citation format. The requirement is to use an unnumbered first-level heading for the references.\n'}, 'limitations': {'value': 'The suggestions have been claimed in ""Weaknesses"" and ""Questions"".\n\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper studies online RL under linear $q^\\pi$ realizable MDPs, and proposes an algorithm that learns an epsilon-optimal policy in polynomial time and polynomial sample complexity.  Previous online RL in linear RL either assumes that transitions and rewards are linear individually (e.g., linear MDP), or assumes ergodicity (e.g., Politex), or assumes access to an simulator that can reset to a previously visited states (Confidence-MC-Politex). This work removes all these assumptions and show that as long as $q^\\pi$ is realizable for all $\\pi$, polynomial-time algorithm is possible. The novel and surprising observation is that linear $q^\\pi$ MDP is actually a linear MDP if the ""range"" of all states are large. The proposed algorithm is inspired by ELEANOR but ""skip"" low-ranged state in its execution, and at the same time refine the estimation for the range on the fly using some techniques related to optimal design.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '1 poor'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The observations and techniques in this paper are novel and creative. It answers an open question by Du et al. (2019) on whether sample-efficient RL under linear $q^\\pi$ MDP is possible. \n\n[Du et al., 2019] Simon Du, Sham Kakade, Ruosong Wang, Lin F. Yang. Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?'}, 'weaknesses': {'value': 'While I appreciate the technical contribution, the delivery of the result is far from ideal. The paper is very difficult to read. I have identified the following possible reasons: \n1. Highly cluttered notation.  I think a rule of thumb in writing math is to avoid super/subscript of super/subscript as best as we can, and keeping the super/subscript as simple as possible, because they can make the expression difficult to parse. However, this kind of notations is everywhere in this paper, like $\\hat{\\theta}\\_{\\hat{G}\\bar{\\theta}}^{p^{mkj}(k),i}$ or \n$||\\varphi_{p(k)}^{mkj}||\\_{X^{-1}_{m,p^{mkj}(k)}}$ where not only the super/subscript dependence is deep, each layer has many letters. It becomes a significant obstacle when tracing the calculations. Besides, for the notation $p^{mkj}(k)$, I did not find a place where the parameter in the parenthesis does not match the second parameter in the superscript, so maybe one of them can be omitted? \n2. The ""definition"" dependence is deep. This means that the definition of a quantity usually involves another quantity defined somewhere else; and when I visit the ""somewhere else"", it further requires me to understand other quantities defined in other places, and so on. For example, Optimization Problem 4.12 involves $y^{ki}\\_{\\hat{G}\\bar{\\theta}}$ and \n$\\hat{F}^{ki}\\_{\\hat{G}\\bar{\\theta}}$ for which I have to check the complicated Eq. (12) for their definitions. The $c^j_{ki}$ \nthere is further defined by a big quantity in (18) and the definitions of $\\varphi^{mkj}\\_{p(k)}$ and $\\hat{\\theta}\\_{\\hat{G}\\bar{\\theta}}^{p^{mkj}(k), i}$ are further scattered in the previous page which further requires understanding other quantities first. I think part the difficulty to trace is also because of Reason 1 --- the readers are facing highly cluttered notations in each step of tracing the definitions, and eventually cannot really grasp the overall meaning.  \n3. No reminders for the place of the definitions.  Since there are a big amount of cluttered notations, the readers easily forget where they are defined, so I think it\'s better that there could be reminders here and there to let the reader know where the notations are defined previously.  For example, when I first see $C_{\\hat{G}\\bar{\\theta}}$ in Line 279, I don\'t know where this is defined. After a long time, I realized that it is a result of the statement in Line 256-258 with the $C$ defined in (8). \n4. Confusing notation/terminology: In Line 188, $Z(Q,h)$ is defined as some subspace, but $Proj_{Z(Q,h)}$ is defined as projection onto its *orthogonal* space, which is counterintuitive notational-wise. As another example, in Line 266 or Line 4 of Algorithm 2, $\\tau$ is called a ""skipping probability"", but to my understanding, $\\tau$ is more like ""probability of *not* skipping"". \n5. Lack of high-level explanation. Though I can see that the authors have used a considerable space for describing the components of the algorithm, there are still many design choices left unexplained. For example, I don\'t quite understand why an additional index of k in Line 6 of Algorithm 1 is needed, and why we need to call Algorithm 2 with that input k. I also hope to see a more high-level interpretation of the $\\mathbf{f}$ defined in Line 240, or what does it implied if $v^\\top_{\\||(Q,h)} \\mathbf{f}w$ is $\\alpha$-admissible (Lemma 4.9 and Corollary 4.11). For example, what\'s the importance of this fact for the checking consistency procedure. The design of the regression target $E^{\\rightarrow}(s_i\\rightarrow)$ also deserves more explanation, e.g., what\'s the relation between this and the standard one in ELEANOR. \n\nI understand that the main text space is very limited. But I believe there is way to give a high-level explanation and self-contained story in the main texts, and leaving details to the appendix. Currently, the main text itself is crowded with difficult-to-trace notation and lacks necessary explanations. This also hinders me from making a careful check for the correctness of the proofs. So I suggest that the authors spend time re-thinking about how to present the results, to really make it a strong paper. \n\nOther notations I couldn\'t find corresponding definitions: \n- $B_i$ in Line 5 of Algorithm 2\n- $\\otimes$ in (12). '}, 'questions': {'value': 'Can you give some high-level ideas of Optimization Problem 4.12? What are the meanings of $y^{ki}\\_{\\hat{G}\\bar{\\theta}}$ and $\\hat{F}^{ki}\\_{\\hat{G}\\bar{\\theta}}$? \n\nBesides, why do we need the for-loop in Line 6 in Algorithm 1? '}, 'limitations': {'value': ""There's no potential societal impact. ""}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proves that the standard online episodic RL with the $q^\\pi$-realizability assumption can be learned with polynomial samples, without generative models. Technically, this paper proves that the states of any MDPs with $q^\\pi$-realizability assumption can be partitioned into two disjoint sets, where the states in the first set have small range (i.e., the advantage function on the state is always small for every policy), and the transitions on the states in the second set can be approximated by a linear MDP. Consequently, this paper designs a novel algorithm called SKIPPYELEANOR that learns to distinguish the states with small range and the linear MDPs simultaneously. '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'This paper solves a long-standing open question of reinforcement learning theory by showing that MDPs with $q^\\pi$-realizability assumption can be learned with polynomial samples. The result is significant and beneficial to the community. The observation that the difference between MDPs with $q^\\pi$-realizability and linear MDPs is only the set of states with very small range is novel and neat. Conceptually, this observation deepens our understand on the $q^\\pi$-realizability assumption and can potentially inspire a new line of research.'}, 'weaknesses': {'value': 'The exposition of the results could be improved. Current Section 4 of this paper is very technical and involves too many symbols and definitions, which makes it less readable, despite the fact that the algorithm is conceptually simple. Is there a simpler setting that demonstrate the core idea of the algorithm while keeps the technical part less involved? '}, 'questions': {'value': 'In the last paragraph in Section 3, this paper argues that a MDP with $q^\\pi$-realizability can be converted to linear MDP by skipping the states with low range. Is this a rigorous reduction? How to construct the new MDP? In particular, the states are staged in the original MDP. By skipping some states, is the new MDP also staged, and is the stage of the un-skipped states unchanged?\n\n[Minor] In the caption of Figure 1, should the feature of all other states be 0 instead of 0.5?\n\n[Minor] What’s $S_h$ in the displayed equation after line 222?\n'}, 'limitations': {'value': 'The authors adequately addressed the limitations and potential negative societal impact.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This submission provides the first algorithm learning an $\\epsilon$-optimal policy with poly many samples obtained through online interactions with a $q^\\pi$-realizable MDP. This is an important contribution to an open question in the community. Indeed previous works either adopted a generative model or they required more stringent condition on the MDP class such as Linear MDP.\nThe core observations that might be useful for futures work are that:\n1) $q^\\pi$-realizability + strictly positive lower bound on the range $\\implies$ Linear MDP.\n2) In a $q^\\pi$-realizable MDP not only $q^\\pi$ are in the features span but also all admissible (see definition 4.6) functions.\n\nUnfortunately, the proposed algorithm is computationally inefficient as the authors mention at line 35 in the introduction.\nI think that this limitation should have been better discussed in the paper and mentioned in the abstract as well.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'Learning an $\\epsilon$-optimal policy with poly many samples obtained through online interactions with a $q^\\pi$-realizable MDP was an open question before this paper (to the best of my knowledge). This paper solves it with an elegant approach unveiling the fact that $q^\\pi$-realizable MDP are not linear MDP due to the existence of some low range states.\nHowever this states are unimportant for the goal of finding an optimal policy and therefore in these states we can fix an arbitrary policy and reduce a $q^\\pi$-realizable MDP to a Linear MDP with features norm bound inversely proportional to the range lower bound.\nThe authors further develop their algorithm to bypass the requirement of knowing the low range states in advance.\nI think this reduction to Linear MDP will be important for further advancements in the field. '}, 'weaknesses': {'value': 'I think the authors should have discussed better the fact that their algorithm is not computationally efficient.\nIn particular, I believe that the authors should explain that the computational barrier comes from Optimization Problem 4.10. This is probably obvious for reader already familiar with ELEANOR but I would still suggest to include this discussion in a Limitations section that the authors may want to add in their final revision. \n\nSome steps in the presentation might also be improved (please see questions in the next Section)'}, 'questions': {'value': ""1) Which is the output of Algorithm 2 ? In Algorithm 1, at line 7 the policy $\\pi^{mk}$ is defined as output of Skippy Policy which is not specified. Is it the policy that at state $S_i$ sample an action from $\\pi^+(S_i)$ with probability $\\tau_i$ and plays action 1 otherwise ?\n\n2) Is the quantity $E^{\\rightarrow}(s_i \\rightarrow)$ at line 275 be the same as the quantity $E_{G\\theta}^{\\rightarrow}(S_{t+1}^{lkj}, \\dots R_H^{lkj})$ used in the least squares target ?\n\n3) I couldn't follow your reasoning to show that $E_{G\\theta}^{\\rightarrow}(S_{t+1}^{lkj}, \\dots R_H^{lkj})$\n  is linearly realizable. In particular, Corollary 4.11 shows that is realizable for the true guess. However the solution to the Optimization Problem 4.10 is different from the true guess so in this case $E_{G\\theta}^{\\rightarrow}(S_{t+1}^{lkj}, \\dots R_H^{lkj})$ can not be guaranteed to be realizable. Could you please elaborate more on this step in the rebuttal ?\n\n4) Given the reduction from $q^\\pi$-realizable MDPs to Linear MDPs that you discovered in this paper. What would prevent one from applying efficient algorithms for linear MDPs such as LSVI-UCB to solve $q^\\pi$-realizable  MDPs ? Why did you choose to adopt the computationally inefficient Eleanor as base algorithm for solving Linear MDPs while computationally efficient alternatives exist ?""}, 'limitations': {'value': 'The limitations are not well discussed. In particular, I would suggest to add a discussion concerning the computational cost of the algorithm.\n\n**Minor**: typo at line 302 ""th matrix"" -> ""the matrix""'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Online RL in Linearly $q^\\pi$-Realizable MDPs Is as Easy as in Linear MDPs If You Learn What to Ignore'}, 'authors': {'value': ['Gellért Weisz', 'András György', 'Csaba Szepesvari']}, 'authorids': {'value': ['~Gellért_Weisz2', '~András_György2', '~Csaba_Szepesvari1']}, 'keywords': {'value': ['Reinforcement learning', 'linear function approximation', 'online learning']}, 'abstract': {'value': 'We consider online reinforcement learning (RL) in episodic Markov decision processes (MDPs) under the linear $q^\\pi$-realizability assumption, where it is assumed that the action-values of all policies can be  expressed as linear functions of state-action features. This class is known to be more general than  linear MDPs, where the transition kernel and the reward function are assumed to be linear functions of the feature vectors. As our first contribution, we show that the difference between the two classes is the presence of states in linearly $q^\\pi$-realizable MDPs where for any policy, all the actions have  approximately equal values, and skipping over these states by following an arbitrarily fixed policy in those states transforms the problem to a linear MDP. Based on this observation, we derive a novel (computationally inefficient) learning algorithm for linearly $q^\\pi$-realizable MDPs that simultaneously learns what states should be skipped over and runs another learning algorithm on the linear MDP hidden in the problem. The method returns an $\\epsilon$-optimal policy after $\\text{polylog}(H, d)/\\epsilon^2$ interactions with the MDP, where $H$ is the time horizon and $d$ is the dimension of the feature vectors, giving the first polynomial-sample-complexity online RL algorithm for this setting. The results are proved for the misspecified case, where the sample complexity is shown to degrade gracefully with the misspecification error.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/a8b113bfc07bee53bdfd98c3c43077729ede3a5d.pdf'}, '_bibtex': {'value': '@inproceedings{\nweisz2023online,\ntitle={Online {RL} in Linearly \\$q{\\textasciicircum}{\\textbackslash}pi\\$-Realizable {MDP}s Is as Easy as in Linear {MDP}s If You Learn What to Ignore},\nauthor={Gell{\\\'e}rt Weisz and Andr{\\\'a}s Gy{\\""o}rgy and Csaba Szepesvari},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=HV85SiyrsV}\n}'}, 'paperhash': {'value': 'weisz|online_rl_in_linearly_q^\\pirealizable_mdps_is_as_easy_as_in_linear_mdps_if_you_learn_what_to_ignore'}}]"
"['Konstantin Makarychev', 'Liren Shan']",NeurIPS,Random Cuts are Optimal for Explainable k-Medians,https://neurips.cc/virtual/2023/oral/73858,2023," We show that the RandomCoordinateCut algorithm gives the optimal competitive ratio for explainable $k$-medians in $\ell_1$. The problem of explainable $k$-medians was introduced by Dasgupta, Frost, Moshkovitz, and Rashtchian in 2020. Several groups of authors independently proposed a simple polynomial-time randomized algorithm for the problem and showed that this algorithm is $O(\log k \log\log k)$ competitive.  We provide a tight analysis of the algorithm and prove that its competitive ratio is upper bounded by $2\ln k+2$. This bound matches the $\Omega(\log k)$ lower bound by Dasgupta et al (2020).",Oral 6D Theory,https://openreview.net/pdf?id=MFWgLCWgUB,https://openreview.net/forum?id=MFWgLCWgUB,MFWgLCWgUB,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The reviewers greatly appreciated the main contribution of the paper, and there was consensus that this a very strong submission.'}}, {'comment': {'value': 'I thank the authors for their response and maintain my evaluation.'}}, {'comment': {'value': 'Thanks for the responses. I think it is worth adding more discussions according to your answers, especially for point 1. '}}, {'rebuttal': {'value': 'We thank the reviewer for suggesting how we can improve the presentation. We will address all your comments in the final version of the paper.\n\n1. For Theorem 2.2, we do not assume the reference centers are optimal centers for k-medians. We show that for every set of k reference centers, the Random Coordinate Cut finds a threshold tree with the cost at most $2\\ln k+2$ times the unconstrained cost given by the input reference centers. We define the competitive ratio as the ratio between the cost of the decision tree and the cost of the input reference centers. The price of the explainability for k-medians is the ratio of the cost of the decision tree and the optimal unconstrained k-medians cost. To get an $O(\\log k)$ upper bound on the price of explainability, we need to use a constant factor approximation algorithm for k-medians to find the reference centers.\n\n2. Yes. Threshold cuts are sampled uniformly at random.\n\n3. Yes. We will add a discussion about the surprise sets.\n\n4. The Set Elimination Game can potentially be used to analyze other weighted sampling algorithms with non-independent events but we are not aware of any specific examples now.\n'}}, {'rebuttal': {'value': 'Yes, our result can be used for explainable k-means. Makarychev and Shan (2021) provided a cut-preserving terminal embedding from $\\ell_2^2$ to $\\ell_1$ with distortion $O(k)$. Thus, we can first run the terminal embedding and then use the Random Coordinate Cut algorithm on the new instance. Our analysis and also the analysis by Gupta et al. (2023) show that this algorithm achieves $O(k\\log k)$ competitive ratio for explainable k-means. This ratio matches the previous best ratio given by Esfandiari, Mirrokni, and Narayanan (2022). Gupta et al. (2023) proposed a new algorithm that achieves the $O(k \\log\\log k)$ competitive ratio for k-means.'}}, {'rebuttal': {'value': 'First of all, we would like to thank all the reviewers for their valuable feedback. We will address\nall their comments and implement all their suggestions in the final version of the paper. \n\nSeveral reviewers asked us to compare our proof and the proofs obtained independently by Gupta, Pittu, Svensson, and Yuan (2023). Gupta et al (2023) gave two different proofs. In the first, simpler proof, they also used the exponential clock technique. However, this proof is somewhat different from ours. First, it does not consider the set elimination game and instead works directly with cut metrics. Second, it keeps track of the elimination time of set $S_1$ (using our terminology) rather than its hitting time. This makes the technical details a bit different from ours. Their proof gives a slightly better bound than ours (their bound is $(1+o(1))\\ln(k)$, our bound is $2\\ln k +2$). The second more involved proof provided by Gupta, Pittu, Svensson, and Yuan (2023) gives a tight competitive ratio of $1+H_{k-1}$. This proof uses a different approach: It reduces an arbitrary instance of the problem to the “uniform” instance, in which all centers other than the closest center to point x are at the same distance from x.\n'}}, {'summary': {'value': 'This paper considers the Explainable k-Medians problem, which is a more interpretable model for k-clustering than traditional models such as k-median. An explainable clustering partitions space based on coordinate threshold cuts, so that instead of a Voronoi diagram as in k-median / k-means, we end up with rectangular partitions. More specifically, the partitions are determined by a binary decision tree where each node contains a coordinate and a threshold, and the left child corresponds to points that fall below the threshold in that coordinate, and the right child corresponds to points that fall above the threshold in that coordinate. An algorithm is f(k)-competitive for explainable k-median if it produces an explainable clustering that has cost at most f(k) times the cost of the optimal (unconstrainted) k-median clustering. This paper shows that Random Coordinate Cut algorithm (studied by several authors before this paper) has the optimal competitive ratio: specifically, they prove it is (2 \\log k + 2)-competitive--improving on the previously best known bound of O(log log k)--and matching a previously known \\Omega(log k) lower bound. \n\nThe technique is to reduce the problem to a game which the authors call the Set Elimination Game, which is syntactically similar to the Random Coordinate Cut algorithm (and indeed, the authors note that other authors have implicitly analyzed this game). In it, there is some ground set \\Omega and an associated probability measure \\mu, along with a set of subsets. At each round, an element of \\Omega is chosen according to \\mu, and any remaining subset that contains this element is eliminated (unless all remaining subsets contain this element). The last remaining subset is the winner, and the cost of the game is \\mu(winner). The main result, which directly translates to the competitive ratio bound for explainable k-median, is that the expected cost of the game is at most (2 log k + 2) times the cost of any subset. \n\nThe idea behind the analysis is to associate each round with an arrival in a Poisson process, so that they may then view the times at which elements first are chosen in the game as hitting times with exponential distributions.  The hitting times have the nice property that they are independent for different elements. Notably, hitting times single-handedly determine the behavior of the game, so the analysis of the game can be reduced to the analysis of hitting times. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- This paper resolves the question of whether the Random Coordinate Cut algorithm is optimal via a tight analysis. \n\n- The analysis of the Set Elimination Game using Poisson processes is creative and novel (based on my understanding from the related work section, other papers implicitly analyze this game, but the method here is new). It is also quite clean. \n\n- The formulation of the Set Elimination Game and the main result on its expected cost (Theorem 2.1) may be of independent interest. '}, 'weaknesses': {'value': 'The result is slightly weaker (by a factor of 2) than a concurrent result of Gupta, Pittu, Svensson, and Yuan (2023), which gives a bound of 1+H_{k-1}. '}, 'questions': {'value': 'Can any of the methods in this paper potentially be adapted to explainable k-means?'}, 'limitations': {'value': 'Not applicable. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""The paper considers the problem of explainable $k$-medians which was recently introduced by Dasgupta et al, and analyzes the RandomCoordinateCut algorithm. The paper proves an upper bound of $2\\ln k + 2$ on the competitive ratio of RandomCoordinateCut. This matches a previously known lower bound of $\\Omega(\\log k)$, and hence the paper proves that RandomCoordinateCut for explainable $k$-medians is optimal up to constant factors.\n\nEdit: I've read the authors' rebuttals. As I mentioned in my first review, I believe that this is a strong accept paper.""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The paper proves optimality of RandomCoordinateCut for $k$-medians with a remarkably simple and elegant proof. Furthermore, the paper is generally very well written and easy to follow.'}, 'weaknesses': {'value': 'I can\'t see any significant weakness in the paper.\n\nHere are few minor comments/typos:\n- Page 4, line 116: The equation $Pr(\\omega_n = \\omega) = \\mu(\\omega)/\\mu(\\Omega)$  is not strictly formal for spaces that are not discrete.\n- Page 5: In the displayed equation right after line 156, the summation should be over $j$.\n- Page 5, line 185: ""all sets are non-empty and disjoint"" -> ""all sets are non-empty and distinct"".\n- Page 8: In the displayed equation after line 296, I think that in (c) we should also specify that the winner is not $S_1$, because technically $S_1$ does not satisfy the definition of a surprise set.'}, 'questions': {'value': '- Can the authors comment about the proof of Gupta et al. (mentioned on page 4, line 105)? Is it very different from the approach that is presented in the current paper?'}, 'limitations': {'value': 'No concerns regarding potential societal impact of this work.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper provides a tight analysis of the random-coordinate-cut (RCC shortly) algorithm for explainable k-medians in the $ \\ell_1 $ metric. To be precise, the RCC algorithm was independently proposed  by several works, and for the explainable k-medians in $ \\ell_1 $ , the tightest proved competitive ratio is $ O(\\log k \\log\\log k) $, which has a small gap between its lower bound $ \\Omega(\\log k) $. This paper shows that the competitive ratio is no larger than $ 2\\ln k+2 $, thereby concluding that the RCC algorithm is optimal for explainable k-medians.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- This paper completely answers the problem of whether there exists an algorithm with a\xa0competitive ratio\xa0that matches the lower bound $ \\Omega(\\log k) $ for the explainable k-medians problem.  Its contribution is significant and solid. The proofs are simple and elegant.\n- The idea behind the analysis method set elimination game is ingenious. Actually, it effectively summarizes a series of prior works in a concise and abstract manner.'}, 'weaknesses': {'value': 'i don’t find obvious weaknesses'}, 'questions': {'value': '- I have no questions but the independent work of this paper. I am interested in learning more about the comparison between these two works, particularly with regard to the differences in the techniques and high-level ideas underlying them.'}, 'limitations': {'value': 'None'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper studies the optimal upper bound of explainable k-median and shows a tight analysis for the random coordinate cut algorithm. The explainable k-clustering model was first introduced by Dasgupta et al. [ICML’20] and was followed by a flurry of work to understand the optimal approximation factor to achieve explainability. For the k-median task, previous work has shown that an $\\Omega(\\log k)$ factor is necessary, and algorithms that follow a random coordinate cut scheme can achieve $O(\\log k \\cdot \\log\\log k)$-approximation. This paper shows that by picking appropriate distributions, the random coordinate cut can achieve the asymptotically tight approximation of $O(\\log k)$.\n\nAt the heart of the analysis of the paper is a newly-defined *set elimination game* (SEG), where elements are split into multiple (potentially overlapping) sets, and the referee takes an element $e$ at random and eliminates all the sets that contain $e$ unless every remaining set contain $e$. The final value of the game is defined as the measure of the final surviving set. The paper establishes the upper bound for explainable k-median clustering by: 1). showing a ‘’reduction’’ from the cost of explainable k-median of a single point $x$ to the value of the SEG, 2). proving the expected value of the game as $O(\\log k)\\cdot \\mu(S^*)$, where $S^*$ is the set with the smallest measure.\n\nIn my opinion, the paper is generally well-written, and it settles an important question in explainable k-median clustering. The proof idea is novel, and it is presented in a clean manner (minus some minor exposition issues, see the weakness for details). Therefore, I believe the merits of the paper are sufficient for acceptance.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'Explainable clustering has been a popular topic in the recent few years, and the paper settles an open problem in the area. The idea of set elimination games is novel and interesting, and the paper is well-written. The organization helps the reader a lot in understanding the paper.\n'}, 'weaknesses': {'value': 'I do not see any major technical weaknesses in the paper. On the exposition part, I have some minor comments:\n- The paper is written in relatively advanced technical languages, and they might not be readily accessible to the broader NeurIPS audiences. To make the readers’ task easier, I think it makes sense to add some more intuitions on why using the set elimination game, why the value should be small, and the high-level intuitions for the analysis. \n- Conversely, the paper spent little effort discussing why explainability in k-clustering is important and why shaving off the exponentially-small $\\log\\log k$ factor is significant. I would recommend adding some discussion on this front for later versions.\n- Some notation problems. In the proof of Theorem 2.2, there is a slight overload of notation in the construction of $\\Omega$, and $S$: $S$ was used as a *variable* for the sets in the definition of the SEG, but in the proof it becomes the *realization*, i.e., fixed sets. I would recommend using a different notation instead. Also, $x_j$ (which I guess means the j-th coordinate of the point $x$) is used before it is defined.\n'}, 'questions': {'value': ""- You never mentioned the initialization of the reference sets, but judging from the proof of Theorem 2.2, you’re assuming the optimal k-median centers as the reference centers, right? Something like this should be mentioned and discussed.\n- You never mentioned the *distribution* of the random coordinate cut in the paper; from the requirement of Theorem 2.1, it seems uniform at random works. Is this right? You should explicitly define the distribution, either way (‘’pick at random’’ $\\neq$ ‘’pick uniformly at random’’ – the former only means picking something from *a* distribution).\n- What is the intuition for the 'surprising sets'? I can read that the name 'surprising' may come from the fact that for $h(S_1) \\cdot \\mu(S_i) \\geq \\log k$, either $S_1$ should be hit very late or $S_i$ should have a high volume, which means it should have been hit/eliminated way earlier. If this is true, please also add a discussion about it, as it'll help readers understand your proof.\n- Do you see any other applications for the Set Elimination Game?\n""}, 'limitations': {'value': 'The work is of theoretical nature, so the (non-technical) limitations are on the model side, e.g., the explainable clustering model might not provide easy-to-understand explanations in real life. However, I do not think this affects the significance of the contribution.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Random Cuts are Optimal for Explainable k-Medians'}, 'authors': {'value': ['Konstantin Makarychev', 'Liren Shan']}, 'authorids': {'value': ['~Konstantin_Makarychev1', '~Liren_Shan1']}, 'keywords': {'value': ['Clustering', 'k-medians', 'Decision Tree', 'Explainability']}, 'TLDR': {'value': 'We provide the optimal competitive ratio for explainable k-medians.'}, 'abstract': {'value': 'We show that the RandomCoordinateCut algorithm gives the optimal competitive ratio for explainable $k$-medians in $\\ell_1$. The problem of explainable $k$-medians was introduced by Dasgupta, Frost, Moshkovitz, and Rashtchian in 2020. Several groups of authors independently proposed a simple polynomial-time randomized algorithm for the problem and showed that this algorithm is $O(\\log k \\log\\log k)$ competitive.  We provide a tight analysis of the algorithm and prove that its competitive ratio is upper bounded by $2\\ln k+2$. This bound matches the $\\Omega(\\log k)$ lower bound by Dasgupta et al (2020).'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/bb8719116080561461e3e5886e13698302a67ef8.pdf'}, 'supplementary_material': {'value': '/attachment/d8398adbdd7a2d983c92c37af1cd805c47bed1a1.pdf'}, '_bibtex': {'value': '@inproceedings{\nmakarychev2023random,\ntitle={Random Cuts are Optimal for Explainable k-Medians},\nauthor={Konstantin Makarychev and Liren Shan},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=MFWgLCWgUB}\n}'}, 'paperhash': {'value': 'makarychev|random_cuts_are_optimal_for_explainable_kmedians'}}]"
"['Alicia Curth', 'Alan Jeffares', 'Mihaela van der Schaar']",NeurIPS,A U-turn on Double Descent_ Rethinking Parameter Counting in Statistical Learning,https://neurips.cc/virtual/2023/oral/73856,2023," Conventional statistical wisdom established a well-understood relationship between model complexity and prediction error, typically presented as a _U-shaped curve_ reflecting a transition between under- and overfitting regimes. However, motivated by the success of overparametrized neural networks, recent influential work has suggested this theory to be generally incomplete, introducing an additional regime that exhibits a second descent in test error as the parameter count $p$ grows past sample size $n$  -- a  phenomenon dubbed  _double descent_. While most attention has naturally been given to the deep-learning setting, double descent was shown to emerge more generally across non-neural models: known cases include _linear regression, trees, and boosting_. In this work, we take a closer look at the evidence surrounding these more classical statistical machine learning methods and challenge the claim that observed cases of  double descent truly extend the limits of a traditional U-shaped complexity-generalization curve therein. We show that once careful consideration is given to _what is being plotted_ on the x-axes of their double descent plots, it becomes apparent that there are implicitly multiple, distinct complexity axes along which the parameter count grows. We demonstrate that the second descent appears exactly (and _only_) when and where the transition between these underlying axes occurs, and that its location is thus _not_ inherently tied to the interpolation threshold $p=n$. We then gain further insight by adopting a classical nonparametric statistics perspective. We interpret the investigated methods as _smoothers_ and propose a generalized measure for the _effective_ number of parameters they use _on unseen examples_, using which we find that their apparent double descent curves do indeed fold back into more traditional convex shapes -- providing a resolution to the ostensible tension between double descent and traditional statistical intuition.",Oral 1D DL Theory,https://openreview.net/pdf?id=O0Lz8XZT2b,https://openreview.net/forum?id=O0Lz8XZT2b,O0Lz8XZT2b,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The paper provides valuable insights into the paradox of double descent curve. Observations on the double descent curve postulate there is a gap between theoretical uniform convergence rate and practical observations. While multiple studies on this observation, the current paper introduces an innovative perspective aimed at bridging the disparity between theory and practice through the introduction of a more precise understanding of complexity. The paper shows that the phenomenon of double descent arises from the amalgamation of two distinct effects within a single plot, potentially leading to confusion. This outcome underscores the need for future practical and theoretical investigations, with the potential to ultimately resolve the paradox inherent in the double descent curve.'}}, {'comment': {'value': 'Thank you for the detailed response! After reviewing all of your comments, especially those relating to insights about the richer bases and about the effective parameter count, as well as promises to add more contextualization and lit review, I am willing to bump up my score to a 7.'}}, {'comment': {'value': 'Thanks for the detailed response! I remain recommending acceptance for this paper.'}}, {'comment': {'value': 'Thank you for your great and instructive answers. I am reassured about most of the points that I raised. I think the authors provided satisfactory explanations. It would be great if the authors could provide these discussions (especially on W2, W3, W4) in the main text once they are allowed to do so. I have decided to raise my score to 7 since after seeing the answers the paper seems to be a clear accept for me. '}}, {'title': {'value': 'Reviewer response'}, 'comment': {'value': 'I thank the authors for their rebuttal and have decided to raise my score to 7. I still believe the authors should contextualize their claims more early on in the paper to note the known results for ridge regression.'}}, {'comment': {'value': 'I thank the authors for their response. I have decided to raise my score to a 7.'}}, {'rebuttal': {'value': 'We thank the reviewer for the thoughtful review -- we are delighted by the positive assessment of our presentation, complexity reparametrization and effective parameter measure! We hope to resolve doubts about any weaknesses in our point-by-point response below.\n\n**Inclusion of boosting and trees.** We are delighted by the deep interest in our results on the linear regression case study and effective parameters, and certainly agree that they might be of most individual interest to the community. Nonetheless, allow us to attempt to convince you why we consider the case studies on trees and boosting an important part of our paper. The goal of our work was to study the appearance of double descent outside of deep learning generally, motivated by [BHMM19] who suggest they “provide evidence for the existence and _ubiquity of double descent for a wide spectrum of models_” (abstract). The experiments that we replicate were said to “give empirical evidence that the families of functions explored by boosting with decision trees and random forests also show similar generalization behavior to that of neural nets” (p.4) – this constitutes the only example of non-deep double descent except for linear regression that we are aware of, which is why we consider these results important to include. We certainly agree that the experimental setup is a lot less natural than the regression case study – in fact, this is precisely what inspired our paper in the first place: our investigation of the tree-based experiments (where the two-axes decomposition may be intuitively apparent to some readers) is what motivated our search for orthogonal parameter axes in the linear regression case (leading us to distinguish between PC and excess features), and we thus consider it an important pre-requisite for our deeper analyses. \n\n**Experimental settings.** The goal of our work was to reanalyse and provide explanations for the existing evidence for non-deep double descent -- of which BHMM19 (and the datasets within) provided the broadest account. Therefore, following closely the experimental setup in their paper was a key design choice for our work, as this focus allowed us to really zoom-in and provide in-depth analyses of the original experiments and findings.However, we are happy to provide results on an additional non-image, real-world dataset of different modality for this reviewer (also, note that replication of our complete analyses using some additional datasets were already included in our App E.6). To do so we selected MiniBooNE, a dataset from the particle physics community in the Fermilab in which 50 features represent a stream of muon neutrinos that are fired and recorded by a detector which measures the presence of electron neutrinos (signal) among the muon neutrinos (noise). The goal is to classify observations as signal or background noise. This task has been recently recognised as a recommended benchmark task in researching machine learning methods for unstructured data [1].\n\nWe process the data just as in the other experiments and repeat the analysis for the RFF-regression. The results are included in the attached PDF in the top level rebuttal where we observe the same double descent effect along the raw axes, which, when using our proposed measure of effective parameters, again reduces into a familiar U-shaped complexity curve consistent with our previous experiments.\n\n[1] Grinsztajn, Léo, Edouard Oyallon, and Gaël Varoquaux. ""Why do tree-based models still outperform deep learning on typical tabular data?."" Advances in Neural Information Processing Systems 35 (2022): 507-520\n\n\n**Connections to the ridge regression results of HMRT22** The results in our work are entirely consistent with and complimentary to those of [HMRT22]. This is particularly highlighted in their Fig. 1 where they find the usual double descent shape in (ridgeless) min-norm regression but _no double descent_ in optimally tuned ridge regression (i.e. where the regularization strength is selected to optimize validation performance). Interestingly, at $\\gamma = 1$, where the number of features is equal to the number of examples, standard analysis based on just parameter counts would suggest performance should be poor. This is because, as shown in our work, this is typically where _effective parameters_ are highest. However, this is counteracted by optimally tuned ridge regression which would automatically select for higher regularization at this point and therefore reduces the implied effective parameters – thus removing the double descent behaviour entirely. This is an excellent illustration of the importance of measuring _effective parameters_ over raw parameters as advocated for in our work. We therefore thank the reviewer for suggesting that our section on extended related work in appendix A could be expanded even further; we will include additional discussions of the connections between ridge regression and PCR as well as a discussion of work on regularization in the context of the double descent phenomenon!\n\n**Further discussion of MBW20, DLM20, and DSYW20.**  We will include an additional discussion of the effective parameter measures used by DLM20, and DSYW20 into Appendix D, where we already discuss MBW20’s measure in more detail.\n'}}, {'rebuttal': {'value': 'We thank the reviewer for the thoughtful review -- we are delighted by the positive assessment of our presentation, relevance and our insights into the linear regression case study!\n\n**Connections to Neural Networks.** We completely agree that – as discussed in l. 356ff. – understanding double descent in neural networks is a natural and very interesting next step – which we consider highly nontrivial, and to hence fall beyond the scope of this paper. In addition to the possible connections already stated in our conclusion, we believe that one very interesting and promising starting point for extending our work to the neural network setting is to use our approaches for understanding double descent in linear models and apply them to neural networks trained  in the _lazy regime_ (see e.g. ‘On Lazy Training in Differentiable Programming’, Chizat et al, NeurIPS19), which essentially act like models that are linear in features defined through the gradients of the model at initialisation. Nonetheless, allow us to emphasize that we strongly believe that understanding double descent in simpler models (e.g. smoothers), as we do in this paper,  is of value to the community as is – both in its own right _and_ to provide a foundation for follow up work to understand this phenomenon in more complex models – exemplified also by the numerous papers published recently studying double descent in linear models exclusively.\n\n**How does our linear regression explanation extend to BLLT20 and HMRT22?** Where BLLT20 and HMRT22 also study min-norm linear regressions, our basic arguments naturally apply: Also in their studies, due to the use of the min-norm solution,  there is an implicit change in the parameter-increasing mechanism at p=n and thus once p>n, the number of truly determined directions remains constant at n and $p^{train}_s=n$ by construction. While $p^{train}_s$ is easy to determine as it is independent of the problem characteristics and simply equal to min(n,p),  $p^{test}_s$ depends on the data characteristics thus studying theoretically how this would evolve would likely involve different assumptions on the data-generating mechanism. Studying the interaction between our work and specific data generating process would definitely be an interesting avenue for future work!\n'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the very interesting, in-depth and constructive review! We are delighted by the reviewer’s overwhelmingly positive review of our paper, in particular the assessment that “it will have a high impact and is relevant for many researchers”! We also put much effort into making the paper intuitive and easy to follow, and are especially excited to hear that this was appreciated. (Responding to the aside, we were also very interested in the reviewer’s own experience with applying other measures of complexity to this problem, and in this light especially thrilled by the review’s favourable assessment of our own approach!).\n\nFinally, we are grateful for the additional references included in the review –  we will include these in the updated version of  the extended literature review in Appendix A.  \n\nWith regards to the question on providing bounds for generalization using our effective parameter measure, we completely agree with the reviewer that this will be a very natural -- albeit challenging -- next step that will drive further, more crisp, understanding of the effect of effective parameters on generalization. It is not something we have investigated deeply so far, as we were focussed on finding an intuitive and empirical resolution to the double descent phenomenon, but we hope that it may be possible to borrow further insights from the vast literature on smoothing to make progress in this direction in the future!'}}, {'rebuttal': {'value': ""We thank the reviewer for the thoughtful review -- we are very delighted by the very positive assessment of our work! Below, we respond to the points raised in the review in turn.\n\n**The need to evaluate effective parameters on test samples.** We appreciate this reviewer raising this point as we believe this to be, in fact, a key strength of our work. Specifically, we would like to highlight that, as shown in Fig. 6, we _can_ compute our metric on the training examples too -- but observed this measurement of effective parameters without consideration of the test input distribution to be insufficient to explain generalization performance and were therefore motivated to address this limitation in our calculation of effective parameters. This becomes apparent when we compare to the measure in [MBW20] as suggested. Note that [MBW20]'s metric is motivated from a Bayesian setting where one uses a prior with parameter $\\alpha>0$ (corresponding to ridge regularization in a frequentist setting), while we consider unregularized regression. If we let $\\alpha$ approach 0, their effective parameter measure $\\sum\\_{i=1}^p \\lambda\\_i/(\\lambda\\_i+\\alpha)$, where $\\lambda\\_i$ are the eigenvalues of X'X (computed using training examples), approaches $\\sum\\_{i=1}^p 1[\\lambda\\_i>0] = rank(X'X) = min(n, p)$ which is exactly equal to what we measure with $p^{train}_s$ for linear regression -- and hence constant once p>n. Therefore, like the case of applying our metric to the training data (as shown in Fig 6), this metric would fail to capture the decrease in complexity during the second descent. This highlights precisely the _strength_ of our metric being that it _can_ also be applied to test data (note: this is without requiring access to labels).  Only through this application to test data, as discussed on L262-281, we may better extend beyond the fixed design setting into the modern machine learning regime where we are primarily interested in generalization to _unseen_ covariates.\n\n**Do these two types of axes exist for all types of models?** While we intentionally focused here on the three specific methods under investigation, we would certainly consider it an interesting and fruitful direction for future research to understand whether other ML methods also have a similar distinction into parameter axes along which generalisation performance evolves in particular patterns! Our results provide anecdotal evidence that the first parameter axes may be responsible for bias reduction – it controls how well the training data can be fit –, while the second parameter axes drive variance reduction for test-time predictions; studying how other methods fit into this intuition would certainly be an interesting next step!\n\n**How does the proposed measurement fit into unsupervised learning?** Although model complexity is typically primarily considered in the supervised setting, notions of model complexity are certainly valuable in the unsupervised setting too. Since the smoother matrix upon which we measure effective parameters is a transformation from ground truth labels to predictions one might similarly consider the unsupervised setting in which we have a transformation from input space into some (usually compressed) representation. A simple example might be the family of principal component analysis methods. Another interesting case for consideration might be semi-supervised learning in which we have access to some unlabelled data which clearly aligns with our measure. While further exploration of these settings is clearly outside the scope of this paper, considering how one might transfer the results from this and other similar works beyond the supervised setting would certainly make for an interesting research direction. \n\n\n""}}, {'rebuttal': {'value': 'We would like to once more thank all reviewers for their time and effort put into the review process -- we thoroughly enjoyed reading the interesting and constructive reviews we received. We were delighted by the overwhelmingly positive response to our paper, and are thrilled that all 6 reviewers agreed that our study of the double descent phenomenon will be of interest to the NeurIPS community! We also received numerous stimulating questions (extending far beyond what we could hope to answer within the scope of a single conference paper) and hope that future work will follow up on many of interesting directions highlighted in the reviews!\n\nBelow, we provide some responses to questions raised by multiple reviewers, and have also attached additional figures that -- as requested -- display the relationship between the two raw axes and effective parameter axes across the different methods (Figs 1 and 2) and experiments using an additional dataset of different modality (Fig 3).\n\n**How could we extend this work to neural networks?** (Reviewers  Uot3, tnvy) In addition to the possible connections already stated in our conclusion  l. 356ff., we believe that one very interesting and promising starting point for extending our work to the neural network setting would be to use our approaches for understanding double descent in smoothing models  and apply them to neural networks trained  in the _lazy regime_ (see e.g. ‘On Lazy Training in Differentiable Programming’, Chizat et al, NeurIPS19), as these networks essentially act like models that are linear in features defined through the gradients of the model at initialisation -- to these linearised networks some of our arguments from the linear regression case study may extend very naturally. \n\n**What is the relationship between the two raw parameter axes and effective parameter count?**  (Reviewers WN4r, tnvy) In the attached Figs. 1&2, we find that along the respective first axes ($P^{leaf}, P^{boost}, P^{PCA}$) effective parameters monotonically increase while along the second axes ($P^{ens}, P^{ex}$), effective parameters monotonically decrease. Thus, this further confirms that (as we had stated in l. 317) the second axis acts by ‘decreasing the effective complexity implied by each value’ along the first axis). We agree that these results provide interesting evidence that compliments Figs 6 & 7 – and will include some of the insights into the updated manuscript once the additional content page becomes available!\n\n**How exactly does adding more $P^{ex}$ improve model performance?** (Reviewers WN4r, tnvy) We agree that this is a very interesting (and nontrivial!) question, whose answer may extend beyond the scope of our original investigation. Below, we discuss our current understanding, but think that exploring this question further would constitute a fruitful direction for future work. \n\nReviewer tnvy raised this question while noting that ""all the information necessary to predict y should already be encoded in X"" and that thus representing it with an increasing number of features (regardless of the conditioning of some matrix) would not seem to explain the improvement in performance. To intuitively address this point, we note that, for example, once p>n, adding additional features indeed does not add any new information for predicting the observed (training inputs) y. Yet, in such underspecified settings, different representations that make the same predictions on training inputs can lead to wildly different generalisation performance to new inputs– despite being indistinguishable on the training data. A basis construction step thus essentially serves to choose between models that all explain y equally well (and hence cannot be distinguished based on supervised loss), akin to an unsupervised pre-processing step. The _implicit inductive bias_ encoded in the step we uncover essentially consists of constructing and choosing the top-$P^{PCA}$ features that _capture the directions of maximum variation_ in the data. \n\nWithin this inductive bias, the role of $P^{ex}$ appears to be that -- as more excess features are added -- the variation $\\lambda_p$ captured by each of the top-$P^{PCA}$ principal components is likely to increase (which we indeed see empirically in Appendix B.3). This increase in the $\\lambda_p$ in turn is likely to _decrease_ the variance of the regression predictions on unseen inputs because $Var(\\hat{y}) = Var(s(x\\_0)y)=\\sigma^2\\sum^{P^{PCA}}\\_{p=1} b^2\\_p(x\\_0)/\\lambda\\_p$ (where $b(x_0)=(b_1(x_0), ..., b_{P^{PCA}}(x_0))$ is the representation of the input point using the PCs) can explode on the unseen testing inputs when previously unseen large values $b^2\\_p(x\\_0)$ occur along the low-variance directions with very small $\\lambda\\_p$ at test time (which is exactly what we observe in our experiments).\n\nStill, using the directions of maximum variation is certainly not guaranteed to be optimal in all applications (Jolliffe, ""A note on the use of principal components in regression."",  1982) but it tends to be an effective inductive bias in practice as noted in Tukey (“ Exploratory data analysis.”, 1977) who suggested that the high variance components are likely to be more important for prediction unless nature is ""downright mean"". However, note that we do not intend to make a claim that increasing $P^{ex}$ is always effective – rather, we are simply uncovering that this appears to be the underlying effect in the RFF experiments.\n\n'}, 'pdf': {'value': '/pdf/e0cb77571dbcd37d1cc769aaf8f39b796f367284.pdf'}}, {'rebuttal': {'value': 'We thank the reviewer for the in-depth and constructive review! We were delighted by the assessment that our paper is ""interesting"", ""well-presented "" and ""likely to encourage follow-on work in the field"", and, limited by space constraints, hope to resolve doubts about any weaknesses in our response below!\n\n**Inclusion of boosting and trees.** We are delighted by the deep interest in our results on the linear regression case study! We agree that these may be of most individual interest to the community and will use the additional space in the updated manuscript to prioritise moving some of the additional linear regression results from the appendix to the main text. Nonetheless, allow us to attempt to convince you why we consider the case studies on trees and boosting an important part of our paper. The goal of our work was to study the appearance of double descent outside of deep learning generally, motivated by [BHMM19] who suggest they “provide evidence for the existence and _ubiquity of double descent for a wide spectrum of models_” (abstract). The experiments that we replicate were said to “give empirical evidence that the families of functions explored by boosting with decision trees and random forests also show similar generalization behavior to that of neural nets” (p.4) – this constitutes the only example of non-deep double descent except for linear regression that we are aware of, which is why we consider these results important to include. We certainly agree that the experimental setup is a lot less natural than the regression case study – in fact, this is precisely what inspired our paper in the first place: our investigation of the tree-based experiments (where the two-axes decomposition may be intuitively apparent to some readers) is what motivated our search for orthogonal parameter axes in the linear regression case (leading us to distinguish between PC- and excess features), and we thus also consider this part an important pre-requisite for our deeper analyses. \n\n**Connections between min-norm solutions, SVD, and PCA.** We did not intend to imply that we are the first to notice a connection between these concepts; rather, we indeed consider our application of these insights to the double descent context our main novelty. However, to the best of our knowledge, the specific result derived in Prop 1 has not previously been formalized in this way in the literature and provided an essential tool for our analysis in Sec. 3. We have added a line to our discussion of these topics further emphasising this point.  \n\n**Additional analyses of raw and effective parameter count.** We thank the reviewer for the suggestion to include further analyses of the raw parameter axes and the effective parameter count, as we agree that this provides interesting new insights into the behaviour of the ML methods. In particular, per the reviewer\'s request, we created figures plotting the effective parameters against the two separate parameter axes (see Figures attached to general rebuttal), which allows to make even more clear the role of the two parameter axes: along the first axes, effective parameters monotonically increase while along the second axes, effective parameters monotonically decrease. Thus, this further confirms that (as we had stated in l. 317) the second axis acts by ‘decreasing the effective complexity implied by each value’ along the first axis).  We agree that these results provide evidence that compliments Figs 6 & 7  – and will include some of the insights into the updated manuscript once the additional content page becomes available!\n\n**Understanding basis quality implied by $P^{ex}$.** Please refer to the general rebuttal, where we answer this for multiple reviewers! \n\n**Additional connections to related work.** We thank the reviewer for suggesting that our section on extended related work in appendix A could be expanded even further; we will include additional discussions of the connections between ridge regression and PCR as well as a discussion of work on regularization and the double descent phenomenon! We will also expand upon the connections between neural networks and our work. \n\n\n\n\n'}}, {'rebuttal': {'value': 'We thank the reviewer for the very interesting, in-depth and constructive review! We were delighted by the assessment that Part 1 of our paper was ""novel, surprising, important , interesting, neat and probably impactful"" and, limited by space constraints, hope to resolve more pressing doubts about Part 2 in our response below.\n\n**Novelty of part 2 (W1).** We certainly agree that – as discussed in the related work section – we are not the first to use alternative ways of measuring model complexity to study double descent (DD) in general. Nonetheless, the approach we take in our paper is very different from existing work, resulting in significant novelty also in this section: in particular a) we are able to quantify and understand the effective parameters used by _different classes of methods_ than existing work, while making new connections to the literature on smoothing, b) we are the first to study and discover differences in the used effective parameters at training and testing inputs, and c) are able to uncover the ‘stacked U-curve’ phenomenon in Figure 7 (which, to the best of our knowledge, has not previously appeared in any related work) only _because our decompositions from part 1 revealed the two-axis nature of the original experiments_.\n\n**Comparison to [MBW20] (W1).** First, allow us to emphasize that we strongly believe our work to be _complementary_ to  [MBW20]: while their approach cannot natively handle models trained without explicit loss function, our $p^0_s$ may indeed seem less _naturally_ applicable to study neural networks (*see also the top-level rebuttal for more on neural nets!) – thus, depending on the use-case of interest, either may be more appropriate to use.  Second, regarding (W1, ii) we would like to highlight that a need to look beyond train-time effective parameters to understand DD can also arise when using [MBW20]’s approach.  To see this, note that linear regression is the only method considered in both our and [MBW20]’s paper; however, while we consider _unregularized_ regression like BHMM19, [MBW20]’s metric is really only well-motivated when one uses a prior with hyperparameter $\\alpha > 0$ (i.e. corresponding to inclusion of a ridge penalty in a frequentist setting). If we let $\\alpha$ -> 0, their effective parameter measure $\\sum_{i=1}^p \\lambda_i/(\\lambda_i+\\alpha)$ approaches $\\sum_{i=1}^p 1[\\lambda_i>0] = rank(X’X) = min(n, p)$ which is exactly equal to our $p^{train}_s$ for linear regression and hence constant once $p>n$. For the unregularized linear regression case, their approach therefore cannot explain DD and a train-test distinction is also necessary here. Finally, regarding (W1, iii) we agree with the review – [MBW20]’s measure does not require access to test time labels and we did not intend to imply that it does. We would like to clarify that the statement in l. 377  refers to selection criteria based on held-out loss (e.g. cross-validation) as discussed in l. 374 (and not [MBW20]’s work discussed earlier in the paper).\n\n**Understanding why $p^{test}_s$ drops along axis 2 (W2).** For tree-based methods, this is easiest to see: Intuitively, $||s(x_0)||^2$ here measures the non-uniformity in weight given to each training target when issuing predictions. In a single tree grown to full depth, each test example will fall into a leaf with a single training example – which has the maximum number of effective parameters. However, when ensembling multiple such trees, for test inputs $x_0$ in underdetermined regions of the feature space, weight is likely to be spread more uniformly as different random splits place $x_0$ in leaves with different training examples across the different trees in an ensemble. While a single tree acts like a 1-NN regressor, an ensemble of multiple trees can thus act more like a k-NN regressor (with k>1) for unseen inputs. For the regression case, note that – for a basis B constructed through PCA, we have that $||s(x\\_0)||^2=||b(x\\_0)(B’B)^{-1}B’||^2=b(x\\_0)(B’B)^{-1}b’(x\\_0)=\\sum^{P^{PCA}}\\_{p=1} b^2\\_p(x\\_0)/\\lambda\\_p$ as B has orthogonal columns and for each column $B\\_p’B\\_p=\\lambda_p$ (where $\\lambda_p$ is the pth eigenvalue of  $\\Phi’\\Phi$) by construction. On the training data, we have that, as expected, $\\sum^n\\_{i=1}||s(x\\_i)||^2=\\sum^n\\_{i=1}\\sum^{P^{PCA}\\}_{p=1} b^2\\_p(x\\_i)/\\lambda\\_p = P^{PCA}$ as $\\lambda\\_p$ is also the empirical variance of the PCs ($\\lambda\\_p=n^{-1} \\sum^n\\_{i=1} b^2\\_p(x\\_i)$). However, on the unseen testing inputs, it is possible that previously unobserved large values along the low-variance directions with very small $\\lambda_p$ will lead to terms that blow up the $s(x_0)$ immensely (which is exactly what we observe in our experiments). Thus, $||s(x_0)||^2$ for new inputs likely shrinks as the variances $\\lambda_p$ of the included PCs grow – which – as we see empirically in Appendix B3 – happens as we increase $P^{ex}$ for fixed $P^{PCA}$. As suggested, we also included a plot of $p^{test}_s$ by $P^{ex}$ and $P^{PCA}$ separately (see the general rebuttal).  While our primary interest lies in understanding the DD phenomenon, we agree that interesting insights about the methods themselves can be gained through study of $p^{test}_s$ -- and will include some of the above into the updated manuscript, thank you for the suggestion!  \n\n**Why would adding more $P^{ex}$ improve model performance? (W3)** Please refer to the general rebuttal, where we answer this for multiple reviewers!\n\n**Non-symmetry between axes (W4).** Our results provide some anecdotal evidence that the first axis can be best understood as a bias-reduction axis – it controls how well the training data can be fit (increasing its parameters reduces underfitting – only when the first axis is set to its maximum can interpolation be achieved). The second axis appears to predominantly achieve variance-reduction _at test-time_: it reduces ||s(x_0)||, reducing the impact of label noise by smoothing over more training examples.'}}, {'summary': {'value': 'The paper analyzes the seeming appearance of double descent in non-deep models, and finds various ways in which it disappears when thinking more carefully about how the parameters are scaled. Trees and boosted models see double descent because parameters start increasing along a different and more effective dimension (ensemble size) once p=n. Linear regression sees double descent because the min-norm optimization solution used in prior work functions differently before and after p=n. And all of these methods no longer see double descent when the ""effective number of parameters"" is used as the x-axis instead of the raw number of parameters.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'I greatly enjoyed reading the paper. The findings on linear regression are very interesting and contribute towards the understanding of the important phenomenon of double descent. It is well-presented, with concise and easy-to-understand figures and clear writing. It is likely to encourage follow-on work in the field.'}, 'weaknesses': {'value': 'The portions on trees/boosting and linear regression sit a bit unevenly together. In my view, the trees/boosting section doesn\'t actually tell us much about double descent since we\'re talking about independently trained ensembles, which is a different issue altogether. Meanwhile, the linear regression bit is very interesting.\n\nThe connections between min-norm solutions, SVD, and PCA (and the Moore-Pensrose pseudoinverse) are reasonably well understood (see e.g. these class notes http://www.sci.utah.edu/~gerig/CS6640-F2012/Materials/pseudoinverse-cis61009sl10.pdf), so I\'d question the novelty of the theory a bit. However, the application of the theory to understand the problem was excellent.\n\nThe section on effective number of parameters didn\'t spend enough time analyzing the relationship between raw parameter count and effective parameter count (and any implications thereof), which seems worth dwelling a bit from the purpose of understanding double descent (more so than showing the lack of double descent using that metric as the x-axis).\n\nI think the paper would be improved with more connections to related work and related ideas, e.g. regularization and particularly ridge regression (due to its connections with PCA), work on multi-layer linear networks and PCA (e.g. Baldi and Hornik 1988, ""Neural Networks and Principal Component Analysis: Learning from Examples Without Local Minima), connections between neural network optimization and min-norm solutions (which you do give a brief mention to, but seems quite relevant)'}, 'questions': {'value': 'I like the paper and applaud your work, but as a take-it-or-leave-it suggestion I would consider whether a reframing around your core contributions (insights about overparameterized linear regression) vs. being a rebuttal to another paper (forces simple and less interesting critiques about ensembles to take up space) would help. There\'s interesting stuff in the appendix (e.g. condition number analyses of bases) that could certainly fit in the main paper if you end up going that route.\n\nOne major question on my mind after reading this paper is what it ""means"" to find a richer basis among the input features and why that helps. Do you have any insights on this? Are there applications to preconditioning? How closely tied is it to the choice of RFF features, vs. alternate setups where e.g. there are p>n features by default?\n\nPer the \'weakness\' above, can you add the relationship/analysis of raw parameter count and effective parameter count?'}, 'limitations': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper studies the double descent phenomenon focusing on the complexity axis used to display the phenomenon. For trees and boosting, they show that double descent is a result of peculiar axes used by one previous work and that an alternative formulation of complexity removes the phenomenon. They then propose a generalized measure for the effective number of parameters for both trees, boosting, and lienar models which recovers a more classical U-shape.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The paper is clearly written\n- The reparameterization of complexity for trees and boosting is clear and needed + for linear models is well-motivated\n- The introduced generalized effective number of parameters based on smoothers is interesting and seems to work well'}, 'weaknesses': {'value': '- The evidence for double descent in trees is very limited and weak (one main figure and one appendix figure in BHMM19); the authors may want to dedicate more time to the rest of the paper rather than refuting this phenomenon\n- The experimental settings shown are very limited, would be nice to see less synthetic settings, particularly in Fig 7 to see how well the proposed complexity measure holds\n'}, 'questions': {'value': '- A deeper comparison with related work would be helpful, particularly MBW20, DLM20, and DSYW20.\n- The authors should connect their analysis in Section 3 based on principal components  with the more popular analyses using ridge regression rather than limiting PCs (e.g. that in HMRT22). The empirical observations are extremely similar and the connection is fairly close, as ridge regression can (often) be seen as a smooth eversion of PCA regression.\n'}, 'limitations': {'value': '- See above'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper studies the double descent phenomenon where it has been suggested that optimal generalization performance is achieved as model complexity gets extremely large and training data is perfectly overfit. However, this work suggests that true model complexity is not described simply by the number of parameters. This claim is backed by replications of experiments from a foundational double descent paper, where the main result is empirical evidence and a theoretical explanation on how linear regression in high dimension reduces to a lower dimension problem on principle component features. Lastly, the authors propose a way to measure the number of effective parameters for each replicated experiment.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The paper is well-written and the motivation for the work is well-defined\n- Proposition 1 is an interesting and novel observation and its proof is rigorous from what I can tell\n- The area of overparameterized machine learning is of very high relevance today'}, 'weaknesses': {'value': 'An obvious weakness of the paper is that it does not use modern neural network models. I recognize that work on linear models is necessary as a foundation and the authors do discuss this limitation in the discussion, however it is troubling that there is no proper justification/commentary on the connection between the work and modern architectures.'}, 'questions': {'value': ""I'm curious how well your linear regression explanation extends to other statistical models like in BLLT20 and HMRT22.""}, 'limitations': {'value': 'The authors adequately address the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes a new perspective for understanding the double descent behavior in non deep learning models: Once the number of raw parameters goes pass the interpolation threshold, the effective parameter number actually stops increasing and if one keeps increasing the number of parameters, the underlying model class will be modified. The authors analyze three examples from existing literature: Decision tree, gradient boosting and linear regression. In particular, the authors perform a novel analysis on overparameterized linear regression shows that the increment of Fourier feature dimensions would first increase the number of PCA regression dimensions, which follows the classic U curve structure, and then increase the number of excess feature dimension, which results in a L shape of test error. However, studying the effective dimension size requires model-specific derivation, therefore the author proposes a unified framework for studying the effective parameter size in different models using techniques from smoothers. With, the proposed measurement as the x-axis, the double descent shape on y-axis disappears, which aligns with the experiment results for individual models.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The paper is well written and well motivated.\n\n- The analysis and proposed measurement of effective number of parameter is technically sound.\n\n- The relationship with existing literature is thoroughly discussed.'}, 'weaknesses': {'value': '- If I understand correctly, the proposed measurement needs to be computed using test samples, which is not as straightforward as other metrics that only requires training sample, e.g. the measurement proposed in [MBW20].'}, 'questions': {'value': '- The authors show that for decision tree, gradient boosting, and linear regression, there exists an axis in model complexity which follows ""bigger is better"". Does this axis exist for all types of models?\n\n- How does the proposed measurement fit into unsupervised learning models where there does not exist `y` in the task.'}, 'limitations': {'value': 'See Weaknesses'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper critically looks at the double descent phenomena, and it is shown that the number of parameters on the x-axis does not represent the complexity well for double descent curves, and in essence, causes the double descent. If a more appropriate complexity measure is adopted, in this paper, the effective number of parameters, the phenomena disappears, and we observe a typical U-shape or L-shape, as expected from learning theory. \n\nNote: I did not have time to study the appendix in detail. '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'This paper addresses and resolves some paradoxes in the community surrounding the double descent phenenoma. As such, I believe it will have a high impact and is relevant for many researchers. Furthermore, the introduced complexity measure can be highly relevant for model selection tasks. \n\nThe analysis is straightforward and complete. Especially nice is that it revisits the original experiments of Belkin exactly and finds the root-causes of the behavior. \n\nThe figures are clear and intuitive, especially the color-coding with blue and red curves is very helpful to our understanding.\n\nThe analysis of linear regression seems to agree with some very early analysis by \nS. Raudys and R. Duin, “Expected classification error of the\nFisher linear classifier with pseudo-inverse covariance matrix,”\nPattern Recognit. Lett., vol. 19, no. 5-6, pp. 385–392, 1998\nwho noted that dimensionality reduction indeed plays the suggested role. A more recent work that covers this is:\nJ. H. Krijthe and M. Loog, “The peaking phenomenon in semisupervised learning,” in S+SSPR. Springer, 2016, pp. 299–309\nwhich can be slightly easier to read. However, the presentation in the current paper is much more clear and also covers the boosting and random forest experiments, while these papers only cover linear regression.\n\nMore connections and background on the double descent phenomena can be found in:\nViering, T., & Loog, M. (2022). The shape of learning curves: a review. IEEE Transactions on Pattern Analysis and Machine Intelligence.\nFor example, double descent can either be visible in learning curves or feature curves, a connection that is often overlooked. \n\nNote that, historically, the double descent behavior was studied inbetween 1990 and 2019 (as also apparent from above), but that this was in a subcommunity that was not popular. \n\nAs an aside, we have attempted a similar analysis as the one given in the paper via VC bounds and other similar measures for regression, but they generally are not fine grained enough for the analysis required. I am very happy the authors did manage to unmask the paradox via the proposed complexity measure. '}, 'weaknesses': {'value': 'none'}, 'questions': {'value': 'Are there any connections with the proposed metric of Generalized Effective Number of parameters and generalization? E.g. are there any upperbounds on the generalization that can be given in terms of the proposed measure? That would be an added strength\n\n'}, 'limitations': {'value': 'none'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper aims to explain the well-known phenomenon of double-descent in the scope of several traditional ML methods (random forests, boosting and linear regression on random Fourier features). The main message of the paper (in the mentioned scope) is that what appears to be a double-descent on the first sight (using plots that count raw number of model parameters), might actually be a consequence of an intristincly two-dimensional parameter development composed of two traditionally behaved, complementary components. In all the studied cases, authors disentangle the parameter count into two parts - one accounting for a complexity of ""a single model within the considered class"", while the second accounting for something, that one could call ""extent of statistical power in terms of some proxy of mixture of experts, or ensembles"". The authors show that once the parameters are counted in this two-dimensional manner, the double-descent curve folds into two curves, of which one usually exhibits traditional U-shape and the other one exhibits an L-shape. For linear regression, authors consider a non-trivial disentanglement - into the number of basis vectors that are directly used for regression and the number of exceeding features. \n\nIn an independent part, authors consider models that fall into the category of smoothers (kNN, trees and forests, LR) and show that if one counts parameters in a more sensible way (in the paper via a specific, smoothers-tailored effective number of parameters measure), one can not even register a double-descent behavior anymore. The authors show that the test performance can be partially explained via the effective number of parameters (though it seems the number of ensembles/extra features should be taken into account too). '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""S1: The idea of decomposing the parameter count into two independent dimensions which unfold (and therefore partially explain) the well-known double-descent is (I believe) novel, surprising, important (at least within the scope of the studied models), interesting, neat and probably impactful. The analysis done for the models considered is strong, empirical evidence convincing and theoretical analysis for RFF-LR makes sense. The experiments in this section are well-chosen and well-done and to the point. \n\nS2: As a part of the paper's exposition, another very important observation is made (around lines 192-195) - the double descent, being a consequence of different mechanisms (explained in the paper), is not strictly tight to the point where the model capacity enters the interpolation regime. We can obtain similar double-descent curves with breaking points far below the interpolation threshold.\n\nS3: The quality of writing and the overall clarity and structure of the paper are well-above the average. \n\n""}, 'weaknesses': {'value': 'The weaknesses are roughly sorted by severity, starting with the most severe. \n\nW1: The whole part 2 of the paper - explaining the double descent with alternative parameter counting - is not novel, as acknowledged by the authors. The idea of the double-descent appearing to happen only if raw parameters are displayed, but disappearing, or being more explainable, if effective number of parameters measure is used instead, is already done in several works cited by the paper. The authors defend the originality and novelty of this part and of the used effective parameter count as a tool for explaining double descent, within the scope of smoothers, by claiming that (i) unlike some of the previous work, it covers model classes that use trees and (ii) the proposed distinction between train and test time parameter count is essential to explaining the double-descent and (iii) the proposed parameter count does not require test-time labels, unlike the previous methods. However: (i) while this is true, the disadvantage is that this method is only usable for smoothers, and therefore it is very unclear how this can be used for, for instance, neural networks (unlike the measures used in the cited literature), which limits not only the scope of this part, but also, more importantly, the potential impact of this part. On the other hand, (ii) seems not to be well-reasoned. While it is true that for this particular measure and for smoothers and in-sample double-descent this seems to be the case, other complexity measures, such as the one considered in [1], but also those that [1] compares itself against, seem perfectly capable of explaining double-descent (for most of the models excluding trees) without this train-test distinction. Finally, (iii) seems not to even be true, as the method considered in [1] and the ones cited by [1] do not require the held-out / test data at all. \n\nW2: Related to W1, the authors do not explain at all why the effective parameter count drops so significantly if we increase the number of ensembles/exceeding features (i.e. the secondary parameter count dimension). Perhaps it is not in the scope of the paper, but I would find it a significant strengthening of the paper, if this was included. In fact, the authors don\'t even explain (except in the in-sample RFF-LR case with the first dimension of parameters already being equal $n$), why the effective parameter count in the test time doesn\'t increase. I would, moreover, want to see an alternative to Figure 7, but with $P^{PCA}$ being fixed and $P^{Ex}$ being the variable for different base levels of $P^P{PCA}$, because with this it is not even clear what the relation between the $P^{Ex}$ and the effective parameter count with fixed (and potentially small) $P^{PCA}$ is. \n\nW3: Though the authors provide a heuristic explanation on why increasing $P^{Ex}$ should improve the model\'s performance (by providing better basis features and better-conditioned feature matrices), this does not really explain the improvement in model\'s performance. The connection between the quality of basis features in terms of the properties of the basis feature matrix and the test performance is not clear. Information-theoretically, all the information necessary to predict $y$ should already be encoded in $X$, thus representing $X$ with increasing number of random features, just because some matrix becomes better conditioned, does not seem to causally explain the improvement in test performance. \n\nW4: Related to W3, the authors do not at all discuss the apparent non-symmetry between the first and the second dimension. How come the second dimension of parameter count enjoys L-curve, while the first dimension still displays U-curve? Can you provide an explanation that would extend beyond the particularities of Appendix B and wrap all the considered models in a simple (or at least general-enough) way? \n\nW5 (minor): I don\'t agree with line 290: ""First, we observe that these results perfectly match the intuition developed in Part 1"" - In part 1, there is no intuition built on why the measures of effective number of parameters should never increase beyond the first dimension of parameter count. \n\n[1] Maddox, Wesley J., Gregory Benton, and Andrew Gordon Wilson. ""Rethinking parameter counting in deep models: Effective dimensionality revisited."" arXiv preprint arXiv:2003.02139 (2020).'}, 'questions': {'value': 'Q1: Why is the difference between test and train effective parameter count in Figure 6 for RFF-LR at the interpolation threshold so huge? \n\nQ2: Do you have an intuition on how to extend the results of part 1 to neural networks? What would be the candidates for the two dimensions? What about other models? Is there a way to make this more model-agnostic? \n\nQ3: Can you explain any of the questions raised in the ""weaknesses"" section? \n\nBesides, I have a few comments: \n\nC1: The statement in lines 159-160 seems to be incorrect. I don\'t see how min-norm solutions can project $y$ into a row space. \n\nSummary: \n\nDespite several significant concerns I have raised in the ""weaknesses"" section, the paper brings some truly novel and important ideas (most of the part 1). Therefore, I recommend accepting the paper. However, I would be more happy, if the authors addressed the issues raised in the ""weaknesses"" section, either in the rebuttal, or, more conveniently for them, by withdrawing the paper and submitting the improved version to another venue, producing a very strong submission. \n\nNote: After seeing the author\'s response and having most of my concerns resolved, I have decided to raise my score from the original 6 to new 7.'}, 'limitations': {'value': ""I didn't find any explicit discussion of limitations, despite being marked present by the authors in the paper checklist. Perhaps a few sentences here-and-there can be interpreted as a discussion of limitations. ""}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'A U-turn on Double Descent: Rethinking Parameter Counting in Statistical Learning'}, 'authors': {'value': ['Alicia Curth', 'Alan Jeffares', 'Mihaela van der Schaar']}, 'authorids': {'value': ['~Alicia_Curth1', '~Alan_Jeffares1', '~Mihaela_van_der_Schaar2']}, 'keywords': {'value': ['Double Descent', 'Statistical Machine Learning', 'Interpolation Regime', 'Effective Parameters']}, 'abstract': {'value': 'Conventional statistical wisdom established a well-understood relationship between model complexity and prediction error, typically presented as a _U-shaped curve_ reflecting a transition between under- and overfitting regimes. However, motivated by the success of overparametrized neural networks, recent influential work has suggested this theory to be generally incomplete, introducing an additional regime that exhibits a second descent in test error as the parameter count $p$ grows past sample size $n$  -- a  phenomenon dubbed  _double descent_. While most attention has naturally been given to the deep-learning setting, double descent was shown to emerge more generally across non-neural models: known cases include _linear regression, trees, and boosting_. In this work, we take a closer look at the evidence surrounding these more classical statistical machine learning methods and challenge the claim that observed cases of  double descent truly extend the limits of a traditional U-shaped complexity-generalization curve therein. We show that once careful consideration is given to _what is being plotted_ on the x-axes of their double descent plots, it becomes apparent that there are implicitly multiple, distinct complexity axes along which the parameter count grows. We demonstrate that the second descent appears exactly (and _only_) when and where the transition between these underlying axes occurs, and that its location is thus _not_ inherently tied to the interpolation threshold $p=n$. We then gain further insight by adopting a classical nonparametric statistics perspective. We interpret the investigated methods as _smoothers_ and propose a generalized measure for the _effective_ number of parameters they use _on unseen examples_, using which we find that their apparent double descent curves do indeed fold back into more traditional convex shapes -- providing a resolution to the ostensible tension between double descent and traditional statistical intuition.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/657c11ef685da6b627f82d70f3119ec73899dc58.pdf'}, '_bibtex': {'value': '@inproceedings{\ncurth2023a,\ntitle={A U-turn on Double Descent: Rethinking Parameter Counting in Statistical Learning},\nauthor={Alicia Curth and Alan Jeffares and Mihaela van der Schaar},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=O0Lz8XZT2b}\n}'}, 'TLDR': {'value': 'By demonstrating that the double descent shape observed in recent studies of non-deep ML methods is a direct consequence of the x-axes used to present it, we provide a resolution to the tension between statistical intuition and double descent.'}, 'paperhash': {'value': 'curth|a_uturn_on_double_descent_rethinking_parameter_counting_in_statistical_learning'}}]"
"['Boxin Wang', 'Weixin Chen', 'Hengzhi Pei', 'Chulin Xie', 'Mintong Kang', 'Chenhui Zhang', 'Chejian Xu', 'Zidi Xiong', 'Ritik Dutta', 'Rylan Schaeffer', 'Sang Truong', 'Simran Arora', 'Mantas Mazeika', 'Dan Hendrycks', 'Zinan Lin', 'Yu Cheng', 'Sanmi Koyejo', 'Dawn Song', 'Bo Li']",NeurIPS,DecodingTrust_ A Comprehensive Assessment of Trustworthiness in GPT Models,https://neurips.cc/virtual/2023/oral/73736,2023," Generative Pre-trained Transformer (GPT) models have exhibited exciting progress in capabilities, capturing the interest of practitioners and the public alike. Yet, while the literature on the trustworthiness of GPT models remains limited, practitioners have proposed employing capable GPT models for sensitive applications to healthcare and finance – where mistakes can be costly. To this end, this work proposes a comprehensive trustworthiness evaluation for large language models with a focus on GPT-4 and GPT-3.5, considering diverse perspectives – including toxicity, stereotype bias, adversarial robustness, out-of-distribution robustness, robustness on adversarial demonstrations, privacy, machine ethics, and fairness. Based on our evaluations, we discover previously unpublished vulnerabilities to trustworthiness threats. For instance, we find that GPT models can be easily misled to generate toxic and biased outputs and leak private information in both training data and conversation history. We also find that although GPT-4 is usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more vulnerable given jailbreaking system or user prompts, potentially due to the reason that GPT-4 follows the (misleading) instructions more precisely. Our work illustrates a comprehensive trustworthiness evaluation of GPT models and sheds light on the trustworthiness gaps. Our benchmark is publicly available at https://decodingtrust.github.io/.",Oral 1B Datasets & Benchmarks,https://openreview.net/pdf?id=kaHpo8OZw2,https://openreview.net/forum?id=kaHpo8OZw2,kaHpo8OZw2,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (Oral)'}, 'comment': {'value': 'The paper presents an intensive and extensive study of trustworthiness in GPT models. The paper discusses different evaluation perspectives of trustworthiness using different benchmarks. \n\nAll reviewers have positive opinions about the paper.\nThere are minor concerns authors must take into account for the final version.'}}, {'title': {'value': 'Useful additions'}, 'comment': {'value': 'I see that the authors added important illustrations which is useful for all readers to understand the cost and the impact. \nI will keep my score, this is a useful paper and I would like to see it accepted'}}, {'title': {'value': 'Thank you for your valuable follow-up comments'}, 'comment': {'value': 'Thank you so much for your valuable suggestions. We provide rich content in the appendix due to the comprehensiveness of our trustworthiness evaluations as recognized by the reviewers. Following your suggestions, we have made sure that the main paper (10 pages) is self-contained, and readers can clearly get the evaluation goal, setup, and findings for each perspective by only reading the main paper. In the appendix, we mainly add more examples, conversational templates, and some experimental details. We would like to note that these detailed examples will help readers to get more intuition and understanding about the vulnerabilities and capabilities of LLMs, but they are definitely not required in order to understand the paper. For instance, our related work in the appendix is of 6 pages to provide a very comprehensive literature survey, which we believe will largely benefit the community, but it is not required to read the entire related work to understand our paper.\n\nIn addition, following the reviewer’s suggestion, we have further moved some examples and conversational templates from the appendix. We hope this addresses your concerns. Please let us know if you have other suggestions or comments, and we are glad to discuss more and further improve our work to contribute to the community! Thank you for your constructive feedback again!!'}}, {'title': {'value': 'Comments on the response to the review'}, 'comment': {'value': 'Thank you very much for taking the time to respond to my comments, and to provide a revised version of the manuscript. I appreciate the efforts made to improve the contribution and address my concerns.\n\nI still do believe that the manuscript is too substantial (24 pages of main text + 100 pages of supplementary material) to be correctly evaluated, limiting the discussion and engagement with authors on each specific points discussed in the paper. Nonetheless, I think that the the overall approach and its implementation is serious and consistent enough to be relevant to many researchers and practitionners in the field. In particular, it seems relatively feasible to reproduce the results on specific aspects, and build on top of it more focused analysis of the evaluation strategies and improve them.\n\nBased on that, I will update my initial review to take into account the revision of the manuscript.'}}, {'title': {'value': 'Response to Comment'}, 'comment': {'value': 'Thank you for the detailed clarifications and I also appreciate the effort in changing the paper according to it. I am still thinking that your work is a great contribution to the community and to study the trustworthiness of LLMs. I will keep my score and am certain that this will positively affect the overall result for you : )'}}, {'title': {'value': 'General Response'}, 'comment': {'value': 'We thank all the reviewers for their comments and valuable feedback. We have made the following major updates following the reviews to further improve our work.\n\n1. Following the suggestions from Reviewer JNyJ and Reviewer UhDT, we add more details about the experimental setups of our evaluations in Section 3 and Section 5, such as the details of the stereotype dataset and the evaluation aspects of out-of-distribution robustness.\n\n2. Following the suggestions from Reviewer imyr and Reviewer qCen, we add Section 10 in the main text, which incorporates the potential future directions to safeguard LLMs, discussing the possible strategies to address the identified vulnerabilities.\n\n3. Following the suggestion from Reviewer qCen, we add Section 11 Related work in the main text, which provide discussions about existing benchmarks, prompt injection strategies, and regulations for the safety of AI systems.\n\n4. Following the suggestions from Reviewer JNyJ and Reviewer UhDT, we add Appendix K, which provides the computational and query cost for all trustworthiness perspectives and specifies the 1) total number of prompts, 2) total number of prompt tokens, 3) total number of completion tokens, and 4) total run costs for each trustworthiness perspective. In addition, we further break down our evaluation for each perspective into detailed scenarios and report the computation and query costs for each scenario for different perspectives.\n\n5. Following the suggestions from Reviewer UhDT, Reviewer j1j9, Reviewer qCen, we add Appendix L, which provides evaluations from all the trustworthiness perspectives on the top open-source LLMs in the Open LLM leaderboard, including Llama-v2-7B-Chat, Vicuna-7B, Alpaca-7B, MPT-7B, Falcon-7B, RedPajama-INCITE-7B-Instruct.\n\n6. Following the suggestions from Reviewer imyr, Reviewer qCen, and Reviewer ADRf, we add discussions about the potential misuse and negative impacts of our datasets and discuss why it is important to publish these evaluations in Appendix N.\n\n7. Following the suggestion from Reviewer qCen, we add discussions about DecodingTrust and existing AI regulations in Appendix Q.\n\nAll updates are highlighted in blue in our revision. If the manuscript is accepted, all contents in blue in the main text will remain given the extra page limit for the camera-ready version.'}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': ""2. “It might be a good idea for them to keep these specific prompts private and only share them if someone asks for them for research purposes. Balancing between being open in their research and avoiding potential misuse of the information is tricky, but it's something important the authors need to tackle… / Should they keep a private set of prompts to evaluate to ensure more robust testing? Or could there be an automated solution that continually generates new prompts to challenge the models?”\n\n- Thanks for the insightful comments. We agree that sharing of the adversarial experimental settings in this paper such as the jailbreaking prompts could be exploited by malicious users to misuse these models. Hence, it is important for us to balance between research openness and avoiding misuse of information. We have added more discussion about the potential social impacts in Appendix N in the revision. \n\n- First, we believe sharing the high-level settings of our evaluation will be beneficial for both researchers and practitioners who aim to train LLMs and understand the model capabilities, and need to be aware of the model vulnerabilities before deployment. In particular, our platform and findings provide comprehensive evaluations to understand the model capabilities and vulnerabilities, which is critical before deploying LLMs in practice. Similar to several concurrent efforts in exploring the vulnerabilities of LLMs [1,2,3], we aim to provide better understandings and insights about the models in adversarial environments, so that users could avoid the potential attacks.\n\n- In addition, we note that **our studies are able to generate more prompts automatically for all the perspectives**. We will share the prompts used in our evaluation while preserving some newly generated prompts for future evaluation to balance the research openness and information misuse. Taking the toxicity perspective as an example, the existing toxic sentences could be served as seed prompts for LLMs to generate coherent continuations which are later served as new challenging user prompts and jailbreaking prompts. Similarly, we can automatically generate more adversarial instances for AdvGLUE++ to test the adversarial robustness of LLMs, generate more testing prompts based on existing tabular datasets for fairness evaluation, and generate more privacy extraction prompts, etc. In principle, we will keep parts of the newly generated challenging data private to ensure that as a white-hat model evaluation, we are slightly ahead of the actual adversaries in the real world, so that we can start to design potential solutions against these vulnerabilities before they are implemented in practice.\n\n[1] Qiu, H., Zhang, S., Li, A., He, H., & Lan, Z. (2023). Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output Robustness of Large Language Models. ArXiv, abs/2307.08487.\n\n[2] Liu, Y., Yao, Y., Ton, J., Zhang, X., Cheng, R.G., Klochkov, Y., Taufiq, M.F., & Li, H. (2023). Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment.\n\n[3] https://www.jailbreakchat.com/""}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': 'We thank the reviewer for the valuable comments and feedbacks. We are glad that the reviewer finds our work conducting comprehensive analysis, providing holistic approach, giving a better understanding of the LLM’s performance and their potential vulnerabilities, and doing a great job diving into LLM understandings. We provide details response as below.\n\n1. “It could benefit from a more explicit discussion of potential solutions or strategies to address the identified vulnerabilities in the LLMs.”\n\n- Thanks for the insightful suggestion. We have listed several potential solutions and strategies to mitigate potential vulnerabilities in the LLMs in Appendix M. Specifically, we mention four potential ways to safeguard the trustworthiness of LLMs, including:\n\n    -  **Safeguarding LLMs with additional knowledge and reasoning analysis**: PAs purely data-driven models such as GPT models would suffer from the imperfection of the training data and lack of reasoning capabilities in various tasks. Thus, it would be important to equip domain knowledge and logical reasoning capabilities for language models and safeguard their outputs to make sure they satisfy basic, domain knowledge and logic to ensure the trustworthiness of the model outputs.\n\n    - **Safeguarding LLMs based on consistency checking**: Our designed system prompts based on “role-playing"" shows that models can be easily fooled based on role-changing and manipulation. This indicates that during the conversation of LLMs, it is possible to design diverse roles to ensure the consistency of the model’s answers, and therefore at least avoid the models being self-conflict. It is also possible to design different roles for the models to make sure it understands the context well to provide more informative and trustworthy answers.\n\n   - **Safeguarding LLMs via trustworthy finetuning**: Our generated challenging and adversarial prompts usually represent the long-tailed and “rare” events of the original training data distribution. As a result, it would be helpful to use our generated challenging prompts to finetune the LLMs and improve their trustworthiness. On the other hand, we note that new adaptive adversarial attacks could still be conducted against the new finetuned LLMs, and therefore we need to be aware of new adaptive attacks and try to provide certain trustworthiness verifications which are agnostic to actual attack strategies. \n\n    - **Verification for the trustworthiness of LLMs**: Empirical evaluations of LLMs are important but lack of guarantees, especially in safety-critical domains, so rigorous trustworthiness guarantees would be critical. To safeguard the trustworthiness of LLMs, it is important to provide verification for the trustworthiness of LLMs based on specific functionalities or properties, or map the discrete input space to their corresponding continuous space such as the embedding space with semantic preservation to perform verification leveraging existing verification tools in the continuous space.\n\n- We have incorporated the above discussions in Section 10 of our main text in the revision, and thank you for the valuable suggestions!'}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': '- In addition, we further break down our evaluation for each perspective into detailed scenarios, and Table 46-53 in Appendix K show the similar computing and query costs for these detailed scenarios under different trustworthiness perspectives. Similarly, we report the 1) number of prompts for each scenario and GPT models, 2) number of tokens of the prompts, 3) number of completion tokens that answer the prompts, 4) single run cost of answering the prompts, 5) number of the run repetitions, and 6) total run cost. These tables also allow users to flexibly determine whether they want to run some subsets of the scenarios of each perspective based on their available resources.\n\n- We thank the reviewers for all the insightful suggestions and comments, and hope our additional experiments and discussions will help address your concerns. We are very grateful for the reviewer’s suggestions on helping to improve our work.'}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': '7. “The use of GPT 4 and 3.5 raises two significant concerns regarding reproducibility that should be addressed. Firstly, it is not clear whether the tested versions (which are dated ""March"" according to the Supplementary Material) will be accessible to researchers from external sources, as only latest versions are generally accessible. This issue raises doubts about whether or not these experiments can be successfully replicated by other researchers. Secondly, to the best of my knowledge, access to GPT models is not free. While this does not invalidate the approach, it is important that the cost of reproducing the results is mentioned in the paper to ensure transparency and make sure that the findings and reproducibility are accessible to the broader scientific community.”\n\n- Thanks for the insightful comments. According to the [official documentation from OpenAI](https://platform.openai.com/docs/deprecations/), GPT-3.5 and GPT-4 are released with incremental updates, without immediate deprecation of older versions. The March-released GPT-3.5 (`gpt-3.5-turbo-0301`) and GPT-4 (`gpt-4-0314`) models we used in our evaluation are still available for external researchers until June 13, 2024, which ensures the reproducibility. Moreover, we have open-sourced all of our code and corresponding model outputs in the GitHub repo to make sure that our results are reproducible. \n- Furthermore, our codebase can support the evaluation of open-source LLMs (e.g., models hosted in Huggingface), which ensures that our evaluation framework and findings are reproducible and accessible to the broader scientific community. (Table 1 above shows our evaluations on different open-source LLMs and GPT models.)\n- Regarding the cost of the evaluation, we have added details of the computation and query costs in Appendix K in the revision following the suggestions. We also put a detailed analysis of costs in Table 2 below.\n\nTable 2 summarizes the 1) total number of prompts, 2) total number of prompt tokens, 3) total number of completion tokens, and 4) total run costs for each trustworthiness perspective and GPT models.\n\n*Table 2. Total computing costs of evaluation on different trustworthiness perspectives on GPT models*\n| Perspectives                                 | Models  | #/ Prompts | #/ Prompt Tokens | #/ Completion Tokens | Total Cost ($) |\n| -------------------------------------------- | ------- | ---------- | ---------------- | -------------------- | -------------- |\n| Toxicity                                     | GPT-3.5 | 49,200      | 10,966,554       | 15,796,800           | 78.14          |\n| Toxicity                                     | GPT-4   | 49,200      | 10,966,554       | 15,796,800           | 2158.97        |\n| Stereotype                                   | GPT-3.5 | 3,456       | 766,296          | 12,960,000           | 27.46          |\n| Stereotype                                   | GPT-4   | 3,456       | 766,296          | 12,960,000           | 800.58         |\n| Adversarial Robustness                       | GPT-3.5 | 42,755      | 3,596,216        | 684,080              | 9.30            |\n| Adversarial Robustness                       | GPT-4   | 42,755      | 3,596,216        | 684,080              | 162.23         |\n| OOD                                          | GPT-3.5 | 47,079      | 13,879,675       | 470,790              | 28.70           |\n| OOD                                          | GPT-4   | 47,079      | 13,879,675       | 470,790              | 444.64         |\n| Robustness against adversarial demonstration | GPT-3.5 | 233,100     | 152,882,443      | 322,259              | 306.41         |\n| Robustness against adversarial demonstration | GPT-4   | 233,100     | 144,558,043      | 256,140              | 4352.11        |\n| Privacy                                      | GPT-3.5 | 106,150    | 6,363,542        | 2,408,800            | 17.54          |\n| Privacy                                      | GPT-4   | 106,150    | 6,363,542        | 2,408,800            | 335.43         |\n| Machine Ethics                               | GPT-3.5 | 21,869     | 6,796,656        | 373,380              | 15.31          |\n| Machine Ethics                               | GPT-4   | 21,869     | 6,796,656        | 373,380              | 242.29         |\n| Fairness                                     | GPT-3.5 | 32,400     | 16,798,525       | 180,000              | 34.00             |\n| Fairness                                     | GPT-4   | 32,400     | 16,798,525       | 180,000              | 503.35         |'}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': ""4. “Given the possible negative consequences associated with such work, I believe it would be valuable for the paper to include a discussion of this aspect. Such a discussion could help readers understand the reasoning behind the decision to publish the work and encourage greater discussion and consideration of responsible AI research.”\n\n- Thanks for the insightful comments. We follow your suggestions and add a more detailed discussion about potential negative consequences such as the misuse of the information in Appendix N to make sure users are aware of the potential negative impacts. We agree that such discussion will help readers to understand the reasoning behind the decision to publish the work and we will put more detailed discussion below for such reasoning and our motivation of the work.\n\n- First, we believe sharing the high-level settings of our evaluation will be beneficial for both researchers and practitioners who aim to train LLMs and understand the model capabilities, and need to be aware of the model vulnerabilities before deployment. In particular, our platform and findings provide comprehensive evaluations to understand the model capabilities and vulnerabilities, which is critical before deploying LLMs in practice. Similar to several concurrent efforts in exploring the vulnerabilities of LLMs [1,2,3], we aim to provide better understandings and insights about the models in adversarial environments, so that users could avoid the potential attacks.\n\n- In addition, for the detailed generated challenging and adversarial prompts, we will share the prompts used in our evaluation, while preserving some newly generated prompts for future evaluation to balance between the research openness and information misuse. In particular, we will keep parts of the newly generated challenging data private to ensure that as a white-hat model evaluation, we are slightly ahead of the actual adversaries in the real world, so that we can start to design potential solutions against these vulnerabilities before they are implemented in practice.\n\n[1] Qiu, H., Zhang, S., Li, A., He, H., & Lan, Z. (2023). Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output Robustness of Large Language Models. ArXiv, abs/2307.08487.\n\n[2] Liu, Y., Yao, Y., Ton, J., Zhang, X., Cheng, R.G., Klochkov, Y., Taufiq, M.F., & Li, H. (2023). Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment.\n\n[3] https://www.jailbreakchat.com/ \n\n5. “Relation To Prior Work: This section is under-developed in the main text, and its inclusion in the Supplementary Material (where it is much more detailed) is not adequate.”\n\n- Thanks for the valuable comments. We follow your suggestions and add a more detailed related work section in Section 11 of the main paper to provide more background about the trustworthiness of LLMs, including existing benchmarks, adversarial strategies against LLMs, and related regulations. We have highlighted our revision in blue. Thank you for the valuable suggestions.\n\n6. “It is not clear whether the contribution is meant to be a benchmark (i.e., software) or a dataset (i.e., text). From my understanding of the organization of the repository, it seems to be the former, but there are several mentions of a dataset that are confusing (for instance, the presence of a data sheet in the supplementary material). Otherwise, the repository is well-organized and allows for reproducibility, even if the source code lacks proper documentation and comments that could make the re-use by other research groups relatively difficult.”\n\n- Thanks for the valuable comments. Indeed, our DecodingTrust project provides both a unified trustworthiness evaluation platform and several challenging and adversarial datasets for trustworthiness evaluation on different LLMs flexibly.\n\n- To provide a unified trustworthiness evaluation platform, we allow users to use a simple entry (`python main.py`) to execute all the evaluations for different perspectives and different models in one pass. We also provide an [updated tutorial documentation] (https://github.com/AI-secure/DecodingTrust/blob/main/Tutorial.md) to help users to walk through our codebase and allow flexible customization to configure the model parameters and evaluation settings. \n\n- To provide challenging evaluation datasets, we propose and generate new challenging user prompt datasets that can better, for instance, elicit model toxicity than existing standard benchmarks. We have added the related discussions in Section 1 in the revision to make it more clear.""}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': '2. “Discussing mitigation measures and exploring how they impact overall trustworthiness.”\n\n- Thanks for the insightful suggestion. We have listed several potential solutions and strategies to mitigate the potential vulnerabilities in the LLMs in Appendix M. Specifically, we mention four potential ways to safeguard the trustworthiness of LLMs, including:\n\n    -  **Safeguarding LLMs with additional knowledge and reasoning analysis**: As purely data-driven models such as GPT models would suffer from the imperfection of the training data and lack of reasoning capabilities in various tasks. Thus, it would be important to equip domain knowledge and logical reasoning capabilities for language models and safeguard their outputs to make sure they satisfy basic, domain knowledge and logic to ensure the trustworthiness of the model outputs.\n\n    - **Safeguarding LLMs based on consistency checking**: Our designed system prompts based on “role-playing"" shows that models can be easily fooled based on role-changing and manipulation. This indicates that during the conversation of LLMs, it is possible to design diverse roles to ensure the consistency of the model’s answers, and therefore at least avoid the models being self-conflict. It is also possible to design different roles for the models to make sure it understands the context well to provide more informative and trustworthy answers.\n\n   - **Safeguarding LLMs via trustworthy finetuning**: Our generated challenging and adversarial prompts usually represent the long-taild and “rare” events of the original training data distribution. As a result, it would be helpful to use our generated challenging prompts to finetune the LLMs and improve their trustworthiness. On the other hand, we note that new adaptive adversarial attacks could still be conducted against the new finetuned LLMs, and therefore we need to be aware of new adaptive attacks and try to provide certain trustworthines verifications which are agnostic to actual attack strategies. \n\n    - **Verification for the trustworthiness of LLMs**: Empirical evaluations of LLMs are important but lack of guarantees, especially in safety-critical domains, so rigorous trustworthiness guarantees would be critical. To safeguard the trustworthiness of LLMs, it is important to provide verification for the trustworthiness of LLMs based on specific functionalities or properties, or map the discrete input space to their corresponding continuous space such as the embedding space with semantic preservation to perform verification leveraging existing verification tools in the continuous space.\n\n- We have incorporated the above discussions in our main text in the revision, and thank you for the valuable suggestions!\n\n3. “Connecting this framework with legal requirements in current AI regulations.”\n\n- Thanks for the insightful suggestions. We follow your suggestions to extract the legal requirements from EU AI Act and the U.S. White House announcement. In summary, the trustworthiness of LLMs and other AI systems has become one of the key focuses of policymakers, such as the European Union\'s Artificial Intelligence Act (AIA) and the United States AI Bill of Rights. The AIA adopts a risk-based approach that categorizes AI systems based on their risk levels, necessitating stringent compliance assessments for high-risk systems. The U.S. has proposed principles for safe AI systems, including safety, fairness, privacy, and human-in-the-loop intervention. \nThese regulations align well with the trustworthiness perspectives that we define and evaluate in our DecodingTrust platform, such as adversarial robustness, out-of-distribution robustness, privacy, fairness, and disclosure. In addition, these regulatory measures reflect growing attention on evaluation and risk assessment for AI systems from different angles, which resonates with the research community and our research efforts to ensure responsible and reliable AI evaluation and deployment. We believe our platform will help facilitate the standard evaluation and risk assessment benchmarking efforts for AI systems and contribute to developing trustworthy ML and AI systems in practice. \n\n- Moreover, as shown in our evaluation of GPT models and open LLMs, none of them can achieve the best performance on all the trustworthiness perspectives, which provides an insightful understanding of different models and the underlying connections between different trustworthiness perspectives. We believe our evaluation can shed light on the development of trustworthy LLMs considering different perspectives. We have incorporated the detailed discussion highlighted in blue in Appendix Q in the revision.'}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': 'We thank the reviewer for the insightful comments and feedback! We are glad that the reviewer finds our work providing a comprehensive assessment of GPT models, analyzing a wide range of critical aspects, and making valuable findings to the scientific community and beyond. We provide detailed responses below.\n\n1. “Adopting a unified view to test different aspects jointly.” “Studying the interplay between the different perspectives and how they interact with each other. / Expanding the benchmarking approach of the paper by testing other models, including open-source ones.”\n\n- Thank you for the valuable and constructive comments.  Following the reviewer’s suggestions, we have provided a unified view to test different aspects jointly by providing a unified testing API which allows the users to easily add new evaluation perspectives and evaluate different LLMs. \n\n- In particular, our unified testing API is able to evaluate different trustworthiness perspectives jointly through a single entry point. We have updated our evaluation framework in [Github](https://github.com/AI-secure/DecodingTrust). Our unified API features structured configuration, enabling the following functionality: (1), our API can provide users with a simple entry (main.py) to execute all experiments in one pass. (2), if you only want to run the selected evaluations of DecodingTrust (e.g., some trustworthiness perspectives), you can specify the argument to run specific scenarios (`python main.py +toxicity=toxic-gpt4`) in the command line input. (3), if you want to run the evaluations with your custom configuration, you can simply set up the sub-configuration file and override the corresponding argument in the command line input. \n\n- In addition, our API can evaluate different LLMs, including open LLMs hosted in Huggingface and proprietary LLMs through API queries.\nWe also follow your suggestion and run the following top open-source LLMs in the Open LLM leaderboard, including Llama-v2-7B-Chat, Vicuna-7B, Alpaca-7B, MPT-7B, Falcon-7B, RedPajama, on all the trustworthiness perspectives. The results are shown below. For each perspective, we report one single score to facilitate clearer comparison, which is aggregated from the evaluation results of all scenarios under that perspective.  We have also added corresponding setup details, experimental results, and related analysis in Appendix L.\n\n*Table 1 Comprehensive evaluation results of open-source LLMs*\n\n| Model     | Toxicity | Stereotype Bias | Adversarial Robustness | OOD Robustness | Robustness to\xa0 Adv. Demonstrations | Privacy | Machine Ethics | Fairness |\n| --------- | -------- | --------------- | ---------------------- | -------------- | ---------------------------------- | ------- | -------------- | -------- |\n| Llama2    | 80.00    | 97.60           | 51.01                  | 75.65          | 55.54                              | 97.39   | 40.58          | 100.00   |\n| Vicuna    | 28.00    | 81.00           | 52.16                  | 59.10          | 57.99                              | 72.96   | 48.22          | 85.53    |\n| Alpaca    | 22.00    | 43.00           | 46.43                  | 51.79          | 34.15                              | 46.39   | 30.43          | 92.63    |\n| MPT       | 40.00    | 84.60           | 46.20                  | 64.26          | 58.25                              | 78.93   | 26.11          | 100.00   |\n| Falcon    | 39.00    | 87.00           | 43.98                  | 51.45          | 33.95                              | 70.26   | 50.28          | 100.00   |\n| RedPajama | 18.00    | 73.00           | 44.81                  | 54.21          | 58.51                              | 76.64   | 27.49          | 100.00   |\n| GPT-3.5   | 47.00    | 87.00           | 56.69                  | 73.58          | 81.28                              | 70.13   | 86.38          | 77.57    |\n| GPT-4     | 41.00    | 77.00           | 64.04                  | 87.55         | 77.94                              | 66.11   | 76.60          | 63.67    |\n\nWe aim to study the interplay between the different perspectives based on the evaluations above. As illustrated in the table, among the 8 trustworthiness perspectives, GPT-4 achieves the best performance on 3 perspectives: Adversarial Robustness, Out-of-Distribution Robustness, and Robustness to Adversarial Demonstrations. The open-source model, Llama 2, achieves the best performance on 4 perspectives: Toxicity, Stereotype Bias, Privacy, and Fairness, which demonstrate the efforts that the Llama2 team have put into developing less-biased, privacy-aware, and fairness-aware LLMs. Overall, we can see that currently no model can achieve the best performance on all the perspectives, and there are tradeoffs between different perspectives. We believe our observations will lead to interesting future work on developing more trustworthy LLMs and understanding the underlying connections between different trustworthiness perspectives.'}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': '3. ""The benchmark is not easy to extend without a lot of manual effort. Each method and dataset are manually selected or crafted. However, I can clearly see the difficulties here and appreciate the effort by the authors. The evaluation is limited to two (recent) LLMs.""\n\n- We deeply appreciate your valuable comments. We are pleased to note that our project code has been unified as a unified API, which is easy to extend (e.g., adding new evaluation perspectives), and can be used to evaluate any open-source models conveniently. \n\n- In particular, our unified DecodingTrust API has the following characteristics:\n     - **1) Structured and unified.** As for the API configuration, the top-level main configuration file contains basic information required by all perspectives such as model name and API key, and the sub-configuration files contain the dedicated configurations for each trustworthy perspective, respectively. Based on this structured configuration, **first of all**, our API can provide users with a simple entry (`python main.py`) to execute all experiments in one pass. **Second of all**, if the users only want to run the selected evaluations of DecodingTrust (e.g., some trustworthiness perspectives), they can specify the argument to run specific scenarios (`python main.py +toxicity=realtoxicityprompts-toxic`) in the command line input. **Lastly**, if the users want to run the evaluations with their custom configuration, they can simply set up the sub-configuration file and override the corresponding argument in the command line input. We have also updated our README as well as a [tutorial page](https://github.com/AI-secure/DecodingTrust/blob/main/Tutorial.md) for more examples. \n    - **2) Incorporating more open-source language models.**\nOur API can support interacting with different API-based LLMs as well as Huggingface open LLMs. Thus, practitioners can utilize our DecodingTrust API to evaluate their own LLMs by simply configuring the corresponding argument in the command line input following our tutorial. \n\n- We have also followed your suggestion and evaluate the following top open-source LLMs in the Open LLM leaderboard, including Llama-v2-7B-Chat, Vicuna-7B, Alpaca-7B, MPT-7B, Falcon-7B,  RedPajama, on all the trustworthiness perspectives. The results are shown below. For each perspective, we report one single score to facilitate clearer comparison, which is aggregated from the evaluation results of all scenarios under that perspective.  We have also added corresponding setup details, aggregation protocols, experimental results, and related analysis in Appendix L.\n\n*Table 1 Comprehensive evaluation results of open-source LLMs*\n\n| Model     | Toxicity | Stereotype Bias | Adversarial Robustness | OOD Robustness | Robustness to\xa0 Adv. Demonstrations | Privacy | Machine Ethics | Fairness |\n| --------- | -------- | --------------- | ---------------------- | -------------- | ---------------------------------- | ------- | -------------- | -------- |\n| Llama2    | 80.00    | 97.60           | 51.01                  | 75.65          | 55.54                              | 97.39   | 40.58          | 100.00   |\n| Vicuna    | 28.00    | 81.00           | 52.16                  | 59.10          | 57.99                              | 72.96   | 48.22          | 85.53    |\n| Alpaca    | 22.00    | 43.00           | 46.43                  | 51.79          | 34.15                              | 46.39   | 30.43          | 92.63    |\n| MPT       | 40.00    | 84.60           | 46.20                  | 64.26          | 58.25                              | 78.93   | 26.11          | 100.00   |\n| Falcon    | 39.00    | 87.00           | 43.98                  | 51.45          | 33.95                              | 70.26   | 50.28          | 100.00   |\n| RedPajama | 18.00    | 73.00           | 44.81                  | 54.21          | 58.51                              | 76.64   | 27.49          | 100.00   |\n| GPT-3.5   | 47.00    | 87.00           | 56.69                  | 73.58          | 81.28                              | 70.13   | 86.38          | 77.57    |\n| GPT-4     | 41.00    | 77.00           | 64.04                  | 87.55         | 77.94                              | 66.11   | 76.60          | 63.67    |\n\nFrom the table, GPT-4 achieves the best performance on 3 perspectives: Adversarial Robustness, Out-of-Distribution Robustness, and Robustness to Adversarial Demonstrations. The open-source model, Llama 2, achieves the best performance on 4 perspectives: Toxicity, Stereotype Bias, Privacy, and Fairness, which demonstrate the efforts that the Llama2 team has put into developing less-biased, privacy-aware, and fairness-aware LLMs. On the other hand,  we can see that currently, no model can achieve satisfactory performance for all the perspectives. In light of these observations, developing more trustworthy LLMs remains an important task for future work. We appreciate your comments to help improve our work.'}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': '2. “What are other attack vectors in case of, for example, whitebox access to a model? This is particularly important to evaluate a worst-case scenario.”\n\n- Thank you for the insightful question. We agree that conducting whitebox attacks against LLMs can serve as a worst-case evaluation. On the one hand, since both GPT-3.5 and GPT-4 only provide text completion without providing direct access to model weights or output logits, it can be challenging to directly conduct whitebox attacks on GPT-3.5 and GPT-4. On the other hand, **we have conducted whitebox attacks on open-source LLMs (Alpaca, Vicuna, and Stable Vicuna)** to evaluate their worst-case performance. Moreover, we transfer our adversarial textural attack instances generated by whitebox attacks to GPT-3.5 and GPT-4 as AdvGLUE++, and we find that **our whitebox-generated adversarial textural attacks against open-source LLMs can effectively transfer and attack GPT-3.5 and GPT-4 models**. For example, the robust accuracy of GPT-3.5 and GPT-4 significantly drop on our adversarial instances generated against Alpaca-7B, where the corresponding robust accuracies of GPT-3.5 and GPT-4 are only 49.23% and 55.64%, respectively.'}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': 'We thank the reviewer for the valuable suggestions and comments! We are glad that the reviewer finds our paper providing comprehensive evaluation, successfully identifying most of the important known threats, and conducting thorough experiments with insightful findings. We will provide detailed responses below.\n\n1. “The paper does not specifically describe the benchmark framework. What makes it a benchmark? How easy is it to add new evaluation aspects”\n\n- Thanks for the valuable questions and feedbacks. We indeed aim to make the DecodingTrust a general benchmark framework as suggested, which is easy to add new evaluation perspectives and easy to evaluate other models. In particular, we follow the principles of constructing standard benchmarks [1, 2] to ensure that our platform can serve as a benchmark for evaluating the trustworthiness of language models. Below we highlight some key principles of and illustrate how DecodingTrust aligns with these principles.\n  - *(1) Standardization*: Our benchmark designs leverages a set of standardized criteria and metrics that are used consistently across prior studies on LLM evaluation and different models. \n  - *(2) Accessibility and Coverage*: DecodingTrust is designed to facilitate comparisons among different LLMs conveniently. It is easy to evaluate any LLM by providing the model URL to the DecodingTrust platform following our tutorial. In particular, for each trustworthiness perspective, we have developed multiple standardized evaluation structures (each includes a detailed setup, datasets, metrics, etc), as shown in Figure 3 in Appendix A. This set of standardized scenarios serves the purpose of evaluating the trustworthiness of different language models. In the revision, we also integrate six more open-source LLMs from the top Open LLM leaderboard to analyze the trustworthiness of open-source LLMs. We include our evaluation results in Appendix L in the revision, which shed light on the future directions of improving open-source LLMs. In summary, these standardized scenarios can be effectively utilized to compare the performance and resilience of different language models across various trustworthiness perspectives.\n   - *(3) Disincentives for Biased Models*: DecodingTrust benchmark conducts a comprehensive and reliable measure of different trustworthiness perspectives for LLMs, which further provides insightful understandings of the capabilities and vulnerabilities of LLMs. In particular, practitioners have proposed applying capable GPT models to sensitive applications such as healthcare and finance, where mistakes can be costly. Hence, trustworthiness is a crucial aspect that requires attention. DecodingTrust manages to provide a comprehensive trustworthiness-focused evaluation on GPT models together with some open-source models, assessing their performance and resilience in adversarial environments across different aspects of trustworthiness. Thus, we believe DecodingTrust will serve as a standard benchmark to disincentive untrustworthy models especially for safety-critical domains in practice. \n   - *(4) Documentation and Transparency*: A benchmark should have clear documentation that outlines the methodology, procedures, and metrics used in the evaluation process. DecodingTrust is well documented and includes a website, detailed instructions and codes for every trustworthiness perspective.\n\n\n- In addition, to add new evaluation perspectives, the overhead is very low thanks to our unified DecodingTrust API. In particular, users only need to specify the model name (either an OpenAI model or a Huggingface Hub model) and the perspective they would like to evaluate in the command line interface following our tutorial. The code base of DecodingTrust consists of a wrapper that unifies the programming interface of OpenAI API and Huggingface Hub models, the Python modules that host the implementation of each trustworthiness perspective, a configuration system backed by Hydra [3], and a centralized code runner that delegates command line input to perform the evaluation. \nBy adding the Python module of the new perspective following the unified format, we could easily conduct evaluations on the new perspective.\n\n[1] [What Will it Take to Fix Benchmarking in Natural Language Understanding?](https://arxiv.org/pdf/2104.02145.pdf)\n\n[2] [Datasheets for Datasets](https://arxiv.org/pdf/1803.09010.pdf)\n\n[3] [Hydra - A framework for elegantly configuring complex applications](https://github.com/facebookresearch/hydra)'}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': 'We thank the reviewer once again for the valuable suggestions and comments! We are glad that the reviewer finds our paper providing a comprehensive, valuable, and timely evaluation, conducting very thorough experiments with detailed takeaways, and very clear and enjoyable to read. We have provided detailed responses above.'}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': '3. “The total compute is not specified. Can you provide any metrics on how long it took to run the evaluation and how much compute resources were used (e.g. maybe in the form of the number of processed tokens by the OpenAI API)”\n\n- Thanks for your valuable suggestions about demonstrating the computing resources used in the evaluations in the paper. We have added detailed computing and query costs and analysis in Appendix K in the revision following the suggestions.\n\n- Table 2 summarizes the 1) total number of prompts, 2) total number of prompt tokens, 3) total number of completion tokens, and 4) total run costs for each trustworthiness perspective and each GPT model.\n\n*Table 2. Total computing costs of evaluation on different trustworthiness perspectives on GPT models*\n| Perspectives                                 | Models  | #/ Prompts | #/ Prompt Tokens | #/ Completion Tokens | Total Cost ($) |\n| -------------------------------------------- | ------- | ---------- | ---------------- | -------------------- | -------------- |\n| Toxicity                                     | GPT-3.5 | 49,200      | 10,966,554       | 15,796,800           | 78.14          |\n| Toxicity                                     | GPT-4   | 49,200      | 10,966,554       | 15,796,800           | 2158.97        |\n| Stereotype                                   | GPT-3.5 | 3,456       | 766,296          | 12,960,000           | 27.46          |\n| Stereotype                                   | GPT-4   | 3,456       | 766,296          | 12,960,000           | 800.58         |\n| Adversarial Robustness                       | GPT-3.5 | 42,755      | 3,596,216        | 684,080              | 9.30            |\n| Adversarial Robustness                       | GPT-4   | 42,755      | 3,596,216        | 684,080              | 162.23         |\n| OOD                                          | GPT-3.5 | 47,079      | 13,879,675       | 470,790              | 28.70           |\n| OOD                                          | GPT-4   | 47,079      | 13,879,675       | 470,790              | 444.64         |\n| Robustness against adversarial demonstration | GPT-3.5 | 233,100     | 152,882,443      | 322,259              | 306.41         |\n| Robustness against adversarial demonstration | GPT-4   | 233,100     | 144,558,043      | 256,140              | 4352.11        |\n| Privacy                                      | GPT-3.5 | 106,150    | 6,363,542        | 2,408,800            | 17.54          |\n| Privacy                                      | GPT-4   | 106,150    | 6,363,542        | 2,408,800            | 335.43         |\n| Machine Ethics                               | GPT-3.5 | 21,869     | 6,796,656        | 373,380              | 15.31          |\n| Machine Ethics                               | GPT-4   | 21,869     | 6,796,656        | 373,380              | 242.29         |\n| Fairness                                     | GPT-3.5 | 32,400     | 16,798,525       | 180,000              | 34.00             |\n| Fairness                                     | GPT-4   | 32,400     | 16,798,525       | 180,000              | 503.35         |\n\n- In addition, we further break down our evaluation for each perspective into detailed scenarios, and Table 46-53 in Appendix K show the similar computing and query costs for these detailed scenarios under different trustworthiness perspectives. Similarly, we report the 1) number of prompts for each scenario and GPT models, 2) number of tokens of the prompts, 3) number of completion tokens that answer the prompts, 4) single run cost of answering the prompts, 5) number of the run repetitions, and 6) total run cost. These tables also allow users to flexibly determine whether they want to run some subsets of the scenarios of each perspective based on their available'}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': '2. “While Figure 1 is excellent and the paper is easy to read, it lacks sufficient explanations of experimental setups for most sections of the main body and refers to appendix for crucial details and explanations central to the experimental setup. It would be great to provide necessary details in the main body and refer to appendix only for supplementary details.”\n\n- Thanks for your understanding that it is challenging for us to cover all detailed information in the current 9-page paper, and thanks for the reminder to keep the last version self-read and self-contained, which is really important and helpful for readers. To make the main paper self-contained following the suggestion, we leverage the additional one page in the final version to make sure that the following items are included in each trustworthiness perspective for consistency and completeness. \n    - Goal: This part allows readers easily understand what we aim to evaluate and what scenarios will be included.\n    - Setup: This part includes 1) the task we are focusing on, 2) the scenarios we will design and evaluate, 3) the descriptions of the datasets, and 4) the evaluation metrics.\n    - Results and findings: All the figures and tables in this part are also self-contained, whose title will clearly convey the content and purpose of the figure or table without requiring readers to refer to the main text.\n- For instance, we have added the details of the stereotype dataset (e.g., the selected stereotype groups and stereotype topics, and some examples of our user and system prompts) in the revision Section 3. We have also added more explanations about the aspects that OOD robustness aims to evaluate (i.e., OOD knowledge, OOD language style, and OOD in-context demonstrations) in revision Section 5.'}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': '1. “The paper only focuses on GPT models, however, those are proprietary models. It would be valuable to add evaluation of open-source models available to the general public and identify the most trustworthy open models.”\n\n- Thanks for your valuable suggestions on expanding the scope of our work! We are pleased to note that our project code has been unified as a unified API, which can be used to evaluate any open-source models. \n\n- In particular, our unified DecodingTrust API has the following characteristics:\n     - **1) Structured and unified.** As for the API configuration, the top-level main configuration file contains basic information required by all perspectives such as model name and API key, and the sub-configuration files contain the dedicated configurations for each trustworthy perspective, respectively. Based on this structured configuration, **first of all**, our API can provide users with a simple entry (`python main.py`) to execute all experiments in one pass. **Second of all**, if the users only want to run the selected evaluations of DecodingTrust (e.g., some trustworthiness perspectives), they can specify the argument to run specific scenarios (`python main.py +toxicity=realtoxicityprompts-toxic`) in the command line input. **Lastly**, if the users want to run the evaluations with their custom configuration, they can simply set up the sub-configuration file and override the corresponding argument in the command line input. Overall, the unified API offers users a convenient and user-friendly approach to effortlessly conduct evaluations according to their preferred settings. We have also updated our README as well as a [tutorial page](https://github.com/AI-secure/DecodingTrust/blob/main/Tutorial.md) for more examples. \n    - **2) Incorporating more open-source language models.**\nOur API can support interacting with different API-based LLMs as well as Huggingface open LLMs. Thus, practitioners can utilize our DecodingTrust API to evaluate their own LLMs by simply configuring the corresponding argument in the command line input following our tutorial. We have also followed your suggestion and evaluate the following top open-source LLMs in the Open LLM leaderboard, including Llama-v2-7B-Chat, Vicuna-7B, Alpaca-7B, MPT-7B, Falcon-7B,  RedPajama, on all the trustworthiness perspectives. The results are shown below. For each perspective, we report one single score to facilitate clearer comparison, which is aggregated from the evaluation results of all scenarios under that perspective.  We have also added corresponding setup details, aggregation protocols, experimental results, and related analysis in Appendix L.\n\n*Table 1 Comprehensive evaluation results of open-source LLMs*\n\n| Model     | Toxicity | Stereotype Bias | Adversarial Robustness | OOD Robustness | Robustness to\xa0 Adv. Demonstrations | Privacy | Machine Ethics | Fairness |\n| --------- | -------- | --------------- | ---------------------- | -------------- | ---------------------------------- | ------- | -------------- | -------- |\n| Llama2    | 80.00    | 97.60           | 51.01                  | 75.65          | 55.54                              | 97.39   | 40.58          | 100.00   |\n| Vicuna    | 28.00    | 81.00           | 52.16                  | 59.10          | 57.99                              | 72.96   | 48.22          | 85.53    |\n| Alpaca    | 22.00    | 43.00           | 46.43                  | 51.79          | 34.15                              | 46.39   | 30.43          | 92.63    |\n| MPT       | 40.00    | 84.60           | 46.20                  | 64.26          | 58.25                              | 78.93   | 26.11          | 100.00   |\n| Falcon    | 39.00    | 87.00           | 43.98                  | 51.45          | 33.95                              | 70.26   | 50.28          | 100.00   |\n| RedPajama | 18.00    | 73.00           | 44.81                  | 54.21          | 58.51                              | 76.64   | 27.49          | 100.00   |\n| GPT-3.5   | 47.00    | 87.00           | 56.69                  | 73.58          | 81.28                              | 70.13   | 86.38          | 77.57    |\n| GPT-4     | 41.00    | 77.00           | 64.04                  | 87.55         | 77.94                              | 66.11   | 76.60          | 63.67    |\n\nFrom the table, GPT-4 achieves the best performance on 3 perspectives: Adversarial Robustness, Out-of-Distribution Robustness, and Robustness to Adversarial Demonstrations. The open-source model, Llama 2, achieves the best performance on 4 perspectives: Toxicity, Stereotype Bias, Privacy, and Fairness, which demonstrate the efforts that the Llama2 team has put into developing less-biased, privacy-aware, and fairness-aware LLMs. On the other hand,  we can see that currently, no model can achieve satisfactory performance for all the perspectives. In light of these observations, developing more trustworthy LLMs remains an important task for future work.'}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': '3. “Was it expensive to run all these prompts on GPT-4? Is a normal user or a student able to run all these prompts? If you can mention this in the paper, that would be really appreciated.”\n\n- Thanks for your insightful questions! We have added details about computation and query costs in Appendix K in the revision following the suggestions. We also put a detailed analysis of costs below.\n\n- Table 1 summarizes the 1) total number of prompts, 2) total number of prompt tokens, 3) total number of completion tokens, and 4) total run costs for each trustworthiness perspective and each GPT model.\n\n*Table 1. Total computing costs of evaluation on different trustworthiness perspectives on GPT models*\n| Perspectives                                 | Models  | #/ Prompts | #/ Prompt Tokens | #/ Completion Tokens | Total Cost ($) |\n| -------------------------------------------- | ------- | ---------- | ---------------- | -------------------- | -------------- |\n| Toxicity                                     | GPT-3.5 | 49,200      | 10,966,554       | 15,796,800           | 78.14          |\n| Toxicity                                     | GPT-4   | 49,200      | 10,966,554       | 15,796,800           | 2158.97        |\n| Stereotype                                   | GPT-3.5 | 3,456       | 766,296          | 12,960,000           | 27.46          |\n| Stereotype                                   | GPT-4   | 3,456       | 766,296          | 12,960,000           | 800.58         |\n| Adversarial Robustness                       | GPT-3.5 | 42,755      | 3,596,216        | 684,080              | 9.30            |\n| Adversarial Robustness                       | GPT-4   | 42,755      | 3,596,216        | 684,080              | 162.23         |\n| OOD                                          | GPT-3.5 | 47,079      | 13,879,675       | 470,790              | 28.70           |\n| OOD                                          | GPT-4   | 47,079      | 13,879,675       | 470,790              | 444.64         |\n| Robustness against adversarial demonstration | GPT-3.5 | 233,100     | 152,882,443      | 322,259              | 306.41         |\n| Robustness against adversarial demonstration | GPT-4   | 233,100     | 144,558,043      | 256,140              | 4352.11        |\n| Privacy                                      | GPT-3.5 | 106,150    | 6,363,542        | 2,408,800            | 17.54          |\n| Privacy                                      | GPT-4   | 106,150    | 6,363,542        | 2,408,800            | 335.43         |\n| Machine Ethics                               | GPT-3.5 | 21,869     | 6,796,656        | 373,380              | 15.31          |\n| Machine Ethics                               | GPT-4   | 21,869     | 6,796,656        | 373,380              | 242.29         |\n| Fairness                                     | GPT-3.5 | 32,400     | 16,798,525       | 180,000              | 34.00             |\n| Fairness                                     | GPT-4   | 32,400     | 16,798,525       | 180,000              | 503.35         |\n\n- In addition, we further break down our evaluation for each perspective into detailed scenarios, and Table 46-53 in Appendix K show the similar computing and query costs for these detailed scenarios under different trustworthiness perspectives. Similarly, we report the 1) number of prompts for each scenario and GPT models, 2) number of tokens of the prompts, 3) number of completion tokens that answer the prompts, 4) single run cost of answering the prompts, 5) number of the run repetitions, and 6) total run cost. These tables also allow users to flexibly determine whether they want to run some subsets of the scenarios of each perspective based on their available resources.'}}, {'title': {'value': 'Thank you for your valuable comments'}, 'comment': {'value': 'We thank the reviewer for the valuable suggestions and comments! We are glad that the reviewer finds our paper providing a comprehensive evaluation, and conducting extensive experiments with profound analysis. We will provide detailed responses below.\n\n1. ""The details of the stereotype dataset should be in the paper not the appendix, this is important detail and if the appendix is separated later in the proceeding, it would be hard for the reader to follow. Fig.2 is a bit misleading without its illustration which is also in the appendix.""\n\n- Thank you for your valuable suggestions. We’ve followed the reviewer’s comments and added the details of the stereotype dataset (e.g., the selected stereotype groups and stereotype topics, and some examples of our user and system prompts) in the revision Section 3; we have also added illustrations to explain Fig 2 (i.e., the detailed meaning of the numbers in the cells and some findings). We have highlighted our revision in blue. Please let us know if there are further suggestions. Thank you!\n\n2. ""Out-of-distribution robustness should be illustrated in what perspective are we evaluating, that was not clear to me.”\n\n- Thank you for the valuable suggestion. Following the suggestion, we’ve added more explanations about what perspectives we aim to evaluate in the “goal” part in the revision Section 5. Specifically, For out-of-distribution robustness, we mainly focus on evaluating the robustness of GPT models under OOD instances that significantly deviate from the distribution of training or in-context demonstrations. \n\n- In particular, our study focuses on three perspectives: 1) OOD language style: evaluation of inputs with uncommon text styles (e.g., Bible style) that may fall outside the training or instruction tuning distribution, with the goal of assessing the robustness of the model when the input style is unusual. 2) OOD knowledge: evaluation of questions that can only be answered with knowledge after the training data was collected, which we aim to investigate the trustworthiness of the model’s responses when the queries are out of scope. 3) OOD in-context demonstrations: evaluation of how in-context demonstrations that are on purpose drawn from different distributions or domains from the test inputs can affect the final performance of GPT models. \n\n- We thank the reviewer for the constructive feedback, and we will leverage the additional page in the revision to add all the details and related discussions following the suggestions.'}}, {'title': {'value': 'An extensive study on Trustworthiness in GPT models '}, 'rating': {'value': '7: Good paper, accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'The paper presents a very intensive and extensive study on trustworthiness in GPT models, they are evaluating different perspectives of trustworthiness using different benchmarks. This is not mainly a benchmark paper but kind of papers we need to understand important perspectives in new models. This paper contributes to our understandings of how GPT models treat the toxic and trustworthiness prompts.'}, 'strengths': {'value': '1- different evaluation metrics and different capabilities of GPT models are evaluated relying on different standard benchmarks.\n2- a benchmark for toxiticity and trustworthiness is presented\n3- an extensive study for different aspects are presented with a profound analysis'}, 'opportunities_for_improvement': {'value': 'The details of the stereotype dataset should be in the paper not the appendix, this is important detail and if the appendix is separated later in the proceeding, it would be hard for the reader to follow.\nFig.2 is a bit misleading without its illustration which is also in the appendix. (hard to follow, either remove the parts, or add the illustration with it)\nout-of-distribution robustness should be illustrated in what perspective are we evaluating, that was not clear to me.\nIn general, the appendix contained many important information, which made the written harder to follow without. I know you want to keep all the info inside the 9 pages, but consider in the last version to keep it self-read and self-contained.\n'}, 'limitations': {'value': 'yes, the authors are adressing the potentail social impact by  their evaluation and study.'}, 'correctness': {'value': 'the submission and claims seem correct to me.'}, 'clarity': {'value': 'It is well written, the only point for me is that the authors want to compact all the experiments and results in the 9 pages, which sometimes leads to going to the appendix a lot and make it hard to follow. Other than that, the paper is very well presented and it is well organized.'}, 'relation_to_prior_work': {'value': 'Yes in the introduction, they are relating to the prior contributions and they are relying on many prior benchmarks in their studies.'}, 'documentation': {'value': 'They are providing a url which ahs all their code snippets and the datasets they used.'}, 'ethics': {'value': 'no, I do not suspect that.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'There is a concern or more as a question to the authors:\n- Was it expensive to run all these prompts on GPT-4?  is a normal user or a student able to run all these prompts? If you can mention this in the paper, that would be really apprecoated.'}}, {'title': {'value': 'Comprehensive evaluations of GPT 3.5 and GPT 4'}, 'rating': {'value': '7: Good paper, accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'The paper provides comprehensive evaluation of trustworthiness of GPT models across diverse aspects ranging from toxicity to adversarial robustness, to machine ethics and fairness, to privacy, and others. In total, the paper explores 8 evaluation dimensions. The evaluation is experimental and very thorough, with insightful takeaways. The dataset and evaluation scripts are released under permissive licenses and available.\n\n'}, 'strengths': {'value': 'Strengths:\n- The problem of systematic evaluation of trustworthiness is very important and somewhat urgent, this paper provides a valuable and timely contribution\n- The evaluation of every trustworthiness aspect of GPT models is very thorough and with detailed takeaways providing insight into the trustworthiness of GPT models and evaluating their robustness under potential misuse. The insights from this paper highlight opportunities for LLM improvement and areas where more research is needed to improve LLM trustworthiness.\n- the systematic trustworthiness evaluation benchmark is a valuable contribution in itself, in addition to the insights about GPT models\n- the dataset and evaluation scripts are released and available to the public under permissive license\n- the paper is very clear and enjoyable to read\n'}, 'opportunities_for_improvement': {'value': 'Weaknesses:\n- The paper only focuses on GPT models, however, those are proprietary models. It would be valuable to add evaluation of open-source models available to the general public and identify the most trustworthy open models.\n- While Figure 1 is excellent and the paper is easy to read, it lacks sufficient explanations of experimental setups for most sections of the main body and refers to appendix for crucial details and explanations central to the experimental setup. It would be great to provide necessary details in the main body and refer to appendix only for supplementary details. \n'}, 'limitations': {'value': 'Limitations are addressed in appendix'}, 'correctness': {'value': 'The paper is sound'}, 'clarity': {'value': 'The paper is very clear'}, 'relation_to_prior_work': {'value': 'Prior work is covered well'}, 'documentation': {'value': 'Yes, details on the dataset and evaluation scripts are provided in the supplement, on the website and on GitHub'}, 'ethics': {'value': 'I do not see any ethical concerns'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'Questions: \n- The total compute is not specified. Can you provide any metrics on how long it took to run the evaluation and how much compute resources were used (e.g. maybe in the form of the number of processed tokens by the OpenAI API)?'}}, {'title': {'value': 'Detailed analysis of current challenges in LLMs, with a thorough problem description.'}, 'rating': {'value': '10: Top 5% of accepted papers, seminal paper'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'The paper provides a comprehensive evaluation of the security, privacy, and trustworthiness of language models, with a focus on GPT-3.5 and GPT-4. It covers topics such as toxicity, stereotypes, adversarial robustness, and information leakage, among others. For each aspect, the authors provide a detailed explanation and introduction to the dataset used, tailored specifically to the analyzed task. The results are presented for various facets of each aspect and include multiple datasets.'}, 'strengths': {'value': 'In my opinion, the paper successfully identifies most of the important known threats and conducts thorough experiments using useful datasets. The threats are described comprehensively and highlight the current challenges of LLMs and you can clearly see that a lot of effort has been put into the paper and the benchmark itself.'}, 'opportunities_for_improvement': {'value': 'The paper does not specifically describe the benchmark framework. What makes it a benchmark? How easy is it to add new evaluation aspects?\n\nWhat are other attack vectors in case of, for example, whitebox access to a model? This is particularly important to evaluate a worst-case scenario.'}, 'limitations': {'value': 'The benchmark is not easy to extend without a lot of manual effort. Each method and dataset are manually selected or crafted. However, I can clearly see the difficulties here and appreciate the effort by the authors.\n\nThe evaluation is limited to two (recent) LLMs'}, 'correctness': {'value': 'The paper appears to be correct.'}, 'clarity': {'value': 'The paper is well-written and easy to follow.'}, 'relation_to_prior_work': {'value': 'The paper discusses significant related work.'}, 'documentation': {'value': 'The project is well documented and include a website, and detailed instructions and code for every aspect.'}, 'ethics': {'value': 'There are ethical aspects in the paper, but they are clearly indicated '}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'No additional feedback'}}, {'title': {'value': 'Thorough contribution with major concerns about the narrative and the level of details in the main text'}, 'rating': {'value': '7: Good paper, accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'The paper provides a comprehensive evaluation of the trustworthiness of recent large language models (LLMs), specifically GPT-3.5 and GPT-4. The authors examine various dimensions, including toxicity, stereotype bias, robustness, privacy, machine ethics, and fairness, and provide empirical findings on each. The paper highlights the new capabilities of LLMs to follow instructions and the potential concerns that arise from these capabilities. The findings are that GPT-4 is generally more trustworthy than GPT-3.5 but the authors also note instances where GPT-4 demonstrates higher toxicity than GPT-3.5. Overall, the paper aims to advance the field of LLMs by promoting the development of more reliable, unbiased, and transparent language models that meet the needs of users while upholding trustworthiness standards.'}, 'strengths': {'value': ""The contribution of this paper is a comprehensive assessment of the trustworthiness of GPT models, analysing a wide range of critical aspects. The authors present a thorough analysis of their benchmark methodology, designed to test the trustworthiness of LLMs, and apply their approach to two popular large language models that are already embedded in numerous products and services. The relevance of this study is heightened by the current context, where the safety and ethical implications of language models are currently under scrutiny.\n\nThe authors'  examination of various aspects of the GPT models is a crucial strength of the paper, making their findings valuable to the scientific community and beyond. Their approach and methodology are expected to be readily applied to other language models.""}, 'opportunities_for_improvement': {'value': 'The authors raised valid limitations concerning their work (Obscure pretraining data, subjectivity, specific focus on GPT models) that would deserve to appear in the main text with potential solutions to address them.\n\nOverall, my main concern is about the significant amount of detail in the the supplementary material. While I appreciate the thoroghness of the analysis, it may be challenging for readers to fully grasp the significance and the soundness of the contribution without a significant investment of time and effort. As a reviewer, I understand that authors may feel limited by page restrictions. Nonetheless, in this case, some key information that should be in the main text is relegated to the supplementary material. This approach raises two issues for me:\n1) insufficient detail in the main text to evaluate the scientific soundness;\n2) a weak narrative of the paper, as each subsection is only connected by the trustworthiness concept, which is a bit shallow. \n\nIn other words, the paper seems like a collection of tests for evaluating different aspects of trustworthiness, where each aspect is taken independently to the others. This is also visible in the Related works section, where each aspect is considered separately. If we fully extend this reasoning, each subsection (or maybe a group of subsections) could be a separate contribution.\n\nThis does not put into question the quality of the contribution, and potential approaches to address the concerns mentioned earlier include:\n1. Adopting a unified view to test different aspects jointly.\n2. Studying the interplay between the different perspectives and how they interact with each other.\n3. Discussing mitigation measures and exploring how they impact overall trustworthiness.\n4. Connecting this framework with legal requirements in current AI regulations.\n5. Expanding the benchmarking approach of the paper by testing other models, including open-source ones.'}, 'limitations': {'value': 'There is an important concern regarding the potential misuse of this work by malicious actors, who may use it to test the effectiveness of various strategies to bypass the safety mechanisms of language models. This possibility poses a risk for users of GPT-based systems. Despite this, my personal opinion is that the positive outcomes of publishing such frameworks outweigh the potential risks, as it facilitates scientific progress and allows for a deeper understanding of the field.\n\nHowever, given the possible negative consequences associated with such work, I believe it would be valuable for the paper to include a discussion of this aspect. Such a discussion could help readers understand the reasoning behind the decision to publish the work and encourage greater discussion and consideration of responsible AI research.'}, 'correctness': {'value': ""I have not noticed anything incorrect in the main text, but I haven't been into the (necessary) details of the supplementary material, and therefore cannot ensure that everything is scientifically sound.""}, 'clarity': {'value': 'The paper is well-written and clear.'}, 'relation_to_prior_work': {'value': 'This section is under-developed in the main text, and its inclusion in the Supplementary Material (where it is much more detailed) is not adequate.'}, 'documentation': {'value': 'It is not clear whether the contribution is meant to be a benchmark (i.e., software) or a dataset (i.e., text). From my understanding of the organisation of the repository, it seems to be the former, but there are several mentions of a dataset that are confusing (for instance, the presence of a data sheet in the supplementary material).\n\nOtherwise, the repository is well-organised and allows for reproducibility, even if the source code lacks proper documentation and comments that could make the re-use by other reseach groups relatively difficult. \n\nThe use of GPT 4 and 3.5 raises two significant concerns regarding reproducibility that should be addressed. Firstly, it is not clear whether the tested versions (which are dated ""March"" according to the Supplementary Material) will be accessible to researchers from external sources, as only latest versions are generally accessible. This issue raises doubts about whether or not these experiments can be successfully replicated by other researchers. Secondly, to the best of my knowlege, access to GPT models is not free. While this does not invalidate the approach, it is important that the cost of reproducing the results is mentioned in the paper to ensure transparency and make sure that the findings and reproducibility are accessible to the broader scientific community.'}, 'ethics': {'value': 'No specific ethical concerns found, beyond the potential use by malicious actors as discussed in section ""Limitations"".'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': ""While I have reservations about the contribution, I must concede that the paper  presents valuable insights and that the benchmark could be of interest to the community and beyond. Nonetheless, the concept of trustworthiness, which is a central theme throughout the paper, could benefit from greater emphasis and elaboration. In this regard, I feel that the narrative should be strengthened by expanding the discussion and introducing more unified views on the different persperctives, and/or thorough evaluation of different models beyond GPT models. Moreover, the current evaluation of the proposed framework is complex and presents several challenges. The lack of clarity and specificity in the evaluation methodology of the main text, makes it difficult to assess the soundness of the framework and its applicability in real-world scenarios. Based on these observations, I believe that further work is needed to improve the overall quality and relevance of the paper. The author should focus on refining their arguments, developing a more comprehensive evaluation methodology and providing more narrow messages.\n\n**Update after comments from authors**\n\nI changed my review from 5 to 7, following author's comments and revised version. See my comments below.""}}, {'title': {'value': 'Trustworthiness in GPT Models'}, 'rating': {'value': '7: Good paper, accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': ""This paper provides a comprehensive evaluation of the trustworthiness of two large language models (LLMs), GPT-3.5 and GPT-4, across a range of aspects including toxicity, stereotype bias, adversarial robustness, out-of-distribution robustness, adversarial demonstrations, privacy, machine ethics, and fairness. Its novelty lies in the thorough comparison of these two models and the identification of trustworthiness factors that affect the performance of these LLMs. This paper reveals that although GPT4 and GPT3.5 achieve superior performance on natural language benchmarks, they can be easily manipulated by adversarial attacks or hand-crafted toxic prompts.\n\nThis kind of paper is definitely needed in the NLP and LLM community. It's so important to get a clear understanding of how trustworthy these big language models are, and this paper does a great job of diving into that.\n""}, 'strengths': {'value': '1） The paper has comprehensive analysis of trustworthiness across multiple dimensions. This holistic approach gives us a better understanding of the LLMs’ performance and their potential vulnerabilities.\n\n2） This paper finds that GPT-4 is easier to manipulate due to its higher instruction-following capability, telling the community that we should also consider trustworthiness alongside performance in LLMs.\n\n'}, 'opportunities_for_improvement': {'value': 'It could benefit from a more explicit discussion of potential solutions or strategies to address the identified vulnerabilities in the LLMs.'}, 'limitations': {'value': ""When the paper shares examples of unsafe or private prompts, it could give people with bad intentions ideas on how to misuse these models. It might be a good idea for them to keep these specific prompts private and only share them if someone asks for them for research purposes. Balancing between being open in their research and avoiding potential misuse of the information is tricky, but it's something important the authors need to tackle.\n\nAlso, one question that arises from the paper's approach is the reliance on specific prompts to trigger trustworthiness issues in the LLMs. If the developers of these models were to correct the problems highlighted by these prompts, the revised models might appear more trustworthy and robust when re-evaluated using the same prompts. However, this may not necessarily mean the models have become 'truly' more trustworthy in a broader sense. It could just mean they have been optimized to pass these specific tests. Should the keep a private set of prompts to evaluate to ensure more robust testing? Or could there be an automated solution that continually generates new prompts to challenge the models?\n""}, 'correctness': {'value': 'The methodology appears to be sound. The paper clearly describes the metrics used to evaluate the models and the design of evaluations.'}, 'clarity': {'value': 'The paper is well-structured and clear.'}, 'relation_to_prior_work': {'value': 'Yes'}, 'documentation': {'value': 'Yes, a public github link is provided.'}, 'ethics': {'value': 'Please see limitation section.'}, 'flag_for_ethics_review': {'value': '1: Yes, there are significant ethics concerns'}, 'additional_feedback': {'value': 'NA'}}, {'title': {'value': 'DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models'}, 'authors': {'value': ['Boxin Wang', 'Weixin Chen', 'Hengzhi Pei', 'Chulin Xie', 'Mintong Kang', 'Chenhui Zhang', 'Chejian Xu', 'Zidi Xiong', 'Ritik Dutta', 'Rylan Schaeffer', 'Sang T. Truong', 'Simran Arora', 'Mantas Mazeika', 'Dan Hendrycks', 'Zinan Lin', 'Yu Cheng', 'Sanmi Koyejo', 'Dawn Song', 'Bo Li']}, 'authorids': {'value': ['~Boxin_Wang1', '~Weixin_Chen1', '~Hengzhi_Pei1', '~Chulin_Xie1', '~Mintong_Kang1', '~Chenhui_Zhang2', '~Chejian_Xu1', '~Zidi_Xiong2', '~Ritik_Dutta1', '~Rylan_Schaeffer2', '~Sang_T._Truong1', '~Simran_Arora1', '~Mantas_Mazeika3', '~Dan_Hendrycks1', '~Zinan_Lin1', '~Yu_Cheng1', '~Sanmi_Koyejo1', '~Dawn_Song1', '~Bo_Li19']}, 'keywords': {'value': ['trustworthiness evaluation', 'GPT models', 'GPT-3.5', 'GPT-4', 'toxicity', 'stereotypes', 'bias', 'adversarial robustness', 'out-of-distribution robustness', 'privacy', 'ethics', 'fairness']}, 'TLDR': {'value': 'We propose a comprehensive trustworthiness evaluation for large language models considering diverse perspectives – including toxicity, stereotype bias, robustness,  privacy, machine ethics, and fairness.'}, 'abstract': {'value': 'Generative Pre-trained Transformer (GPT) models have exhibited exciting progress in capabilities, capturing the interest of practitioners and the public alike. Yet, while the literature on the trustworthiness of GPT models remains limited, practitioners have proposed employing capable GPT models for sensitive applications to healthcare and finance – where mistakes can be costly. To this end, this work proposes a comprehensive trustworthiness evaluation for large language models with a focus on GPT-4 and GPT-3.5, considering diverse perspectives – including toxicity, stereotype bias, adversarial robustness, out-of-distribution robustness, robustness on adversarial demonstrations, privacy, machine ethics, and fairness. Based on our evaluations, we discover previously unpublished vulnerabilities to trustworthiness threats. For instance, we find that GPT models can be easily misled to generate toxic and biased outputs and leak private information in both training data and conversation history. We also find that although GPT-4 is usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more vulnerable given jailbreaking system or user prompts, potentially due to the reason that GPT-4 follows the (misleading) instructions more precisely. Our work illustrates a comprehensive trustworthiness evaluation of GPT models and sheds light on the trustworthiness gaps. Our benchmark is publicly available at https://decodingtrust.github.io/.'}, 'venue': {'value': 'NeurIPS 2023 Datasets and Benchmarks Oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Track/Datasets_and_Benchmarks'}, 'pdf': {'value': '/pdf/caa1e2c3affb6458c77ba18772f7b7f6021810cb.pdf'}, 'supplementary_material': {'value': '/attachment/86d4ad242da9ee3171f5f302ad989f043972b204.zip'}, '_bibtex': {'value': '@inproceedings{\nwang2023decodingtrust,\ntitle={DecodingTrust: A Comprehensive Assessment of Trustworthiness in {GPT} Models},\nauthor={Boxin Wang and Weixin Chen and Hengzhi Pei and Chulin Xie and Mintong Kang and Chenhui Zhang and Chejian Xu and Zidi Xiong and Ritik Dutta and Rylan Schaeffer and Sang T. Truong and Simran Arora and Mantas Mazeika and Dan Hendrycks and Zinan Lin and Yu Cheng and Sanmi Koyejo and Dawn Song and Bo Li},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\nyear={2023},\nurl={https://openreview.net/forum?id=kaHpo8OZw2}\n}'}, 'paperhash': {'value': 'wang|decodingtrust_a_comprehensive_assessment_of_trustworthiness_in_gpt_models'}}]"
"['Zhongjie Yu', 'Martin Trapp', 'Kristian Kersting']",NeurIPS,Characteristic Circuits,https://neurips.cc/virtual/2023/oral/73875,2023," In many real-world scenarios it is crucial to be able to reliably and efficiently reason under uncertainty while capturing complex relationships in data.  Probabilistic circuits (PCs), a prominent family of tractable probabilistic models, offer a remedy to this challenge by composing simple, tractable distributions into a high-dimensional probability distribution.   However, learning PCs on heterogeneous data is challenging and densities of some parametric distributions are not available in closed form, limiting their potential use.   We introduce characteristic circuits (CCs), a family of tractable probabilistic models providing a unified formalization of distributions over heterogeneous data in the spectral domain.  The one-to-one relationship between characteristic functions and probability measures enables us to learn high-dimensional distributions on heterogeneous data domains and facilitates efficient probabilistic inference even when no closed-form density function is available.   We show that the structure and parameters of CCs can be learned efficiently from the data and find that CCs outperform state-of-the-art density estimators for heterogeneous data domains on common benchmark data sets.",Oral 1C Tractable models,https://openreview.net/pdf?id=5W7cXno10k,https://openreview.net/forum?id=5W7cXno10k,5W7cXno10k,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper proposes a great new member of the probabilistic circuit family, representing characteristic polynomials. It might turn out to be a seminal paper in modeling tractable distributions.'}}, {'comment': {'value': ""Thank you for taking your time to answer the questions. I look forward to reading more about the connections between MLE and minimizing CFD in an updated version of the paper. I'm in favor of accepting this paper.""}}, {'comment': {'value': ""I would like to thank the authors for the clarification. I'm happy to raise my score.""}}, {'comment': {'value': 'Thank you very much for detailed reply. I think the comparison of probabilistic generating circuits and characteristic circuits is adequately addressed in the rebuttal comment.\nRegarding the tractability of queries, I agree with Reviewer HuCd in that the sampling is one of the most important query that PCs can do. However, I think that even if sampling is generally difficult for CCs, the other parts of the paper (concepts, comparison with PCs, and the empirical results) can constitute significant technical contributions. Thus, I am in favor of accepting this manuscript.'}}, {'comment': {'value': ""Many thanks for your clarifications. I further confirm the positive impression I had, and I'll keep supporting the paper. However, I'd stick to my score: I would have raised my score if sampling had been possible in CCs (at the very least, it's unclear if it is going to be).\n""}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the feedback and questions.\n\n> Key difference between CCs and PCs:\n - PCs do not naturally lend themselves to a unified view over heterogeneous data domains, while CCs more naturally provide a framework to model high-dimensional mixed data distributions. To highlight this, recall that PCs are formulated over density/mass functions which is the Radon–Nikodym derivative w.r.t. some base measure. In heterogeneous domains, the relationship to the base measure becomes involved as dimensions might have a density w.r.t. different base measures. This fact is typically hidden in PCs and results in challenges when learning such models over heterogeneous data domains as, for example, gradient-based parameter learning will now depend on different base measures depending on the dimensions considered. This can result in undesirable behaviour and is elevated, for example, in MSPNs by discretizing the continuous domain, hence, ensuring the same base measure for all dimensions. However, discretization introduces challenges going beyond this rebuttal. CCs, on the other hand, evaluate this problem in a more principled way by instead modelling the Fourier transform of the probability measure directly. This makes the learning and modelling process independent of the base measure and provides a truly unified view compared to PCs. We hope that this expose better explains the conceptual difference between CCs and PCs.\n\n> Expressiveness and tractable queries:\n - We agree that investigating the expressive efficiency and tractability of CCs is an interesting avenue. Although not discussed in detail in the paper, the moments of any CC can be computed tractably through differentiation given that the leaf nodes allow tractable differentiation. Even though the current work focuses on a unified view by moving to the spectral domain, we believe this to be a particularly useful property and added further details to the updated manuscript. We leave a theoretical analysis of the expressive efficiency of CCs for future work.\n\n> Proof of marginal computation:\n - A proof sketch of marginalization is given in lines 221 to 225 and we will add a more detailed proof in the appendix. \n - Proof sketch: \nFollowing lines 216 to 225, we have assumed that the circuit decomposes all dimensions into univariate leaves, RVs $Z = X \\cup Y$, $t = t_X \\cup t_Y$, and we aim to compute $\\varphi_X(t_X)$.  \nThen for any leaf node, we have \n$\\varphi_L(t_j) =  1$ if $ t_j = 0$, and  $\\varphi_L(t_j)$ otherwise, by definition of CFs.    \nLet $P$ be a product node that splits at least one $Y_j$ from its scope into a single child and let this child be denoted as $N_j$, then   \n$\\varphi_P(t \\cup 0) = \\varphi_{N_j}(0) \\prod_{N \\in ch(P)\\setminus{N_j}} \\varphi_{N}(t_{\\psi(N)}) = \\varphi_{P\\setminus{N_j}}(t)$,  \nwhere $\\varphi_{N_j}(0)=1$.\nBy the assumption that sum nodes are convex combinations (weights sum up to one) and recursive application of the above, one can show that any marginal distribution can be obtained tractably in CCs.\n\n> Choice of CC over PC:\n\n - There are various tasks in which CCs are preferable over PCs. In particular, as outlined before, CCs provide a more principled and natural representation in the case of heterogeneous data domains. Moreover, CCs enable the modeling and learning of distributions that do not have an analytical density function. Lastly, CCs provide an efficient representation of moments even in case densities are not available in closed form as CCs circumvent the challenge of integration in this case and instead only require differentiation of the model.\n\n> $\\alpha$-stable distribution leaves and MSPNs:\n\n - We agree that studying the combinations of MSPNs and CCs is an interesting direction. Henceforth, we will provide additional results using MSPNs as a construction algorithm for the CC structure. However, we want to stress that MSPNs and CCs are conceptually very different as MSPNs aim to model heterogeneous domains non-parametrically through discretization, while CCs directly model the characteristic function of the mixed distribution. Therefore, CCs provide a more flexible framework and allow for meaningful parameter learning that is more suited to mixed data domains. Moreover, we want to note that we empirically observed improvements by fitting CCs (work in the spectral domain) also in the case $\\alpha$-stable distribution has not been employed, see results CC-P in Tab. 2, indicating that CCs are a promising modeling family even if tractable densities exist.\n\n\n\n\n\n\n'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for pointing out both the strength and possible weakness of our work. \n\n> Inappropriate structure can limit the modelling power:\n\n - Similar to related modelling families (e.g., PCs, PGCs), the structure can have a high impact on the performance of the CC. To mitigate this issue, we proposed the first structure learning algorithm adapted from the well-known algorithm by [Gens and Pedro, 2013] for PCs. Note that structure learning of circuits (PCs, CCs alike) is a challenging and open task and further investigation is needed. However,  an approach similar to the one taken in Einsum networks [Peharz et al. 2020] combined with minimization of the CFD could be a promising future direction.   \n\n> Reliability of numerical integration:\n\n - We ran additional experiments with an increasing number of sample points to verify the reliability of the numerical integration through quadrature. The results indicate that a low number of sample points is sufficient as numerical integration is only required on the real line (1D). We thank the reviewer for pointing this out and will include the results into the Appendix and add further discussion on the reliability of the numerical integration. \n\n> Sampling:\n\n - Sampling from a characteristic function is generally not straightforward. There has been literature discussing sampling from CFs [Devroye, 1986, Ridout, 2009, Walker, 2017] and we believe these sampling algorithms can be adapted to sampling from CC in future works. Thanks for pointing this out, we will add this to the discussion of interesting future work.\n\n> Unified view:\n\n - PCs do not naturally provide a unified view and treat discrete and continuous RVs differently. For discrete RVs probabilities or mass values are computed w.r.t. the  counting measure, while for continuous RVs the reference measure is the Lebesgue measure. Moreover, RVs distributed according to a singular (continuous) distribution can typically not be represented at all. This dependence on the base measure is hidden in PCs and can result in challenges when it comes to learning these models in heterogeneous domains. For example, a model might focus only on maximizing the likelihood w.r.t. the Lebesgue measure during fitting. Consequently, prior works have suggested discretising the domain of continuous RV (see MSPNs), which introduces new challenges. Moving away from the dependence on the base measure by representing the distribution through its characteristic function, which is independent of the base measure, elevates this issue. Hence, CCs provide a truly unified view compared to PCs. We will clarify the “unified view” in the revised paper to better reflect our contribution.\n\n> MLE at the root and at a leaf node:\n\n - In parameter learning, maximizing the likelihood at the root of a CC needs to apply the inversion theorem to CC for each training data. When leaf nodes do not have a closed-form density function, numerical integration has to be employed to obtain the density value given data. This makes the MLE at the root not guaranteed to be tractable. \n - We thank the reviewer for raising this interesting question about the relationship between minimizing the distance and MLE, which is similar to the question from reviewer 1MK1. Connections between maximum likelihood estimation (MLE) and minimizing a distance (e.g., the CFD) to the empirical characteristic function (ECF) is indeed an interesting question. Minimizing the CFD to the ECF can be beneficial if no tractable form of the likelihood exists but the characteristic function can be tractably evaluated. As discussed in prior works (e.g., In [Yu, 2004]), minimizing a distance function to the ECF is most related to moment-matching approaches, but can result in more accurate fitting results. We will add further detail and a discussion on the topic to the revised version. \n - Creating leaf nodes in structure learning. Leaf nodes are created by fitting the estimated distribution to local data during structure learning. When closed-form density/mass function is available at a leaf, the leaf parameters can be estimated via MLE. In the case of ECF leaves, the leaf nodes are created from local data following the definition of ECF (in line 134). When there is no closed-form density, e.g. $\\alpha$-stable distributions, the algorithm in [McCulloch, 1986] is employed to estimate the parameters at the $\\alpha$-stable leaves. We apologise that we did not specify this detail in the manuscript and will add the above to lines 248-250 for better clarification.  \n\n> Minors:\n - Induced trees notation: Thanks for pointing this out, we will add one section in the Appendix to briefly introduce the notation of induced trees.\n - Indeed there is no x in the definition of the characteristic function at the leaf, because a characteristic function is a function of t, as illustrated in Eq (1).\n***\n[Gens and Pedro, 2013] Robert Gens and Domingos Pedro. ""*Learning the structure of sum-product networks.*"" In ICML, 2013.  \n[Peharz et al. 2020] Robert Peharz et al. ""*Einsum networks: Fast and scalable learning of tractable probabilistic circuits.*"" In ICML, 2020.  \n[Devroye, 1986] Luc Devroye, ""*An automatic method for generating random variates with a given characteristic function.*"" SIAM journal on applied mathematics, 1986.  \n[Ridout, 2009] Martin S Ridout. ""*Generating random numbers from a distribution specified by its Laplace transform.*"" Statistics and Computing, 2009.  \n[Walker, 2017] Stephen G Walker. ""*A Laplace transform inversion method for probability distribution functions.*"" Statistics and Computing, 2017.  \n[Yu, 2004] Jun Yu. ""*Empirical characteristic function estimation and its applications.*"" Econometric reviews, 2004.  \n[McCulloch, 1986] J. Huston McCulloch. ""*Simple consistent estimators of stable distribution parameters.*"" Communications in statistics-simulation and computation, 1986.\n\n'}}, {'rebuttal': {'value': 'We thank the reviewer for the feedback and the suggested related work. \n\n> Comparison to PGCs\n\n - Indeed, PGCs are related to CCs as both can be considered to represent the probability distribution using its generating function rather than its density function. We added a discussion and further details on how the two approaches relate to the updated manuscript. The key difference between PGCs and CCs is that, while PGCs can only represent discrete probability distributions that admit a probability generating function representation (finite countable), CCs can represent any probability distribution as every probability measure has an associated characteristic function. Interestingly, compared to directly modeling the density/mass function of a distribution, we can perform model fitting even in cases where a density w.r.t. the Lebesgue or counting measure does not exist or is not tractable to evaluate by minimizing the CFD to the empirical characteristic function. \n\n> Are there any other tractable queries for characteristic circuits? \n\n - Although not discussed in detail in the paper, the moments of any CCs can be computed tractably through differentiation. Even though the current work focuses on a unified view by moving to the spectral domain, we believe this to be a particularly useful property and added further details to the updated manuscript. \n - Sampling from a characteristic function is generally not straightforward. There has been literature discussing sampling from CFs [Devroye, 1986, Ridout, 2009, Walker, 2017] and we believe these sampling algorithms can be adapted to sampling from CCs in future works. We thank the reviewer for pointing this out and will add a discussion to the manuscript.\n***\n[Devroye, 1986] Luc Devroye, ""*An automatic method for generating random variates with a given characteristic function.*"" SIAM journal on applied mathematics, 1986.  \n[Ridout, 2009] Martin S Ridout,. ""*Generating random numbers from a distribution specified by its Laplace transform.*"" Statistics and Computing, 2009.  \n[Walker, 2017] Stephen G Walker. ""*A Laplace transform inversion method for probability distribution functions.*"" Statistics and Computing, 2017.\n'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the feedback and questions. \n\n> How is the probability measure encoded as a CF?\n\n - The characteristic function of a probability measure is its Fourier transform and, hence, can be obtained through the application of the Fourier transform. However, in our work, we do not start from the probability measure but directly model the characteristic function instead. This allows us to implicitly learn any probability measure by instead learning its spectral form. We refer to [Sasv&#225;ri, 2013] for a more detailed discussion. \n\n> Details on the empirical evaluations:\n\n - The likelihoods in the empirical evaluations are computed based on the inversion theorem. For discrete leaves and Gaussian leaves, the likelihoods can be computed analytically. While for $\\alpha$-stable leaves, the likelihoods are computed via numerical integration using quadrature. In general, it depends on the form of the characteristic function that is assumed at the leaf nodes. For example, one might relax the assumption that it is specified by a parametric family and could learn the characteristic functions directly. However, doing so is more involved as one has to ensure that the properties listed in Section 3.2. are still fulfilled. We believe this to be a promising future avenue. Once likelihoods at the leaves are computed, they are propagated bottom up following the inversion theorem in Section 4.1. We will improve the description in the updated manuscript.\n\n> Acronyms:\n\n - We will reduce the use of acronyms (RS, SL, etc.) in the updated manuscript for better readability and thank the reviewer for pointing this out. \n\n> Regarding the question on the relationship between CFD and likelihood:\n\n - Connections between maximum likelihood estimation (MLE) and minimizing a distance (e.g., the CFD) to the empirical characteristic function (ECF) is indeed an interesting question. Minimizing the CFD to the ECF can be beneficial if no tractable form of the likelihood exists but the characteristic function can be tractably evaluated. As discussed in prior works (e.g., [Yu, 2004]), minimizing a distance function to the ECF is most related to moment-matching approaches, but can result in more accurate fitting results. An interesting future direction could be a hybrid objective in which tractability of either the likelihood function or the characteristic function is exploited. We thank the reviewer and will add further detail and a discussion on the topic to the revised version. \n***\n[Sasv&#225;ri, 2013] Zolt&#225;n Sasv&#225;ri. ""*Multivariate characteristic and correlation functions.*"" volume 50. Walter de Gruyter, 2013.  \n[Yu, 2004] Jun Yu. ""*Empirical characteristic function estimation and its applications.*"" Econometric reviews, 2004.\n'}}, {'summary': {'value': 'This paper studies the use of characteristic functions as probabilistic models for heterogeneous data and proposes characteristic circuits (CC) for their representations. The authors propose efficient algorithms for computing (marginal) densities with CCs and show that parameters of CCs can be learned by minimizing the CFD between CC and ECF. The authors also show that CCs achieve strong performance not only on synthetic data but also on some commonly used density estimation benchmarks. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'To the best of my knowledge, the use of characteristic functions as a new language for probabilistic modeling, especially as a unified framework for heterogeneous data, is very novel. The empirical results is also very strong. I believe this work opens a brand new avenue for density estimation.'}, 'weaknesses': {'value': 'As a non-expert, I spent a lot of time on the background section; despite the uniqueness part in the inversion theorem, it is not completely intuitive how a probability measure is encoded as its characteristic function. It would be helpful if the authors could provide at least one simple example.\n\nAuthors use too many acronyms throughout the paper, especially in Section 5; it is not easy for me as a reader to distinguish between CC-N, RS, SL, CFD and etc. \n\nFor non-expert readers like me, more details on the empirical evaluations (in the main paper) could be helpful: e.g. how are the likelihoods measured for the heterogeneous datasets? are they computed via numerical integrations? etc.'}, 'questions': {'value': 'In Section 4.2, the authors proposes to do parameter learning by minimizing the CFD between CC and ECF because the likelihood of CC is not guaranteed to be tractable. Yet I wonder if it is possible to discuss the relationship between CFD and likelihood.'}, 'limitations': {'value': 'The structure learning algorithm seems more of an adaptation of the existing structure learning algorithms for SPNs. This is not a major issue as structure learning of circuits has been a very challenging problem and probably not a main focus of this work.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This manuscript proposes a framework for directly representing characteristic function of random variables by a probabilistic circuit-like structure. Unlike the ordinal probabilistic networks, the proposed framework, characteristic circuits, can treat distributions that do not have closed-form expressions for the density, or even marginals of discrete and continuous random variables. This is because the characteristic function provides a unified view for both discrete and continuous random variables. As a result, the characteristic circuit can treat broader class of distributions than the ordinal probabilistic circuits. Despite this, it is proved that the characteristic circuit keeps tractability of computing densities and marginals, which is an important query for probabilistic inference. Also, the parameter and circuit-structure learning algorithms for characteristic circuits are given. The experiments showed that the proposed characteristic circuits perform well for density estimation task on heterogeneous data sets, which includes both discrete and continuous variables.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'I think that representing a characteristic function by a circuit is a simple yet strong idea for representing broader class of distributions. Also, proposing an algorithm for computing marginals on characteristic circuits is really good, because it inherits the strengths of the original probabilistic circuits that some rich inference queries are tractable in time proportional to the size of the circuit; although it only proves the marginal query, I think this query is one of the most important one for probabilistic inference. The experimental results truly support the usefulness of characteristic circuits when applied to density estimation task where the evaluation metric is the test log-likelihood. Since the original probabilistic circuits also show their strengths in this task, I think the selection of tasks is appropriate.'}, 'weaknesses': {'value': 'It is not the first attempt to represent a generating function regarding random variables directly; the first one (as far as I know) is:\nProbabilistic Generating Functions https://arxiv.org/abs/2102.09768 (published in ICML 2021).\nThis represents the probability generating function directly, thus I think this framework is for discrete variables only. However, to clearly show the standing position of this paper, the comparison with this work should be clearly done in the main article.'}, 'questions': {'value': 'Within the queries that are tractable for the ordinal probabilistic circuits, are there any other tractable queries than marginal for characteristic circuits? Or, are there any queries that is proven to be hard (e.g., NP-complete) for characteristic circuits?'}, 'limitations': {'value': 'I think the authors adequately addressed the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper introduces characteristic circuits (CCs), a new family of tractable probabilistic models (TPMs) that leverages univariate characteristic functions as leaves of probabilistic circuits (PCs) for modelling a tractable joint of heterogeneous data distributions (i.e. with both continuous and discrete variables).\nCCs model the characteristic function of the data distribution in the continuous spectral domain (cf. Equation 1), thus providing a unified framework for discrete and continuous random variables.\nAs a consequence, one of the main advantage of CCs is that they can model distributions that do not have closed-form probability density functions, such as $\\alpha$-stable distributions.\nImportantly, authors also show that CCs allow exact and efficient computation of joint and marginal probabilistic queries.\nCCs are evaluated on two synthetic datasets and 12 heterogeneous real-world tabular datasets.\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The research is definitely original as it proposes a new class of TPMs with many (novel) benefits\n- The model naturally lends itself to modelling heterogeneous data\n- The model allows to use distributions that do not have closed-form expressions, such as $\\alpha$-stable distributions, something that is not possible in current PCs\n- Despite having input units with no closed-form expressions, CCs can still deliver exact marginalisation \n\nOverall, a solid contribution.\n\n'}, 'weaknesses': {'value': ""- From experiments, it looks like inappropriate structure can limit the modelling power of CCs. This is can prevent using CCs when a good structure is not available.\n- It's unclear how reliable/precise numerical integration can be (lines 128-129-130)\n- Sampling it's an important inference routine of PCs yet it is not discussed at all, and it's unclear if CCs can provide it""}, 'questions': {'value': '- Is sampling possible from CCs? If yes, can we know how CC samples compare with the ones of standard PCs? If not, what are the challenges?\n- Can you elaborate a bit more on what precisely you mean with ""unified view for discrete and continuous random variables"" (line 57)? While, to some extent, I understand what author mean, one may think ""but even standard PCs can handle heterogeneous data"". I think being more precise here can improve this major selling point of the paper.\n- Can you elaborate a bit more on lines 230-231-232? Why MLE is not tractable? How does Eq. 14 relate to MLE? (Also lines 248-249-250 are unclear to me)\n'}, 'limitations': {'value': ""Limitations are not explicitly addressed.\nIt looks like sampling can be one of these.\n\nMinors:\n- In Lemma 4.2, I think there's no explanation of what $\\tau$ and $E(\\mathcal{T}_i)$ represent. I know it's notation related to induced trees, but it is not introduced in the text.\n- In line 175, there's no $x$ occuring in the definition of $\\phi_{L_\\text{Normal}}(t)$, why?""}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work proposes a new tractable probabilistic model called characteristic circuits or CC. The CC is defined in a similar way to probabilistic circuits (PCs) but with leave nodes defined as characteristic functions instead of the distributions as in PCs. The authors further show the computation of marginals and the learning algorithms for CC. Empirical evaluations on both synthetic datasets and UCI datasets are presented.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': '- This paper is generally well-written, with sufficient backgrounds provided to help readers understand the proposed new model.\n- The authors show that CC shares the same efficient marginal computations as in PCs.\n- CC provides a unified view for mixed continuous and discrete distributions. Also, the \\alpha-stable distributions are less explored in the previous literature of tractable probabilistic models to my knowledge and the use of these seems help deliver good performance in the UCI experiments.'}, 'weaknesses': {'value': ""- From what is presented, it seems that the authors simply rewrite the distribution nodes and computations of PCs into their characteristic function duals. It is unclear what are the key differences between CC and PCs and when would one prefer one over the other. I don't think the unified view of the discrete and continuous distributions serves as a strong motivation since mixed SPN can also handle the mixed distributions.\n- To further illustrate the previous point, one would expect to see investigations on expressiveness, such as are there any distributions that can be tractably represented by CCs but not PCs, or investigations on tractable operations, such as what probabilistic queries would be intractable for PC but tractable for CC, while none of these are discussed in this work.\n- A proof for the validity of the marginal computations seems to be missing.""}, 'questions': {'value': '- Can the authors elaborate on the motivation for CCs, that is, when one would prefer CC over PC?\n- Can the authors provide some discussions on the expressiveness and tractable queries of CC?\n- For the empirical results on UCI datasets, I wonder if the improvements are from CC itself or from the alpha-stable distributions. What would happen if the continuous leaves in MSPN are defined as alpha-stable distributions? Such an ablation study might make the results more convincing.'}, 'limitations': {'value': 'Yes.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'I am not qualified to review this paper.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'I am not qualified to review this paper.'}, 'weaknesses': {'value': 'I am not qualified to review this paper.'}, 'questions': {'value': 'I am not qualified to review this paper.'}, 'limitations': {'value': 'I am not qualified to review this paper.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '10: Award quality: Technically flawless paper with groundbreaking impact, with exceptionally strong evaluation, reproducibility, and resources, and no unaddressed ethical considerations.'}, 'confidence': {'value': '1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Characteristic Circuits'}, 'authors': {'value': ['Zhongjie Yu', 'Martin Trapp', 'Kristian Kersting']}, 'authorids': {'value': ['~Zhongjie_Yu2', '~Martin_Trapp2', '~Kristian_Kersting1']}, 'keywords': {'value': ['Characteristic Circuit', 'Characteristic Function', 'Probabilistic Circuit', 'Heterogeneous Data', 'Density Estimation']}, 'TLDR': {'value': 'Characteristic circuit is a deep probabilistic model over characteristic functions that enables a unified view for discrete and continuous random variables and allows to learn distributions that do not have closed form expressions for their density.'}, 'abstract': {'value': 'In many real-world scenarios it is crucial to be able to reliably and efficiently reason under uncertainty while capturing complex relationships in data.\n  Probabilistic circuits (PCs), a prominent family of tractable probabilistic models, offer a remedy to this challenge by composing simple, tractable distributions into a high-dimensional probability distribution. \n  However, learning PCs on heterogeneous data is challenging and densities of some parametric distributions are not available in closed form, limiting their potential use. \n  We introduce characteristic circuits (CCs), a family of tractable probabilistic models providing a unified formalization of distributions over heterogeneous data in the spectral domain.\n  The one-to-one relationship between characteristic functions and probability measures enables us to learn high-dimensional distributions on heterogeneous data domains and facilitates efficient probabilistic inference even when no closed-form density function is available. \n  We show that the structure and parameters of CCs can be learned efficiently from the data and find that CCs outperform state-of-the-art density estimators for heterogeneous data domains on common benchmark data sets.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/1b14fc713133ee79da3bc17eebb9f14a63a02e04.pdf'}, 'supplementary_material': {'value': '/attachment/2446f7a8dc485c31615fd77e147c1ab4793ad044.zip'}, '_bibtex': {'value': '@inproceedings{\nyu2023characteristic,\ntitle={Characteristic Circuits},\nauthor={Zhongjie Yu and Martin Trapp and Kristian Kersting},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=5W7cXno10k}\n}'}, 'paperhash': {'value': 'yu|characteristic_circuits'}}]"
"['Niklas Muennighoff', 'Alexander Rush', 'Boaz Barak', 'Teven Le Scao', 'Nouamane Tazi', 'Aleksandra Piktus', 'Sampo Pyysalo', 'Thomas Wolf', 'Colin Raffel']",NeurIPS,Scaling Data-Constrained Language Models,https://neurips.cc/virtual/2023/oral/73832,2023," The current trend of scaling language models involves increasing both parameter count and training dataset size. Extrapolating this trend suggests that training dataset size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity, including augmenting the training dataset with code data or removing commonly used filters. Models and datasets from our 400 training runs are freely available at https://github.com/huggingface/datablations.",Oral 2A Efficient Learning,https://openreview.net/pdf?id=j5BuTrEj35,https://openreview.net/forum?id=j5BuTrEj35,j5BuTrEj35,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper presents a valuable investigation into the scaling of language models in data-constrained regimes, offering insights into the optimal use of compute resources and potential approaches for mitigating data scarcity. The authors conducted a large set of experiments and proposed a scaling law for compute optimality, which was empirically validated. The provision of trained models and datasets used in the experiments for public access adds to the value of this paper. Overall, this work is a very solid contribution to the communnity in pretraining of LLMs.'}}, {'comment': {'value': 'Thank you for updates and answer about the question. I raised my score after reading the rebuttal.'}}, {'comment': {'value': 'Thank you for the clarifications, I am happy with the responses.'}}, {'title': {'value': 'Response'}, 'comment': {'value': ""> If you have specific suggestions, we are open to revising the text based on them.\n\nI guess my (lazy) suggestion is just arxiv'ing a longer (8+) pages :)""}}, {'rebuttal': {'value': 'We thank all reviewers for their thorough reviews. We have made the following updates to the paper:\n\nIncreased the scale of the models in the first plot (right) showing even more significant results in support of scaling data faster than parameters when repeating (also in terms of downstream performance shown in a table in the Appendix). As we cannot upload a new version of the paper, we’re attaching the plot and table to this message.\n\nAdded several new Appendix sections:\n- Appendix G: Case study on how Galactica should have allocated compute according to data-constrained scaling laws\n- Appendix K: Details on how loss is computed, how scores are normalized and smoothing for the graphs\n- Appendix P: Loss curves of complementary strategies\n\nImproved several Appendix sections:\n- Appendix A: More details on the calculation of $U_N$ and comparison of different fits and their loss and $R^2$\n- Appendix F: Added experiments on an alternative formulation to let excess parameters hurt performance by decaying alpha and beta\n- Appendix I: Fixed one loss plot for OSCAR\n- Appendix Q: Added hyperparameter sensitivity as a new limitation\n- Appendix R: Specified some more hyperparameters\n\nRephrased several sentences throughout and fixed typos.\n\nWe agree with the overall sentiment expressed by the reviewers that there are many exciting related research questions, such as behavior at hundreds of billions of parameters and trillions of tokens, different datasets beyond C4 and OSCAR and data-constrained scaling laws during finetuning. We look forward to answering these together with the broader research community in future work.\n'}, 'pdf': {'value': '/pdf/28bb725641494e45c5caaf8ab528ebc804b5690a.pdf'}}, {'rebuttal': {'value': 'Thank you for your thorough review. \n\nWeaknesses:\n\n> There is something unclear about using the validation or the test loss. The authors say (#42) that they are reporting test loss, but many of the tables and graphs say that they are showing validation loss. Which one is it? Reporting test loss is a problem, as it might lead to overfitting the test data (e.g., by others who want to adapt the proposed recipes).\n\nWe are sorry for the lack of clarity. We have rephrased the mention of test loss to “we report loss on a held-out test set unless otherwise specified”. In the main text, only Figure 4 reports validation loss throughout training instead. We have also added a detailed explanation of how loss is computed in a new section Appendix K “Evaluation Details”. We are not sure why reporting the test loss would be a problem. We are using a fully held-out dataset and compute the loss over it for each model at the end of training. Apart from loss, we also show that our findings are mirrored in downstream performance in the Appendix. Given that all our models will be open-sourced, future work can also run them and compute loss on their own datasets if desired.\n\n\n> The loss differences are often very small. E.g., in Fig1 (right), a difference of 0.006, or in Fig5 (left). Are these results significant?\n\nWe have updated Fig1 (right) to larger models with 8.67B and 6.34B parameters. The loss difference for that setup is 0.017. At these scales, loss decreases very slowly, for example for the 8.67B model, its last 5,000 steps ($\\approx$10B tokens) correspond to about a 0.017 loss decrease. Thus, we consider it to be significant. We have also added downstream performance of these two models in the Appendix. Across our 19 downstream evaluation tasks, the 6.34B model has an average score of 25.9, while the 8.7B model scores 23.5. This reinforces our findings that data should be scaled faster than parameters in the repeated regime.\n\nQuestions:\n\nWe are sorry for the confusion. We meant to say that if we have e.g. 10B unique tokens, those same 10B unique tokens are also a subset of every setup where we have >10B unique tokens. This ensures that as much as possible of the data is shared across runs and our results are not impacted by simply having trained on a better data subset. We have rephrased the caption of that Figure as “We ensure that runs using less data (more epochs) always use a subset of the data used in runs with more data (fewer epochs).”.\n\n\nTypos:\n- #132-133: The behavior for R_D = R_D* is the same as the behavior for R_N = R_N* due to the symmetry hence either one is fine in these lines.\n- #147: Thank you for noting, we have fixed it.\n'}}, {'rebuttal': {'value': 'Thank you for your review. We agree that future work confirming these findings at >10B would be very interesting. The Galactica 120B model from prior work does provide preliminary evidence that you can repeat at these larger scales, but more experiments are needed.\n\nQuestions:\n\n>  Data-Constrained IF (instruction fine-tuning) and RLHF\n\n* While we are very interested in IF and RLHF, we think the scaling environment for these problems is different enough to warrant an analysis outside of the Chinchilla regime. For IF, often the datasets are quite small and training looks more like traditional ML training (for example the LIMA dataset from Meta only contains 1000 examples). For RLHF, the reward model is ""data-constrained"" in the sense that annotations are costly. However this model looks more like a classification/regression model, and would likely have different scaling properties than next-token prediction models. Furthermore, published models only scale up to the order of 1M examples which is a different order of magnitude than these examples. Scaling the RL phase of the system is quite interesting, however, this phase also has a different objective and training procedure (PPO).\n'}}, {'rebuttal': {'value': 'Thank you for your thorough summary of the work and careful review. \n \n> by repeating data, they are able to train a comparable model (in terms of performance and compute budget) with 27% less parameters.\n\nWe have updated the main plot (right) to larger scales comparing a 8.7 billion parameter model and a 6.3 billion parameter one. The difference is even more significant now with the smaller model performing better. We further show that the difference between these two models is also significant in terms of downstream performance. Thus, we would go beyond calling them comparable but rather that the smaller model is indeed better.\n\n\n> The experiments on filtering even hint that it might be better to even be more aggressive in current filtering and repeating the cleaner tokens.\n\nThis is a great observation. Indeed the models that repeat C4 twice are better than the models trained on OSCAR (Appendix) with just one repeat.\n\n**Weaknesses:**\n\n> ..fitting metrics..\n\nWe have added R^2 and loss for the different versions of our exponential decay formulation as well as applying no decay at the end of Appendix A. Thank you for this suggestion.\n\n\n> I think the paper could also be improved by making the theoretical discussion more concise and moving some of the (very interesting) findings from the appendix to the main text.\n\nWe agree with the sentiment that much of the Appendix could be part of the main text, however, we are unsure how to reduce the theoretical discussion to make space for that without sacrificing content necessary to understand the main text. If you have specific suggestions, we are open to revising the text based on them.\n'}}, {'rebuttal': {'value': 'Thank you for your detailed review and thought-provoking points. \n\nWeaknesses:\n\nChoice of the parametric form:\n- Decay: We agree that these experiments do not rule out other parameteric forms, such as polynomial. We think exponential was an intuitive starting point out of possible decay formulations and the sharp dropoff in data value (which rules out forms like linear decay). We stuck with it given that it fits our data well with few parameters. \n- Parameters: While we do not have a mechanistic explanation for this term, our hypothesis why this decay is necessary is that if you are trying to fit an over-parameterized model to little data then parameters learn redundant features, and so they end up ""repeating"" in a similar way to the data. \n\nDifferent types of data:\n- We agree that different types of data is an important factor, although it is challenging to change dataset genre, while controlling for scale. We do run experiment with another large-scale web dataset, OSCAR, which has a different data distribution with less filtering. Despite this difference we found the trends to be about the same. While its difficult to define a general-purpose scalar value of complexity, controlled experiments based on this factor is certainly an interesting research direction for future work. (And personally it would be refreshing if quality had a non-linear scaling factor compared to quantity.)\n\nLarger models:\n- We agree that it is important to further validate these findings at even larger scales than our 8.7B models. We already spent a significant amount of compute for the experiments at hand, so we leave this to future work.\n- We investigated 3 model scales in detail (2.7B, 4.2B, 8.7B) and found very similar behavior. However, it could indeed be that there are fundamental changes when going significantly beyond 10B.\n\nMore data:\n- We have swapped the models in the first plot (right) for larger models trained on more data: 8.67 billion parameters for 178 billion tokens and 6.34 billion parameters trained for 242 billion tokens. This has reinforced our findings as we see the same behavior of many epochs still being beneficial (9.7 epochs). We are indeed not hitting the trillion token regimes and it is important for future work (with access to even more compute) to investigate this.\n- This depends on the model size. E.g. with 10B tokens and a 1B model, you will get lots of value from repeating. However, with 1T tokens and a 1B model, then the model will already be close to its maximum capacity at 1T tokens, so repeating is expected to have less value. If we adapt the model size to be bigger in the second case and have more capacity, then our current findings suggest that we can get the same value out of repeating as in the smaller case.\n\n\nQuestions:\n\nOur intuition is that code data benefits tasks that require long-term state tracking. Here is an example input from bAbI: “Sandra travelled to the office. Sandra went to the bathroom. Mary went to the bedroom. Daniel moved to the hallway. John went to the garden. John travelled to the office. Daniel journeyed to the bedroom. Daniel travelled to the hallway. John went to the bedroom. John travelled to the office. Where is Daniel?” The correct answer is “hallway"". Without code data, the models benchmarked are not able to solve this task. However, as soon as code data is added the ability of state tracking appears to emerge and they can solve such tasks. We believe that this could be due to the necessity of keeping track of variable states in order to accurately predict code.'}}, {'summary': {'value': 'This paper studies the scaling behavior of language models by repeating the training data to multiple epochs. The authors extend the recent successful Chinchilla scaling law to a data-constrained regime by adding exponential decay of data and model terms then fit the empirical observations. The key takeaway is that repeating data up to 4 times yields negligible changes to\xa0loss compared to having unique data, consistent with the observation of Galactica. The authors further studies additional methods like adding code data to 50% and find out this does not compromise model performance on text tasks. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'This paper studies a very important problem (what should one do to further scale up data when data is used up) and offers very practical advice (repeating the data 4 times and using code 50% to the training data). I believe this paper will make a clear impact in the area of language models and general AI. '}, 'weaknesses': {'value': 'Although this paper has clear advantages in terms of practical guidance, I am concerned about the following weakness: \n\nThe choice of the specific parametric form in equation 5 and 6 are not clearly explained and may be subject to debate, specifically:\n\n- Why the decay in equation 5 should be exponential (other than, say, polynomial) as when data points are small, exponential may look similar to polynomial (or other functional forms).\n- Why the decay in model scale (Eq. 6) should follow the same form as data (Eq. 5). For the original Chinchilla scaling law, the two terms taking symmetric forms are understandable due to their nature. But for repeating data, model parameter and data scale are not as symmetric as unique data setting, thus considering the same form of decay as data (though I do believe there should be a certain form of decay in model scale) might be less justified\n\nDifferent types of data may need different levels of repetition. \n\n- The Chinchilla model mostly considers webpages v.s. the Galactica model mostly consider academic papers. Intuitively, the level of complexity of webpages might be lower than papers, and one may want to repeat the complex data over simple ones.\n\nThe conclusions hold for smaller models that are less than 10B may not hold for models that are larger than 65B\n\n- This is actually my largest concern with regard to this paper. Empirically, at least for fine-tuning, people have observed that larger models do not require as many fine-tuning epochs as smaller models. In general, models that are smaller than 10B has different behaviors than models larger than 65B\n- An alternative explanation for the repeating 4 times conclusion drawn by this paper could be: smaller models do not have enough capability to fit the data with only one pass, but larger models may be able to do so.\n\nThe conclusion holds for data scale that is less than 100B may not hold for data scale that is larger than 1T. \n\n- Most of the experiments in this paper consider training models with less than 100B data. In the current practice, models (even if they are just 7B) are mostly trained with 1T data (either code or text). This means that in practice, the problem is whether repeating 1T data 4 times, rather than repeating 10B data 4 times.\n- As the data becomes large, a possible model behavior could be: with 10B data, because data is relatively small, repeating is beneficial, yet when data becomes large, repeating may not be as beneficial as the small data regime.'}, 'questions': {'value': 'The authors reported that WebNLG and BaBI immediately improveSee about discussions as one mix in code data. I am curious about what kind of synergy between text and code data and what are the families of text tasks that would benefit the most from mixing code? '}, 'limitations': {'value': 'See above discussion about weakness'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper investigates scaling properties of languages, in the presence of *repeated data*: plenty of work has studied the scaling properties of LLMs (and ML architectures in general), both with respect to the number of parameters and amount of data, but they generally assume each new datapoint is unique. However, as newer LLMs start to reach the limit of available (internet) data, repeated use of the same datapoints sets will become more common and understanding the ""worth"" of a repeated datapoint is a very important research question.\n\nThe authors conduct extensive experiments, training hundreds of model ranging from 10 million to 9 billion parameters and trained up for up to 1500 (repeated) epochs. They then propose a novel *data-constrained* scaling law by introducing a multiplicative factor the data term that decays with the number of repetitions and (briefly) validate it, showing a better fit than the typical Chinchilla scaling law in the presence of repeated data.\n\nThey then use their proposed scaling to study two questions:\n\n1. *Allocation: What is the optimal balance of (compute/data) resources?*\nTheir results suggest that its better to first scale epochs/number of repetions, and only then parameter count: by repeating data, they are able to train a comparable model (in terms of performance and compute budge) with 27% less parameters.\n2. *Return: What is the expected value of additional resources?*\nThey discover that while there are diminishing returns to adding more compute resources in the presence of the same training dataset, there\'s a notable value in repeating data: training up to 4 epochs yields almost the same loss as training on unique data, but beyond that the value of adding compute resources to train further effectively drops to zero.\n\nLastly, they explore several methods to address data limitations without the need to produce new natural language data. They found that incorporating code tokens into training data yielded a two-fold increase in effective tokens, even for tasks solely evaluating natural language. They also explored varying data filtering techniques, concluding that data filtering primarily yields substantial benefits on noisy datasets, and not so much on cleaner ones.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'This was very interesting read, and is quite well written. I think this work has the potential to have big impact in the LLM pretraining community: the limits of unique data we can get from the internet are already being reached, but the findings in this paper suggest that won’t necessarily be a problem for a while, and that repeating tokens a few times to obtain an optimal capacity-data compute allocation is probably fine. The experiments on filtering even hint that it might be better to even be more aggressive in current filtering and repeating the cleaner tokens. Their evaluation on Section 7 is also quite strong, using downstream performance, and the findings with code are insighful and also super relevant to the pretraining community, and further confirm “implicit” knowledge in the community.'}, 'weaknesses': {'value': 'The only slightly more serious flaw I see is that the proposed scaling law is not well validated: from what I see, in the main paper only a single plot showing the fit is shown, and no comparable fitting metrics (like r2), commonly reported in scaling law papers, are given to quantitatively compare to the unique-data scaling laws.\n\nI think the paper could also be improved by making the theoretical discussion more concise and moving some of the (very interesting) findings from the appendix to the main text.'}, 'questions': {'value': 'N/A'}, 'limitations': {'value': 'See above'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper demonstrates the scaling law both mathematically and experimentally in data-constrained situations. They analyze three experimental protocols: allocation (fixed unique data), return (fixed FLOPs), and parametric fit, and obtain new conclusions that were not found in previous research. For example, they demonstrate that increasing the data repetition (epochs) is more effective than increasing the parameters when the number of unique tokens is fixed, and the performance drop is shown to be negligible when there is a slight decrease in unique data within a predetermined number of FLOPs. They also analyze the effects of code data augmentation and data filtering strategies that can be applied in data-constrained situations.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- The research is well-motivated and necessary.\n- They present scaling laws and propose optimal training strategies in a situation where data is limited.\n- They derive reliable and generalizable conclusions through extensive experiments.'}, 'weaknesses': {'value': '- Increasing the maximum parameter size (e.g. >= 10B in Chinchilla [1]) would further enhance comprehension of the scaling law in large language models.\n\n[1] Hoffmann, Jordan, et al. ""An empirical analysis of compute-optimal large language model training."" Advances in Neural Information Processing Systems 35 (2022): 30016-30030.'}, 'questions': {'value': 'Since many large language models utilize IF (instruction fine-tuning) and RLHF (reinforcement learning from human feedback), do authors have plans to expand research on scaling laws of data-constrained language models in the IF or RLHF scenario, where the data includes instruction or human feedback data?'}, 'limitations': {'value': 'The authors adequately suggest limitations in various aspects.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper studies an important empirical question: what is the optimal tradeoff between LLM size and the amount of data available for training it. The authors follow an existing line of work (e.g., Chinchilla), and additionally consider the role of data repetition (via multiple epochs), e.g., what is the effect of training a model for K epochs on N tokens each, compared to training it for one epoch on K*N unique tokens. The authors adjust the power law equation introduced in Chinchilla to take into account the “effective data”, which considers the lower value of repeated tokens, and similarly the “effective model size”, which considers the lower value of parameters trained on such data. They present an overwhelmingly large set of experiments, some VERY expensive (the total amount of compute spent on this work is 4.5 million GPU hours). This makes this study practically irreproducible for 99.999% of the community on the one hand, but very valuable still to those training such huge models. The conclusions reached by the authors are interesting: e.g., models can be trained on data that is repeated for up to 4 times, and reach a similar loss as models trained on a similar amount of unique tokens. They also study the effect of augmenting text corpora with code, and applying deduplication filtering steps.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- An important empirical question.\n- A potentially more accurate modeling of the params/data scaling law.\n- A very large set of experiments covering a range of models and scenarios.\n- Some interesting and non-trivial observations. \n- Paper is generally well written\n\n'}, 'weaknesses': {'value': '- There is something unclear about using the validation or the test loss. The authors say (#42) that they are reporting test loss, but many of the tables and graphs say that they are showing validation loss. Which one is it? Reporting test loss is a problem, as it might lead to overfitting the test data (e.g., by others who want to adapt the proposed recipes).\n- The loss differences are often very small. E.g., in Fig1 (right), a difference of 0.006, or in Fig5 (left). Are these results significant? \n'}, 'questions': {'value': '- I am not sure I entirely understand the data repetition setup. In particular, the caption of fig2 says “Training runs with different epochs reuse subsets of the same data to ensure different training data is not a confounding factor.” What does subsets of the same data mean? Is the data sampled from the training data in each repetition? Doesn’t that mean that the data is not effectively repeated?\n\nTypos and such:\n- #132-133: I think R_D and U_D in these lines should be R_N and U_N?\n- #147: [65]partir\n'}, 'limitations': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Scaling Data-Constrained Language Models'}, 'authors': {'value': ['Niklas Muennighoff', 'Alexander M Rush', 'Boaz Barak', 'Teven Le Scao', 'Nouamane Tazi', 'Aleksandra Piktus', 'Sampo Pyysalo', 'Thomas Wolf', 'Colin Raffel']}, 'authorids': {'value': ['~Niklas_Muennighoff1', '~Alexander_M_Rush1', '~Boaz_Barak2', '~Teven_Le_Scao1', '~Nouamane_Tazi1', '~Aleksandra_Piktus1', '~Sampo_Pyysalo2', '~Thomas_Wolf1', '~Colin_Raffel1']}, 'keywords': {'value': ['large language models', 'scaling laws', 'data engineering']}, 'abstract': {'value': 'The current trend of scaling language models involves increasing both parameter count and training dataset size. Extrapolating this trend suggests that training dataset size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity, including augmenting the training dataset with code data or removing commonly used filters. Models and datasets from our 400 training runs are freely available at https://github.com/huggingface/datablations.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'Scaling laws for training LLMs on multiple epochs & code filling + filtering experiments'}, 'pdf': {'value': '/pdf/03ec57a3ce6b03fb08789fe3ab535f98b1b0e51a.pdf'}, 'supplementary_material': {'value': '/attachment/5520ed6bfca03ba7cee444d619bced7f0ab65067.pdf'}, '_bibtex': {'value': '@inproceedings{\nmuennighoff2023scaling,\ntitle={Scaling Data-Constrained Language Models},\nauthor={Niklas Muennighoff and Alexander M Rush and Boaz Barak and Teven Le Scao and Nouamane Tazi and Aleksandra Piktus and Sampo Pyysalo and Thomas Wolf and Colin Raffel},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=j5BuTrEj35}\n}'}, 'paperhash': {'value': 'muennighoff|scaling_dataconstrained_language_models'}}]"
"['Sébastien Lachapelle', 'Divyat Mahajan', 'Ioannis Mitliagkas', 'Simon Lacoste-Julien']",NeurIPS,Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation,https://neurips.cc/virtual/2023/oral/73849,2023," We tackle the problems of latent variables identification and ""out-of-support'' image generation in representation learning. We show that both are possible for a class of decoders that we call additive, which are reminiscent of decoders used for object-centric representation learning (OCRL) and well suited for images that can be decomposed as a sum of object-specific images. We provide conditions under which exactly solving the reconstruction problem using an additive decoder is guaranteed to identify the blocks of latent variables up to permutation and block-wise invertible transformations. This guarantee relies only on very weak assumptions about the distribution of the latent factors, which might present statistical dependencies and have an almost arbitrarily shaped support. Our result provides a new setting where nonlinear independent component analysis (ICA) is possible and adds to our theoretical understanding of OCRL methods. We also show theoretically that additive decoders can generate novel images by recombining observed factors of variations in novel ways, an ability we refer to as Cartesian-product extrapolation. We show empirically that additivity is crucial for both identifiability and extrapolation on simulated data.",Oral 2B Objects/ Neuroscience/Vision,https://openreview.net/pdf?id=R6KJN1AUAR,https://openreview.net/forum?id=R6KJN1AUAR,R6KJN1AUAR,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'Motivated by the problem of disentanglement in generative models, \nThis paper proposes a novel decoder architecture for latent variables identification and ""out-of-support"" image generation in representation learning. The model is based on the addition of block-wise latent variables, where blocks of latents correspond to semantic factors.\nIdentifiable disentanglement is achieved with very mild conditions on the latent distribution. Additionally, the paper shows that the model can generate images that are out of the training images\' support (called cartesian-product extrapolation). \n\nI agree with the reviewers that the paper addresses an important problem in representation learning, which is learning disantangled representations, and that the proposed approach can have a significant impact in the community.'}}, {'comment': {'value': 'We now have a complete proof that **($C^2$) compositional decoders are additive**. This implies that the class of additive decoders is *strictly* more expressive than the class of $C^2$ compositional decoder ([Brady et al., 2023] assumes only $C^1$, see below for more on this). We provide a partial proof here. We’ll be glad to provide further details on request.\n\nWe give a definition of compositional decoder adapted from Brady et al..\n\n**Def:** Given a partition $\\mathcal{B}$,  a function $f$ is compositional w.r.t. $\\mathcal{B}$ when, for all $i \\in [d_z], z \\in \\mathbb{R}^{d_z}, B \\in \\mathcal{B}$, we have that $D_B f_i(z) \\not= 0 \\implies D_{B^c} f_i(z) = 0$, where $B^c = [d_z] \\setminus B$.\n\n**Proof sketch:** Our strategy is to show that the Hessian of $f_i$ is block diagonal everywhere on $\\mathbb{R}^{d_z}$ and then use Proposition 5 from Appendix A.2 to conclude that $f_i$ must be additive. \n\nFor each $z_0 \\in \\mathbb{R}^{d_z}$, we know there exists a $B \\in \\mathcal{B}$ such that $D_{B^c}f_i(z_0) = 0$. \n\nIn the case where $D_Bf_i(z_0) \\not= 0$, we have by continuity of $Df_i$ that there exists an open neighborhood of $z_0$ on which $D_Bf_i(z) \\not= 0$. By compositionality, we must also have that $D_{B^c}f_i(z) = 0$ on that neighborhood. This means that the derivative of $D_{B^c}f_i$ at $z_0$ is zero, i.e. $DD_{B^c}f_i(z_0) = 0$. Since $f$ is $C^2$, its Hessian is symmetric and thus $D_{B^c}Df_i(z_0) = 0$. We can thus conclude that $D^2f_i(z_0)$ is filled with zeros except possibly at the entries $B\\times B$. Hence it is block diagonal.\n\nIn the case where $D_Bf_i(z_0) = 0$, the argument is slightly more involved because we cannot necessarily take derivatives because $(D_Bf_i)^{-1}(\\\\{0\\\\})$ is a closed set (by continuity of $D_Bf_i$) and thus $z_0$ might be on its boundary. If $z_0$ is in the interior of $(D_Bf_i)^{-1}(\\\\{0\\\\})$, we can use an argument similar to above to show that $D^2 f_i(z_0) = 0$. If $z_0$ is on the boundary, by using the continuity of $D^2f_i$, we can show the Hessian is also going to be block-diagonal. (We made this last part of the argument more precise in our revision. We can provide these additional details on request.) $\\blacksquare$\n\n**We would like to reiterate the differences between both works:**\n\n- We consider additive decoders which, as we just showed, are strictly more expressive than $C^2$ compositional decoders introduced in [Brady et al., 2023]. \n- We assume the decoder is $C^2$ whereas [Brady et al., 2023] assumes only C^1 (which is weaker).\n- We consider very general domains for the latent vector z (Brady et al. study only fully supported latent vectors)\n- We prove additive decoders can extrapolate (their work has no discussion of extrapolation).\n\nNote that we cannot say that our identifiability result is stronger than theirs because we assume $C^2$ decoders while they assume $C^1$. This also makes the comparison between our “sufficient nonlinear” assumption (which refers to second derivatives) and their “irreducibility assumption” (which we believe to be somewhat analogous) difficult.\n\nWe\'d like to correct a mistake we made in a previous message: We said that ""compositional"" means that the Jacobian cannot have more than one nonzero entry per row. This is true only in the special case where $\\mathcal{B} := \\{\\{1\\}, ..., \\{d_z\\}\\}, but the Brady et al. allowed for more general partitions. The definition we gave above is correct.\n\nFeel free to ask if you have any questions, we\'ll be happy to clarify.'}}, {'comment': {'value': ""Thanks for engaging with us and insisting on that point! After some thinking and discussion, we’ve come to agree with you that our usage of the term “ICA'' was too broad and that “ICA” should be reserved for methods where some form of statistical independence between the components is assumed for identification. Of course, under this definition, our approach does not qualify as ICA. To address this issue, we propose the following modifications:\n\n1- Regarding your request to contrast more transparently with nonlinear ICA, we suggest adding this paragraph at L87 in the “Background & literature review”:\n\n**Relation to nonlinear ICA.** [Hyvärinen & Pajunen, 1999] showed that the standard nonlinear ICA problem where the observation $x$ is given by a general nonlinear transformation of *statistically independent latent factors* $z_i$ is unidentifiable. This motivated various extensions of nonlinear ICA where more structure on the factors is assumed [CITE nonlinear ICA works]. Our approach departs from the standard nonlinear ICA problem along three axes: (i) we restrict the mixing function to be additive, (ii) the factors do not have to be necessarily independent, and (iii) we can identify only the blocks $z_B$ as opposed to each $z_i$ individually up to element-wise transformations, unless $\\mathcal{B} = \\\\{\\\\{1\\\\}, ...,\\\\{d_z\\\\}\\\\}$ (see Section 3.1).\n\n2- We will also add the following clarification right after L178 in Section 3.1:\n\n“Note that, unless the partition is $\\mathcal{B} = \\\\{\\\\{1\\\\}, …, \\\\{d_z\\\\}\\\\}$, this corresponds to a weaker form of disentanglement than what is typically seeked in nonlinear ICA, i.e. recovering each variable individually.”\n\n3- We suggest replacing the following problematic sentence from the abstract:\n\nL10: “Our result provides a new setting where nonlinear independent component analysis (ICA) is possible and adds to our theoretical understanding of OCRL methods.”\n\nby\n\n“Our result adds to our theoretical understanding of OCRL methods and provides a new variation of nonlinear independent component analysis (ICA) where latent factors can be identified.”\n\n(The rationale behind keeping the keyword “ICA” in the abstract is that we believe this result will be of interest to this community.)\n\nPlease let us know whether you find these modifications to be satisfactory or not.\n\nNote: We would like to clarify your point that “Similarly the prefix 'nonlinear' is also not really justified when one is not able to recover nonlinearly mixed components, but can merely recover the partitions (symbols/objects)”.  Strictly speaking, a function of the form $\\sum_B f^{(B)}(z_B)$ can be nonlinear in $z$, even when the partition is trivial. That being said, we agree that a case can be made that the *mixing* itself is linear in the following sense: Additive decoders with the trivial partition can be written as $f(z) = S(F(z))$ where $F(z) = [f^{(1)}(z_1), …, f^{(d_z)}(z_{d_z})] \\in \\mathbb{R}^{d_x \\times d_z}$ and $S: \\mathbb{R}^{d_x \\times d_z} \\rightarrow \\mathbb{R}^{d_x}$ is the linear operator consisting of summing the columns of $F(z)$. Of course, $F(z)$ can be nonlinear, but it does not mix the latent factors. The mixing occurs only in $S$, which is a linear operator. So although the decoder function $f(z) = S(F(z))$ is indeed nonlinear, the *mixing step* is linear.\n""}}, {'comment': {'value': 'I still find this problematic. With regards to above discussion about nonlinear ICA, and lack of identifiability of nonlinear mixtures, I can see where you are coming from, but still hold my opinion that this paper is not really doing nonlinear ICA. You say that:\n\n*""The term ""nonlinear ICA"" sometimes mean different things in different context.  [...] Some will use it to mean any setting where the mixing function is a general invertible map but will allow for richer latent distribution like with auxiliary variables [Khemakhem et al., 2020] or temporal dependencies [Lachapelle et al., 2022] for example""*\n\nPerhaps, but using the term ICA to refer to situations where the latent variables are not independent, logically does not really make sense and is poor usage, in my opinion, given what the abbreviation stands for. In Khemakhem (iVAE paper) the latent components are conditionally independent so I feel it\'s justified there. As a case in point, Khemakhem et al. also have works where variables are *not* independent -- in his phd thesis he calls those works \'identifiable representation learning\', which I find much more appropriate. Similarly the prefix \'nonlinear\' is also not really justified when one is **not** able to recover nonlinearly mixed components, but can merely recover the partitions (symbols/objects). \n\n**To accept this paper, I would require this to be discussed more openly** Currently you write: l.177  ""Thus, B-disentanglement means that the blocks of latent dimensions zB are disentangled from one  another, but that variables within a given block might remain entangled."" I don\'t think this is enough because a careless / casual reader might not easily realize how different this is from the typical nonlinear ICA. I think it would suffice however if you had a sentence or two along the lines ""note that the B-disentanglement result is different from those in nonlinear ICA in that we do not recover each latent component, but rather disentangle the partitions, that is, variables within a given block might remain entangled"". Key is to stress the difference to nonlinear ICA which is missing now. \n\n*Sincerely sorry for the inconvenience, we\'ll make sure to fix this in the camera-ready version. You said that in general the colors are poorly chosen, are there any other specific places that caused trouble?*\nI just meant Figure 4 in general -- it is also hard for me to tell apart the two balls as they are red and greenish or something like that. Figure 5 is fine. I appreciate that you can not see the Figures through other peoples eyes so it can always be hard to find colors that suit everyone!\n\n\n\n\n\n\n\n\n\n\n'}}, {'comment': {'value': 'Thanks for seriously engaging with our rebuttal, we appreciate it. Below we address your concerns. We apologize for the lengthy answer, but we felt some point required careful explanations.\n\n**""If you have have partition {{1}, {2}, ..., {d_z}} then each $f^{(b)}(z_b)$ only takes as an input a single random variable, no?""**\n\nThat is correct.\n\n**""so there is complete lack of nonlinear mixing (only a linear mixture is disentangled to find the individual components)""**\n\nIt depends on what is meant by ""complete lack of nonlinear mixing"". The resulting data-manifold can still be highly nonlinear. However, it is true that the nature of the mixing between components is limited by the additivity. I believe the point you are making here reduces to the point you initially made that ""additivity is restrictive"". We agree with this. Many works have considered restricted function classes to improve identifiability like [Brady et al., 2023], [Buchholz et al., 2022], [Gresele et al., 2021]  and [Taleb & Jutten, 1999]. It is clear that these works as well as ours do not form a complete solution to the nonlinear ICA problem, which, in his original formulation, is known to be unsolvable [Hyvärinen & Pajunen, 1999]. That being said, some function classes will be useful for some applications, but not all. In this work we argued that additivity makes intuitive sense for object-centric representation learning (with caveats).\n\n**""As soon as the partitions are larger than size 1, the block-specific nonlinear mixture is immediately unidentifiable.""**\n\nThat is correct. The blocks of the partition will be disentangled from one another, but the variables within a given block can remain entangled.\n\n**""Therefore, you are not solving nonlinear ICA, you are only disentangling the partitions from each other""**\n\nThe term ""nonlinear ICA"" sometimes mean different things in different context. Some people use it to refer to the original problem where the decoder is a general invertible map and the latents are independent [Taleb & Jutten, 1999] (which is unidentifiable). Some will use it to mean any setting where the mixing function is a general invertible map but will allow for richer latent distribution like with auxiliary variables [Khemakhem et al., 2020] or temporal dependencies [Lachapelle et al., 2022] for example. In this work, we use the term ""nonlinear ICA"" to mean any problem where the goal is to recover latent variables from some nonlinear mixture (which might be restricted). Of course, under this definition, additive decoders count as ""nonlinear ICA"" (since additive functions are nonlinear in general). Note that, although our identifiability result restricts the mixing function, we allow for much more general distribution over the latents (dependencies + general support shape) than the strictest interpretation of ""nonlinear ICA"" which assumes independent latents.\n\n**""there representations you learn for each block may be completely arbitrary (bijective) transformations of the ground-truth representations. Is this correct?""**\n\nIndeed, the block $\\hat{z}\\_B$ of a learned representation can be an arbitrary nonlinear transformation of some block of the ground-truth $z_{B\'}$.\n\n**Poor choice of color in Figure 4**\n\nSincerely sorry for the inconvenience, we\'ll make sure to fix this in the camera-ready version. You said that in general the colors are poorly chosen, are there any other specific places that caused trouble?\n\n[Brady et al., 2023] https://arxiv.org/abs/2305.14229 \n\n[Buchholz et al., 2022] https://arxiv.org/abs/2208.06406\n\n[Gresele et al., 2021] https://arxiv.org/abs/2106.05200\n\n[Taleb & Jutten, 1999] https://ieeexplore.ieee.org/document/790661\n\n[Hyvärinen & Pajunen, 1999] https://www.cs.helsinki.fi/u/ahyvarin/papers/NN99.pdf\n\n[Khemakhem et al., 2020] https://arxiv.org/abs/1907.04809\n\n[Lachapelle et al., 2022] https://arxiv.org/abs/2107.10098'}}, {'comment': {'value': 'Thanks for engaging with our work and adjusting your evaluation.'}}, {'comment': {'value': 'Thanks for engaging with our rebuttal! \n\nRegarding the relationship between additive and compositional decoders, we now almost have a complete proof that compositional implies additive. We are stuck on a small technical detail. In the worst case, adding a mild regularity assumption should do the trick. Essentially, we (almost) showed that a compositional decoder has a Hessian with a single nonzero element that lies on its diagonal. This of course means that they have diagonal Hessians and thus are additive (Appendix A.2 shows that additivity is equivalent to diagonal Hessian). This is interesting has it makes the connection between both function classes very transparent.\n\nWe will make sure to give more updates before the end of the discussion period to confirm (or infirm) everything.'}}, {'comment': {'value': 'Glad we could resolve this confusion and thanks for adjusting your evaluation.'}}, {'comment': {'value': 'Thank you for engaging with the rebuttal and adjusting your evaluation.\n\nWith the additional space, we should be able to add details about example 2 and 3, thanks for the suggestion.\n\nClarification: Assumption 2 is not about the model used for learning. It is an assumption about the data-generating process. Here, since the dataset is synthetic, we can test the assumption, however in general it might not be possible. '}}, {'comment': {'value': 'Thanks for the comments -- I am mostly happen with them except below:\n\n**We believe that extending existing proof techniques to block identifiability is actually a strength, since it is more general and it includes the trivial partition {{1}, {2}, ..., {d_z}}, which would yield full disentanglement.**\n\nI am not convinced by this argument. If you have have partition {{1}, {2}, ..., {d_z}} then each $f^{(b)}(z_b)$ only takes as an input a single  random variable, no? so there is complete lack of nonlinear mixing (only a linear mixture is disentangled to find the individual components). As soon as the partitions are larger than size 1, the block-specific nonlinear mixture is immediately unidentifiable. Therefore, you are not solving nonlinear ICA, you are only disentangling the partitions from each other -- there representations you learn for each block may be completely arbitrary (bijective) transformations of the ground-truth representations. Is this correct?\n***\nFigure 4 -- as someone who has red-green color blindness, the red square of extrapolations in Figure 4 is almost invisible (i only saw it once zooming in full screen). The colors in general are poorly chosen -- there exist several colour palettes that take these issues into account.\n***\n\np.s. dodgy grammar in l.286 ""i.e. it is the observation one would have obtain by evaluating""\n\n'}}, {'comment': {'value': 'I appreciate the detailed response from the authors -- many thanks! I have raised my rating to reflect this.\n\nI would be interested in learning from the authors about the relationship between additive and compositional functions, if they happen to have further updates on this.'}}, {'comment': {'value': ""I found the author's rebuttal convincing. The new numerical experiment on explicitly verifying Assumption 2 is helpful. At least for toy data with well-conditioned matrices, this assumption can be verified in practice. I will raise my score.""}}, {'title': {'value': 'Thank you for the follow-up'}, 'comment': {'value': 'Thank you for the follow. Indeed, your analysis was spot on for my confusion regarding links to mixture models. I will increase my score.'}}, {'comment': {'value': ""I believe the authors' response and the discussions included in the appendix address most of my questions/concerns. The 1-page pdf file also provides useful clarifications about the authors’ work.\n\nThe remaining point, in my view, is the requirement in assumption 2 which is not related to known notions of nonlinearity. However, authors explain in the rebuttal (and in the appendix) that this assumption somehow relates to previous assumptions in the OCRL literature. They further explain in the pdf that this assumption is satisfied for the models they have used in their experiments. As this is a conference paper, I find these arguments convincing and I’m raising my score.\n\nI suggest authors expand further on their examples 2 and 3, and explain the implications of their assumption 2 for neural networks, e.g., which models would not satisfy this requirement, which models would satisfy it, what is the minimal neural network architecture that would satisfy the requirement in assumption 2, etc.""}}, {'rebuttal': {'value': '**Regarding uncited relevant works:**\n \nObject-centric representation learning is a vast field and our literature review did not cover all works. We believe many OCRL datasets have this nice additive structure and many OCRL approaches have the inductive bias of additive decoder, which underlines the relevance of our work. We will add these works to our review. \n\nWe want to reemphasize the point we addressed in our general response: we are not proposing any novel approach for object-centric learning; instead we analyze additivity as an inductive bias already present in many OCRL decoders. Hence, our analysis is applicable to several OCRL methods. The only baseline we considered was non-additive decoder as we are concerned with understanding the impact of additivity on latent identification and extrapolation. Hence, using the suggested papers by Nanbo et al. and Yoon et al. as baselines does not align with the goal of our analysis.\n\n**“The images in the VAEC dataset are designed as an extrapolation task. Do authors think this task can fit into their framework?”**\n\nThe VAEC dataset contains a single object, and we believe the attributes like size, location, and brightness cannot be disentangled/identified using additive decoders as the effect of these latent variables on the resulting image is not additive. For example, in our image dataset we could disentangle the latents (position) of a ball from those of the other ball, however, we cannot disentangle the x-y positions of each ball. Hence, the additive decoder inductive bias cannot help us to recover the position of the object in the VAEC dataset, similar to the non-identifiability of position of a particular ball in our dataset. This also implies the question of extrapolation in the VAEC dataset is out of scope from our analysis as we provide guarantees for extrapolation w.r.t latent factors that have additive relationship in the true data generation process.\n\nWe now attempt to demonstrate that the “scale” factor of variation is not additive, as suggested by the reviewer: Let z_1 = size of object and z_2 = position of object and let’s forget about the other factors for the sake of the argument. We now want to write the images as x = f1(z_1) + f2(z_2). If we want f1(z_1) to correspond to “adding mass to object”, the issue is that “where to add the mass in the image” will depend on “where the object is located”, which is given by z_2. This means f1(z_1) could not implement “adding mass” since, to do so, it would have to depend on z_2 (which would violate additivity). \n\n**“It appears that authors attempt to define the reasonableness”**\n\nClarification: We do not attempt to define reasonableness. Instead, we denote by Z^test the set of latent factors that are *reasonable* for a given application, without explicitly defining what it means to be reasonable. This is similar in spirit to the ground-truth decoder f which captures what are the ""natural factors of variations"" in the given application. Most works (including ours) do not try to define what makes some factors of variations ""natural"", they just denote by f the mapping between the ""natural factors"" and the images x, whatever these natural factors might be in a given application.\n\n**“It is not clear what is the difference between Z^test and Z^train”**\n\nZ^test is the set of all reasonable latent vectors. Z^train is the set of latent vectors observed during training. This distinction is made in Assumption 1.\n\n**“Perhaps identifying the boundaries of the “reasonable” manifold is hard, but it may be helpful to describe and contrast what is unreasonable.”**\n\nIn Appendix A.10, we give an example of an unreasonable z in the context of occlusion, i.e. z \\not\\in Z^test.\n\n**“It seems that the notation D (for the Jacobian) is only defined in the appendix under Table 2”**\n\nThe notation is introduced for the first time on page 2 in the paragraph titled “Notation”. We did not use \\nabla to avoid the confusion with the gradient of a scalar-valued function, since here we are concerned with the derivative of vector-valued functions. A solution to improve clarity would be to recall the meaning of D the first time it is used in the paper. We’ll make sure to add this clarification in the next revision.\n\n**“For assumption 2, it may be better to use “linearly independent” instead of “independent””**\n\nAgreed, we implemented the change in the text.\n\n**“Is there any precedence for the notion of nonlinearity defined under assumption 2 for any class of functions?”**\n\nNot that we know of. However this assumption is very closely related to previous works in nonlinear ICA (see discussion in Appendix A.5)\n\n**Assumption 2 and notions of curvature in differential geometry.**\n\nConnection between Assumption 2 and known notions of curvature in differential geometry is a very interesting question worth investigating in the future as it might lead to a better understanding of these types of assumptions in nonlinear ICA. However we consider this to be out of scope for this work.\n\n**“Why should assumption 2 be satisfied over the entire manifold?”**\n\nIt comes from the nature of the proof. The argument is local in the sense that we start by showing ""local disentanglement"" in Theorem 1 (Jacobian of v is a block-permutation scaling everywhere) and then use further assumptions to show global disentanglement in Theorem 2. For the local part of the proof, we need assumption 2 to hold for all z.\n\n**“If each of the first and second order derivatives, individually have full column rank, would that be sufficient?”**\n\nAgain this comes from the nature of our proof, which requires W(z) to have full column-rank everywhere. Having the first and second derivatives individually have full rank would not be sufficient in our current proof (although we do not exclude the possibility that a proof exists that requires only this weaker condition).'}}, {'rebuttal': {'value': '**Connection to mixture models:**\n\nWe assume that by “mixture models” the reviewer refers to models of the form $p(x) = \\sum_k p(c=k)p(x | c=k)$ where $c$ is the random component index. After some thinking, we do not see a clear connection between mixture models and our additive decoders. A possible point of confusion is that a mixture model is a sum (more precisely a convex combination) of *distributions* while the additive decoder $x = \\sum_k f^{(k)}(z_k)$ is a sum of *random variables*. Both models are very different, since the distribution of a sum of random variables is the *convolution* of their respective distributions (assuming the RVs are independent), not the *convex combination*. Please let us know if the confusion persists or if we misunderstood your point.\n\n**Confusion around assumptions of Corollary 3:**\n\nEssentially, in each result, we always require the assumptions of the previous results. Each result essentially adds more assumptions to obtain stronger guarantees. We’ll add that comment in the next revision.\n\n**Lines 281 to 304 seems speculative:**\n\nLines 281-288: We believe these to be objective. We describe a procedure we actually implemented in the experiments of Figure 4.\n\nLines 289-297: See answer to Reviewer 2rwH under *“It appears that authors attempt to define the reasonableness”* for clarifications.\n\nLines 298-304: We believe it is clear that if a decoder f_hat is disentangled w.r.t. a ground-truth decoder f on the training domain, nothing prevents both decoders to have very different behavior outside the training domain, i.e. no extrapolation, unless these decoders are restricted in some way, either via architectural choice (like in this paper) or via some other means like implicit regularization of the optimizer or loss function. \n\n**Meaning of the term “partition”:**\n\nIn mathematics, a “partition of a set A” refers to a set of subsets of A that are mutually disjoint and covers A. This is a very common terminology, see e.g. https://en.wikipedia.org/wiki/Partition_of_a_set. An element of a partition is usually referred to as a “block”. So here, $\\mathcal{B}$ is a partition and $B \\in \\mathcal{B}$ is a block.\n\n**Why is v = f^{-1} \\circ f_hat a diffeomorphism?**\n\nWe need both f and f_hat to be diffeomorphisms (these assumptions can be found in Assumption 1 and the statement of Theorem 1, respectively). \n\n**How to ensure that f is a diffeomorphism?**\n\nWe would like to clarify that f is the ground-truth decoder so we cannot force it to be diffeomorphism, we have no choice but to assume that it is a diffeomorphism. That being said, Theorem 1 requires that f_hat, the learned decoder, is diffeomorphism. In practice, we do not enforce this even if our theory prescribes it. This doesn\'t seem to be a problem, but might be worth exploring in future works.  \n\n**“I did not understand Assumption 2 at all. Can you explain it to me?”**\n\nThis is a rather technical assumption which makes it difficult to formulate in words. But the main point is that it prevents f from being linear as Example 2 shows. Keep in mind that this is an assumption about the data-generating process. Relating this assumptions to notions of curvature in differential geometry as proposed by Reviewer 2rwH might help us understand this assumption better, but is left as future work.\n\n**“In Theorem 2 it is assumed that f is injective, which seems like a rather strong assumption. Can this be loosened?”**\n\nJust to clarify: the ground-truth decoder f was assumed to be a diffeomorphism (and hence injective) much earlier in Assumption 1. Loosening this common assumption is an important open question in the field. Part of the difficulty is in defining the relationship between the learned representation and the ground-truth representation which here is given by v. Without injectivity, many z could correspond to a single z_hat.\n\n**“In line 271 it is stated Z is typically a subset of CPE(Z). What is meant by ""typically""?”**\n\nQuick correction: we wrote that “Z is typically a *proper* subset of CPE(Z)” (“proper” means Z != CPE(Z)). We simply meant that Z is going to be a subset of CPE(Z) unless Z = CPE(Z). One could argue that, in some sense, there are much more sets Z such that Z != CPE(Z) than there are sets such that Z = CPE(Z). That’s what we meant by “typically”. To avoid confusion, we replaced this sentence by “The Cartesian-product extension of Z, CPE(E), is indeed an extension of Z since Z is a subset of CPE(Z)”. \n\n**Why the extension should be axis-aligned?**\n\nOur identifiability result shows that the additive structure in the decoder induces natural axes (the axes that make the map from z to x additive). Given this, it is expected to have extrapolation that is aligned with these natural axes.\n'}}, {'rebuttal': {'value': '**On the restrictiveness of the sufficient nonlinearity assumption:**\n\nAt line 218, we refer to Appendix A.5 to provide intuition for why the sufficient nonlinearity assumption is likely to be satisfied when d_x >> d_z. However, we notice that this explanation is lacking from our submission. In the next revision, we will add this explanation to Appendix A.5: \n\nWe now look at why Assumption 2 is likely to be satisfied when d_x >> d_z. Informally, one can see that when d_x is much larger than d_z, the matrix W(z) has much more rows than columns and thus it becomes more likely that we will find enough rows that are linearly independent, thus satisfying Assumption 2.\n\n**Regarding how to enforce Assumption 2:**\n\nWe note that Theorem 1 and 2 never require to enforce Assumption 2 in the learned model. This is an assumption about the data generating process, not about the learned model, so there is no need to enforce it during training. \n\n**On the restrictiveness of the additivity assumption:**\n\nWe agree that the additivity assumption can be rather restrictive and is unlikely to hold for realistic data. Nevertheless we argued in the paper that standard OCRL decoders are “almost” additive and that our analysis shed light on why these methods work on realistic data. Of course, this is only a first step and more work is needed to understand these approaches theoretically. \n\n**Regarding [Brady et al., 2023]:**\n\nThis work came out almost exactly as we were submitting this work, and thus we did not include it in our related work section. We will add it to the next revision. Brady et al. studies “compositional decoders” which by definition have Jacobians that, for all z, have always at most one nonzero value per row (note that the nonzero elements can have different locations for different values of z). Example 3 in our paper is an example of function that is additive but not compositional, since the Jacobian has more than one nonzero element per row. Moreover, we suspect, although aren’t fully convinced yet, that compositional functions are additive, since we couldn’t come up with an example of a compositional function that is not additive. If that turns out to be the case, that would mean that additive decoders form a (strict) superset of compositional decoders. We will keep working on this and update you during the discussion period in case we find a definitive answer. \n\nOther important distinctions between our work and theirs is that (i) we consider very general domains for the latent vector z (Brady et al. study only fully supported latent vectors) and (ii) we prove additive decoders can extrapolate (their work has no discussion of extrapolation).\n\n**Some details lacking in experiments:** \n\nThanks for bringing this to our attention. The different shades of color correspond to the value of one of the ground-truth latent factors. This is useful to assess disentanglement visually. The red dots correspond to the latent factors used to generate the images. In figure 4, the only difference is the estimation model, the data is the same. We’ll make sure to add these clarifications in the next revision.\n'}}, {'rebuttal': {'value': '**Strength of the assumptions**\n\nWe agree that the additive assumption is rather strong and won’t make sense in many applications other than OCRL. That being said, we believe our work is a nice starting point for other works to investigate more expressive function classes.\n\n**Issues raised by block-disentanglement**\n\nWe believe that extending existing proof techniques to block identifiability is actually a strength, since it is more general and it includes the trivial partition {{1}, {2}, ..., {d_z}}, which would yield full disentanglement. The level of granularity of the partition controls the trade-off between expressivity and identifiability: The finer the partition, the more constrained is the function class and the tighter the identifiability guarantee. The optimal level of granularity is going to be task-dependent. Regarding the impact on the CPE, we have that the finer the partition is, the larger the CPE is going to be. To see this, consider the case where the Z^train is a sphere in 3D (so that d_z = 3). If B = {{1}, {2}, {3}}, we have that CPE is the smallest cube containing the sphere. If B = {{1,2}, {3}}, the CPE is a cylinder, which is a proper subset of the cube. We plan on adding a discussion on these considerations in the next revision.\n\n**“it is hard to be sure whether the theorems fully explain their performance especially given these concerns about block-wise unidentifiability.”**\n\nNote that, in our experiments, we always test for B-disentanglement. For the ScalarLatents dataset, B = {{1}, {2}} whereas for the BlockLatents datasets, B = {{1,2}, {3,4}}. In the first case, B-disentanglement is simply “full/complete disentanglement”, but for the last case, our evaluation does not penalize entanglement within a block. At line 328, we provide details on our evaluation metrics. \n\n**“Could you please explain what you exactly mean by imitation?”**\n\nWe use “imitation” for lack of a better word at line 244 and 281. This terminology is borrowed from [Ahuja et al., 2021] which was used in a similar way for transition mechanisms. For example, in equation (8) which relates the f_hat^B with f^{\\pi(B)}, the two functions are not equal, but they are closely related to one another via the map v_bar and the additive constant c, so one can think about f_hat^B as imitating f^{\\pi(B)}. We provide a more explicit explanation at lines 245-248.\n\n[Ahuja et al., 2021] https://arxiv.org/abs/2110.15796 \n\n**Regarding necessity of restricting decoder in order to enable extrapolation:**\n\nWithout a restriction on the decoder class, there are no ways to guarantee what will happen outside the domain of the training set. And disentanglement is not enough since you might be disentangled on the training domain but crazy things might happen outside. Note that this restriction might be enforced via the choice of architecture (like we did in the present work) or by some implicit bias of the optimizer or the loss function etc… We use the phrase “restricted decoder” in its broadest sense here. \n'}}, {'rebuttal': {'value': '**Practical relevance of Assumption 2**\n\nAlthough we haven’t shown that Assumption 2 is necessary in the sense that it cannot be relaxed, we know that we cannot simply remove it and get the same guarantees since this would contradict the very well established non identifiability of linear ICA when latents are independent and non-gaussian. That’s because, without Assumption 2, the decoder would be allowed to be linear (See Example 2). So this assumption has at least some practical relevance. \n\n**Verifying Assumption 2 in the “ball dataset” (new experiments!)**\n\nThis is a very good suggestion which we decided to investigate. The image generator we are using to generate these images takes only integer values which, strictly speaking, prevents us from even talking about the derivative of this generator. That being said, we created a very similar dataset which takes continuous values as input and can thus be differentiated (in fact, this generator is infinitely differentiable). This allowed us to verify numerically that Assumption 2 is satisfied. To make this verification, we considered a grid of values of z and for each point on that grid, we computed the matrix W(z) from Assumption 2, normalized its columns to have unit length, and computed $\\sqrt{|det(W^t W)|}$ which gives the 4D volume of the parallelogram spanned by the 4 columns of W. This quantity should be 1 when columns are orthogonal (i.e. maximally linearly independent) and 0 when the columns are linearly dependent. We found the minimal value of $\\sqrt{|det(W^t W)|}$ to be ~0.97, which indicates that the columns of W are linearly independent. **Please check the pdf linked in the general response for a visualization of the new dataset as well as the contour plot of sqrt(|det(W^t W)|) as a function of z. The pdf also contains an experiment in which we trained both additive and non-additive decoders. It leads to very similar conclusion to what we found in the paper.** \n'}}, {'rebuttal': {'value': 'We would like to thank all reviewers for engaging with our work and asking important and thought-provoking questions.\n\nWe were glad to see that many reviewers appreciated the clarity, relevance and novelty of our work. For example, **Reviewer C5F5** said that “The paper touches on an important topic (identifiability), and the focus on additive decoders is both interesting, relevant, and novel.” We were happy to read that **Reviewer CUR1** thought that “extrapolation guarantees is a nice addition, something previous works have been missing, and is something that hopefully will be adopted by the community”. **Reviewer 2rwH** said that the paper had a “broad and practical view” while **Reviewer 7aiT** thought the paper was well motivated. **Reviewer JkNs** wrote “The paper is generally very well written in terms of giving intuitions behind the presented math”. **Reviewer CUR1** thought that our result was “insightful” and that “its connection to previous literature is nicely illustrated”.\n\nSome concerns were raised by more than one reviewer, so we decided to address them here in this general response. The other concerns are addressed in individual responses. **Please not that we added additional data and experiments in response to Reviewer 7aiT (see PDF).**\n\n**Absence of large-scale/more complex datasets (7aiT, CUR1, 2rwH)**\n\nWe would like to emphasize that the bulk of our contribution is not to propose a novel architecture with the goal to compare to SOTA methods in object-centric representation learning. Instead, we bring theoretical insights as to why current OCRL methods work in the first place (with the caveats that these OCRL decoders are not exactly additive, but close to it, as discussed in the paper). We note that Peebles et al. [41] already showed convincingly that the diagonal Hessian penalty (which is equivalent to additivity, as we showed in Appendix A.2) improves disentanglement on more realistic datasets, although without any theory for why this worked. Our work can be seen as filling this gap. In addition, our identifiability result is interesting in and of itself to the nonlinear ICA community since it shows yet another case where nonlinear ICA is possible. \n\n[41] W. Peebles, J. Peebles, J.-Y. Zhu, A. A. Efros, and A. Torralba. The hessian penalty: A weak prior for unsupervised disentanglement. In ECCV, 2020.\n\n\n**Lack of discussion surrounding limitations. (7aiT, C5F5)**\n\nWe would like to point out that this is in opposition with Reviewer CUR1’s comment which pointed out to discussions of limitations in our work. For example, the paragraph on line 156 titled “Differences with OCRL in practice” discusses some limitations of our analysis like the fact that the standard masked decoder used in practice is not additive and the fact that we do not consider variable numbers of objects across images, like most OCRL methods can do. Also, on line 325, we refer to Appendix A.11 where we explain why additive decoders cannot represent occlusion. On line 357, we discuss the importance of the “connected support” assumption. \n\nIf the reviewers have specific ideas of limitations to discuss, we would be happy to include them in our next revision.\n\n**How is this analysis going to help us understand creativity in more modern generative model? (7aiT, CUR1)**\n\nThanks for raising this. We agree we did not develop this point sufficiently in the paper, so we add clarifications here and plan on adjusting the next revision accordingly. We believe our analysis illustrates how studying the identifiability of a function class can help us understand how it will extrapolate. We believe this type of analysis is novel and hope that it will motivate other researchers to apply similar analyses to other function classes/learning algorithms (e.g. DALLE-2) to understand and maybe improve extrapolation capabilities. Whether additivity is going to be central to these analyses is left to be seen. It might not be and this does not matter since our point that “identifiability is an interesting lens to study extrapolation” remains.'}, 'pdf': {'value': '/pdf/8012382b41971c933931b9990034d7abe1878044.pdf'}}, {'summary': {'value': 'Motivated by the problem of disentanglement in generative models, this paper proposes a novel decoder architecture, so-called additive decoders, based on the addition of block-wise latent variables, where blocks of latents correspond to semantic factors.\n\nAn extrapolation property of their decoder is demonstrated, which essentially consists of forming new products of latent blocks unseen at train time.\n\nA theoretical analysis of their decoder is carried out. Several new definitions are made, as well as few necessary assumptions. Two theorems are presented on ""local disentanglement"" and ""global disentanglement"".\n\nAn empirical investigation based on synthetic image data, consisting of two balls randomly placed, is carried out, showing a case where their decoder improves upon a baseline case.\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper addresses the problem of disentanglement in an interesting way: through blocks of latent variables which contribute additively to the overall decoding. This is a natural and reasonable idea.\n\nThe motivation for this paper is good: restrict the decoder to be additive to address the problem of latent variable identifiability.\n\nThe proof technique appears to build on the well-established results (Hyvärinen, AISTATS 2019).\n'}, 'weaknesses': {'value': 'The paper is quite technical. This makes it challenging to ensure all technical details are correct. I did not find any errors.\n\nThe authors write that this work may help explain the ""creativity"" of mainstream generative models like DALLE-2 and Stale Diffusion. It is not so clear to me that their analysis will be helpful.\n\nRegarding Assumption 2, which the authors write is ""key"" for Theorem 2, I am not clear on how realistic this assumption is in practice. I understand that it is motivated by similar assumptions made in the ICA literature. However I come away with the feeling that it may not have much practical relevance. The authors give a toy numerical example in Example 3, which is helpful. But for instance, has this assumption been verified for the additive decoders used in the Experiments (Section 4)?\n\nThe proposed additive decoder cannot handle occlusions, as noted by the authors in Section 4, and discussed in the appendix. This is a limitation, since real images may have occlusions. \n\nOnly small-scale synthetic data are included. It doesn\'t appear to me that training on larger scale data is feasible, but more discussion of this would be helpful. It\'s reasonable to develop theory on simple cases, perhaps even necessary in this cases, but we should be clear whether scaling the results can be expected.\n'}, 'questions': {'value': 'Can the authors further justify their statement that this work ""has the potential of expanding our creativity in generative model"" (line 368).\n\nCan assumption 2 be verified for the decoders in used in the Experiments (Section 4)?\n\nIs training on larger-scale data possible with this method? If not, why not?\n'}, 'limitations': {'value': ""Unfortunately I did not find any discussion of limitations in the main text. \n\nI don't think this paper requires a discussion on societal impact.\n""}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""This paper extends the recently popular approach of constraining the nonlinear function to achieve identifiable disentanglement. Here the idea is that $\\mathbf{f}$ is additive i.e. made of constituent functions that operate independently on non-overlapping partitions of the latent function. Identifiable disentanglement is achieved in this situation with very mild conditions on the latent distribution. These additive decoders can be seen as rudimentary version of the decoders used in object-centric representation learning and thus help explain their generalization performance. In particular, the paper shows that by exploring the full cartesian product of the latent symbols the model can generate images that are out of the training images' support (called cartesian-product extrapolation).""}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""- very well written paper with clear and intuitive examples despite the technical topic\n- a novel way in which we can understand disentanglement by restricting the nonlinearity from the point of view of OCRL is a nice new angle to this increasingly popular field\n- by making assumption about the structure of $f$ the authors are able make very mild assumptions about the distribution of the latent factors which is in contrast to the much more distribution\n- additive decoders and the relevant results here provide a nice simple baseline model upon which future works can build more realistic ocrl models\n- extrapolation guarantees is a nice addition, something previous works have been missing, and is something that hopefully will be adopted by the community (though it's unclear how that could be done; see below)\n- assumption of sufficient nonlinearity is an insightful result and its connection to previous literature is nicely illustrated (albeit in the appendix)""}, 'weaknesses': {'value': 'Since the latent variables have only very mild restrictions, the price is paid by having fairly strong restriction on the \'mixing\' function i.e. block-wise additivity (likely problematic in many realistic situations such as images with occlusion) + requirements on nonlinearity. This is likely useful for OCRL (e.g. scene mixtures) but in general may be very restrictive in the more general nonlinear ICA/disentanglement and also abstracts away from the desired goal of traditional nonlinear ICA where the aim is to separate out sources from \'heavily mixed\' signals. \n\nFurthermore, the additivity also leads to a slightly problematic level identifiability results in the sense that each partition-block $z_b$ is identified only up to arbitrary invertible nonlinear transformation (equation 8. & 9. and $v_B$ specifically) -- this can be interpreted as there being a nonlinear ICA / mixing problem completely *unsolved* and thus unidentified for each block. So even though we are no longer left with the generic unidentifiability problem of $x = f(z)$, we are still left with complete unidentifiability in each block $B$, $ x_B = f_B (z_B)$. It feels like the term ""partition-respecting permutation"" and ""B-disentanglement"" are thus very specific to this approach and not really corresponding to the commonly accepted definitions of disentanglement in literature. Indeed the authors write ""Thus, B-disentanglement means that the blocks of latent dimensions zB are disentangled from one 177 another, but that variables within a given block might remain entangled.""\n\nRelated to this, for OCRL the model is quite simple, as admitted by the authors, and while they indeed may provide a good baseline (as mentioned above) it is hard to be sure whether the theorems fully explain their performance especially given these concerns about block-wise unidentifiability.\n \nIt would have been nice to see more extensive experiments and especially on more complex data.'}, 'questions': {'value': 'Do you believe the block-wise unidentifiability/entanglement is undesirable? Or do you believe my concerns above are not a problem? I\'m talking practically speaking. What do you think is the impact of this on CPE? What if the blocks could also be fully disentangled -- what would this change (e.g. in CPE?). Again I\'m interested in your thoughts on practical implications rather than theory.\n\nYou say that: ""is “imitating” a block-specific ground-truth decoder"". Could you please explain what you exactly mean by imitation? I find that quite vague. \n\nYou write that ""We believe it illustrates the  fact that disentanglement alone is not sufficient to enable extrapolation and that one needs to restrict the hypothesis class of decoders in some way."" These sound like very generic statements -- do you have confidence that they hold much beyond this setting?\n\n""our in this work to understand “out-of-support” generation is a step towards understanding theoretically why modern generative models such as DALLE-2 [42] and 53 Stable Diffusion [43] can be creative"" Could you please explain this more specifically? Do you believe additiveness to be important to this? '}, 'limitations': {'value': 'There is some good discussion of limitations in the paper e.g. ""additive decoders make intuitive sense for OCRL, they are not expressive enough to represent the “masked decoders” typically used in"", ""Additionally, this  parameter sharing across f (B) enables modern methods to have a variable number of objects across  samples, an important practical point our theory does not cover."" Appendix also has nice examples of what happens when some assumptions are violated.\n\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents the identification theory for the additive mixing function. Specifically, they transfer the existing nonlinear ICA conditions from the distribution (i.e., sufficient variability) to the nonlinear mixing function (i.e., sufficient nonlinearity). Under this model, they make the connection to extrapolation for generative models. Synthetic data experiments are designed to demonstrate their arguments.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': '1. This paper is well written — both the assumptions and the implications are adequately discussed and thus easy to understand.\n2. The block-wise identification result is novel as a result of the sufficient nonlinearity condition inspired by the sufficient variability condition in prior work.\n3. The connection to the extrapolation is interesting and yields a valuable understanding of current large models.'}, 'weaknesses': {'value': '1. Some key assumptions, although discussed, are still evasive in their restrictiveness. The most notable is the sufficient nonlinearity assumption, which appears very restrictive. How to enforce this for the estimation model is challenging.\n2. The primary assumption, namely additivity, can be very stringent. It is hard to believe this would hold for any realistic data-generating process. This also somehow trivializes the significance of the extrapolation part. I would also like to learn about the relation to recent work [1].\n3. The experimental results lack detailed explanation. I struggle to make sense of the visualizations: what are the colored shades mean in Figure 4, and what does the color mean for the dots? Are the generating processes identical in the additive and the non-additive cases, i.e., does the only difference lie in the estimation model?\n\n[1]. https://arxiv.org/abs/2305.14229'}, 'questions': {'value': ""I would like to learn about the authors' response to the weaknesses listed above, which may give me a clearer perspective on the paper's contribution.""}, 'limitations': {'value': 'Please see the weakness section.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper analyses the statistical identifiability of latent variables in an autoencoder with a so-called additive decoder. It is shown that under this class of decoders, the blocks of latent dimensions associated with the additive decoder can be identified. This result is further related to the ability of a model to extrapolate.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '(These may be subject to change depending on the answers to my questions below)\n\n1. The paper is generally very well written in terms of giving intuitions behind the presented math (see the counter view in Weakness 1 below).\n2. The paper touches on an important topic (identifiability), and the focus on additive decoders is both interesting, relevant, and novel.\n3. The paper does a nice job of providing proof sketches, which is helpful since space constraints prevent the authors from including actual proofs in the main text.\n4. The paper does a very nice job of connecting assumptions and results to existing work in various branches of the literature. This is very helpful.\n5. Finally, I want to emphasize that the theoretical findings are both novel and interesting.\n'}, 'weaknesses': {'value': ""(These may be subject to change depending on the answers to my questions below)\n\n1. The mathematics is often phrased sufficiently convoluted that the phrased intuitions are required (see Strength 1 above). E.g. I found definition 3 to be nearly unreadable, and I could not verify if the clearly phrased intuitions (lines 177-178) actually describe the math (I trust that it does, but it's a problem that it is so difficult to verify).\n2. The 'additive decoder' construction seems quite similar to mixture models for which decades of work exist regarding identifiability. I was surprised to not see this link even briefly touched upon.\n3. I found the extrapolation part of the paper to be less convincing than the identifiability part. Bluntly put, I got lost in the many assumptions made (Corollary 3 holds under the assumptions of Theorem 2, which hold under the assumptions of Theorem 1 which holds under Assumption 1) that I was unable to tell which were the important assumptions for the particular corollary. Thus, I lost my intuition, and the following discussion (Lines 381-304) seems rather speculative. Fere I struggle to determine what's what.""}, 'questions': {'value': '1. It seems to me that additive decoders are effectively a form of mixture model with non-trivial components. Here, we know quite a bit about conditions under which components can be identified up to permutation. This seems quite similar to the presented results. Can you elaborate on this connection? Am I misunderstanding something?\n2. In definition 2, you write ""let $\\mathcal{B}$ be a partition..."" Should this have been $\\mathcal{B}$ be the set of partitions...""? Otherwise, I struggle to understand what $B \\in \\mathcal{B}$ actually means. But perhaps I misunderstood something.\n3. Can we agree that $v := f^{-1} \\circ \\hat{f}$ is a diffeomorphism simply because assumption 1 states that $f$ is a diffeomorphism or is there more to this? (I ask as the statement about $v$ appears in several places in the paper)\n4. How do you ensure that $f$ actually is a diffeomorphism? Here I mainly very about $f$ self-intersecting. I can see how it is easy to ensure that $f$ is an immersion, but in my reading of the paper you seem to require that $f$ is an embedding. Did I get this part right?\n5. I did not understand Assumption 2 at all. Can you explain it to me?\n6. In Theorem 2 it is assumed that $f$ is injective, which seems like a rather strong assumption. Can this be loosened?\n7. In line 271 it is stated $Z$ is *typically* a subset of $CPE(Z)$. What is meant by ""typically""?\n8. I didn\'t quite understand the motivation behind the Cartesian-product extension (CPE). According to the intuition of Fig. 3, the CPE makes an axis-aligned extension, but isn\'t the entire issue regarding identifiability that we cannot assign much meaning to the axes (the axes concern the parametrization and not the underlying support)? Then, why is it natural to extend along the axes? (To be clear, I do see the point of making an extension when studying extrapolation, so my question is more why the said extension should be axis-aligned).'}, 'limitations': {'value': 'There is no need for a discussion regarding societal impact, etc., in a purely theoretical paper such as the present.\n\nI wish the paper had had a greater discussion regarding the many assumptions made throughout the paper. Such a discussion would be akin to a ""limitations"" section often found in more empirical/methodological papers, and I don\'t see why a theoretical paper should not openly be discussing the limitations of the analysis (i.e. if the assumptions are appropriate).'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper develops a theory to show how an additive decoder may be able to disentangle an image composed of several components. The proposed theory also shows how an additive decoder may produce novel images, possibly providing insights about the process performed by generative models.\n\nBesides the theory, paper also performs some experiments showing that additive decoders may have certain advantages in performing those tasks.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'Paper is well written.\n\nThe topic and the experiments are interesting.\n\nIt has a broad and practical view. Literature review is relatively good.\n\nThe proposed theory might turn into a useful contribution for the research community.'}, 'weaknesses': {'value': 'Experiments are interesting but limited and disconnected from existing experiments in the literature, in my view.\n\n-----------------\n\nThere are a few publications that are relevant but not cited:\n\n–Li, N., Raza, M.A., Hu, W., Sun, Z. and Fisher, R, Object-centric representation learning with generative spatial-temporal factorization, NeurIPS 2021.\n\n–Yoon, J., Wu, Y.F., Bae, H. and Ahn, S., An investigation into pre-training object-centric representations for reinforcement learning, ICML 2023.\n\nBoth of the above papers have experiments on images that may be decomposed in the authors’ additive scenario and possibly be used as a baseline for comparison.\n\n-----------------\n\n“Reasonableness”, mentioned under section 3.2, seems to be an unclear definition underlying a significant portion of the theory. It appears that authors attempt to define the reasonableness, yet, it is not clear what is the difference between $Z^{test}$ and $Z^{train}$. Given the bijective assumption, the difference between $Z^{test}$ and $Z^{train}$ should refer to a specific region in the domain and range of the function. Yet, it is not clear what that difference is.\n\nI understand it is hard to define the limits of the underlying manifold of relevant images - that is exactly the heart of the difficulty in developing useful theory for deep learning. Could authors expand on their “reasonable” assumption? Perhaps identifying the boundaries of the “reasonable” manifold is hard, but it may be helpful to describe and contrast what is unreasonable. Perhaps providing a discussion and citing some previous studies on the underlying manifold of images would be helpful as well, e.g.:\n \nCohen, U., Chung, S., Lee, D.D. and Sompolinsky, H., 2020. Separability and geometry of object manifolds in deep neural networks. Nature Communications, 11(1), p.746.\n\n\n-----------------\n\nThere is an extrapolation study and a dataset called VAEC from the paper below.\n\nWebb, T., Dulberg, Z., Frankland, S., Petrov, A., O’Reilly, R. and Cohen, J., Learning representations that support extrapolation. ICML 2020.\n\nThe images in the VAEC dataset are designed as an extrapolation task. Do authors think this task can fit into their framework?\n\n\n-----------------\n\nIt seems that the notation D (for the Jacobian) is only defined in the appendix under Table 2. Since the notation is used in the main body of the paper, it would be useful to define it there. If instead of D, $\\nabla$ was used for the Jacobian, I would have inferred what authors mean by it. However, I was not sure about D until I found it in the appendix.\n\n-----------------\n\nFor assumption 2, it may be better to use “linearly independent” instead of “independent”.\n\nMoreover, it might be better to explain in words that: this assumption is requiring the … matrices, to have full column rank.\n\nOverall, the notion formalized in assumption 2 seems strange to me. Are authors familiar with the notion of curvature for functions and manifolds?\n\nIs there any precedence for the notion of nonlinearity defined under assumption 2 for any class of functions? I am not sure how authors’ notion of nonlinearity relates to known notions of nonlinearity/curvature, for example, the notions of curvature in differential geometry. Why should assumption 2 be satisfied over the entire manifold?\n\nIn its current form, assumption 2 stacks the first and second order derivatives together and then requires that the stacked matrix to have full column rank. It is not clear to me why stacking of these matrices is necessary. If the unrolled second derivatives have full column rank, would it be necessary for the first derivatives to have full column rank? If each of the first and second order derivatives, individually have full column rank, would that be sufficient?\n\n\n-----------------\n\nThis is not a weakness of the paper, but perhaps worth mentioning. It is common in the literature to use x as the input to a function/model, and use y or z as the output of a function/model. However, this paper uses z to denote the inputs and x to denote the output. This may sometimes be a bit confusing. But that is the authors’ choice, and this is just feedback.\n\n'}, 'questions': {'value': 'Please see the questions under weaknesses, especially the questions about assumption 2. (Assumption 2 and what is built on it is my main concern about this work. I hope authors can be more clear and more convincing about their approach.)\n\nHave authors considered expanding their own experiments to something more sophisticated? For example, the shape of objects could be not just circles, but several other types: diamonds, triangles, rectangles, etc. The size of the objects could vary as well. \n\nDo authors think their extrapolation method can be applied to the VAEC dataset (or some modification of it)? The point is to connect this paper’s experiments to existing experiments in the literature. For example, when an object in the VAEC dataset is enlarged, the enlarged object can be considered an addition of two smaller objects which would fit the authors’ additive framework. Currently, this paper’s experiments seem to be isolated from the literature. If VAEC is not suitable, authors may want to consider some other datasets from the literature.\n'}, 'limitations': {'value': 'I did not see a discussion on limitations.\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation'}, 'authors': {'value': ['Sebastien Lachapelle', 'Divyat Mahajan', 'Ioannis Mitliagkas', 'Simon Lacoste-Julien']}, 'authorids': {'value': ['~Sebastien_Lachapelle1', '~Divyat_Mahajan1', '~Ioannis_Mitliagkas1', '~Simon_Lacoste-Julien1']}, 'keywords': {'value': ['identifiability', 'nonlinear ICA', 'causal representation learning', 'disentanglement', 'object-centric representation learning', 'extrapolation']}, 'TLDR': {'value': 'We show that additive decoders have an identifiable representation and allow to generate novel images never seen during training, an ability we refer to as Cartesian-product extrapolation.'}, 'abstract': {'value': 'We tackle the problems of latent variables identification and ""out-of-support\'\' image generation in representation learning. We show that both are possible for a class of decoders that we call additive, which are reminiscent of decoders used for object-centric representation learning (OCRL) and well suited for images that can be decomposed as a sum of object-specific images. We provide conditions under which exactly solving the reconstruction problem using an additive decoder is guaranteed to identify the blocks of latent variables up to permutation and block-wise invertible transformations. This guarantee relies only on very weak assumptions about the distribution of the latent factors, which might present statistical dependencies and have an almost arbitrarily shaped support. Our result provides a new setting where nonlinear independent component analysis (ICA) is possible and adds to our theoretical understanding of OCRL methods. We also show theoretically that additive decoders can generate novel images by recombining observed factors of variations in novel ways, an ability we refer to as Cartesian-product extrapolation. We show empirically that additivity is crucial for both identifiability and extrapolation on simulated data.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/53ecc8f20d0162d461fe74ebd87fb99d412b32ae.pdf'}, '_bibtex': {'value': '@inproceedings{\nlachapelle2023additive,\ntitle={Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation},\nauthor={Sebastien Lachapelle and Divyat Mahajan and Ioannis Mitliagkas and Simon Lacoste-Julien},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=R6KJN1AUAR}\n}'}, 'paperhash': {'value': 'lachapelle|additive_decoders_for_latent_variables_identification_and_cartesianproduct_extrapolation'}}]"
"['Moni Naor', 'Kobbi Nissim', 'Uri Stemmer', 'Chao Yan']",NeurIPS,Private Everlasting Prediction,https://neurips.cc/virtual/2023/oral/73814,2023," A private learner is trained on a sample of labeled points and generates a hypothesis that can be used for predicting the labels of newly sampled points while protecting the privacy of the training set [Kasiviswannathan et al., FOCS 2008]. Past research uncovered that private learners may need to exhibit significantly higher sample complexity than non-private learners as is the case of learning of one-dimensional threshold functions [Bun et al., FOCS 2015, Alon et al., STOC 2019].We explore prediction as an alternative to learning. A predictor answers a stream of classification queries instead of outputting a hypothesis. Earlier work has considered a private prediction model with a single classification query [Dwork and Feldman, COLT 2018]. We observe that when answering a stream of queries, a predictor must modify the hypothesis it uses over time, and in a manner that  cannot rely solely on the training set.We introduce {\em private everlasting prediction} taking into account the privacy of both the training set {\em and} the (adaptively chosen) queries made to the predictor. We then present a generic construction of private everlasting predictors in the PAC model.The sample complexity of the initial training sample in our construction is quadratic (up to polylog factors) in the VC dimension of the concept class. Our construction allows prediction for all concept classes with finite VC dimension, and in particular threshold functions over infinite domains, for which (traditional) private learning is known to be impossible.",Oral 2D Privacy,https://openreview.net/pdf?id=y8UAQQHVTX,https://openreview.net/forum?id=y8UAQQHVTX,y8UAQQHVTX,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The paper got a very strong set of reviews. The reviewers, and I will recommend the authors to update the presentation in light of the discussions.'}}, {'comment': {'value': 'Thanks for your responses!'}}, {'title': {'value': 'Thank you for your response'}, 'comment': {'value': 'Thank you for the explanation! It addresses my concerns and I agree that the new concept is very meaningful. I would like to increase my score to a 7.'}}, {'title': {'value': 'Thank you for your resonse'}, 'comment': {'value': 'Thank you for your response. I believe the new concept is very meaningful and could inspire a new line of research. I will increase my score to 7.'}}, {'rebuttal': {'value': 'Thank you for your thoughtful comments. Below we address the points you make:\n\n**> In the algorithm GenericBBL,  $\\tau>1.1\\times 10^{10}$, seems too large. Can the constant be made any smaller?**\n\nWe have not optimized constants as our contribution focuses on asymptotic complexity. The  paper introduces a new concept - private everlasting prediction - and demonstrates an unbounded asymptotic improvement over private learning. While the construction may be impractical at this stage, we believe that it provides a significant theoretical improvement that would be followed by more theoretical and practical research towards making everlasting predictors usable in a variety of practical applications. \n\n**> The algorithm is not computationally efficient**\n\n Although our algorithm is not computationally efficient it does yield in some cases polynomial time constructions. We clearly state the question of making the construction efficient as an open problem. We expect that future work would resolve the question whether an efficient generic construction exists.\n\n**> In terms of writing, the authors could provide a brief overview of the proof ideas for Theorem 5.1.**\n\nWe will include an overview of the proof. Very briefly - the high-level idea is to use LabelBoost to label the unlabeled dataset and use BetweenThreshold to predict labels. The privacy and accuracy guarantees come from these two algorithms.\n\n**> In practice, some large models are pretrained on public data which can be considered non-private. Theoretically, is it relevant to consider the case when the training set S is non-private and the stream of queries is private? How would the sample complexity change?**\n\nVariations of this question were studied in the standard private learning model (where the learner releases a model), e.g., by [1,2]. We believe that this could also be relevant in our context, but this would require adjustment to the learning scenario to be meaningful. More specifically, in our context, if pre-training can be performed on O(VC) non-private labeled examples, then that would nullify the need for private learning/prediction, as we could simply release the resulting non-private model. \n\nWe believe that this would make sense in other learning scenarios where you would like to use the private queries in order to improve the error of the non-private model you obtained from the initial (non-private) training set. Our privacy definition could potentially fit such scenarios.\n\n[1] Beimel, Nissim, Stemmer. Private Learning and Sanitization: Pure vs. Approximate Differential Privacy. RANDOM 2013.\\\n[2] Bassily, Moran, Alon. Limits of Private Learning with Access to Public Data. NeurIPS 2019\n'}}, {'rebuttal': {'value': 'Thank you for your thoughtful comments. Below we address the points you make:\n\n**> Limited applicability: The paper focuses on the theoretical aspects of private everlasting prediction and does not provide concrete practical applications or empirical evaluations**\n\nWe agree that the construction of efficient practical algorithms that can be used in concrete practical applications is important. Establishing a sound theory of private learning and improving the asymptotic behavior of private learning algorithms is no less important. In fact many if not most of the practical applications of differential privacy would not have existed hadn\'t they began as concepts which were introduced in theoretical results, even if initial constructions were impractical.\n\n**> Lack of comparative experimental analysis**\n\nWe present a novel concept (everlasting prediction) as an alternative to private learning. We also present a construction demonstrating that everlasting prediction is possible in tasks where private learning was proved to be impossible. For example, the sample complexity for private learning of threshold functions grows with the domain size. In contrast, as we mention in the paper, threshold functions can be predicted efficiently, regardless of the domain size.\n\n**> Lack of empirical validation... makes it hard to justify the utility of the proposed algorithm**\n\nAt this phase of this research, an experimental analysis and an empirical validation would not yield meaningful conclusions beyond deeming the current algorithms ""impractical"". Rather, a mathematical asymptotic analysis is the right tool for analyzing our results. We believe that our work would lead to future studies on this topic, both theoretically and practically oriented.\n\n**> The contents shown in the supplementary materials contain a lot of redundant information compared with the paper**\n\nThe supplementary materials contain all the formal details which were omitted from the main paper. We are open to reorganizing the paper (within the page limit).\n\n**> What is the application scenario of the everlasting prediction?**\n\nEssentially, private everlasting predictors can be used in many scenarios where we would like to use the outcome of private learning algorithms for prediction, e.g.,\n\n1. A hospital might use a private everlasting predictor in supporting decisions whether patients need to be treated for COVID19, based on their tests and medical history. The process would bootstrap with an initial sample of patients that would be labeled by experts and continue with private prediction. Due to the very sensitive nature of the data (as well as legal and ethical considerations) it is important to protect the information of both the initial sample and of patients to whom prediction is applied.\n\n2. Similarly, a bank might use a private everlasting prediction as part of its decision process whether to offer loans to customers.\n'}}, {'rebuttal': {'value': 'Thank you for your thoughtful comments. Below we address the points you make:\n\n**> There are two obvious limitations of the main result that yield very interesting open problems… computational efficiency and sample complexity**\n\nWe believe that - even with these questions unresolved - the concept of everlasting prediction is of interest to the private learning community, in particular because it gets around impossibility results. We hope that follow up work will resolve the open questions we present in the paper.\n\n**> Is it strictly necessary for accuracy that the query points are iid? ... Does this seem like it could be possible, or is it too strong?**\n\nWe believe that a construction similar to ours should work in a setting where not too many of the challenge queries are chosen adversarially, provided that the given non-private learners can withstand a poisoning attack with related parameters. We view this research direction (and in particular the stronger formulation you suggested) as an interesting direction for future work.\n\n**> Minor clarification ... can we get a similar or only slightly weaker result without using BetweenThreshold**\n\nWe can get a similar (but weaker) result even without BetweenThresholds. Specifically, this will yield an algorithm in which the initial labeled sample S has a worse dependency on the accuracy parameter alpha.\n'}}, {'rebuttal': {'value': 'Thank you for your thoughtful comments. Below we address the points you make:\n\n**> the notion of privacy defined... is not as strong as would be nice since the label for a data point needs to depend on the data point**\n\nWe don’t see the fact that the adversary does not get to see the label of one point (where the inputs differ) as a serious weakness - this is a necessity due to the characteristics of the problem, and it makes sense in may applications of private prediction (e.g., when prediction is used to support a decision whether to give a patient a certain treatment, it is OK for the patient to learn the result of applying the prediction to their own medical information; what is important is that privacy of other patients needs to be preserved). Note that the adversary we consider is nevertheless very powerful. In particular, after the single point where it does not see the label it can still adaptively choose an unbounded number of points and learn their labels.\n\n**> The reasoning for the use of LabelBoost didnt entirely make sense to me**\n\nIn our construction we need to ensure that the sum of $\\alpha_i$ converges, so that the overall error is under control. LabelBoost helps here because its utility guarantees are better than what we can guarantee during ""runtime"", i.e., when responding to the queries online. We do not know if LabelBoost is necessary for this, but so far we could not get the error to converge without it.\n\n**> The comment about their model of prediction, in principle, allowing memorization was interesting. It\'s not clear that this is true- it seems like memorizing something in the training set would affect future predictions which would affect the adversary\'s views** \n\nMemorization need not be of just the initial training set but also of the query points posed to the predictor. What we meant to say is that our construction yields private predictions regardless of how the internal non-private learners operate, and even in case they memorize points of the training set or points presented as queries.\n\nA possible example for this would be the class $C^{enc}_{thresh}$ (described in Item 1 in the same section). Bun and Zhandry [2016] showed that privately learning this class is computationally hard, whereas non-private learning is easy. This difference actually follows from the private learner\'s inability to memorize data points from the training set. As we mentioned in Item 1, our construction yields an efficient learner for this class (in our privacy model). The resulting learner would not leak to the adversary information about data points, but it would still memorize some of them internally. We will include this observation in the final version.\n\n**> Is there a simple (eps, 0)- version of this algorithm?**\nWe don\'t know whether pure-DP everlasting predictors exist. Our analysis strongly relies on the advanced composition theorem, and hence yields approximate-DP.\n\n**> The diagrams in the privacy proofs are a little too convoluted to be useful to the reader** \nThank you for the comment. We will consider whether to keep the diagrams (or simplify them).\n\n**> In Algorithm LabelBoost step 4, \'choose\' based on exponential mechanism is not well defined (it can be inferred from context)**\n\nRight. We will state this explicitly.\n\n**> In Claim E.4 don\'t you need to account for the fact that the function labeling the sample is not the real function, but rather the one chosen by LabelBoost?**\n\nYes, the samples are labeled by the concept chosen by LabelBoost. We argue that this concept has low error compared with the original concept in claim E.3\n\n**> On page 8... I think you mean privacy composition**\n\nYes, we use advanced composition because BetweenThreshold will halt within c times with high probability.\n'}}, {'summary': {'value': 'This work studies differentially private prediction. It has two major contributions: \n\na) Prediction corresponds to being given an initial labeled training set, and then subsequently making predictions on other data points based on it. This paper shows that differentially private prediction can be performed on an unbounded number of queries, with strong accuracy guarantees, with the initial training set sample complexity scaling only as a polynomial in the VC dimension of the hypothesis class. Prior work either studied prediction for a small number of queries or studied the more stringent task of private PAC learning where significantly stronger lower bounds are known (PAC learning asks for the release of an entire model as opposed to predictions alone).  \n\nb) Since queries correspond to data points, they are usually sensitive user information. The authors formalize a model of privacy (similar to joint differential privacy) that gives a meaningful notion of privacy for these data points, even when adversaries can choose the queries adaptively. Their algorithms satisfy this notion of privacy.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'This paper makes a valuable and somewhat surprising discovery by proving that differentially private prediction can be performed on an unbounded number of queries, with no training set sample complexity dependence on the number of queries! They leverage standard techniques such as sparse vector in clever ways to do so. They operate in rounds, and use queries themselves as data points for future rounds, calling upon techniques from the semi-supervised differentially private learning literature . Their results suggest new ways to get around lower bounds for differential privacy.\n\nTheir algorithms involve reducing private prediction to non-private PAC learning, and while their techniques are not yet practical in many cases (because of time complexity), their reduction can be readily extended to any non-private learning algorithm, and hence there is lots of potential for future work to come up with ways to make their techniques more practical.\n'}, 'weaknesses': {'value': 'One (minor) drawback is that the notion of privacy defined for the adaptively chosen queries is (necessarily) not as strong as would be nice since the label for a data point needs to depend on the data point to achieve any reasonable notion of accuracy (since otherwise you can only do something like randomized response). '}, 'questions': {'value': '1) The reasoning for the use of LabelBoost didnt entirely make sense to me- the stated reason was that the predictions provided during a round are not consistent with any concept in the hypothesis class. However, it’s not immediately clear to me that this is a problem- for example, using agnostic (non-private) learning algorithms may get around this issue (at the expense of worse sample complexity dependence on the accuracy parameter). More explanation of this would be useful.\n\n2) The comment about their model of prediction, in principle, allowing memorization was interesting. It’s not clear that this is true- it seems like memorizing something in the training set would affect future predictions which would affect the adversary’s views. Would love more clarification on this.\n\n3) Is there a simple (eps, 0)- version of this algorithm? It’s not clear to me that approx DP is necessary (sparse vector by itself is pure DP, though a variant is used in this paper).\n\n4) The diagrams in the privacy proofs are a little too convoluted to be useful to the reader. I don’t have great suggestions on how to simplify them, but the privacy proofs by themselves are relatively simple, and I’m not sure the diagrams make them simpler to understand.\n\n5) Some minor comments:\n\na) In Algorithm LabelBoost step 4, ‘choose’ based on exponential mechanism is not well defined since the score function is not specified (it can be inferred from context that it’s the negative of empirical risk) but specifying would be good.\n\nb) In Claim E.4 don’t you need to account for the fact that the function labeling the sample is not the real function, but rather the one chosen by LabelBoost? Specifically, Claim E.3 is about a function with 0 sample error, whereas LabelBoost will incur some error, and hence I think you want a version of claim E.3 where sample error is bounded by alpha.\n\nc) On page 8, where it says ‘using standard privacy amplification arguments, BetweenThresholds can be modified to allow for c times of outputting bot before halting)’, I think you mean privacy composition.'}, 'limitations': {'value': 'Limitations adequately addressed.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper provides an intriguing path to evading known lower bounds for differentially private PAC learning. Whereas nonprivately the sample complexity of learning is proportional to the VC dimension, the private sample complexity for (pure) DP is characterized by the representation dimension, which can be much larger. In particular, some natural classes such as threshold functions over an infinite domain (e.g. Z or R) have finite VC dimension but infinite representation dimension, so they can be learned nonprivately but not privately (even with approximate DP, by a separate result).\n\nThis paper shows that this impossibility only holds for privately releasing a hypothesis and not for privately classifying samples. In particular, it shows that in the online prediction setting, for any hypothesis class there is a generic stateful algorithm with sample complexity based on the VC dimension (to be precise, quadratic in the VC dimension) that can privately answer an unbounded sequence of iid queries with the same accuracy guarantee as PAC learning, but where the state of the algorithm remains hidden and only the query labels are revealed. The algorithm is allowed to remember previous queries but must be differentially private with respect to them as well as the points of the original (labeled) training set. It also shows that statefulness is necessary to achieve this result.\n\nFor general hypothesis classes the algorithm is inefficient, but it can be made efficient on important special cases, including threshold functions. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'This is a very interesting result that enhances our understanding of differentially private learning by bypassing known lower bounds. It essentially gives a separation between interactive and non-interactive private prediction, showing that interactivity reduces the private sample complexity to nearly that of nonprivate learning (as long as we only have to output predictions and not a hypothesis). The paper is quite well-written.'}, 'weaknesses': {'value': 'There are two obvious limitations of the main result, that yield very interesting open problems posed in the paper: whether it\'s possible to come up with a similar algorithm that is computationally efficient for all hypothesis classes, and whether it\'s possible to improve the sample complexity from VC^2 to VC.\n\nMinor corrections:\n104: points --> point\n147: ""upto"" should be ""up to""'}, 'questions': {'value': '1) Is it strictly necessary for accuracy that the query points are iid? Or could we hope for the following stronger statement: \n\nGiven query points x_1, x_2, ... and a subset of indices I (not known to the algorithm) such that x_i is sampled from the distribution for i\\in I but is chosen by the adversary for i\\notin I, we require accuracy only for the points in I. \n\nThat is, as long as the challenge queries are sampled from the distribution, we want to be robust to data poisoning using the other queries. Does this seem like it could be possible, or is it too strong?\n\n2) Minor clarification: In the technical overview on page 3-4 it sounds like the parameters discussed are based on the standard composition bound, without using BetweenThresholds. It might be helpful to clarify whether this is the case and if we get a similar or only slightly weaker result without using BetweenThreshold, or if we truly need the tighter privacy analysis of BetweenThreshold. '}, 'limitations': {'value': 'Yes.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper discusses private everlasting prediction, which extends private prediction to answer an unlimited sequence of prediction queries. The goal is to present a generic private everlasting predictor with low training sample complexity. The paper introduces definitions for everlasting prediction and everlasting differentially private prediction interfaces. It then presents a generic construction called GenericBBL for private everlasting prediction.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': '1. This paper introduces a formal framework for everlasting prediction.\n2. This paper provided a comprehensive privacy analysis to the proposed privacy-preserving everlasting prediction task.'}, 'weaknesses': {'value': '1. Limited applicability: The paper focuses on the theoretical aspects of private everlasting prediction and does not provide concrete practical applications or empirical evaluations. It remains to be seen how well the proposed approach translates into real-world scenarios.\n2. Lack of comparative experimental analysis: The excerpt does not mention any comparison or benchmarking against existing methods or alternative approaches. Without such comparisons, it is difficult to assess the novelty or superiority of the proposed method.\n3. Lack of empirical validation: The excerpt does not mention any empirical experiments, simulations, or case studies to validate the effectiveness or robustness of the proposed private everlasting predictor. It is unclear how the proposed construction performs in terms of privacy preservation, utility, and sample complexity compared to other techniques.\n4. The contents shown in the supplementary materials contain a lot of redundant information compared with the paper. '}, 'questions': {'value': 'What is the application scenario of the everlasting prediction?'}, 'limitations': {'value': 'It lacks experimental analysis of the proposed algorithm, which makes it hard to justify the utility of the proposed algorithm.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work proposes the notion of private everlasting prediction. Given a training dataset, the predictor responds to a sequence of queries and privacy has to be preserved for both the training data and all queries. The authors explore the PAC learnability problem under this model and show that the sample complexity scales quadratically with the VC dimension through a generic construction from non-private learners. '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""1. The authors formulate a new notion of private everlasting prediction. This is an original theoretical concept which extends the single query prediction model and has practical relevance.\n2. The authors prove several interesting theoretical properties for private everlasting prediction. First it requires that the hypothesis needs to change over time. Second, the authors show that the sample complexity scales quadratically with the VC dimension of the concept class. This is a significant improvement compared to private learning which is impossible over infinite domains.\n3. The writing is clear and easy to follow.\n\nUpdate: increased my score to seven after seeing the authors' response and other reviewer comments.""}, 'weaknesses': {'value': '1. In the algorithm GenericBBL, $\\tau>1.1\\times 10^10$ seems too large. Can the constant be made any smaller?\n2. The algorithm is not computationally efficient.\n3. In terms of writing, the authors could provide a brief overview of the proof ideas for Theorem 5.1.'}, 'questions': {'value': 'In practice, some large models are pretrained on public data which can be considered non-private. Theoretically, is it relevant to consider the case when the training set $S$ is non-private and the stream of queries is private? How would the sample complexity change?'}, 'limitations': {'value': 'The authors adequately addressed the limitations and potential negative societal impact.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Private Everlasting Prediction'}, 'authors': {'value': ['Moni Naor', 'Kobbi Nissim', 'Uri Stemmer', 'Chao Yan']}, 'authorids': {'value': ['moni.naor@gmail.com', '~Kobbi_Nissim2', '~Uri_Stemmer1', '~Chao_Yan2']}, 'keywords': {'value': ['Differential privacy', 'private learning', 'private prediction']}, 'abstract': {'value': 'A private learner is trained on a sample of labeled points and generates a hypothesis that can be used for predicting the labels of newly sampled points while protecting the privacy of the training set [Kasiviswannathan et al., FOCS 2008]. Past research uncovered that private learners may need to exhibit significantly higher sample complexity than non-private learners as is the case of learning of one-dimensional threshold functions [Bun et al., FOCS 2015, Alon et al., STOC 2019].\n\nWe explore prediction as an alternative to learning. A predictor answers a stream of classification queries instead of outputting a hypothesis. \nEarlier work has considered a private prediction model with a single classification query [Dwork and Feldman, COLT 2018]. We observe that when answering a stream of queries, a predictor must modify the hypothesis it uses over time, and in a manner that  cannot rely solely on the training set.\n\nWe introduce {\\em private everlasting prediction} taking into account the privacy of both the training set {\\em and} the (adaptively chosen) queries made to the predictor. \nWe then present a generic construction of private everlasting predictors in the PAC model.\nThe sample complexity of the initial training sample in our construction is quadratic (up to polylog factors) in the VC dimension of the concept class. Our construction allows prediction for all concept classes with finite VC dimension, and in particular threshold functions \nover infinite domains, for which (traditional) private learning is known to be impossible.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/4b3ac664335fefb029dd0b4a5ab121189a9d47ca.pdf'}, 'supplementary_material': {'value': '/attachment/104331818fd334848f016fd632748676a248d740.pdf'}, '_bibtex': {'value': '@inproceedings{\nnaor2023private,\ntitle={Private Everlasting Prediction},\nauthor={Moni Naor and Kobbi Nissim and Uri Stemmer and Chao Yan},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=y8UAQQHVTX}\n}'}, 'paperhash': {'value': 'naor|private_everlasting_prediction'}}]"
"['Ahmed Alaa', 'Zaid Ahmad', 'Mark van der Laan']",NeurIPS,Conformal Meta-learners for Predictive Inference of Individual Treatment Effects,https://neurips.cc/virtual/2023/oral/73862,2023," We investigate the problem of machine learning-based (ML) predictive inference on individual treatment effects (ITEs). Previous work has focused primarily on developing ML-based “meta-learners” that can provide point estimates of the conditional average treatment effect (CATE)—these are model-agnostic approaches for combining intermediate nuisance estimates to produce estimates of CATE. In this paper, we develop conformal meta-learners, a general framework for issuing predictive intervals for ITEs by applying the standard conformal prediction (CP) procedure on top of CATE meta-learners. We focus on a broad class of meta-learners based on two-stage pseudo-outcome regression and develop a stochastic ordering framework to study their validity. We show that inference with conformal meta-learners is marginally valid if their (pseudo-outcome) conformity scores stochastically dominate “oracle” conformity scores evaluated on the unobserved ITEs. Additionally, we prove that commonly used CATE meta-learners, such as the doubly-robust learner, satisfy a model- and distribution-free stochastic (or convex) dominance condition, making their conformal inferences valid for practically-relevant levels of target coverage. Whereas existing procedures conduct inference on nuisance parameters (i.e., potential outcomes) via weighted CP, conformal meta-learners enable direct inference on the target parameter (ITE). Numerical experiments show that conformal meta-learners provide valid intervals with competitive efficiency while retaining the favorable point estimation properties of CATE meta-learners.",Oral 2C Causality,https://openreview.net/pdf?id=IwnINorSZ5,https://openreview.net/forum?id=IwnINorSZ5,IwnINorSZ5,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper addresses an important and timely questions, namely to provide uncertainty quantification of individual treatment effect in causal inference. The reviewers agree that this is a well written paper and it is pleasant to read, that the tackled problem is challenging and impactful, and that the proposed solution is backup by both theoretical and experimental results. While some reviewers questioned the conservatism of the procedure, it is not showing in the simulation. The known propensity setting is also very common in the literature. It is determined that this paper should be accepted.'}}, {'comment': {'value': 'I acknowledge that I have read the rebuttal and I have increased the rating.'}}, {'title': {'value': ""Reviewers, please respond to author's rebuttal.""}, 'comment': {'value': 'As a minimum, please acknowledge that you have read the rebuttal and whether it helps to change your rating, as the authors have tried to respond to your comments in the review. Thank you.'}}, {'title': {'value': 'Good rebuttal!'}, 'comment': {'value': 'Thanks for the good response during the rebuttal! My concerns are addressed and I have increased my score accordingly.'}}, {'title': {'value': 'Thanks for your response'}, 'comment': {'value': 'Thanks for your response. When hidden confounding exists, the causal effects are not identifiable so the coverage guarantees do not apply. However, one can operationalize the stochastic ordering framework to conduct sensitivity analysis for the meta-learner in a manner similar to Jin et al. 2023.'}}, {'comment': {'value': ""Thank you for your comments. While the answers to my first and last questions are not completely addressing them, I feel they are fair responses. I'll keep my scores as this paper makes valuable contributions yet still some assumptions/conditions remain not fully clear. \n\nOne last question just out of curiosity: does this meta-learner idea apply to the confounded setting such as in Jin et al. 2023? ""}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the thoughtful feedback and comments. Regarding condition (ii) in Theorem 1, the ordering is written correctly for the SOSD condition. Because these notations come from the decision theory literature, they are written to express risks associated with different distributions. SOSD is conventionally written in an opposite fashion to other types of conditions because it means that $V^*$ is ""less risky"" (i.e., has less spread) than $V_\\varphi$. \n\nPlease see below our point-by-point responses to your comments and questions. \n\n- **What if the propensity score is unknown?**\n\nWhen the data comes from an observational study with an unknown treatment mechanism, we need to estimate the propensity score $\\pi$ and use this estimate in the pseudo-outcome transformation. In this case, the general conditions in Theorem 1 still hold, but Theorem 2 does not hold anymore. While an accurate estimate of $\\pi$ will lead to a ""approximate"" validity, no formal result along these lines follow directly from Theorems 1 and 2. \n\nThe good news is: to make progress in establishing validity of inference with estimated propensity scores, we can still use our stochastic ordering result in Theorem 1 combined with generalization bounds on estimated propensities to identify the conditions under which meta-learners with approximate propensities are valid. This is an interesting and natural extension of our work that can build on the novel stochastic dominance framework proposed in this paper to solve an even more challenging problem.\n\nWhile our analysis focuses on the case of known propensities, we believe that it still pushes the boundary of what we can do for the ITE inference problem, since all previous work applies CP to POs rather than ITE. To the best of our knowledge, this is the first paper that applies CP to infer ITE in an end-to-end fashion and enables the utilization of a broader range of meta-learners as the underlying CATE estimators. The novel stochastic ordering framework can also be used to solve more challenging versions of our setup, e.g., when hidden confounding exists or when propensity scores are unknown.\n\n- **How large is the validity region for conditions (ii) and (iii) in Theorem 1 or practically used conformity scores?**\n\nIn almost all our experiments, we found that the pseudo-scores have FOSD over the oracle scores, which means that $\\alpha^*=1$ and conformal meta-learners are valid for all target coverage. This is the case in all experiments in the main text (see Figures 4(c) and 5) as well as in the 77 experiments in the ACIC benchmark (provided in the Appendix). We believe that the IPW and DR may satisfy stronger stochastic orders (i.e., FOSD) than what we proved in Theorem 2. This is because our proof technique is based on an analysis of pointwise stochastic orders conditional on any feature point $X=x$. This is a sufficient but not necessary condition for the marginal scores to satisfy the MCX conditions in Theorem 2. It is likely that a stronger version of Theorem 2, showing that the meta-learner scores have FOSD over the oracle scores is viable.\n\nCharacterizing $\\alpha^*$ is a challenging problem because it requires inference on the crossing points of the CDFs of unknown distributions (i.e., the blue and red CDFs in Figures 4(c) and 5). This is a very interesting but technically-involved analysis that is of broad interest beyond the ITE inference problem, and would warrant a separate paper on its own. \n\n- **Both POs missing case vs. Only one PO missing**\n\nPlease note that we only focus on the more challenging problem of inferring the ITE on a new point $X$ when both POs are missing. All our experiments and analyses are focused on this case. In fact, it is impossible to infer one PO with the IPW- and DR-learners because they do not provide explicit estimates of the POs in the first place. We will clarify this in the final manuscript.\n\n- **Does it only apply to the setting without covariate shift?**\n\nAs mentioned in the previous point, we only focus on the case when both POs are missing. Please note that the key idea of our method is to apply a pseudo-outcome transformation to obtain a single dataset $(X_i, \\widetilde{Y}_{\\varphi, i})$, where $\\widetilde{Y}_{\\varphi}$ depends on the observables $X$, $Y$, and $W$. This transformation merges both the control and treated group into one dataset. Our framework applies the regression model and CP procedure to $(X_i, \\widetilde{Y}_{\\varphi, i})$. Since the covariates in this dataset are drawn from $P_X$, the tuple $(X_i, \\widetilde{Y}_{\\varphi, i})$ is exchangeable between calibration and test data, and there is no covariate shift between calibration and test pseudo-outcome labeled data points. Intuitively, for the IPW and DR-learners, the pseudo-outcome transformation adjusts for covariate shift in the output space rather than the covariate space.\n\n- **What affects the relative performance of meta-learner-based approaches?**\n\nWe agree that a pre-fitting test for whether meta-learners would be a good approach for the problem at hand is important for practitioners to best use our method. It is hard to attribute performance to a single aspect of the data generation process (i.e., noise or non-linearity). Our hypothesis is that the “very strong dominance of pseudo-scores over oracle scores” (Line 339) that leads to the under-performance of meta-learners in terms of interval length is also associated with poor RMSE. We are working on a theory to establish the formal relationship between the meta-learner’s interval length and RMSE. If both quantities correlate, we can devise a hypothesis test for whether the RMSE of the conformal meta-learner exceeds that of the WCP methods, we can use this test to determine whether we should use conformal meta-learners for inference. Luckily, there are already plenty of formal model selection procedures for CATE estimation models that can be used for this purpose. \n'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the thoughtful feedback and comments. In the final manuscript, we will fix the overlapping elements in Fig. 4(c).\n\nPlease see below our point-by-point responses to your comments. \n\n- **Uncheckable assumptions involved in the stochastic ordering framework**\n\nWe are unsure what assumptions the reviewer is referring to. The assumptions required for Theorems 1 and 2 in our paper to hold are:\n\n-- Exchangeability of training and testing points (Line 230). Note that this is a typical assumption that is guaranteed if the data points are drawn from i.i.d distributions.\n\n-- The propensity score is known. This is not an uncheckable assumption, and it holds in application domains where the treatment mechanism is known. \n\nPlease note that **we do not assume stochastic ordering** between the pseudo-scores and oracle scores. Instead, we prove that if such ordering holds, then the resulting predictive intervals are valid (Theorem 1). In Theorem 2, we show that some of the well known pseudo-outcome transformations guarantee that stochastic ordering holds. Both results rely only on the two assumptions adobe and both assumptions are checkable.\n\n- **Performance comparison with other methods**\n\nThe reviewer mentions that the proposed method only improves the RMSE of the CATE and not the interval width. Please note that the main goal of the paper is to develop an inference procedure that reuses some of the meta-learner architectures that perform well in terms of the RMSE while retaining validity of inference. That being said, the conformal DR-learner also outperforms all valid methods in terms of interval length (i.e., efficiency) in many experiments. In 77 experiments within the ACIC benchmark (provided in the Appendix), we found that DR-learners consistently outperformed all valid baselines (WCP exact and naive) in terms of efficiency and not just RMSE (Fig. c.1 in the Appendix).\n\n- **Plug-in estimates of the propensity scores**\n\nYes, when the propensity scores are unknown, a plug-in estimate of $\\pi$ can be used instead of the true propensities in the pseudo-outcome transformation. However, Theorem 2 will not hold in this case and a new analysis is needed. Fortunately, our proposed stochastic order framework can still be used to analyze the setting when propensity scores are approximate (please also refer to our responses to **Reviewers 855y** and **vDHA**).\n\n- **Conservatism of conformal meta-learners**\n\nWe found the DR-learner intervals to be overly conservative only in the NLSM experiment. This is why we chose to highlight the NLSM experiment in the main text in order to demonstrate the cases when conformal meta-learners under-perform. \n\nOur empirical results do not show that its intervals are generally more conservative than other valid procedures. In most of our experiments (Fig. 4(b) and 4(c), Table 2 (IHDP)), the DR-learner intervals were comparable to the valid inference baselines (WCP exact and naive). In our extensive experiments on 77 datasets from the ACIC challenge (provided in the Appendix), we found that conformal DR-learners significantly outperforms all valid procedures based on WCP in terms of efficiency (Figure C.1 in the Appendix). \n\nIn theory, there is no reason to believe that conformal meta-learners are destined to issue conservative intervals compared to the naive and exact WCP methods. These methods use Bonferroni correction or other multiple testing approaches to combine intervals on POs, which is also going to lead to conservative intervals. The conservatism of ITE intervals is a natural consequence of not observing counterfactuals.\n'}}, {'rebuttal': {'value': 'Thank you for your thoughtful comments and the feedback on our paper. Please see below some points that we would like to clarify in response to your comments. \n\n- **Knowledge of the propensity scores**\n \nPlease note that this is not a unique limitation to our method. To date, all valid inference procedures for ITE in the literature require knowledge of the propensity scores. There are practical setups where this assumption will hold true, i.e., when the data comes from a randomized trial with or when treatment assignments follow a strictly known policy.  However, when the data comes from a real-world observational study, we need to estimate the propensity score $\\pi$ and use this estimate in the pseudo-outcome transformation. In this case, the results in Theorem 2 will no longer hold and we will need to establish the conditions under which approximate propensity scores would give rise to valid inferences.\n\nOn the positive side, the theoretical framework we proposed in this paper can help address this problem. Since the results of Theorem 1 still applies under approximate propensities, our stochastic ordering framework can still be used to analyze the validity of conformal meta-learners with approximate propensity scores. To approach this problem, one can use a PAC-style generalization bound on approximate propensities along with Theorem 1 to derive conditions for stochastic dominance (i.e. validity).\n\n- **Conservatism of conformal meta-learners**\n\nWhile we have not conducted a theoretical analysis of the efficiency of the DR-learner, our empirical results do not show that its intervals are more conservative than other valid procedures. In most of our experiments (Fig. 4(b) and 4(c), Table 2 (IHDP)), the DR-learner intervals are comparable to other valid procedures (WCP exact and naive) and are only outperformed by invalid procedures (inexact WCP). We chose to highlight the NLSM experiment in the main text in order to show the cases where conformal meta-learners under-perform, i.e., when the CDF of pseudo-scores and oracle scores deviate significantly (Figure 5). In our extensive experiments on 77 datasets from the ACIC challenge provided in the Appendix, we found that conformal DR-learners significantly outperforms all valid procedures based on WCP in terms of efficiency (Figure C.1 in the Appendix).\n\nIn theory, there is no reason to believe that conformal meta-learners are destined to issue conservative intervals compared to the naive and exact WCP methods. These methods use Bonferroni correction or other multiple testing approaches to combine intervals on POs, which is also going to lead to conservative intervals. The conservatism of ITE intervals is a natural consequence of not observing counterfactuals—analyzing the optimal length of these intervals is an interesting direction for future work.\n\n- **Comparison with the oracle interval length in synthetic experiments**\n\nThank you for this suggestion. We believe that we have already done this comparison in Figure 4(b) (blue vertical lines correspond to optimal interval widths). Please let us know if this addresses your question or if we misunderstood the oracle length you are referring to.\n'}}, {'rebuttal': {'value': 'We would like to thank the reviewer for the thoughtful and detailed feedback. Please see below our point-by-point responses to your comments. \n\n- **Conformal meta-learners and inductive biases**\n\nIn the points below, we clarify our argument on how the proposed framework enables a more flexible set of choices of inductive priors for the CATE function.\n\n1. First, we would like to stress that we *did not claim* that conformal meta-learners are *not affected by the choice of inductive priors* or that they are *robust to inductive biases*. In fact, inductive priors are not a problem that we need to overcome, but rather a design dimension that we need to consider when building our estimators. As we mention in Lines 146-147, covariate shift and inductive priors are *”two distinct characteristics of CATE estimation that interact with the conformal prediction procedure”*. As the reviewer rightly pointed out, the performance of the model (in terms of RMSE and efficiency) will depend on the choices for the models of $\\mu_0$ and $\\mu_1$. This is also evident in all our empirical results that compare the different meta-learners (i.e., different inductive biases) in Figures 4 and 5, as well as Tables 2 and 3.\n\n2. The key finding of our paper is that a stochastic ordering framework can be used to evaluate the **validity (and not performance) of any meta-learner architecture** that encodes a specific inductive prior. This means that through the conformal meta-learners approach, we can apply CP to a broader class of models that correspond to a wider range of inductive priors. This enables us to conduct CP on top of models that typically perform well in terms of point estimation (RMSE), such as the DR-learner, instead of restricting to models that estimate and conformalize potential outcomes separately as in [1].\n\n3. To sum up, our work does not propose a method that is *robust to inductive biases*, but proposes a framework for conducting valid inferences with a broader class of inductive priors than what was previously possible.\n\n4. We believe that this confusion might have been caused by the wording in Line 47 which presents covariate shift and inductive biases as *two challenges*. We will improve the phrasing of this paragraph in the final version of the manuscript.\n\n- **Conformal meta-learners and covariate shift**\n\nCovariate shift arises in the treatment effect estimation problem because the covariates in the datasets $(X_i, Y_i(0))$ and $(X_j, Y_j(1))$ are drawn from distributions $P_{X|W=1}$ and $P_{X|W=0}$, respectively, which differ from the target distribution $P_X$.\n\nOn the contrary, when we apply the pseudo-outcome transformation, we get a single dataset $(X_i, \\widetilde{Y}_{\\varphi, i})$, where $\\widetilde{Y}_{\\varphi}$ depends on the observables $X$, $Y$, and $W$. This transformation merges both the control and treated group into one dataset. Our framework applies the regression model and CP procedure to $(X_i, \\widetilde{Y}_{\\varphi, i})$. Since the covariates in this dataset are drawn from $P_X$, there is no covariate shift. Intuitively, for the IPW and DR-learners, the pseudo-outcome transformation adjusts for covariate shift in the output space rather than the covariate space.\n\n- **Knowledge of the propensity scores**\n\nTo the best of our knowledge, all existing valid inference procedures for ITE require knowledge of the propensity scores. This assumption holds true when the data comes from a randomized trial with or when treatment assignments follow a strictly known policy. When the data comes from an observational study, we need to estimate the propensity score $\\pi$ and use this estimate in the pseudo-outcome transformation. The challenge that would arise in this case is that the results on Theorem 2 will no longer hold and one will need to establish the conditions under which approximate propensity scores would give rise to valid inferences.\n\nSince the results of Theorem 1 still applies under approximate propensities, we note that our stochastic ordering framework can be useful in analyzing the validity of conformal meta-learners with approximate propensity scores. To approach this problem, one can use a PAC-style generalization bound on approximate propensities along with Theorem 1 to derive conditions for stochastic dominance (i.e. validity). \n\n- **Clarity of writing in Section 3**\n\nThank you for this suggestion. In the final manuscript, we will improve the clarity of writing in Section 3 by clarifying how conformal meta-learners handle inductive biases and covariate shifts as explained above.\n'}}, {'summary': {'value': 'The paper deals with confidence intervals for the ITE prediction task, where the authors propose to use the framework of conformal prediction for meta learners. The learning of nuisance models for generating pseudo outcomes is done one separate data split, and the final regression models trained to predict pseudo outcomes are evaluated on a validation set to compute the empirical calibration distribution. The proposed approach for calibration removes the issues of covariate shift and inductive biases on nuisance models with the prior approaches of weighted conformal prediction. The authors also provide guarantees on when the confidence intervals for ITE with pseudo outcomes cover the confidence interval for ITE with true outcomes; and further validate their findings with synthetic and semi-synthetic datasets.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '* ITE prediction is an extremely relevant problem in causal inference as population level effects (ATE, CATE) would not necessarily transfer to the individual level effects. Further, having an estimate of uncertainity along with ITE prediction is crucial for high-stakes application scenarios. Hence, the approach of conformal meta learners is highly relevant for the current challenges in causal inference. \n\n* The proposed combination of conformal prediction with meta learners is novel to the best of my knowledge. Further, the ITE coverage results with pseudo outcomes for standard meta learners (DR Learner) are quite significant as it is non-trivial to understand when the predicted confidence intervals with observed information can represent the confidence intervals with counterfactual information. \n\n* The proposed conformal meta learner approach is technically sound with theoretical proofs on their validity and empirical justification on a decently diverse set of benchmarks.'}, 'weaknesses': {'value': 'I do not think the paper has any serious weaknesses, but I have listed some of them in the questions section ahead. One major suggestion is that the paper could be written with better clarification for the section on conformal meta learner being robust to covariate shift and inductive biases. The arguments are stated informally and it is a bit hard to follow.'}, 'questions': {'value': '* I do not understand the argument of authors that conformal prediction with meta learners is not affected by the choice of inductive biases of nuisance models. The pseudo outcomes are a function of the nuisance models, hence the predicted effect (ITE), which is learnt using pesudo outcomes, indeed depends indirectly on the nuisance models. Hence, the choice of nuisance models would affect the empirical calibration distribution, consequently the confidence intervals for ITE. \n\n* I do not follow the argument of authors that conformal meta learners are not affected by the covariate shifts. The covariate shift between the control and treatment population should still affect the computation of pseudo outcomes with finite samples; hence the confidence intervals.\n\n* Please clarify the assumption of knowing the true propensity model. What challenges would the authors in their analysis if they do not make this assumption.'}, 'limitations': {'value': 'Yes, the authors have addressed any potential negative societal impact of their work.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper adresses individual treatment effect (ITE) inference using conditional average treatment effect (CATE) meta learners. \n\nThe authors propose to wrap the meta-learners with a conformal prediction step so as to obtain valid confidence intervals for the estimated treatment effect. Since the CATE estimator induces a distribution shift wrt conformity scores, the coverage guarantee does not immediately translate into the desired coverage of actual ITE. In a who can do more can do less spirit, the authors point out that ITE coverage is ensured if conformity scores obtained from pseudo-outcomes stochastically dominate the scores obtained from actual «\xa0oracle\xa0» outcomes. The authors succeed at providing stochastic dominance results for several stochastic order / meta-learner pairs. \n\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- the paper is very clear and pleasant to read\n- the tackled problem is challenging and impactful\n- the proposed solution is backup by both theoretical and experimental results'}, 'weaknesses': {'value': '- the method is by-design over-conservative \n'}, 'questions': {'value': 'In my humble opinion, this is a very good paper. The problem is well formulated, the proposed solution is clearly exposed and easy to reproduce. The solution is theoretically proved to work (under some clearly stated conditions) which is confirmed by numerical studies.\n\nFurthermore, the authors have correctly self-identified the limitations of their approach (knowledge of propensity score and hard to assess level range). \n\nMy only remark is that I would have like to see a synthetic experiment how far is the proposed solution to the optimum/oralce especially in terms of interval length.'}, 'limitations': {'value': '- knowledge of the propensity score is required\n- validity range of level $\\alpha$ not always easy to determine\n- over-conservatism of the prediction intervals\n\nThe two first points are already discussed by the authors in the submission. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""The paper introduces a framework for inferring treatment effects, merging concepts of conformal prediction and meta-learner. This framework is characterized by its distribution-free validity and coverage guarantees. The authors utilize stochastic ordering techniques to substantiate the framework's validity.""}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper is well written and sounded. The innovative approach of employing stochastic ordering to validate the use of pseudo outcomes in conformal prediction is particularly noteworthy.'}, 'weaknesses': {'value': 'The concept of employing stochastic ordering is innovative; however, its practical application is impeded by the fact that the assumptions are inherently uncheckable\n\nIn comparison to the method proposed in [1], the current method exhibits better performance only in terms of the RMSE of the CATE. However, when considering coverage and average length, it does not surpass the performance of the inexact method. \n\n\n[1] Lihua Lei and Emmanuel J Candès. Conformal inference of counterfactuals and individual treatment effects. Journal of the Royal Statistical Society Series B: Statistical Methodology, 83(5):911–938, 2021.'}, 'questions': {'value': '(1). Assuming the propensity score is unknown, could we estimate it first and then follow the same procedure outlined in the paper?\n\n(2). For the experimental results, it seems your method can be overly conservative.\n\n(3). Figure 4(c) could be adjusted to resolve the issue of elements overlapping.'}, 'limitations': {'value': 'See weakness'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper develops a meta-learner-based approach for conformal inference of individual treatment effects (ITEs). Instead of predicting the missing outcome (the counterfactual), the proposed approach uses plug-in pseudo outcomes as the inference proxy. The validity of ITE inference is based on careful analysis of the statistical dominance of the ITE and the inference proxy. In this way, one no longer needs to adjust for the covariate shifts in applying conformal inference, and the validity holds in a model-free fashion (although the coverage guarantee is more limited). Overall, this paper finds a novel approach to predictive inference of ITEs, and the method works well in synthetic and real-world datasets. '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. Novel contribution to an important problem \n\nThis paper makes novel contributions, with a new methodology, to an important problem: uncertainty quantification and predictive inference of individual treatment effects. The proposed methodology significantly differs from the PO-prediction-based approaches in the literature, and the analysis contains interesting findings/perspectives. I believe these are important contributions to the literature of conformal inference, and might inspire more developments in the future. \n\n2. Good writing quality and clarity \n\nThis paper is well-written and enjoyable to read. The challenges are clearly stated and the contributions are easy to capture. I still have some questions/suggestions for improving the presentation; please see my questions. '}, 'weaknesses': {'value': '1. The analysis is somewhat limited to the known propensity case. \n\nSince previous ITE methods already achieve validity in the known propensity case, the contribution of this paper is somewhat marginal in the sense that it does not push the limit of how well/ how much we can do for this problem (although i still appreciate the novel perspective provided here). However, the authors only mentioned the challenge of unknown propensity score at the end of the paper, which is a bit unsatisfactory. \n\n2. The setting in synthetic datasets should be stated more clearly. \n\nI think the most challenging part of ITE inference is when both POs are missing, and this is where the proposed approach becomes most interesting. However, when reading the experiments part I am not sure which situation we are in. Are we inferring the ITE for both POs missing case, and what is the calibration data here? I think further clarification will be helpful. \n\n3. The benefits of this method in experiments is a bit unclear. \n\nThe experiment part contains rich information. However, I am not sure I fully understand in which cases the proposed method performs the best - is it particularly beneficial for both-PO-missing case, or one-PO-missing part? I thought in the latter case the previous approach should suffice, or it still can be improved due to no covariate shift adjustment? I also do not understand why IPW and DR lead to so long prediction intervals for the NLSM dataset. It is mentioned that ""conformity scores have “very strong” dominance over oracle scores"", but it is difficult to understand in which cases this might happen (strong signal? large noise? high nonlinearity?).'}, 'questions': {'value': ""1. What if the propensity score is unknown? \n\nA natural question is whether the proposed method is robust to fitted propensities in the pseudo outcomes. I guess the dominance condition should still be (approximately) reasonable if the estimation is accurate (at least for DR?) since the expectation is the same, and the linear relation still holds? Currently the discussion on this point is a bit passive. But given the existing methods' good performance in this aspect, I was wondering whether more can be said about this problem. \n\n\n2. Do we have a sense of how large $\\alpha^*$ is for conditions (ii) and (iii) in Theorem 1, or practically used conformity scores? \n\nIt is also discussed that $\\alpha^*$ is difficult to know, which I think is a hurdle to the current method. While it's said that $\\alpha^*$ is evaluated in the experiments, I didn't understand how this can be done. Can we have some examples of the $\\alpha^*$ under some parametric models + gaussian noise? Can we know how it changes with characteristics of the distributions? \n\n\n3. A clarification question: Does it only apply to the setting without covariate shift? \n\nFrom my understanding the method requires that the calibration data are exchangeable with the future point. This means for both-PO-missing parts we should also find such individuals in the calibration data, and similarly for single-PO-missing ones. If this is the case, it will be helpful to explicitly mention this because it would be helpful to practitioners. \n\n\n4. Clarification in the presentation of the experiment part. \n\nWhen reading the experiments part I am not sure which situation we are in. Are we inferring the ITE for both POs missing case, and what is the calibration data here? Did you evaluate the performance for the case with only one PO missing? \n\n\n5. What affects the relative performance of meta-learner-based approach? \n\nI see that the performance of the proposed approach is not always the best, and it can yield very long intervals for the NLSM dataset. It is important for practitioners to understand in which cases this method will perform well or poorly. Is it possible to give some guidance on how the performance changes with the data generating process, such as the coupling of POs, the strength of signal/noise? \n\n\n\n---\nMinor points & typos:\n\n1. Should condition (ii) in Theorem 1 be $V_\\varphi \\succeq_{(2)} V^*$? Seems the current order is opposite to other types of conditions. ""}, 'limitations': {'value': 'Yes.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Conformal Meta-learners for Predictive Inference of Individual Treatment Effects'}, 'authors': {'value': ['Ahmed Alaa', 'Zaid Ahmad', 'Mark van der Laan']}, 'authorids': {'value': ['~Ahmed_Alaa1', 'zaidahmad@berkeley.edu', 'laan@berkeley.edu']}, 'keywords': {'value': ['Heterogeneous treatment effects', 'conformal prediction']}, 'abstract': {'value': 'We investigate the problem of machine learning-based (ML) predictive inference on individual treatment effects (ITEs). Previous work has focused primarily on developing ML-based “meta-learners” that can provide point estimates of the conditional average treatment effect (CATE)—these are model-agnostic approaches for combining intermediate nuisance estimates to produce estimates of CATE. In this paper, we develop conformal meta-learners, a general framework for issuing predictive intervals for ITEs by applying the standard conformal prediction (CP) procedure on top of CATE meta-learners. We focus on a broad class of meta-learners based on two-stage pseudo-outcome regression and develop a stochastic ordering framework to study their validity. We show that inference with conformal meta-learners is marginally valid if their (pseudo-outcome) conformity scores stochastically dominate “oracle” conformity scores evaluated on the unobserved ITEs. Additionally, we prove that commonly used CATE meta-learners, such as the doubly-robust learner, satisfy a model- and distribution-free stochastic (or convex) dominance condition, making their conformal inferences valid for practically-relevant levels of target coverage. Whereas existing procedures conduct inference on nuisance parameters (i.e., potential outcomes) via weighted CP, conformal meta-learners enable direct inference on the target parameter (ITE). Numerical experiments show that conformal meta-learners provide valid intervals with competitive efficiency while retaining the favorable point estimation properties of CATE meta-learners.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/71a53f799d2d38af1f45a8cfe5e91dc17acccea5.pdf'}, '_bibtex': {'value': '@inproceedings{\nalaa2023conformal,\ntitle={Conformal Meta-learners for Predictive Inference of Individual Treatment Effects},\nauthor={Ahmed Alaa and Zaid Ahmad and Mark van der Laan},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=IwnINorSZ5}\n}'}, 'paperhash': {'value': 'alaa|conformal_metalearners_for_predictive_inference_of_individual_treatment_effects'}}]"
['Kevin Ellis'],NeurIPS,Human-like Few-Shot Learning via Bayesian Reasoning over Natural Language,https://neurips.cc/virtual/2023/oral/73840,2023," A core tension in models of concept learning is that the model must carefully balance the tractability of inference against the expressivity of the hypothesis class. Humans, however, can efficiently learn a broad range of concepts. We introduce a model of inductive learning that seeks to be human-like in that sense.It implements a Bayesian reasoning process where a language model first proposes candidate hypotheses expressed in natural language, which are then re-weighed by a prior and a likelihood.By estimating the prior from human data, we can predict human judgments on learning problems involving numbers and sets, spanning concepts that are generative, discriminative, propositional, and higher-order.",Oral 3A Neuro,https://openreview.net/pdf?id=dVnhdm9MIg,https://openreview.net/forum?id=dVnhdm9MIg,dVnhdm9MIg,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper presents a method that synthesizes computational cognitive science modeling with large language models, crossing discipline boundaries and making a creative new contribution. Reviewers all agree it should be published, with some very strongly advocating for its value. Authors were responsive during the rebuttal, addressing  the reviewer suggestions. Should definitely be presented at NeurIPS, likely as a spotlight or oral.'}}, {'title': {'value': 'Thanks for the detailed response.'}, 'comment': {'value': 'I appreciate the careful point-by-point responses. While I have to disagree with this characterization of the Bayesian computational cognitive science literature (full disclosure: I am an author on one of the referenced papers), I understand that not all disagreements can be resolved through this channel, and my remaining quibbles are minor relative to the strengths of the paper. I have bumped up my score to reflect the improvements made through the response process.'}}, {'title': {'value': 'Thanks for the reply!'}, 'comment': {'value': 'Thank you for the reply, which is very helpful for clarifying the few things I found unclear about the paper. I continue to view this paper highly and to enthusiastically recommend acceptance.'}}, {'title': {'value': ""Thanks for the engagement! We're revising as follows""}, 'comment': {'value': 'Thank you for raising interesting points and helping us refine the paper. We\'re revising as follows:\n> the exact same theoretical model with different choices plugged in could do substantially better or worse in practice.\n\nThis is an important point, and relevant to many structured Bayesian cognitive models: there are typically multiple reasonable choices for the prior, likelihood, inference method, and hypothesis space. In our past experience with Bayesian models, good agreement with humans requires at least *some* “tinkering” of these components, and can require sampling budgets larger than what we think humans plausibly process.\n\nRelative to other Bayesian Program Learners we’ve worked with, this new model required less ""tinkering"", and vastly smaller sampling budgets. For example, all LLMs reported are the first ones we tried (except for logical concepts: we tried codex before GPT4). We needed less “tinkering” as we largely remove a critical degree of freedom: The design of the structured symbolic hypothesis space itself. We also introduce new degrees of freedom, like the choice of LLM, and new continuous parameters for estimating the prior.\n\nSome related models, like Rational Rules, have almost no continuous parameters, but require designing a custom discrete hypothesis space. Piantadosi et al. ‘16 shows such model performance depends on that design. We have extra learnable parameters, but remove combinatorial degrees of freedom as a result.\n\nWe\'ll add this to the discussion:\n\n**Generalizability of the theoretical framework.** The basics of the model make few commitments, yet instantiating it requires selecting specific language models, engineering prompts and likelihoods, etc. More broadly, a high-resolution cognitive model, particularly a structured Bayesian one, requires domain-specific modeling choices. How much credit should we assign to the general theoretical framing, as opposed to particular engineering decisions? Although our paradigm introduces new degrees of freedom (which LLMs/prompts to use), it removes others (the grammatical structure of the symbolic hypothesis space). On balance, we are cautiously optimistic that the framework will generalize with significantly less domain-specific tinkering, at least for abstract symbolic domains. This optimism is because the framework replaces hand-designed structured hypothesis spaces with pretrained neural models, and because reasonable “default” neural networks worked well across our experiments.\n> someone includes this model as a baseline… plug in a set of \'reasonable\' off-the-shelf models… find that it performs very poorly relative to their approach. Would they then be licensed to reject the whole model?\n\nFollowing the above discussion, we’d feel comfortable with other researchers using the theoretical framework as a baseline and rejecting it if it flunks their data. (And we couldn’t say the same for DreamCoder, BPL, SOAR, etc.) One nuance, though, is that the proposal distribution needs a strong LLM, which we now have hard data to support, thanks to your earlier input.\n> the terminology... \'inference\' is being used in a deeply misleading way here... [suggesting] the problem of \'performing Bayesian inference over natural language\'... using, e.g., principles of pragmatics and social cognition\n\nThank you for explaining. We’ll change the title to not include the phrase “Bayesian Inference over Natural Language”, and clarify that our work has nothing to do with the Rational Speech Act model, recursive/social reasoning, etc. Thanks for suggesting possible titles.\n\nWe also use “utterance” in the paper. Do you think that could mislead readers into thinking this is about external communicative language? If so, we’ll globally remove “utterance”.\n> I\'m not familiar with any adjacent literature that uses \'inference\' to describe the problem of marginalizing over a pre-existing posterior distribution\n\nRespectfully, we’d like to explain why we think the phrase “Bayesian Inference” is consistent with literature on Bayesian Program Learning and Bayesian computational cognitive science.\n\nWe view $q$ as a data-driven proposal distribution. Given that, Lake et al. ‘15 uses “inference” to refer to generating data-driven proposals, which are then weighed by prior and likelihood, like our model. This approximate posterior—the result of inference—is then marginalized over to form predictions, like our model. DreamCoder [Ellis et al. ‘21] also uses this terminology, as does Latent Language [Andreas et al. ‘18] (“inference”, minus the term Bayesian).\nOther NeurIPS papers in cognitive modeling have long used similar terminology. From Shi&Griffiths ‘09: “importance sampling provides a simple and efficient way to perform Bayesian inference, approximating the posterior distribution with samples from the prior weighted by the likelihood.”\n\nThinking of the raw LLM as a pre-existing amortized posterior is an interesting perspective, but not the only appropriate vocabulary.'}}, {'title': {'value': 'Thanks! '}, 'comment': {'value': 'I very much appreciate the careful and thoughtful response, particularly the new results with Llama-2 pointing out the importance of having a strong pre-trained model for the proposal distribution. I think the paper will be greatly strengthened by these changes. I still think this is a good paper (thus the positive score) but given the opportunity for some back-and-forth, I wanted to clarify two points. \n\n1. About the \'brittleness\' of the pipeline: I agree that the \'classes\' of ablations appropriately map onto the \'joints\' of the approach. I was instead trying to note brittleness in the linking function between the idealized mathematical model worked out in section (3) and the many specific *instantiations* or *choices* used to realize the model (e.g. `CodeGen` for the pre-trained prior, `all-MiniLM-L6` for the tuned prior, ` code-davinci-002` as the proposal distribution translating to Python, the tuneable Platt transform as the linking function to Likert ratings, etc.) Each of these choices represent an important \'ancillary assumption\' that constrains the interpretation of the results --- the exact same theoretical model with different choices plugged in could do substantially better or worse in practice. Imagine that someone includes this model as a baseline in a future paper; they plug in a set of \'reasonable\' off-the-shelf models as the linking functions, and find that it performs very poorly relative to their approach. Would they then be licensed to reject the whole model? Or would you respond ""of course it doesn\'t work if you plug in those, you should have used these."" But there are enough \'experimenter degrees of freedom\' for each choice that it\'s not clear what can ultimately be attributed to the core theoretical approach (vis-a-vis section 3) and what is an artifact of the particular bundle of ancillary assumptions used as linking functions. It\'s ok if it\'s intended to be an existence proof that some bundle of ancillary assumptions suffices to achieve a certain level of performance, but it\'s hard to generalize any core principles. \n\n2. About the terminology: I\'m sorry to be grumpy about this, but I have to insist that \'inference\' is being used in a deeply misleading way here. There is an active community at the intersection of computational cognitive science and ML specifically working on the problem of \'performing Bayesian inference over natural language\' (i.e. inferring a posterior `P(concept | natural language) \\propto P(natural language | concept) P(concept)` using, e.g., principles of pragmatics and social cognition in the likelihood function). The title and abstract of the paper strongly suggest that the problem has been solved and we are now able to do Bayesian inference over natural language. However, this is not at all the problem addressed by the paper. I believe a large segment of the target audience for this paper (i.e. computational cognitive scientists working on human few-shot concept learning) will be confused or misled by the non-standard evocation of an \'inference\' problem here. I\'m not familiar with any adjacent literature that uses \'inference\' to describe the problem of marginalizing over a pre-existing posterior distribution. I\'d be much happier to recommend this paper given a less contentious (but still very cool!) tweak of the title/abstract like ""Modeling Human Few-Shot Learning using Amortized Language Models"" or ""Modeling Human Few-Shot Learning by Translating Linguistic Proposals"" or just ""Modeling Human Few-Shot Learning using Natural Language"" or something. \n'}}, {'title': {'value': 'Thanks for the response'}, 'comment': {'value': 'Thanks for the response elaborating and clarifying with respect to my questions. The additional results described (maximized predictive perf and DreamCoder baseline) and details about different prompt/model variations tried would strengthen the submission even further, which would be great to see. '}}, {'comment': {'value': ""Thanks for the response, and for the increase to your score. \n\n> I still think this paper would be better served by a longer abstract\n\nAgreed: and if accepted, we'll have an extra page to use for expanding the abstract and providing further details and discussion throughout the paper.""}}, {'comment': {'value': 'Thanks for answering my questions. The hyperparameter choices for sampling make sense to me, and my concerns have been adequately addressed. I have increased my score to a 7.\n\nI still think this paper would be better served by a longer abstract. For example, calibration is at the core of this paper, and this is elided into ""can be fit to human data"" in the abstract. Unpacking and explaining calibration with an extra sentence would make sense to me. However, if the authors feel committed to the short abstract, I will not continue belaboring this point and leave it to their discretion.'}}, {'rebuttal': {'value': 'Thank you all for your reviews, and especially for the encouragement and constructive criticism. Below we summarize some important strengths and weaknesses identified across the reviews, and overview the new results in the attached PDF that address those weaknesses.\n\n**Strengths:** \n\nqc38 describes the work as an “important advance in computational cognitive science” which ""identifies a major open question (tractability vs expressivity) and addresses it via a key insight (using natural language is now much more feasible with recent LLM advances)"". The other reviewers find the work “promising and potentially influential” [y5Ba], ""useful for future researchers"" across Bayesian AI and deep learning ""as a way to take insights from one school of thought and use them to overcome weaknesses of the other school of thought"" [ce9a], and contributing a ""super cool result"" [8GEn]. Experiments “illuminate both the power and limitations” in light of ”strong baselines” [qc38], yielding ""results [that] compare favorably with pother recent approaches that have been well-received at NeurIPS"" [y5Ba] and “provides a strong fit to human data” [ce9a]. Reviewers mentioned the ability to explain patterns of human mistakes via ""explainable failure modes""; the ability to ""generalize to totally novel concepts"" [qc38]; and last, the ""transfer [of] human priors into a neural model"" [ce9a]. From a technical perspective, reviewers describe the computational model as one which ""takes classic ideas and “\'remixes\' and integrates them in an interesting way” [y5Ba] via ""multiple non-obvious steps” [qc38].\n\n**Weaknesses, and responses (see also attached PDF):**\n\n- qc38 asks ""Is there a stronger or more recent baseline for Number Game, vs Latent Language from 2018?"", echoed by y5Ba, who requests ""a more reasonable neurosymbolic BPL baseline"". We have now run DreamCoder, a 2001 neurosymbolic Bayesian Program Learner. We find a nontrivial gap between DreamCoder and our model (see attached PDF), even when DreamCoder is granted 2 orders of magnitude more test-time samples. This finding further supports the conclusion that, relative to prior BPL frameworks, our model can produce more human-like predictions with far fewer samples.\n\n\n- y5Ba points out that we use closed-source LLMs, which is a reproducibility hazard. qc38 has a slightly different take, noting ""reproducibility issues with using GPT4 seem addressed by including the responses in the software/data release"" (indeed: we are including it in the data release, as noted in the author checklist). Further addressing this reproducibility hazard is being done by replicating the results using an open source model, Llama-2. The provided PDF shows results on a Llama-2 Number Game model, showing that open LLMs can be used to build a decent model, but that they are currently slightly worse than OpenAI\'s LLMs as a proposal distribution. (Llama-2 on logical concepts would take more than 2 weeks to complete on the hardware available to us.)\n\n\n- y5Ba asks ""how to do credit assignment to the many potentially brittle component parts of the pipeline"" and requests a broader set of LLMs be tried, including weaker ones for different pipeline stages. As a reminder, the pipeline includes prior, likelihood, and proposal distributions. We ablated the prior by not tuning it, and by disabling it completely (for latent language), and also ablated the proposal distribution, but we never ablated the likelihood. The attached PDF shows a new likelihood ablation, revealing that the likelihood is very important. To understand what happens when the individual components are merely made weaker instead of ablated entirely, the new Llama-2 results include data for when individual components are replaced with the weaker Llama-2. The new data show that weaker LLMs can implement effective likelihood models, but stronger LLMs are important for proposal distributions, especially in the low-sample regime. Although the Llama-2 results do not change the scientific conclusions, they are helpful in understanding how to practically engineer systems like ours using off-the-shelf tools.\n\n\n**Potentially Revised Terminology:** Reviewer y5Ba suggests that the framing as ""Bayesian inference over natural language"" is technically incorrect, preferring to think of pretraining the LLM as ""inference"", and our model as predicting based on that already inferred distribution. We\'re happy to revise our terminology, and understand that Bayesian vocabulary can be quite nuanced (and occasionally contentious!). Right now, we think our original terminology is consistent with adjacent literature, but we can go with whatever terminology the reviewers collectively feel is best.'}, 'pdf': {'value': '/pdf/ab4120f7a1d93151b79bb48a1867d86817b9c690.pdf'}}, {'rebuttal': {'value': 'Thank you for the thoughtful input and enthusiastic support. We are happy to correspond more during the discussion period, but here we mainly just address the specific question you raised:\n\n> …unclear to me what the paper’s main contribution is: Is it (i) a new hypothesis about how humans perform few-shot learning, or is it (ii) a way to make tractable some previously-existing hypotheses that were previously intractable to evaluate? … It’s clear that the paper accomplishes (ii), but it is not obvious to me that it does (i)\n\nThank you for this helpful way of thinking about the different contributions of the work.\n\nOur main contribution is (ii), offering a computational model that makes inference tractable for certain very expressive hypothesis spaces that have proved valuable in cognitive modeling (Line 31: ""Our goal is to build a model of humanlike concept learning that makes progress toward resolving the tension between intractable inference and expressive hypothesis classes""). There is also a more speculative account of our contributions (i), namely that our model offers a hypothesis for how human brains resolve the “curse of a compositional mind” (Spelke 2022: freeform recombination of concepts yields a combinatorial explosion). In this more speculative hypothesis, culturally-transmitted concepts and linguistic schemas help guide inner thought, making combinatorial thinking more tractable. We\'ve shied away from making that claim, because it is not directly supported by our findings, though it is not contradicted by our work, either. Right now the manuscript tries to strike a balance by simply saying that ""Natural language, even if it is not actually the same as our inner mental language, acts as a vast reservoir of human concepts, and provides a flexible algebra for combining them. Thus our best near-term strategy for modeling human thinking may be  to use natural language as a *heuristic approximation* to an inner Language of Thought"" (emphasis added), later refining the claim from natural language generally to large language models specifically as a ""reasonable surrogate for this [human] bottom-up [proposal] process, even if it its inner workings might differ greatly from human bottom-up proposal processes"".\n\nWe hope that the paper\'s current wording manages to strike the right balance, and are happy to revise in order to more clearly signpost the actual contributions, results, and concrete hypotheses, especially given that, if accepted, we have an additional page to include discussion and add clarifications.\n\nLast, about the other weaknesses you raise:\n> [the work is] not suited to concepts that do not have a straightforward linguistic definition... the authors are clear in stating (in lines 286 to 293) that they do not claim that natural language is the language of thought but rather that it is a useful heuristic tool for modeling human thinking.\n\n> Natural language is ambiguous, so natural language strings do not really provide clear concept definitions - and, by extension, inference over natural language strings cannot strictly be viewed as inference over concept definitions. The authors acknowledge this point\n\nIndeed, we *do not* provide a unified theory of human few-shot concept learning. Thank you for pointing out that the submission is careful about clearly discussing the limits of the work.'}}, {'rebuttal': {'value': 'Thank you for the thoughtful review and kind words. Below we respond to some of your main points, but can discuss further during the discussion period:\n\n> Do you have thoughts on exactly how ""strong"" you should make the prior and likelihood functions?\n\nOur thoughts are that the proposal distribution $q$ needs to be the ""strongest"", because it needs to propose plausible hypotheses from scratch. In our paper, the likelihood $p(X|C)$ only needs to translate English to Python, so it requires a decent LLM or a fine-tuned smaller model (we likely could have fine-tuned a T5-like model also).\n\nIn the global response, we have attached a PDF showing analysis of using smaller open-source models for the proposal distribution and the likelihood. These new results suggest, as above, that $q$ needs to be the ""strongest"", but that a weaker $q$ can still work, provided that you take more samples. This introduces an interesting tradeoff between the ""strength"" of $q$, and the amount of compute (# samples) that are taken at test time.\n\nThe prior $p(C)$ is only responsible for giving a soft bias toward simpler, shorter language, and in our experience, does not require a ""strong"" model: we tried both a 350M open source model and tuning a ~100M model.\n\n> Is there a sweet spot wrt model capabilities for matching human judgments? If so, what are the implications for your rational process model?\n\nThat is an interesting scientific question. For example, a stronger proposal distribution might sometimes outperform humans, which could suggest certain limits on bottom-up psychological processes. Although our paper does not specifically explore the questions you raise, they would make for thrilling future work. We will add this to the discussion.\n\n> What’s the sampling technique—nucleus sampling, greedy, etc?\n\nThe proposal distribution was sampled with temperature $T=1$ and $\\text{topP}=1.0$., which effectively disables nucleus sampling. Because we are taking multiple proposals, a higher temperature made more sense to encourage diversity.\n\nFor the likelihood, which calls out to an LLM to translate English to Python, we sampled with temperature $T=0$, both because Codex was very reliable at this translation, and to avoid needless stochasticity.\n\nThe revision will mention these issues. Thanks for the catch.\n\n> Why is this well-suited for natural language? [prime numbers less than 30]\n\nPerhaps a better phrasing would be that these concepts are ""suitable to be expressed in natural language"". All that is meant is that it is possible and reasonably practical to express these concepts in words.\n\n\n\n> Can you just explain how you fit the parameters right after you introduce them? I was wondering how you trained the parameters for a few paragraphs.\n\nYes, we can move up the explanation of parameter fitting in Section 4. \n\n> Figure 3: Do you have a higher resolution screenshot?\n\nNo we don\'t: this image was provided to us by Piantadosi et al. 2016 (with permission).\n\n'}}, {'rebuttal': {'value': 'Thank you for the thoughtful input, kind words, and suggested improvements. We address the main issues, with **new results bolded**, but can answer all of your questions during the discussion period.\n\n> My primary concerns are around how to do credit assignment to the many potentially brittle component parts of the pipeline\n\nIn our view, the key ideas are (1) natural language as a hypothesis space, (2) Bayesian reasoning for forming predictions, and (3) LLMs for tractable inference. Achieving the full suite of results requires all ingredients, established by comparing against Bayesian Program Learning (no natural language), latent language (no Bayes), latent source code (LLMs, but no natural language), and no proposal dist (no bottom-up proposals for tractability).\n\nOur pipeline has 3 components: prior; likelihood; and proposal distribution. We ablate the prior by not tuning it and by removing it (in latent language). The proposal distribution was also ablated. The likelihood is so critical for discarding erroneous hypotheses that we did not even consider a model without it, but **we\'ve now run a likelihood ablation (global response PDF), confirming that the likelihood computation is essential.**\n\n> what if the best cutting-edge model were used as the proposal distribution, but a weaker code-generation model were used in the likelihood\n\nTo understand what happens when the individual components are merely made weaker instead of ablated entirely, we\'ve run **new experiments on Llama-2, a recent 70B open-source model that is thought to be weaker than Codex (see attached global response PDF).** The new data show that a weaker LLM, like Llama-2, can implement effective likelihood models (act as code-generators), but stronger LLMs are important for proposal distributions, especially in the low-sample regime. Although these Llama-2 results do not change our scientific conclusions, they help in understanding how to practically engineer systems like ours using off-the-shelf tools.\n\n> Codex... has now been deprecated, making these results difficult to reproduce\n\nCodex is deprecated but freely available for academic use (with a special application needed), or on Azure (expensive, but for anyone). Ultimately, any closed-source model hurts reproducibility, and will be eventually deprecated. To mitigate this, we\'ve archived our OpenAI queries+responses, as noted in the author checklist, and are doing Llama-2 replications (see above).\n\n> data came from the extremely small, cherry-picked set of concepts used in the original Tenenbaum dataset (with N=8)... larger and more systematic datasets are now standard, e.g. Bigalow & Piantadosi\n\nBefore performing our study we closely examined the Bigalow & Piantadosi dataset and discussed it with one of the authors of that dataset. We concluded it was too noisy, and that many Mechanical Turk workers were not correctly following the instructions. We suggest examining their data for ""powers of 2"", which shows that participants failed to even label the provided numbers (16, 32, 2, 8) as being 100% in the concept.\n\nAlthough small, the Tenenbaum data exhibits important phenomena such as few-shot learning of both rule-based and similarity-based generalizations. It is also canonical and pedagogical, serving as a main example of Bayesian concept learning in the textbook ""Machine Learning: A Probabilistic Perspective"" (Murphy 2012). Although a bigger dataset would be desirable, we believe the Tenenbaum data effectively shows the basics of the model, before moving onto the bigger logical concepts dataset.\n\n> scaling... outside of toy domains\n\nFrom the perspective of cognitive modeling, the logical concept data is quite challenging. To the best of our knowledge, there is no other study of logical concept learning in humans which is nearly as broad, high-quality, and high-resolution, as Piantadosi et al. 2016.\n\n> how train-test splits were handled\n\nFor Number Game we split the human judgments in 10-way cross-validation, *mixing across concepts.* Originally we thought that with only 8 concepts, fitting a prior while holding out whole concepts would not work. **Based on your question we reran by testing only on held-out concepts, finding that the results change very little: $R^2$ drops from 0.95 to 0.91.** Therefore, the model learns a prior that works for novel concepts / training data. For logical concepts, we followed Piantadosi 2016, which held out specific learning curves run on independent participants. That split shows generalization to new training data, like the new Number Game result given above. Our replication experiments get their test data from running new participants on novel out-of-distribution concepts (training on Piantadosi 2016), again showing that the learned prior can transfer to never-before-seen concepts.\n\n> I would have liked to see a more reasonable neurosymbolic BPL baseline\n\nWe appreciate your suggestion of a modern neurosymbolic baseline, and **have now ran a DreamCoder comparison, which gives a decent (but not great) fit to Number Game concepts (attached pdf).**\n\n> \'no proposal dist\' model might potentially be competitive if it was given more than 100 samples\n\nWe performed a new experiment, finding that **with an order of magnitude more samples ($10^3$), \'no proposal dist\' agrees with the human data only at $R^2=.41$, ie, it levels off in fit, although it should eventually trend upward with enough samples.** As the number of samples tends toward infinity, \'no proposal dist\' should be just as good as the full model.\n\n>  there is no Bayesian inference at all in this pipeline, and certainly no inference over natural language\n\nWe\'ve raised this issue in the global response, and can certainly alter our word choice.\n\n> how the Latent Language model actually worked... did it just take the single maximum likelihood concept from the proposal distribution instead of marginalizing proportional to each sample?\n\nExactly, it works as you described.'}}, {'rebuttal': {'value': 'Thank you for the thoughtful review and enthusiastic support. Please find below our clarifications:\n\n> …mention of some task or problem setting that successfully ""red teams"" this approach - ie, some problem which is adversarially chosen to be challenging or ill-suited for this framework (while still remaining in-scope within the domain of non-embodied abstract concept learning).\n\nBecause we use a large language model as a proposal distribution, problems which LLMs struggle with would likely foil our approach. However, there is one caveat: because we draw multiple proposals (~100), and because we reweigh each of them using Bayes Rule, the model only needs a few proposals that hit the mark. Therefore, our approach could be “red teamed” by problems that cause LLMs to “fall on their face,” but probably not by problems that cause LLMs to become merely “flakey”. \n\nAlso, our current approach translates each natural language concept into Python, so it would struggle to learn concepts that are not easily expressible in a precise formal language like Python. This restriction is not strictly necessary: you could instead define the likelihood $p(X|C)$ using another neural model in order to allow learning ""fuzzier"" concepts, although this would probably come at the expense of precision. The last sentence of the paper alludes to these subtleties by saying ""We bypass natural language’s ambiguity by translating it into Python for the likelihood computation, but future work needs to determine if language models can produce language precise enough for induction, or if refining into languages like Python is more practical."" If accepted, we\'d have an extra page for expanding that point with this discussion.\n\n> …critically dependent on the quality of the Python code generation aspect. From the supplemental materials it looks like a lot of prompt engineering went into getting that to work\n\nFor the initial submission, we tried exactly two prompts for converting logical concepts into python: a short simple prompt (which was unreliable), and later a very long prompt, which proved reliable (but probably went overboard). In the weeks after the submission, we also tried prompting GPT-4 with instructions but no few-shot examples, which works better than the long Codex prompt used in the initial submission.\n\nIn our experience, though, converting simple natural language utterances into snippets of python requires little prompt-engineering, provided one is willing to use larger models such as Codex. In the global response, we also describe new results using Llama-2 70B, a very recent open source LLM, to convert natural language into Python, which required zero new prompt engineering.\n\n> I guess if we were purely looking for some kind of ""predictive performance"" task there might be other approaches that ""outperform"" the framework here. However, the grounding in cognitive science for this work means that is probably not the right criterion, but rather this work is pursuing improved understanding of learning itself.\n\nIndeed, our primary aims are scientific. After the submission deadline, we tried optimizing the logical concept model to maximize average task performance, instead of maximizing fit to humans. We found that the maximizing average performance makes the model surpass human performance, but also degrades human-model agreement. If accepted, we will include these results in the revision.\n\n> Section 4: Is there a stronger or more recent baseline for Number Game, vs Latent Language from 2018?\n\nThanks for the suggestion. We have now ran a DreamCoder baseline (a recent neurosymbolic Bayesian program learner). It achieves a decent (but not great) fit to the human Number Game data: $R^2=.75$, which should be contrasted width $R^2=.95$ for our full model.\n\n> it\'s a little unclear what it means to say that $P(X_\\text{test} \\in C)$ ...  I guess the key assumption here is that $\\mathbb{1}[X_\\text{test} \\in C]$ is easily computable\n\nWe like how you put it: The key assumption is that $\\mathbb{1}[X_\\text{test} \\in C]$ is easily computed, which comes from translating $C$ into Python. A footnote will be added clarifying this.'}}, {'summary': {'value': 'The paper proposes an approach to scaling up intractable Bayesian models of few-shot concept learning. The key idea is to (1) train an amortized posterior distribution q(C|X_{1:K}) over concepts (represented as natural-language expressions) and then (2) make predictions about membership by marginalizing over a finite set of latent concepts sampled from q. Several variants of this approach are considered, all of which use a large language model (Codex) for the likelihood function p(X | C) and proposal distribution q. The approach is evaluated on two few-shot learning experiments: a generative number concept task, and a discriminative logical concept task. A version of the model that reweights sampled concepts according to a prior distribution trained on human judgements is found to fit human patterns better than alternative models which either (1) replace the human-tuned prior scores with an off-the-shelf language model (CodeGen), (2) replace the natural-language prior with a Python prior, or (3) entirely omitting the separate proposal distribution q and sampling proposed concepts directly from the (learned) prior instead.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""The manuscript presents a promising and potentially influential approach to scale up Bayesian models on few-shot learning tasks. A number of timely ideas are explored, and the results compare favorably with other recent approaches that have been well-received at NeurIPS (e.g. Bayesian program learning, and other neurosymbolic approaches). Many of the basic ideas in play are pretty familiar by now (e.g. amortizing a proposal distribution to avoid costly search over hypotheses, using natural language as a more expressive latent hypothesis space, fine-tuning on human priors to impart human-like inductive biases). But this work still 'remixes' and integrates them in an interesting way: for example, other language-guided BPL approaches (e.g. Wong et al, 2021, ICML; Andreas et al., 2017) have required a set of language annotations to fine-tune on, rather than utilizing more generic priors (although Codex would be more impractical for multi-modal tasks, conditioning on images). Evaluating on human behavior (rather than synthetic benchmarks) are another strength.""}, 'weaknesses': {'value': ""My primary concerns are around how to do credit assignment to the many potentially brittle component parts of the pipeline, and the applicability of this scaling approach outside of toy domains. One somewhat deflationary critique is that there is no Bayesian *inference* at all in this pipeline, and certainly no inference *over natural language*. The approach depends on the independent existence of a sufficiently powerful amortized posterior distribution from a very expensive inference procedure that has already been performed off-stage (i.e. training Codex). the model comparisons simply show more or less efficient ways to approximate a *predictive* distribution by marginalizing over high-probability regions of that independently pre-existing posterior. This isn't inference! Arguably, it's just wrangling the amortized product of an earlier inference, exploring different ways of leveraging human data to correct distortions in this mammoth amortized posterior and project it down to specific tasks at hand. \n\nI still think this kind of 'wrangling' work is interesting and novel, as there are clearly more or less effective ways to do it, but (1) I believe the framing of actually doing Bayesian inference over natural language is misleading (including statements like 'our work adds Bayesian inference'), and (2) I would suggest much more focus and scrutiny on the black-box, closed-source models that are the 'wizard behind the curtain,' the parts of the pipeline actually responsible for the few-shot concept induction. For example, it is stated that Codex was used 'because we hypothesized that training on source code would transfer to reasoning about numbers,' but no other choice was considered. \n\nI would like to see a bigger space of candidate posteriors compared. I would also like to see a stronger 'credit assignment' analysis testing components of the Codex pipeline (which I understand has now been deprecated, making these results difficult to reproduce?) For example, one very strong assumption is that each linguistically expressed concept maps deterministically to a single Python program, which in turn, can be evaluated deterministically on each number. There may be multiple valid programs corresponding to each linguistic utterance. What if the linguistic concept is good but the translation to python is bad? i.e. what if the best cutting-edge model were used as the proposal distribution, but a weaker code-generation model were used in the likelihood to evaluate the generated concepts on numbers? The current analysis cannot pull these apart.""}, 'questions': {'value': '1. It wasn\'t clear how train-test splits were handled. The Fig. 2 caption alludes to \'held-out\' judgements, but what was the split? How many examples were used to tune the prior? Were entire concepts held out, or were some human data seen for each example set? \n\n2. In Fig. 2, it looked like the \'no proposal dist\' model might potentially be competitive if it was given more than 100 samples to hit on good descriptions. This is still a relatively small number of samples, and even if it is somewhat expensive, it would aid understanding to extend the x-axis one more degree of magnitude. \n\n3. It looked like data came from the extremely small, cherry-picked set of concepts used in the original Tenenbaum dataset (with N=8). However, much larger and more systematic datasets are now standard, e.g. Bigalow & Piantadosi, https://doi.org/10.5334/jopd.19, releasing 272k judgements using many more concepts. I would strongly suggest reporting generalization performance to these new concepts. \n\n4. It wasn\'t clear how the Latent Language model actually worked for these task; it would help to clarify precisely how it differed from the other models in this case (did it just take the single maximum likelihood concept from the proposal distribution instead of marginalizing proportional to each sample?)\n\n5. Did the likelihood function assume boolean output from the codex-derived python code? how was this ensured? what happened if the generated python code returned an error or non-boolean? \n\n6. Section 5 states: ""Except we now have a discriminative learning problem instead of a generative one"" -- except wasn\'t the number game treated as discriminative by the model, using an indicator function (effectively deriving a disciminative classifier for whether each number is in or out the concept?)\n\n7. I would have liked to see a more reasonable neurosymbolic BPL baseline, which actually does proper Bayesian inference (i.e. MCMC) using the latent concept space as the proposal distribution over valid programs. \n\nA related more recent paper that may be worth including:\n\n* Wong, L., Grand, G., Lew, A. K., Goodman, N. D., Mansinghka, V. K., Andreas, J., & Tenenbaum, J. B. (2023). From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought. arXiv preprint arXiv:2306.12672.'}, 'limitations': {'value': 'A clear limitation is that a central pillar of the approach, the Codex API, is now deprecated and unavailable to other researchers. It is therefore not clear whether any of the results can be replicated, creating further incentive for the authors to compare performance on a number of other amortized posteriors (proposal functions) and likelihood functions, ideally those which are open and maintained.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors introduce a computational approach for explaining how humans perform few-shot concept learning. The proposal is that humans use Bayesian inference over natural-language definitions of concepts. In more detail, a bottom-up proposer generates a set of candidate concept definitions, and Bayesian inference is then performed over these candidates - based on a prior distribution over concept definitions and a likelihood capturing how well the definition covers the observed examples.\n\nThe paper then presents two main experiments that implement the proposal via the use of recent large language models (LLMs). The prior over natural-language concept definitions is the probability that an LLM assigns to the definition. The proposer is instantiated as the responses of an LLM prompted with the training examples. The likelihood is computed by translating the proposed concept definitions into Python code using a code-based LLM and then running the Python code on the training examples. In both case studies (the Number Game and learning compositional logical concepts), the proposed approach provides a strong fit to human data.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- S1: The approach provides an interesting combination of Bayesian inference and neural network models that combines complementary strengths of both approaches: the powerful inference abilities of Bayesian models and the tractability and flexibility of neural models. This combination results in a system that is arguably more powerful than either type of approach on its own, representing an important advance in computational cognitive science.\n- S2: The components of the approach are well-motivated by high-level considerations and are well-operationalized using current AI tools.\n- S3: The results are compelling: in both case studies, the proposed model shows advantages (in overall fit to human data and/or in computational tractability) over strong baselines on both the Bayesian side and the neural network side.\n- S4: Working within this proposed paradigm, the authors show how to fit a model to human data in a way that successfully transfers human priors into a neural model.\n- S5: This work will likely be useful for future researchers working in Bayesian modeling and/or neural networks as a way to take insights from one school of thought and use them to overcome weaknesses of the other school of thought.\n'}, 'weaknesses': {'value': '- W1: Natural language is ambiguous, so natural language strings do not really provide clear concept definitions - and, by extension, inference over natural language strings cannot strictly be viewed as inference over concept definitions. (I.e., in the general case, natural language cannot be unambiguously translated into Python code). That said, as the experiments show, it is clearly close enough to work very well in at least some settings. In addition, the authors are clear in stating (in lines 286 to 293) that they do not claim that natural language is the language of thought but rather that it is a useful heuristic tool for modeling human thinking.\n- W2: The specific proposal is well-suited to concepts that can be naturally expressed in language, but is not suited to concepts that do not have a straightforward linguistic definition. The authors acknowledge this point (lines 48 to 51).\n- W3: It was a little unclear to me what the paper’s main contribution is: Is it (i) a new hypothesis about how humans perform few-shot learning, or is it (ii) a way to make tractable some previously-existing hypotheses that were previously intractable to evaluate? Both types of contribution are valuable, but it would be helpful to clarify which is/are being made here. It’s clear that the paper accomplishes (ii), but it is not obvious to me that it does (i), as the basic high-level ideas seem to be present in the cited prior work (e.g., ideas about performing Bayesian inference over a small-ish number of heuristic proposals are present in prior work about bounded rationality). It’s not a problem if (i) is not done here, but if it is done, it would be helpful to clearly state what new hypothesis is being offered, and if it is not done, it would be helpful to state explicitly that (ii) is the main type of contribution being made. One reason I’m confused here is due to differing senses of the word “model”: the paper clearly states that it proposes a new model, but I’m not sure if this is meant in the sense where “model” means “hypothesis” or the sense where it means something more like “implementation”.\n'}, 'questions': {'value': 'It would be helpful to hear your thoughts on the point discussed in W3 above, under “weaknesses.”'}, 'limitations': {'value': 'The authors do a strong job of discussing and acknowledging limitations\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '10: Award quality: Technically flawless paper with groundbreaking impact, with exceptionally strong evaluation, reproducibility, and resources, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes a model for human learning of concepts from few examples (aka ""few shot"" setting) that leverages natural language as an internal concept representation. This is a key trick because it means that\n\n* an LLM can be used to act as a proposal distribution for (efficiently) generating data-dependent candidate concepts\n* a prior distribution over concept space can be tuned (estimated) from human judgments using NLP features\n* a ""likelihood function"" for determining whether a concept could have generated an observation can be implemented via a ""text2code"" LLM that derives Python code from the natural language concept representation\n\nExperiments on ""Number Game"" and logical concept learning show concept learning with ""psychologically plausible"" sample complexity, remarkable agreement with human judgments, and explainable failure modes. In comparison with state-of-the-art Bayesian Program Learning (BPL) this approach is able to search through a much smaller hypothesis space (thanks to ""high quality"" natural language candidate proposals) but also generalize to totally novel concepts which are not express-able in the BPL due to the flexibility of natural language vs the primitives available to the BPL approach.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The paper is well-contextualized with respect to related work. It identifies a major open question (tractability vs expressivity) and addresses it via a key insight (using natural language is now much more feasible with recent LLM advances). Actually implementing this idea requires multiple non-obvious steps to bring it all together. The experiments systematically illuminate both the power and limitations of the approach in controlled but challenging problem settings. The agreement with human subject results gives the approach credibility. The comparison approach (Bayesian Program Learning) is a strong baseline. Overall I found this work to be a creative and well-executed integration of LLM advances into Bayesian cognitive modeling.'}, 'weaknesses': {'value': 'I guess if we were purely looking for some kind of ""predictive performance"" task there might be other approaches that ""outperform"" the framework here. However, the grounding in cognitive science for this work means that is probably not the right criterion, but rather this work is pursuing improved understanding of learning itself.\n\nI\'d be interested to see a discussion or mention of some task or problem setting that successfully ""red teams"" this approach - ie, some problem which is adversarially chosen to be challenging or ill-suited for this framework (while still remaining in-scope within the domain of non-embodied abstract concept learning).\n\nThe approach seems critically dependent on the quality of the Python code generation aspect. From the supplemental materials it looks like a lot of prompt engineering went into getting that to work. To some extent this seems like kind of a ""weak link"" for the whole enterprise: using natural language as the concept space requires the availability of a (very general) mechanism for computing observation likelihood or concept membership given the concept. \n'}, 'questions': {'value': ""L92: it's a little unclear what it means to say that P(X_{test} \\in C) - it doesn't seem exactly to be P(X_{test} | C), or even P(X_{test}, C), but rather more like the posterior probability that X_{test} was generated by _the same latent concept C that generated X_{1:K}_. I guess the key assumption here is that \\mathbb{1}[X_{test} \\in C] is easily computable, but that isn't clear or established by this point in the development (later it is shown how to do this with NL-to-Python). \n\nL147: this summary of all the variations is pretty dense and takes a bit of reader effort to unpack.\n\nSection 4: Is there a stronger or more recent baseline for Number Game, vs Latent Language from 2018?""}, 'limitations': {'value': 'Limitations seem reasonable and likely avenues for future work.\n\nThe reproducibility issues with using GPT4 seem addressed by including the responses in the software/data release.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents a model for how humans learn abstract symbolic concepts from induction. The model uses an off-the-shelf language model as a meta-prior, which is then tuned to form a task-specific prior over hypotheses using a small number of human samples. This prior is then incorporated into a Bayesian inference setup to solve inductive reasoning tasks. The model closely adheres to human judgments and also seems to show that natural language is a better performing hypothesis space than programs.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- Clear and concise\n- Thoughtful discussion\n- Novel incorporation of LLMs into cognitive modeling\n\nComments:\n- Line 162: Super cool result. I’d love if you could stay on this result a little longer and speculate why this might be.\n- Line 275: You’re basically using LLMs as a meta-prior, and then tuning it to obtain a task-specific prior. This is very interesting. '}, 'weaknesses': {'value': '- The abstract is vague. I’d recommend the authors expand the abstract in length and make reference to their results. \n- Some more implementation details in Sections 4 and 5 would be helpful for future readers. Please see questions below.'}, 'questions': {'value': 'Major:\n- Do you have thoughts on exactly how ""strong"" you should make the prior and likelihood functions? For example, I\'d imagine you might get even better raw performance by using GPT-3 as the prior model. Is there a sweet spot wrt model capabilities for matching human judgments? If so, what are the implications for your rational process model? \n\nMinor:\n- Line 36: ”regularizes the learner toward probable generalizations” Some references here would be nice—you can just duplicate the ones you have later in the text.\n- Line 48: Why is this well-suited for natural language? \n- Line 83: typo “has also” \n- Line 135: What’s the sampling technique—nucleus sampling, greedy, etc? I’d like some more detail on the implementation of the proposal distribution, because sampling and sampling technique can change the effective distribution a lot.\n- Line 142: Can you just explain how you fit the parameters right after you introduce them? I was wondering how you trained the parameters for a few paragraphs.\n\nNits:\n- Figure 3: Do you have a higher resolution screenshot?'}, 'limitations': {'value': 'Yes, the authors have addressed limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Human-like Few-Shot Learning via Bayesian Reasoning over Natural Language'}, 'authors': {'value': ['Kevin Ellis']}, 'authorids': {'value': ['~Kevin_Ellis1']}, 'keywords': {'value': ['Cognitive science', 'Bayesian', 'Language model', 'Induction', 'Psychology', 'Reasoning']}, 'TLDR': {'value': 'We build a model of human concept learning by integrating language models with probabilistic reasoning'}, 'abstract': {'value': 'A core tension in models of concept learning is that the model must carefully balance the tractability of inference against the expressivity of the hypothesis class. Humans, however, can efficiently learn a broad range of concepts. \nWe introduce a model of inductive learning that seeks to be human-like in that sense.\nIt implements a Bayesian reasoning process where a language model first proposes candidate hypotheses expressed in natural language, which are then re-weighed by a prior and a likelihood.\nBy estimating the prior from human data, we can predict human judgments on learning problems involving numbers and sets, spanning concepts that are generative, discriminative, propositional, and higher-order.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/365617a4ee6f25e8e6dcafc99a67d86919974771.pdf'}, 'supplementary_material': {'value': '/attachment/580e66d8c96f01560bcf82f7044ad62b0065aeda.pdf'}, '_bibtex': {'value': '@inproceedings{\nellis2023humanlike,\ntitle={Human-like Few-Shot Learning via Bayesian Reasoning over Natural Language},\nauthor={Kevin Ellis},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=dVnhdm9MIg}\n}'}, 'paperhash': {'value': 'ellis|humanlike_fewshot_learning_via_bayesian_reasoning_over_natural_language'}}]"
"['Dan Friedman', 'Alexander Wettig', 'Danqi Chen']",NeurIPS,Learning Transformer Programs,https://neurips.cc/virtual/2023/oral/73853,2023," Recent research in mechanistic interpretability has attempted to reverse-engineer Transformer models by carefully inspecting network weights and activations. However, these approaches require considerable manual effort and still fall short of providing complete, faithful descriptions of the underlying algorithms. In this work, we introduce a procedure for training Transformers that are mechanistically interpretable by design. We build on RASP [Weiss et al., 2021], a programming language that can be compiled into Transformer weights. Instead of compiling human-written programs into Transformers, we design a modified Transformer that can be trained using gradient-based optimization and then automatically converted into a discrete, human-readable program. We refer to these models as Transformer Programs. To validate our approach, we learn Transformer Programs for a variety of problems, including an in-context learning task, a suite of algorithmic problems (e.g. sorting, recognizing Dyck languages), and NLP tasks including named entity recognition and text classification. The Transformer Programs can automatically find reasonable solutions, performing on par with standard Transformers of comparable size; and, more importantly, they are easy to interpret. To demonstrate these advantages, we convert Transformers into Python programs and use off-the-shelf code analysis tools to debug model errors and identify the “circuits” used to solve different sub-problems. We hope that Transformer Programs open a new path toward the goal of intrinsically interpretable machine learning.",Oral 3B NLP/Tools,https://openreview.net/pdf?id=Pe9WxkN8Ff,https://openreview.net/forum?id=Pe9WxkN8Ff,Pe9WxkN8Ff,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper introduces a novel method to learn transformer programs, which are executable programs that can be interpreted by a transformer model. The reviewers recognized that the paper presents an interesting and original idea that has potential applications in natural language processing and program synthesis. They also pointed out some issues such as the interpretability and scalability of the generated programs, the optimization challenges, and performance comparing to the baseline Transformer models. The authors provided a rebuttal that addressed most of the issues raised by the reviewers and promised to improve their work in the final version. Based on the reviews, the rebuttal, and the discussion, I recommend an ACCEPT to this paper. I believe this work will inspire further research and applications in this direction and suggest that the authors address the remaining concerns of the reviewers and provide more details and comparisons in the final version.'}}, {'comment': {'value': 'Thank you for your response!\n\nA couple follow-ups:\n\n> This is because it is possible to manually construct Transformer Programs that solve RASP tasks perfectly, so the performance limitations must be attributed to optimization challenges. One caveat is the “less than” predicate...\n\nThe reason I asked is because it does seem your target language is less general than RASP. One example is predicates like ""less than"" (which feels quite significant). But it was unclear to me if this is really the only limitation in comparison to general RASP -- clarifying this in the final draft would be appreciated.\n\n> During training, we define...\nIs this differentiable? How do you propagate derivatives through the one-hot, or do you not need to?\n\n> We did not investigate these questions in detail but we will run this analysis and add it to our final draft.\n> we agree it would be interesting to measure the extent to which (a) whether standard Transformers and Transformer Programs learn similar solutions, and (b) the similarity between Transformer Programs with different random seeds, and we will add this analysis to our next draft.\nThanks, I look forward to reading these analyses.\n\nThanks also for your general response discussing scaling challenges. Overall, after the author response, I am slightly more lukewarm on the current results, but believe this work represents a good first step toward learning Transformers that can be represented as symbolic programs. I still support publication of the manuscript & am excited to see how the research community builds on these ideas / results in the future!'}}, {'comment': {'value': ""Thank you for the clarifications and apologies for the model distillation misunderstanding. After re-reading the paper, I'm raising my score to a weak accept.""}}, {'comment': {'value': 'Thank you for your responses, especially for pointing to the original/discrete transformer accuracy comparisons I missed! In light of this, I have increased my score from a 6 to a 7.'}}, {'rebuttal': {'value': 'Thank you for your review! We believe there is some misunderstanding in the main concerns, and we have addressed them below. We kindly request the reviewer to reconsider the evaluation, and we  are more than happy to further clarify if anything is still unclear.\n\n> Do the constraints violate properties (e.g. superposition)?\n\nOur constraints do prevent the model from using feature superposition. As noted by [1], superposition is a major obstacle to interpretability. Our work is one attempt to solve it. It is not clear that superposition is “intrinsic to the utility of transformers” – in [1], the authors suggest that superposition is useful but might not be necessary; in fact, every model can be seen as equivalent  to a “hypothetical disentangled model” that uses higher-dimension embeddings. On the other hand, we agree that superposition is useful, because it enables the use of lower-dimensional representations. One avenue for future work is to extend our framework to enable the use of more compressed representations, while still preserving interpretability.\n\nPlease let us know if there are other properties that raise concerns (aside from superposition).\n\n> Poor robustness / relationship to model distillation\n\nWe believe this concern might be based on a misunderstanding:  our work is not really a model distillation approach, or analogous to the method in [2] (which targets a different domain and architecture–physics modeling with GNNs). Our approach is better thought of as a continuous relaxation of discrete search, where the search space is the set of Transformer networks with discrete weights. As such, we do not have any prior reason to expect that the discrete programs will be more robust. On the contrary, our primary goal is interpretability, and we expect that Transformer Programs might sacrifice accuracy for this goal. Nevertheless, we show that Transformer Programs can achieve competitive accuracies on synthetic RASP tasks and real-world NLP tasks. We also highlight some areas where our method struggles to learn robust programs, due to the challenges of discrete optimization. Replacing large transformers with drop-in interpretable counterparts is an ambitious project, and we see this work as a first step. Addressing these optimization challenges is an avenue for future work.\n\n> Lack of Reusability\n\nOur experiments show that the Transformer Programs do in fact learn to compose operations, computing primitive values at lower layers and using these results at higher layers to compute higher order patterns. For example: the simple in-context-learning program learns an  induction-head pattern  (section 4.1), and the double-histogram program (appendix Figure 9) learns to compute the first-order histogram in the first layer, and consume this value in the second layer. In Appendix C.2 (Figure 10), we show that higher-layer attention heads often read information from intermediate-layer attention and MLP layers, showing that the programs do indeed learn to reuse previously computed values.\n\n> Results on longer sequence tasks\n\nTo clarify, this line is referring to models that are trained on longer sequences, not to OOD generalization. As noted above, our work is not a model distillation approach, and we don’t expect other results about distillation to apply here. The reason the results degrade on longer sequences is related to optimization challenges: our programs tend to find solutions that use relatively shallow features of the input, rather than the most robust, parsimonious solution. As discussed above, addressing these optimization challenges will require significant research advances, which we are leaving for future work.\n\n> Learned solutions vs. human-written solutions\n\nWe did not expect in advance that the Transformer Programs would learn the same solutions as the human-written programs for RASP, which represent just one possible way to solve the problems. In fact, in the RASP paper (Table 1), they find that even standard Transformers do not always learn the same solution as the human-written program. As noted above, many of the programs described in the paper learn to reuse previously computed values. However, there could be other inductive biases that make some solutions more difficult for our model to learn–for example, it might be harder for our model to learn arbitrary feed-forward operations.\n\n> What is a variable here?\n\nWe use the word variable in the same sense as a variable in a computer program: a named container that takes on a particular value when the program is executed. In the example in section 3.1, the program has four variables: _tokens_, _positions_, _attention 1 outputs_, and _attention 2 outputs_. We follow the design of the Tracr compiler and use a one-hot encoding for categorical variables, meaning the embedding size is equal to the number of variables times the number of possible values they can take on. We will define this more precisely in our final draft.\n\n> requiring each query token attend to a single key token\n\nIn this paper, we support two kinds of attention: categorical attention, where each query token attends to a single key token, and numerical attention, where each query token can attend (uniformly) to any number of key tokens. This is a limiting constraint, but we adopt it from RASP/Tracr, and it is important for ensuring that the resulting programs are discrete and easy to interpret. Moreover, existing work has shown that these attention patterns are empirically common in Transformer LMs [4], and, theoretically, are expressive enough to model a large class of formal languages [5].\n\n[4] Merrill et al., 2021. Effects of Parameter Norm Growth During Transformer Training: Inductive Bias from Gradient Descent.\n\n[5] Merrill et al., 2022. Saturated transformers are constant-depth threshold circuits..\n\n> Related work\n\nThank you for the pointer! We will add a discussion and related references in our final draft.'}}, {'rebuttal': {'value': ""Thank you for your review! Please also see the GR for our comments about whether the solutions are always interpretable, and about the comparison between Transformer Programs and standard Transformers.\n\n> Learning solutions to the RASP tasks makes it easier for the model to learn interpretable solutions. The paper would be stronger if it targeted other tasks where the compilation is more surprising.\n\nIn addition to the RASP tasks, we trained models on two non-synthetic NLP tasks: named entity recognition (Section 4.3) and text classification (Appendix C.3). In the paper, we show examples from the learned programs to illustrate how they allow us to interpret the solution. For example, in Figure 7, we identify some of the features that the program uses to distinguish location entities from organization entities. These include attention heads that copy lexical information from the preceding and subsequent tokens–e.g., a token is more likely to be the beginning of a location entity if the following word is a word like “Germany”, “Italy”, or “Netherlands.” On a question classification dataset (Appendix Fig. 11), we can see that the model focuses on tokens at the beginning of the input–for example, predicting that the input is a numerical question if it starts with a question word like “when”, or relevant nouns like “year”, “time”, and “date.”\n\nWe chose to experiment on the RASP tasks because these reflect a variety of algorithmic subproblems. We would also note that, even though these tasks can be solved with concise, interpretable programs, it is still non-trivial to automatically learn these solutions given only input-output pairs.\n\n> How well can a discrete transformer solve problems relative to the original transformer?\n\nThe paper and appendix include experimental results comparing the original transformer and our discrete transformers on the NLP tasks: Appendix C.4 (Table 6) shoes that the Transformer Programs are are either competitive with or slightly worse than the standard transformer on four  text classification tasks, and Section 4.3 (Table 2 in the main paper) shows that the Transformer Program actually slightly outperforms a standard transformer in our NER experiments.\n\nOn the other hand, the Transformer Programs under-perform a standard transformer on some RASP tasks, and on longer inputs. We did not include RASP results with a standard transformer, but Weiss et al. [1] report that standard transformers get > 99% accuracy on tasks with a sequence length of up to 100 tokens, while our Transformer Programs perform worse on longer sequences (Appendix C.1, Table 3). (We will include RASP results with a standard transformer in our next draft.) This is an optimization issue rather than an expressivity issue: we can write Transformer Programs that achieve perfect accuracy at arbitrary sequence lengths, but our optimization procedure fails to find these programs in practice. We hope to address these optimization challenges in future work. (In general, Transformer Programs can be as expressive as RASP models, with the caveat that we have restricted the size of the feed-forward layers; like RASP models, the discrete transformers are less expressive than standard transformers due to the limitations of hard attention [2].)\nWe will highlight this discussion in greater detail in our final draft.\n\n[1] Weiss et al., 2021. Thinking Like Transformers.\n\n[2] Hao et al., 2022. Formal language recognition by hard attention transformers: Perspectives from circuit complexity.\n\n> Are there tasks where the code was uninterpretable or the discretized transformer couldn't achieve high accuracy?\n\nAs noted above, the discretized model performs worse than a standard transformer on RASP tasks with longer sequences, and performs slightly worse on some text classification datasets. The Transformer Programs also perform relatively poorly on the Most-Freq task (Table 1), which requires the model to count, sort, and identify unique elements. In general, we might expect Transformer Programs to perform worse on tasks like Most-Freq that require the composition of a series of higher-order functions, because of optimization challenges (i.e. local minima).\n\nRegarding tasks where the code was difficult to understand: In Section 4.2, we highlight some subsets of the _sort_ program with non-obvious interpretations. For example, Figure 6 illustrates a circuit of two attention heads that propagates early-position tokens to later positions and late-position tokens to early positions by first copying them to the beginning- and end-of-sequence tokens. In general, for larger-scale tasks, it might become more difficult to understand the code at the level of individual attention heads. Some interesting directions for future work are  to develop tools for identifying higher-level abstractions in large programs, and for imposing an inductive bias in favor of sparser programs. Please also see our comment in the GR about whether the learned programs are interpretable.""}}, {'rebuttal': {'value': 'Thank you for the comments!\n\n> Higher-level constructs for more complex tasks\n\nThank you for the great suggestions! We agree that future work should explore extending the framework to include more complex primitives, or perhaps automatically identifying higher-level programming abstractions in learned programs (e.g. as in [1]). We will mention this direction in our updated draft.\n\nPlease also see the GR for our more general comment about whether complex tasks admit interpretable algorithms.\n\n[1] Ellis et al., 2023. DreamCoder: Growing generalizable, interpretable knowledge with wake–sleep Bayesian program learning.\n\n> Converting MLP layers into a program\n\nThank you for pointing this out – this is correct. For each MLP, for each layer of the Transformer, we extract a lookup table that will be added to the Python program. (However, within a single Transformer layer, each MLP module is converted into a single lookup table, regardless of the number of hidden layers within the MLP itself.) The size of the lookup table is determined by the number and cardinality of the input variables, although in practice we can compress the lookup tables in situations where the model does not use all of the output values. Some example MLP functions are presented in the appendix in Figures 8 and 9. We will update Section 3.2 to explain this more clearly.\n\n> Defining a library of common operations for MLPs\n\nThank you for the suggestion! This is a great idea and it would be simple to incorporate this type of module into this framework. We chose to treat MLPs as lookup tables following Tracr, but we agree the resulting lookup tables are not necessarily easy to interpret, and incorporating common operations like addition would be a good alternative. We will mention this suggestion in our final draft as a possibility for future work.\n'}}, {'rebuttal': {'value': 'Thank you for your review! Please see our comments in the GR about whether the programs are interpretable, and the main challenges to scaling up this approach.\n\n> More analysis of the programs\n\nThank you for the great suggestions! Regarding debugging: We do not necessarily expect that standard transformers will make the same errors, but we agree it would be interesting to measure the extent to which (a) whether standard Transformers and Transformer Programs learn similar solutions, and (b) the similarity between Transformer Programs with different random seeds, and we will add this analysis to our next draft.\n\n> Are the categorical distributions peaked?\n\nWe did not investigate these questions in detail but we will run this analysis and add it to our final draft. Anecdotally, we found that the accuracy of the argmax model closely approximates the final training accuracy.\n\n> Why limit the predicate matrices to contain only one ‘1’ per row?\n\nThis was a design choice that we made because it leads to programs that are (qualitatively) easier to understand. It is also possible to allow the predicate matrix to have multiple 1’s per row, and using a Gumbel-sigmoid function. In our preliminary experiments, we trained models with this form of predicate matrix and found they obtained similar classification performance but were qualitatively more difficult to understand. We omitted this discussion for lack of space but will add it to the appendix in our final draft.\n\n> Argmax attention / location of Gumbel-softmax operations\n\nThank you for pointing this out. We use the Gumbel-softmax during training, in the place of hard attention (this is mentioned in section 3.2 but not in the appendix–we will correct this in the next draft). Using the notation from Section 2, the output of the attention layer is defined as $AxW_V$, where A is an attention matrix with each row adding up to one, and S is a matrix of attention scores. With argmax attention, $A_i = \\text{One-hot}(\\text{arg}\\max_j S_{i, j})$. During training, we define $A_i = \\text{One-hot}(\\text{Gumbel-softmax}(\\log (S_i + \\epsilon)))$ for some small $\\epsilon$. We will explain this more clearly in our next draft, and include a table laying out the different components of the model.\n\n> Additional in-context learning experiments\n\nWe did try (2), training larger Transformer programs. We found that over-parameterized models are more likely to learn the correct solution (as measured by the percentage of training runs that achieve perfect test accuracy). For example, if we train a model with two heads per layer, we are more likely to find that one pair of heads implements the induction head, perhaps analogously to the lottery ticket hypothesis. One interesting question for future work is whether we can identify the interpretable subprogram automatically, for example by adapting pruning methods. We will add this discussion to our updated draft.\n\n> Can you clarify how the word embeddings are trained?\n\nBefore training, we initialize the word embeddings to $E = E_G  \\Pi$, where $E_G \\in \\mathbb{R}^{|\\mathcal{V|} \\times 100}$ denotes the GloVe embedding matrix, and $\\Pi \\in \\mathbb{R}^{100 \\times 128}$ is a matrix with each entry sampled independently from $\\mathcal{N}(0, 1/128)$. This embedding matrix is then split into four $|\\mathcal{V}| \\times 32$ matrices (one for each variable), and we sample categorical word embeddings by taking a Gumbel sample for each row of each of the four matrices. We will explain these details more clearly in our updated draft.\n\n> Why not include MLP layers in the NLP tasks?\n\nWe used one MLP layer in all of the NLP tasks, but this is not clearly reflected in the paper–thank you for pointing this out. We will update the method description to be more clear.\n\n> Explaining the RASP tasks that were not successfully solved\n\nWe believe that the main issue is (1): good solutions exist but are not found by our optimization procedure. This is because it is possible to manually construct Transformer Programs that solve RASP tasks perfectly, so the performance limitations must be attributed to optimization challenges. One caveat is the “less than” predicate, which appears in RASP programs for  tasks such as sorting. This predicate is difficult to express using our version of categorical attention, where each query value attends to a single key value, but could be expressed using the one-to-many version of attention discussed above. It is straightforward to extend our approach to include this kind of attention. In our preliminary experiments, we found that, even using one-to-many attention, the  Transformer Programs did not learn the “less-than” predicate. We will add these experiments to our updated draft.'}}, {'rebuttal': {'value': 'We thank the reviewers for their thoughtful comments! The reviewers have made a number of great suggestions that we will incorporate into our next draft, including clarifying some details about the method; providing more discussion about optimization challenges; and including some additional analysis of the learned programs. We respond to each of the reviewers in detail, and to some common issues below. \n\n> Are the programs interpretable?\n\nSome of the reviewers questioned whether the learned programs are actually interpretable (Kcxc, HW9X), or whether more complex tasks even admit interpretable solutions (vQnY). We provided a number of examples in Section 4 and Appendix C illustrating interpretable subsets of programs for different tasks, including sorting (Figure 5); NER (Figure 7); double histogram (Appendix Figure 8);  Dyck-2 (Appendix Figure 9), and a classification task (Appendix Figure 11). For more complex tasks, the program can be thought of as a collection of individually interpretable feature functions, rather than a single interpretable algorithm. For example, a circuit in the Dyck-2 program checks for invalid bigrams using an attention layer and an MLP. In the NER program (Fig. 7), the model is more likely to predict that a token is the beginning of a location entity if the following word is a word like “Germany”, “Italy”, or “Netherlands.”\n\nOn the other hand, we acknowledge that the learned programs can still be complicated and non-intuitive. (For example, Figure 6 illustrates a subset of a _sort_ program whose interpretation is not immediately obvious.) We would emphasize that this method always provides a baseline level of interpretability: even when the program is complicated, we can trace how information flows between different positions and model components, and we can inspect the program using off-the-shelf code analysis tools, like debuggers. Nonetheless, we agree that the programs can still be difficult to interpret, and we think a good avenue for future work is to explore methods for automatically analyzing the resulting programs, and for imposing an inductive bias in favor of more interpretable programs.\n\n> Scaling, expressivity, and optimization challenges\n\nSeveral of the reviewers asked if we could provide more details about how the Transformer Programs compare to standard Transformers (HW9X, TaJd); provide more insight into the cases where the Transformer Programs under-perform standard Transformers (Kcxc, HW9X, TaJd); and discuss the key challenges to scaling up this approach. We provided relevant analysis in the paper by experimenting on RASP tasks with longer sequences (Appendix C.1) and on NLP tasks (Section 4.3 and Appendix 3.3), but we add some additional discussion here. In particular, Reviewers HW9X and Kcxc ask whether the main limitation of this method is (a) limited expressivity or (b) optimization challenges.\n\nWe think that the main scalability challenges are optimization challenges. In particular, Transformer Programs are expressive enough to represent robust solutions to the majority of RASP tasks, but in practice they do not learn these solutions. This is reflected in the results in Table 3 (in the appendix), where we learned programs for longer sequences. For example, we can construct a Transformer Program that achieves perfect accuracy on the _reverse_ task, by first calculating the sequence length, then calculating the target position indices using a feed-forward layer (_target_index_ = _length_ - _position_ + 1), and then copying the token from the target index. In ablation experiments, we found that Transformer Programs could learn to calculate these intermediate values if they were trained directly, but failed to learn this decomposition when trained end-to-end on the _reverse_ task. We think that the underlying optimization issue is that it is more difficult for these discrete models to escape from local minima. (We will add this discussion to our next draft.)\n\nAddressing these challenges will require more research on discrete optimization. While our approach might not be a drop-in replacement for regular Transformers just yet, we think that our work represents a significant first step towards this goal, and can help lay the groundwork for future research.\n'}}, {'summary': {'value': 'This paper proposes a new technique for training Transformer models while ensuring that the learned weights obey certain constraints, designed to facilitate mechanistic interpretability. In particular, the technique works by (1) freezing certain weight matrices throughout training (e.g., to always write the output of an attention layer to a previously unused linear subspace of the residual stream) and (2) introducing Gumbel-softmax sampling at various steps of the computation, and annealing the temperature down during training to ensure that at convergence, those computations perform discrete operations. The resulting Transformers can be automatically converted into symbolic programs that read, write, and perform lookup-table-style computation with a fixed number of categorical and integer variables. The authors train (quite small) Transformers in this way, to solve several tasks, including named entity recognition and sentiment classification on short sequences. The authors also provide some analysis of the programs extracted from these Transformers.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'This is a neat paper that advances two exciting lines of research:\n\n- RASP and Tracr been helpful as intuition pumps for how trained Transformers *could* work, but it has not been clear whether the (correct) RASP algorithms researchers manually developed could be discovered automatically by gradient descent, and if not, what different properties these learned Transformer algorithms would have. This paper proposes a method for learning Transformer programs that could be used to start to answer these questions.\n- A key challenge in mechanistic interpretability research (e.g. on Transformer circuits) is that Transformers trained by (unconstrained) gradient descent appear to collapse multiple conceptually distinct concepts via superposition. This paper proposes training methods that may help to mitigate superposition by forcing the network to read, write, and manipulate individual ‘variables’ that live in orthogonal subspaces of the residual stream.\n\nAlthough terse in some places (perhaps due to length constraints), the methodology is for the most part clearly described, and the limitations of the approach seem sensible for a first attempt at this kind of constrained training. Another strength is that the framework seems to be extensible—the examples in the paper paint a clear enough picture of how to modularly extend the target symbolic programming language with new features (and then how to extend the neural net architecture and training procedure accordingly).'}, 'weaknesses': {'value': '- Although the motivation is interpretability, I was not convinced that the learned programs in the experiments were particularly interpretable. It would have been nice to see more detailed analysis of the programs. Outside the toy in-context learning example, are there any interpretable algorithms that are learned? Can examples on which the learned programs fail be traced back to particular ‘bugs’ in the symbolic programs? Can the symbolic programs be used to engineer adversarial examples on which the Transformer will fail? Do ordinary transformers trained without constraints also fail on these adversarial examples (indicating that they might be using similar flawed algorithms)? How stable are the learned programs across different training runs?\n\n- It is unclear how scalable the presented technique is, to more complex problems, longer sequences, or bigger networks. I also would have appreciated more discussion / investigation of how easy or tricky the optimization was, and why it appears to work more poorly for larger Transformers (e.g., that handle larger sequence lengths). What are the key challenges in scaling up? Do the Gumbel gradient estimates become too noisy, e.g.? Or are there other main challenges?'}, 'questions': {'value': ""- At the end of training, your Gumbel-Softmax's have been annealed to Categorical distributions, but these distributions are not necessarily *peaked* or low-entropy categoricals. Therefore, your extracted program (which takes the argmax of the categorical) may behave quite differently from your trained network (which randomly samples the categorical). Have you investigated (a) the extent to which the learned categoricals are peaked at a single mode, and (b) the difference in task performance / accuracy between the final learned Transformer and the extracted program?\n- Why limit the predicate matrices to contain only one ‘1’ per row? Is it just because this constraint is more amenable to the Gumbel-softmax training procedure?\n- In the description (Appendix A.1) of the categorical attention mechanism, you appear to use an argmax operation that is not differentiable. During training do you actually use Gumbel-softmax? If so, how are the resulting samples used to compute the output of the attention layer? (More generally, it would help if the paper more clearly laid out exactly where in the architecture all the Gumbel-softmax samples are used. Perhaps algorithm boxes in the style of https://arxiv.org/pdf/2207.09238.pdf could be provided for each component of the neural architectures you build?)\n- For the in-context learning experiment, did you try (1) training an ordinary Transformer of the same size on the task? and/or (2) training a larger (i.e., overparameterized) Transformer program on the task? I’d be curious about the results of either experiment, if you did run them. Under the ‘lottery ticket hypothesis,’ overparameterization is an important part of how algorithms are learned by gradient descent — it would be interesting to see what this looks like in a Transformer program. E.g., in a larger model, do we end up with a small interpretable subprogram that correctly completes the task?\n- Can you clarify how the word embeddings are trained? What does it mean that the 100-d GloVe embeddings are “randomly projected” to e.g. 32*4=128-d embeddings? Do you use a randomly generated dense 100x128 matrix? Then how are the embeddings trained? Is there a Gumbel sample for each of the categorical variables?\n- Why not include MLP layers in the NLP tasks?\n- For the RASP tasks that were not successfully solved by learned Transformer programs, do you believe this is because (1) good solutions exist, but are not found by gradient descent, or (2) your subset of RASP is too limited and the tasks cannot be solved with this subset? If (2), what are the prospects for handling a broader subset of RASP?""}, 'limitations': {'value': 'Limitations are adequately discussed, but I do think it could be useful to say a bit more about the challenge of scaling this approach -- what are the key obstacles & prospects for addressing them?'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents an approach to constraint the parameter space of Transformers so that when trained, the resulting weights can be directly translated to a human-readable program, e.g. in Python. To do so, attention is modified so that the internal model representation is, in practice, composed of a set of distinct variables that the attention processes read/write to. The base approach focuses in attention-only models (no MLP layers), but the authors propose extensions to support MLP layers.\n\n- page 5: line 165-166: ""For row in the predicate matrix"" -> there seems to be some word missing around ""row"".\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'I found the idea of constraining the parameter space extremely interesting. While the types of programs that can currently be learned seem a bit restricted (e.g., as the number of variables grows, the model/program could potentially grow very large), I think this is a very promising direction, and a greag foundation to build on.\n'}, 'weaknesses': {'value': 'While it seems clear that programs for simple tasks can be interpreted, it is not clear that many tasks (specially vision/natural language tasks) actually even afford interpretable algorithms. So, perhaps future work needs to focus on more complex primitives for the programming language supported by the models that would simplify the programs, or enable higher-level constructs that are interpretable.\n'}, 'questions': {'value': ""- Section 3.2: the explanation for how to extract the part of the program that corresponds to the attention layers is clear. But how about the MLP layers? How do you infer what the MLP layers have learned to do to conver that into a program? [edit: this is explained immediately below, but it's still unclear; so, for EACH MLP in EACH LAYER of the model, you would have to extract a look-up table that will be added to the Python program?]\n- (more a comment than a question): concerning MLPs. I wonder if it would be possible to define a library of commmon operations (e.g. addition/multiplication/etc., or whatever makes sense with other categorical values), and allow non-learnable, pre-defined MLP weights to be used via some gating (e.g., the model choosing to use one of these built-in methods, or a custom-learned weight matrix). to increase the chance of having an interpretable function in the resulting model, rather than having one look-up table per MLP layer.\n""}, 'limitations': {'value': 'See weaknesses above.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""There has been prior work on compiling programs written in a domain-specific language (RASP) into a transformer that emulates the function. In this paper, the authors target the opposite direction of training transformers and generating RASP programs that are faithful to the model's computation. The authors do this by proposing an architecture that serves as a discretized version of a transformer, allowing translation to a discrete, interpretable python program after training. They find that for a variety of tasks, it is possible to 1) learn a solution in this architecture and 2) compile it into RASP.""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'This work demonstrates a novel architecture that allows for direct translation to code. The paper does a great job of demonstrating their method for synthetic tasks. Though prior work has noticed sparsity improved interpretability, this work leverages it for full programmatic translation. I hope this can inspire future work in interpretable neural networks.'}, 'weaknesses': {'value': ""1. Learning solutions to the RASP tasks makes it easier for the model to learn interpretable solutions. The paper would be stronger if it targeted other tasks where the compilation is more surprising.\n2. How well can a discrete transformer solve problems relative to the original transformer? I imagine the discretized model has a lower representation capacity or worse optimization. I think it's important to experimentally/theoretically analyze what is lost as a result of this architectural choice, considering it's not a standard transformer in many key aspects.\n""}, 'questions': {'value': 'No questions beyond the one in the weaknesses/limitations.'}, 'limitations': {'value': ""Are there tasks where you tested this method and either the code was uninterpretable or the discretized transformer couldn't achieve high accuracy, unlike the standard transformer? If not, are there any tasks where you wouldn't expect this to work?\n\nOther than this, the authors have adequately addressed limitations.""}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': '_Background_: RASP is a tensor processing language which provides a language to hand-write transformers. Tracr presents a framework to compile RASP programs to a transformer architecture automatically. \n\nThe authors of this project are interested in distilling a transformer architecture to an equivalent program in RASP. This is challenging because RASP is not a sound language: the behavior of many trained transformers is equivalent to that of a single RASP program. The authors go around this problem by constraining the transformer architecture in strategic places so that there is a deterministic mapping from a transformer to an equivalent program in RASP. The authors present a model distillation procedure to construct such reduced transformers (called Transformer Programs) automatically. The authors test the Transformer Programs on three tasks: 1) in-context learning, 2) recovering handwritten RASP programs, and 3) simple real-world NLP tasks. They observe mixed results: transformer programs can fully solve (1), they cannot generalize to larger sequences for (2), and they are better than non-sequential baselines on (3) but worse than generic transformers. The authors also show the utility and interpretability of the distilled programs by analyzing the programs using off-the-shelf debuggers.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'Originality\n* RASP programs are inherently unsound: one RASP program is equivalent to many trained transformers. Solving this problem by constraining the transformer to elicit a bijective mapping is a simple yet elegant idea. \n\nSignificance\n* This paper shows a simple method to distill transformers into interpretable programs. This work opens the door for work in program synthesis, static analysis, and model checking to be used for sequential processing tasks.\n* Many downstream tasks rely on transformers to processing temporal sequences of data into labels. While the transformer architecture presented is constrained, an interpretable transformer can be very useful for tasks where high degree of interpretability and accuracy are required. \n\nClarity and Quality\n* The framework is well motivated, and the writing is clear and precise.'}, 'weaknesses': {'value': ""__Weaknesses__\n\nI have three main concerns (paraphrased from the questions section below):\n* I’m concerned that the constraints mentioned here violate properties[1] that the mechanistic interpretability community have identified as being intrinsic to the utility of transformers.\n* Poor robustness: Model distillation has been observed to produce models that are more robust to outliers while being slightly less accurate[2]. However, in experiments it seems that the distilled models are neither robust to outliers nor as accurate as baselines, which makes it harder to use this as a drop-in replacement.\n* Lack of Reusability: An interesting property of the RASP programs (and RASP distilled transformers) is that many tasks can be efficiently solved by precomputing useful primitives. The algorithm presented here does not seem to model this property. For instance, in the reverse proposed in RASP, the authors' solution precomputes length of the sequence and then uses length to flip the indices of an identity matrix. The derived transformer also captures this behavior. Does the Transformer Program also capture this behavior? If not, why not? \n\nClarity:\n* 135. subpace -> subspace\n* Related work: I defer to the authors, however, I feel adding a section on other model distillation approaches would be relevant. In the context of model distillation, [3] seems similar to this work in learning a transformer (for multi-agent communication) and then by discretizing it (using MCMC) to obtain an interpretable policy.\n\nOverall, I've given the paper a __borderline rejection__. The problem statement presented has promise to have significant impact, however, the experimental results do not instill confidence in the downstream utility of this method and I believe this paper will benefit from another round of review. I'm more than willing to change my recommendation after the rebuttal period.\n\n====\n__EDIT__: I misinterpreted the paper as a _model distillation_ paper instead of a continuous relaxation one. In light of this, and other clarifications presented by the authors, I'm raising my score to a __weak accept__.  \n\n1. https://transformer-circuits.pub/2022/toy_model/index.html\n2. https://arxiv.org/abs/2006.11287\n3. https://arxiv.org/abs/2101.03238\n\n""}, 'questions': {'value': '* Constraint 1 “the token embeddings encode … fixed set of variables… in orthogonal subspace. What is a variable here? I’m going to assume variable=token, but it would be good to define this. \n   * Does this mean that encoding 100 variables requires a 100 dimensional vector? Does this assumption violate some of the properties we know about transformers? For instance: nonlinear superposition[1]?\n* 155: “require that each query token attend to a single key token”. This constraint seems very limiting. Do most sequential problems where transformers are used adhere to this constraint?\n* 256 “results degrade on longer sequence tasks.” This seems concerning. Are these results for the trained model or for the extracted program? Ideally, model distillations are more robust to OOD tasks than the model itself[2]. Is there any indication for why this might be the case?  \n. 259 “our solution might be different from human written solutions.” This seems concerning because RASP programs attempt to upper-bound the number of transformer layers that might be needed for computation. Do we have any indication for why this might be happening? Is this maybe because the human written solutions reuse previously computed values?\n\n1. https://transformer-circuits.pub/2022/toy_model/index.html\n2. https://arxiv.org/abs/2006.11287\n'}, 'limitations': {'value': 'The authors have addressed the limitations of the method adequately to the best of my knowledge.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Learning Transformer Programs'}, 'authors': {'value': ['Dan Friedman', 'Alexander Wettig', 'Danqi Chen']}, 'authorids': {'value': ['~Dan_Friedman2', '~Alexander_Wettig1', '~Danqi_Chen1']}, 'keywords': {'value': ['mechanistic interpretability', 'transformers']}, 'abstract': {'value': 'Recent research in mechanistic interpretability has attempted to reverse-engineer Transformer models by carefully inspecting network weights and activations. However, these approaches require considerable manual effort and still fall short of providing complete, faithful descriptions of the underlying algorithms. In this work, we introduce a procedure for training Transformers that are mechanistically interpretable by design. We build on RASP [Weiss et al., 2021], a programming language that can be compiled into Transformer weights. Instead of compiling human-written programs into Transformers, we design a modified Transformer that can be trained using gradient-based optimization and then automatically converted into a discrete, human-readable program. We refer to these models as Transformer Programs. To validate our approach, we learn Transformer Programs for a variety of problems, including an in-context learning task, a suite of algorithmic problems (e.g. sorting, recognizing Dyck languages), and NLP tasks including named entity recognition and text classification. The Transformer Programs can automatically find reasonable solutions, performing on par with standard Transformers of comparable size; and, more importantly, they are easy to interpret. To demonstrate these advantages, we convert Transformers into Python programs and use off-the-shelf code analysis tools to debug model errors and identify the “circuits” used to solve different sub-problems. We hope that Transformer Programs open a new path toward the goal of intrinsically interpretable machine learning.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/ef31a762e143cce8427cedf3e1c02d37cbc8acf3.pdf'}, 'supplementary_material': {'value': '/attachment/fce5c2f04d332b4ee67bbd01bdfcc9d75ac2b4cc.pdf'}, '_bibtex': {'value': '@inproceedings{\nfriedman2023learning,\ntitle={Learning Transformer Programs},\nauthor={Dan Friedman and Alexander Wettig and Danqi Chen},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=Pe9WxkN8Ff}\n}'}, 'paperhash': {'value': 'friedman|learning_transformer_programs'}}]"
"['Tsun-Hsuan Johnson Wang', 'Juntian Zheng', 'Pingchuan Ma', 'Yilun Du', 'Byungchul Kim', 'Andrew Spielberg', 'Josh Tenenbaum', 'Chuang Gan', 'Daniela Rus']",NeurIPS,DiffuseBot_ Breeding Soft Robots With Physics-Augmented Generative Diffusion Models,https://neurips.cc/virtual/2023/oral/73877,2023," Nature evolves creatures with a high complexity of morphological and behavioral intelligence, meanwhile computational methods lag in approaching that diversity and efficacy.  Co-optimization of artificial creatures' morphology and control in silico shows promise for applications in physical soft robotics and virtual character creation; such approaches, however, require developing new learning algorithms that can reason about function atop pure structure. In this paper, we present DiffuseBot, a physics-augmented diffusion model that generates soft robot morphologies capable of excelling in a wide spectrum of tasks. \name bridges the gap between virtually generated content and physical utility by (i) augmenting the diffusion process with a physical dynamical simulation which provides a certificate of performance, and (ii) introducing a co-design procedure that jointly optimizes physical design and control by leveraging information about physical sensitivities from differentiable simulation.  We showcase a range of simulated and fabricated robots along with their capabilities. Check our website: https://diffusebot.github.io/",Oral 3C Diffusion Models,https://openreview.net/pdf?id=1zo4iioUEs,https://openreview.net/forum?id=1zo4iioUEs,1zo4iioUEs,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': ""This paper presents DiffuseBot, a physics augmented diffusion model that can be used to design soft robots and the control in simulation and in the real-world. The initial reviews were mostly positive. The concerns raised in the reviews were sufficiently addressed in the rebuttal. All reviewers unanimously voted for acceptance. Please incorporate the contents in the rebuttal and reviewer's suggestions into the final version of this paper.""}}, {'comment': {'value': ""Thank you for the detailed response. I understand that it was not the main focus of the paper, and I appreciate the detailed analysis of the potential sources of the sim2real gap. I'll keep the rating as is, and I think it's a strong and interesting work.""}}, {'title': {'value': 'nice work!'}, 'comment': {'value': 'Thanks a lot for the rebuttal and the nice work! Authors cleared most of my concerns. Would like to keep my rating of 7 Accept. '}}, {'title': {'value': 'Thank you for your response'}, 'comment': {'value': 'Thank you for replying to my comments. I confirmed and understood them, but I am not an expert in soft robots, so I will leave my rating as is.\n'}}, {'title': {'value': ""Please read and respond to authors' rebuttals""}, 'comment': {'value': 'Dear reviewers,\n\nThank you for your reviews. The authors have posted their rebuttal. If you have not yet done so, please read the rebuttal and the other reviews, and comment on whether the rebuttal has addressed your comments or concerns.'}}, {'comment': {'value': 'I thank the authors for their thorough response.\n\nIt would be great if the authors could integrate them into the revised manuscript, particularly those changes regarding clarity.\nKeeping the writing clear for the audience is important.\n\nSince I am not an expert in soft robot design, I will keep the score as is.\n\nThanks!'}}, {'title': {'value': ""Thanks for the authors' effort ""}, 'comment': {'value': ""Considering that the author has already addressed most of my concerns, I decide to raise the score to 6. Please don't forget to include the promised part about evaluation of mean and variance in the updated version.""}}, {'title': {'value': 'Addressing the remaining concern'}, 'comment': {'value': 'Thanks for acknowledging our effort for the rebuttal and bringing up the remaining concern about reporting the mean and variance.\n\nWe will provide mean and variance for the results in Table 2 of the main submission from the supplementary Table A3 along with the discussion presented in the above to further strengthen the persuasiveness of our analysis based on your suggestion. As we cannot edit the main paper now, we will incorporate those results and changes right after we can do so.\n\nWe greatly appreciate your timely follow-up on our rebuttal.'}}, {'title': {'value': 'Thanks for the rebuttal.'}, 'comment': {'value': 'Thanks for the authors. \n\nNovelty is currently acceptable to me. \n\nI am very grateful for the efforts made by the author, especially for incorporating the VAE-based generation method (although I was anticipating seeing the advantages of diffusion over other generative models by incorporating physics constraints or knowledge as conditions in the backbone of conditioned VAE). However, considering the limited rebuttal time window, I will not be demanding more.\n\nFurthermore, I still believe that providing mean and variance through multiple evaluations is better than reporting only the best results. For instance, in the supplementary Table A3 provided by the author, for the locomotion task and the task of moving a box, it can be observed that the variance is particularly high. There is already significant overlap with the VAE algorithm that does not incorporate physics constraints. The author should  provide the mean and variance for the baseline in Table 2 of the main submission to enhance the persuasiveness of the results and conclusions.\n\nIf my concerns are addressed, I will immediately increase the score.'}}, {'title': {'value': 'Thank you and we are looking forward to your post-rebuttal feedback!'}, 'comment': {'value': ""Dear AC and all reviewers:\n\nThanks again for all the insightful comments and advice, which helped us improve the paper's quality and clarity.\n\nThe discussion phase has been on for several days and we have not heard any post-rebuttal responses yet.\n\nWe would love to convince you of the merits of the paper. Please do not hesitate to let us know if there are any additional experiments or clarification that we can offer to make the paper better. We appreciate your comments and advice.\n\nBest,\n\nAuthor""}}, {'rebuttal': {'value': 'We thank reviewer vV19 for bringing up several concerns. We provide additional experimental results (see the one-page pdf in the global response) and discussion as the below.\n\n**Limited novelty.**\n\nWe aim to design robots with physical function and simple pattern generation will not get us there. We hence propose an entirely new framework by leveraging the computational power of a physics simulator to achieve meaningful results. Generative models are far from sufficient as:\n- The generated contents of most large-scale pre-trained generative models don’t reason about physics and fail to achieve any physical utility or functionality.\n- Unlike most training of generative modeling, computational robot design normally doesn’t have access to real data (which in our case, a dataset of well-performing robots). Instead, we need to leverage the physics-based simulation that evaluates the performance of a robot.\n\nPlease refer to 1-3 paragraphs in the introduction for more detailed justification. Thus, we make the following technical contributions,\n- introduce a new framework that augments the diffusion-based synthesis with physical dynamical simulation in order to generatively co-design task-driven soft robots in morphology and control (the last paragraph in the introduction).\n- propose a method to robotize 3D shapes from diffusion samples for meaningful evaluation in physics-based simulation (section 2.3).\n- present methods for driving robot generation toward improved physical utility by optimizing input embeddings and incorporating differentiable physics into the diffusion process (section 2.4).\n\n**Stronger baselines.**\n\nAs opposed to pure 3D generative modeling, soft robot co-design remains relatively unexplored. We believe most prior methods are covered as baselines for benchmarking, e.g., we adapt one of the most well-known yet a bit old method CPPN [49] to Diff-CPPN that can be used with the more recent and powerful techniques via differentiable physics. Nevertheless, we further compare with a very recent paper, DiffAqua [27]. Originally, we didn’t include this baseline since this method is designed for swimming tasks and lacks generality across a wide range of tasks. Briefly, DiffAqua proposes to compute Wasserstein barycenter among a set of primitives of underwater creatures. We report mean and standard deviation for all tasks in Table A1.\n\nWe can observe that DiffuseBot outperforms DiffAqua across all tasks. There is a natural tradeoff in the method between choosing a larger set of primitives for potentially better performance across diverse tasks and obtaining good solutions in Wasserstein barycenter optimization. To this end, we believe leveraging the power of large-scale pre-trained 3D generative models remains a more scalable and general method toward soft robot co-design.\n\n**Report the mean and var.**\n\nWe report the best results since normally the soft robot co-design problem expects to only produce one final robot design that can achieve high performance for a certain task (somewhat similar to other applications like drug discovery). To make the analysis more thorough, we report the mean and standard deviation in Table A2. Most results lead to conclusions that are consistent with Table 2 (using the best), except for hurdling, where the implicit function (IF) gives slightly better performance. However, IF is much more unstable, indicated as the much larger 0.63 standard deviation.\n\n**Ablation on physics components.**\n\nThe ablation for the physics-augmenting components is shown in Table 1, Table 3, and Table 4 (this is the figure with caption “Varying starting...”; it is incorrectly labeled as table).\n- In Table 1, we show the results of improved physical utility by augmenting physical simulation with diffusion models; specifically, we demonstrate how the 3D diffusion model (Point-E) works poorly (1st row), and how the proposed components in DiffuseBot greatly enhance the task performance (2nd, 3rd rows). Please refer to section 3.2 paragraph “Physics-augmented diffusion” for more detailed discussion.\n- In Table 3 and Table 4, we conduct more fine-grained ablation studies on embedding optimization and diffusion as co-design. Please refer to section 3.3 for more detailed discussion.\n\n**Baselines such as VAE or transformer.**\n\nWhile there exist many 3D generative models other than diffusion-based models (including VAE [A1,A2], normalizing flow [A3], GAN [A4], etc.), it is non-trivial to incorporate physics priors into the generative process. Compared to other generative models, diffusion models allow us to elegantly build theoretical constructs to incorporate external knowledge like physic-based simulation as guidance throughout the iterative generative process, which is also the major technical contribution in DiffuseBot. Besides, diffusion models have emerged as the de-facto of content generation, inspiring our work to harness such power to soft robot design application.\n\nTo further strengthen the paper, in Table A3, we compare with a recent VAE-based 3D generative model [A1], which outperforms other widely adopted baselines [A2-A6]. Given it is an open question to augment physics in VAE-based models (and, in fact, any other generative models), we perform direct optimization of co-design on the generated samples of [A1] to leverage physics-based simulation. With more advanced ways to inject physics prior into generative process as proposed in DiffuseBot, much superior performance can be achieved. Lastly, DiffuseBot uses a transformer-based architecture to generate 3D point clouds as in Point-E.\n\n**Limitations.**\n\nPlease check the paragraph about limitations in the global response.\n\n**References**\n\n[A1] Cheng. Autoregressive 3d... ECCV 2022.\n\n[A2] Kim. Setvae: Learning hierarchical... CVPR 2021.\n\n[A3] Yang. Pointflow: 3d point... ICCV 2019.\n\n[A4] Wu. Multimodal shape... ECCV 2020.\n\n[A5] Luo. Diffusion...point cloud generation. CVPR 2021.\n\n[A6] Zhou. 3d..point-voxel diffusion. ICCV 2021.'}}, {'rebuttal': {'value': 'We thank reviewer zr6A for acknowledging that our approach is interesting and promising. We address remaining questions as the below.\n\n**Clearer exposition in diffusion as co-design.**\n\nGradient-based optimization is shown to achieve more efficient and effective design search in soft robot co-design [19,25,44,48], especially with soft robots having a continuum of bodies and non-rigid contact. Thus, we aim to connect gradient-based optimization to diffusion-based generative processes in our work.\n\nThe “synergy” in line 152 is between diffusion models and energy-based models, not robot co-design; it draws a connection to MCMC sampling in energy-based models and makes the update of diffusion process more “gradient-descent-like”. This allows us to elegantly formulate gradient-based optimization, which is commonly used in soft robot co-design, in the diffusion-based generative process. Please refer to [11,12,42] for more details about the theory and the appendix section D paragraph “Connection to MCMC” for more complete theoretical motivation.\n\nMore precisely, the condition refers to the embedding either from text inputs, or from image inputs, or directly optimized in the Embedding Optimization stage to achieve physical utility. \n\nWe will improve the exposition in section 2.4 paragraph “Diffusion as Co-design” in the revision.\n\n**Actuator and stiffness.**\n\nThe goal of DiffuseBot is to demonstrate the potential of using diffusion models to generate soft robot design and to leverage the knowledge of the pre-trained generative models learned from a large-scale 3D dataset. Under this setting, the generated output of the diffusion model can only provide the geometry information of robot designs, leading to our design choice of having full dependency of actuator and stiffness on the geometry. This may be a reasonable simplification as prior works [48] have shown geometry along with properly-set actuator and stiffness (we take manual efforts to design proper mapping from geometry to actuator and stiffness in this work) roughly reflect the performance of a soft robot design. For better generality, one potential remedy is to optimize actuator and stiffness independently from the geometry generated by the diffusion model, i.e., apply DiffuseBot and do direct optimization on actuator and stiffness afterward or at the same time. Another interesting direction may be, for actuators, to leverage part-based models [A5] to decompose a holistic geometry into parts (or different actuator regions in soft robots).\n\n**The connection to [A1].**\n\nThere is some synergy between text inversion in [A1] and embedding optimization in DiffuseBot. Both of them aim at tuning the embedding toward reflecting certain properties of the output generation, i.e., describing the output generated images in [A1] and toward improved physical utility in DiffuseBot. The major difference lies in the nuance of the data/samples used to carry out the optimization. Text inversion performs a direct optimization using latent diffusion model loss (Eq. (2) in [A1]), which computes losses on noisy samples/latents corrupted from the real dataset. On the other hand, it is tricky to think about real dataset in robot design (as discussed in line 40-44 and line 125-130), embedding optimization in DiffuseBot computes losses on noisy samples corrupted from self-generated data filtered by robot performance (as in Algorithm 1 and section 2.4). Conceptually, it is more like a mixture of diffusion model training and online imitation learning like DAGGER [A4].\n\nWe will include this discussion in the revision.\n\n**Discussion on more general applications [A2,A3].**\n\nA potential and interesting way to adapt DiffuseBot to other applications like motion planning or control [A2,A3] is to view a generated robot as one snapshot/frame of a motion/state sequence and the physics prior can be the dynamics constraint across timesteps (e.g., robot dynamics or contact dynamics that enforce non-penetration). The physics prior can be injected similarly to diffusion as co-design that propagates the enforcement of physical plausibility of generated states from differentiable physics-based simulation to diffusion samples. For example, considering states in two consecutive timesteps, we can compute loss in the differentiable simulation to measure the violation of physical constraints regarding robot dynamics or interaction with the environment. Then, we can compute gradients with respect to either control or design variables; for gradients in control, this will essentially augment works like [A2,A3] with classifier-based guidance to achieve physical plausibility; for gradients in design, this will much resemble optimizing toward the motion sequence of a shape-shifting robot.\n\nWe will include this discussion in the revision.\n\n**Features used in k-means clustering.**\n\nWe use the 3D coordinates offset by the center of the geometry as the feature for k-means clustering. We will make it clearer in line 120 in the revision.\n\n**Structural biases in line 86.**\n\nThe structural biases refer to the knowledge in the pre-trained 3D generative models learned from large-scale 3D datasets. The idea is, instead of searching for good robot designs from scratch, explore in the space of what a 3D generative model has learned, which provides biases toward diverse and sensible 3D structures. We will provide a clearer description in the revision.\n\n**References**\n\n[A1] Gal et al. “An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion.”, ICLR, 2023.\n\n[A2] Janner et al. “Planning with Diffusion for Flexible Behavior Synthesis.”, ICML, 2022.\n\n[A3] Ajay et al. “Is Conditional Generative Modeling all you need for Decision-Making?” ICLR, 2023.\n\n[A4] Ross et al. A reduction of imitation learning and structured prediction to no-regret online learning. AISTATS 2011.\n\n[A5] Kaiser et al. A survey of simple geometric primitives detection methods for captured 3D data. CG 2019.\n'}}, {'rebuttal': {'value': 'We appreciate the reviewer syw2 recognizing our work as well-written, novel, and with extensive results. We address the remaining questions as the below.\n\n**Limitations or failure scenarios.**\n\nPlease check the paragraph about limitations in the global response.\n\n**Hyper-parameter choices.**\n\nHyperparameters are chosen mostly based on intuition and balancing numerical scale with very little tuning. In the following, we briefly discuss the design choices of all hyperparameters listed in Table 5 and 6 in the appendix. For min buffer size, samples per epoch, training iteration per epoch, and batch size, we roughly make sufficiently diverse the data used in the optimization and use the same setting for all tasks. For buffer size, we start with 60 and if we observe instability in optimization, we increase to 10 times, 600 (similar to online on-policy reinforcement learning); note that buffer size refers to the maximal size and increasing this won’t affect runtime. For buffer Top-K, we start with 6 and if we observe limited diversity of generation throughout the optimization (or lack of exploration), we double it. For $t_{max}$, $t_{min}$, and $\\Delta t$ (we made some typos in Table 6, all 60’s should be 50’s), we roughly inspect how structured the generation in terms of achieving the desired robotic task to determine $t_{max}$ and modify $\\Delta t$ accordingly to match the similar number of performing MCMC sampling (e.g., $t_{max}$/$\\Delta t$: 400 / 50 $\\approx$ 150 / 25). For the number of MCMC steps K, we simply set 3 for passive tasks and 5 for active tasks by intuition. For $\\sigma$, we simply follow one of the settings in [11]. For the guidance scale $\\kappa$ and renorm scale, we check the numerical values between $\\epsilon$ and gradient from differentiable simulation and try to make them roughly in the similar magnitude, and set the same scale for all tasks for simplicity. For $\\gamma$, we set 0.001 for trajectory optimization and 0.01 for parameterized controllers based on our experience of working with differentiable physics. Overall, from our empirical findings, the only hyperparameters that may be sensitive include buffer size and buffer Top-K for optimization stability and generation diversity, and guidance scales, which need to be tuned to match the numerical magnitude of other terms so as to take proper effect.\n\nWe will include the above descriptions in the appendix section C.\n\n**Details on robot manufacturing.**\n\nThe details of the physical robot experiment and the manufacturing is in the appendix section G. We describe how to build muscle fiber with tendon-driven actuators, how to achieve soft bodies with lattice structure, and how to fabricate the physical robot with a carbon 3D printer. Please find more details in the section G along with videos of using the soft gripper to pick up various types of objects in the project site (link shown in line 685). In addition, we further conduct a simple quantitative analysis on the behavior of simulation and the physical robot. Please check out more details in the response to reviewer 7Vvn.\n\nAlthough, at present, the compilation of the virtual robot to a physical, digitally fabricated counterpart involves manual post-processing of algorithm\'s output, most, if not all of these steps could be automated. Our method outputs a point cloud (defining geometry), actuator placements, and an open-loop controller, along with a prescribed stiffness. Since we can easily convert the point cloud into a 3D triangle mesh, the geometry can be created by almost any 3D printing method. In order to realize an effective stiffness and material behavior, stochastic lattices, specifically Voronoi foams, have been used [A1,A2] in the past and employed here in order to match target material properties.  Given the actuator placement, tendons [A3,A4] can be aligned with the prescribed (contiguous) regions. Since a lattice is used, threading tendons through the robot body is simple, and we note that even more complex routings have been studied in detail in the literature [A5]. Creating attachment points for the tendons is a relatively simple geometry processing problem [A6]. Thus, converting a virtual robot to a specification that incorporates geometry, material, and actuation can be automated in a straightforward way.\n\nWe note that when controlled, the physical robot may not always match the virtual robot\'s motion.  This is the sim-to-real gap, and is significantly harder to overcome in our case than translating the virtual robot to physical hardware.  Significant literature has been invested in specifically tackling the sim-to-real gap, and in our case would require its own dedicated project; however, we note that often hardware can be adapted to work by modifying only the control policies using feedback from real-world experiments, often even with little human intervention [A7].\n\n**Metrics.**\n\nThey are more of a soft version of success rate. The definition of the metric in Table 1 and 2 is in the appendix section D. We will add a pointer at line 182 in section 3.1 as,\n\n“We refer the reader to the appendix Section D for more detailed task descriptions and performance metrics.”\n\n**References**\n\n[A1] Martínez et al. ""Procedural voronoi foams for additive manufacturing."" TOG 2016.\n\n[A2] Goswami et al. 3D‐architected soft machines with topologically encoded motion. Advanced functional materials 2019.\n\n[A3] In et al. A novel slack-enabling tendon drive that improves efficiency, size, and safety in soft wearable robots. ToM 2016.\n\n[A4] Kim et al. Slider-tendon linear actuator with under-actuation and fast-connection for soft wearable robots. ToM 2021.\n\n[A5] Bern et al. ""Interactive design of animated plushies."" TOG 2017.\n\n[A6] Chen et al. Encore: 3D printed augmentation of everyday objects with printed-over, affixed and interlocked attachments. UIST 2015.\n\n[A7] Ha et al. Learning to Walk in the Real World with Minimal Human Effort. CoRL 2021.'}}, {'rebuttal': {'value': 'We appreciate reviewer 7Vvn for recognizing our paper as a robust, comprehensive and innovative work supported by extensive experiments and a proof-of-concept physical robot to demonstrate the potential of future research. We address the remaining suggestions as the below.\n\n**Simulation and physical robot: quantitative analysis and potential future solution.**\n\nThanks for bringing this extremely interesting question. To start off, we would like to highlight that the main focus of our work is to showcase the fascinating possibility of applying diffusion-based generative models to soft robot co-design by augmenting physics, and the hardware experiment is more of a proof-of-concept that minimally demonstrates the potential. The sim-to-real issue in soft robots involves materials, actuation, fabrication, and many other factors, and is an open and extremely challenging research question.\n\nIn order to explore the quantitative gap between the behavior of the physical robot and the simulated robot, we conducted an experiment with the following conditions, where similar setups are commonly adopted in soft robot literature [A1]. The objective was to measure the change in distance between two tips when we pull/release two tendons - one for closing the gripper (flexion) and the other for opening it (extension). The tendons were pulled or released in increments and decrements of 2mm, and the results are depicted in Figure A1 in the one-page pdf in the global response.\n\nWhen contracting the tendon to flex or extend the fingers, both simulation and real robot results show log-shaped graphs. The pattern in the physical robot plot is a commonly observed phenomenon called hysteresis. However, the main difference between the simulation and real-world cases can be seen when releasing the tendon from a fully contracted state. In the real robot experiment, the tip distance changes rapidly, while in the simulation, the opposite effect is observed.\n\nOne plausible explanation for this disparity could be attributed to the friction direction and elongation of the tendons. During the transition from tendon contraction to tendon release, the tension of the tendon at the end-effector may change suddenly due to the change of the friction direction. Also, since we only control the motor position (not the tendon position) to pull/release the tendon with 2mm step, the exact tendon length may not be exactly the same when we consider the tendon elongation.\n\nGiven that the gap between simulation and real robot performance seems to originate from the actuation/transmission method, our future work will focus on developing a tendon-driven actuation simulation framework. This framework aims to address the differences and improve the accuracy of our simulations. We are exploring other possible explanations for the sim-to-real gap and will investigate any additional factors that may contribute to the observed discrepancies. Overall, as for a high-level general solution, we believe (1) adjusting parameters based on observed sim to real gap and repeat the design process or (2) building a more accurate physics-based simulation (which can be straightforwardly plug-and-played in DiffuseBot) can largely bridge the sim-to-real gap of fabricating physical robots; or more interestingly, connecting generative models to commercial-level design and simulation softwares.\n\n**References**\n\n[A1] Fang, B., Sun, F., Wu, L., Liu, F., Wang, X., Huang, H., Huang, W., Liu, H. and Wen, L., 2022. Multimode grasping soft gripper achieved by layer jamming structure and tendon-driven mechanism. Soft Robotics, 9(2), pp.233-249.\n'}}, {'rebuttal': {'value': 'We thank reviewer 5Fqn for positive comments on the soundness and the contribution of our work. We address the remaining questions as below.\n\n**Challenges of physical robot fabrication.**\n\nThanks for recognizing the contribution of our work in spite of these non-trivial challenges of real-world transfer. We further conduct a simple quantitative analysis on sim-to-real transfer. Please check out more details in the response to reviewer 7Vvn along with the experimental results shown in the one-page pdf in the global response as well as the in-depth discussion on manufacturing physical robots in the response to reviewer syw2.\nNote that this experiment only serves a preliminary study and more comprehensive and in-depth analysis along with further contribution should be done in the future research. We will also dedicate a paragraph to discuss these challenges and potential remedy in the limitation section in the revision.\n\n**No reference to 2.2.**\n\nWe will add the following in the first paragraph of section 2 in the revision,\n\n“… then describe the proposed DiffuseBot framework, which consists of diffusion-based 3D shape generation (Section 2.2), a differentiable procedure …”\n\n**Explicit definition of \\bold c.**\n\nThe **c** in Eq. (5) is the embedding to be optimized. We will add a clearer definition at line 133 right after Eq. (5) in the revision.\n\n**L159: what does the slash mean?**\n\nIt is a typo and it should be a period. We will update this in the revision.\n\n**Motivation for the tasks.**\n\nAt a high level, we select tasks that \n1. can cover a wide spectrum of existing robotics tasks: we briefly categorize tasks into passive dynamics, locomotion, and manipulation. Note that passive dynamics tasks are explicitly considered here since there is no active control of robot bodies, making optimization on robot design a direct factor toward physical utility.\n2. only involve lower-level control/motion without the complications of long-term or higher-level task planning: we select tasks that mostly involve few motor skills, e.g., in manipulation, instead of pick and place, we simply aim at picking up/gripping an object.\n3. are commonly considered in other soft robot co-design literature: all proposed active tasks are widely used in the soft robot community, including crawling [5,7,35,48], hurdling/jumping [19,A1,A2], and manipulating objects [3,8,27]. \n4. may induce more visible difference in robot designs between the performing and the non-performing ones to facilitate evaluation and algorithmic development: we select tasks more based on heuristics and intuition, e.g., in crawling, we expect leg-like structures may outperform other random designs.\n\nWe will include the above discussion in the appendix section D in the revision.\n\n**Explanation about the performance metric.**\n\nThe performance metrics are described in the appendix section D. We will add brief description as below and a pointer in section 3.1,\n\n“We refer the reader to the appendix Section D for more detailed task descriptions and performance metrics.”\n\n**Brief introduction to the baselines.**\n\nIn the revision, we will add the following paragraph in section 3.2 with more details in the appendix: \n\n“In Table 2, we compare with extensive baselines of soft robot design representation: particle-based method has each particle possessing its own distinct parameterization of design (geometry, stiffness, actuator); similarly, voxel-based method specifies design in voxel level; implicit function uses use a shared multi-layer perceptron to map coordinates to design; DiffCPPN uses a graphical model composed of a set of activation function that takes in coordinates and outputs design specification. These baselines are commonly used in gradient-based soft robot co-design [19,44,48]. ”\n\n**Incorrect labeling of Table 4.**\n\nThanks for catching these typos. Table 4 at the bottom of page 7 should be labeled as Figure X and the reference of Figure 4 in L233 should be Figure X. We will fix the labeling and referencing in the revision. (After fixing this issue in the manuscript, X is 6 and the original Figure 6 becomes Figure 7)\n\n**Other input formats than texts.**\n\nThe use of textual inputs additional to the embeddings optimized toward physical utility is achieved by both being able to be consumed by the diffusion model to produce guidance for the diffusion process $\\epsilon$. More concretely speaking, in DiffuseBot, we use the CLIP feature extractor as in Point-E and it allows to extract embedding for both text and image modalities, which can then be used as a condition $\\mathbf{c}$ in the diffusion model. Thus, we can also incorporate images as inputs and perform the exact same procedure as that of the textual inputs. Theoretically, the textual inputs are incorporated via following the intuition in lines 162-165, where the textual inputs additionally provide gradients toward following the textual specification. Similarly, the image inputs can also be processed to provide gradients since CLIP embeddings live in a joint space of images and languages. More interestingly, if we build DiffuseBot on models other than Point-E, which can consume embeddings for other modalities like audio as conditioning, we can then straightforwardly perform robot design generation guided by the other corresponding input formats (and meanwhile, toward physical utility). Note that this critical feature of compositionality across different sources of guidance throughout the reverse diffusion process is one of the biggest advantages of using diffusion-based models as opposed to other types of generative models.\n\nWe will include this discussion in the appendix in the revision.\n\n**Limitation in the conclusion.**\n\nPlease check the paragraph about limitations in the global response.\n\n**Reference**\n\n[A1] Tolley, M.T., et al., An untethered jumping soft robot. IROS 2014.\n\n[A2] Bartlett, N.W., et al., A 3D-printed, functionally graded soft robot powered by combustion. Science 2015.\n'}}, {'rebuttal': {'value': 'We thank all reviewers for their thoughtful and constructive feedback. We are encouraged to hear the reviewers acknowledge,\n- that the proposed approach is robust, innovative, and extends beyond theoretical construct to practical, real-world applications (reviewer 7Vvn), interesting and promising as a crucial solution to inject a physics prior to diffusion models (reviewer zr6A), novel and interesting (reviewer syw2), and introduces a new framework that augments diffusion-based synthesis with physical dynamical simulation (reviewer 5Fqn);\n- that the paper is well-written and easy to follow with overall clarity (reviewer zr6A, syw2, vV19);\n- that the results verify the effectiveness of DiffuseBot (reviewer 5Fqn), are with thorough experimental coverage and extensive testing (reviewer 7Vvn), are comprehensive and thoughtful (reviewer zr6A), and provides extensive comparisons with baselines and ablation studies (reviewer syw2);\n- that the proof-of-concept physical robot solidifies the relevance and potential of the research in real-world scenarios (reviewer 7Vvn), is impressive (reviewer zr6A). \n\nIn response to feedback, we provide individual responses below to address the remaining concerns from each reviewer to improve clarity of missing details and to provide additional discussion that strengthen our paper. Briefly, we summarize the added experiments and revision to the paper,\n- Add quantitative analysis on the behavior of simulation and physical robots along with further discussion on physical robot fabrication.\n- Add a paragraph for the discussion on limitations.\n- Comparison to an additional baseline of a more recent soft robot co-design method.\n- Comparison to an additional baseline of a VAE-based generative model.\n- Report additional statistics including mean and standard deviation for baseline comparison.\n- Add more clarification to the paper and discussion on relevant works.\n\nFor more details, please check individual responses. We thank all reviewers’ for their time and efforts! We hope our responses have persuasively addressed all remaining concerns. Please don’t hesitate to let us know of any additional comments or feedback on improvement.\n\nNote that we include all additional experimental results in the one-page pdf submitted along with this global rebuttal response.\n\n**A paragraph dedicated to limitations.** Re reviewer 5Fqn, syw2, vV19. We will add this to the revision.\n\n“The major limitation of DiffuseBot is that we make a simplification in the parameterization of actuators and stiffness; we make dependencies of the two design specifications on robot geometry (check more technical details in section 2.3 paragraph Actuators and Stiffness. This works well with properly-crafted mapping from geometry to the others yet limits the potential by human prior with little use of the generative power. While this may be reasonable as properly-set actuators and stiffness based on geometry (hand-tuned empirically in this work) roughly reflects task performance, a more flexible parameterization can definitely lead to improved performance. Potential remedy can be using part-based 3D generative models for actuators and direct optimization for stiffness. Another limitation is the gap between simulated results and real robots. While the hardware experiment has shown as a proof-of-concept that minimally demonstrates the potential, physical robot fabrication and real-world transfer have countless non-trivial challenges including stiffness and actuator design, sim-to-real gap, etc. This may require studies on more high-fidelity physics-based simulation, which can be straightforwardly plugged into DiffuseBot.”\n'}, 'pdf': {'value': '/pdf/f16d5eb664b497787f779ea7f0de90a17099cb87.pdf'}}, {'summary': {'value': 'This paper proposes a physics-augmented diffusion model that generates soft robot morphologies capable of excelling in a wide spectrum of tasks called DiffuseBot. DiffuseBot bridges the gap between virtually generated content and physical utility by (i) augmenting the diffusion process with a physical dynamical simulation which provides a certificate of performance, and ii) introducing a co-design procedure that jointly optimizes physical design and control by leveraging information about physical sensitivities from differentiable simulation. In the experiment, they showed a range of simulated and fabricated robots along with their capabilities.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. The paper introduces a new framework that augments diffusion-based synthesis with physical dynamical simulation in order to co-design task-driven soft robots in morphology and control.\n2. The method leverages optimizing input embeddings and incorporating differentiable physics into the diffusion process for driving robot generation in a task-driven way toward improved physical utility. \n3. They performed experiments in simulation to verify the effectiveness of DiffuseBot, extensions to text-conditioned functional robot design, and a proof-of-concept physical robot as a real-world result. \n'}, 'weaknesses': {'value': 'The presentations in this paper were sometimes unclear, as asked in the following placeholder. The paper admitted that there are countless non-trivial challenges in the physical robot fabrication and real-world transfer, including stiffness and actuator design, and the sim-to-real gap. However, in my opinion, other contributions of this paper may outperform the weaknesses. '}, 'questions': {'value': '1. In Section 2 before 2.1, there was no reference to 2.2. Is it fine?\n2. I did not find the explicit definition of bold c in Eq. (5).  \n3. L159: what does the slash mean? \n4. In the experiments, I want to know why such tasks were selected (i..e, motivation for the tasks). \n5. I cannot find the explanation about the performance metric such as Tables 1 and 2 (sometimes having minus values). This information is important and should be mentioned in the main text.\n6. The (short) introduction of the baseline models and the reasons can be mentioned. \n7. The figure at the bottom of page 7 was Table 4, but may be incorrect. And Figure 4 in L233 may be incorrect. \n8. Section 3.4: The paper discusses the use of textual inputs and is very interesting. Can the authors discuss the potential for using other input formats?\n'}, 'limitations': {'value': 'In the conclusion section, there seems to be less limited information about this work from the experimental results. In other parts, general limitations were mentioned.\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper introduces DiffuseBot, a system that aims to simplify and automate the design of soft robots in simulation and real-world systems. DiffuseBot uses diffusion-based algorithms to co-design soft robot morphology and control for specific tasks, combining the diversity of evolutionary algorithms with the efficiency of gradient-based optimization. The system is made possible by advancements in AI-driven content generation.\n\nHowever, existing generative algorithms face challenges when applied to physical soft robot co-design, such as the lack of consideration for physics and task performance. To overcome these, DiffuseBot uses physical simulation to guide the generative process of pretrained large-scale 3D diffusion models. It also develops an automatic procedure to convert raw 3D geometry into a format compatible with soft body simulation.\n\nThe system optimizes the embeddings that condition the diffusion model, skewing the sampling distribution toward better-performing robots as evaluated by a simulator. It also reformulates the sampling process to incorporate co-optimization over structure and control.\n\nDiffuseBot has been tested on a wide range of tasks, demonstrating its superiority to comparable approaches. It also allows for human input in the robot generation process and has been used to create a proof-of-concept 3D-printed real-world robot. The paper contributes a new framework that augments the diffusion-based synthesis with differentiable physics simulation, methods for driving robot generation in a task-driven way toward improved physical utility, and extensive experiments in simulation to verify the effectiveness of DiffuseBot.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'This paper is robust and comprehensive in its approach. It introduces an innovative method that applies diffusion models to the co-design of robots, representing a significant contribution to the field. The authors have ensured thorough experimental coverage by testing their system, DiffuseBot, on a diverse range of tasks. This extensive testing underscores the versatility and applicability of the proposed method. Furthermore, the paper is not limited to theoretical constructs but extends to practical, real-world applications. The authors demonstrate this by providing a proof-of-concept 3D-printed real-world robot, thereby solidifying the relevance and potential of their research in real-world scenarios. '}, 'weaknesses': {'value': 'The paper does not exhibit any significant shortcomings or areas of concern.'}, 'questions': {'value': ""In your paper and supplementary materials, you've provided a qualitative discussion on the challenges of translating simulated results into the fabrication of real robots based on the design developed in simulation. Could you delve deeper into this issue by providing more detailed, quantitative results that highlight the discrepancies between the behavior of the simulated robot and its real-world counterpart? Additionally, could you propose potential solutions aimed at minimizing this gap between simulation and reality?""}, 'limitations': {'value': 'The paper effectively addresses all identified limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper introduces DiffuseBot, a physics-augmented diffusion model designed for generating and optimizing the morphologies and control mechanisms of soft robots. DiffuseBot aims to bridge the gap between virtually generated content and physical utility in the domain of soft robotics. Firstly, it combines the diffusion process with a physical simulation that serves as a performance certificate, thereby ensuring the feasibility and effectiveness of the generated designs. Secondly, it details a co-design procedure that simultaneously optimizes the physical design and control of the soft robots, leveraging insights from differentiable simulation. The paper validates the efficacy of this approach by presenting a variety of both simulated and physically fabricated robots, along with their diverse capabilities.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""1. In general, the paper is well written, with only minor flaws. Even those unfamiliar with soft robot design will find the paper easy to comprehend.\n\n2. Although diffusion models are expressive and powerful, their performance for tasks dealing with physical tasks often falls short. Thus, injecting a physics prior or 'physics-augmented diffusion model' is crucial. I think the method proposed in this paper is interesting and promising. \n\n3. The evaluation is comprehensive and thoughtful. The physical robot is impressive.\n""}, 'weaknesses': {'value': 'Overall, I did not identify any major weaknesses in the paper, but here are a few points that could strengthen it:\n\n1. While the writing is generally clear, certain sections could benefit from clearer exposition, such as:\n*  The section on diffusion as co-design is not very intuitive, especially for audiences not familiar with soft robot design. Specifically, it should be clearer how gradient-based optimization benefits robot design and what exactly line 152\'s ""synergy"" means.\n* It would be helpful if the authors clarify that the ""condition"" in this work actually refers to text.\n2. The robot\'s actuator and stiffness seem oversimplified, having only constant stiffness. Given that the gradient of $\\Psi_{act}$ is almost zero, it appears that the actuator and stiffness are solely determined by the geometry.\n3. A similar idea of tuning in the embedding space is proposed in[1]. A discussion and connection to this existing work could be interesting.  \n4. In general, the method the paper uses to inject a physics prior into the generation process could be applicable to more general scenarios. Works like Diffuser[2] or Decision Diffuser[3] generate state sequences with diffusion models, but the generated states can sometimes be physically implausible. A deeper discussion about the potential of the method could make the paper stronger.\n\n[1] Gal, Rinon, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit H. Bermano, Gal Chechik and Daniel Cohen-Or. “An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion.”, ICLR, 2023.\n\n[2] Janner, Michael, Yilun Du, Joshua B. Tenenbaum and Sergey Levine. “Planning with Diffusion for Flexible Behavior Synthesis.”, ICML, 2022. \n\n[3] Ajay, Anurag, Yilun Du, Abhi Gupta, Joshua B. Tenenbaum, T. Jaakkola and Pulkit Agrawal. “Is Conditional Generative Modeling all you need for Decision-Making?” ICLR, 2023. '}, 'questions': {'value': '\n1. I do not fully understand how the k-means clustering is performed for actuator and stiffness generation. Specifically, what kind of feature is used for clustering?\n\n2. In line 86, which structural biases are you referring to ?\n'}, 'limitations': {'value': 'see weakness.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents DiffuseBot, a framework that uses physics-augmented diffusion models to generate soft robot designs and control strategies for various tasks. The authors propose to optimize the embeddings conditioned by the diffusion model to improve the physical utility of the generated robots, and to reformulate the diffusion sampling process as a co-design optimization that leverages differentiable simulation. The authors demonstrate the effectiveness of their method on several tasks, such as balancing, landing, crawling, hurdling, gripping, and moving objects. They also show how to incorporate human feedback and fabricate a physical robot prototype.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper is well-written and clear. The proposed method is novel and interesting, combining diffusion models for shape generation, physics-based simulation and co-design optimization. The paper provides extensive experimental comparisons with baselines and ablation studies on both latent optimization and co-design to validate the proposed method. The paper also shows some fun qualitative results of diverse robot designs that function under passive dynamics, locomotion tasks and manipulation tasks. '}, 'weaknesses': {'value': '- The paper does not discuss the limitations or failure scenarios of the proposed method. In addition, discussions on design choices can be help: how hyper-parameters are chosen, such as the guidance scale, or the number of MCMC steps? \n- Figure 1 shows that the motivation of this work is to deploy the optimized soft robot into the real world. However, though I may miss it, I did not find discussions in the paper about the feasibility of manufacturing the resulting soft robots, such as the soft gripper. Given that the actuators are currently assumed to be muscle fibers, it can be hard for manufacturing. '}, 'questions': {'value': '- Can limitations of the current pipeline be discussed and included in the paper?\n- Can the paper includes discussions about manufacturing?\n- How design choices are set? How sensitive is the current pipeline to hyper-parameters?\n- How to interpret the metric reported in Table 1, 2? ""We report the average performance with standard deviation in the superscript."" -- Is the performance success rate?'}, 'limitations': {'value': 'Please include a section about limitations. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work proposed a new framework that augments the diffusion-based synthesis with physical dynamical simulation in order to generatively co-design task-driven soft robots in morphology and control. The extensive experiments in simulation to verify the effectiveness of DiffuseBot.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': '1. The paper is well-written and easy to follow.\n2. The visualization is good and help me understand how the method works.\n3. The application of diffusion is always be encouraged and diffusion model is an interesting and promising backbone.\n\n'}, 'weaknesses': {'value': ""1. The novelty is limited and more like an incremental work that applied diffusion model into 3D soft body generation task. The relationship and difference with  Softzoo mentioned in the paper should be more clearly illustrated.\n2. The baseline for comparison is relatively weak, consisting of some outdated works from a few years ago. The paper should includes more strong and recent baselines.\n3. The evaluation way is not agreed. 'To avoid being trapped in the local optimum, we run each baseline with 20 different random initializations and choose the best one. Since DiffuseBot is a generative method, we draw 20 samples and report the best' . If the baseline is sensitive to the initialization seed, more detailed results should be reported rather not choose the best one. And the 20 runs should report the mean and var rather not the best. The explanation about the generative model is not convincing enough for me.\n4. The novelty is limited and more like an incremental work applying diffusion model in 3D generation domain. \n5. The physics augmented component is not included in ablation studies and this will harm the convincing conclusion in the paper.\n6. Why diffusion not other generative model, such as VAE or transformer? The ablation studies should be listed or the paper will be likely the incremental work.\n""}, 'questions': {'value': 'Please give more detailed clarification and experiments results to address my concerns. '}, 'limitations': {'value': '1. The novelty is limited and the motivation of using diffusion model is not well illustrated.\n2. The baseline is weak and old, the evaluation way is not agreed. The ablation studies are not enough.\n3. The role and the improvement bring by physic-augmented component is not well studied.\n4. The limitation part is absent in the submitted version. I hope the authors can discuss the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'DiffuseBot: Breeding Soft Robots With Physics-Augmented Generative Diffusion Models'}, 'authors': {'value': ['Tsun-Hsuan Wang', 'Juntian Zheng', 'Pingchuan Ma', 'Yilun Du', 'Byungchul Kim', 'Andrew Everett Spielberg', 'Joshua B. Tenenbaum', 'Chuang Gan', 'Daniela Rus']}, 'authorids': {'value': ['~Tsun-Hsuan_Wang2', '~Juntian_Zheng1', '~Pingchuan_Ma3', '~Yilun_Du1', '~Byungchul_Kim1', '~Andrew_Everett_Spielberg1', '~Joshua_B._Tenenbaum1', '~Chuang_Gan1', '~Daniela_Rus1']}, 'keywords': {'value': ['soft robot', 'diffusion model', 'co-design']}, 'abstract': {'value': ""Nature evolves creatures with a high complexity of morphological and behavioral intelligence, meanwhile computational methods lag in approaching that diversity and efficacy.  Co-optimization of artificial creatures' morphology and control in silico shows promise for applications in physical soft robotics and virtual character creation; such approaches, however, require developing new learning algorithms that can reason about function atop pure structure. In this paper, we present DiffuseBot, a physics-augmented diffusion model that generates soft robot morphologies capable of excelling in a wide spectrum of tasks. \\name bridges the gap between virtually generated content and physical utility by (i) augmenting the diffusion process with a physical dynamical simulation which provides a certificate of performance, and (ii) introducing a co-design procedure that jointly optimizes physical design and control by leveraging information about physical sensitivities from differentiable simulation.  We showcase a range of simulated and fabricated robots along with their capabilities. Check our website: https://diffusebot.github.io/""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'Use diffusion models augmented by physics-based simulation to breed soft robots'}, 'pdf': {'value': '/pdf/99219790f12d9993715f2e6a2eb03395ccb6b38e.pdf'}, 'supplementary_material': {'value': '/attachment/ffc986d9683f1056512609ca36966932ba11a6bd.pdf'}, '_bibtex': {'value': '@inproceedings{\nwang2023diffusebot,\ntitle={DiffuseBot: Breeding Soft Robots With Physics-Augmented Generative Diffusion Models},\nauthor={Tsun-Hsuan Wang and Juntian Zheng and Pingchuan Ma and Yilun Du and Byungchul Kim and Andrew Everett Spielberg and Joshua B. Tenenbaum and Chuang Gan and Daniela Rus},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=1zo4iioUEs}\n}'}, 'paperhash': {'value': 'wang|diffusebot_breeding_soft_robots_with_physicsaugmented_generative_diffusion_models'}}]"
"['Wisdom Ikezogwo', 'Saygin Seyfioglu', 'Fatemeh Ghezloo', 'Dylan Geva', 'Fatwir Sheikh Mohammed', 'Pavan Kumar Anand', 'Ranjay Krishna', 'Linda Shapiro']",NeurIPS,Quilt-1M_ One Million Image-Text Pairs for Histopathology,https://neurips.cc/virtual/2023/oral/73744,2023," Recent accelerations in multi-modal applications have been made possible with the plethora of image and text data available online. However, the scarcity of analogous data in the medical field, specifically in histopathology, has slowed comparable progress. To enable similar representation learning for histopathology, we turn to YouTube, an untapped resource of videos, offering $1,087$ hours of valuable educational histopathology videos from expert clinicians.From YouTube, we curate QUILT: a large-scale vision-language dataset consisting of $802, 144$ image and text pairs.QUILT was automatically curated using a mixture of models, including large language models, handcrafted algorithms, human knowledge databases, and automatic speech recognition.In comparison, the most comprehensive datasets curated for histopathology amass only around $200$K samples.We combine QUILT with datasets from other sources, including Twitter, research papers, and the internet in general, to create an even larger dataset: QUILT-1M, with $1$M paired image-text samples, marking it as the largest vision-language histopathology dataset to date. We demonstrate the value of QUILT-1M by fine-tuning a pre-trained CLIP model. Our model outperforms state-of-the-art models on both zero-shot and linear probing tasks for classifying new histopathology images across $13$ diverse patch-level datasets of $8$ different sub-pathologies and cross-modal retrieval tasks.",Oral 4B Datasets & Benchmarks,https://openreview.net/pdf?id=OL2JQoO0kq,https://openreview.net/forum?id=OL2JQoO0kq,OL2JQoO0kq,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (Oral)'}, 'comment': {'value': ""The paper presents a multimodal image-text dataset comprising one million histopathology image-text pairs, highlighting innovative data collection methods involving ASR and LLM for text extraction and correction. While concerns were raised regarding dataset accessibility, overlap with existing sources, and the performance gap between fine-tuning and training from scratch, the reviewers were highly enthusiastic about the merits of this work, including the comprehensive distribution of code, the dataset's significance for the research community due to its size, clear and well-written content, and ethical considerations. I believe this work will be of significant value to the research community.""}}, {'title': {'value': 'Thank you for the feedback'}, 'comment': {'value': 'Thank you for your responses and also for making the dataset available.  I am happy with the feedback from the authors'}}, {'title': {'value': 'Post rebuttal'}, 'comment': {'value': 'I would like thank the authors for the responses and subsequent updates to the manuscript. Having read other reviews, I am convinced this work would be valuable to community and inspire more extensions for foundation models specific to histopathology. Overall, I am happy to raise my initial score.'}}, {'title': {'value': 'Thank you'}, 'comment': {'value': 'Thank you for your detailed responses and also for making the dataset available. I have raised my score to 9.'}}, {'title': {'value': 'Thanks for your feedback to my comments.'}, 'comment': {'value': 'I am happy with the feedbacks from the authors. Considering the substantial workload in this study, I really hope this work could be accepted.'}}, {'comment': {'value': ""We would like to appreciate reviewer jVw5 for their review comments on our study.\n\n**Reviewer jVw5 asked how the authors determined the data sources are disparate.**\nTo clarify, we claim that QUILT does not overlap with existing data sources like LAION, OpenPath and PubMed, thus allowing us to merge it with those data sources to form QUILT-1M. QUILT does not overlap with existing histopathology image-text pair data (ARCH, OpenPath) because there is no overlap between the actual WSIs described between the two datasets.\n\n**Reviewer jVw5 asked why the finetuned CLIP model outperforms the CLIP model trained from random initialization (scratch).**\nWe believe the underperformance of training from scratch is tied to empirical observations that models with CLIP's contrastive objective tend to excel with larger datasets when trained from scratch, as compared to other vision-language objectives, such as ITM in VILT or BEiT. This is especially evident when the text encoder is being trained from scratch.\n\n**Reviewer jVw5 suggested ablation experiments to determine the downstream impact of other sources of data on the QUILT data.**\nWhile we acknowledge that further ablation studies could provide deeper insights into the quality of each sub-dataset and how much they provide on top of QUILT, our academic computational constraints restricted the extent of our evaluations. Only large industry labs would be able to complete such experiments within a reasonable period of time. Thus we've designated this comprehensive analysis for future work. \n\n**Reviewer jVw5 identified typos.**\nThanks for pointing out these typos! We have fixed the typo on page 9 in the discussion section, identifying the correct subsection in the Appendix as A5. We have corrected the number of external histopathology datasets to 13 (from 12) on page 2.\n\n**Reviewer jVw5 asked about the reproducibility of QUILT.**\nWe take data reconstruction concerns seriously. While our dataset is largely reproducible, some slight differences may arise due to non-deterministic elements within our pipeline (e.g. median image wrt pixels), or as rightly pointed out by the reviewer, creators may take down videos. Hence, we have chosen to release the full dataset (QUILT-1M) restrictively to those who comply with user data privacy policies via Zenodo (https://zenodo.org/record/8239942) and GoogleDrive (https://forms.gle/TKohQ7zLwYfFn8qRA) after researchers agree to certain terms, protecting against further distribution of the dataset and committing to its specified research use.""}}, {'comment': {'value': '\n**Reviewer rAj5 asked about the discrepancy in the manuscript-reported size of QUILT vs the observed size in the released CSV.** \nWe apologize for the oversight. The correct size of QUILT (which is the largest part of QUILT-1M) is actually 802,148 image-text pairs from the possible 802,186 rows in the released CSV, 38 of which had no captions. The figure of 768,826 mentioned in the paper is incorrect. Additionally, the actual number of images is 437,878, not the 419,780 stated in the paper. This discrepancy occurred because we accidentally shared only the training set while excluding the holdout set in our initial report. Also, the official number of the others are incorrect as they were numbers before quality checks, specifically, our PubMed subset has 59,371 pairs down from 62,458 pairs, our Laion subset has 22,682 pairs down from 23,240 pairs, and our OpenPath subset has 133,511 down from 133,526 reported in the manuscript, hence totaling up to 1,017,712 samples. The manuscript has been corrected to reflect this.\n\n**Reviewer rAj5 asked about access to the complete QUILT-1M, as the reconstruction code released is specific to QUILT and not any other data source that makes up QUILT-1M.** \nIndeed, our code/pipeline is specifically designed to reproduce only QUILT, not QUILT1M. To obtain QUILT1M, one would either \nneed to extract histology images from sources like Pubmed, Laion, and Openpath individually or \ndirectly request access to the dataset through Zenodo (https://zenodo.org/record/8239942) and GoogleDrive (https://forms.gle/TKohQ7zLwYfFn8qRA). These links are also available in the GitHub repo and website of the project.\n\n**Reviewer rAj5 suggested changes to certain claims and choice of words in the manuscript.**\nWe agree with the reviewer and have changed the word from ""halted"" to “slowed” in the abstract (line 3).\nPrior to our work Youtube or any online video platform has not been leveraged as a source of histopathology image and text data for training ML models, hence our use of the word untapped in line 5.\nFinally, the reviewer is correct in noticing the word “untapped” is unfit for line 94. We have omitted the word ‘untapped’ from the manuscript at that line.\n\n**Reviewer rAj5 asked for the reasoning behind the use of the word “expressive” on lines 55-56.**\n“Expressive” here is used to mean textual descriptions that clearly describe the image features and the underlying histologic concepts e.g describing the shape of a cell as well as the underlying consequences of that cell, as compared to text from say articles\' figure captions that aren’t as descriptive due to either many factors e.g page limits, descriptions unaligned with the figure.\n\n**Reviewer rAj5 asked about the resolution of downloaded videos that make up QUILT.**\nLow resolution simply means we download the lowest possible resolution a Youtube video has to provide, this is variable but typically is around 320p, so we set 320p as a minimum resolution used for search ONLY newly referenced on line 126. For the image extraction that forms the dataset we use the highest possible resolution, typically 1080p, and have referenced this on line 254. We’ve added the average height and width of the images on line 253 and this provides a sense of the average resolutions of videos dowxnloaded.\n\n**Reviewer rAj5 asked if any image-text pairs were checked for quality by humans.**\nDue to the extensive size of the data, our quality control measures were confined to eliminating non-histopathology images (considering our histopathology classifier has an approximate 5% false positive rate) and removing histopathology images accompanied by non-descriptive texts from all datasets (including PubMed, QUILT, Laion, and OpenPath). Nevertheless, the superior downstream performance of our model indirectly attests to the accurate alignment and quality of the data.\n'}}, {'comment': {'value': 'We highly appreciate reviewer rAj5 for their comments on our work. \n\n**Reviewer rAj5 asked if the dataset can be made available directly due to difficulty in reconstruction.**\nWe have chosen to release the full dataset (QUILT-1M) restrictively to those who comply with user data privacy policies via Zenodo (https://zenodo.org/record/8239942) and GoogleDrive (https://forms.gle/TKohQ7zLwYfFn8qRA) after researchers agree to certain terms, protecting against further distribution of the dataset and committing to its specified research use. Users can refer to the links on the website and the GitHub repo to request access to QUILT-1M.\n\n**Reviewer rAj5 asked for the manuscript to specify the applicable license.**\nWe have added this to the manuscript under the Datasheet for Dataset section. The data is shared under the MIT license (as described in our Repository and on openreview.)\n\n**Reviewer rAj5 asked how the identified narrators were considered/vetted to be experts.**\nHistopathology, being a specialized field, ensures that the majority of those discussing it possess notable expertise. Given the limited number of channels from which we curate content (only 278 in total), we undertook a manual assessment to verify the credibility of our narrators. Our findings revealed that most of these channels belong to hospitals or specialized doctors. We identified channels that had an educational format, and/or aimed their content towards an audience of other experts, implying a certain level of proficiency. Thus, even without direct assessment of each narrator’s capabilities, we theorize that our narrators are not only well-informed but are professionals with the confidence to disseminate educational content to their peers on public platforms.\n\n**Reviewer rAj5 suggested changes to certain claims made in the manuscript regarding previous methods in computational pathology.**\nWe acknowledge the reviewer\'s point. As outlined in lines 62-64 of the paper, we highlight the prevailing trend in computational pathology to operate at the WSI level. This is primarily driven by the costs associated with data collection at the patch level. It\'s crucial to clarify, however, that our assertion doesn\'t suggest the absolute nonexistence of any other CPATH task beyond weak-supervision on the slide level. Our use of ""suboptimal"" is to emphasize that models trained at the WSI level tend to underperform on patch-level tasks, particularly because they often rely on embeddings from out-of-distribution feature extractors, such as unfinetuned ResNets. We will make these statements clearer.\n\n**Reviewer rAj5 identified omissions of contextual information on models used and some dataset statistics in the manuscript.**\nWe have made the needed changes; reporting the LLM version used in the main paper (line 41) as GPT 3.5 and in the main paper as well as the appendix, the average resolution (height and width) of images, which is 882 x 1468 pixels (line 253), the scale of images (line 37), and the pre-trained model leveraged as OpenAI pre-trained CLIP model (line 264).\n\n**Reviewer rAj5 asked for a detailed data acquisition description of how our approach differs from OpenPath.** \nWith OpenPath releasing only the tweet IDs and associated text, leaving out images and the post-publication changes to Twitter\'s API, which became more restrictive and costly, our approach involved manual data curation complemented by our custom Twitter crawlers. Any discrepancies between our version of OpenPath and the original can be attributed to manual curation challenges and potential tweet deletions over time. It\'s essential to clarify that we solely utilized the tweet IDs shared by OpenPath without any additional inclusions.\n\n**Reviewer rAj5 suggested the use of dataset-hosting platforms with easy programmatic  access for hosting QUILT-1M.** \nTo aid findability, reproducibility, and most especially to provide the data to researchers without the CPU compute hours to run the reconstruction code, we offer access to the resized images version of QUILT via Zenodo (https://zenodo.org/record/8239942) and the full-sized images via GoogleDrive (https://forms.gle/TKohQ7zLwYfFn8qRA) due to restrictions in upload-size on other platforms.\n'}}, {'comment': {'value': 'We thank reviewer 7iJR and appreciate the time and effort invested in reviewing our work.\n\n**Reviewer 7iJR asked if any experts verified the data pairs and their level of involvement.**\nNo extra expert-pathologist’s hours were spent verifying the data. It\'s important to underscore that our data already originates from medical experts, implying an inherent level of accuracy and credibility. While we recognize concerns about the post-processing phase and potential inaccuracies therein, we are cognizant of this. We have verified a small subset for inaccuracies manually and are actively investigating potential inaccuracies as we build upon this contribution in our next project. \n\n**Reviewer 7iJR asked if ablations with varying dataset sizes were carried out to further extrapolate the dataset\'s utility in low-resource environments.**\nFirstly, it\'s crucial to emphasize that we released multiple QuiltNet models on Huggingface of varying model capacities (three models to be exact, ViT-B-32|GPT77, ViT-B-16|GPT77, and ViT-B-16|PMB-256). This ensures that researchers with limited resources can access and benefit from our models without having to undertake extensive training themselves.\n\nSecond, training a single model demanded significant computational power and time, using up 4-6 A100 GPUs for 12 hours for training. The resource intensity of the process substantially limited our ability to conduct additional ablations. Furthermore, in resource-scarce scenarios, considerations frequently pivot towards model size and FLOPs, more so given the extensive size of our dataset. This influenced our decision to train VIT models using varied patch sizes and text tower configurations, ensuring consistent dataset use across tests.\n\nFinally, we concede that a more granular analysis examining the correlation between dataset size and training performance would be beneficial. However, owing to the aforementioned computational limitations, we refrained from such an analysis. That said, both Figure 3 and Table 1 offer indirect evidence of the advantages conferred by a more substantial training dataset. Our model\'s performance, when juxtaposed with PLIP [1] (trained on a smaller dataset), is distinctly superior.\n\nIn light of these points, we commit to executing the suggested ablations and updating the manuscript in subsequent iterations.\n\n- [1] Huang, Zhi, et al. ""Leveraging medical Twitter to build a visual–language foundation model for pathology AI."" bioRxiv (2023): 2023-03.\n'}}, {'comment': {'value': 'We would like to thank this reviewer 8biP for their comments to improve our submission.\n \n**Reviewer 8biP suggested that QUILT(-1M) be made public due to the reconstruction challenges.**\nWhile our dataset is largely reproducible, some slight differences may arise due to non-deterministic elements within our pipeline e.g. (median image w.r.t pixels). Hence, we have chosen to release the full dataset (QUILT-1M) restrictively via Zenodo (https://zenodo.org/record/8239942) and GoogleDrive (https://forms.gle/TKohQ7zLwYfFn8qRA) after researchers agree to certain terms, protecting against further distribution of the dataset and committing to its specified research use.\n\n**Reviewer 8biP suggested an expansion of QUILT(-1M), including data modalities and multi-lingual captions.**\nWe\'re grateful to the reviewer for highlighting the importance of dataset diversity, a concern we wholeheartedly share and prioritize. To streamline our initial efforts, we focused exclusively on the English language for two primary reasons: 1) It facilitates a straightforward evaluation of LLM outputs, and 2) It maintains consistency with prior work [1], which solely comprises English-written tweets. However, as part of our ongoing endeavors, we are in the process of curating an expanded medical dataset from YouTube. This new collection will encompass various medical domains beyond histopathology and will include content in multiple languages.\n\n**Reviewer 8biP had some ethical concerns with the source of the images narrated by the experts which make up QUILT(-1M).**\nThe dataset is sourced from videos presented by medical experts who are already well-acquainted with the imperatives of protecting Protected Health Information (PHI), in compliance with privacy rules and laws, with histology images in the public domain from platforms such as pathpresenter and histologyguide.com. We limit the curation of our dataset to only publicly available YouTube videos which have already scraped private patient information from the histopathology images being discussed.\n\n**Reviewer 8biP had asked about the underperformance of QuiltNet on BACH in comparison to BiomedClip.**\nWe hypothesize that the dataset\'s limited size and our choice of text prompt might play a role in this.  Additionally, breast tissue is among the underrepresented sub-pathologies within QUILT. This might explain the underperformance on BACH, in which the distribution shift may be more pronounced than other breast-related datasets. Finally, BiomedClip [2] training benefits from more samples (possibly more medical breast-related samples).\n\n- [1] Huang, Zhi, et al. ""Leveraging medical Twitter to build a visual–language foundation model for pathology AI."" bioRxiv (2023): 2023-03.\n- [2] Zhang, Sheng, et al. ""Large-scale domain-specific pretraining for biomedical vision-language processing."" arXiv preprint arXiv:2303.00915 (2023).\n'}}, {'comment': {'value': 'We thank this reviewer for their suggestions to improve the paper.\n\n**Reviewer MJNv asked if data quality can be evaluated by pretraining the same network on QUILT(-1M) vs other datasets and measuring performance on a fixed test set as a proxy to measure data quality.**\nWhile we acknowledge the need for an extensive evaluation to determine the quality of our dataset, our current assessments already illustrate the distinct advantage QUILT offers. This is particularly evident when contrasting the performance of our VIT-32-B model with the  PLIP VIT-32-B model [1] that was trained on OpenPath [1]. Given that the core architecture of both models remains unchanged, with the dataset being the sole differing factor, any performance disparities underscore the enhanced quality of our data relative to OpenPath. Additionally, the public version of ARCH [2], comprising 7.5k entries, is notably smaller than OpenPath, being lesser by over an order of magnitude. Hence, we opted to employ ARCH as an external test set, focusing on measuring our model\'s zero-shot performance on it. \n\n**Reviewer MJNv suggested that we acknowledge a few more limitations.**\nFirst, we will add a statement that further human refinement might improve the quality of the dataset. Second, we concur with the reviewer\'s perspective that alternative models, such as BEIT or VILT, might potentially deliver superior performance given the volume of data we possess. Nonetheless, to minimize our computational overhead rather than training with discrete data subsets like OpenPath, we maintained consistency by using an architecture aligned with PLIP [1], ensuring straightforward performance evaluations. We will incorporate this point into our limitations section, recognizing it as an avenue for future exploration. In fact, we are already in the process of leveraging this dataset with varied learning objectives.\n\n- [1] Huang, Zhi, et al. ""Leveraging medical Twitter to build a visual–language foundation model for pathology AI."" bioRxiv (2023): 2023-03.\n- [2] Gamper, Jevgenij, and Nasir Rajpoot. ""Multiple instance captioning: Learning representations from histopathology textbooks and articles."" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021.'}}, {'title': {'value': 'Excellent contribution with a vast, information-rich histopathology dataset. However, concerns about copyright and data quality need addressing.'}, 'rating': {'value': '7: Good paper, accept'}, 'confidence': {'value': '3: The reviewer is fairly confident that the evaluation is correct'}, 'summary_and_contributions': {'value': ""The paper presents QUILT-1M, a large vision-language dataset for histopathology with a million image-text pairs. It's created using a blend of language models, algorithms, knowledge databases, and speech recognition. Using QUILT-1M, a fine-tuned CLIP model surpasses existing models in zero-shot, linear probing tasks, and cross-modal retrieval tasks for classifying various histopathology images. \n\n\n""}, 'strengths': {'value': '1. The paper addresses the scarcity of analogous data in the medical field, specifically in histopathology, which has halted comparable progress. The introduction of QUILT-1M can help overcome this limitation and enable researchers to develop better models for histopathology. The dataset can have significant implications for the field of histopathology, which can ultimately benefit patients by enabling better diagnosis and treatment.\n\n2. This paper provide a comprehensive pipeline about the data preprocessing and post-processing with the a mixture of models, including large language models, handcrafted algorithms, human knowledge databases, and automatic speech recognition, to curate the datase. This information is pretty helpful for the research community to create more open-sourced datasets in other domains.'}, 'opportunities_for_improvement': {'value': 'Further evaluation and comparison are necessary to determine the quality of the data in relation to other related datasets. Given the substantial scale of the data, examining each sample individually presents a challenge. However, an alternative could be to pre-train the same model on different datasets and evaluate their performance using identical testing data. In this paper, the authors exclusively demonstrate the results of models trained with their proposed Quilt dataset, without comparison to other datasets like ARCH and OpenPath.'}, 'limitations': {'value': ""While the authors did not sufficiently address the limitations, it's somewhat understandable given the limitations of existing tools in comprehending and interpreting medical terminology within the histopathology domain. Further data refinement could potentially benefit from the inclusion of expert human input.\n\nAdditionally, based on existing literature, training CLIP tends to require much larger datasets compared to other pretraining architectures. I would recommend exploring other self-supervised algorithms such as ViLT and BEiT. Pretraining these models from scratch with the proposed dataset could potentially yield superior results compared to simply fine-tuning the pretrained CLIP model.""}, 'correctness': {'value': 'No correctness issue.'}, 'clarity': {'value': 'Overall, the paper is well-written. However, the authors should provide further clarification on a couple of points:\n\n1. The relationship and differences between CLIP and QuiltNet need to be more explicitly defined. From the presented information, it appears that different encoders, such as VIT-B/32 and VIT-B/16 for image encoding and GPT-2 for text encoding, are used. If the architectures differ, it remains unclear how the authors were able to train QuiltNet by fine-tuning a pre-trained CLIP model.\n\n2. The concept of \'few-shot performance with linear probing\' requires additional explanation. Specifically, does \'shot\' refer to the sample-level or the class-level?\n\n3. In section 3.3, what is the definition of ""conditioned"" and ""unconditioned""?'}, 'relation_to_prior_work': {'value': 'Yes. Briefly speaking, the authors introduce QUILT-1M, the largest vision-language histopathology dataset with 1M image-text samples, far surpassing previous datasets. They acknowledge the difficulty in discerning histopathology-relevant portions in broader datasets like PMC-15M. This paper enhances the field by tackling the limitations of existing medical datasets, particularly in histopathology.'}, 'documentation': {'value': 'Authors provide a sufficient details on data collection and organization but do not mention the ethical and responsible use.'}, 'ethics': {'value': 'Considering the dataset is licensed by the MIT and it could be used by commercial medical institutions, the data quality remains questionable as the authors discussed in the section 3.3 and section 5. \n\nBesides, the copyright issue should be clarified because the data is collected from the YouTube.'}, 'flag_for_ethics_review': {'value': '1: Yes, there are significant ethics concerns'}, 'additional_feedback': {'value': 'N/A'}}, {'title': {'value': 'Review comments'}, 'rating': {'value': '10: Top 5% of accepted papers, seminal paper'}, 'confidence': {'value': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'summary_and_contributions': {'value': 'Extensive multimodal models have demonstrated considerable promise for various applications. Nonetheless, the absence of a high-quality image-text histopathology dataset has impeded the use of such large multimodal models in digital histopathology. To address this issue, this paper bridges the gap by introducing the QUILT-1M text-image dataset. Furthermore, the authors fine-tune the CLIP model using the QUILT-1M dataset, leading to histopathology-specific CLIP-Similar model called QUILTNET. The availability of both the dataset and the multi-modal model is expected to significantly enhance research in digital histopathology.'}, 'strengths': {'value': 'The paper is well written. The dataset generation process is well described, which ensures the quality of the dataset. Compared to prior histopathology text-image datasets, QUILT-1M contains more sample pairs. The limitation and potential social ethic issues are also discussed. I have no doubt that the QUILT-1M dataset and the multimodal model QUILTNET have significant contribution to digital histopathology.'}, 'opportunities_for_improvement': {'value': '1. It would be greatly appreciated if the authors could make the QUILT or QUILT-1M dataset accessible via Google Drive or other cloud platforms. Although the toolkits to regenerate the dataset are available, there might be numerous challenges to address during the reconstruction process, as outlined in the paper. These challenges could potentially result in a lower-quality dataset if regenerated.\n\n2. As the authors have pointed out, the QUILT-1M dataset exclusively comprises image-text pairs with English text, potentially introducing social biases during model training. I know it is difficult and challenging, but I do wish the dataset would expand and include more diverse data. '}, 'limitations': {'value': 'Yes, the authors discussed the limitations of the dataset due to the involvement of automation tools for data collection. In addition, the study is also aware of the social bias in data collection process.'}, 'correctness': {'value': 'Yes.'}, 'clarity': {'value': 'A very well written paper.'}, 'relation_to_prior_work': {'value': 'Yes. All of the quality and sample amount of QUILT-1M and the resulting QUILTNET model differentiate this study from previous works.'}, 'documentation': {'value': 'Yes, very detailed information on data collection.'}, 'ethics': {'value': 'I think there might be a minor ethics concern. But since the dataset is collected from Youtube and public domain, the tissue images may contain subject privacy information. So I flag this paper and leave it to ACs for a final decision.'}, 'flag_for_ethics_review': {'value': '1: Yes, there are significant ethics concerns'}, 'additional_feedback': {'value': 'I was a bit surprised to find the underperformance of QUILTNET on BACH and SICAPV2. Particularly, BACH is a widely used histopathology image classification dataset. But zero-shot using QUILTNET is 14% worse than BiomedClip. Is there any comments about this?'}}, {'title': {'value': 'Quilt-1M: One Million Image-Text Pairs for Histopathology'}, 'rating': {'value': '8: Top 50% of accepted papers, clear accept'}, 'confidence': {'value': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'summary_and_contributions': {'value': 'This work introduces a large-scale vision language dataset for histopathology consisting of 1 million image-text pairs curated from public sources including YouTube videos, Twitter, and research papers. To curate such a dataset, several automated processes are employed i.e., mixture of models, language models, handcrafted algorithms, and automatic speech recognition in order to collect more representative videos, filter narratives, and extract text efficiently. As opposed to existing vision language datasets for pathology, this work is more comprehensive in terms of collections and identifies potential biases herein, proving to be a truly large-scale dataset that can enable further research in multi-modal representation learning for histopathology. To validate the utility of the curated dataset, several text-based metrics are employed, along with a pre-trained CLIP model for downstream tasks i.e., zero-shot and linear probing across several datasets with diverse sub-pathologies.'}, 'strengths': {'value': '- The paper is well written and easy to follow and motivates the need for such a dataset in coherent manner.  \n\n- The authors target histopathology images, this is very relevant and timely. As opposed to many existing vision-language models in medical literature that focused on different modalities, the curation of this dataset tailored to pathology is truly a commendable effort. \n\n- The use of Youtube videos is novel and interesting.  The internet is considerably an unlimited source of information, and the designed curation procedure considers several aspects from filtering to modalities alignment after text-extraction from frames. \n\n- The authors extensively evaluated the curated dataset via downstream tasks after pre-training, achieving state of the art performance on several tasks i.e., zero/few-shot and cross modal retrieval.'}, 'opportunities_for_improvement': {'value': '[See Limitations]'}, 'limitations': {'value': '- It is unclear to what extent human experts verified the curated text-image pairs and the level of involvement i.e., how many expert pathologists confirmed the false positive rates.  \n\n- A CLIP model was pre-trained on the 1M dataset, did the authors evaluate the potential of the fine-tuned model on downstream tasks when trained with less data (<< 1M). This may be useful to assess the utility of this dataset in low-resource environments (hardware etc.).'}, 'correctness': {'value': 'The dataset is constructed in a structured and careful manner. The authors detailed each curation strategy.'}, 'clarity': {'value': '[Yes.]'}, 'relation_to_prior_work': {'value': 'The discussed works are sufficient.'}, 'documentation': {'value': '[Yes]. URLs and documentation are included for better understanding.'}, 'ethics': {'value': 'Public sources were employed for curation, and the research was not on human subjects.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': '[]'}}, {'title': {'value': 'Review of QUILT-1M, an image-text histopathology dataset curated from YouTube and other sources'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'The authors present QUILT-1M, a dataset of image-text pairs of histopathology images. Many of these images and textual descriptions are curated from YouTube as well as Twitter and other sources. This is a clever method to mine histopathology images with textual descriptions and follows a few recent papers [1, 2]. This dataset is rich, and the authors demonstrate this with assessments of zero-shot, full-shot, and linear probing. A major contribution of this dataset is its size -- the authors claim it is the largest dataset of its kind to date. To accomplish this scale, the authors used automated tools, like large language models, to aid in dataset creation.\n\nMy main concerns are of dataset findability and accessibility. The QUILT dataset (the subset of QUILT-1M sourced from YouTube) seems to not be available in its entirety. The authors have provided a CSV with URLs of YouTube videos used in QUILT and code to recreate the dataset (and in fact another user has experienced problems recreating this dataset: https://github.com/wisdomikezogwo/quilt1m/issues/7). In addition, I am not able to locate the full QUILT-1M dataset. The GitHub repository https://github.com/wisdomikezogwo/quilt1m appears to generate QUILT but not QUILT-1M. My concerns of dataset findability and accessibility are the main contributors to my score of 5. I am glad to improve this score if (1) the authors make the QUILT and QUILT-1M datasets fully available or (2) the authors provide a rationale for not releasing the final QUILT and QUILT-1M datasets. If the authors are not able to make the datasets available, I strongly suggest that they revise the manuscript to reflect the fact that users will have to re-generate the dataset in order to use it.\n\nReferences\n1. Huang, Z., Bianchi, F., Yuksekgonul, M., Montine, T., & Zou, J. (2023). Leveraging medical Twitter to build a visual–language foundation model for pathology AI. bioRxiv, 2023-03.\n2. Lu, M. Y., Chen, B., Zhang, A., Williamson, D. F., Chen, R. J., Ding, T., ... & Mahmood, F. (2023). Visual Language Pretrained Multiple Instance Zero-Shot Transfer for Histopathology Images. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 19764-19775).'}, 'strengths': {'value': 'Please find a list of strengths below:\n\n1. The authors were clever to mine YouTube for this dataset. This is indeed a large resource, and I myself have watched several histopathology videos on YouTube.\n2. The size of the QUILT dataset is a strength. The authors write that QUILT includes 419,780 images and 768,826 matched text pairs. \n3. QUILT includes multiple sentences per image, which allows multiple descriptions of images.\n4. The authors provide a detailed description of the method they used to create QUILT.\n5. The experimental results (Section 4) are comprehensive.\n6. Limitations and biases are discussed.\n7. The code to create the dataset and models are publicly available. Thank you for hosting your models on HuggingFace. I am not affiliated with HuggingFace but I appreciate that your model is available for reuse. Please see point 11 in the “opportunities for improvement” for a related suggestion about the dataset. A critical weakness is that the final dataset is not publicly available.\n8. The authors have created an effective website to describe the dataset.'}, 'opportunities_for_improvement': {'value': 'Please find a list of opportunities for improvement below:\n\n1. It appears to me that the QUILT and QUILT-1M datasets are not publicly available in their final form. What is the reason for this? This is a critical weakness in my opinion and is one of the main contributors to my score. (Please also see item 11 for suggestions of hosting the dataset.) If the dataset cannot be shared publicly, the authors should indicate this clearly in the manuscript and include steps that users must take to regenerate the dataset. This is particularly a concern for the subset of QUILT-1M curated from Twitter, because Twitter is no longer publicly viewable without an account and its API has been rate limited, making the re-creation of QUILT-1M much more difficult.\n2. In the manuscript, the authors do not provide the license under which they distribute QUILT and QUILT-1M. Please specify the applicable license.\n3. How are the authors certain that the narrators of the YouTube videos are “experts? The quality of the textual descriptions relies on the expertise of the narrator.\n4. I disagree with the authors’ statement on lines 62 and 63. Patch-based classification, region segmentation, nuclear segmentation, and other tasks have all been commonly done with machine learning for many years now. Weakly-supervised learning is just one of many methods in computational pathology.\n5. In lines 64 and 65, the authors claim that weakly-supervised models are “sub-optimal” and cite two papers. Neither of these references provides evidence for this claim. In fact, I would argue that the model proposed in reference 11 (the MCAT model) is far from “sub-optimal”.\n6. Please describe the scale of the histopathology images earlier on in the manuscript. This is described in lines 250-251 but I would argue that it is important to mention early on (perhaps somewhere in the introduction).\n7. Please identify which LLMs are used.\n8. Please specify the resolution of the resulting image dataset. What is the average height and width of the images?\n9. In line 261, please specify which pre-trained model was used. What was it pretrained on?\n10. Near line 226 (“Twitter Data from OpenPath”), please describe in more detail how your approach differs from that of OpenPath. The difference is not clear to me. A short description of the OpenPath dataset would likely address this concern.\n11. I urge the authors to host the dataset on another platform other than Google Drive, because programmatic download (e.g., from the command line or scripts) can be difficult from Google Drive. In fact, I have never succeeded in downloading a file from Google Drive programmatically, and for this reason, I suggest that the authors host QUILT and QUILT-1M on another platform. I highly recommend hosting the dataset on the HuggingFace Hub or on Zenodo. In both cases, a DOI can be created for the dataset which is useful in identifying the source of the data. This improves findability and reusability.\n12. The authors provide a CSV of the video IDs and text. This CSV contains 802,186 rows (not including the header). The authors write that QUILT contains 768,826 image-text pairs, and QUILT-1M contains around one million images. Where does the number 802,186 come from? Related to this, is this CSV enough to reconstruct QUILT-1M? Or is this only to construct QUILT? This is unclear to me.\n13. Related to 12 above, is the GitHub repository sufficient to recreate QUILT-1M? After reviewing the code, I believe it generates QUILT but not QUILT-1M. Is this correct? If so, how does one access QUILT-1M?'}, 'limitations': {'value': 'The authors adequately address limitations and social biases.'}, 'correctness': {'value': ""The vast majority of the claims made are correct. I have noted claims that I do not agree with (please see 'Opportunities for improvement').""}, 'clarity': {'value': 'The paper is well written.'}, 'relation_to_prior_work': {'value': 'The authors discuss how their work differs from previous work.'}, 'documentation': {'value': 'The authors provide sufficient detail on data collection and organization. However, the availability and maintenance are unclear to me. When I first read the manuscript, I was under the impression that the full (final) dataset was available. When I downloaded the CSV file however, it appeared that the download was intended to be used to re-create the dataset. It also seems that the CSV can only be used to recreate QUILT but not QUILT-1M. It is not clear whether QUILT-1M is shared publicly. If the authors are not able to share the final dataset, they should make this clear in the manuscript.\n\nRegarding maintenance, I suggest that the authors host their dataset on a platform that assigns a DOI, like Zenodo or HuggingFace. This will alleviate my concerns of persistence and findability.\n\nIn addition, the manuscript does not assign a license to the dataset. Can the authors please include this information in the manuscript?'}, 'ethics': {'value': 'I do not suspect any ethical concerns.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'Great work overall. I have a few minor comments:\n\n1. In line 3, the word “halted” is not precise. Research in this field has not been halted, though I would argue that research has not been at the same pace as in other fields. Please use a more precise phrase here.\n2. In line 5, I would argue YouTube is not an “untapped” resource, though I am not familiar with any research in histopathology that uses data from YouTube. Please use a more precise phrase here.\n3. In line 55-56, the authors write “... provide more expressive”. My question is, more expressive than what?\n4. In line 94, the word “untapped” seems inappropriate, because in the previous sentences, the authors write that several studies have used YouTube videos.\n5. In line 126, what is the resolution of the downloaded videos? The authors write “low-resolution”. Is a consistent resolution used? I wonder because the resolution of the downloaded videos presumably affects the resolution of the resulting images for QUILT.\n6. Were any of the final image-text pairs checked for quality by a human? Section 3.3 (Quality) does not contain an answer to this.'}}, {'title': {'value': 'Open-source multimodal dataset for Histopathology'}, 'rating': {'value': '8: Top 50% of accepted papers, clear accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'The main contribution of this work is a multimodal image-text dataset comprising one million histopathology image-text pairs. The dataset encompasses various sources, including the newly created QUILT dataset, image-text pairs from PubMed open access, histopathology images from the LAION dataset, and Twitter data from OpenPath. \n\nThe authors thoroughly describe the collection process and provide insights into the properties of the resulting dataset. Furthermore, they introduce QUILTNET, a modified version of the CLIP model, and fine-tune it on their dataset. Subsequently, they assess its performance on 12 downstream histopathology datasets. Lastly, the paper extensively discusses technical limitations, safety considerations, ethical aspects, and potential biases associated with the research. '}, 'strengths': {'value': '- The authors employed a novel approach to collect this dataset, integrating various state-of-the-art techniques. These include text extraction using ASR, text correction utilizing the LLM, and employing image classifiers to identify videos containing histopathology images.\n\n- The distribution of all the codes used in constructing this dataset represents a substantial engineering endeavor.\n\n- The release of this artifact holds significant importance for the research community. Recent scientific progress has underscored the value of comparable datasets containing numerous image and text pairs. However, existing sources of such datasets are often limited in size or not openly accessible (e.g., PMC-15M).\n\n'}, 'opportunities_for_improvement': {'value': '- In several parts of the papers, the authors state that QUILT and QUILT-1M do not overlap with existing data sources. My question is how did you check whether they overlap?\n- Can authors provide reasons why training from scratch underperformed a fine-tuned CLIP model? Can it relate to some noisy transcriptions of images?\n\n'}, 'limitations': {'value': ""- It would be interesting to see to what extent including different image-text sources such as LAION, Twitter, and PubMed can improve the accuracy of the proposed model. Could the authors conduct an ablation study to assess the impact of incorporating LAION, Twitter, and PubMed datasets on the QUILT dataset? This study would determine whether these additional sources are beneficial in enhancing the model's performance or if they potentially lead to a decrease in performance.""}, 'correctness': {'value': "" I don't have concerns about the correctness of the data collection process.""}, 'clarity': {'value': 'Yes'}, 'relation_to_prior_work': {'value': 'The authors have well discussed the relationship of their work with the previous contributions.'}, 'documentation': {'value': 'Yes'}, 'ethics': {'value': 'The authors have discussed this topic in the supplementary material (A.5).\n'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'Typo error on page 9, Discussion section: see A.6 in the Appendix (perhaps A.5). I didn’t find A.6 in the Appendix. \n\nTypo error on page 2: 13 external histopathology datasets (I assume it’s 12 as you mentioned in section 4)\n\nA question about dataset reproducibility:\n- Can I expect a 100 % reproducible dataset? I’m asking this because videos can be deleted by users in the future for any reason\n'}}, {'title': {'value': 'Quilt-1M: One Million Image-Text Pairs for Histopathology'}, 'authors': {'value': ['Wisdom Oluchi Ikezogwo', 'Mehmet Saygin Seyfioglu', 'Fatemeh Ghezloo', 'Dylan Stefan Chan Geva', 'Fatwir Sheikh Mohammed', 'Pavan Kumar Anand', 'Ranjay Krishna', 'Linda Shapiro']}, 'authorids': {'value': ['~Wisdom_Oluchi_Ikezogwo1', '~Mehmet_Saygin_Seyfioglu1', '~Fatemeh_Ghezloo1', '~Dylan_Stefan_Chan_Geva1', '~Fatwir_Sheikh_Mohammed1', '~Pavan_Kumar_Anand1', '~Ranjay_Krishna1', '~Linda_Shapiro1']}, 'keywords': {'value': ['Vision-Language', 'Dataset', 'Histopathology', 'Medical', 'Video', 'Image-Text']}, 'abstract': {'value': 'Recent accelerations in multi-modal applications have been made possible with the plethora of image and text data available online. However, the scarcity of analogous data in the medical field, specifically in histopathology, has slowed comparable progress. \nTo enable similar representation learning for histopathology, we turn to YouTube, an untapped resource of videos, offering $1,087$ hours of valuable educational histopathology videos from expert clinicians.\nFrom YouTube, we curate QUILT: a large-scale vision-language dataset consisting of $802, 144$ image and text pairs.\nQUILT was automatically curated using a mixture of models, including large language models, handcrafted algorithms, human knowledge databases, and automatic speech recognition.\nIn comparison, the most comprehensive datasets curated for histopathology amass only around $200$K samples.\nWe combine QUILT with datasets from other sources, including Twitter, research papers, and the internet in general, to create an even larger dataset: QUILT-1M, with $1$M paired image-text samples, marking it as the largest vision-language histopathology dataset to date. \nWe demonstrate the value of QUILT-1M by fine-tuning a pre-trained CLIP model. \nOur model outperforms state-of-the-art models on both zero-shot and linear probing tasks for classifying new histopathology images across $13$ diverse patch-level datasets of $8$ different sub-pathologies and cross-modal retrieval tasks.'}, 'venue': {'value': 'NeurIPS 2023 Datasets and Benchmarks Oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Track/Datasets_and_Benchmarks'}, 'pdf': {'value': '/pdf/850fb0a031f4db9d50a1189d91114aa7d4870128.pdf'}, 'supplementary_material': {'value': '/attachment/8a4074f8fc67cf55cf04c9aebe716ba8127ec264.pdf'}, '_bibtex': {'value': '@inproceedings{\nikezogwo2023quiltm,\ntitle={Quilt-1M: One Million Image-Text Pairs for Histopathology},\nauthor={Wisdom Oluchi Ikezogwo and Mehmet Saygin Seyfioglu and Fatemeh Ghezloo and Dylan Stefan Chan Geva and Fatwir Sheikh Mohammed and Pavan Kumar Anand and Ranjay Krishna and Linda Shapiro},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\nyear={2023},\nurl={https://openreview.net/forum?id=OL2JQoO0kq}\n}'}, 'paperhash': {'value': 'ikezogwo|quilt1m_one_million_imagetext_pairs_for_histopathology'}}]"
"['Yujia Zheng', 'Kun Zhang']",NeurIPS,Generalizing Nonlinear ICA Beyond Structural Sparsity,https://neurips.cc/virtual/2023/oral/73834,2023," Nonlinear independent component analysis (ICA) aims to uncover the true latent sources from their observable nonlinear mixtures. Despite its significance, the identifiability of nonlinear ICA is known to be impossible without additional assumptions. Recent advances have proposed conditions on the connective structure from sources to observed variables, known as Structural Sparsity, to achieve identifiability in an unsupervised manner. However, the sparsity constraint may not hold universally for all sources in practice. Furthermore, the assumptions of bijectivity of the mixing process and independence among all sources, which arise from the setting of ICA, may also be violated in many real-world scenarios. To address these limitations and generalize nonlinear ICA, we propose a set of new identifiability results in the general settings of undercompleteness, partial sparsity and source dependence, and flexible grouping structures. Specifically, we prove identifiability when there are more observed variables than sources (undercomplete), and when certain sparsity and/or source independence assumptions are not met for some changing sources. Moreover, we show that even in cases with flexible grouping structures (e.g., part of the sources can be divided into irreducible independent groups with various sizes), appropriate identifiability results can also be established. Theoretical claims are supported empirically on both synthetic and real-world datasets.",Oral 4A Optimization,https://openreview.net/pdf?id=gI1SOgW3kw,https://openreview.net/forum?id=gI1SOgW3kw,gI1SOgW3kw,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This article extends the previous work on nonlinear Independent Component Analysis (ICA) identifiability, which focused on structural sparsity assumptions. This paper builds on that by handling the undercomplete scenario and relaxing sparsity and source independence assumptions. The article includes theoretical advancements and practical examples to illustrate their identifiability theorems.\n\nOverall, the paper is intriguing, offering fresh insights into inducing identifiability in nonlinear ICA through sparsity. Theoretical advancements are well-presented, expanding the applicability of nonlinear ICA. The relaxation of assumptions is motivated logically, supported by experimental results. The paper is well-written and structured, effectively delineating prior work, contributions, and theoretical foundations.\n\nThe level of novelty and contribution to the community is deemed substantial.'}}, {'comment': {'value': 'We are very grateful for all of your constructive and insightful suggestions! We believe that the manuscript has been improved a lot with your help.'}}, {'comment': {'value': 'Thank you -- I appreciate your patience and efforts. I have revised my score.'}}, {'title': {'value': 'We sincerely appreciate your further feedback'}, 'comment': {'value': 'Thank you so much for your reply. Wrt. A13, in addition to the definition of “block-wise identifiability” before Thm. 4.1, in light of your suggestions, we have now also added the following text after L208 (directly following Thm. 4.1):\n\n> “We would like to highlight that **the block-wise identifiability of $\\mathbf{s}_D$ does not mean that sources in $\\mathbf{s}_D$ are element-wise identifiable** (i.e., identifiable up to an element-wise invertible transformation and a permutation). Instead, it only guarantees that sources in $\\mathbf{s}_D$ will not be mixed with sources outside of $\\mathbf{s}_D$ (e.g., $\\mathbf{s}_I$ in Eq. 3), which might be helpful in scenarios such as disentangling changing styles across images from different domains for the purpose of finding the block of style variables, but not necessarily each individual style variable.”\n\nWe hope that, by incorporating this, readers can get a clearer picture of the results. Thanks again for your constructive suggestion! We are looking forward to your kind feedback.'}}, {'comment': {'value': ""**With respect to A12:** Yes that's much better and helps to avoid confusion with the Zheng paper -- it also makes your contribution and its novelty much clearer!\n\n**Wrt. A13:** Yes I am aware of the term 'block-wise identifiable' and I do think this is better but I do find it bit weird when there is no mention of $S_I$. Would you consider perhaps adding explanation under the theorem just to explain what is meant by this block-wise identifiability and explain that it does *not* mean that $S_D$ are identified element-wise?\n\n**Wrt. A14+A15:** Thanks.""}}, {'title': {'value': 'Thanks so much for your further suggestions (2/2)'}, 'comment': {'value': '**Q15:** Comments on the breath of real-world experiments.\n\n**A15:** We fully agree with you that there are *millions of different possible inductive biases* for the true hidden generating process of real-world datasets. We also agree that, besides the visual disentanglement task, there are various other exciting applications that could potentially benefit from our theory and worth exploring (e.g., the brain\'s signals as you mentioned). The lack of more applications is indeed a limitation of our work (as highlighted in the conclusion, L396-397), and we are very grateful for your kind suggestions on what could be the next steps.\n\nAt the same time, since it is impossible to know the structure of the real-world unknown data-generating process, our theory can only be rigorously **validated** by ablation studies (via simulated data), which we have done as part of the experiments. The asymptotic guarantee has also been further validated by the experiments varying the sample size in the attached PDF in the global response. The experiments on the image datasets are indeed not very complicated, and we aim to use these results as potential, explainable,  illustrations of the application scenarios, complementing our validations of the theory. \n\nApologies if there is any potential confusion in our previous response regarding that. We do agree with you that there are more exciting real-world applications that could take this paper to the next level, and we are very grateful for your specific suggestions on them.\n\n---\n\nLast but not least, we genuinely appreciate the time and effort you dedicated to reviewing our manuscript. We greatly value this opportunity for clarification and are thankful for the chance you provided to further improve the presentation.\n\n---\n\n[1] Zheng et al. ""On the identifiability of nonlinear ICA: sparsity and beyond.""\n\n[2] Kong et al. “Partial identifiability of domain adaptation.”\n\n[3] Von Kügelgen et al. ""Self-supervised learning with data augmentations provably isolates content from style."" \n\n[4] Teshima et al. ""Coupling-based invertible neural networks are universal diffeomorphism approximators.""'}}, {'title': {'value': 'Thanks so much for your further suggestions (1/2)'}, 'comment': {'value': 'Thank you very much for your further comment. We respectfully believe that there exist some misunderstandings that could be addressed. We are very glad that you provide us the opportunity to further clarify and highlight them. In light of your suggestions, we have further incorporated changes in the updated version:\n\n**Q12:** The novelty compared to the result about undercompleteness in [1].\n\n**A12:** Thanks a lot for your suggestion, which let us realize again the necessity of clarification on that earlier in the introduction. We must emphasize that **[1] did not give any identifiability result on the undercomplete nonlinear ICA at all**. As discussed in (1) A2 in the response to reviewer jekt, (2) A9 in the response to reviewer qJ69, and (3) L159-160, [1] did not give an identifiability result but only provide a way to distinguish spurious solutions due to rotated-Gaussian MPA (Thm. 3 in [1]). Thus, identifiability with Structural Sparsity and undercompleteness was not established in [1].\n\nSince this misunderstanding can be clearly avoided by highlighting the difference between proving identifiability and distinguishing a specific spurious solution, we have added additional detailed discussions **earlier in the introduction and abstract** to avoid potential confusion, as mentioned in the responses to other reviewers. Specifically, the related sentences in the **introduction (after L81)** have been added as follows:\n\n> ”We would like to highlight that [1] provided guarantees to avoid the spurious solution of rotated-Gaussian MPA in the undercomplete case with structural sparsity. However, it is not an identifiabilty result since there exist numerous other spurious solutions in nonlinear ICA (see, e.g., the Darmois construction). Thus, the identifiability with undercompleteness and partial sparsity is still an open question, which is one of the motivations of our work.”\n\nFurthermore, we have added the following sentence in the **abstract (after L9)**:\n\n> ”Structural Sparisty has been introduced before to avoid the spurious solution of “rotated-Gaussian MPA” in the undercomplete case, but the identifiability has not been provided.”\n\nWe hope the updated text could clarify the potential confusion. Thanks again for highlighting the necessity of that. If you have other related concerns, please kindly let us know.\n\n\n**Q13:** The exact changes on Thms 4.1 and 4.3.\n\n**A13:** We sincerely appreciate your valuable suggestions on improving the presentation and your agreement on the implications of these theorems. Regarding the presentation, we have replaced the related sentences with *“$\\mathbf{s}_D$ is block-wise identifiable”*. We would like to note that the usage of the term “block-wise identifiable” originates from previous works on identifiably disentangling the changing style from images across domains (e.g., Thm. 4.2 in [2], Thm. 4.2 in [3]), which is similar to our definition of $\\mathbf{s}_D$ since its distribution does change across different values of $\\mathbf{u}$. We have also highlighted these works for specifying the reference of the definition.\n\n\n**Q14:** Include a short explanation of the universal approximation and GIN in the paper.\n\n**A14:** Thanks so much for the suggestion. It has been added, specifically after L345, as follows:\n\n> ”It is worth noting that,  according to [4], coupling-based flows (e.g., GIN) are universal diffeomorphism approximators. The volume-preserving nature of GIN does not hinder it from validating our theorems, as rescaling is one of the allowed indeterminacies after identification.”'}}, {'comment': {'value': 'I am not sure why but it did indeed look like you were missing from \'readers\'. I also couldnt edit it. So here I am re-sending it:\n\nI have now read all the reviews and rebuttals carefully. I feel like I have no choice but to reduce the rating by one point from \'4\' to \'3\' as it better reflects my current opinion of the paper. Overall the paper makes interesting theoretical contribution but the results are not as novel as the author claims, and a lot of them are to be expected as combinations of previous results (e..g sparsity and auxiliary variables combined). The experimental validation lacks breadth. Additionally the following are further problems that justify my new rating:\n\n- One of the other reviews made me realize that undercompleteness was already discussed in [1]. This result is not properly acknowledged in this paper at all. The \'introduction\' is written as if the authors are presenting the combination of undercompleteness and structural sparsity for the first time. For example, in the introduction you write: *""Unfortunately, Zheng et al. (2022) require Structural Sparsity to hold for all sources in order to provide any identifiability guarantee...[paragraph change] Besides partial sparsity, identifiability with Structural Sparsity also fails with the undercompleteness (more observed variables than sources) and/or partial source dependence (potential dependence among some hidden sources).""*. This makes it look like the structural sparsity in Zheng would fail in undercomplete case and does not at all acknowledge that they in fact *do* provide result for undercomplete case. This is not good, and the introduction **must** be changed to properly attribute for this. Currently you only make a comment on Zheng\'s work on undercompleteness at the end of section 3 (l. 158). To raise my score, I expect to see exact changes the author will implement. \n\n- **with regards to author\'s A2**: You write *""In Thm. 4.1, the identifiability of $S_d$ up to an invertible transformation means that it will not be mixed with sources in $S_I$ after estimation.""*. Yes I agree that your are identifiably disentangling $S_d$ and $S_I$ from each other however saying you \'identify $S_d$ up to invertible transformation\' is non-sensical in that that the $\\hat{S}_d$ that you estimate have no guarantee of being related in any reasonable way to the ground-truth $S_d$ (so completely unidentified). Further, you don\'t even say anything about $S_I$ in Thm. 4.1. But merely: ""Then $s_D$ is identifiable up to an invertible transformation."". I expect to hear of the exact changes you would make to Thms 4.1 - 4.3 so that the reader gets a better picture of what these theorems *really* mean.\n\n- **wrt. A3:** You should include a short explanation of this in the paper (the part about universal approximation and GIN), if it\'s not already there.\n\n- **wrt. A4:** If I understand correctly, you essentially claim here that you don\'t need more experiments because previous literature has shown identifiability in all kinds of situations and you provide explanation of that. I think you are being far too generous to yourselves here. There are million different possible inductive biases that could potentially explain these observations (ofc. including your work too) but it is not good enough reason in my opinion for the lacking empirical side. \n\nI am happy to revise my score if these issues have good resolution. \n\n***\n[1] Zheng et al. (2022), ""On the Identifiability of Nonlinear ICA: Sparsity and Beyond""'}}, {'comment': {'value': ""Thanks for your reply. We didn't find any feedback from you except the score change. Would you mind kindly checking if we are the readers of that comment?""}}, {'comment': {'value': 'I am confused -- can you not see my comment to your rebuttal I made above?'}}, {'comment': {'value': 'We have been eagerly looking forward to your feedback on our detailed response.  However, without seeing your feedback, we noticed that the rating by you was changed from 4 (Borderline reject) to 3 (Reject).  We therefore are wondering whether it was intended to be changed this way or just a mistake.  If you have any further questions or concerns, please kindly let us know.  Your feedback will be appreciated.'}, 'title': {'value': 'Mistake in updating the rating?'}}, {'comment': {'value': 'Sorry for the repeated reminders. As the discussion will end in **48 hours**, would you mind kindly checking if you have any further questions? For instance, we have clarified the **implication of Thms. 4.1 and 4.3**, and you have mentioned in the second point of weakness that\n\n> ""if I have understood correctly -- please correct me if I\'m wrong and I\'ll adjust my score accordingly""\n\nAs all reviewers noted, our results are important to the community in a timely manner. Thus, we would like to try our best to address any potential confusion given the opportunity for discussion.'}}, {'comment': {'value': 'Thanks so much for your effort! We are very grateful for your encouragement.'}}, {'title': {'value': 'Reviewer response to rebuttal'}, 'comment': {'value': ""Thanks to the authors for the thorough response to my comments and for including the additional plot in the one-page pdf. You've addressed all the questions and suggestions for improvements in my review. I will keep my score of 8.""}}, {'comment': {'value': 'Thanks a lot for your encouragement. We are very grateful for all of your insightful suggestions.'}}, {'comment': {'value': '\nI have read your response.  Thank you for preparing it.  It has clarified the meaning of certain passages in the paper.  Maybe it would be an even better paper if the theory could tell you whether to use a certain identifiability approach given a particular set of empirical data, rather than having to perform ablation studies, but the current paper as it is does break new ground.'}}, {'comment': {'value': 'Thanks so much for your further feedback.'}}, {'comment': {'value': 'Thank you once more for your time and suggestions. Since the discussion window narrows, might we kindly ask if our clarification has resolved the potential confusion, especially in **Q2 & A2**? Your further feedback is deeply appreciated.'}}, {'comment': {'value': 'I would like to thank the authors for their clarifications.'}}, {'rebuttal': {'value': ""We extend our sincere thanks to each of the reviewers for their thoughtful insights and the time devoted to reviewing our manuscript. We are encouraged that all of the reviewers have found our paper of good quality in various ways. With appreciation, we have provided detailed, point-by-point responses to each reviewer's comments in the individual replies. In this global response, we take the opportunity to present additional experimental results, which have been summarized in the attached PDF. Specifically, the quality of the identification improves w.r.t. the increasing of the sample size.""}, 'pdf': {'value': '/pdf/77deb388a81995cfb13cad178502c703e4cf73d3.pdf'}}, {'rebuttal': {'value': 'We sincerely appreciate your detailed reading and insightful questions. All of these constructive suggestions have further improved the quality of the updated manuscript. Please find our point-by-point response below.\n\n**Q1:** Implementation availability.\n\n**A1:** Thanks for finding our work interesting. We are more than happy to make the scripts publicly available soon. For quick utilization, kindly note that all experiments are conducted using public GitHub repositories (FrEIA and GIN), detailed in Section B.1. Please feel free to let us know if you have any questions about the experiments.\n\n**Q2:** Clarification on some notations.\n\n**A2:** We are very grateful for your detailed reading, which helps improve our manuscript\'s clarity. We have emphasized all these points in the updated manuscripts:\n\n- **Q2(a):** Is $|\\mathcal{F}|$ the $\\ell_0$ or $\\ell_1$ norm of $\\mathcal{F}$?\n\n- **A2(a):** It is the $\\ell_0$ norm of $\\mathcal{F}$.\n\n- **Q2(b):** Is $\\mathcal{C}_{k}$ a minimal set of sample indices to uniquely identify source $k$?\n\n- **A2(b):** We do not necessitate the set $\\mathcal{C}\\_{k}$ to be minimal, only that it uniquely identifies $k$. Of course, it is equivalent to consider $\\mathcal{C\\}_{k}$ as a minimal set.\n\n- **Q2(c):** What are $\\mathbf{u}\\_1$ and $\\mathbf{u}\\_2$?\n\n- **A2(c):** These are two distinct values of the auxiliary variable $\\mathbf{u}$.  \n\n**Q3:** More experiment configurations.\n\n**A3:** Thanks for your suggestion. In light of it, we have conducted additional experiments with different sample sizes, of which the results are shown in the attached PDF in the global response. From the results, it is clear that increasing the sample size could improve MCCs and further stabilize the performance.\n\n**Q4:** Statistical tests to compare results between proposed methods and baseline methods.\n\n**A4:** Thanks a lot for the suggestion. Accordingly, we have conducted statistical tests on all comparisons, and all p-values are less than $0.01$, which are consistent with the visual differences in the violin graphs. We have emphasized this in the updated manuscript.\n\n**Q5:** Word ""exits"" should be ""exists"" at L236.\n\n**A5:** Thanks! It has been corrected.\n\n**Q6:** How does assumption ii of Thm. 3.1 show Structural Sparsity?\n\n**A6:** We are grateful for that insightful question. If the connective structure between sources and observed variables is extremely dense (e.g., no zero entry in the Jacobian matrix), assumption ii cannot be satisfied, emphasizing its role in promoting structural sparsity. However, it is worth noting that, after extending from the bijective setting in [1], where the assumption of Structural Sparsity is originally proposed, to the undercomplete case in our manuscript, this assumption can be met even with a relatively dense structure, provided there are enough observed variables and the underlying graph is not fully connected. Thus, it leans more toward a ""structural diversity"" assumption in our generalization, and the name “Structural Sparsity” is chosen primarily to acknowledge its root and maintain continuity with its original name.\n\n**Q7:** Better include the regularization constraint during estimation in theorems.\n\n**A7:** Thank you for the suggestion. We have now incorporated it into all related theorems to avoid potential misunderstanding. Initially, we had just emphasized it following the theorem since it was not an assumption about the data-generating process, but including it directly in the theorem indeed improves the clarity.\n\n**Q8:** Better explanation of theorems and some notations (e.g., using plain words) so that readers can understand them more easily.\n\n**A8:** Thanks a lot for the kind suggestion. We have added descriptions in plain words of all theorems in the updated manuscripts. For example, Thm. 3.1 states that with sufficient sample size and structural sparsity (detailed later) on the connective structure between sources and observed variables, component-wise identifiability can be achieved even under undercomplete cases with sparsity regularization. We have also highlighted some notations used in the theorems. For instance, $\\mathcal{C}_{k}$ in the assumption of Structural Sparsity denotes a set of source indices.\n\n**Q9:** Could you clarify the novelty between your proposed theorem and that proposed in [1] about the undercomplete case?\n\n**A9:** We appreciate the great question. As mentioned in L159-160, [1] only removes the rotational indeterminacy while our theorem removes all major indeterminacies and only preserves the component-wise transformation and permutation. In other words, [1] only gets rid of specific spurious solutions due to the rotational indeterminacy (e.g., the ‘rotated-Gaussian’ MPA) while we prove the full identifiability of the undercomplete case.\n\n**Q10:** How do Thms. 4.1 and 4.2 uncover the dependence structures and the number of dependent sources?\n\n**A10:** Thanks for your insightful question. For the set of dependent sources, i.e., $\\mathbf{s}\\_D$, Thms. 4.1 and 4.2 only provide the subspace-wise identifiabliity up to an invertible transformation, and thus not being able to uncover the structures and the number of dependent sources. The identifiability of $\\mathbf{s}\\_D$ up to an invertible transformation means that $\\mathbf{s}\\_D$ will not be mixed with sources in $\\mathbf{s}\\_I$ after estimation, i.e., the block-wise identifiability (e.g., Thm 4.2 in [2]), which does not mean the component-wise identifiability of sources in $\\mathbf{s}\\_D$.\n\n**Q11:** How to identify linkages across multiple modalities.\n\n**A11:** Thank you for the great question. Since we stil assume the (conditional) independence between different subspaces $\\mathbf{s}\\_{c\\_j}$ (Eq. 4), we do not allow dependencies across subspaces and thus cannot identify linkages across multiple modalities.\n\n---\n\n\n\n[1] Zheng et al. ""On the identifiability of nonlinear ICA: sparsity and beyond.""\n\n[2] Kong et al. “Partial identifiability of domain adaptation.”\n'}}, {'rebuttal': {'value': 'We appreciate the reviewer for the time dedicated and constructive feedback, which has greatly improved the quality of the updated manuscript. Please find the responses to all your comments below.\n\n**Q1:** More discussion on the assumption (i) in Thm. 3.1.\n\n**A1:** Thanks so much for the suggestion. The assumption (i) does not necessitate a particular $\\hat{\\mathcal{F}}$, and it is typically satisfied asymptotically as detailed in L129-136 (it only necessitates the **existence** of one $\\mathrm{T}$ in the entire space). Except for the required sparsity regularization (L125-128), there are no specific functional classes to constrain $\\hat{\\mathcal{F}}$ during estimation. We have further highlighted it in the updated manuscript.\n\n**Q2:** L97: Traditional or linear ICA does not necessarily require m=n.\n\n**A2:** Thanks a lot. We have modified it to: “Different from settings where m=n …”\n\n**Q3:** L114: Should $\\mathcal{S}$ be $\\mathcal{A}$?\n\n**A3:** Yes, you are totally right. We have corrected the typo in the updated manuscript. \n\n**Q4:** L111 vs L536: $\\mathcal{T}$ has two differing definitions.\n\n**A4:** Thanks for rasing this point. We have corrected the denotation of $\\mathcal{T}$ in L536 to a set of matrices with the same support of $\\mathbf{T}(\\mathbf{s})$, and correspondingly, $\\mathrm{T} \\in  \\mathcal{T}$ in the following sentence.\n\n**Q5:** Thm. 4.1: the linearly independent vectors \'$w$\'  have not been sufficiently motivated.\n\n**A5:** Thanks for the suggestion. The linear independence of $w$ requires that the conditional distribution varies sufficiently across different values of $\\mathbf{u}$ (L229-230). The motivation of it is similar to the common assumption of variability used in [1, 2, 3]. Even though the assumption of variability is almost surely fulfilled as discussed in [1, 2, 3], our assumption is still strictly weaker from various perspectives as detailed in L229-241. For example, our definition of $w$ is only the first half of Eq. 8 in [1] and we require much fewer distinct values of $\\mathbf{u}$. We have further highlighted it in the updated manuscript.\n\n**Q6:** L190: The meaning of ""changing"" sources.\n\n**A6:** Thanks for the question. The ""changing"" sources ($\\mathbf{s}\\_D$) mean that the distribution of these sources changes across different values of the auxiliary variable $\\mathbf{u}$. For instance, styles of images change across domains while their content stays invariant.\n\n**Q7:** L195-196: More clarification on ""For sources $\\mathbf{s}\\_D$, they do not need to be mutually independent as long as they are dependent on the variable $\\mathbf{u}$"".\n\n**A7:** Thank you for your suggestion. It means that sources in $\\mathbf{s}\\_D$ (i.e., those with indices $\\\\{n\\_{I+1},\\cdots,n\\\\}$) do not need to be (mutually) conditionally independent given the auxiliary variable $\\mathbf{u}$; they only need to be influenced by (dependent on) $\\mathbf{u}$. The variable $\\mathbf{u}$ only provides changes on the distributions of these sources, like a domain label or time index.\n\n**Q8:** How does Thm. 4.1’s contribution compare with those from [2, 3]?\n\n**A8:** Thanks for raising this. We only require sources in $\\mathbf{s}\\_D$\u200b to depend on an auxiliary variable $\\mathbf{u}$ with $n\\_D\u200b+1$ values, intuitively fitting scenarios where fewer changes (smaller $n\\_D$) correspond to easier identifiability (fewer required values, i.e., $n\\_D+1$). In contrast, prior works like [2, 3] assume all sources to depend on $\\mathbf{u}$ with $nk+1$ values ($k$ denotes the order of the distribution), limiting identifiability to ideal situations without any degree of violations on either the number of sources dependent on $\\mathbf{u}$ or the number of values of $\\mathbf{u}$. This can restrict practical application, as often only subsets of sources are influenced by auxiliary variables, or those variables lack sufficient variability. Of course, as a trade-off, Thm. 4.1 itself does not provide component-wise identifiability. More details can be found in L224-247.\n\n**Q9:** L215-217: More explanation on the motivation and some notations ($\\mathbf{s}\\_d$ and $B\\_{\\mathbf{s}\\_I}$) of condition (i) in Thm. 4.2.\n\n**A9:** We appreciate these insightful questions and suggestions. Condition (i) in Thm. 4.2 originates from [4], which intuitively means there exist two values of the auxiliary variable such that their influences on the sources are different. $\\mathbf{s}_d$ is a typo and should be $\\mathbf{s}\\_D$, which denotes sources that dependent on $\\mathbf{u}$ (sorry for the confusion). $B\\_{\\mathbf{s}\\_I}$ is a subspace of $\\mathcal{S}\\_I$. In light of your suggestions, we have moved the discussion (L229-L247) to the paragraph directly following Thm. 4.2 and further emphasized these notations.\n\n**Q10:** More explanation on Figs. 4 and 5.\n\n**A10:** For these images (triangles in Fig. 4 and hand-written digits in Fig. 5), we assume that they are generated by hidden sources (e.g., angle, height, etc.), and try to recover these from their observed mixtures (i.e., images). Each row represents a source we identified, and we vary its value with the rightmost column showing a heatmap of the absolute pixel difference to visualize its influence. We interpret the estimated sources’ potential semantics from their influences, as listed in the captions. We only deal with single classes (e.g., zero in EMNIST), without auxiliary variables (e.g., digit labels). Thus, prior identifiability theories relying on auxiliary variables cannot support these seemingly reasonable results, but our generalized theorems could probably underpin them.\n \n\n---\n\n\n\n[1] Hyvarinen et al. ""Nonlinear ICA using auxiliary variables and generalized contrastive learning.""\n\n[2] Khemakhem et al. ""Variational autoencoders and nonlinear ica: A unifying framework.""\n\n[3] Sorrenson et al. ""Disentanglement by nonlinear ica with general incompressible-flow networks (gin).""\n\n[4] Kong et al. “Partial identifiability of domain adaptation.""\n'}}, {'rebuttal': {'value': 'Thanks so much for your time and insightful comments. We are glad that you find our results important and the paper of good quality. Please find our point-by-point response below.\n\n**Q1:** Limited coverage of some works.\n\n**A1:** Thanks for the suggestions. We have now detailed the discussion in the introduction. Specifically, in [1], there are assumptions on both source distribution and mixing functions: (1) the sources are assumed to be a Gaussian mixture, with an unobserved state $\\mathbf{u}$ (L158-161); (2) the mixing function is assumed to be piece-wise affine. These allow identifiability of sources up to an affine transformation where mixtures remain, with more assumptions needed (e.g., conditional independence given $\\mathbf{u}$) for component-wise identifiability.\n\nThus, we differ by (1) having no distributional assumptions, and (2) allowing general nonlinear functions if the assumption on connective structures is met. We do not claim that our assumption on the mixing functions is better than those in [1]. Structural sparsity allows general nonlinearity with sparse connections, while piece-wise affine functions allow dense structures.\n\nIn addition, we fully agree that [2] should be further emphasized for its highly significant contributions. We have highlighted its generalization to arbitrary dependency order (e.g., spatial dependencies) without assuming conditional independence. Meanwhile, additional information (e.g., time or spatial index) may not always be available, which is one of the motivations of our work.\n\n**Q2:** Implication of Thms. 4.1 and 4.3.\n\n**A2:** Thanks for the question. We have added more descriptions to clarify this. In Thm. 4.1, the identifiability of $\\mathbf{s}\\_D$ up to an invertible transformation means that $\\mathbf{s}\\_D$ will not be mixed with sources in $\\mathbf{s}\\_I$ after estimation. In practice, it implies that the **subspace** of the changing part (the distribution of $\\mathbf{s}\\_D$ changes w.r.t. $\\mathbf{u}$) can be disentangled from the mixture of both changing and invariant parts ($\\mathbf{s}$), which aids tasks like domain adaptation, e.g., the changing style (as a whole) can be disentangled from different images with invariant content. Similarly, in Thm. 4.3, the subspace-wise identifiability means sources in $\\mathbf{s}\\_{c\\_i}$ will not be mixed with sources outside $\\mathbf{s}\\_{c\\_i}$, which disentangles $\\mathbf{s}\\_{c\\_i}$ as an individual high-dimensional component.\n\n**Q3:** Novelty appears limited to theorems, and whether sparsity penalty and GIN are just heuristics.\n\n**A3:** According to our theory, the additional sparsity penalty on the MLE objective during estimation (L339-341), together with assumptions on the data-generating process, is needed to guarantee the correct identification (L125-128). Moreover, according to [3], coupling-based flows (e.g., GIN) are universal diffeomorphism approximators. The volume-preserving nature of GIN does not hinder it from validating our theorems, as rescaling is one of the allowed indeterminacies after identification. Of course, there exists some approximation of $\\ell_0$ norm for gradient-based optimization (MCP penalty), and more work could be done for further improvement.\n\n**Q4:** Experiments on more tasks.\n\n**A4:** Indeed, there are various tasks that benefit from our theory, and more applications would be intriguing. Meanwhile, we have emphasized in introduction (L88-89) and experiment (L329-334) with additional citations (>9) that prior research shows latent variable models are likely identifiable in complex scenarios, possibly involving undercompleteness and violations of sparsity and independence. Our theory may interpret these empirical results, and our ablation studies and experiments on both the synthetic and real-world datasets provide further validations, complementing previous works.\n\n**Q5:** Discuss structural sparsity and failure cases more.\n\n**A5:** Thanks, we have added more discussion on it. For failure, one may consider recording in a very crowded room, where every microphone records the mixture of signals from most sources at the same time.\n\n**Q6:** Is it necessary to know which latent variables are independent/dependent?\n\n**A6:** No. In practice, each data point can be assigned a class corresponding to the value of the auxiliary variable of dependent variables (L335-337). These labels do not provide extra information for independent variables since they do not need auxiliary variables.\n\n**Q7:** How to reduce dimensions and compute the Jacobian for non-bijective transformations?\n\n**A7:** As in prior works (e.g., [4]) and noted in L346-347, we concatenate latent sources with independent Gaussian noises for flow-based estimation\'s dimensionality needs and Jacobian computation.\n \n**Q8:** Level of nonlinearity, e.g., number of layers.\n\n**A8:** 10 layers (L881).\n\n**Q9:** What does \'specific algebraic form\' mean?\n\n**A9:** Great question. We meant to refer to ""specific"" function classes like conformal mappings mentioned above but have clarified this by changing the term to \'the above-mentioned classes\' to avoid confusion.\n\n**Q10:** Explain: ""The most … are heavily disentangled.""\n\n**A10:** Apologies for the typo. It should be ""heavily **entangled**"", like a crowded room where sources heavily influence each other, resulting in a dense Jacobian.\n\n**Q11:** More suggested updates:\n\n- (1) relocate a reference;\n\n- (2) specify undercompleteness claim to sparsity;\n\n- (3) a new title;\n\n- (4) cite an earlier ISA work;\n\n- (5) further highlight a limitation of Thm. 4.4.\n\n**A11:** We are grateful for all the constructive suggestions. All points have been updated accordingly.\n \n\n---\n\n[1] Kivva et al. ""Identifiability …""\n\n[2] Hälvä et al. ""Disentangling …""\n\n[3] Teshima et al. ""Coupling-based invertible neural networks are universal diffeomorphism approximators.""\n\n[4] Sorrenson et al. ""Disentanglement by nonlinear ICA with general incompressible-flow networks (gin).""\n'}}, {'rebuttal': {'value': 'We are very grateful for your detailed reading and insightful suggestions. Your comments on the quality of our paper and the strength of our contributions mean a lot to us. Please kindly find our point-by-point response below.\n\n**Q1:** There are many other interesting real-world tasks that would be interesting to see in future work.\n\n**A1:** Thanks a lot for your great suggestions. Indeed, there are various tasks that could benefit from our theory, and, as you suggested, more applications would be intriguing. We have shown some positive results on the visual tasks, and perhaps natural language is also a promising field. At the same time, various empirical research have shown that latent variables are likely identifiable in complex scenarios, possibly involving undercompleteness and violations of sparsity and independence (L88-89, L329-334). Complementing previous works, our theory may interpret these empirical results, and our ablation studies and experiments on both the synthetic and real-world datasets provide further validations. Of course, validating our theory in even more tasks is exciting and will be constantly done in future works.\n\nIn addition, we have also included new experimental results in the PDF attached to the global response. These results demonstrate that the quality of identification can be enhanced by increasing the sample size, further validating our theorems.\n\n**Q2:** L84-85: “Irreducible subgroup” is a term in algebra with a specific meaning. You could avoid this “collision” by saying “irreducible independent subgroupings” or something similar.\n\n**A2:** Thank you so much for the constructive suggestion. We have replaced “subgroup” with “subgrouping” in the updated manuscript.\n\n**Q3:** L156: “Differently, …” could be replaced with “In contrast, …”\n\n**A3:** Thanks. We have updated it accordingly.\n\n**Q4:** L167: “While this removes the restriction of bijectivity between sources and observed variables, it remains uncertain as to whether Structural Sparsity holds in general, particularly for all sources in a universal way.” This sentence is confusing.\n\n**A4:** Thanks for the insightful question. In this sentence, we are trying to motivate the importance of dealing with potential partial violations of Structural Sparsity among a subset of sources. In light of your suggestion, we have revised it to “... it remains uncertain as to whether Structural Sparsity always holds for all sources in a universal way”. We hope it could help to avoid potential confusion.\n\n**Q5:** L177: It is weird to start this sentence with “Differently”.\n\n**A5:** Yes, we fully agree with you. We have removed this in the updated manuscript.\n\n**Q6:** A handful of sentences are started with “Besides, ..”, which could be replaced with more appropriate words.\n\n**A6:** We are very grateful for the great suggestion. We have carefully modified the related connecting words in the updated manuscript as follows:\n\n- **L37:** Replaced “Besides” with “Moreover”.\n\n- **L64:** Replaced “Besides” with “In addition to”.\n\n- **L100:** Replaced “Besides” with “Furthermore”.\n\n- **L110:** Replaced “Besides” with “Additionally”.\n\n- **L212:** Replaced “Besides” with “Furthermore”.\n\n- **L278:** Replaced “besides” with “in addition to”.\n\nWe hope these modifications could improve the transition between related sentences. Thanks again!\n\n**Q7:** Discuss [1] in the introduction and cite [2] as prior work.\n\n**A7:** Thanks so much for sharing these excellent works. In the updated manuscript, we have highlighted in the introduction that [1] introduced the idea of proving identifiability with sparsity, which then inspired [3]. Moreover, we have emphasized in both the introduction and theory that [2] also uses sparsity for partial identifiability.\n\n---\n\n\n[1] Sébastien, et al. ""Disentanglement via mechanism sparsity regularization: A new principle for nonlinear ICA.""\n\n[2] Lachapelle, Sébastien, and Simon Lacoste-Julien. ""Partial disentanglement via mechanism sparsity.""\n\n[3] Zheng et al. ""On the identifiability of nonlinear ICA: sparsity and beyond.""\n'}}, {'rebuttal': {'value': 'We sincerely thank the reviewer’s time on carefully reading our manuscript and providing insightful suggestions. These have undoubtedly further improved the manuscript. Please kindly find our detailed, point-by-point response below.\n\n**Q1:** Suggestions on expanding empirical comparisons.\n\n**A1:** We are very grateful for these constructive suggestions. It is worth noting that, instead of proposing a better model to disentangle the sources, we focus on providing a theoretical guarantee for uncovering generating processes under certain conditions. Our result could be one of the lacking interpretations of many previous empirical studies showing that latent variable models are likely identifiable in complex scenarios, as mentioned in L88-89 and L329-344. The various extensions proposed for nonlinear ICA focus on the assumptions regarding the ground-truth data-generating process, rather than the estimation methods. Therefore, they can only be rigorously validated through ablation studies conducted on different data-generating processes. Complementing various previous empirical studies, we believe that our ablation studies and experiments on both the synthetic and real-world datasets provide further validations.\n\nIn addition, we have also included new experimental results in the PDF attached to the global response. These results demonstrate that the quality of identification can be enhanced by increasing the sample size, further validating our theorems.\n\n**Q2:** Clarify the theorem proposed in [1] about the undercomplete case.\n\n**A2:** We appreciate the great suggestion. As mentioned in L159-160, [1] only removes the rotational indeterminacy while our theorem removes all major indeterminacies and only preserves the component-wise transformation and permutation. In other words, [1] only gets rid of specific spurious solutions due to the rotational indeterminacy (e.g., the ‘rotated-Gaussian’ MPA) while we prove the full identifiability of the undercomplete case. We have added additional detailed discussion earlier in the introduction to avoid potential confusion.\n\n**Q3:** Notations:\n\n- **(1):** It was a bit confusing that on L113, $\\mathcal{A}$ is defined as a set of natural number tuples but on L103 $\\mathcal{A}$ is defined as a subset of natural numbers;\n\n- **(2):** there is a typo on L114, i.e., $\\mathcal{S}$ should be $\\mathcal{A}$.\n\n**A3:** Thank you so much for reminding us, and sorry for any potential confusion. We have modified L113-114 as: “For any set of indices $\\mathcal{B} \\subset \\\\{1, \\ldots, m\\\\} \\times \\\\{1, \\ldots, n\\\\}$, analogously, we have $\\mathcal{B}\\_{i,:}\\coloneqq\\\\{j \\mid(i, j) \\in \\mathcal{B}\\\\}$ and $\\mathcal{B}_{:,j}\\coloneqq\\\\{i \\mid(i, j) \\in \\mathcal{B}\\\\}$."" This modification also corrects the typo. Thanks again!\n\n\n---\n\n\n\n[1] Zheng et al. ""On the identifiability of nonlinear ICA: sparsity and beyond.""\n'}}, {'summary': {'value': ""\nThe paper introduces more flexible ways to perform nonlinear independent component analysis (nonlinear ICA).  Nonlinear ICA involves identifying the sources s from the observed x when both s and x are related by x = f(s) and f is a nonlinear function.  Previous work has developed a method for this problem under a strict structural sparsity assumption that the s's and x's are one-to-one and onto, and all the s's are independent of each other.  Current work provides theorems that relax the assumption in various ways including: (1) undercompletness--there can be more observed variables x than sources s; (2) partial sparsity--only a subset of all the s's may map to x's; (3) source dependence--all sources s do not have to be statistically dependent on each other; and (4) flexible grouping structures--the possibility that some of the sources can be partitioned into independent subgroups of sources.  There are experiments on synthetic and real world datasets that show the effectivness of their approach.\n\n\n""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '\nThis paper is original because it introduces novel approaches, as far as I know, that extend the situations where nonlinear ICA can be applied.\n\nThe paper exhibits good quality in various ways.  First, there are various theoretical results included in the paper that extend the cases where nonlinear ICA can be applied.  Second, there are also results in several experimental settings that back up the theory.\n\nThe paper is mostly clear in its explanations.\n\nIn terms of significance, extending the situations where nonlinear ICA can be applied is an accomplishment.\n'}, 'weaknesses': {'value': ""While in theory extending the cases where nonlinear ICA can be applied is a strength, because there wasn't any empirical qualitative evaluation of how this approach compares to other approaches in disentangling the sources, it is not clear how significant this work is.  It does not have to be a comparison of how well it disentangles sources; it could be comparing them on some other application, such as how well they extract features that are useful for classification, for example.  It does not even have to be comparing this paper's approach to previous approaches; it could be comparing the different extensions of nonlinear ICA presented in this paper.\n\nAlso, as pointed out by the authors, another limitation of this work is that the experimental results were only on visual datasets but not on other modalities.\n""}, 'questions': {'value': 'While the undercompleteness result appears to me to be unique to this paper, (Zheng et al 2022) also has an undercompletness result.  This paper is written so that it sounds like (Zheng et al 2022) has no undercompletness result.  It would be nice if this situation could be explained or clarified.\n\nIt was a bit confusing that on line 113, A is defined as a set of natural number tuples but on line 103 A is defined as a subset of natural numbers.\n\nI think on line 114 that A_{:,j} := { i | (i,j) \\in S } should really be A_{:,j} := { i | (i,j) \\in A }.\n'}, 'limitations': {'value': 'Yes.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper extends a recent result from Zheng et al 2022, which introduces an assumption they call “structural sparsity” to induce identifiability in nonlinear ICA without relying on a common (but arguably unrealistic) assumption that the observed variables are conditionally independent given observed auxiliary information. Whereas Zheng et al 2022 gave identifiability results only in the setting where the structural sparsity assumption holds perfectly and there are an equal number of sources and observed variables, this paper relaxes these assumptions in several interesting ways and gives identifiability or partial identifiability results in these more general settings.\n\nThe first theoretical contribution shows identifiability under structural sparsity in the undercomplete setting, where there are more observed variables than sources. This lets them relax the usual assumption that the mixing function must be bijective, and instead only requires that the mixing function be injective.\n\nThe second theoretical contribution relaxes the structural sparsity assumption to the setting where you have partial structural sparsity (it holds for a subset of sources) or partial independence of sources and shows partial identifiability under these assumptions. Here the partial dependence of sources does not need to be known.\n\nThe third theoretical contribution assumes that the dependence between sources is known, and the fourth theoretical contribution assumes the sources with dependencies are conditionally independent given auxiliary variables (which is distinct from existing work because they don’t assume all sources are influenced by the auxiliary variable, just the dependent sources).\n\nThey use an estimation method using a sparsity regularizer (that encourages a sparse estimated mixing function) with a flow-based generative model. They perform experiments on two simple visual datasets (Triangles and EMNIST) and perform ablations where they generate data that satisfy two combinations of assumptions for their theory, compared to a base setting that does not satisfy their assumptions. Following existing work, they use MCC as their metric and their models achieve higher MCC when the assumptions are satisfied.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- Overall, this is a very interesting paper and makes novel contributions in what I think is an interesting setting: using sparsity to induce identifiability in nonlinear ICA.\n- They clearly motivate why relaxing each assumption makes the assumptions more realistic.\n- I agree that the “conditional independence given auxiliary information” assumption that is common in the literature is not a great assumption, and I’m happy to see recent work removing or reducing this assumption.\n- They don’t require distributional assumptions.\n- It is well-written and well-structured overall. It is very clear what the prior work accomplishes and what the contributions are.'}, 'weaknesses': {'value': '- There could be more experiments in realistic settings. (However, given the strength of the theoretical contributions in this paper, I think the paper should be accepted as is.)\n\nMinor comments on the writing (did not affect score):\n- Line 84-85: You say “part of the sources can be grouped into irreducible independent subgroups…”, but “irreducible subgroup” is a term in algebra with a specific meaning. You could avoid this “collision” by saying “irreducible independent subgroupings” or something similar.\n- Line 156: You start a sentence with the word “Differently, …” which sounds strange. You could say “In contrast, …” instead.\n- Line 167: “While this removes the restriction of bijectivity between sources and observed variables, it remains uncertain as to whether Structural Sparsity holds in general, particularly for all sources in a universal way.”\n    - This sentence is confusing - you are saying it is uncertain whether Structural Sparsity holds in general, but Structural Sparsity is one of your assumptions. Are you saying it is uncertain whether Structural Sparsity is a reasonable assumption, based on whether it is likely to be satisfied on real-world data?\n- Line 177: It’s also weird to start this sentence with “Differently”.\n- Multiple lines: You start a handful of sentences with “Besides, …” and each time that is not really the word you mean. You should rethink how each of these sentences connects to the previous sentences and find the appropriate word for each case.'}, 'questions': {'value': '- Are you aware of Lachapelle et al 2022b? See https://arxiv.org/pdf/2207.07732.pdf. Lachapelle et al 2022a uses mechanism sparsity to induce permutation identifiability, but Lachapelle et al 2022b extends this approach to the partial identifiability setting. It would be (1) worth mentioning in the Introduction section that Lachapelle et al 2022a introduced the idea to use sparsity to induce identifiability, which inspired the approach of Zheng et al. 2022 (as stated in the text of Zheng et al 2022, see Section 3.1 of that paper), and (2) to cite Lachapelle et al 2022b as prior work using sparsity for partial identifiability (though in a distinct setting from your results as it relies on conditional independence given observed auxiliary variables).'}, 'limitations': {'value': '- Their experiments are only on visual disentanglement tasks and there are many other interesting disentanglement or other tasks that would be interesting to see in future work.\n- No concerns about negative societal impacts.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""The paper extends identifiability theory of nonlinear ICA (NICA), and deep latent variable models in general, by utilizing structural sparsity. In particular, previous works have shown that NICA can be identified if there is some observed auxiliary data or latent dependencies that essentially capture the inductive biases in the data generative process. The approach of structural sparsity (Zheng, '22) instead takes an alternative approach, namely constraining the nonlinear mixing function and its Jacobian. In this paper the authors extend that work as follows i.e. assuming structural sparsity and some additional assumptions:\n\n1. the authors show identifiability for a situation in which the mixing function is injective rather than bijective i.e. undercomplete case / i.e. smaller latent dimension than observed dimension. This is important for e.g learning low dimensional, semantically meaningful, interpretable latent features\n\n2. the authors show identifiability for a situation in which the structural sparsity principle applies only to some of the independent components\n\n3. further identifiability is shown for situation where not all the latent components are independent, rather components form independent subspaces. In fact some components may be dependent, conditionally independent or have some grouping structures.""}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'First, this paper is in general of good quality in that it is well organized and, in general, clearly written.\n\nMain strengths:\na.) most significantly, authors remove several strong limitations of previous works and extend identifiability of structural sparsity to undercomplete and case where not all latent components are structurally sparse (in those situations the remaining sources are shown to be identifiable). As a result these ideas are now more applicable to realistic data and scenarios.\n\nb.) These results have been reached, mostly, without too strong additional assumptions. For instance, it is shown that the necessary assumptions are more likely to hold in this new undercomplete case which is encouraging!\n\nc.) authors bridge gap between structural sparsity and the previous works that assume auxiliary variables. in particular, this work allows unconditionally independent components to follow structural sparsity and components which are conditionally independent given auxiliary variables. Whilst arguably to be expected, it is important to show this result (but see below for potential related weakness)'}, 'weaknesses': {'value': 'In general the weakness of this paper is that provides only few theoretical advances (albeit important; as mentioned above) but provides little beyond that. In particular, this is the results of:\n\n1. Contribution of the paper is not as significant as the authors describe, or at least there is limited coverage of relevant works\n2. Potential problems in some of the identifiability theorems\n3. Novelty is limited to identifiabiltiy theorems -- no new algorithms \n4. Experiments are lacking\n\nI will expand on each of these points below:\n\nMore detail for 1.):  In particular the authors state that ""Therefore, we establish, to the best of our knowledge, one of the first general frameworks for uncovering latent variables with appropriate identifiability guarantees in a principled manner"". I think this is too vague and general and fails to acknowledge the generality of some other works -- your work can be novel whilst admitting the generality of some other works too. First, Kivva \'22 show a very general framework for identifiability by making, arguably, less strong assumptions on the mixing functions -- currently the work of Kivva \'22 is only mentioned later on in section 3 (and even there in a problematic manner as ill point out below). Due to the generality of the results in Kivva, I would expect their result to be discussed in the introduction / early on in the text and tell the reader why yours is better or at least different. For example Kivva make different type of assumptions on the mixing function (piecewise affine) etc, while you on the sparsity. Second the work of Halva \'21 (disentangling identifiable features) provides another very general framework and unlike what you claim, it is not limited to time-series but to any dependencies of arbitrary order, and also does not require condition independence on some auxiliary variables but rather also assumes unconditional independence.\n\nMore detail for 2.): In Theorems 4.1 and 4.3  $S_d$ is ""identified up to an invertible transformation"". Surely if something is identified just up to invertible (vector-valued) function then we are not doing any better than nonlinear ICA i.e. we are essentially where one started and thus we have not identified anything. To me this is misleading and not a publishable identifiability result (if I have understood correctly -- please correct me if I\'m wrong and I\'ll adjust my score accordingly). Authors do acknowledge this point but rather than talking about it they make a vague remark that ""Thm. 4.1 may be helpful for some tasks that do not necessitate the recovery of each individual source, such as domain adaptation."" This does not suffice in my opinion. And similarly about Thm 4.3 they say: ""there exists an invertible transformation $h_{c_i}$ which is analogous to the previous element-wise indeterminacy. Consequently, even when dealing with mixtures of high and one-dimensional sources, like in the case of multi-modal data, we can still recover the hidden generating process to some extent."" Again I think this is bit generous and hiding the fact that $\\mathbf{s}_{c_i}$ is fully unidentifiable in the sense of nonlinear ICA. At least this limitation must be admitted more clearly -- preferably its usefulness would be shown empirically.\n\nMore detail for 3.):\nThere is a simple regularization term of the jacobian added -- but this is heurestic (vs. mle methods) from previous work. Undoubtedly there could be work done towards what is the best way to estimate a model that assumes structural sparsity but such is not done here.\n\nMore detail for 4.) \nAn important question is whether structural sparsity is a valid assumption. I think this can indeed be the case for many types of generative processes.  But the question then is then do the experiments strengthen that intuition. I feel not. It is not clear to me why e.g. EMNIST experiment there would be structural sparsity. EMNIST is also a very simple data set. I would expect the experiments to show that the learned independent components are useful in practical applications (see the brain signal experiments in Halva \'21 for instance or in Khemakhem (iVAE) \'20). I\'m not saying specifically this type of real data experiments need to be introduced, but something to further highlight the strenght of this method would be helpful. Another example is to evaluate the method more thoroughly on some benchmarks from the disentanglement learning literature. There are also some claims in the paper that would be good to justify experimentally for instance you claim on line 311-313 that ""This is particularly helpful in the context of self-supervised learning 311 (Von Kügelgen et al., 2021) or transfer learning (Kong et al., 2022), where latent representations are 312 modeled as a changing part and an invariant part."" If this indeed the case, why not show that on data? Indeed 311 to 324 gives nice discussion and its a great shame this has not been shown experimentally as it would really take this paper to the next level.'}, 'questions': {'value': 'I will use this space for further suggestions and questions:\n\n- Could you please introduce structural sparsity bit more clearly and intuitively -- if one has not read the original Zheng\'22 paper then it is difficult to follow.\n\n- In estimation, please clarify: is it required that we know which groups of latent variables are independent, and which are potentially dependent? How is this exactly established in practice?\n\n- please explain in more detail how your algorithm, in practice, allows dimension reduction without assuming observation noise, and how jacobian can be computed for non-bijective transformation\n\n- What is the level of nonlinearity in the mixing functions? I dont believe this is mentioned anywhere, e.g. number of layers or similar. \n\n- "". Since the proposed condition is on the connective structure from sources to observed variables, i.e., the support of the Jacobian matrix of the mixing function, it does not require the mixing function to be of any specific algebraic form."". Please make this sentence bit more precise or explain better what does \'specific algebraic form\' mean. Because structural sparsity does still limit the form of the function -- f can not longer be any arbitrary function.\n\n-  ""Most of these methods require auxiliary variables to be observable, such as class labels and domain indices (Hyvärinen and Morioka, 2016, 2017"". H&M 2017, really only require the previous data so it\'s not really a big limitation and it\'s arguable whether this really constitutes of having auxiliary variables...I would consider moving that reference to the next sentence since it\'s a time-series model : ""with the exceptions being those for time series...[move H&M\'17 reference here]""\n\n- ""The most obvious  one arises from the fact that it may fail in a number of situations where the generating processes are heavily disentangled."" Please explain in more detail why this may be?\n\n- ""We first present the result on removing one of the major assumptions in ICA, i.e., the number of observed variables m must be equal to that of hidden sources n."" This makes it sound like it hasn\'t been done previously in general, which of course it has been done many times previously in linear ICA (e.g eriksson and koivunen \'03) and nonlinear ICA (e.g. khemakhem \'20, halva \'21 etc etc). so rather than saying removing majort assumption in ICA, make it specific to sparsity\n\n- as for the title: are you really ""generalizing beyond structural sparsity""? as I feel structural sparsity is still the fundamental building block here. I would say you are generalizing structural sparsity in nonlinear ICA.\n\n- ""This is similar to Independent Subspace Analysis (ISA) (Theis, 2006)""  Either explain why you cite Theis, or cite an earlier ISA work (e.g. Hyvarinen & Hoyer, 2000)?'}, 'limitations': {'value': 'Authors should discuss limitations in more detail:\n\n- what are possible limitations of structural sparsity assumptions should be discussed more e.g. any scenarios where you expect it to be a poor assumption?\n\n- the point discussed in the ""Weaknesses"" section about the limitations in the identifiability theorems of 4.1 and 4.3 must be addressed and justified much more clearly or else those theorems should be removed\n\n- authors should note the heurestic approach of their estimation algorithm -- does GIN even have universal _function_ approximation capability? \n\n- related, discuss limitations of estimation algorithm in general. Is the algorithm guaranteed to find the correct sparsity for example? If not, then that should be pointed out as need for future works.\n\n- ""However, our setting is more flexible in the sense that we do not assume all sources to be influenced by the auxiliary variable. Specifically, sources in $s_I$ are mutually independent as in the original ICA setting, while only  sources in $s_D$ have access to the side information from the conditional independence given u,"". This is true and a nice result of theorem 4.4, but there is the limitation that should be discussed, namely now you are making restricting assumption on _both_ the mixing function as well as on the auxiliary variables -- in some sense this is worst of both worlds (but still a nice theoretical result with possible practical uses).'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The article serves as an extension to the work of Zheng et al. 2022, which posited the identifiability of nonlinear ICA based on specific structural sparsity assumptions related to the mapping of sources and mixtures. This current article expands on that by addressing the undercomplete case—where the number of mixtures exceeds the number of sources—and furthermore, it relaxes both the sparsity and source independence assumptions to yield more general identifiability results.\tIn the end authors provide some numerical examples to illustrate the applications of their identifiability theorems.\t'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The article tackles the foundational issue of the nonlinear inverse problem, making significant assertions regarding fundamental identifiability theorems. These are premised on assumptions of partial independence and structural sparsity.The problem under investigation is a fundamental problem and the article offers some important results for this problem.'}, 'weaknesses': {'value': ""The most significant shortcoming of the article lies in its presentation, particularly in its explanation of the core assumptions underpinning the theorems, as well as the motivation for the conditions applied in these assumptions. Absent a solid grasp of these theorems, it becomes challenging to properly evaluate the paper's contributions and ascertain its potential impact.\n\nIn terms of specific issues:\n\n* Concerning Theorem 3.1: This theorem seems to aim at generalizing Theorem 1 from Zheng et al., 2022 for a complete (m=n) case to an undercomplete (m>n) case. The identifiability results for ICA setups typically do not depend on a specific estimator choice or estimation algorithm. However, the statement of Theorem 3.1 seems rather unclear in this context. According to the article's notation, \\hat{f} refers to a specific estimate of the mixing function. Both the set of support matrices \\mathcal{T} and the support \\hat{\\mathcal{F}} depend on this particular estimate. The assumption (i) used in Theorem 3.1 is based on \\mathcal{T} and \\hat{\\mathcal{F}}, hence, this condition appears to be linked to a specific choice of the estimator for mixing. It would be beneficial if the authors could clarify whether the assumption (i) must hold on a particular \\hat{f}, a specific set of functions, etc. This clarification will likely impact the proof in the supplementary material and the explanation given between lines 129-136.\n\n\n* Line 97: Traditional or linear ICA does not necessarily require m=n.\n\n* Line 114: Should \\mathcal{S} be \\mathcal{A}?\n\n* Line 111 vs Line 536: The symbol \\mathcal{T} has two differing definitions - the set of matrices sharing the same support as T(s) and the support of T(s) itself.\n\n* Theorem 4.1: The vectors 'w' - whose independence implies identifiability - have not been sufficiently motivated or explained.\n\n* Similar comments can be made for other identifiability theorems.\n""}, 'questions': {'value': '* Line 190: Could you clarify what is meant by ""changing"" sources?\n\n* Line 195-196: 6, the phrase ""For sources s_D, they do not need to be mutually independent as long as they are dependent on the variable u"" is somewhat confusing. Subsequent equation (3) implies that S_D and S_I are conditionally independent when conditioned on u, and that the components of s_I are independent. What is the necessity for this latent variable u? Perhaps the authors could shed some light on this.\n\n* How does Theorem 4.1’s contribution compare with those from Khemakhem et al. (2020a) and Sorenson et al. (2020)?\n\n* Lines 215-217: Could you elucidate what condition (i) in Theorem 4.2 represents? What do s_d and B_{s_I} signify? Perhaps the discussions on lines 229-247 should precede Theorem 4.2 to better contextualize its contents and results, potentially with more lucid explanations.\n\n* Regarding Figure 4 and 5, could you expound on how these examples pertain to the nonlinear ICA setup (what are the sources, which appear to be images, and what are the nonlinear mixings)? How are the interpretations in the captions of these figures derived? Could you also elucidate how these examples relate to the identifiability theorems presented in the article and the conditions stipulated in these theorems?\n'}, 'limitations': {'value': 'Yes, the authors adequately addressed the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper utilizes the structural sparsity assumption on the support of the Jacobian matrix of the mixing function to extend the identifiability of nonlinear ICA in more settings including under-completeness, partial sparsity and source dependence, flexible grouping structures. It is a technically solid paper supported by theorems, proofs and experiments.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. Overall, the manuscript is well written with clear organization, comprehensive literature review, technically solid theorems, detailed proofs and promising experiment results. \n\n2. This work addressed some limitations of theorems about identifiability with Structural Sparsity in Zheng et al. 2022 and extended nonlinear ICA with Structural Sparsity to more general settings. The proposed theorems could be more practically useful in real-world datasets.\n\n3. The notations, theorems and proofs are clear in general.'}, 'weaknesses': {'value': '1. This work is interesting, and it would be great if code is provided to replicate the results. Please consider making the code publicly available. \n\n2. The meanings of some notations are not clear. See Questions. \n\n3. Ablation study. The author(s) only evaluated MCCs w.r.t. the number of sources. In Figure 3, the MCCs for 8 or 10 sources are a bit low so I wonder if more samples can help to improve MCCs. It would be more informative and convincing if more experiment configurations are considered (e.g., number of samples, various grouping structures) to demonstrate the effectiveness of proposed Theorems.\n\n4. Ablation study. Though the result comparison seems obvious visually, the authors should consider performing statistical tests to compare results between proposed methods and baseline method. \n\n5. Minor: ""exits"" should be ""exists"" at line 236.'}, 'questions': {'value': '1. Theorem 3.1: Is $|\\mathcal{F}_{i,:}|$ the $L_0$ or $L_1$ norm of $\\mathcal{F}$? Is $\\mathcal{C}_k$ a minimal set of sample indices to uniquely identify source $k$? How does the assumption ii show Structural Sparsity? The regularization constraint $|\\hat{\\mathcal{F}}| \\leq |\\mathcal{F}|$, which induces sparsity, should be included in Theorems. Also, I note that the author(s) tried to explain the assumptions in the following paragraphs, but I would suggest to describe the Theorems, at least Theorem 3.1, in plain words so that readers can better understand the Theorems. Or at least explain the notations (e.g., $\\mathcal{C}_k$) which are not explained in Section 2 Preliminaries.\n\n2. Theorem 3.1: Zheng et al. 2022 also proposed a Theorem on the undercomplete case. Could you kindly clarify the novelty between your proposed Theorem and that proposed in Zheng et al. 2022?\n\n3. Theorem 4.1: The author(s) claimed that we do not need to know the dependence structures or the number of dependent sources, but it is not intuitive to me how Theorems 4.1 and 4.2 uncover the dependence structures and the number of dependent sources. Could you please clarify?\n\n4. Theorem 4.2: What are $u_1$ and $u_2$? Are they two different sets of auxiliary labels?\n\n5. Lines 281 - 283: The claim on multi-modal data is unclear. Could you please clarify how to identify linkage across multiple modalities?'}, 'limitations': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Generalizing Nonlinear ICA Beyond Structural Sparsity'}, 'authors': {'value': ['Yujia Zheng', 'Kun Zhang']}, 'authorids': {'value': ['~Yujia_Zheng1', '~Kun_Zhang1']}, 'keywords': {'value': ['Latent variable models', 'nonlinear independent component analysis']}, 'TLDR': {'value': 'We establish a set of new identifiability results of nonlinear ICA in the general settings of undercompleteness, partial sparsity and source dependence, and flexible grouping structures.'}, 'abstract': {'value': 'Nonlinear independent component analysis (ICA) aims to uncover the true latent sources from their observable nonlinear mixtures. Despite its significance, the identifiability of nonlinear ICA is known to be impossible without additional assumptions. Recent advances have proposed conditions on the connective structure from sources to observed variables, known as Structural Sparsity, to achieve identifiability in an unsupervised manner. However, the sparsity constraint may not hold universally for all sources in practice. Furthermore, the assumptions of bijectivity of the mixing process and independence among all sources, which arise from the setting of ICA, may also be violated in many real-world scenarios. To address these limitations and generalize nonlinear ICA, we propose a set of new identifiability results in the general settings of undercompleteness, partial sparsity and source dependence, and flexible grouping structures. Specifically, we prove identifiability when there are more observed variables than sources (undercomplete), and when certain sparsity and/or source independence assumptions are not met for some changing sources. Moreover, we show that even in cases with flexible grouping structures (e.g., part of the sources can be divided into irreducible independent groups with various sizes), appropriate identifiability results can also be established. Theoretical claims are supported empirically on both synthetic and real-world datasets.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/c8cacba57be0e9de38f156a8525e062ef65ed2e7.pdf'}, '_bibtex': {'value': '@inproceedings{\nzheng2023generalizing,\ntitle={Generalizing Nonlinear {ICA} Beyond Structural Sparsity},\nauthor={Yujia Zheng and Kun Zhang},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=gI1SOgW3kw}\n}'}, 'paperhash': {'value': 'zheng|generalizing_nonlinear_ica_beyond_structural_sparsity'}}]"
"['Jerone Andrews', 'Dora Zhao', 'William Thong', 'Apostolos Modas', 'Orestis Papakyriakopoulos', 'Alice Xiang']",NeurIPS,Ethical Considerations for Responsible Data Curation,https://neurips.cc/virtual/2023/oral/73743,2023," Human-centric computer vision (HCCV) data curation practices often neglect privacy and bias concerns, leading to dataset retractions and unfair models. HCCV datasets constructed through nonconsensual web scraping lack crucial metadata for comprehensive fairness and robustness evaluations. Current remedies are post hoc, lack persuasive justification for adoption, or fail to provide proper contextualization for appropriate application. Our research focuses on proactive, domain-specific recommendations, covering purpose, privacy and consent, and diversity, for curating HCCV evaluation datasets, addressing privacy and bias concerns. We adopt an ante hoc reflective perspective, drawing from current practices, guidelines, dataset withdrawals, and audits, to inform our considerations and recommendations.",Oral 5B Privacy/Fairness,https://openreview.net/pdf?id=Qf8uzIT1OK,https://openreview.net/forum?id=Qf8uzIT1OK,Qf8uzIT1OK,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (Oral)'}, 'comment': {'value': 'This paper is exceptionally written and presents important and timely work that is of relevance to the D&B Track. I agree with the reviewers that it warrants acceptance to the conference.'}}, {'comment': {'value': 'I would like to thank the authors for taking the time and effort to address my comments on their current work. As my main concern was about the limitations revolving this research, I believe that the authors have adequately addressed them by appending the respective changes in the paper. As a result, I’m raising my score from 8 to 9.\n\nI’m looking forward to see this work getting published and the upcoming work that would leverage those considerations.'}}, {'title': {'value': 'Reply to rejoinder'}, 'comment': {'value': 'Thank you, authors, for the comprehensive review.\nI am of the opinion that *Appendix A is a strong addition which is of utility*, and that *removing the ""principlism-guided"" claim* (which was one of my major concerns re Beauchamp&Childress et al) have ameliorated the substantial concerns I\'ve had.\nThe score has been revised accordingly, for transparency, from ""3"" to ""7"".'}}, {'title': {'value': '[Continued] Author Response'}, 'comment': {'value': '> A major issue as mentioned above: the main claims of \'principlism-guided\' need to be reconsidered, or removed entirely. The Beauchamp & Childress concepts are not engaged with at depth; and the claim of ""principlism-guided"" needs to be tempered.\n\n\n* We have updated the title of our paper from *Principlism Guided Responsible Data Curation* to *Considerations for Responsible Data Curation*\n* The paper is entirely focused on our extensive literature review of current practices, guidelines, dataset withdrawals, and audits, which inform our considerations and recommendations. As mentioned by the reviewer, principlism was not engaged with at depth, and as such its removal is inconsequential to our comprehensive literature review and recommendations that are motivated and explained in detail.\n* However, we still maintain within our *Development Process* section that ""we employed the same principles underpinning established guidelines [24, 329] for protecting human subjects in research to *identify* ethical issues in HCCV dataset design"". The use of these principles to identify ethical issues is well motivated by the limitations we raised above (Lines 57-94 in the revised paper), regarding IRBs, the NeurIPS Code of Ethics, and ethics review processes.\n\n\n\n> The authors also claim (I quote) ""[c]urrent remedies address issues post hoc, lack persuasive justification for adoption, or fail to provide proper contextualization for appropriate application"" -- while this paper makes a solid attempt at the middle criterion, and perhaps the latter criterion, many valid points raised in this paper can be used in a post-hoc fashion as well.\n\nWe agree that several of our recommendations can be applied in a post-hoc fashion. However, our point was that our considerations and recommendations should be mediated over prior to data collection.\n\nWe have now further clarified this in the revised paper (see Lines 51-53). That is, ""While several of our recommendations can also be applied retroactively such measures cannot undo incurred harm, e.g., resulting from inappropriate uses, privacy violations, and unfair representation [128].""\n\nFor example, offering bonuses to data annotators to ensure they earn at least minimum wage is a positive step. Nonetheless, this action does not erase any harm that may have occurred before implementing it. That is, while the annotators\' compensation was below minimum wage.\n\nSimilarly, consider the situation where Exif metadata is absent from images due to, e.g., post-processing or device limitations. This absence can make it difficult to gauge the influence of instrument-related factors. Unfortunately, there is no way to address this post-data collection, which could potentially limit the thoroughness of fairness and robustness assessments.\n\nTo address these issues, it is important to proactively plan before collecting data. For example, this may involve considering factors such as permissible devices (i.e., capable of recording Exif) to ensure that potential challenges are anticipated and mitigated from the outset.\n\n\n---\n\nLet us know if these additions are satisfactory. Thank you again for taking the time to review our paper and the opportunity to improve the paper.'}}, {'title': {'value': 'Author Response'}, 'comment': {'value': 'Thank you for your insightful review. We particularly appreciate your recognition of our paper’s extensive literature review, clarity and presentation, as well as its distinctiveness in relation to prior work. In addition, thank you for raising areas for improvement.\n\n\n---\n\nPlease see our responses addressing Opportunities for *Improvement*, *Correctness*, and *Additional Feedback* below.\n\n\n> there is a risk of \'missing the forest for the trees\', in that (1) the submission has a prior assumption that ""bypassing Institutional Review Board supervision"" is the norm rather than the exception (p.3) -- having familiarity with data governance and IRB processes, this reviewer begs to differ.\n> \n> As a result, this submission seems to be creating an additional onus on potential experimenters to go through in addition to IRBs, which leads to (2) potential lack of uptake -- when compared against, e.g., Mitchell et al\'s model cards which are designed to be compact, thought-provoking, and most importantly complements existing processes -- which is a buy-in for adoption.”\n\nAddressing (1), we have expanded upon this point in the revised paper (see Lines 57-74 in the *Development Section*) and below:\n\nHCCV should adhere to the most stringent ethical standards to address privacy and bias concerns. As stated in the NeurIPS Code of Ethics [1], it is essential to abide by established institutional research protocols, ensuring the safeguarding of human subjects. These protocols, initially designed for biomedical research, have, however, been met with confusion, resulting in inconsistencies when applied in the context of data-centric research [217]. For example, HCCV research often amasses millions of public images without obtaining informed consent or participation, disregarding serious privacy and ethical concerns [35, 132, 244, 300, 3]. This exemption from research ethics regulation is grounded in the limited definition of human-subjects research, which categorizes extant, publicly available data as minimal risk [255, 217]. Thus, numerous ethically-dubious HCCV datasets would not fall under Institutional Review Board (IRB) oversight [246]. What’s more, the NeurIPS Code of Ethics only mandates following existing protocols when research involves direct *interactions* between human participants and researchers or technical systems. Even when research is subjected to supervision, IRBs are restricted from considering broader societal consequences beyond the immediate study context [216]. Compounding matters, CV-centric conferences are still to adopt ethics review practices [305]. In combination, this is problematic due to the potential for predictive privacy harms when seemingly non-identifiable data is combined [69, 217, 35] or when data is used for harmful downstream applications such as predicting sexual orientation [342, 191], crime propensity [356, 363], or emotion [223, 10].\n\nAddressing (2), we have now created an Appendix. In *Appendix A*, similar to existing AI ethics checklists [204, 224, 268, 355, 200, 89], we have created a checklist which translates each of our considerations and recommendations into action items for researchers and practitioners. Presented as a series of questions, mirroring the structure of our paper, these items are designed to stimulate discussions among data collection teams. The checklist is intended to be engaged with as a preliminary exercise before beginning data collection, promoting informed decision-making and minimizing risks. The checklist does not guarantee ethical compliance; rather, it functions as a catalyst for discussion and reflection. \n\nOur intention is that this addition aids data collection teams in transitioning, or at the very least, prompts contemplation about adopting more ethical practices.\n\n\n'}}, {'title': {'value': '[Continued] Author Response'}, 'comment': {'value': ""> Also, I haven't seen any dedicated limitations discussion in the paper.\n\nWe have replaced our *Conclusion* section with a *Discussion* section, where we now acknowledge the following limitations: \n* Implementing our proposed recommendations could face resistance due to established norms [217], inertia [33], diffusion of responsibility [150], and liability concerns [15].\n* Seeking consent from all depicted individuals could be logistically challenging, requiring investment in consent management systems and personnel. Particularly for smaller organizations and academic research groups, these limitations could present considerable hurdles.\n* Scaling our recommendations to large datasets, such as democratizing foundation model-sized training datasets [118, 287, 288, 103], presents an economic challenge. For example, the GeoDE dataset of ~67k crowdsourced object-centric images [261], without personally identifiable information, incurred a cost of $1.08 per image.\n\n\nIn addition, within the *Discussion* section, we provide some recommendations and thoughts on how to address the above limitations:\n\n* Platforms such as NeurIPS could adopt a model similar to the registered reports format, embraced by over 300 journals [50, 246]. This entails pre-acceptance of dataset proposals before curation, alleviating financial uncertainties associated with implementing more ethical practices. (As detailed in Section 3.2, the UK's 2021 Research Excellence Framework has acknowledged the significance of registered reports. This recognition suggests that authors who opt for publishing registered reports might potentially secure augmented funding for their respective institutions [50].)\n* Smaller organizations and academic research groups, potentially alongside larger institutions, could form data consortia [165, 120], which can help to address operational challenges by pooling resources and knowledge. A successful, prominent example is the Ego4D consortium [120].\n* While our recommendations may not seamlessly scale to the curation of fairness-aware, billion-sized image datasets, it is worth considering that “solutions which resist scale thinking are necessary to undo the social structures which lie at the heart of social inequality” [129]. Large-scale, nonconsensual datasets, driven by scale thinking, have included harmful and distressing content, including rape [36, 35], racist stereotypes [130], depictions of children [127], and derogatory taxonomies [182, 34, 128, 68]. The inclusion of such materials may further generate legal concerns [2]. We contend that these issues can be mitigated through the implementation of our recommendations.\n* Balancing resources between model development and data curation is a value-laden choice shaped by “social, political, and ethical values” [38]. While organizations readily invest significantly in model training [226, 334], compensation for data contributors often appears neglected [336, 335], disregarding that “most data represent or impact people” [378]. Remedial actions could be envisioned to bridge the gap between models developed with ethically curated data and those benefiting from expansive, nonconsensual crawled data. Reallocating research funds away from dominant data-hungry methods [38] would help to strike a balance between technological advancements and ethical imperatives. That being said, the granularity and comprehensiveness of our diversity recommendations could be adapted beyond evaluation contexts, particularly when employing “fairness without demographics” [209, 188, 133, 49] training approaches, reducing financial costs.\n\n\n---\n\nLet us know if these additions are satisfactory. Thank you for taking the time to review our paper and providing such positive feedback.\n""}}, {'title': {'value': 'Author Response'}, 'comment': {'value': ""Thank you for the very positive feedback, we are pleased that you found our paper to be thorough and well-presented. Also we appreciate your positive recognition of our efforts to assemble a diverse research group with backgrounds and research domains relevant to this work.\n\n---\n\nPlease see our responses addressing *Limitations* below.\n\n> I would really like to see how they gathered the respective literature and what they might didn't explored, also mentioning it as future work.\n\nWe have added additional details to the *Development Section* in the paper. In addition, we have created an Appendix. In *Appendix B*, we present details on our literature review, which we summarize below.\n* Through a thematic search strategy, we identified relevant research studies and datasets, revealing deficiencies in current image data curation practices or proposing potential solutions. By utilizing Semantic Scholar and Google Scholar, we curated relevant papers covering a wide spectrum of themes, including HCAI, human-subjects research, HCCV datasets, ethical considerations, legal aspects, privacy, fairness, diversity, representation, critical AI, and more.\n* The themes were chosen based on our expertise and experience in designing CV datasets, training models, and developing ethical guidelines.\n* To ensure a focused approach, we manually selected papers aligned with the scope of our study based on the relevance of a paper’s title and abstract. We present our initial categorization scheme in *Appendix B* Table 1, detailing key ethical considerations related to HCCV. \n* Initially broad, we further refined the categories to address the most prominent ethical issues pertaining to HCCV dataset curation, particularly for fairness and robustness evaluations. Consent and privacy categories were combined due to their interrelated nature and the influence of shared legal frameworks. Additionally, we integrated acquisition-related considerations into the categories of diversity, consent and privacy, as well as purpose, recognizing their interconnectedness in ethical image data collection, labeling, and usage. Maintenance-related matters were intentionally excluded from our scope, as these primarily pertain to post-dataset creation activities, while technical and organizational security measures are typically covered through consent forms. Ownership concerns, often intertwined with privacy issues, were incorporated into the consent and privacy category. \n* To establish a comprehensive view, we expanded our corpus as necessary. This encompassed examining cited works within our initial corpus, studies referencing our primary sources, and additional contributions by authors from our initial corpus. Our review was supplemented by incorporating publicly available resources from reputable sources, such as government bodies, private institutions, and reliable news organizations. \n* In total, our analysis covered 500 research studies and online resources.""}}, {'title': {'value': 'Author Response'}, 'comment': {'value': 'Thank you for the very positive feedback and appreciation that our work represents an excellent contribution to the field of responsible data curation.\n\n---\n\nPlease see our responses addressing *Opportunities for Improvement* and *Limitations* below.\n\n> Although the authors note the mutability and multiplicity of identity, it raises the question of whether the kind of very granular information they suggest gathering allows for this kind of flexibility. The emphasis is put on data subjects to opt out or modify their self assessments.\n\nWe have clarified this in the revision (see Lines 383-386). That is, we have acknowledged the potential burden of self-identification on fluid and dynamic identities. Nonetheless, acknowledging the mutability and multiplicity of identity is necessary to prevent oversimplification and marginalization. \n\nMoreover, we have acknowledged possible requests from data subjects for metadata updates. We assert that an image only captures a single moment in time and space. Evolving identity, therefore, may not require metadata updates. Nevertheless, we have augmented our recommendation by additionally recommending the provision of mechanisms that empower data subjects to update metadata for previously submitted images.\n\n> ... the paper could state more clearly the human rights failures of HCCV so far, and who has been most harmed. How should that increase the responsibility of practitioners, and in particular, why shouldn\'t they commit to doing human subjects review? \n> ... this paper would benefit from more detail on the scale and specificity of potential harms, and being more direct about examples of dehumanizing and discriminatory impacts of datasets. It should be more detailed about the kinds of harms already discovered (e.g Crawford and Paglen 2019; Prabhu and Birhane 2021).\n\n\n* In the *Development Process* section, we have added a few examples of harmful applications (see Lines 73-74).\n* In the new *Discussion* section, we have added examples of harmful and distressing content in large-scale datasets.\n* We have included an Appendix as well. In *Appendix C*, we showcase a range of notable instances displaying discriminatory outcomes within HCCV, spanning from 2011 to 2022. Furthermore, we underscore the obligation that researchers and practitioners hold in addressing broader societal repercussions. This responsibility is particularly pertinent due to the limited scope of IRBs, which primarily focus on immediate research study contexts rather than broader societal impacts. Due to formatting constraints in the NeurIPS D&Bs Track\'s ""submitted to"" option, which differs from the ""camera ready"" option, we were unable to incorporate the contents of *Appendix C* into the main text. Should our paper be accepted, our intention is to make this inclusion.\n\n\n\n\n---\n\nLet us know if these additions are satisfactory. Thank you for taking the time to review our paper and providing such positive feedback.\n'}}, {'title': {'value': '[Continued] Author Response'}, 'comment': {'value': '> I think this paper would be additionally enhanced and the recommendations more likely to be adopted if the authors could help HCCV researchers to make the transition from current ways of working to these much more ethical, but person time intensive, methods.\n\nWe have now created an Appendix. In *Appendix A*, similar to existing AI ethics checklists [204, 224, 268, 355, 200, 89], we have created a checklist which translates each of our considerations and recommendations into action items for researchers and practitioners. Presented as a series of questions, mirroring the structure of our paper, these items are designed to stimulate discussions among data collection teams. The checklist is intended to be engaged with as a preliminary exercise before beginning data collection, promoting informed decision-making and minimizing risks. The checklist does not guarantee ethical compliance; rather, it functions as a catalyst for discussion and reflection. \n\nOur intention is that this addition aids data collection teams in transitioning, or at the very least, prompts contemplation about adopting more ethical practices.\n\n\n\n---\n\nLet us know if these additions are satisfactory. Thank you for taking the time to review our paper and providing such positive feedback.'}}, {'title': {'value': 'Author Response'}, 'comment': {'value': ""Thank you for very positive feedback and your kind words. We are particularly pleased that you envision our paper as a significant bookmark that readers in this field will regularly revisit. \n\n---\n\nPlease see our responses addressing *Opportunities for Improvement* below.\n\n> I would have loved to see an acknowledgement of what could NOT be done in HCCV if these recommendations were put in place.\n\nWe have replaced our *Conclusion* section with a *Discussion* section, where we now acknowledge the following limitations: \n* Implementing our proposed recommendations could face resistance due to established norms [217], inertia [33], diffusion of responsibility [150], and liability concerns [15].\n* Seeking consent from all depicted individuals could be logistically challenging, requiring investment in consent management systems and personnel. Particularly for smaller organizations and academic research groups, these limitations could present considerable hurdles.\n* Scaling our recommendations to large datasets, such as democratizing foundation model-sized training datasets [118, 287, 288, 103], presents an economic challenge. For example, the GeoDE dataset of ~67k crowdsourced object-centric images [261], without personally identifiable information, incurred a cost of $1.08 per image.\n\n\nIn addition, within the *Discussion* section, we provide some recommendations and thoughts on how to address the above limitations:\n\n* Platforms such as NeurIPS could adopt a model similar to the registered reports format, embraced by over 300 journals [50, 246]. This entails pre-acceptance of dataset proposals before curation, alleviating financial uncertainties associated with implementing more ethical practices. (As detailed in Section 3.2, the UK's 2021 Research Excellence Framework has acknowledged the significance of registered reports. This recognition suggests that authors who opt for publishing registered reports might potentially secure augmented funding for their respective institutions [50].)\n* Smaller organizations and academic research groups, potentially alongside larger institutions, could form data consortia [165, 120], which can help to address operational challenges by pooling resources and knowledge. A successful, prominent example is the Ego4D consortium [120].\n* While our recommendations may not seamlessly scale to the curation of fairness-aware, billion-sized image datasets, it is worth considering that “solutions which resist scale thinking are necessary to undo the social structures which lie at the heart of social inequality” [129]. Large-scale, nonconsensual datasets, driven by scale thinking, have included harmful and distressing content, including rape [36, 35], racist stereotypes [130], depictions of children [127], and derogatory taxonomies [182, 34, 128, 68]. The inclusion of such materials may further generate legal concerns [2]. We contend that these issues can be mitigated through the implementation of our recommendations.\n* Balancing resources between model development and data curation is a value-laden choice shaped by “social, political, and ethical values” [38]. While organizations readily invest significantly in model training [226, 334], compensation for data contributors often appears neglected [336, 335], disregarding that “most data represent or impact people” [378]. Remedial actions could be envisioned to bridge the gap between models developed with ethically curated data and those benefiting from expansive, nonconsensual crawled data. Reallocating research funds away from dominant data-hungry methods [38] would help to strike a balance between technological advancements and ethical imperatives. That being said, the granularity and comprehensiveness of our diversity recommendations could be adapted beyond evaluation contexts, particularly when employing “fairness without demographics” [209, 188, 133, 49] training approaches, reducing financial costs.""}}, {'title': {'value': 'Review for ""Principlism Guided Responsible Data Curation""'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': ""This paper presents a detailed list of decisions and actions for data curation in human-centric computer vision. There are ethical considerations and practical recommendations for 1) considering the purpose of the dataset, 2) respecting individuals' consent and privacy, and 3) understanding the diversity of the people represented in the dataset.""}, 'strengths': {'value': 'This paper is exceptionally thorough and well referenced. I found it easy to read and very interesting. The authors have distilled the existing literature and focused their synthesis into practical recommendations that can be put in place by human centric computer vision researchers. I expect that readers working in this field will bookmark this paper and return to it often.'}, 'opportunities_for_improvement': {'value': 'My only quibble is that the ""practical recommendations"" are - from some perspectives - not very practical at all. I would have loved to see an acknowledgement of what could NOT be done in HCCV if these recommendations were put in place. The cost of collecting data would be higher I expect. But how much higher? How should that be estimated if we can\'t use existing datasets (for clearly explained ethical reasons)? How much data is needed? Does the enhanced curation mean models can be run on less? (I expect so) But how much less? Who would know.\n\nI think this paper would be additionally enhanced and the recommendations more likely to be adopted if the authors could help HCCV researchers to make the transition from current ways of working to these much more ethical, but person time intensive, methods.'}, 'limitations': {'value': ""I don't see any negative social impact of this work. This paper is very strongly encouraging the reader to work more responsibly with data for human centric computer vision. They are working to undo some of the existing negative social impact.\n\nThe scope of the paper is well explained and I don't see any limitations that have not been covered.\n""}, 'correctness': {'value': 'This paper is exceptionally well referenced and represents an accurate assessment of ethical considerations around responsible data curation.'}, 'clarity': {'value': 'Very well written, very clear. I found it easy to read and understand and I expect many others will come back to it regularly for the practical recommendations, the overarching ethical considerations, and the references.'}, 'relation_to_prior_work': {'value': 'This work synthesises the existing literature and presents actions specific to human centric computer vision. The work builds on but represents a distinct and important contribution to the field.'}, 'documentation': {'value': 'Not applicable.'}, 'ethics': {'value': 'No ethical concerns.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'I look forward to a future where these recommendations are implemented!! Thank you for your work.'}}, {'title': {'value': 'Principlism Guided Responsible Data Curation'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'summary_and_contributions': {'value': ""This paper addresses the state of human-centric computer vision (HCCV) datasets, and observes how they prioritize dataset size and utility while often ignoring privacy and bias concerns, leading to unfair models and dataset retractions. These practices heavily rely on nonconsensual web scraping, which may result in models that lack necessary metadata for fairness evaluations. The authors propose an 'ante hoc' approach that integrates ethical considerations from the start, focused on purpose, consent, privacy, and diversity, guided by the ethical framework of principlism (autonomy, beneficence, non-maleficence, justice). ""}, 'strengths': {'value': 'The paper is an excellent summary of the existing literature that points to the need for diversity, agency, sensitivity, and fairness in HCCV datasets. It makes contributions regarding the confused taxonomies of attributes like sex and gender, race and ethnicity, biased annotator influences, and ethical considerations such as data collection without consent, noninclusive labelling practices, and under-compensation of remote workers. The greatest strength is its specific practical recommendations, demonstrating a deep understanding of the need for diversity and inclusivity in dataset creation. The authors make a strong case for adopting self-reported data and open-ended response options. Although the authors note the mutability and multiplicity of identity, it raises the question of whether the kind of very granular information they suggest gathering allows for this kind of flexibility. The emphasis is put on data subjects to opt out or modify their self assessments. \n\nA standout aspect of these recommendations is their focus on fair and equitable treatment of contributors. The authors argue for a recognition system that goes beyond just compensation, and includes clear communication channels.\n\n\n'}, 'opportunities_for_improvement': {'value': ""The one thing I would suggest the authors reflect on further is connecting their interpretation of principlism with its origins in bio-ethics, and particularly the dark history of why human subjects processes were instituted in the first place. That is, the paper could state more clearly the human rights failures of HCCV so far, and who has been most harmed. How should that increase the responsibility of practitioners, and in particular, why shouldn't they commit to doing human subjects review? The paper currently states that as 'ideal' but not necessary, and this could benefit from being strengthened, particularly given the kinds of harms that are possible.  ""}, 'limitations': {'value': ""Again, this paper would benefit from more detail on the scale and specificity of potential harms, and being more direct about examples of dehumanizing and discriminatory impacts of datasets. It should be more detailed about the kinds of harms already discovered (e.g Crawford and Paglen 2019; Prabhu and Birhane 2021). Otherwise practitioners may see the excellent recommendations as more 'ideal if possible', rather than necessary to avoid serious consequences for data subjects and model performance. ""}, 'correctness': {'value': 'As far as is possible, yes. '}, 'clarity': {'value': 'Very well written. '}, 'relation_to_prior_work': {'value': 'The paper is excellent at reviewing prior literature.'}, 'documentation': {'value': 'NA'}, 'ethics': {'value': 'No. '}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'This is an excellent paper that contributes to the work on responsible data curation. '}}, {'title': {'value': 'A thorough overview of current HCCV data curation practises and domain-specific recommendations.'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '3: The reviewer is fairly confident that the evaluation is correct'}, 'summary_and_contributions': {'value': 'The authors provide a thorough overview of current human-centric computer vision (HCCV) data curation practices. They primarily focus on proposing proactive, domain-specific recommendations for curating HCCV datasets, addressing privacy and bias, guided by current practices, guidelines, and the ethical framework of principlism.'}, 'strengths': {'value': '- This work has been written by authors of diverse backgrounds, and research domains, which makes a crucial strong point for this kind of work.\n- The paper is well-written and nicely presented by the authors.\n- The work focuses on open research challenges and issues revolving around the topic.'}, 'opportunities_for_improvement': {'value': 'I would really like to see some case studies or a kind of evaluation of these recommendations in order to demonstrate if they are practically feasible to be applied.'}, 'limitations': {'value': ""I would really like to see how they gathered the respective literature and what they might didn't explored, also mentioning it as future work.\n\nAlso, I haven't seen any dedicated limitations discussion in the paper.""}, 'correctness': {'value': 'It seems that the claims are adequately supported by the related literature.'}, 'clarity': {'value': 'I found the paper clear, concise, and well-written.'}, 'relation_to_prior_work': {'value': 'The authors adequately provided and compared points related to previous work in specific discussions in the paper.'}, 'documentation': {'value': 'Not applicable to this kind of contribution.'}, 'ethics': {'value': 'I have not found any ethical concerns to address.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'Good work overall. I really liked that the authors compose a diverse research group of backgrounds and research domains that are of high importance for this kind of contribution.'}}, {'title': {'value': 'Review of #258: Principlism Guided Responsible Data Curation'}, 'rating': {'value': '7: Good paper, accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'To summarize, this submission is about an ante-hoc ""reflective perspective"" on ethical considerations for curation of datasets (specifically HCCV - Human-centric Computer Vision). The authors claim that this differs from existing ones which are ""post hoc, lack persuasive justification for adoption, or fail to provide proper contextualization for appropriate application"".\n\nIn the contribution, the authors review a significant body of literature and highlight broad categories of issues with the three broad themes of Purpose / Consent and Privacy / Diversity. Each category has ethical issues and considerations identified from extant literature; and suggested ameliorative recommendations are provided for each issue/consideration.'}, 'strengths': {'value': 'The key strength of the paper lies in the broad depth of literature surveyed and synthesised - 331 sources [covered in] 20 pages. The depth of work needs to be acknowledge and this reviewer commends the author team for this. \n\nIn addition, the authors have narrowed down specific issues pertaining to HCCV datasets, which is an attempt at addressing the unique issues not found in others such as LLM training corpora (e.g., ""privacy leaking image regions and metadata"", p.5). In addition, the recommendations provided are guided by legal considerations (the ubiquitous GDPR, say) in tandem with academic studies. \n\nFurther, the authors are aware of the existing sets of broad strategies in different working groups/committees/government agencies and attempt to tie these into the suggestions raised in their ""Practical recommendations"" sections.\n\n* EDIT: ""covered in 20 pages""'}, 'opportunities_for_improvement': {'value': 'The paper has some opportunities for improvement. For starters, the evidence for Principlism as an *advantage* is lacking - beyond several mentions at the start and towards the end, the use of these Beauchamp & Childress principles are not covered in detail nor justified (see *Correctness* below, in particular 1. not considering other frameworks and justifying the choice; and 2. lack of contextualisation for each issue with the Beauchamp & Childress 4 principles). \n\nThe authors also claim (I quote) ""[c]urrent remedies address issues post hoc, lack persuasive justification for adoption, or fail to provide proper contextualization for appropriate application"" -- while this paper makes a solid attempt at the middle criterion, and perhaps the latter criterion, many valid points raised in this paper *can be used in a post-hoc fashion* as well. \n\nLastly, there is a risk of \'missing the forest for the trees\', in that (1) the submission has a prior assumption that ""bypassing Institutional Review Board supervision"" is the *norm* rather than the exception (p.3) -- having familiarity with data governance and IRB processes, this reviewer begs to differ. As a result, this submission seems to be creating an *additional* onus on potential experimenters to go through in addition to IRBs, which leads to (2) potential lack of uptake -- when compared against, e.g., Mitchell et al\'s model cards which are designed to be compact, thought-provoking, and most importantly complements existing processes -- which is a buy-in for adoption.'}, 'limitations': {'value': '[The submission is pitched as a set of recommendations towards improving the ethical landscape on research, and hence this section does not apply.]'}, 'correctness': {'value': 'In terms of *Correctness* (expanding from *Opportunities For Improvement*), I\'d suggest that if the Beauchamp & Childress 4 Principles are to be engaged with, it should be more than just brief mentions of the four principles. A search through the document for each of the four principles yields at most 5 mentions. The methodology of ""To align our expertise with the ethical framework, we collaboratively discussed principlism’s four pillars, considering each author’s background"" might not suffice here -- a reviewer would expect, say, for the sake of argument: \n> ""Consent revocation"" (p.4) aligns with the principle of ""autonomy"" because the data subject needs to be able to have ""decision-making rights"" in the spirit of Kantian philosophy (i.e., using others not merely as a means in achieving, say, data saturation -- cf. 2nd Categorical Imperative) -- citing Beauchamp & Childress (2001).\n\nFurther, a misconception that might need to be addressed is that the Beauchamp & Childress 4 Principles are meant to be used as an easy set of heuristics in decision-making, and not merely used in setting the scene for a literature review -- this has to be again *emphasised in this contribution if it were to maximise the usefulness of these principles*. Again, pick any recommendation such as ""Obtain self-reported annotations"" -- autonomy plays a role here (one would argue being the primary principle at work); and so is ""nonmaleficence"" and ""justice"" as the fact that misclassification is a form of *epistemic hermeneutical injustice* cf Miranda Fricker (2007). Such argumentation will help solidify the benefit of these principles and guide the reader to *why* recommendations provided are grounded in Beauchamp & Childress.'}, 'clarity': {'value': 'In the main, it is quite well written with no issues with language nor presentation. The authors are commended for this.'}, 'relation_to_prior_work': {'value': 'As discussed above: this work differs from existing ones which are ""post hoc, lack persuasive justification for adoption, or fail to provide proper contextualization for appropriate application"".'}, 'documentation': {'value': '[The submission is pitched as a set of recommendations towards improving the ethical landscape on research, and hence this section does not apply.]'}, 'ethics': {'value': '[The submission is pitched as a set of recommendations towards improving the ethical landscape on research, and hence this section does not apply.]'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'This reviewer would encourage the authors to instead pitch the submission as a literature review and position paper -- more importantly, with the aims of establishing a new *framework* on data curation in HCCV - which will potentially be more topical, contextual, and very likely to succeed (in this reviewer\'s opinion). \n\nThis includes, e.g. potential templates or actionable prompts in the same direction as Mitchell et al\'s Model Cards or Gebru et al\'s Datasheets initiatives which are compact, self-contained, and [more importantly] easy-to-get-uptake from the researcher community -- their position papers create a framework, guided by extant research, and are easily applicable.\n\nA major issue as mentioned above: the main claims of \'principlism-guided\' need to be reconsidered, or removed entirely. The Beauchamp & Childress concepts are not engaged with at depth; and the claim of ""principlism-guided"" needs to be tempered. '}}, {'title': {'value': 'Ethical Considerations for Responsible Data Curation'}, 'authors': {'value': ['Jerone Andrews', 'Dora Zhao', 'William Thong', 'Apostolos Modas', 'Orestis Papakyriakopoulos', 'Alice Xiang']}, 'authorids': {'value': ['~Jerone_Andrews1', '~Dora_Zhao1', '~William_Thong1', '~Apostolos_Modas1', '~Orestis_Papakyriakopoulos1', '~Alice_Xiang1']}, 'keywords': {'value': ['human-centric', 'datasets', 'computer vision', 'fairness', 'algorithmic bias', 'robustness', 'responsible AI']}, 'TLDR': {'value': 'Practical recommendations for responsibly curating human-centric computer vision datasets for fairness and robustness evaluations, addressing privacy and bias concerns'}, 'abstract': {'value': 'Human-centric computer vision (HCCV) data curation practices often neglect privacy and bias concerns, leading to dataset retractions and unfair models. HCCV datasets constructed through nonconsensual web scraping lack crucial metadata for comprehensive fairness and robustness evaluations. Current remedies are post hoc, lack persuasive justification for adoption, or fail to provide proper contextualization for appropriate application. Our research focuses on proactive, domain-specific recommendations, covering purpose, privacy and consent, and diversity, for curating HCCV evaluation datasets, addressing privacy and bias concerns. We adopt an ante hoc reflective perspective, drawing from current practices, guidelines, dataset withdrawals, and audits, to inform our considerations and recommendations.'}, 'venue': {'value': 'NeurIPS 2023 Datasets and Benchmarks Oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Track/Datasets_and_Benchmarks'}, 'pdf': {'value': '/pdf/1daedc021c3de0f830968b313518b6b21e77f8a0.pdf'}, '_bibtex': {'value': '@inproceedings{\nandrews2023ethical,\ntitle={Ethical Considerations for Responsible Data Curation},\nauthor={Jerone Andrews and Dora Zhao and William Thong and Apostolos Modas and Orestis Papakyriakopoulos and Alice Xiang},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\nyear={2023},\nurl={https://openreview.net/forum?id=Qf8uzIT1OK}\n}'}, 'paperhash': {'value': 'andrews|ethical_considerations_for_responsible_data_curation'}}]"
"['Constantine Caramanis', 'Dimitris Fotakis', 'Alkis Kalavasis', 'Vasilis Kontonis', 'Christos Tzamos']",NeurIPS,Optimizing Solution-Samplers for Combinatorial Problems_ The Landscape of Policy-Gradient Method,https://neurips.cc/virtual/2023/oral/73826,2023," Deep Neural Networks and Reinforcement Learning methods have empirically shown great promise in tackling challenging combinatorial problems. In those methods a deep neural network is used as a solution generator which is then trained by gradient-based methods (e.g., policy gradient) to successively obtain better solution distributions.In this work we introduce a novel theoretical framework for analyzing the effectiveness of such methods. We ask whether there exist generative models that (i) are expressive enough to generate approximately optimal solutions; (ii) have a tractable, i.e, polynomial in the size of the input, number of parameters; (iii) their optimization landscape is benign in the sense that it does not contain sub-optimal stationary points. Our main contribution is a positive answer to this question. Our result holds for a broad class of combinatorial problems including Max- and Min-Cut, Max-$k$-CSP, Maximum-Weight-Bipartite-Matching, and the Traveling Salesman Problem. As a byproduct of our analysis we introduce a novel regularization process over vanilla gradient descent and provide theoretical and experimental evidence that it helps address vanishing-gradient issues and escape bad stationary points.",Oral 5C Probability/Sampling,https://openreview.net/pdf?id=mmTy1iyU5G,https://openreview.net/forum?id=mmTy1iyU5G,mmTy1iyU5G,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The reviewers have provided a thorough evaluation of the paper and have generally agreed on its strengths and potential impact. The paper presents a novel theoretical framework for analyzing the effectiveness of deep models trained by gradient-based methods as solution generators for combinatorial problems. The authors have done an excellent job in presenting their work and justifying their design choices. The paper is well-written and the main insights are presented in a simple yet rigorous manner. \n\nThe reviewers have raised some concerns and questions, mainly related to the practical implications of the framework and its scalability. However, these concerns do not undermine the theoretical contributions of the paper. The authors are encouraged to address these concerns in their final version of the paper or in future work.\n\nOverall, the paper is technically solid and has the potential to have a high impact on the field. The theoretical contributions are significant and the paper is well-positioned to stimulate further research in this area. Therefore, I recommend accepting this paper.'}}, {'title': {'value': 'thank you for the responses'}, 'comment': {'value': 'I thank the authors for their detailed response. I encourage them to include these clarifications in the final paper version.'}}, {'comment': {'value': 'I thank the authors for their extensive response to my review and the raised questions. Trusting that the authors will incorporate the promised changes, I am increasing my score from 4 to 6.'}}, {'title': {'value': 'Acknowledging rebuttal'}, 'comment': {'value': 'Commenting to confirm I have read the rebuttals and other reviews and will digest and engage in discussion. '}}, {'rebuttal': {'value': '\nWe are very encouraged from the very positive feedback of the reviewer and their excitement about our work and potential impact.  We are also very excited about our work and believe that our work will initiate a principled theoretical study of neural combinatorial optimization and its theoretical insights will be of practical significance.'}}, {'rebuttal': {'value': ""We would like to thank the reviewer (i) for finding the contribution of our paper great and for providing extensive constructive feedback, (ii) for pointing out various typos in the current draft, which we will fix in our first revision and (iii) for proposing additional references and suggestions for the Related Work section; we added the papers' for a more complete and detailed exposition. We continue by explicitly addressing the reviewer's questions.\n\n> I think the paper (implicitly and sometimes explicitly) oversells the contribution of [BPL+16] ...\n\nThe work of  [BPL+16] is the (experimental) work that introduced the framework of Neural Combinatorial Optimization. Our work is the first theoretical approach to design a rigorous and principled way to study and argue about the fundamental questions behind this problem. Hence, we chose to design our theoretical framework on top of this (arguably) well-accepted work. We do not claim that the experimental results of  [BPL+16] are SOTA. However, we find that this work is the simplest and most natural setting to go from a completely practical to a rigorous theoretical framework. Hence, our work does not build on the experimental contribution of  [BPL+16] (as the reviewer correctly mentions there are various follow-up works that improve on this front) but builds on the conceptual contribution of  [BPL+16] providing the first formal theoretical guarantees. We will clarify the fact that the results of  [BPL+16]  are for smaller instances.\n\n> Line 219\n\nThis is standard, see e.g., Spielman (2010). We will add a reference, as the Reviewer proposes.\n\n[Spielman, Algorithms, graph theory, and linear equations in Laplacian matrices, 2010]\n\n> Line 73\n\nThis is the standard expression for policy gradient, for the reference see e.g., Section 2 and 5 in the paper of Kakade (2001) as we mention in our manuscript and for a proof see the book by Szepesvári (2022).\n\n[Kakade, A natural policy gradient, 2001]\n\n[Szepesvári, Algorithms for reinforcement learning, 2022]\n\n> Line 75\n\nOne does not need access to an explicit representation of the cost function (e.g., the Laplacian matrix of the Graph in the Max-Cut problem) but only black box access to the cost oracle (i.e., the values of the function).\n\n> Model of Computation\n> \n> Line 96\n\nGradient descent is not explicitly performed on a finite set – it is just the rounding of the iterates (due to finite memory in its implementation) that implicitly makes the set discrete.  Our description size captures exactly this finite precision issue. Say we require $d$ parameters for the parameter space of gradient descent; then a description size of $O(d \\log(1/\\epsilon))$ would mean that when you implement gradient descent you should use $O(d \\log(1/\\epsilon))$ bits for the representation of its iterates (roughly $\\log(1/\\epsilon)$ bits for each parameter).  Since the loss that we use is $\\mathrm{poly}(d)$-Lipschitz with respect to the parameter $w$ (assuming that $w$ belongs in the continuous space), rounding the iterates of Gradient descent to $O(d\\log(1/\\epsilon))$ bits does not introduce substantial error. We performed the analysis of gradient descent in the real-valued model for simplicity; we will add a remark on this in our updated manuscript.\n\n> Line 99\n\nAs it is standard in the optimization literature (see e.g., Bubeck (2015)), we cannot hope for truly polynomial dependence on $1/\\epsilon$ unless the objective enjoys some special structure such as strong convexity. To this end, we settle for the natural $\\mathrm{poly}(1/\\epsilon)$ dependence. In contrast, we stress that the parameter space should be of truly polynomial size, i.e. polynomial in $\\log(1/\\epsilon)$. \n\n[Bubeck, Convex optimization: Algorithms and complexity, 2015]\n\n> Line 107\n\nEach point of the hypercube corresponds to a cut in the graph. The full parametrization corresponds to assigning a single parameter to any possible cut (which are exponentially many). The description is finite due to the finite precision requirement (see also our response to the previous question regarding finite precision).\n\n> Remark 5\n\nAs our wording of Remark 5 shows this is a high-level/intuitive statement. The fact that optimizing (even simple) two layer neural networks is computationally intractable indicates that end-to-end optimization of deep solution samplers that can generate samples efficiently (in polynomial-time) is most likely impossible.  For more evidence we remark that having an efficient (and “small”, i.e., with polynomial number of parameters) neural network sampler that can also be provably optimized via gradient descent in polynomial iterations would imply a polynomial-time algorithm for the problems considered in this work (e.g., for Max-Cut) which is a well-known NP-hard (even to approximate) problem.\n\n> Remark 6\n\nLet us consider the weighted Max-Cut problem, with known weights. In this case, one can take the weighted Laplacian matrix and again express the loss function in the exact same form as in the unweighted case. Then the feature mappings are exactly the same.\n\n> Are there natural combinatorial optimization problems to which the framework is not applicable? If so, which problems, and why?\n\nWe kindly refer to our response to Reviewer VMa2.\n\n> It seems like the proposed method is theoretically superior to what people use in practice. Is this true? And if so, why is it not the standard method in practical settings nowadays? Do you expect it to become that?\n\nYes, our method is theoretically superior to the vanilla objective as the additional reguralization and the fast/slow mixture generators help avoid minimizers at infinity and vanishing gradients (see Section 3 of our manuscript). Our preliminary experimental evaluation indicates that some of our theoretical insights (entropy regularization, fast/slow mixing) leads to better performance. We also kindly refer to our response to Reviewer jXn4.""}}, {'rebuttal': {'value': '\nWe thank the reviewer for the very positive feedback and the provided questions.\n\n> *The authors may want to conduct experiments on more combinatorial problems with larger scales to demonstrate the effectiveness of the proposed method.*\n\n*Response:* We kindly refer to our general response about experimental evaluation on large instances for Max-Cut. As a direct future direction we aim to extend our experiments to other interesting combinatorial problems.\n\n\n> *The authors apply MLP to combinatorial problems with a fixed number of graph nodes. However, MLPs fail to process instances with varying scales. The authors may want to consider more suitable models such as the graph neural network (GNN).*\n\n*Response:* We agree with the reviewer that GNNs are more suitable for such tasks and plan to use them in future experimental evaluation of our work. Since our current work is primarily theoretical, we tried to keep our simulations as simple as possible (we do not aim to improve over SOTA methods for NCO). \n\n\n> *Could you please give some examples of combinatorial problems that do not satisfy Assumption 1?*\n\n*Response:* An interesting combinatorial problem not captured by our framework is SAT.\n\nGiven a combinatorial problem, Assumption 1 essentially asks for the **design** of feature mappings for the solutions and the instances that satisfy desiderata such as boundedness and variance preservation.\n \nMax-Cut, Min-Cut, TSP and Max-$k$-CSP and other problems satisfy Assumption 1 because we managed to design appropriate (problem-specific) feature mappings (see Section 2) that satisfy the requirements of Assumption 1. \n\nThere are interesting combinatorial problems for which we do not know how to design such good feature mappings. For instance, the ""natural"" feature mapping for the Satisfiability problem (SAT) (similar to the one we used for Max-$k$-CSPs) would require feature dimension exponential in the size of the instance (we need all possible monomials of $n$ variables and degree at most $n$) and therefore, would violate item 4 of Assumption 1.\n\n\n> *Could you please provide more details on the representations of input data, such as the input features and dataformat?*\n\n*Response:* At each iteration, the input is an instance (e.g., a graph). A potential representation of the graph is the Laplacian matrix (e.g., in Max-cut). Hence, the input features are a collection of Laplacian matrices. We note that the input features depend on the combinatorial problem in hand.\n\n\n> - *The authors analyze the existence and properties of the feature mappings for the solutions and instances, but how to learn such mappings remains unexplored.*\n> \n> - *Assumption 1 might be difficult to check for a general combinatorial problem, which may limit the applicability of the theoretical results in this paper.*\n\n*Response:* In this work, we present a general framework for establishing the first theoretical understanding regarding challenging and fundamental combinatorial problems. Assumption 1 allows for our framework to be quite general and expressive. The mildness of our Assumption is justified by the number of problems it captures (Max-Cut, TSP, and Max-$k$-CSP). We emphasize that the featured mappings for the instances and the solutions correspond to a design problem; in our work, we designed appropriate feature mappings for Max-Cut, TSP and other combinatorial problems. Hence, it is not exactly the case that Assumption 1 is hard to check; the challenge is to design good feature mappings, which currently is a problem-specific task. Designing principled ways to find these mappings is an interesting direction. \n\n'}}, {'rebuttal': {'value': '\nWe would like to thank the reviewer for the positive feedback and insightful questions.\n \n> - *I understand that the main focus of this work is to provide a generic framework with reasonable assumptions and strong performance guarantees. I feel that the authors have delivered on that premise. That said, readers may be left with the question: what is the true empirical potential of this framework, especially when we compare it to state of the art combinatorial neural solvers? After reading the paper, I was not really clear whether this work is mainly about introducing a generic framework, or if it was also about proving its practical value on various benchmarks.*\n>\n>\n>- *Is this work only intended to theoreticians or to practitioners as well? If the latter is the case, then the authors would need to provide evidence for that claim, e.g., performance of their solution generators compared to other continuous solvers. I feel that this question is not answered in the current paper.*\n\n*Response:* In this work, we present a general framework for establishing **theoretical** understanding regarding challenging and fundamental combinatorial problems such as Max-Cut, TSP, and Max-$k$-CSP. Hence, our work is mainly intended for theoreticians and we leave more extensive experimental evaluation of our work as an interesting question for future work.\n\nHowever, as our simulations (see also the additional experiments on larger instances provided in this rebuttal) show that some of the insights we obtain as a byproduct of our theoretical proof of convergence may be of practical significance. Moreover, we would like to point out an interesting connection between our theoretical work and a prior experimental paper. The work of Kim et al. (2021) uses an entropy maximization scheme in order to generate diversified candidate solutions. This experimental heuristic is quite close to our theoretical idea for entropy regularization. In our work, entropy regularization allows us to design quasar-convex landscapes and the fast/slow mixing scheme to obtain diversification of solutions.\n\n[Kim, Park, Kim, Learning Collaborative Policies to Solve NP-hard Routing Problems, 2021]\n\n>- *On a similar note, the number of nodes $n=15$ used in the ablation study is small - could these methods scale to larger instances? Do the authors have any take-away messages for practitioners who may be interested in trying out such methods? Is it perhaps fair to say that the proposed framework mostly serves as an abstraction but without necessarily powerful practical implications?*\n>- *In the discussion of P vs. NP, the authors explain that sampling from their solution generators may be computationally expensive but add that techniques based on Langevin dynamics may help to circumvent this issue in practice. It would be worthwhile for the authors to see whether such techniques would be of any help, especially with large instances.*\n\n*Response:* We refer to our previous answer and the additional simulations in the general response. In our additional simulations, we implemented our method using approximate samplers based on Langevin dynamics to circumvent this issue.  Given that even in larger instances our method outperforms the vanilla objective we are optimistic that our theoretical insights are going to be of practical significance.'}}, {'rebuttal': {'value': '**General Response**\n\nWe thank all reviewers for taking the time to read our manuscript carefully and for providing constructive and insightful feedback. We are very encouraged by the positive comments of the reviewers on the novelty and significance of our theoretical framework for Neural Combinatorial Optimization (Reviewers jXn4, dPn4), theoretical contributions (Reviewers m1vy, dPn4) and the writing quality and the clarity of the presentation of the ideas (Reviewers jXn4, VMa2, dPn4). \n\nWe provide detailed responses to each reviewer separately. We look forward to engaging in further discussion with the reviewers, answering questions, and discussing improvements. \n\nBefore that, we start with a general comment where we provide detailed additional experimental results on large instances.\n\n\n**Additional Simulations - Larger Instances/Approximate Samplers**\n\n\nOur experiments in the paper (which do not need Langevin dynamics for sampling) showed that even for very small instances of Max-Cut (i.e., with 15 nodes), optimizing the vanilla objective is not sufficient and the iteration gets trapped in local optima. In contrast, our method using entropy regularization always manages to find the optimal cut. A natural question raised by the reviewers is whether this improvement is also apparent in larger graphs.\n\nWe focus on the case of random $d$-regular graphs with $n$ nodes. It is well-known that for this family of graphs, with high probability as $n \\to \\infty$, the size of the maximum cut satisfies $\\mathrm{MaxCut}(G(n,d)) = n(d/4 + P_\\star \\sqrt{d/4} + o_d(\\sqrt{d})) + o(n)$, where $P_\\star \\approx 0.7632$ is a universal constant [Dembo et al., 2017].\n\nWe aim to find a good approximation for the normalized cut-value, defined as $(\\mathrm{cut\\_value}/n - d/4)/\\sqrt{d/4}$, which (roughly speaking) takes values in $[0,P_\\star]$.\n\nWe obtain approximate random samples from the density $e^f$ using the Metropolis-Adjusted Langevin Algorithm (MALA). In particular, an approximate sample from this density is obtained by the Euler–Maruyama method for simulating the Langevin diffusion: $x_{k+1} = x_k + \\tau \\nabla f(x_k) + \\sqrt{2\\tau} \\xi_k$, where $\\xi_k$ is an independent Gaussian vector $\\mathcal{N}(0,I)$. MALA incorporates an additional step based on the Metropolis-Hastings algorithm (see [Besag, 1994, Song and Kingma, 2021]). In our case, the score function $f$ is a simple 3-layer ReLU network. \n\n**In our additional experiments for 3 larger random regular graphs (600 nodes) using the fast/slow mixing technique along entropy regularization we see that our method leads to improvements over the vanilla objective.** Plots of the trajectories of the vanilla and our method can be found in the figures provided in the pdf of the rebuttal. In the horizontal axis we plot the iterations and in the vertical axis we plot the normalized cut score of each method (higher is better) -- we stop the plot of the vanilla trajectory after 200 iterations because we observed that its output has fully converged and is stuck.\n\n[Dembo, Montanari and Sen, Extremal cuts of sparse random graphs, 2017]\n\n[Besag, Comments on “Representations of knowledge in complex systems” by U. Grenander and MI Miller, 1994]\n\n[Song and Kingma, How to train your energy-based models, 2021]\n'}, 'pdf': {'value': '/pdf/0b9ee3c7a0885e797d9bc1356efdeb577a64f9ce.pdf'}}, {'summary': {'value': 'This paper deals with a significant question at the intersection of combinatorial optimization and continuous-based optimization: is it possible to design solution generators for combinatorial problems that are (1) expressive enough to generate approximately optimal solutions, (2) tractable so that their parameterization is only polynomial in the number of inputs, and (2) efficiently optimizable so that only a polynomial number of stochastic gradient descent (SGD) steps is required to learn a parameterization with almost optimal performance? The paper answers this question in the affirmative. It develops a general framework that can be used to describe complete, compressed and efficiently optimizable solution generators, which can be instantiated to accommodate a wide range of NP-hard problems. The framework requires feature mappings for both the instances and the solutions tat have a number of desired properties. Assuming this is the case, the authors provide a very general positive result. The paper highlights two challenges related to the optimization. First, the loss function may accept a minimizer at infinity, so that gradient descent may get stuck to sub-optimal configurations. The authors address this by introducing an entropy regularization term. Second, vanishing gradients may slow down optimization, rendering it inefficient. This is addressed by introducing a mixture of a fast and a slow solution generator: the fast component helps to reach the optimal solution while the slow component helps to keep a non-zero variance throughout the optimization process, hence avoiding the problem of vanishing gradients. The authors provide experimental evidence in favor of their entropy regularizer and the fast/slow mixing scheme.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. The paper is extremely well-written. The authors have done an excellent job presenting in a simple yet rigorous manner the main insights behind their framework and the various design choices. Every single choice is adequately justified, which makes it very easy even for non-familiar readers to grasp the main messages of this work. I also liked the the fact that the authors took extra care to elucidate some potentially confusing aspects, e.g., with respect to the P vs. NP question.\n2. The main result requires very reasonable assumptions and is general enough to encompass several standard hard problems. \n3. The two proposed tricks (entropy regularization and fast/slow mixing scheme) are extremely well motivated but also justified theoretically. The ablation study at the end confirms their usefulness empirically.\n4. The framework is novel and a major part of its novelty precisely stems from its generality. \n5. Even though I was not able to check all math details, the part that I was able to check was free of problems.'}, 'weaknesses': {'value': '1. I understand that the main focus of this work is to provide a generic framework with reasonable assumptions and strong performance guarantees. I feel that the authors have delivered on that premise. That said, readers may be left with the question: what is the true empirical potential of this framework, especially when we compare it to state of the art combinatorial neural solvers? After reading the paper, I was not really clear whether this work is mainly about introducing a generic framework, or if it was also about proving its practical value on various benchmarks. '}, 'questions': {'value': '1. Is this work only intended to theoreticians or to practitioners as well? If the latter is the case, then the authors would need to provide evidence for that claim, e.g., performance of their solution generators compared to other continuous solvers. I feel that this question is not answered in the current paper.\n2. On a similar note, the number of nodes n=15 used in the ablation study is small - could these methods scale to larger instances? Do the authors have any take-away messages for practitioners who may be interested in trying out such methods? Is it perhaps fair to say that the proposed framework mostly serves as an abstraction but without necessarily powerful practical implications?\n3. In the discussion of P vs. NP, the authors explain that sampling from their solution generators may be computationally expensive but add that technique based on Langevin dynamics may help to circumvent this issue in practice. It would be worthwhile for the authors to see whether such techniques would be of any help, especially with large instances.'}, 'limitations': {'value': 'None.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes a theoretical framework for analyzing the effectiveness of deep models trained by gradient-based methods as solution generators for combinatorial problems. The authors first investigate the complete, compressed and efficiently optimizable properties of the solution generator on many combinatorial tasks. To address the challenges of minimizers at infinity and vanish gradients, the authors devise an entropy regularization and a fast/slow mixture generation scheme. Experiments demonstrate that the proposed method helps address vanishing-gradient issues and escape bad stationary points.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. The paper gives a positive answer to the existence of complete, compressed and efficiently optimizable solution generators for combinatorial tasks, and it designs a family of such solution generators.\n2. The paper addresses the challenges of minimizers at infinity and vanishing gradients by the proposed entropy regularization and fast/slow mixture generation scheme.\n3. A general and solid foundational theorem (Theorem 1) is clearly presented.\n'}, 'weaknesses': {'value': '1. The authors may want to conduct experiments on more combinatorial problems with larger scales to demonstrate the effectiveness of the proposed method.\n2. The authors analyze the existence and properties of the feature mappings for the solutions and instances, but how to learn such mappings remains unexplored.\n3. The authors apply MLP to combinatorial problems with a fixed number of graph nodes. However, MLPs fail to process instances with varying scales. The authors may want to consider more suitable models such as the graph neural network (GNN).'}, 'questions': {'value': '1. Could you please give some examples of combinatorial problems that do not satisfy Assumption 1?\n2. Could you please provide more details on the representations of input data, such as the input features and data format?'}, 'limitations': {'value': 'Assumption 1 might be difficult to check for a general combinatorial problem, which may limit the applicability of the theoretical results in this paper.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper provides a theoretical analysis of policy-gradient methods for combinatorial optimization problems. It defines a set of three desirable properties one might wish to be fulfilled for such a property, namely being able to generate an approximately optimal solution, being small in size, and enabling efficient optimization via SGD. The main result of the paper is to prove that there exists a policy gradient method satisfying all three properties simultaneously. The proposed method is general enough to capture many well-known combinatorial optimization problems. A small empirical study is provided, too.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'I think the idea behind this work is great. Theoretical foundations for reinforcement learning methods applied to CO problems are highly needed. Defining a set of desirable properties and analyzing whether and how they can be satisfied simultaneously seems to be the right approach.'}, 'weaknesses': {'value': 'Since I believe that the contributions of this paper are great, I feel really sorry that I cannot give a more positive evaluation at the moment. I try to give as much constructive feedback as possible and encourage the authors to revise the manuscript and, if not accepted here, resubmit to another top venue. My main concern is:\n- I have a few mathematical issues / questions, where I do not understand the paper. I think one source of these issues is that the model of computation is not well-defined. The authors wildly switch between bit-representations and real models of computation. To solve these issues, the authors should clearly define in which model of computation they work and make all assumptions / requirements / statements consistent with this model. There are a few more unrelated issues, see my more specific questions in the ""Questions"" section.\n\nApart from that, I have a whole bunch of secondary comments, see below:\n- I think the paper (implicitly and sometimes explicitly) oversells the contribution of [BPL+16] to amplify the motivation for their own work. So far, reinforcement learning is NOT a state-of-the-art method for combinatorial optimization problems like TSP. The work of [BPL+16] is great as a proof of concept, but statements like ""[BPL+16] [...] generate very good solutions for (Euclidean) TSP instances"" without mentioning that these are very small toy problems should be avoided. I think the fact that NNs for CO are still in their beginnings should be pointed out more clearly and the motivation of this paper should build upon a larger variety of prior work than only [BPL+16].\n- line 103: I suppose you want to refer to Def. 2 and not to Qu. 1 here (in particular, because otherwise you refer to Qu. 1 before even stating it).\n- line 143: I find it more natural to write this with $L(s,I)$ instead of $\\mathcal{O}(s,I)$. I understand that this is the same by definition, but here the focus is more on the cost structure and less on the fact that such an oracle exists. Maybe one could even drop the notation $\\mathcal{O}(s,I)$ everywhere in the paper and use always $L$? In Definition 1, one could instead just write in words that such an oracle exists.\n- line 196: I feel that the split into supervised and unsupervised models here is very artificial because papers in both categories apply sophisticated algorithms mixing very different paradigms. I doubt that the negative result [YGS20] is directly applicable to the settings of the three papers you cite for the supervised case. I suggest not to artificially split the related work into these two categories.\n- Related work: even though of a very different flavor, I think the following two papers about the theoretical ability of neural networks to solve CO problems should be discussed in the related work section: Hertrich, C., & Skutella, M. (2023). Provably good solutions to the knapsack problem via neural networks of bounded size. INFORMS Journal on Computing. AND: Hertrich, C., & Sering, L. (2023). ReLU neural networks of polynomial size for exact maximum flow computation. In International Conference on Integer Programming and Combinatorial Optimization.\n- line 219: please either provide a proof or a reference for the reformulation of the MaxCut problem via the Laplacian.\n- line 241: say that Thm. 4 is in the appendix.\n- line 246: a unknown -> an unknown. Also the whole sentence is a bit hard to read, maybe split into two?\n- line 286: ""the point $\\bar{W}=-\\tau M$ when $\\tau\\rightarrow+\\infty$"" is not a point. What you write here is not mathematically precise, even though I understand what you mean. Consider revising.\n- lines 323/324: I recommend a comma between ""fast"" and ""making"".\n- line 344: there is a ""to"" too much (between ""we"" and ""pick"").\n- line 382: you should not assume that everyone knows what $G(n,p)$ is.'}, 'questions': {'value': '- line 73: why is this the gradient? Please provide some explanation. In particular: where does the logarithm come from?\n- line 75: what do you mean by ""using only access to a solution cost oracle""? Do you want to point out that something particular is not used? If so, what? I suppose you also need to be able to sample $I$ and $s$ according to their respective distributions, and you need to be able to compute the gradient of $log(p(s;I;w))$ w.r.t. $w$.\n- line 96: what is the ""description size of the parameter space $\\mathcal{W}$""? Is it the number of bits required to represent any parameter $w\\in \\mathcal{W}$? But then, $\\mathcal{W}$ is a finite set, so how can you ever perform gradient descent on it?\n- line 99: why do you allow running time polynomial in $1/\\epsilon$, but the parameter space must be polynomial in $\\log(1/\\epsilon)$?\n- line 107: I do not understand what ""the full parametrization of all distributions over the hypercube"" is. There are uncountably many such distributions, so how can you ever represent them in a set $\\mathcal{W}$ of finite description size?\n- Remark 5: Is this a formal statement or an intuitive statement? I really would like to see more details about how exactly the cited paper implies a negative result for neural network solution samplers in the setting of your paper.\n- Remark 6: What if I WANT to encode the weights into the instances? I suppose you would it call ""known"" weights then. But it is less clear how to define the feature maps then and still preserve bilinearity. I do not see why what you call ""unknown"" weights is the more general / difficult case.'}, 'limitations': {'value': 'In principal, the authors provide all details required to understand the scope of their results. The discussion on limitations could be improved by answering the following two questions:\n- Are there natural combinatorial optimization problems to which the framework is not applicable? If so, which problems, and why?\n- It seems like the proposed method is theoretically superior to what people use in practice. Is this true? And if so, why is it not the standard method in practical settings nowadays? Do you expect it to become that?'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper presents a thorough consideration on the parametrization of optimizable solution generators that allow using gradient descent to find solutions for combinatorial optimization methods. They find a set of assumptions that enable complete, compressed and efficiently optimizable representations, in particular existence of feature maps of solution and instances onto bounded (norm, diameter and dimensionality) and variance preserving feature spaces which allow for a bilinear cost oracle $c(I,S)=f_I^T M f_S$ for instance/solution features $f_I/f_S$ and a matrix $M$ s.t. $\\Vert M \\Vert_F\\$ is bounded by a constant $C$.\n\nThe implications of this result (including the existence of such parametrizations for TSP) are discussed, notably that existance of such generators does not mean P=NP since sampling from the generator might still take exponential time.\n\nThe theory is developed on max/min cut, max-k-CSP, max-weight BP matching and TSP and experimentally evalauted on max-cut'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""Originality: I love this paper for taking the obvious in hindsight question for actually asking what types of representations make combinatorial optimisation via first order methods work on a *principles* basis\nClarity: The paper is superbly written and conveys it's ideas and limitations well\nQuality: while I did not have the time to carefully check every brief, on a cursory reading they appear to make sense and align well with intuitions.\nSignificance: I think this paper will completely change how the deep learning community will think about dealing with combinatorial optimization (or at least I hope so)""}, 'weaknesses': {'value': 'I cannot point to any'}, 'questions': {'value': 'None'}, 'limitations': {'value': 'I think everything was addressed'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '10: Award quality: Technically flawless paper with groundbreaking impact, with exceptionally strong evaluation, reproducibility, and resources, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Optimizing Solution-Samplers for Combinatorial Problems: The Landscape of Policy-Gradient Method'}, 'authors': {'value': ['Constantine Caramanis', 'Dimitris Fotakis', 'Alkis Kalavasis', 'Vasilis Kontonis', 'Christos Tzamos']}, 'authorids': {'value': ['~Constantine_Caramanis1', '~Dimitris_Fotakis1', '~Alkis_Kalavasis1', '~Vasilis_Kontonis1', '~Christos_Tzamos1']}, 'keywords': {'value': ['Policy Gradient', 'Combinatorial Optimization', 'Gradient Descent']}, 'TLDR': {'value': 'We theoretically study the problem of optimizing solution-samplers for combinatorial problems via gradient-based methods.'}, 'abstract': {'value': 'Deep Neural Networks and Reinforcement Learning methods have empirically shown great promise in tackling challenging combinatorial problems. In those methods a deep neural network is used as a solution generator which is then trained by gradient-based methods (e.g., policy gradient) to successively obtain better solution distributions.\nIn this work we introduce a novel theoretical framework for analyzing the effectiveness of such methods. We ask whether there exist generative models that (i) are expressive enough to generate approximately optimal solutions; (ii) have a tractable, i.e, polynomial in the size of the input, number of parameters; (iii) their optimization landscape is benign in the sense that it does not contain sub-optimal stationary points. Our main contribution is a positive answer to this question. Our result holds for a broad class of combinatorial problems including Max- and Min-Cut, Max-$k$-CSP, Maximum-Weight-Bipartite-Matching, and the Traveling Salesman Problem. As a byproduct of our analysis we introduce a novel regularization process over vanilla gradient descent and provide theoretical and experimental evidence that it helps address vanishing-gradient issues and escape bad stationary points.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/5faf55cfe724b64002bfc1813849da3fb0cf7fbe.pdf'}, 'supplementary_material': {'value': '/attachment/dda6ab3226bdb4f4616896a90218a06d87097c28.zip'}, '_bibtex': {'value': '@inproceedings{\ncaramanis2023optimizing,\ntitle={Optimizing Solution-Samplers for Combinatorial Problems: The Landscape of Policy-Gradient Method},\nauthor={Constantine Caramanis and Dimitris Fotakis and Alkis Kalavasis and Vasilis Kontonis and Christos Tzamos},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=mmTy1iyU5G}\n}'}, 'paperhash': {'value': 'caramanis|optimizing_solutionsamplers_for_combinatorial_problems_the_landscape_of_policygradient_method'}}]"
"['Yu Bai', 'Fan Chen', 'Huan Wang', 'Caiming Xiong', 'Song Mei']",NeurIPS,Transformers as Statisticians_ Provable In-Context Learning with In-Context Algorithm Selection,https://neurips.cc/virtual/2023/oral/73828,2023," Neural sequence models based on the transformer architecture have demonstrated remarkable \emph{in-context learning} (ICL) abilities, where they can perform new tasks when prompted with training and test examples, without any parameter update to the model. This work first provides a comprehensive statistical theory for transformers to perform ICL. Concretely, we show that transformers can implement a broad class of standard machine learning algorithms in context, such as least squares, ridge regression, Lasso, learning generalized linear models, and gradient descent on two-layer neural networks, with near-optimal predictive power on various in-context data distributions. Using an efficient implementation of in-context gradient descent as the underlying mechanism, our transformer constructions admit mild size bounds, and can be learned with polynomially many pretraining sequences.    Building on these ``base'' ICL algorithms, intriguingly, we show that transformers can implement more complex ICL procedures involving \emph{in-context algorithm selection}, akin to what a statistician can do in real life---A \emph{single} transformer can adaptively select different base ICL algorithms---or even perform qualitatively different tasks---on different input sequences, without any explicit prompting of the right algorithm or task. We both establish this in theory by explicit constructions, and also observe this phenomenon experimentally. In theory, we construct two general mechanisms for algorithm selection with concrete examples: pre-ICL testing, and post-ICL validation. As an example, we use the post-ICL validation mechanism to construct a transformer that can perform nearly Bayes-optimal ICL on a challenging task---noisy linear models with mixed noise levels. Experimentally, we demonstrate the strong in-context algorithm selection capabilities of standard transformer architectures.",Oral 4C COT/reasoning,https://openreview.net/pdf?id=liMSqUuVg9,https://openreview.net/forum?id=liMSqUuVg9,liMSqUuVg9,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'In-context learning is an intriguing emerging ability of large language models. This paper makes important and practically relevant contributions towards understanding in-context learning abilities of transformers. There are more than one solid contributions. First, the authors provide efficient constructions for transformers that can learn regression tasks in-context. Their implementation is significantly more efficient than prior art. Notably, they can use a single attention layer with ReLU activation to approximate one GD step whereas prior works required multiple layers. This is insightful for practical performance of ICL. Secondly, the paper makes good contribution towards understanding model selection ability via in-context learning. For instance, prior work provided insights into Bayes optimal linear regression. This work manages to extend such findings to a broader class of algorithms and provide rigorous insights into the algorithm selection ability of TFs. I should note that there are some shortcomings of the paper that reviewer points out such as the use of ReLU attention rather than the canonical attention. But I find these fairly acceptable. I believe it will make a great addition to NeurIPS 2023 program.'}}, {'title': {'value': 'Summary of concerns and our contributions'}, 'comment': {'value': 'We thank the reviewer again for the thoughtful feedback on our paper, and the many efforts in all the engagement with us. We also appreciate the many constructive suggestions.\n\nAs our discussions went lengthy, here we would like to make a **brief summary (from our perspective) for all main concerns raised by the reviewer collectively after our rebuttal, as a reference point for the reviewer/AC discussions**. Feel free to correct us for any disagreement or add in anything, either over here or in the updated review / internal discussions (as the author-reviewer discussion period is ending soon):\n\n* Explanations of possible mechanisms and ReLU activation\n\n* ICL in MLP: About the ICL capability of MLPs and RNNs\n\n* Novelty of Pretraining results\n\n* ""Main hypothesis of our paper"": with disagreement on whether the reviewer\'s proposal is the main hypothesis of our paper\n\n* Further technical concerns (e.g. positional encoding)\n\nWe provided detailed answers to all concerns above, which can be found by keyword search. We would also love to hear the reviewer\'s thought on our final answers to those questions.\n\nWe also briefly restate **our main contributions from our perspective**:\n1. algorithm selection\n2. theory for ICL, with more efficient constructions, covering more tasks, and analysis of pretraining\n3. experimental validation for both strong ICL performance in ""base"" tasks, and the algorithm selection phenomenon'}}, {'comment': {'value': '> ""Our ICL results (apart from algorithm selection) showed that transformers (i) in theory can achieve good ICL performance... The focus is on the efficiency of the theoretical constructions... ""  \nIt seems that these two points have been demonstrated in previous works, like [1]. Although the authors state they need more layers for approximation, the constructions in this paper need more positional embedding. It is hard to state which is more efficient in theory. \n\n[1] uses a 9-layer transformer to approximate a single SGD step for ridge regression, where our construction use a single-layer transformer to approximate a full-batch GD step, and hence $O(\\log(1/\\epsilon))$ layers to approximately solve the full ERM problem for ridge regression (Theorem 4). Using [1]\'s SGD construction, the number of transformer layers for solving the same ERM would be ${\\rm poly}(1/\\epsilon)$ by standard optimization theory, much higher than ours.\n\nWe additionally provided transformer constructions for Lasso, generalized linear models, and gradient descent for two-layer neural networks, all of which are not considered in [1].\n\n> the constructions in this paper need more positional embedding. \n\nWe believe the positional encoding in [1] is actually more complex than ours (provided in their Appendix C.4.1, Eq (32-34)), which involves one-hot indicator vectors $\\mathbf{e}_i$ where $i$ is the position of the token. By contrast, our positional encoding only involves an indicator for being the final (test) token (cf. our Eq(3)).'}}, {'comment': {'value': ""``Our ICL results (apart from algorithm selection) showed that transformers (i) in theory can achieve good ICL performance, and (ii) experimentally does achieve good ICL performance. The focus is on the efficiency of the theoretical constructions, as well as the ICL performance of learned transformers in experiments (with no restriction on the mechanisms).''\n\nIt seems that these two points have been demonstrated in previous works, like [1]. Although the authors state they need more layers for approximation, the constructions in this paper need more positional embedding. It is hard to state which is more efficient in theory. A comparison of the experimental efficiency between the previous work and the existing work should be provided to support the author's claim.\n\n\n[1] Akyürek E, Schuurmans D, Andreas J, et al. What learning algorithm is in-context learning? investigations with linear models[J]. arXiv preprint arXiv:2211.15661, 2022. \n\n[2] Von Oswald J, Niklasson E, Randazzo E, et al. Transformers learn in-context by gradient descent[J]. arXiv preprint arXiv:2212.07677, 2022.""}}, {'title': {'value': 'Response on concerns about ""main hypothesis"" and ""no new message except the algorithm selection part""'}, 'comment': {'value': 'Thank you for the further reply. We briefly remark on your opinions as follows, and would be happy to further engage. \n\nOur main point here is that ""whether transformers use the constructions provided to implement ICL"" is *not our main hypothesis*, and we believe *not the only important question* (though certainly being one) in the body of work on ICL.\n\n> I think our main disagreement is about the main hypothesis of this paper. In my opinion, the main hypothesis of this paper is that transformers use the constructions provided to implement ICL... The experiments verify a potentially different hypothesis: the gradient-based optimization in practice can find a transformer, which may be different from the constructed transformer here.\n\nWe indeed disagree with the reviewer that ""transformers use the constructions provided to implement ICL"" is our main hypothesis. This is not our intended hypothesis, and we did not phrase our results like that in our paper. If any claim in our paper sounded like that to the reviewer, feel free to point out and we would be happy to clarify in our revision. \n\nOur ICL results (apart from algorithm selection) showed that transformers (i) in theory *can* achieve good ICL performance, and (ii) experimentally *does* achieve good ICL performance. The focus is on the efficiency of the theoretical constructions, as well as the ICL performance of learned transformers in experiments (with no restriction on the mechanisms).\n\n> Previous papers also provide different constructions for different algorithms. To make this paper novel, the main hypothesis should be on the new constructions.\n\nWe believe ""novelty"" of neural network constructions could be a subjective measure; we rather focused on objective measures like concrete bounds on the size (number of layers, heads, etc), which we improved significantly over existing work. \n\nAlso, our algorithm selection constructions are arguably ""novel"", as the target ICL algorithm we approximate there is new (involving selection between multiple base algorithms).\n\n> Otherwise, this is no new message except the algorithm selection part.\n\nWe believe our results on algorithm selection are already interesting contributions on their own. \n\n> I think a very simple way to solve this concern is to check whether the trained transformer in the experiment part demonstrates the periodic property in the construction.\n\nWe agree this is an interesting future direction, and the periodicity experiment you suggested would be a good starting point! However, we believe this is out of the scope of the current paper, and is not necessarily the only important question in the body of work on ICL.'}}, {'comment': {'value': 'Thank the authors for the detailed response. I think our main disagreement is about the main hypothesis of this paper.\n\nIn my opinion, the main hypothesis of this paper is that transformers use the constructions provided to implement ICL.  Previous papers also provide different constructions for different algorithms. To make this paper novel, the main hypothesis should be on the new constructions. Otherwise, this is no new message except the algorithm selection part.\n\nI agree that the theorem statements are already self-contained results, but here the hypothesis means that the theory can be verified by the experiments. The experiments verify a potentially different hypothesis: the gradient-based optimization in practice can find a transformer, which may be different from the constructed transformer here. \n\nI think a very simple way to solve this concern is to check whether the trained transformer in the experiment part demonstrates the periodic property in the construction.'}}, {'title': {'value': 'Response'}, 'comment': {'value': 'Thank you for the reply! Regarding the question\n\n> It seems that the authors prefer the latter claim is correct from the provided response, and the results in this paper cannot serve as sufficient conditions for ICL ability of other networks. In my personal understanding, this means that this paper proposes the hypothesis, i.e., the construction result, to explain the ICL ability of the transformer. I am wondering if the authors could provide some methods to verify these hypotheses.\n\nOur paper indeed focuses on the transformer architecture. In terms of ""explaining"" ICL ability of transformers, we believe there could be (at least) 3 typical methods:\n\n1. Theoretical constructions: Prove there exists a transformer with certain size, that does ICL with certain performance guarantee. But the transformer is not guaranteed to be the one learned in experiments.\n2. Experiments: Find a transformer that achieves strong ICL performance, e.g. one pretrained on massive data by gradient-based optimization.\n3. Further mechanistic understanding about the experimentally learned transformer, for example, whether it indeed implements the theoretically constructed mechanisms.\n\nOur paper already provides results in both 1 and 2. We also answered 3 in one aspect in our algorithm selection experiments, where we showed that learned transformers do implement the (high-level) mechanism of selecting different algorithms for different input data (cf. Figure  2, 3, 5). A more comprehensive study of question 3 would be an important question for future work.\n\n>  ... this paper proposes the hypothesis, i.e., the construction result, to explain the ICL ability of the transformer. I am wondering if the authors could provide some methods to verify these hypotheses.\n\nWe additionally remark that, for our theoretical constructions, the theorem statements are already self-contained results (there exists transformers that achieve good ICL performance...) rather than hypotheses. Our experiments verify a different and stronger hypothesis: gradient-based optimization in practice can find such a transformer.\n\n---\n\nWe thank the reviewer again for the fruitful rounds of discussions. We would love to hear whether you have any additional concerns about our paper, and engage with you in the remaining of the discussion period. Otherwise, we would appreciate if the reviewer can reconsider our contributions and the evaluation of our paper accordingly, based on our discussions.'}}, {'comment': {'value': 'Thank the authors for the detailed response. For the question\n\n""the constructions in the paper are a sufficient condition for ICL, i.e., any NN that can approximate these algorithms will have ICL ability, or they are only a hypothesis to explain the ICL ability of transformer? If the latter is correct, could authors comment on how to verify this hypothesis?""\n\nIt seems that the authors prefer the latter claim is correct from the provided response, and the results in this paper cannot serve as sufficient conditions for ICL ability of other networks. In my personal understanding, this means that this paper proposes the hypothesis, i.e., the construction result, to explain the ICL ability of the transformer. I am wondering if the authors could provide some methods to verify these hypotheses.'}}, {'title': {'value': 'Response'}, 'comment': {'value': 'Thank you for the response and the positive feedback on our paper!\n\nRe extension: Yes, we agree extending our in-context learning results to a seq-to-seq setting (for predicting at every token) would be an interesting direction for future work.'}}, {'title': {'value': 'Response'}, 'comment': {'value': 'Thank you for the response. Yes, we agree this generalizing to \\lambda_new would be an interesting direction for future work.'}}, {'title': {'value': ""Response to further questions (cont'd)""}, 'comment': {'value': '**(Novelty of Pretraining results)**\n\nWe re-emphasize that our pretraining results in Section 5 follow from two parts of results, with the **generalization techniques being only one part of it**:\n* Efficient transformer constructions (Section 3 & 4) for performing various ICL algorithms, with mild bounds on the size of the transformer (number of layers, heads, and weight norms).\n* Generalization bounds for pretraining transformers of a given size (Theorem K.1). However, to apply such bounds, the constructed transformers need to have bounded sizes in the first place.\n\nWe only meant that the techniques for the generalization part are standard; The efficient transformer constructions required new techniques such as new efficient implementation of in-context gradient descent, which we did explain in the paper at length (see, e.g. Section 3.3). \n\n> If the novelty is not the technical part, as mentioned in the rebuttal, I think the contribution here needs more discussion.\n\nIn terms of contributions, the result statements themselves (Theorem K.2-K.4) are already new; no such precise quantitative statements about learning ICL algorithms with transformers have been spelled out in the literature to our knowledge. Further, the setting is interesting (learning an ICL algorithm by transformers on a “meta”-distribution of ICL data distributions; cf. Appendix K.1), and the sample complexities are polynomial and depend mildly on all problem parameters. \n\nWe firmly believe that **these statements themselves are already interesting contributions in their own right** and could motivate follow-up works, even with proof techniques aside. \n'}}, {'title': {'value': 'Response to further questions'}, 'comment': {'value': 'We thank the reviewer for the response. We respond to the additional questions as follows. \n\n**(Explanations of possible mechanisms and ReLU activation)**\n\n>  the explanation in the rebuttal of the softmax in [2] seems pale… this is one possible mechanism to understand softmax… a detailed discussion about this will be very helpful.\n\nApart from the “saturating regime”, the way [2] used softmax is very different from the way we used the ReLU. They used softmax attention, in combination with the MLP layers, to approximate various low-level operations such as “aff, mul, mov”, and used them to approximate the gradient of the square loss. A single gradient step requires multiple low-level operations concatenated, and consequently, they need a 9-layer transformer (cf. their Appendix A) to approximate a single SGD step. \n\nBy contrast, we directly use a single attention layer with ReLU activation to approximate a full-batch GD step, and our construction works for a broader class of convex losses (cf. our Proposition E.1). Technically, it directly uses the attention structure efficiently to approximate gradients, different from [2]. \n\nWe will add a discussion about this in our revision.\n\n> the authors mentioned that the results can be generalized to softmax attention. Could the authors provide the intuitions about how to do this?\n\nOur construction can be generalized to softmax attention as follows: We can use the softmax—in conjunction with a specific positional encoding in the input—to implement (tokenwise) sigmoid activation, and then approximate the gradients using sigmoid in place of the ReLU. See, for example, Giannou et al. (ICML 2023; Lemma 5) for implementing sigmoids from softmax attention. The argument would be in essence the same as ours after obtaining the sigmoid, but overall more tedious compared with our construction using the ReLU.\n\nA. Giannou, S. Rajput, J.-y. Sohn, K. Lee, J. D. Lee, and D. Papailiopoulos. Looped transformers as programmable computers. arXiv preprint arXiv:2301.13196, 2023.\n\n**(ICL in MLP)**\n> In fact, I would like to discuss the RNN, which is an universal approximator. Could authors discuss the ICL ability of RNN?\n\nRNNs could approximate ICL algorithms better than vanilla MLPs, due to their suitability for processing sequential inputs.\n\nHowever, for implementing the ICL algorithms in our paper, we believe **RNNs would still be much more inefficient than transformers**. One reason is that RNNs (in its basic form) only consist of matrix-vector products with fixed weight matrices, and lack the attention mechanism where input tokens themselves can interact with each other. Consequently, key mechanisms we used such as in-context gradient descent (cf. Theorem 9) would be much harder to implement by RNNs than transformers. \n\nA simple analogy would be the dot product $\\langle x_1, x_2\\rangle$: RNNs with layers of the form $\\sigma(W[x_1; x_2])$ may approximate this function very inefficiently (by incurring universal approximation results in high dimension), whereas transformers can approximate this function efficiently using the attention mechanism when $x_1$ is the key and $x_2$ is the value.\n\n> the constructions in the paper are a sufficient condition for ICL, i.e., any NN that can approximate these algorithms will have ICL ability, or they are only a hypothesis to explain the ICL ability of transformer?\n\nOur paper merely provides upper bounds for Transformers to do ICL. While our constructions *suggest* that MLPs/RNNs are unlikely to match transformers in the efficiency of doing ICL, strictly speaking, our upper bounds don’t imply how these alternative architectures will do.\n\nOne way to investigate this further is to establish formal lower bounds for these alternative architectures. This would be an interesting direction for future work, but we believe are out of scope for this paper and do not undermine our contributions, as transformers themselves are already widely used and have demonstrated remarkable ICL capabilities. \n'}}, {'title': {'value': 'Response to Authors'}, 'comment': {'value': 'Thank you for clarifying my doubts. \n\nI have no further questions regarding the paper and I stand by my assessment that the paper is technically solid with high impact.\n\nPS:- One idea/further extension could be to prove a seq-2seq result like in [1] but in context. Note that this does not impact the assessment of this paper.'}}, {'comment': {'value': ""Thanks for the author's reply. Given the rebuttal, I have the following concerns:\n\n(Explanations of possible mechanisms and ReLU activation)\n\nThanks for explaining the perspective where the results in this paper are meaningful. I now accept the approximation view in this paper to study ICL. Given this perspective, the explanation in the rebuttal of the softmax in [2] seems pale. Although they mainly use the saturation part of softmax, this is one possible mechanism to understand softmax, viewed from the perspective explained in the rebuttal. I think a detailed discussion about this will be very helpful. \n\nIn addition, the authors mentioned that the results can be generalized to softmax attention. Could the authors provide the intuitions about how to do this? I think this is unclear from the techniques in the current paper.\n\n(ICL in MLP)\n\nThanks for the detailed explanations of the potential problems in MLP. I am sorry for not providing a clear definition of MLP. In fact, I would like to discuss the RNN, which is an universal approximator. Could authors discuss the ICL ability of RNN?\n\nIn my personal opinion, a very important question related to the main theme of this paper is that: the constructions in the paper are a sufficient condition for ICL, i.e., any NN that can approximate these algorithms will have ICL ability,  or they are only a hypothesis to explain the ICL ability of transformer? If the latter is correct, could authors comment on how to verify this hypothesis? The answer to this question is not clear after reading this paper.\n\n(Novelty of Pretraining results)\n\nThe authors mentioned that `We provide the first line of results for pretraining transformers to perform the various ICL tasks\n75 above, from polynomially many training sequences (Section 5 & Appendix K).' in the introduction. It seems that the pretraining result is one of the main contributions of this paper. If the novelty is not the technical part, as mentioned in the rebuttal, I think the contribution here needs more discussion.\n\n\n""}}, {'comment': {'value': 'Thank you for addressing my questions.\n\nConcerning ""generalizing these hyperparameters"": That is what I meant indeed. I imagine when a transformer is tested for lambda_1, lambda_2, .. it might be able to generalize to lambda_new atleast within the bounds of lambdas seen. This might not work perfectly but an approximation should be learned.\nI have to say this is less of a criticism, this would be another work and does not fit the scope of yours.'}}, {'rebuttal': {'value': 'We thank the reviewer for the strong positive feedback on our paper!'}}, {'rebuttal': {'value': 'We thank the reviewer for the valuable feedback on our paper. We respond to the specific questions as follows.\n\n> …Authors motivate this with an example where the hyperparamter in a linear regression varies. I would expect the transformer to be able to learn to generalize these parameters, given a number of different hyperparamters and pretraining rounds. This would not be akin to algorithm selection but rather a learned mechanism that can learn across hyperparameters. While the work might just give upper bounds here, I imagine these are quite hard to transfer into practice.\n\nWe would appreciate it if the reviewer can clarify this question or provide some concrete examples, as we were unsure if the following interpretation was correct. \n\nBy “generalizing these hyperparameters”, did the reviewer mean e.g. generalizing from a finite set of $\\lambda$ (as in Theorem 11)  to a continuous range of $\\lambda$’s? In other words, can transformer pretrained on finitely many $\\lambda$’s perform near-optimal algorithm selection over continuous $\\lambda$.\n\nIn that case, we believe it may be possible to construct a transformer that achieves this. The technical difficulty would be in the statistical analysis of ridge regression about best $\\lambda$ selection (rather than the transformer construction). While we did not pursue this, we believe this could be an interesting direction for future work.\n\n> …relevant prior work on ""Prior-data fitted networks"" is missing, that demonstrates in-context learning with transformers before the term ""in-context learning"" came up. …\n\nWe thank the reviewer for pointing out the missing references on Prior-data Fitted Networks (PFNs), and will properly cite them in our revision. \n\nOverall, these work on PFNs indeed demonstrates the in-context learning capability (Bayesian optimality) of transformers in various settings. We believe the experiments in these work and the theory in our paper complement each other: Our results essentially show that transformers can efficiently approximate a broad class of ICL algorithms, and we give theoretical constructions for concrete ICL algorithms, such as linear regression, Lasso, and gradient descent on neural networks. Such results for the expressive power and the Bayes-optimality of the resulting transformers were not established in the PFN literature.\n\nAlso, our results are not restricted to the Bayesian setting and can be broaderly applicable for providing frequentist in-context prediction guarantees for transformers.\n\n> (Pretraining rounds for excess risk) the authors provide derivations of multiple tasks in terms of the pretraining rounds needed to train transformers with an excess risk to a given baseline… whether such rules can be made up for more general classes of tasks, such that it would be easier to transfer these results to other tasks? Can polynomial guarantees, e.g. be derived given some computational complexity of the baseline algorithm and task?\n\nWe believe there may indeed be some general conditions for tasks that are learnable in-context by transformers. For example, for any task that i) can be efficiently learnable by gradient descent, and ii) the gradient is approximable by attention layers, we should be able to construct transformers to do ICL and obtain similar polynomial sample complexity guarantees as in our paper. Concretely spelling out such general conditions, and identifying alternative conditions (different from GD) would be an important question for future work.\n\n> … what happens when the pretrained transformer is applied to out-of-distribution data? e.g. linear pretraining applied to sparse linear tasks (algorithmically out of distribution) or when the input data is drawn from another distribiution (e.g. higher variance, colinearity, ..)\n\nMost of our approximation results (e.g. Theorem 4, Corollary 5, Theorem 7, Theorem 11) apply to any such OOD scenario, since the transformers we construct work on any in-context dataset with mild boundedness and non-degeneracy assumptions, with no distributional assumptions required. On the other hand, our pretraining results (Section 5) and experiments focus on the in-distribution setting. \n\nExperimentally, Garg et al. (2022) have conducted extensive empirical studies of ICL in OOD scenarios, with mixed results. Theoretically, we believe characterizing the OOD behavior of pretrained transformers is a major open problem and may require new insights and techniques.\n\n> Are there limits to the number of algorithmic tasks selected by transformers in the selection algorithm?\n\nOur transformer constructions do not have a hard limit on the number of tasks. A larger number of tasks $K$ would require a larger hidden token dimension $D$ to store all the intermediate results, as well as a larger $N$ in order for the validation losses to be faithful estimates of the true losses. See Theorem 11 (formal version in Theorem J.1) for an example.\n\n> Limitations are not clearly addressed, those could include: Theoretical analyses are hard to apply to more realtistic and complex real world tasks…\n\nWe agree that complex real-world tasks could be much more challenging than our setting, especially if the task distributions are more complicated or even consist of language data rather than real-valued data (as in our setting).\n\nWe will add a discussion on this and other limitations of our work in our revision.'}}, {'rebuttal': {'value': 'We thank the reviewer for the valuable feedback on our paper. We respond to the specific questions as follows.\n\n> …rare experimental results are provided to corroborate these constructions. For example, the authors construct transformers that implement one step gradient descent with several layers and repeat this pattern. However, such periodic pattern of network parameters and intermediate results is not shown in the simulation section. Consequently, it becomes challenging to assert that transformers indeed implement the algorithms as stated in the paper.\n\nWe did not mean to show that empirically learned transformers implement gradient descent (GD) in its intermediate layers, and we suspect that alternative mechanisms could exist. GD is rather **one possible mechanism** we use in theory for constructing the transformers.\n\n\n> The authors analyze the attention with ReLu activation function, although this particular activation function is rarely employed in practical designs of attentions. To justify the necessity of analyzing ReLU instead of softmax, it would be beneficial to provide reasoning considering that previous studies, such as [1] and [2], predominantly adhere to the softmax activation function.\n\nFor the purpose of our theory, we believe there is no essential difference between ReLU and softmax. We believe our constructions can be generalized to standard softmax attention with some additional technical treatments. Our choice of ReLU was merely to simplify certain arguments.\n\nExperimentally, we tried out exactly the ReLU architecture we used in our theory (cf. Line 289-291 & Appendix M.1) and it performs well. Other recent studies (e.g. Shen et al. 2023) have also found transformers with ReLU attentions to perform well.\n\nK. Shen, J. Guo, X. Tan, S. Tang, R. Wang, and J. Bian. A Study on ReLU and Softmax in Transformer. arXiv preprint arXiv:2302.06461, 2023.\n\nRe [1,2], we remark that [1] only used **linear attentions** instead of softmax, and the constructions in [2] used softmax in its “saturating regime” where it is approximately a **hard max** (cf. their arXiv version Appendix C.4.1, Page 19). Therefore, neither paper should count as ""predominantly using the softmax activation"" in a strict sense.\n\n> whether the results in this paper imply that MLP can also implement the algorithms in the paper and consequently possess the in-context learning ability.\n\nBy “MLP”, did the reviewer mean an MLP over the concatenated input (a vector in $\\mathbb{R}^{dN}$)? In that case, by the universal approximation property, MLPs can also approximate the ICL algorithms we considered. \n\nHowever, such an MLP would be **significantly more inefficient** (with much larger depth and width) compared with our constructions, as i) the input dimension (and thus the number of parameters) already scales linearly with the sequence length, whereas the size of our transformers do not; and ii) we used the attention layers in efficient ways to implement various operations such as in-context gradient descent (see e.g. Proposition E.1 for an example where the attention structure is crucial), which are unclear how to implement efficiently by MLPs. We will add a discussion about this point in our revision.\n\nFeel free to let us know if we understood the meaning of the ""MLP"" correctly.\n\n> In Corollary 6, the paper derives the estimation error of approximate ridge regression in Bayesian setting, but such Bayesian result is missing for Lasso. It will be helpful to discussion such absence of Bayesian analysis for Lasso.\n\nA Bayesian result for Lasso analogous to Corollary 6 holds directly for linear models with the Laplacian prior (by applying Theorem 7). We stated the result for ridge regression for convenience only (instead of for any fundamental reason), as our main focus was on the later results on adaptive algorithm selection building on these “base” algorithms.\n\n> The generalization error bound in section 5 needs more discussions. Previous works, such as [3] and [4], have derived generalization error bounds for transformers. The novalty of the generalization bound in this paper needs more discussion.\n\nThe sample complexity results in Section 5 (& Appendix M) can be viewed as corollaries of our efficient transformer constructions in Section 3 & 4, where we combine the constructions with standard generalization analysis to derive the sample complexities for pretraining. \n\nWe did not claim technical novelty in the generalization analysis part. Our techniques are indeed standard (by controlling Lipschitz constants + chaining arguments), and alternative techniques like [3,4] may also work here.\n\nThe novelty is rather in the efficient transformer constructions in Section 3 & 4, which ensures that the final sample complexity in Section 5 is mild. Results like [3,4] did not provide such concrete constructions for ICL algorithms, and thus they themselves cannot deduce our sample complexity results.\n\nWe will add a discussion of these points (space permitted) in our revision.\n\n> The limitation section is missing in this paper.\n\nWe appreciate the suggestion, and will properly discuss the limitations of our work in our revision.\n\n---\nWe thank the reviewer again for reading our response. We appreciate it if the reviewer could consider raising the score, if our rebuttal has addressed your concerns.\n'}}, {'rebuttal': {'value': 'We thank the reviewer for the valuable feedback on our paper. We respond to the specific questions as follows.\n\n> How results such as those in [1] compares to the one obtained in this paper.\n\nOur approximation results and [1] are very different. [1] shows that transformers are universal approximators for a large class of sequence-to-sequence functions. However, their result is for generic continuous seq-to-seq functions, and their number of layers is exponential in the worst-case (cf. Section 4.4 of [1]). \n\nBy contrast, **our results are for specific target functions (ICL algorithms) but much more efficient**—The number of layers, heads, and weight norms only depend polynomially on relevant problem parameters and the desired approximation accuracy. This happens as our constructions utilize the special structure of the ICL algorithms (our approximation target). \n\n> The reasoning behind choosing Bayes-optimal ICL on noisy linear models with mixed noise levels.\n\nThere is no fundamental reason behind our choice of noisy linear models with mixed noise levels. Rather, we picked this setting as it is solvable by transformers via algorithm selection, and the setting itself is a harder one than that of Akyurek et al. 2022 which studies a single noise level.\n\n> Was that the most complex method for which something like theorem 12 could be proven?\n\nIf we understand correctly, you mean the most complex “setting” (data generating model)? We believe results like Theorem 12 hold as long as 1) the model is a **mixture model**; 2) Bayes-optimal ICL can be done for each component of the mixture; and 3) $N$ is sufficiently large so that the validation losses are accurate estimations of the true population losses. Under these conditions, algorithm selection (post-ICL validation) can be used to do nearly Bayes-optimal ICL. An example is a mixture of generalized linear models with different link functions.\n'}}, {'summary': {'value': 'In context Learning, is a setting in which Transformers can learn to perform new tasks when prompted with training and test examples. This work advances the understanding of the capabilities of ICL. In particular, this paper proves that for a broad class of standard machine learning algorithms like ridge regression, lasso etc, transformers can implement these methods. Moreover ICL can perform in-context algorithm selection and select simple algorithms to learn a more complex algorithm. They also show that using their proposed method they can construct a transformer that can perform nearly Bayes-optimal ICL on noisy linear models with mixed noise levels. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '* This paper expands upon our understanding of ICL. It shows that transformers can implement a plethora of standard ML tasks and require much mild bounds on the number of layers and heads. \n* The paper extends the analysis to in-context algorithm selection and provides two algorithm selection mechanisms. They use the proposed mechanism to construct a transformer that can perform Bayes optimal ICL on noisy linear models. \n* This works opens up new directions to explore (theoretically and empirically) optimal ICL construction on other problems\n* The paper is well written and easy to follow \n'}, 'weaknesses': {'value': '* It would be good to know how results such as those in [1] compares to the one obtained in this paper.\n\n[1] Are transformers universal approximators of sequence-to-sequence functions? a'}, 'questions': {'value': 'what was the reasoning behind choosing Bayes-optimal ICL on noisy linear models with mixed noise levels as an example to show case the usefulness of in context algorithm selection? Was that the most complex method for which something like theorem 12 could be proven? '}, 'limitations': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper theoretically investigate the in-context learning ability from the approximation view. The authors derive the error bound of approximating  least squares, ridge regression, and Lasso algorithms with transformer. The corresponding statistical properties, i.e., the convergence rate and Bayes suboptimality, are derived for transformers. In addition, the authors show that transformers are also able to implement the algorithm selection. Simulation results are provided to verify the theoretical findings.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': 'This paper presents solid error bound for transformer to approximate different kinds of algorithms, which are interesting for the approximation theory of neural networks. The corresponding convergence rates for different algorithms are relevant for explaining the in-context learning behavior of transformer. In addition, the approximation results for the algorithm selection unit are noval in the investigation of in-context learning.'}, 'weaknesses': {'value': '1. Although this paper provides extensive parameters assignments to show that transformer can implement a series of algorithms, rare experimental results are provided to corroborate these constructions. For example, the authors construct transformers that implement one step gradient descent with several layers and repest this pattern. However, such periodic pattern of network parameters and intermediate results is not shown in the simulation section. Consequently, it becomes challenging to assert that transformers indeed implement the algorithms as stated in the paper.\n\n2.  The authors analyze the attention with ReLu activation function, although this particular activation function is rarely employed in practical designs of attentions. To justify the necessity of analyzing ReLU instead of softmax, it would be beneficial to provide reasoning considering that previous studies, such as [1] and [2], predominantly adhere to the softmax activation function.\n\n3. Given the approximation results in the paper of transformers with ReLu activation and the fact that Multi-Layer Perceptrons (MLP) are universal approximators of continuous functions, it is beneficial to discuss that wether the results in this paper imply that MLP can also implement the algorithms in the paper and consequently possess the in-context learning ability.\n\n4. In Corollary 6, the paper derives the estimation error of approximate ridge regression in Bayesian setting, but such Bayesian result is missing for Lasso. It will be helpful to discussion such absence of  Bayesia analysis for Lasso.\n\n5. The generalization error bound in section 5 needs more discussions. Previous works, such as [3] and [4], have derived generalization error bounds for transformers. The novalty of the generalization bound in this paper needs more discussion.\n\nI am happy to change my evaluation if the authors can answer the above questions.\n\n[1] Von Oswald J, Niklasson E, Randazzo E, et al. Transformers learn in-context by gradient descent[J]. arXiv preprint arXiv:2212.07677, 2022.\n\n[2] Akyürek E, Schuurmans D, Andreas J, et al. What learning algorithm is in-context learning? investigations with linear models[J]. arXiv preprint arXiv:2211.15661, 2022.\n\n[3] Edelman B L, Goel S, Kakade S, et al. Inductive biases and variable creation in self-attention mechanisms[C]//International Conference on Machine Learning. PMLR, 2022: 5793-5831.\n\n[4] Zhang Y, Liu B, Cai Q, et al. An Analysis of Attention via the Lens of Exchangeability and Latent Variable Models[J]. arXiv preprint arXiv:2212.14852, 2022.\n\n'}, 'questions': {'value': 'The questions are listed in the previous section.'}, 'limitations': {'value': 'The limitation section is missing in this paper.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'They take an in-depth empirical and also theoretical analysis of the in-context learning abilities of transformers on various tasks. Their theoretical analysis of the learned algorithms is especially strong. The work in my eyes presents an extension of previous works in this field to more complex ICL problems (like least squares, ridge regression, Lasso). They identify mechanisms which transformers can learn by which a number of ICL tasks can be performed.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The submission is technically sound and very detailed in its explanations and supplements.\nThe work extends previous studies on in-context learning. They provide in-depth and very relevant analyses for a number of simple ICL tasks. I do, however, wonder in which ways this work can be of practical relevance. For language modelling, the tasks and architectural sizes are quite different to these evaluated toy tasks. For learning optimization methods, it would be interesting to provide more general bounds for ICL analysis which could be used to transfer to more relevant tasks. Also, it would be interesting to see if the provided analyses could be used to make modifications to the transformer architecture. I understand the scope of this work is huge already and this work might exactly enable these kinds of follow-ups.\n(Capability of transformers for ICL) In my eyes it seems rather obvious that the demonstrated capabilities can be learned through transformers, given that these architectures are able to model far more complex tasks. \n(Architectural choices for ICL) From a practical perspective the suggestions for optimal choices seem less relevant as of now (e.g. which architectural parameters work well in practice for modelling certain ICL aspects), since architectural choices are studied in isolation and only for toy problems. However, theoretical upper bounds on architectural choices seem interesting and seem to provide interesting ways in which to modify and analyse architectures for enhanced ICL.\n'}, 'weaknesses': {'value': 'I do at times wonder if the theoretical derivations on the capabilities of in-context learning do hold up in practice. Take for example Pre-ICL. Authors motivate this with an example where the hyperparamter in a linear regression varies. I would expect the transformer to be able to learn to generalize these parameters, given a number of different hyperparamters and pretraining rounds. This would not be akin to algorithm selection but rather a learned mechanism that can learn across hyperparameters. While the work might just give upper bounds here, I imagine these are quite hard to transfer into practice. \n\nThe capability of transformers to learn various tasks in in-context learning has been known for quite some time. I think some relevant prior work on ""Prior-data fitted networks"" is missing, that demonstrates in-context learning with transformers before the term ""in-context learning"" came up:\nTransformers Can Do Bayesian Inference (ICLR 2022): This work studies if Transformers can in-context learn algorithmic tasks (such as Gaussian Processes and MLPs), to my knowledge the first work to do so (e.g. prior to Garg and Ayurek) and with an eye of the Bayesian approximation learned in ICL. They show e.g. Gaussian Processes and MLPs can be approximated by transformers, demonstrating hyperparameter selection and deriving the Bayesian approximation capabilities of transformers.\nStatistical Foundations of Prior-Data Fitted Networks (ICML 2023)\nTabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second (ICLR 2023): Studies the ability of in-context learning for tabular datasets. It also evaluates task mixtures and shows that transformers are able to model complex algorithmic tasks through ICL.'}, 'questions': {'value': '(Pretraining rounds for excess risk) the authors provide derivations of multiple tasks in terms of the pretraining rounds needed to train transformers with an excess risk to a given baseline. These results are interesting and demonstrate that for a variety of tasks such bounds can be found. I wonder weather such rules can be made up for more general classes of tasks, such that it would be easier to transfer these results to other tasks? Can polynomial guarantees, e.g. be derived given some computational complexity of the baseline algorithm and task?\n\nDid you study what happens when the pretrained transformer is applied to out-of-distribution data, e.g. linear pretraining applied to sparse linear tasks (algorithmically out of distribution) or when the input data is drawn from another distribiution (e.g. higher variance, colinearity, ..)\n\nAre there limits to the number of algorithmic tasks selected by transformers in the selection algorithm?'}, 'limitations': {'value': 'Limitations are not clearly addressed, those could include: Theoretical analyses are hard to apply to more realtistic and complex real world tasks. The analyses are difficult to perform even for the simple tasks shown in this work, probably for most complex tasks infeasable?'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': '1. The authors prove that transformer models can perform several machine learning tasks, such as least squares, ridge regression, lasso and learning of GLMs.\n2. The authors prove that transformer models can select an algorithm from a pool of possible ones, in two scenarios, post ICL validation and pre ICL testing, and thus can perform in context learning.\n3. The authors construct a transformer model with near Bayes-optimal performance on linear models with mixed noise levels\n4. The authors prove polynomial sample complexity results for pretraining transformers to perform ICL.\n5. Experimentally, the authors show that transformer models can indeed perform algorithm selection in context. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. The level of clarity and writing is very good.\n2. The theoretical contributions are insightful\n3. The experimental results support the theoretical arguments\n4. The scope of the work is broad and deep.'}, 'weaknesses': {'value': 'I do not recognize any major weakness'}, 'questions': {'value': '--'}, 'limitations': {'value': '--'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection'}, 'authors': {'value': ['Yu Bai', 'Fan Chen', 'Huan Wang', 'Caiming Xiong', 'Song Mei']}, 'authorids': {'value': ['~Yu_Bai1', '~Fan_Chen4', '~Huan_Wang1', '~Caiming_Xiong1', '~Song_Mei1']}, 'keywords': {'value': ['in-context learning', 'transformers', 'deep learning theory', 'learning theory']}, 'abstract': {'value': ""Neural sequence models based on the transformer architecture have demonstrated remarkable \\emph{in-context learning} (ICL) abilities, where they can perform new tasks when prompted with training and test examples, without any parameter update to the model. This work first provides a comprehensive statistical theory for transformers to perform ICL. Concretely, we show that transformers can implement a broad class of standard machine learning algorithms in context, such as least squares, ridge regression, Lasso, learning generalized linear models, and gradient descent on two-layer neural networks, with near-optimal predictive power on various in-context data distributions. Using an efficient implementation of in-context gradient descent as the underlying mechanism, our transformer constructions admit mild size bounds, and can be learned with polynomially many pretraining sequences.\n    \nBuilding on these ``base'' ICL algorithms, intriguingly, we show that transformers can implement more complex ICL procedures involving \\emph{in-context algorithm selection}, akin to what a statistician can do in real life---A \\emph{single} transformer can adaptively select different base ICL algorithms---or even perform qualitatively different tasks---on different input sequences, without any explicit prompting of the right algorithm or task. We both establish this in theory by explicit constructions, and also observe this phenomenon experimentally. In theory, we construct two general mechanisms for algorithm selection with concrete examples: pre-ICL testing, and post-ICL validation. As an example, we use the post-ICL validation mechanism to construct a transformer that can perform nearly Bayes-optimal ICL on a challenging task---noisy linear models with mixed noise levels. Experimentally, we demonstrate the strong in-context algorithm selection capabilities of standard transformer architectures.""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'Transformers can learn in context like statisticians --- A single transformer can select different algorithms for different data at hand.'}, 'pdf': {'value': '/pdf/56b8f3ee4bb98edac7d196156e54e2b17c966c99.pdf'}, '_bibtex': {'value': '@inproceedings{\nbai2023transformers,\ntitle={Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection},\nauthor={Yu Bai and Fan Chen and Huan Wang and Caiming Xiong and Song Mei},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=liMSqUuVg9}\n}'}, 'paperhash': {'value': 'bai|transformers_as_statisticians_provable_incontext_learning_with_incontext_algorithm_selection'}}]"
"['Junfeng Fang', 'Wei Liu', 'Yuan Gao', 'Zemin Liu', 'An Zhang', 'Xiang Wang', 'Xiangnan He']",NeurIPS,Evaluating Post-hoc Explanations for Graph Neural Networks via Robustness Analysis,https://neurips.cc/virtual/2023/oral/73839,2023," This work studies the evaluation of explaining graph neural networks (GNNs), which is crucial to the credibility of post-hoc explainability in practical usage. Conventional evaluation metrics, and even explanation methods -- which mainly follow the paradigm of feeding the explanatory subgraph and measuring output difference -- always suffer from the notorious out-of-distribution (OOD) issue. In this work, we endeavor to confront the issue by introducing a novel evaluation metric, termed O OD-resistant A dversarial R obustness (OAR). Specifically, we draw inspiration from the notion of adversarial robustness and evaluate post-hoc explanation subgraphs by calculating their robustness under attack. On top of that, an elaborate OOD reweighting block is inserted into the pipeline to confine the evaluation process to the original data distribution. For applications involving large datasets, we further devise a Sim plified version of OAR (SimOAR), which achieves a significant improvement in computational efficiency at the cost of a small amount of performance. Extensive empirical studies validate the effectiveness of our OAR and SimOAR.",Oral 5A GNNs/Invariance,https://openreview.net/pdf?id=eD534mPhAg,https://openreview.net/forum?id=eD534mPhAg,eD534mPhAg,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The reviewers are all excited about this work and unanimously recommended acceptance. \n\nAmong all strengths that reviewers mentioned, this paper is particularly well motivated and focuses on a very important problem, tackling a gap between on evaluating the explanation for GNN. The detailed discussion on the drawbacks of different evaluation protocols is also appreciated. The experimental study is solid, with user study and diverse criteria.'}}, {'comment': {'value': ""I appreciate the comprehensive reply and the extra experiments you conducted. They have resolved most of my inquiries and worries. Having gone through the other reviews, I'm content to keep my initial rating. ""}}, {'comment': {'value': 'Thank you for your detailed response and the additional experiments. These have addressed the majority of my questions and concerns. After reading the other reviews, I am pleased to maintain my original score. I appreciate the effort and insights the authors put into the paper.'}}, {'title': {'value': 'Response to Reviewer xH8P'}, 'comment': {'value': 'Dear Reviewer xH8P,\n\nI would like to express my sincere gratitude to you for recognizing and providing constructive feedback on our work, which has been invaluable in refining it.\n\nFollowing your comments regarding node classification, we have incorporated the experimental details in the revision. Specifically, for each node in the input graph, **we construct an ego graph for it based on the number of layers in the baseline GNN.** Then, the explanation task for node classification can be transferred to the explanation task for graph classification. Furthermore, the remaining hyperparameters and methods in our OAR/SimOAR remain unchanged.\n\nOnce again, I would like to extend my sincere appreciation for the time and effort you have dedicated to the review process! We truly value the importance of your input in our professional journey!\n\nBest regards,\n\nAuthors\n'}}, {'comment': {'value': 'Thank you for your very detailed review and in particular for the additional experiments.\n\n#### W1+W2\nThank you for rearranging the paper structure and expanding the related work section. In particular, I appreciate that the authors extend this discussion into new experimental results. The results provide further support for their proposed method. I agree that [6] can just be discussed and does not warrant experiments as a baseline. \n\n#### Q1, Q2, Q3, Q5, Q7\nThank you for providing additional details for these questions. I also appreciate here taking the extra effort to create the additional node classification experiment. Can you describe a bit how you adapted OAR to the node setting?\n\n#### Q4\nThank you for taking the time to also try this experiment.\n\n#### W3, Q6\nWhile I am not fully convinced by the argument, I agree with SimOAR as an inspectable alternative to the full VGAE-OAR version. The reason why I am saying I am not fully convinced is that there are differences in performance, even when we help SimOAR with spectral information (from the experiment in Q6).\n\nOverall, I really like the new information from this rebuttal phase. The authors provided four new sets of experiments. They embedded current GNN explanation work in their framework, extended to Node classification, found improvements with L1 regularization and furher compared to a spectral baseline. My assessment of losing inspectability was too pessimistic because of SimOAR, although it lacks slightly behind in performance. Therefore, I increase my score.\n'}}, {'title': {'value': 'Response to Reviewer QMrv'}, 'comment': {'value': 'Dear Reviewer QMrv,\n\nI would like to express my heartfelt gratitude to you for recognizing our work. Your insightful guidance and constructive suggestions have undoubtedly played a vital role in improving the quality of our work. \n\nI would also like to extend my sincere appreciation for the time and effort you have dedicated to the review process. We truly value the importance of your input in our professional journey!\n\nWith warm regards,\n\nAuthors\n'}}, {'title': {'value': 'Response to Authors and raise score from 7 to 8'}, 'comment': {'value': 'Thank you for answering my comments. Your response address the concerns I had, and I will raise my score.'}}, {'rebuttal': {'value': 'Dear Reviewers:\n\nWe gratefully thank you for your valuable comments! We were encouraged to hear that our work has **clear and well-written presentations** (by all Reviewers), **well-designed and interesting technical contributions** (by Reviewer QMrv and vGHJ), **extensive and sufficient experiments** (by all Reviewers), which **addresses a critical and emerging issue** to the research community (by Reviewer uvv7 and vGHJ). \n\nHere we meticulously give point-by-point responses to your comments, and further add the additional experiments and figures into the one-page supplementary PDF. Especially, we have taken measures to enhance the structure of the Introduction and Related Work section, and provided a more rigorous definition of our methods. Furthermore, we have provided a more detailed description of our experimental settings and included a wider range of representative baselines and datasets for conducting additional experiments. We hope that our responses adequately address all your concerns and meet the expectations of the conference committee.\n\nOnce again, we sincerely appreciate your time and effort in reviewing our paper. Your constructive criticism has been invaluable in refining our work, and we are more than happy to add clarifications to address any additional recommendations and reviews from you!\n\nBest, \n\nAuthors \n'}, 'pdf': {'value': '/pdf/b8616b2a912d6b864810dad4a6edce18a6480865.pdf'}}, {'rebuttal': {'value': '*Dear Reviewer vGHJ:*\n\n*Thank you for the thoughtful feedback! Your constructive criticism has been invaluable in refining our work. Below, we give point-by-point responses. Hope our responses could address your concern!*\n\n>*W1 & W2: Concern about the training process in OAR, while SimOAR addresses the above concern but degrades the performance.*\n\nThanks for your concern. We agree that the training process of OAR is complex and time-consuming. In fact, we have delved into this issue in **Appendix F** (Line 175-185) of the main paper. Specifically, \n\n1. We believe that  learning distribution information from this training process  is inevitable to address the problem of OOD. Here is the reason: \n\n    - Explanation (which is indeed the process of sampling subgraphs from inputs) would inevitably introduce the risk of OOD. While to measure this OOD, it is necessary to obtain the distribution information.\n\n2. Although SimOAR is a compromise which degrades the performance, we believe that the experimental results of OAR and SimOAR precisely demonstrate the potential optimization space. Concretely, **OAR and SimOAR represents two extremes:** OAR accurately acquires distribution to combat OOD, while SimOAR completely abandons this acquisition to improve efficiency. It naturally inspired the future optimized directions: \n    - On the one hand, we can find a balance between accuracy (OAR) and speed (SimOAR) to adapt to different tasks.\n    - On the other hand, we can explore more efficient generative algorithms that require less acquisition of distribution information, such as diffusion models, to optimize both accuracy and speed simultaneously.\n\n>*W2: It would also be beneficial to include different types of post-hoc methods.* \n\nThanks for your suggestion. Following your guidance, we have conduct additional experiments across three types of post-hoc methods to validate the effectiveness of our OAR. Limited by the short rebuttal time, we only select one method for each type (*i.e.*, decomposition: **GNN-LRP**, surrogate: **PGMExplainer**, generation: **XGNN**) on BA3 and MNIST-sp. Moreover, we noticed that you are interested in **GSAT** in the following comments, hence, we also conduct the **GSAT** (in its post-hoc mode).\n\nHere are the results (corresponding to Figure 3 in the main paper): \n\n|||BA3|||\n|:-:|:-:|:-:|:-:|:-:|\n||PGMExplainer|GNN-LRP|XGNN|GSAT|\n|RM|0.341|0.355|0.307|0.386|\n|DSE|0.409|0.412|0.367|0.370|\n|OAR|**0.488**|**0.525**|**0.505**|**0.463**|\n|SimOAR|0.463|0.500|0.482|0.432|\n||||||\n\n|||MNIST-sp|||\n|:-:|:-:|:-:|:-:|:-:|\n||PGMExplainer|GNN-LRP|XGNN|GSAT|\n|RM|0.302|0.323|0.287|0.342|\n|DSE|0.314|0.340|0.341|0.317|\n|OAR|**0.546**|**0.583**|**0.520**|**0.554**|\n|SimOAR|0.542|0.548|0.499|0.530|\n||||||\n\nWe will continue to conduct more complete experiments across other post-hoc methods and add them into the reversion.\n\n>*Q1: Concern about the usage of  ""adversarial"" and ""attack"".*\n\nWe are sorry for making you confused. Specifically, our adversarial robustness mean that “How adversarial are random perturbations against the original data distribution, which are measured by OOD score”?\n\nHere are two more reasons why we named our attack as **adversarial attack**: \n\n- First, the starting point of our methods is finding the minimum perturbation leading to the wrong prediction (Line 128-132 in the main paper). However, this target is proved to be hard to reach and sometimes even intractable in the scenario given in the paper (Line 144-151). Thus, we transfer to approximate it from its dual perspective. That is, calculating the largest changes of outputs under the attacks. Hence, **our approach is essentially derived from the adversarial attack.**\n\n- Moreover, here are the imposed objective and the target of the *adversarial attack* and *our attack in OAR*, which are similar with each other:\n\n||Objective|Target|\n|:-:|:-:|:-:|\n|Adversarial Attack|**selected part of input** (*which is selected by the attack algorithm*)|**perturb output as much as possible** (*until flip the outputs*)|\n|Attack in Our OAR|**selected part of input** (*which is selected by the explanations*)|**perturb output as much as possible** (*to see the robustness*)|\n||||\n\n>*Q2: How is the metric RM calculated mathematically?*\n\nIn our paper, Removal-based metric (RM) is employed to quantify the fidelity of the explanations. More formally, for an input graph $G$ and an explanation (subgraph) $G_s$, RM believes that a good explanation should have a large $f(G)-f(G_s)$, where $f$ is the GNN.\n\n>*L1: How would OAR generalize to other tasks?*\n\nThanks for your concern. Following your comments, we have conducted experiments across several prevalent **node classification** datasets following [1]. \n\nHere are the results:\n\n||BA-Shapes|BA-Community|Tree-Cycles|Tree-Grid|\n|:-:|:-:|:-:|:-:|:-:|\n|RM|0.312|0.321|0.295|0.411|\n|DSE|0.406|0.377|0.343|0.384|\n|OAR|**0.542**|**0.560**|**0.489**|**0.440**|\n|SimOAR|0.527|0.535|0.471|0.431|\n||||||\n\nAccording to these results, we can find that our OAR and SimOAR can work well for the task of node classification.\n\n*[1] GNNExplainer: Generating Explanations for Graph Neural Networks. NIPS 2019*\n\n>*L2: Can the idea in OAR help self-explainable methods?*\n\nThanks for your concern. Yes, it can. The evaluation target of OAR is the explanation (subgraph). Hence, any algorithm which generate explanations can be evaluated by OAR. \n\nFollowing your concern, we have conducted the experiments on GSAT:\n\n|||GSAT|||\n|:-:|:-:|:-:|:-:|:-:|\n|| BA3 | MUTAG | TR3 |MINST|\n|RM|0.376|0.381|0.402|0.337|\n|DSE|0.411|0.425|0.417|0.319|\n|OAR|**0.613**|**0.590**|**0.585**|**0.606**|\n|SimOAR|0.598|0.572|0.552|0.581|\n||||||\n\nThese results validate that our OAR can help self-explainable methods.\n\n*Once again, we sincerely appreciate your time and effort in reviewing our paper. Your criticism has been invaluable in refining our work, and we are more than happy to add clarifications to address your concerns!*\n\n*Best,*\n\n*Authors*'}}, {'rebuttal': {'value': '*Dear Reviewer uvv7:*\n\n*We gratefully thank you for your valuable comments! Here we meticulously give point-by-point responses to your comments. Hope that our responses could address your concerns!*\n\n>**W1: Figure 1 is kind of hard to follow. It could be better if authors can refine it.**\n\nThanks for your concern. Following your suggestion, we have made significant refinements to improve its clarity. The refined version provides a more coherent representation of the information it conveys, as shown in the new added *Supplementary PDF*.\n\nThe following are some specific modifications: \n\n- We have extracted the common parts of Figure 1 (a), Figure 1 (b), and Figure 1 (c), and placed them together to avoid repetition. We have also added appropriate textual descriptions to make them easier to understand. \n\n- We have increased the font size to match the text in the main body. \n\n- We have provided detailed illustrations of Figure C (our algorithm OAR) to demonstrate the process of our algorithm more intuitively and smoothly.\n\nWe hope that the revised Figure 1 now effectively supports the content and contributes to the comprehension of our research.\n\nThanks again for your valuable suggestion!\n\n>**W2: Some experiment setting is missing. For example, what is the setting of the GAE? What is the number of the generated graph?**\n\nThanks for your concern. For the setting of the GAE, please refer to **Line 138-140** in Appendix C;  for the number of the generated graph, please refer to **Line 160-161** in Appendix C, where we point out that for BA3, TR3, and MUTAG, the number of perturbed subgraphs $N_{perturb}$ is 20, while for MNIST-sp, the number of perturbed subgraphs $N_{perturb}$ is 50 owing to its large size.\n\nWe agree with your concern about the absence of these important parameters in the main paper. Hence, following your suggestion, **we have moved them from the Appendix C to the Experimental Setup** section in the main paper of the revised version. We hope that this modification could enhance the readability and reproducibility of our paper.\n\n>**W3: Lack of related work, and some important reference is missing. For example, the authors could add a section introduce the explanation methods for GNN according to [1].**\n\nThanks for your concern. Based on your recommendation, we have included the missing reference [1] within the Related work section in the main paper, ensuring proper attribution to the original work. \n\nFurthermore, following your suggestion, we have introduced the current trustworthy GNNs from six aspects (robustness, explainability, privacy, fairness, accountability, and environmental well-being) in the Related Work following [1].\n\nBy incorporating these suggested changes, we believe that we have enriched the manuscript and provided readers with a more comprehensive understanding of the explanation methods for GNN.\n\n[1] Zhang, He, et al. ""Trustworthy graph neural networks: Aspects, methods and trends."" arXiv preprint arXiv:2205.07424 (2022).\n\n*Thank you for drawing our attention to these important aspects. Your valuable feedback has greatly enhanced the quality of our research. If you have any further **recommendations** or require additional **clarification**, please do not hesitate to let us know.*\n\n*Best,*\n\n*Authors*\n'}}, {'rebuttal': {'value': ""**Dear Reviewer QMrv:**\n\n**Thank you for the thoughtful feedback! Your constructive criticism has been invaluable in refining our work. Below, we give point-by-point responses to your comments. Hope that our responses could address all your concerns!**\n\n\n>*W1 & Q1: Does the adversarial robustness mean that “How adversarial are random perturbations against the original data distribution, which are measured by OOD score”?*\n\nThanks for your concern. Yes, it does. \n\nHere are two more reasons why we named our methods OAR (OOD-resistant **adversarial** robustness): \n\n- First, the starting point of our methods is finding the minimum perturbation leading to the wrong prediction (Line 128-132 in the main paper). However, this target is proved to be hard to reach and sometimes even intractable in the scenario given in the paper (Line 144-151). Thus, we transfer to approximate it from its dual perspective. That is, calculating the largest changes of outputs under the attacks. Hence, **our approach is essentially derived from the adversarial attack.**\n\n- Moreover, here are the imposed objective and the target of the *adversarial attack* and *our attack in OAR*, which are similar with each other:\n\n|               |    &emsp; &emsp;&emsp; &emsp; &emsp; &emsp; Objective  |   &emsp; &emsp;&emsp; &emsp; &emsp; &emsp;Target  | \n|:-------------:|:--------:|:--------:|\n|     Adversarial Attack    |   **selected part of input** (*which is selected by the attack algorithm*)   |   **perturb output as much as possible** (*until flip the outputs*)    |   \n|     Attack in Our OAR   |   **selected part of input** (*which is selected by the explanations*)  |   **perturb output as much as possible** (*to see the robustness*)   |  \n||||\n\nMoreover, following your suggestion, we have added these clarifications into the Introduce Section in the reversion. We believe that this will greatly increase the readability, coherence, and comprehensibility of the article.\n\nThanks again for your valuable suggestion!\n\n>*W2 & Q2: How many perturbed subgraphs are needed?*\n\nPlease refer to Line 160-161 in Appendix, where we point out that for BA3, TR3, and MUTAG, the number of perturbed subgraphs $N_{perturb}$ is 20, while for MNIST-sp, the number of perturbed subgraphs $N_{perturb}$ is 50 owing to its large size.\n\n>*W3 & Q3: What is the influence of VGAE quality on the OAR performance?*\n\nThanks for your concern. The quality of VGAE will have a certain impact on the performance of OAR, but it is not significant. Here is the reason:\n\n- The simplified version of OAR -- SimOAR (which can be viewed as the case that the VGAE is poorly trained and produces random scores) -- performs close to OAR. It indicates that the performance of VGAE does not significantly impact OAR's performance, and further demonstrates that the effectiveness of our OAR and SimOAR is mainly attributed to the preferable paradigm, instead of the other module (e.g., VGAE). \n\n**Once again, we sincerely appreciate your time and effort in reviewing our paper. Your constructive criticism has been invaluable in refining our work, and we are more than happy to add clarifications to address any additional recommendations and reviews from you!**\n\n**Best,**\n\n**Authors**\n""}}, {'rebuttal': {'value': ""Thank you very much for your valuable comments. We hope that the following reply could address your concerns!\n\n\n>**W1: Concerns about the Introduction and the missing related work [1-5].**\n\nThanks for bringing this point to us. Following your suggestions, we have implemented the following changes in the response and our revision:\n\n1. **Introduction & Related Work Organization**. The 'Introduction' section has been revamped to streamline previous studies. The 'Related Work' section has been added into the main paper.\n\n2. **Literature View**. We appreciate your introduction to references [1-5] and have incorporated them into the 'Related Work' section. These papers primarily classify current metrics into four categories: accuracy, faithfulness, stability, and fairness. Notably, OAR align with the 'faithfulness' metric.\n\n3. **Evaluation Metric & Dataset**. Drawing from references [1-5], we've specifically adopted the contemporary faithfulness metric, GEF [3], and the latest synthetic dataset, SHAPEGGEN [3], to enhance our paper. We utilized these resources to perform additional experiments, with the outcomes presented in the table below and Table 1 of the main paper. \n\n||SHAPEGGEN|TR3|MUTAG|MNIST|BA3|\n|:-:|:-:|:-:|:-:|:-:|:-:|\n|GEF|0.800|0.734|0.800|0.934|0.734|\n|SimOAR|0.800|0.867|0.800|0.934|0.934|\n|OAR|0.867|0.934|1.000|0.934|1.000|\n|||||\n\n> **W2: [6] might be worth discussing/comparing to.**\n\nThanks for your suggestion. We have incorporated a discussion on CoGE [6] in our revision. \n\nIn essence, although CoGE can determine if a subgraph is associated with the OOD class, it fails to provide a precise score delineating the OOD degree, making it coarser compared to OAR. \n\nMoreover, CoGE is more aligned with explanation methodologies rather than functioning as an evaluation framework, which is why we did not select it as a baseline. \n\nWe hope this classification addresses your concerns!\n\n> **W3: Concerns about transferring the trust problem from the GNN to the VGAE.**\n\nThank you for highlighting this important aspect. While we recognize the concerns of transferring trust to VGAE with OAR, we assert that its impact is relatively minimal for several reasons:\n\n1. **VGAE-guided OAR**. Indeed, the trust and accuracy of VGAE is important to evaluate the explanation faithfully. However, we are optimistic that as generative research (e.g., diffusion models) advances, emerging generation ability will mitigate this limitation.\n\n2. **VGAE-free SimOAR**. Our streamlined variant, SimOAR, sidesteps VGAE altogether. Instead, it utilizes transparent heuristics for perturbation generation. This strategic choice inherently counteracts the transfer of trust issues from GNN to VGAE.\n\n3. **Performance Insights**. As Table 1 shows, SimOAR is slightly worse or on par with OAR, but outperforms all baselines. This underscores the idea that VGAE's influence is minimal.\n\nWe're grateful for your insightful suggestions, and we will incorporate them into the reversion.\n\n>**Q1: Expand the setting of user study following checklist.**\n\nThanks for your suggestions. We have detailed the setting following checklist and incorporated it into our revision:\n\n1. **Instructions.** Each participant was asked to check 5 groups of graphs as shown in Appendix D and answer which subgraph is best preserves digital information.\n2. **Risks.**  Our user study do not have any risks.\n3. **Wage.** The participants in our user study were volunteers. \n\n>**Q2: How to creat the MNIST-sp?**\n\nWe created the MNIST-sp according to [1]. Specifically, the node features are the pixels' values and the  pixels' centers. Edges are the spatial distance between the superpixel centers.\n\n*[1] Geometric deep learning on graphs and manifolds using mixture model cnns. CVPR. 2017*\n\n>**Q3: Does the attacks allow adding and deleting nodes?**\n\nNo, our attacks are only allowed to happen in the given adjacency matrix. We will explore the addition/deletion of nodes in future work.\n\n>**Q4: If OAR would benefit from penalizing surplus nodes.**\n\nFollowing your recommendations, we integrated the L1-norm for explanation size control. Experiments exhibted in the following and the Table 1 of the main paper, verify that the Component you suggested indeed enhances our methods.\n\n||TR3|MUTAG|MNIST|BA3|\n|:-:|:-:|:-:|:-:|:-|\n|SimOAR|0.867|0.800|0.934|0.934|\n|SimOAR+L1|**0.934**$\\uparrow$|0.800|0.934|**1.000**$\\uparrow$|\n|OAR|0.934|1.000|0.934|1.000|\n|OAR+L1|0.934|1.000|**1.000**$\\uparrow$|1.000|\n|||||\n\n>**Q5: Could OAR work for node classification?**\n\nYes, it can. Here are the results on four node classification datasets following [1]:\n\n||BA-Shapes|BA-Community|Tree-Cycles|Tree-Grid|\n|:-:|:-:|:-:|:-:|:-:|\n|RM|0.312|0.321|0.295|0.411|\n|DSE|0.406|0.377|0.343|0.384|\n|OAR|**0.542**|**0.560**|**0.489**|**0.440**|\n|SimOAR|0.527|0.535|0.471|0.431|\n|||||\n\n*[1] GNNExplainer: Generating Explanations for Graph Neural Networks. NIPS 2019*\n\n>**Q6: Can we do something simpler than VGAE, like spectra?**\n\nYes, we can. Spectra is the commonly used techniques in anomaly detection. Considering their typically work for nodes classification, we use the Manhattan distance between the spectrum as the OOD degree and exhibit the results:\n\n||MUTAG|BA3|TR3|MNIST|\n|:-:|:-:|:-:|:-:|:-:|\n|OAR|0.567|0.503|0.483|0.455|\n|SimOAR+Spectra|0.511|0.459|0.449|0.433|\n|||||\n\nBased on these we find that the performance of spectra is inferior to that of VGAE. \n\n>**Q7: Could BA3 and TR3 influence experiments?**\n\nThanks for your concern. We believe that they will not. Here are two reasons: \n\n- First, although ground truth in BA3 and TR3 might not conform to the decision-making process exactly, they contain sufficient discriminative information to help justify the quality of explanations. \n\n- Second, even after excluding the potentially problematic datasets BA3 and TR3, we still have other datasets like MUTAG and MNIST-sp, and our methods also achieved the best performance on these datasets across various settings.\n""}}, {'summary': {'value': 'This paper studies the explainability evaluation of GNNs, and proposes a new evaluation paradigm. Inspired by adversarial robustness, it uses a generative model (VGAE) to fulfill the explanation subgraph, randomly perturbs the fulfilled parts, and uses the OOD scores of perturbed graphs to measure the importance of explanation subgraph. Experiments are done on several datasets and show the improved evaluation quality w.r.t. diverse criteria.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1.\tThis paper summarizes the removal- and generation-based evaluation protocols well, and points out their drawbacks w.r.t. post-hoc explainability. It resolves these drawbacks by calculating the robustness of explanations under attack and OOD-reweighting. This motivation is clear and reasonable.\n2.\tIn terms of technical contributions, the evaluation of explanation robustness is well-designed. It first gives an adversarial robustness-related definition, and then transfers it into a tractable objective and designs an OOD-reweighting block (i.e., an external VGAE) to solve the objective. Moreover, a computationally efficient variant is also proposed.\n3.\tThe experiments are sufficient to demonstrate the effectiveness of the proposed method, w.r.t., explanation evaluation, generalization, model design, and user study.\n4.\tI appreciate the diverse criteria used in the paper, especially the “consistency of ground-truth explanations and human intuition”.\n5.\tThe presentation of the proposed method is clear.\n'}, 'weaknesses': {'value': '1.\tRegarding adversarial robustness, the proposed measurement is based on perturbing the subgraphs. I have two questions: (1) why name the random perturbation as adversarial robustness, which usually performs adversarially perturbation? Does it mean that “How adversarial are random perturbations against the original data distribution, which are measured by OOD score”? (2) How many perturbed subgraphs are needed? I think these concepts are essential to understand the proposed evaluation method. Hence, more clarification is needed.\n2.\tThe OOD reweighting block is implemented by VGAE, hence, the proposed method seems heavily dependent on the VGAE quality. However, many studies show the generative ability of VGAE is suboptimal and degenerated. It would be better to analyze the influence of VGAE quality on the OAR performance.\n'}, 'questions': {'value': '1.\tWhy name the random perturbation as adversarial robustness, which usually performs adversarially perturbation? Does it mean that “How adversarial are random perturbations against the original data distribution, which are measured by OOD score”?\n2.\tHow many perturbed subgraphs are needed?\n3.\tWhat is the influence of VGAE quality on the OAR performance?\n'}, 'limitations': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents a new evaluation metric OAR for evaluating post-hoc explanation methods for GNNs. OAR has two main advantages in that it does not need ground-truth labels and in that it prevents finding spurious explanations based on out-of-data-distribution phenomena. The paper focuses on graph classification: The input for this explanation is a subgraph of the graph for which we want to explain a prediction. The proposed method OAR, creates several permutation of the original graphs, where it is allowed to only permute edges **not** in the explanation. A generative model forces those permutations to not leave the training data distribution. The less the permutations can change the model prediction the better an explanation we consider the subgraph. Experiments validate the effectiveness of OAR.\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper tackles an important topic, GNN explanation, in an ambitious way: To evaluate different explanation methods unsupervised, without access to ground truth explanations.\n\nThe paper is in a good shape (apart from the introduction+related work): The writing is clear and allows for understanding most of the paper in the first or second read. The figures are helpful for understanding and well connected to the text. The experiments chosen by the authors make sense and I appreciate the authors also running a user study.\n'}, 'weaknesses': {'value': 'I do not like the approach the authors have taken for the related work in this paper. The first section is a hybrid of related work and introduction, and I feel it serves neither well. I am missing a concise motivation and a broader context of the paper from this section. The actual related work is in Appendix A, which I would prefer to be in the main paper. I also think that there is an important branch of work missing [1-5]. These works discuss general properties that we may want an explanation method and an evaluation setup to adhere to. I think it would benefit the paper to discuss how OAR is compatible/incompatible with these proposals. These works also offer some alternative benchmarks for evaluation instead of the flawed BA and tree-based (TR) datasets. \n[1] Himmelhuber et al: Demystifying Graph Neural Network Explanations\n[2] Sanchez-Lengeling et al. Evaluating attribution for graph neural networks\n[3] Agarwal et al. Evaluating explainability for graph neural networks\n[4] Agarwal et al. Probing GNN explainers: A rigorous theoretical and empirical analysis of GNN explanation methods\n[5] Faber et al. When comparing to ground truth is wrong: On evaluating GNN explanation methods\n\nThere is also one paper discussing out-of-distribution versus explanation for GNNs [6] that might be worth discussing/comparing to.\n[6] Faber et al. Contrastive graph neural network explanation\n\nI am not convinced about the explanations that the method produces. Generally, we want to create explanations to make humans understand what is happening. For this, every step to create the explanation is ideally human inspectable. Here, it seems like we are transferring the trust problem from the GNN to the VGAE. This becomes the blackbox that somehow determines if the results are good or bad and we cannot inspect this blackbox. For example, using recall on ground-truth data makes for a good explanation metric because us humans can see *why* the explanation is supposedly good.\n'}, 'questions': {'value': 'Could you expand on the setup used for the user study? The previous years (e.g., https://neurips.cc/Conferences/2021/PaperInformation/PaperChecklist) included a paper checklist of what to consider and the details in Appendix D are quite short.\n\nThe study on MNIST explanations seems to be very dependent on the layout of the explanation subgraph (maybe even more so than the choice of what nodes to put there). Can you expand on how you created the graph layout? Are superpixel nodes positioned where they are placed in the image?\n\nDoes the permutation space for the targeted adversarial attacks allow adding and deleting nodes? Or are the attacks constrained to happen in the given adjacency matrix?\n\nOAR itself makes no assumptions on the size of the explanation, but it seems it is easier to get good explanations the larger the explanation graph is: there is less attack space for adversarial permutation and a larger fixed graph likely helps for low OOD scores. I wonder if OAR would benefit from a component that penalizes surplus nodes in the explanation?\n\nCould the method be expanded to also support node classification? One naive angle might be to extract the receptive field of each node and use OAR on those graphs?\n\nFrom what I understand, an important motivation is the fight of out-of-distribution data. This motivates the generative graph model to find and remove outliers. On the other hand, it seems that SimOAR performs similarly without using such a model but a budget(?) on perturbations. Can we maybe do something simpler than the generative model, for example, looking at spectra?\n\nSome of the works linked above showed that the BA and tree based datasets have flaws and GNNs do not always use all the data present in the ground truth. Could these also influence your experiments?\n'}, 'limitations': {'value': 'Addressed by the authors'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper proposes a novel evaluation metric called OOD-resistant Adversarial Robustness (OAR) to address the issue of assessing the credibility of explanations provided by graph neural networks (GNNs). The paper criticizes existing evaluation methods that fail to consider out-of-distribution (OOD) data and can produce inconsistent results. OAR overcomes these limitations by calculating the robustness of explanatory subgraphs under attack and incorporating an OOD reweighting block. The paper also introduces a simplified version of OAR called SimOAR for more efficient evaluation of large datasets. Experimental results show that OAR outperforms current evaluation metrics and demonstrates consistency with metrics like Precision, Recall, and Human Supervision .'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. This work tackles an important research gap on evaluating the explanation for GNN.\n2. The paper is well-written and easy to follow. \n2. The authors conduct experiments, and the results demonstrate the advantage of their proposed method.'}, 'weaknesses': {'value': '1. Figure 1 is kind of hard to follow. It could be better if authors can refine it.\n2. Some experiment setting is missing. For example, what is the setting of the GAE? What is the number of the generated graph?\n3. Lack of related work, and some important reference is missing. For example, the authors could add a section introduce the explanation methods for GNN according to [1].\n\n[1]  Zhang, He, et al. ""Trustworthy graph neural networks: Aspects, methods and trends."" arXiv preprint arXiv:2205.07424 (2022).'}, 'questions': {'value': 'Listed in Weakness.'}, 'limitations': {'value': 'Yes.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""This paper presents a new metric, OOD-resistant Adversarial Robustness (OAR), for evaluating post-hoc explanation methods for Graph Neural Networks (GNNs). Inspired by adversarial robustness, OAR performs random perturbations on the complementary part of the explanation result, reducing the impact of the Out-Of-Distribution (OOD) issue common in previous removal-based metrics and ensuring consistency with GNNs' behavior compared to generation-based methods. The authors further introduce an OOD reweighting block, which measures the OOD score of each perturbed sample, allowing for the marginalization of OOD instances, and the OOD score is assigned via the reconstruction loss of a Variational Graph Auto-Encoder (VGAE) pre-trained by each dataset, inspired by graph anomaly detection methods. Extensive evaluations and ablation studies demonstrate that OAR aligns more closely with the ground truth.\n\n\n\n\n\n\n \n""}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- This work summarizes and addresses a critical and emerging issue in post-hoc explanation methods for GNNs, and the proposed metric is intuitive and can mitigate issues that may happen in previous removal-based and generation-based methods, offering significant benefits to the research community.\n- The authors conduct extensive experiments, demonstrating the potential of the proposed metric as a superior evaluation tool for post-hoc explanation methods.\n- It is interesting to see OOD score can be measured using graph anomaly detection methods (and that works).\n- This paper is well-written and well-motivated.'}, 'weaknesses': {'value': '- As an evaluation metric, OAR introduces an additional component that requires training on the original dataset used for the GNN. This process makes things complex, time-consuming, and may accumulate errors, making it tricky for different research groups to compare methods across various datasets.\n\n- SimOAR somewhat addresses the above concern, but it does so at the expense of performance. From current experiments (w/ six backbone methods), the performance degradation seems to be significant.\n\n- Though I am generally satisfied with evaluating six backbone explanation methods, the inclusion of more baselines would provide a more comprehensive statistical overview, given that this paper aims to introduce a metric for future community use. It would also be beneficial to include different types of post-hoc methods, such as decomposition, surrogate, and generation-based methods, among others.'}, 'questions': {'value': '- I am not quite sure if the usage of ""adversarial"" and ""attack"" in OAR would be clear. I thought there would be some adversarial training in OAR but in fact the authors just got inspiration from them and OAR does not really do adversarial things.\n\n- How is the metric RM calculated mathematically? Is it fidelity? Can the authors provide its formulation?'}, 'limitations': {'value': '- This paper focuses on the explanation of graph-level tasks. How would this generalize to other types of tasks as a metric?\n- There are works showing post-hoc explanation methods are always suboptimal in terms of finding label-relevant patterns and therefore proposing self-explainable models and pretrain-finetuning framework, e.g., GSAT. This may limit the future impact of OAR if it is only for post-hoc methods. Can the idea in OAR help self-explainable methods?\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Evaluating Post-hoc Explanations for Graph Neural Networks via Robustness Analysis'}, 'authors': {'value': ['Junfeng Fang', 'Wei Liu', 'Yuan Gao', 'Zemin Liu', 'An Zhang', 'Xiang Wang', 'Xiangnan He']}, 'authorids': {'value': ['~Junfeng_Fang1', '~Wei_Liu34', '~Yuan_Gao18', '~Zemin_Liu1', '~An_Zhang2', '~Xiang_Wang6', '~Xiangnan_He1']}, 'keywords': {'value': ['Post-hoc Explainability', 'Explanation Evaluation', 'Graph Neural Network', 'Robustness Analysis']}, 'abstract': {'value': 'This work studies the evaluation of explaining graph neural networks (GNNs), which is crucial to the credibility of post-hoc explainability in practical usage. Conventional evaluation metrics, and even explanation methods -- which mainly follow the paradigm of feeding the explanatory subgraph and measuring output difference -- always suffer from the notorious out-of-distribution (OOD) issue. In this work, we endeavor to confront the issue by introducing a novel evaluation metric, termed **O**OD-resistant **A**dversarial **R**obustness (OAR). Specifically, we draw inspiration from the notion of adversarial robustness and evaluate post-hoc explanation subgraphs by calculating their robustness under attack. On top of that, an elaborate OOD reweighting block is inserted into the pipeline to confine the evaluation process to the original data distribution. For applications involving large datasets, we further devise a **Sim**plified version of **OAR** (SimOAR), which achieves a significant improvement in computational efficiency at the cost of a small amount of performance. Extensive empirical studies validate the effectiveness of our OAR and SimOAR.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/f9088a857e15726caa9414c9e0d90b5b2b9f54ed.pdf'}, '_bibtex': {'value': '@inproceedings{\nfang2023evaluating,\ntitle={Evaluating Post-hoc Explanations for Graph Neural Networks via Robustness Analysis},\nauthor={Junfeng Fang and Wei Liu and Yuan Gao and Zemin Liu and An Zhang and Xiang Wang and Xiangnan He},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=eD534mPhAg}\n}'}, 'TLDR': {'value': 'This work draws inspiration from the notion of adversarial robustness and introduces a novel evaluation metric, termed OOD-resistant Adversarial Robustness (OAR).'}, 'paperhash': {'value': 'fang|evaluating_posthoc_explanations_for_graph_neural_networks_via_robustness_analysis'}}]"
"['Ziqian Zhong', 'Ziming Liu', 'Max Tegmark', 'Jacob Andreas']",NeurIPS,The Clock and the Pizza_ Two Stories in Mechanistic Explanation of Neural Networks,https://neurips.cc/virtual/2023/oral/73847,2023," Do neural networks, trained on well-understood algorithmic tasks, reliably rediscover known algorithms? Several recent studies, on tasks ranging from group operations to in-context linear regression, have suggested that the answer is yes. Using modular addition as a prototypical problem, we show that algorithm discovery in neural networks is sometimes more complex: small changes to model hyperparameters and initializations can induce discovery of qualitatively different algorithms from a fixed training set, and even learning of multiple different solutions in parallel. In modular addition, we specifically show that models learn a known Clock algorithm, a previously undescribed, less intuitive, but comprehensible procedure we term the Pizza algorithm, and a variety of even more complex procedures. Our results show that even simple learning problems can admit a surprising diversity of solutions, motivating the development of new tools for mechanistically characterizing the behavior of neural networks across the algorithmic phase space.",Oral 6A LLMs,https://openreview.net/pdf?id=S5wmbQc1We,https://openreview.net/forum?id=S5wmbQc1We,S5wmbQc1We,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'All reviewers agree that this paper is clearly presented and soundly supported, both mathematically and empirically. There is generally a high level of enthusiasm for accepting it. The particular contribution---showing that one of the main demonstrations of mechanistic interpretability is not robust---is timely, and should influence the thinking of people working in this area.'}}, {'title': {'value': 'Rebuttal Response'}, 'comment': {'value': 'I thank the authors for their detailed responses. I have also read other reviews and responses; thus, I am increasing my score and moving toward acceptance. I believe the updated paper will have all the components promised by the authors in their rebuttal. Overall Good work.'}}, {'comment': {'value': 'Thank you for your comprehensive clarifications and the additional experiments/figures to support them. I am happy to increase my score accordingly.'}}, {'title': {'value': 'Reviewer Response'}, 'comment': {'value': ""Thank you for your clarification! I'll maintain my rating.""}}, {'comment': {'value': ""Thank you for the clarifications! I'm keeping my score where it is.""}}, {'title': {'value': 'Reviewer Response'}, 'comment': {'value': 'I thank the authors for answering many of my concerns. I had not thought of combining different circles each doing a different algorithm, that is an interesting possibility, and the information on proportion of networks that are circular is interesting.\n\nI realise I was being an idiot about figure 6 since, as you say, I indeed thought the title of the colourbar was the title of the plot. So you can ignore that!\n\nI think my scoring of the work still stands, and hope to see a cleaned up version of the paper accepted.'}}, {'rebuttal': {'value': ""We would like to thank you for your helpful and constructive questions/suggestions! Below is our reply to your questions:\n\n> Q1: Are $E_{ab}$ and $s$ the same?\n\n> Q2: Are $P_{c}$ and $Q_{abc}$ the same?\n\nA2: Thanks for pointing them out! Yes to both - Appendix A was following an older set of notations. We will make sure to correct these mistakes in the final version.\n\n> Q3: Line 392, an accompanied pizza is mentioned but is only defined long after.\n\nA3: Agreed. We will remove the first sentence in the final version.\n\n> Q4: The notations in Appendix G are confusing.\n\nA4: Thanks for the feedback. We have changed all i’s in the first paragraph to t’s.\n\n> Q5: Are $x^j$ and $x^j_{i}$ the same?\n\nA5: Here $x^j$ stands for the whole residual stream vector and $_{i}$ stands for taking its i’th element / dimension. When we drop the lower index, we are performing vector operations on the whole vector $x^j$. We agree it is very confusing and we will make sure to explain the notation choice.\n\n> Q6: Why the change from x to y,z ?\n\nA6: In our particular case there is only one layer, so we feel using x^0 and x^1 will be more confusing so we switched to x and z instead. Except for the notation choice and the expanded loop, nothing is changed.\n\n> Q7: The sine and cosine formula is missing a factor 2. Also specify the formula somewhere.\n\nA7: Great catch! We have added the missing factor and added the two relevant trigonometry formulas at the beginning of Appendix A.\n\n\n> Q8: No antipodal pairs only require p to be odd, not necessarily prime. \n\nA8: Our intention was to stress the case where p is an odd prime which is the most typical setup, but it is indeed confusing. We will change it to be p odd.\n\n> Q9: Plots in Figure 6 (and similar figures in the appendix) are titled wrong.\n\nA9: If we understood your concerns correctly, the plots are not titled (and are labeled) and the text on top are descriptions for the color bar. We agree it is a bit confusing and we will left-align the text to make it clearer. We will update it in the next version.\n\n> Q10: $\\mathbf{Z}_p$ or $\\mathbf{Z}_p^3$?\n\nA10: It should be $\\mathbf{Z}_p$, thanks for pointing that out! We will surely correct it.\n\n> Q11: It seems there are a class of pizza-like algorithms (e.g. the two in appendix A), and the evidence listed does not distinguish them.\n\nA11: Indeed there exists a class of pizza algorithms. The pizza algorithms can differ in how the terms $\\cos(w_k(a+b))$ and $\\sin(w_k(a+b))$ are approximated by ReLU neurons (Figure 7 and Step 2 in Appendix A). More active neurons could lead to better approximation, but different random seeds and/or hyperparameters may lead to different numbers of active neurons. We will follow your suggestion to update Figure 1 such that it can encompass the whole pizza family and use the current algorithm as a possible special case.\n\n> Q12: Why compute gradients after projecting onto the first six principal components?\n\nA12: The gradient *a*symmetricity is more prominent for the first principal components, as these are more important for the function, and being symmetric is likely easier for the network, and we choose six to be consistent with the later discussion on the three circles. In fact, in the later calculation of gradient symmetricity (Def 4.1) no translation to the principal component space is performed. We’ve attached the same figure with more principal components and without the projection (figure e in the attached pdf). We can see that the gradients are most symmetric for the later principal components as they are not very useful for the algorithm, and without the projection step, the gradient asymmetricity is, in fact, more pronounced for Model B, as the asymmetric gradients on the few principal components are now pronounced across multiple dimensions.\n\n> Q13: What's the rationale behind the gradient symmetry plot?\n\nA13: Past work has shown that neural networks (especially without attention) struggle to learn how to multiply inputs. In this respect, the Clock algorithm felt *unnatural* and we suspected there might be an alternative Pizza-like solution based on linear combination instead.\n\n> Q14: In table 1 it says non-circular algorithms show gradient symmetry, but in general (figure 9) it appears like they don’t.\n\nA14: Thanks for pointing that out! There indeed exist both gradient symmetric and gradient asymmetric non-circular algorithms. We will modify Table 1.\n\n> Q15: The phase transition points seem different when measured by distance irrelevance or gradient symmetricity.\n\nA15: Yes. In short, we believe this is caused by algorithms that are neither clock nor pizza. We consider distance irrelevance to be the *defining* feature of Pizza. Gradient symmetricity is mainly presented as supplementary evidence against the Clock algorithm, which requires multiplying (transformed) inputs, which will result in asymmetric gradients. From figure a in the attached pdf we can see that having low distance irrelevance is indeed a stronger condition than having high gradient symmetricity, suggesting the existence of algorithms that are not clock (high gradient symmetricity) and not pizza (high distance irrelevance).\n\n> Q16: What proportion of models are non-circular?\n\nA16: For our trained 1,2,3,4-layer 128-width models, the circular (circularity >= 99.5%) ones are 34.31%, 9.95%, 11.55% and 6.08%, respectively. We also attached the circular rate at each attention rate decile and at each width range (figure b & c in the attached pdf).\n\n> Q17: The phase change is continuous. What happens in between?\n\nA17: We conjecture that it is a hybrid of clock and pizza: the Algorithm in Appendix 1 takes the dot product of $(\\alpha,\\beta)$ with $(\\cos(w_k c),\\sin(w_k c))$ - same as in the clock algorithm. Therefore, it is possible to have some PCA circles operating as the clock algorithm and some operating as the pizza algorithm, and their results are added together before the final dot product with $(\\cos(w_k c),\\sin(w_k c))$.""}}, {'rebuttal': {'value': 'We would like to thank you for your helpful and constructive questions/suggestions! Below is our reply to your questions:\n\n> Q1: The argument “some networks very similar to the ones trained by [1] preferentially implement a qualitatively different approach"" seems too strong. What is the fraction of neural networks with attention rate 1 that according to your metrics implement the ""pizza"" algorithm?\n\nA1: By “similar” we mean structurally similar: our setup is almost identical to [1] except for the introduction of attention rate. From the data we have it seems quite unlikely for a network with attention rate near 1 to implement the pizza algorithm, although we did observe many non-circular (and thus unlikely clock) ones (Fig 6, Appendix C Fig 9). We agree it is somewhat misleading and we will tone down the claim in the updated version.\n\n\n> Q2: What fraction of trained models is non-circular?\n\nA2: For our trained 1,2,3,4-layer 128-width models, the circular (circularity >= 99.5%) ones are 34.31%, 9.95%, 11.55% and 6.08%, respectively. We also attached the circular rate at each attention rate decile and at each width range (figure b & c in the attached pdf).\n\n\n> Q3: What’s the relation between distance irrelevance vs gradient symmetricity?\n\nA3: We consider distance irrelevance as the deciding factor of pizza, as there seem to be limited other reasons for the output logits to depend on the distance. Gradient symmetricity is mostly used to rule out the clock algorithm as the clock algorithm requires multiplying (transformed) inputs, which will result in asymmetric gradients. Following your suggestion, we compiled the scatterplot of distance irrelevance vs gradient symmetricity over all the standard structure experiments we’ve done, and we can indeed see at low distance irrelevance (suggesting pizza) the gradient symmetricity is always close to 1 (suggesting non-clock) except for a few outliers (figure a in the attached pdf).\n\n> Q4: When two metrics contradict, how to make a confident statement?\n\nA4: Following the answer of Q3, we consider distance irrelevance as the defining signature of the Pizza algorithm,  while gradient symmetricity is additional evidence against Clock.\n\n> Q5: What’s the evidence for some solutions ""implement multiple, imperfect copies of either the Clock or Pizza algorithm in parallel.""?\n\nA5: We agree that it is a bit confusing, but here we refer to the algorithms operating on a single circle as the clock or pizza algorithm, and they are imperfect (the pizza algorithm suffers from antipodal pairs; keeping only the first circle in Model A gives only 32.8% accuracy (L135)). We will clarify this in the revision.\n\n> Q6: Why do accompanied pizzas achieve almost perfect accuracy despite the failure mode of antipodal pairs?\n\nA6: Mechanically, the numbers are arranged differently in each circle so they have different antipodal pairs. In circle #2 of Fig 4, 0 and 10 are roughly antipodal, so circle #2 alone might not be able to get the input (0,10) correct, but we can see that they are relatively close in circle #1, and circle #1 is likely to provide the correct answer. In other words, the multiple copies of the pizza algorithm error correct each other. The accompanying pizzas can also be helpful (Appendix D) although the three circles alone are enough to get close to 100% accuracy.\n\n> Q7: Test the hypothesis that “accompanying pizzas are primarily used early in training”.\n\nA7: We observed the early emergence of a pattern similar to accompanying pizza in training runs (figure f in attached pdf) and removing that circle brings accuracy down from 99.7% to 97.9%. They are less helpful later in the network (removing accompanying pizzas in trained Model A only brings accuracy down to 99.7%).\n\n> Q8: Why use the terminology “symmetricity” rather than “symmetry”?\n\nA8: We think “symmetry” is mostly used as a binary adjective (something either poses symmetry or not), so we used the word “symmetricity” to emphasize the continuous aspect of our metric.\n'}}, {'rebuttal': {'value': 'We would like to thank you for your helpful and constructive questions/suggestions! Below is our reply to your questions:\n\n> Q1: L78: Why the choice of 6 vectors specifically? For exposition? Will choosing less significant components introduce unnecessary noise?\n\nA1: The main motivation is that the gradient *a*symmetricity is more prominent for the first principal components, as these are more important for the function, and being symmetric is likely easier for the network. The choice also helps to be more consistent with the later discussions on 3 circles (Fig 4, Fig 5), which correspond to the first 6 principal components. In fact, in the later calculation of gradient symmetricity (Def 4.1) no translation to the principal component space is performed. We’ve attached the same figure with more (20) principal components and without the principal component projection (figure e in attached pdf).\n\n> Q2: L113: What would happen with an odd number of ReLU units?\n\nA2: We can implement absolute value $|x|$ by $\\text{ReLU}(x)-\\text{ReLU}(-x)$. If there are an odd number of ReLU units, some could be dead neurons (in the sense that the activation is near-zero for all inputs). There are also multiple possible variants of the pizza algorithm (Appendix A).\n'}}, {'rebuttal': {'value': 'We would like to thank you for your helpful and constructive questions/suggestions! Below is our reply to your questions:\n\n> Q1: Calling $Q_{abc}$ output logit is confusing.\n\nA1: This terminology has been used in many previous interpretability studies [Nanda2023] [Wang2023], so we are using standard nomenclature in this research area.\n\n\n\n> Q2: Can we determine the intermediate vector $E_{ab}$ to gain insights into the algorithmic process?\n\nA2: It is certainly possible, and we can prove that mechanistically in constant-attention Transformers, the computation starts by adding two embeddings (Appendix G). \n\n\n**Reference**\n\n[Nanda2023] “Progress measures for grokking via mechanistic interpretability”, Nanda et al.\n\n[Wang2023] “Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small”, Wang et al.'}}, {'rebuttal': {'value': 'We would like to thank you for your helpful and constructive questions/suggestions! Below is our reply to your questions:\n\n> Q1: Ablation study is missing. Can authors provide ablation studies on various values of attention rate and also the width of layers?\n\nA1: Thank you for the suggestion! If we understand correctly, the ablation study you are requesting is already provided in Figure 6 of the submission, which shows behavior at  various values of attention rate and model width.\n\n> Q2: Did authors perform a grid search to select the best hyper-parameters? Then that should be mentioned with ranges in the appendix.\n\nA2: No. We largely followed [Nanda2023] for hyperparameter setups and we chose p=59 following [Liu2023] to simplify the investigation.\n\n\n> Q3: Can you discuss the literature and cite relevant papers?\n\nA3: Thanks for pointing us to these references, which are indeed relevant to our work. We would like to include the citations in the next updated version.\n\n\n> Q4: How to determine the threshold for circularity?\n\nA4: This is necessarily a bit subjective. Circularity is fundamentally a qualitative phenomenon, and this threshold indicates how tolerant we are in terms of considering some shapes as being approximately circular (which the authors all agreed was true of shapes with circularity >= 99.5%). \n\n\n> Q5: Can this analysis apply to convolutional neural networks or recurrent neural networks?\n\nA5: Yes, our analysis can apply to other architectures, e.gCNN and RNN. This analysis does not require inspecting latent representations (which are specific to architectures), only involving output logits and gradients wrt to input embeddings (which are universal to all architectures).\n\n> Q6: For the transition from circular to non-circular algorithms, what is the bound (phase transition point) along depth, attention rate, width?\n\nA6: There is no clear phase transition from circular to non-circular algorithms against attention rate and width, but depth 1 networks are clearly more likely to be circular solutions than deeper (2-4 layers) networks. See figure b and c in the attached pdf.\n\n\n\n> Q7: How does the model effectively interpolate between the memorizing and generalization solutions?\n\nA7: Our work focuses mostly on analyzing the final (generalization) solution. The training dynamics (how the model interpolates from a memorizing to a generalization solution) is interesting but might be out of the scope of this work.\n\n\n> Q8: Does this also work with sinusoidal embeddings, masked embedding? Does the choice of embedding have an issue in generalization?\n\nA8: Yes, we believe other types of embeddings can also lead to generalization. We’re currently using learnable positional embedding, but our proposed pizza algorithms do not depend on them, so we believe the pizza algorithms also exist under sinusoidal positional embeddings. As for masked embeddings, in the 1-layer case masked embedding is equivalent to bidirectional embedding (since attention to token #2 to token #1 doesn’t count) so our conclusions should remain valid.\n\n> Q9: How does pruning weights (hence sparsity) affect performance?\n\nA9: It is unclear to us whether our analysis has implications for sparsity. Norm-wise strong concentration is observed and its relationship with attention rate, distance irrelevance is observed but weak (figure g in the attached pdf). We observed some difference in parameter distribution for Model A and Model B (figure d the attached pdf) and we believe it is primarily a result of different model configuration (for example, query and key matrices are ignored by constant-attention Transformers).\n\n\n> Q10: Can you provide computation time (including FLOPs) and error bars?\n\nQ10: We spent roughly 226 GPU days on a V100 cluster with ~30% utilize rate, so the total computation is around 4e19 FLOPs.\nIt is hard to provide an error estimation since we are sampling with respect to multiple parameters, but we have made the full distribution available.\n\n\n> Q11: Figure 4 (and so as other figures) should be improved to maximize readability. \n\nA11: Thanks for the suggestion! We will increase fonts and do other optimization if needed.\n\n\n**References**\n\n[Nanda2023] “Progress measures for grokking via mechanistic interpretability”, Nanda et al.\n\n[Liu2023] “Towards Understanding Grokking: An Effective Theory of Representation Learning”, Liu et al.\n'}}, {'rebuttal': {'value': 'We would like to thank all reviewers for their helpful and constructive suggestions, which will greatly improve the final version of the paper. Besides individual responses, we want to summarize our responses/updates to reviewers’ common questions here. Reviews prompted us to try several additional experiments, which have led to fruitful discoveries:\n\n### Distance irrelevance vs gradient symmetricity\n\nDistance irrelevance is a rather surprising and defining feature of the pizza algorithm while the gradient symmetricity is mainly presented as supplementary evidence mostly used to rule out the Clock algorithm, which requires multiplying (transformed) inputs and hence has asymmetric gradients. We plotted the relationship between gradient symmetricity and gradient irrelevance for all the 1~4 layer 128-width models we trained, and we confirmed that low distance irrelevance (suggesting Pizza) almost always implies close to 1 gradient symmetricity (suggesting non-Clock) (figure a in the attached pdf).\n\n### Accompanying pizzas are employed early in training\n\nWe observed the early emergence of accompanying pizza in training runs (figure f in the attached pdf; irrelevant principal components not displayed for space concerns). The model was trained 600 epochs at the time and reached 99.7% accuracy on the validation set (for reference, all the models we reported are trained for 20000 epochs). From the logit pattern, the first two principal components of the input embedding resemble the pizza algorithm, and the 13th and 14th principal components resemble the accompanying pizza. It is surprising that although the two components do not exactly resemble a circle due to the lack of training, the logit pattern is still clear and corresponds to the first circle. Removing this “accompanying pizza” brings the accuracy down to 97.9%.\n\n### Projection for gradient symmetricity\nWe projected the gradients of the models to the principal components so as to match our description of algorithms on principal components. The less significant principal components account less for the correct functioning of the model and we observed their corresponding gradients concentrating near 0 (fig e left in the attached pdf). If we consider the raw unprojected gradients, the asymmetricity of a few model B’s principal components’ gradients is more pronounced as it now affects multiple raw gradient dimensions (fig e right in the attached pdf).\n\n### Circularity with respect to layer, attention rate, and width\nWe computed the circular rate (circularity >= 99.5%) of models with respect to the number of layers, attention rate, and width (fig b and fig c in the attached pdf). We found out that the circular rate is higher for 1-layer models than multiple-layer models, and among 1-layer models circular rate is higher when the attention rate is closer to 0 or 1. Our explanation is that Pizza and Clock are two circular phases that are easiest to obtain at 1 layer and attention rate 0 or 1, correspondingly, so setups closer to these two phases are more likely to be drawn to them, resulting in similarly circular states.\n\n### Sparsity and norm distribution\nWe plotted the relationship between attention rate, distance irrelevance, gradient symmetricity, and parameter L2 norm (figure g in the attached pdf). Here the parameter stands for all the trainable coefficients in the trained model. Besides clear concentration, we can see a slight increase in the mean L2 norm as attention rate and distance irrelevance increase. We also observed a slight increase in L2 norm from Model A (22.9) to Model B (24.8). Their parameter distributions are also different (figure d in the attached pdf). We believe this is a result of different attention rate setups. Namely, for Model A with constant attention (attention rate 0), the query and key matrices are ignored so they are optimized to near-0 values.\n\n\n\nBesides empirical experiments, we also incorporate other suggestions from reviewers, including clarifying the family of pizza algorithms (Reviewer 7M7r), related work discussions (Reviewer wANB) and writing (Reviewer 7M7r, ZmSF, DtSC).'}, 'pdf': {'value': '/pdf/de33e26dfbad28910df06ac482bea468780f1a1c.pdf'}}, {'summary': {'value': 'In this work, the authors focus on the problem of learning modular addition in NNs. Using clock and pizza algorithms, they show that model exhibits sharp algorithm transitions, which are affected by layer width and attention strengths, often resulting in the parallel occurrence of these phases.  A series of experiments are performed on the single-layer network to support the hypothesis proposed in this work. '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. Well-written paper.\n2, an useful contribution in terms of interpretability of NNs.\n3. Novel contribution in terms of analyzing the algorithmic transitions.'}, 'weaknesses': {'value': '1. Ablation study is missing\n2. Did authors perform a grid search to select best hyper-parameters? Then that should be mentioned with ranges in the appendix.\n\n\n'}, 'questions': {'value': 'In terms of interpretability there are models inspired by formal language theory that insert rules [1,3] and extract rules [2-7], termed as interpretable by extractions and such models are even tested on mathematical reasoning[4] task and are known to be turing complete even with finite precision and time [8]. Authors should discuss this line of work, as they are relevant.\n\nHow to determine the threshold for the circularity, does value >= 99.5% works for all model/architectures in terms of thresholding for circularity. It would be ideal if authors can provide empirical bound for this and how to determine such threshold. \n\nCan this framework be extended to convolutions with tensor weights or stateful models such as RNNs?\n\nAuthors do point out that deeper models leads to non-circular algorithms, but what is the bound for that? After how many layers non-circular behavior is shown by various models? At minimum providing empirical results will further strengthen this work. I would also like to see some empirical bounds on attention rate, what quantifies as high attention rate and what is low attention rate. Can author provide ablation study on various value of attention rate and also the width of layers?\n\nFew additional comments that are not clear from the manuscript.\n\nHow does the model effectively interpolate between the memorizing and generalizing solutions? \n\nDoes this also work with sinusoidal embeddings, masked embedding? Does the choice of embedding have an issue in generalization?\n\nThe authors do mention pruning the weights, so what effect does sparsity have in the model performance? Can authors comment on this? Like how the two-phase switch? \n\n\n\n\n\nFinally I would like to see total computational time required by the model including FLOPS and also standard error for various trials on proposed experiments.\n\nMinor comments\nThe figure 4 should be improved, its difficult to read values on y-axis and also values overlap in the circular diagram.  Same goes for other figures too.\n\t\n1.\tOmlin, C.W. and Giles, C.L., 1996. Rule revision with recurrent neural networks. IEEE Transactions on Knowledge and Data Engineering, 8(1), pp.183-188.\n2.\tTiňo, P. and Šajda, J., 1995. Learning and extracting initial mealy automata with a modular neural network model. Neural Computation, 7(4), pp.822-844.\n3.\tMali, A.A., Ororbia II, A.G. and Giles, C.L., 2020. A neural state pushdown automata. IEEE Transactions on Artificial Intelligence, 1(3), pp.193-205.\n4.\tMali, A., Ororbia, A.G., Kifer, D. and Giles, C.L., 2021, May. Recognizing and verifying mathematical equations using multiplicative differential neural units. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 35, No. 6, pp. 5006-5015).\n5.\tWeiss, G., Goldberg, Y. and Yahav, E., 2018, July. Extracting automata from recurrent neural networks using queries and counterexamples. In International Conference on Machine Learning (pp. 5247-5256). PMLR.\n6.\tWang, C., Lawrence, C. and Niepert, M., 2022. State-Regularized Recurrent Neural Networks to Extract Automata and Explain Predictions. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(6), pp.7739-7750.\n7.\tOkudono, T., Waga, M., Sekiyama, T. and Hasuo, I., 2020, April. Weighted automata extraction from recurrent neural networks via regression on state spaces. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 34, No. 04, pp. 5306-5314).\n8.\tStogin, J., Mali, A. and Giles, C.L., 2020. A provably stable neural network Turing Machine. arXiv preprint arXiv:2006.03651.'}, 'limitations': {'value': 'As highlighted above, the main point is an ablation study to support the hypothesis and computational overhead.\n\n**********\nScore increased after Author rebuttal Responses\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors present a novel algorithm as a mechanistic explanation of neural networks for modular addition. It is noted that the model without attention fails to implement the ‘Clock’ algorithm. This assertion is substantiated with evidence related to gradient symmetricity and logit patterns. The authors then propose an alternative solution, named the ‘Pizza’ algorithm, supported by evidence concerning logit patterns via circle isolation and accompanying ‘pizza’. Ultimately, they demonstrate the presence of an algorithmic phase transition along the attention rate and model width, employing metrics that indicate gradient symmetricity and distance irrelevance.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper is well-structured and supports its arguments with solid experiments. The authors demonstrate that a neural network is capable of learning diverse algorithms for the same task. They introduce an impressive procedure for interpreting the neural network via embedding vectors. This methodology has the potential for extension to more complex models and tasks.'}, 'weaknesses': {'value': 'The authors employ the term logit $Q_{abc}$ as well as the term output logit, which refers to the un-normalized log probability. The choice of terminology, however, proves to be confusing. Given that $Q_{abc}$ is not used in the model and is a concept introduced by the authors themselves, it would be beneficial to rename $Q_{abc}$ to a more intuitive term like ""value"" or ""rank"".'}, 'questions': {'value': ""What prevents us from directly ascertaining the algorithm employed by the model? Couldn't it be possible to determine the intermediate vector $E_{ab}$ to gain insights into the algorithmic process?""}, 'limitations': {'value': 'As the authors have noted, their focus lies on a simple learning problem. Significant further work is required to adapt their techniques for use with the more complex models typically employed in real-world tasks.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': '*Background*: Previous work in mechanistic interpretability has identified a particular algorithm that NNs implement (the clock algorithm) to solve modular addition. However, under certain architecture changes, the authors notice that NNs implement a different algorithm.\n\nThe main goal of this paper is to present inconsistencies in the clock algorithm for neural networks without attention (ie: an inductive bias that allows the model to implement multiplication) and motivate a different algorithm (the pizza) that explains a different algorithm through which such networks learn modular attention. The observations are backed by experiments on linearly interpolating between a NN with attention and an NN without it. The experiments also demonstrate that a single algorithm doesn’t always win: different models can and do ensemble multiple copies of both algorithms in parallel.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The paper is very well written and the proofs and arguments presented seem airtight. \xa0Most of the questions I’ve had while reading the paper are either addressed in subsequent sections or in the appendix. The experiments are simple yet, I believe, comprehensive in evaluating the arguments presented. This is also an exciting emerging area of research and should lead to interesting discussions in the mechanistic interpretability community.'}, 'weaknesses': {'value': 'This work raises a lot of interesting questions, but I really can’t find any egregious logical inconsistencies with this work.  \nmeta-(non)concern: This work largely relies on a problem from a paper that hasn’t been peer-reviewed. However, I do not think this is a reason to reject this work.\n\nOverall, I recommend _acceptance_.'}, 'questions': {'value': '* L78: Why the choice of 6 vectors specifically? For exposition? Will choosing less significant components introduce unnecessary noise?\n* L113: What would happen with an odd number of ReLU units?\n'}, 'limitations': {'value': 'The authors have addressed limitations in the manuscript. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'In this paper the authors study neural networks doing modular addition of integers, i.e. output $= mod_P( a + b)$ for fixed integer P and input integers a and b. Previous work on these networks has found that small transformers implement a simple _clock_ algorithm. This work verifies this, but shows that if you simplify the transformer’s attention and make your network more like a simple feedforward ReLU network, then you find the networks implement a completely different algorithm they call the _pizza_ algorithm. Their evidence for this includes (i) strange patterns in the correct logit outputs, (ii) gradients that do not fit the clock model but can be understood in their pizza model, (iii) patterns in the logits when the inputs are restricted to particular 2D planes, and (iv) the need for error correcting that leads to particular patterns in a pizza embedding. They then study an algorithmic phase change from pizza to clock as you vary how much attention is included.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'I thought the large-scale motivation for this work was justified, previous people have claimed that this specific task leads many networks to solve it in the same way. Turns out that isn’t true. That seems important.\nI thought the main discovery of this work was very interesting.\nI thought the evidence to back up the claim was convincing.\nI thought the experiments performed were pretty thorough.\nFor the most part the claims were not overblown (for example I really appreciated the discussion of non-circular algorithms for solving this task)\nFinally the appendix was a bit of a treasure trove.\n'}, 'weaknesses': {'value': 'I think the paper’s clarity could definitely improve. At times, mainly in the appendix where a lot of the explanation gets relegated, the paper felt rushed and the explanations were terse, expecting a lot from the reader. \n\nI found this especially true of the equations in the appendix, for example:\n\n1.\tIn appendix A you introduce $s$ on the first line, which is the same as $E_{ab}$ I think. Why do you introduce a new symbol? Why do you not make it clear it is the same as $E_{ab}$ in the main paper? \n2.\tYou then do the same, again in Appendix A, when introducing the symbol $P_c$, which is I believe $Q_{abc}$ from the main paper? You also say thus, which in maths makes me expect to understand that you have derived a result, instead at the moment it reads like a definition of $P_c$ so the use of thus is confusing. \n3.\tLine 392, in step 1 you talk about an accompanied pizza in a section that readers are expected to reach long before they read about accompanied pizzas where that adds no value as far as I can tell, but just makes the whole thing confusing.\n4.\tAppendix G was a minefield of strange notational choices in my mind. The layer index was initially denoted with i, but then changes to t, and i is reused as the token index.  I found this needlessly confusing.\n5.\tYou define $x^j$ as the value of the residual stream after j layers, but then talk about $x_{i}^j$ for a couple of lines of the algorithm, before dropping the lower index. I think this is because there’s only one output logit so after the attention you can drop which token the input is coming from, but I still found it confusing at first (because you never say what I just wrote). It felt important to specify that the lower index of x is tokens for understanding the sum over k in the constant attention equation.\n6.\tFor the next description you switch notation but still use x, but now without the top index rather than the bottom one, and use y and z. Could you highlight what is changing?\n\nAnd beyond the equations I thought that occasionally the appendix was a tough read. For example in appendix H you talked about adding an equal sign. I eventually looked at the caption for figure 19 and understood what that meant, but I thought I’d missed some previously discussed equals sign (I now realise this is a hangover from the original clocks paper). Making sure the writing doesn’t have these kind of moments when the reader hasn’t been told about something and isn’t completely sure where to find out about it seems good. Perhaps you could edit the writing and captions when you try and re-read the paper with fresh eyes to see what is confusing - or get some fresh eyes on it.\n\nA few of small things I am confused by: \n\n1.\tI think the sine and cosine addition formulae you are using in step 2 of the algorithm in appendix A, during the development of alpha and beta, are missing factors of 2. [since you use them so often maybe it would be good to state the sine and cosine addition formulae somewhere]\n2.\tIn section 3.4 it says the condition for there to be no antipodal pairs is for p to be prime, isn’t it for p to be odd? What am I missing?\n3.\tThe plots in figure 6 (and all figures like it in the appendix) are titled wrong.\n4.\tIn the formula for distance irrelevance i on the top row should i be a member of $\\mathbb{Z}_P$ not $\\mathbb{Z}_P^2$?\n\nIt seems there are a class of pizza like algorithms (e.g. the two in appendix A), and the evidence listed does not distinguish them. Is this true? Do you know which is happening? If not, perhaps figure 1 is misleading. Instead your claim is that step 3 is one example of a class of pizza type algorithms that are being implemented, and perhaps figure 1 could say that?'}, 'questions': {'value': '\n1.\tWhy do you compute the gradients after having projected to first 6 principal components of the embedding space? What happens if you don’t do this?\n2.\tFurther, why on earth did you think to make this gradient symmetry plot?! Did you already have the pizza algorithm in mind and knew this would distinguish them???\n3.\tIn table 1 it says non-circular algorithms show gradient symmetry, but in general (figure 9) it appears like they don’t. Why does it say this?\n4.\tThe phase transition appears to happen at slightly different points when measured by distance irrelevance or by gradient symmetry, is this true? This definitely seems true in the 2D phase plots. How do you interpret this?\n5.\tThis study restricts itself to circular algorithms, what proportion of models were circular? \n6.\tThe phase change is not discrete, i.e. it does not just jump from the most pizza-ey to the most clock-ey. This could be outside the scope, but what do you think happens in between? An algorithm that is a mixture of the two somehow? Or an output that is a mixture of both algorithms running concurrently? Any evidence in any direction?\n'}, 'limitations': {'value': 'The authors did a good job discussing limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper takes a closer look at the mechanistic explanation of neural networks learning to perform modular addition expanding on recent work that argued that such networks discover a simple ""clock"" algorithm. The authors demonstrate that changes in initialization and hyperparameters can lead to the discovery of qualitatively different algorithms - most notably what is referred to here as the ""pizza"" algorithm. This provides evidence that even the simple learning problem of modular addition leads to the discovery of diverse solutions in neural networks and mechanistic explanation requires a more complex analysis.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper is well written and succeeds in clearly communicating the findings on an active topic in the field of mechanistic interpretability. The analysis is carefully conducted, empirical results are mostly convincing and the conclusion is of importance for the broader field.'}, 'weaknesses': {'value': 'One of the main claims of the paper is that ""some networks very similar to the ones trained by [1] preferentially implement a qualitatively different approach"" but most of the evidence presented for such different solutions only apply to models that (transiently) remove the attention mechanism.'}, 'questions': {'value': '1. Focusing on one of the main claims that ""some networks very similar to the ones trained by [1] preferentially implement a qualitatively different approach"": What is the fraction of neural networks with attention rate 1 that according to your metrics implement the ""pizza"" algorithm? Judging from Figure 6 it seems to me that this claim might be too strong if the originally investigated model with full attention almost always discovers ""clock"" solutions.\n2. You state that you also find ""non-circular algorithms"" in your trained networks. What fraction of trained models is non-circular and removed from the main analysis? Again this would be especially insightful to understand in dependence of the attention rate.\n3. How are Distance Irrelevance and Gradient Symmetricity related to each other? From my understanding they both intend to measure the same property (pizza vs clock). A scatter plot showing one vs. the other might give some insight on their relationship. \n4. In cases where the metrics contradict each other (judging from Figure 6 this sometimes happens), can you still make a confident statement on what algorithm such solutions implement?\n6. Could you elaborate how you come to the conclusion that some solutions ""implement multiple, imperfect copies of either the Clock or Pizza algorithm in parallel.""? How do such solutions work?\n7. Could you elaborate why accompanied pizzas achieve almost perfect accuracy (footnote of page 6) despite the failure mode of antipodal pairs?\n8. In section 3.4 you conjecture that ""accompanying pizzas"" are primarily used early in training. Would it be possible to test this hypothesis by comparing the accuracy of ""accompanied pizzas"" early in training with and without the hypothesised ""accompanying pizzas""?\n9. Minor point: The word ""symmetricity"" is unfamiliar to me. Is there a reason to deviate from the more common term symmetry, i.e. calling your metric ""Gradient Symmetry""?'}, 'limitations': {'value': 'Limitations have been addressed appropriately.\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks'}, 'authors': {'value': ['Ziqian Zhong', 'Ziming Liu', 'Max Tegmark', 'Jacob Andreas']}, 'authorids': {'value': ['~Ziqian_Zhong1', '~Ziming_Liu2', '~Max_Tegmark1', '~Jacob_Andreas1']}, 'keywords': {'value': ['mechanistic interpretability', 'algorithmic phase transitions', 'arithmetic learning', 'neural network', 'transformer', 'ensemble']}, 'abstract': {'value': 'Do neural networks, trained on well-understood algorithmic tasks, reliably rediscover known algorithms? Several recent studies, on tasks ranging from group operations to in-context linear regression, have suggested that the answer is yes. Using modular addition as a prototypical problem, we show that algorithm discovery in neural networks is sometimes more complex: small changes to model hyperparameters and initializations can induce discovery of qualitatively different algorithms from a fixed training set, and even learning of multiple different solutions in parallel. In modular addition, we specifically show that models learn a known *Clock* algorithm, a previously undescribed, less intuitive, but comprehensible procedure we term the *Pizza* algorithm, and a variety of even more complex procedures. Our results show that even simple learning problems can admit a surprising diversity of solutions, motivating the development of new tools for mechanistically characterizing the behavior of neural networks across the algorithmic phase space.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/3b568a3e9df76cfcf2046d707cc5bf6bbc99b8db.pdf'}, 'TLDR': {'value': 'We find that neural networks do not always rediscover known algorithms (Clock), but also discover new ones (Pizza), with modular addition as a prototypical example.'}, 'supplementary_material': {'value': '/attachment/924775104b53fd9742ebd3872f156cc829bcbfdb.zip'}, '_bibtex': {'value': '@inproceedings{\nzhong2023the,\ntitle={The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks},\nauthor={Ziqian Zhong and Ziming Liu and Max Tegmark and Jacob Andreas},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=S5wmbQc1We}\n}'}, 'paperhash': {'value': 'zhong|the_clock_and_the_pizza_two_stories_in_mechanistic_explanation_of_neural_networks'}}]"
"['Samir Yitzhak Gadre', 'Gabriel Ilharco', 'Alex Fang', 'Jonathan Hayase', 'Georgios Smyrnis', 'Thao Nguyen', 'Ryan Marten', 'Mitchell Wortsman', 'Dhruba Ghosh', 'Jieyu Zhang', 'Eyal Orgad', 'Rahim Entezari', 'Giannis Daras', 'Sarah Pratt', 'Vivek Ramanujan', 'Yonatan Bitton', 'Kalyani Marathe', 'Stephen Mussmann', 'Richard Vencu', 'Mehdi Cherti', 'Ranjay Krishna', 'Pang Wei Koh', 'Olga Saukh', 'Alexander Ratner', 'Shuran Song', 'Hannaneh Hajishirzi', 'Ali Farhadi', 'Romain Beaumont', 'Sewoong Oh', 'Alex Dimakis', 'Jenia Jitsev', 'Yair Carmon', 'Vaishaal Shankar', 'Ludwig Schmidt']",NeurIPS,DataComp_ In search of the next generation of multimodal datasets,https://neurips.cc/virtual/2023/oral/73739,2023," Multimodal datasets are a critical component in recent breakthroughs such as CLIP, Stable Diffusion and GPT-4, yet their design does not receive the same research attention as model architectures or training algorithms. To address this shortcoming in the machine learning ecosystem, we introduce DataComp, a testbed for dataset experiments centered around a new candidate pool of 12.8 billion image-text pairs from Common Crawl. Participants in our benchmark design new filtering techniques or curate new data sources and then evaluate their new dataset by running our standardized CLIP training code and testing the resulting model on 38 downstream test sets. Our benchmark consists of multiple compute scales spanning four orders of magnitude, which enables the study of scaling trends and makes the benchmark accessible to researchers with varying resources. Our baseline experiments show that the DataComp workflow leads to better training sets. Our best baseline, DataComp-1B, enables training a CLIP ViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet, outperforming OpenAI's CLIP ViT-L/14 by 3.7 percentage points while using the same training procedure and compute. We release \datanet and all accompanying code at www.datacomp.ai.",Oral 5D Vision,https://openreview.net/pdf?id=dVaWCDMBof,https://openreview.net/forum?id=dVaWCDMBof,dVaWCDMBof,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (Oral)'}, 'comment': {'value': '- This paper presents DataComp, a new image-text dataset and benchmark designed to offer new avenues for research and evaluation. \n- Both reviewers and the Area Chair agree that this work promises significant contributions to the vision-language research community. Not only does it provide a large-scale dataset, but it also includes a comprehensive benchmark and leaderboard, as well as an extensive set of baseline experiments. \n- The authors have engaged in the discussion with reviewers to address questions and concerns, including dataset licensing and specific requirements for image generation, etc. \n- Considering the reviews and the potential impact of the paper, the Area Chair strongly recommends acceptance of the paper.'}}, {'title': {'value': 'End of the author / reviewer discussion period'}, 'comment': {'value': 'Dear Reviewer TaGM,\n\nThis is just a brief reminder that the author / reviewer discussion period ends in about 23h (Aug 29 8 pm UTC / 1 pm PT). We understand that you are traveling right now and may not be able to participate in the discussion period. We would still very much appreciate it if you could revisit your review and score after your return in light of our response particularly regarding the licensing questions you raised.\n\nThank you for your feedback and safe travels!\n\nBest,\n\nThe DataComp Team'}}, {'title': {'value': 'End of the author / reviewer discussion period'}, 'comment': {'value': 'Dear Reviewer pyn4,\n\nWe would like to thank you again for your thoughtful feedback and remarks. This is just a brief reminder that the author / reviewer discussion period ends in about 23h (Aug 29 8 pm UTC / 1 pm PT). In case you have any remaining questions, we would be happy to respond promptly.\n\nBest,\nThe DataComp Team'}}, {'comment': {'value': 'I want to thank the authors for their thoughtful response and the new experiments conducted in Section M of the appendix. I am confident that the community will benefit a lot from this paper; the insights and results derived from the experiments are invaluable.'}}, {'comment': {'value': 'Thanks for your reply. I believe this work will benifit the VLP community very much.'}}, {'title': {'value': 'Early response'}, 'comment': {'value': 'Dear Reviewer TaGM,\n\nThank you again for your kind reminder and offer to increase your score if we address the licensing question. We hope you are having a good trip! We posted our response to your concerns on August 21 (see below). We would be very grateful if you get a chance to respond and / or adjust your score, and would be happy to provide further clarifications if requested.\n\nSafe travels!\n\nBest,\n\nThe DataComp Team'}}, {'comment': {'value': 'Thank you for your useful comments, and for engaging with us to improve our work. Please see our responses to your individual comments below, and please let us know if there is anything else we can do to further improve our paper.\n\n***\n\n#### **Generation**\n\nThank you for pointing out the use of our dataset for image generation tasks. In response to your comments, we ran new experiments on image generation by fine-tuning Stable Diffusion models on DataComp-1B. As also mentioned in our response to Reviewer pyn4, training models for image generation from scratch using our dataset, while an interesting avenue for future work, is unfortunately too costly to run in the time provided for the response. For example, training a Stable Diffusion model from scratch would take approximately 24,000 GPU hours / 50,000 USD (https://www.mosaicml.com/blog/stable-diffusion-2). \n\nInstead of training from scratch, we fine-tuned a Stable Diffusion model, starting from stable-diffusion-2-base and running for 4M samples from each of DataComp-1B and LAION-2B. Results on this preliminary experiment are shown below. FID is measured as shown here: https://github.com/j-min/DallEval/tree/main/quality. Average and standard deviation are reported across 3 runs of fine-tuning. The base model is not fine-tuned.\n\n| Data | FID score |\n|------|-----------|\n| DataComp-1B | 15.75 $\\pm$ 1.20 |\n| LAION-2B\t   | 15.81 $\\pm$ 0.96 |\n| Stable Diffusion 2 Base | 16.46 |\n \nWhile this is a preliminary experiment and does not show a complete picture on training models for image generation using our data, it does show the potential of our dataset for image generation. We hope that we or others can explore this direction as part of future work. \n\n\n***\n\n#### **Using captioning models to augment datasets.**\n\nWe agree with the reviewer’s suggestion. In our paper we wanted to provide strong baselines for our benchmark, but also wanted to leave more complex avenues of investigation (e.g., figuring out how best to use captioning models to augment datasets) to future participants. **Since DataComp was released, the suggested idea has been successfully validated by follow-up work**. In particular, Ngyuen et al. [1] showed how automatically generated captions can be used to improve image-text datasets. Their best method using captions generated by BLIP2 outperform the best filtering method proposed in our paper by 2 percentage points on ImageNet and 4 percentage points on average across the 38 tasks at the medium scale. They also show large improvements on retrieval, specifically on the Flickr and MS-COCO datasets. Overall, their experiments and results empirically confirm that generated captions can be useful sources of augmentation. Also thank you for the reference. We **added the reference** to our related work section on large-scale multimodal datasets (L108).\n\n***\n\n#### **References**\n\n[1] Nguyen, Thao, et al. ""Improving Multimodal Datasets with Image Captioning."" arXiv preprint https://arxiv.org/abs/2307.10350, (2023). https://arxiv.org/abs/2307.10350.'}, 'title': {'value': 'Response to Reviewer GJCx'}}, {'comment': {'value': '#### **DataComp leaderboard**\n\nThanks for the question. At the time of our submission, DataComp was relatively new (it appeared on arxiv at the end of April) and the only methods implemented were the strategies from our paper, which we called baselines. Since then, we have seen new submissions, which are now on the leaderboard (https://www.datacomp.ai/leaderboard.html). For example, T-MARS [3] improves medium scale filtering track ImageNet zero-shot numbers to 0.330, which is a 3.3 percentage point improvement over the prior state-of-the-art at this scale. Likewise work from Nguyen et al. [4] improves large scale BYOD track ImageNet zero-shot numbers to 0.643, which is a 2.2 percentage point improvement. \n\n***\n\n#### **Consistency in data curation strategies across scales for more complex strategies.**\n\nThank you for acknowledging our effort to understand the consistency of various methods across compute scales. Results from Nguyen et al. [4] point towards consistency across scales for more complex data curation strategies. In particular, Nguyen et al. experiment with using synthetic captions to augment data from CommonPool. Their method yields the 2nd best strategy at the small scale and the best known strategy at medium and large scales in the BYOD track.\n\n***\n\n#### **Correlation between small and xlarge scale results.**\n\nThank you for the question, which we agree is important. We originally did not present the small vs xlarge correlation in the paper due to the small number of experiments we ran at the xlarge scale (which are computationally expensive with about 40,000 A100 hours per training run). However, we present rank correlation (Spearman\'s rank correlation coefficient) in the table below.\n\n\n| Metric            | small vs xl| medium vs xl| large vs xl|\n|-------------------|-------------|------------|------------|\n| ImageNet acc.     | 0.638       | 0.986      | 1.000      |\n| Avg. pref. metric | 0.574       | 0.794      | 0.986      |\n\nWhile the correlation between small and xlarge is 0.638 for ImageNet and 0.574 for average, these numbers increase substantially for the medium and large scales. We would also like to point out that the medium scale is feasible for many academic labs. To put this in context, training at the small scale corresponds roughly to fine-tuning a model on ImageNet (e.g., fine-tuning for 10 epochs or ~4 A100 hours), while training a medium scale model corresponds to training on ImageNet from scratch (e.g., training for 100 epochs or ~40 A100 hours). Lastly, Figure 21 suggests that while there are some filtering strategies that do well at larger scales that would be difficult to find at smaller scales, better filtering strategies at smaller scales typically translate to better filtering strategies at larger scales.\n\n***\n\n#### **References**\n\n[1] Zhou, Xingyi, et al. “Detecting twenty-thousand classes using image-level supervision.” ECCV (2022). https://arxiv.org/abs/2201.02605.\n\n[2] Gupta, Agrim, et al. “”LVIS: A dataset for large vocabulary instance segmentation.” CVPR (2019). https://arxiv.org/abs/1908.03195.\n\n[3] Maini, Pratyush, et al. “T-MARS: Improving Visual Representations by\nCircumventing Text Feature Learning.” arXiv preprint arXiv:2307.03132 (2023). https://arxiv.org/abs/2307.03132.\n\n[4] Nguyen, Thao, et al. ""Improving Multimodal Datasets with Image Captioning."" arXiv preprint arXiv:2307.10350 (2023). https://arxiv.org/abs/2307.10350.'}, 'title': {'value': 'Response to Reviewer N9Hd (part 2/2)'}}, {'comment': {'value': 'Thank you for your encouraging review. We address specific comments below, and please let us know if there is anything else we can help clarify or do to further strengthen our paper.\n\n***\n\n#### **More complex filtering methods: controlling for object classes, number of objects, and object positions.**\n\nThank you for the valuable suggestion! In response we **added new experiments and discussion to the manuscript (Appendix M)**. While controlling for such factors is common in the supervised settings, experimenting with analogous strategies in the context of multimodal datasets and CLIP training is a pertinent direction. Inspired by your comments, we use the Detic detector [1] to annotate the medium pool (128M sample pool) by extracting bounding boxes and class labels for the 1203 LVIS [2] objects categories. Following the original Detic paper, we retain predictions whose confidence score exceeds 0.5. Based on these annotations, we construct the following **five new strategies:**\n\n- **Object exists:** Subset for which there exists at least one detection from the 1203 LVIS categories.\n- **Object centered:** Subset for which there exists at least one detection from the 1203 LVIS categories with a bounding box center falling in the center grid cell of a 3x3 grid superimposed on the image.\n- **Balancing by class:** We define 1204 buckets—1203 buckets corresponding to the LVIS classes and an additional bucket for images that do not have any detections. For each image in the medium pool, we assign the image to the bucket(s) corresponding to the detected classes. We then construct a dataset such that there are an equal number of samples from each bucket and the total number of samples specified by a particular scale (e.g., 128M samples for medium scale). Note, for rare classes there can be many repeated samples and for common classes only a subset of the total samples will be in the dataset.\n- **Balancing by position:** We define 26 buckets—0, 2, …, 24 corresponding to 5x5 grid locations in an image. An image is added to bucket(s) when it contains a bounding box whose center falls in the bucket’s grid cell. The 25th bucket contains images for which there are no detections. We again construct a dataset such that there are an equal number of samples from each bucket.\n- **Balancing by count:** We define 12 buckets—0, 1, 2, …, 10 corresponding to zero to ten detections in an image and a twelfth bucket corresponding to images with more than ten detections. We yet again construct a dataset such that there are an equal number of samples from each bucket.\n\nWe employ each of these strategies at the medium scale. Since the above strategies can be composed with any starting pool, we additionally apply each of the above Detic-based strategies to our previous best medium scale filtered pool: Image-based ∩ CLIP score (L/14 30%). This yields a total of 10 new datasets.\n\nOur results are summarized in the table below. In summary: 1) The Image-based ∩ CLIP score (L/14 30%) baseline still performs best. 2) Balancing data in the context of multimodal CLIP training remains an open problem. All balancing strategies lead to divergence of the CLIP contrastive loss and result in poor model performance. We hypothesize that this is due to the long-tailed nature of the data distribution, which leads to many repeated samples in our balanced data construction. This in turn, increases the likelihood that samples are contrasted with themselves in the loss computation.\n\n|                                               | ImageNet | Average over 38 datasets |\n|-----------------------------------------------|----------|--------------------------|\n| Baseline: Nofilter                            | 0.176    | 0.258                    |\n| &nbsp;&nbsp;&nbsp;&nbsp;∩ Object exists                               | 0.181    | 0.263                    |\n| &nbsp;&nbsp;&nbsp;&nbsp;∩ Object centered                             | 0.187    | 0.263                    |\n| &nbsp;&nbsp;&nbsp;&nbsp;∩ Balancing by class                          | 0.038    | 0.141                    |\n| &nbsp;&nbsp;&nbsp;&nbsp;∩ Balancing by position                       | 0.040    | 0.148                    |\n| &nbsp;&nbsp;&nbsp;&nbsp;∩ Balancing by object count                   | 0.127    | 0.221                    |\n| Baseline: Image-based ∩ CLIP score (L/14 30%) | 0.297    | 0.328                    |\n| &nbsp;&nbsp;&nbsp;&nbsp;∩ Object exists                               | 0.289    | 0.319                    |\n| &nbsp;&nbsp;&nbsp;&nbsp;∩ Object centered                             | 0.247    | 0.286                   |\n| &nbsp;&nbsp;&nbsp;&nbsp;∩ Balancing by class                          | 0.034    | 0.136                    |\n| &nbsp;&nbsp;&nbsp;&nbsp;∩ Balancing by position                       | 0.036    | 0.136                    |\n| &nbsp;&nbsp;&nbsp;&nbsp;∩ Balancing by object count                   | 0.068    | 0.169                    |\n\n***'}, 'title': {'value': 'Response to Reviewer N9Hd (part 1/2)'}}, {'comment': {'value': '#### **References**\n\n[1] Shen, Sheng, et al. ""How much can clip benefit vision-and-language tasks?."" arXiv preprint arXiv:2107.06383 (2021). https://arxiv.org/abs/2107.06383.\n\n[2] Antol, Stanislaw, et al. ""Vqa: Visual question answering."" Proceedings of the IEEE international conference on computer vision. 2015. https://arxiv.org/abs/1505.00468.\n\n[3] Ilharco, Gabriel, et al. ""Patching open-vocabulary models by interpolating weights."" Advances in Neural Information Processing Systems 35 (2022): 29262-29277. https://arxiv.org/abs/2208.05592.\n\n[4] Song, Haoyu, et al. ""Clip models are few-shot learners: Empirical studies on vqa and visual entailment."" arXiv preprint arXiv:2203.07190 (2022). https://arxiv.org/abs/2203.07190.\n\n[5] Yang, Kaiyu, et al. ""A study of face obfuscation in imagenet."" International Conference on Machine Learning. PMLR, 2022.'}, 'title': {'value': 'Response to Reviewer pyn4 (part 2/2)'}}, {'comment': {'value': 'Thank you for your thoughtful feedback and remarks. In response to your comments, we ran several new experiments, which we hope will make our paper stronger. Our responses are detailed below.\n\n***\n\n#### **Task coverage**\n\nThank you for your suggestion! We agree about the importance of a comprehensive evaluation suite, and ran additional experiments in light of your comments. Our original evaluation suite already consists of dozens of tasks on diverse domains, including object recognition, counting, distance prediction, geolocation, texture classification, satellite imagery recognition, classification tasks in the medical domain, scene recognition, image retrieval, text retrieval and commonsense association. In addition, we also provided multiple bias and fairness analyses.\n\nIn response to your comments, **we ran additional VQA evaluations** for all models we trained. More specifically, following Shen et al [1], we use CLIP models to contrast images with prompts formed by the questions and each candidate answer, without fine-tuning (as done for our other DataComp evaluations). Using the VQA v1 dataset [2], for each candidate answer, we construct a text prompt that also includes the question following the template “Question: [question text] Answer: [answer text]”. This text is fed to CLIP’s text encoder. As previously noted by multiple authors, CLIP models struggle on this task, potentially due to the mismatch between the text in the downstream task and the captions seen during pre-training [1,3,4]. Nonetheless, **we observe a strong correlation between VQA performance and ImageNet accuracy (0.877)** and between VQA performance and average accuracy on the rest of our evaluation suite (0.872). **Figure 17 in Appendix O.1** of our updated manuscript shows our full results.\n\nIn addition to VQA, we also ran new experiments on image generation, as detailed in the “model coverage / image generation” section below.\n\n***\n\n#### **Face blurring**\n\nThank you for bringing up that face blurring a dataset can affect the quality of image generation. As pointed out, our experiments and previous literature suggest that such blurring has minimal effect on recognition tasks like ImageNet (Yang et al., 2021 [5], and our Appendix G). However, we agree that the effects of this design decision may be amplified in generative settings. Our competition is primarily focused on discriminative tasks, and when designing our dataset, we wanted to prioritize safety by better protecting the privacy of individuals through automatically blurring faces in our download tooling. That being said, we acknowledge that there are trade-offs between protecting people’s privacy and creating generative models that can reliably generate faces. We added this discussion in our Appendix G and hope others will consider these trade-offs when curating datasets of their own.\n\n***\n\n#### **Model coverage and image generation**\n\nThank you for pointing out the possibility of using models other than CLIP to evaluate our dataset. For the rebuttal, we additionally used our data for image generation, and **ran new experiments on image generation by fine-tuning Stable Diffusion models on DataComp-1B**. We note that training models for image generation from scratch, while an interesting avenue for future work, is unfortunately too costly to run in the time provided for the response. For example, training a Stable Diffusion model from scratch would take approximately 24,000 GPU hours / 50,000 USD. (https://www.mosaicml.com/blog/stable-diffusion-2).\n\nInstead of training from scratch, we fine-tuned a Stable Diffusion model, starting from stable-diffusion-2-base and running for 4M samples from each of DataComp-1B and LAION-2B. Results on this preliminary experiment are shown below. FID is measured as shown here: https://github.com/j-min/DallEval/tree/main/quality. Average and standard deviation are reported across 3 runs of fine-tuning. The base model is not fine-tuned.\n\n| Data | FID score |\n|------|-----------|\n| DataComp-1B | 15.75 $\\pm$ 1.20 |\n| LAION-2B\t   | 15.81 $\\pm$ 0.96 |\n| Stable Diffusion 2 Base | 16.46 |\n \nWhile this is a preliminary experiment and does not show a complete picture on training models for image generation using our data, it does show the potential of our dataset for image generation. We hope that we or others can explore this direction as part of future work. \n\n***'}, 'title': {'value': 'Response to Reviewer pyn4 (part 1/2)'}}, {'comment': {'value': '#### **BYOD** \n\nFor our baselines, **BYOD experiments use preexisting image-text datasets** introduced in prior work, including Conceptual Captions [1,2], RedCaps [3] and LAION [4,5]. We do not re-release these datasets as part of our project. To clarify, **we added the following** line:\n\n> 3.3 The bring your own data (BYOD) track L195-197: In Section 4.2 and Appendix P.2 we describe our exploration using existing public, image-text datasets. These datasets are acquired from their respective sources and are not re-released as part of DataComp.\n\nThere is also a question of how BYOD participants should handle dataset releases. While considerations may differ by jurisdiction the participants are in, we hope that the DataComp, CommonPool, and prior dataset releases [1-5] provide participants with a starting point for exploring options for their own dataset and model releases.\n\nBeyond licensing, we note other potential concerns in the BYOD track including reproducibility, safety, and overlap with our evaluation suite. As stated in our rules (Appendix A), we do not allow BYOD datasets to contain test images from any of the evaluation tasks. We also encourage releasing the image urls or the images themselves in addition to the text for each image, and rigorous documentation of face-blurring and other data safety checks. We open-source all of our tools to make these steps simple and straightforward for participants. As stated in our rules, **we reserve the right to run our own checks on participant provided data and disqualify entries that do not meet adequate standards.**\n\nPlease let us know if you have outstanding concerns related to the BYOD track. We are happy to provide more detail and clarification!\n\n***\n\n#### **References**\n\n\n[1] Sharma, Piyush, et al. ""Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning."" Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2018. https://aclanthology.org/P18-1238/.\n\n[2] Changpinyo, Soravit, et al. ""Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021. https://arxiv.org/abs/2102.08981.\n\n[3] Desai, Karan, et al. ""RedCaps: Web-curated image-text data created by the people, for the people."" arXiv preprint arXiv:2111.11431 (2021). https://arxiv.org/abs/2111.11431.\n\n[4] Schuhmann, Christoph, et al. ""Laion-400m: Open dataset of clip-filtered 400 million image-text pairs."" arXiv preprint arXiv:2111.02114 (2021). https://arxiv.org/abs/2111.02114.\n\n[5] Schuhmann, Christoph, et al. ""Laion-5b: An open large-scale dataset for training next generation image-text models."" Advances in Neural Information Processing Systems 35 (2022): 25278-25294. https://arxiv.org/abs/2210.08402.'}, 'title': {'value': 'Response to Reviewer TaGm (part 2/2)'}}, {'comment': {'value': '#### **CommonPool dataset licensing**\n\nFirst, we would like to thank you for giving us a heads up about your travels and apologize for any inconvenience caused by the short turnaround time in the rebuttal process. We are very thankful for your diligence and will be particularly attentive in the next 24 hours should any additional clarification be needed.\n\nThank you for bringing up the issue of dataset licensing, which we agree is an important point. While our initial submission mentioned in the datasheet appendix that the **“url-text indices for the dataset are distributed under a CC-BY-4.0 license” (L1887)**, we agree that this should be clearer in the main text. Hence **we made the following additions to the main paper**, which appear in the updated PDF and that are quoted here for convenience. \n\n> “To facilitate the filtering track, our second contribution is CommonPool, a dataset of 12.8B image-text pairs collected from Common Crawl and currently the largest public image-text dataset. We release CommonPool as an index of image url-text pairs under a CC-BY-4.0 license” (L46-47).\n\n> “We construct such a pool, CommonPool, from Common Crawl [3]. CommonPool is distributed as an index of image url-text pairs under a CC-BY-4.0 license” (L158).\n\nWe additionally **added a CC-BY-4.0 license to our HuggingFace dataset releases** (e.g., https://huggingface.co/datasets/mlfoundations/datacomp_xlarge). We also added the following statement to our HuggingFace dataset release README:\n\n> “We distribute the image url-text samples and metadata under a standard Creative Common CC-BY-4.0 license. The individual images are under their own copyrights.”\n\nWhen discussing licensing, it is important to note that **we only distribute a URL index pointing to images on the public internet**. We do not distribute the images themselves. This is in line with a number of similar datasets, including Conceptual Captions [1,2], RedCaps [3] and LAION [4,5], which also do not distribute images directly. \n\nHowever, we understand that copyrights associated with particular images can also be relevant to DataComp participants. Hence we provide additional discussion on this topic below.\n\nTo make the distinction between our released index and the images that participants download more clear, we **added terms of service to our HuggingFace dataset releases** as follows:\n\n> We have terms of service that are similar to those adopted by HuggingFace (https://huggingface.co/terms-of-service), which covers their dataset library. Specifically, any content you download, access or use from our index, is at your own risk and subject to the terms of service or copyright limitations accompanying such content. The image url-text index, which is a research artifact, is provided as is. By using said index, you assume all risks, including but not limited to, liabilities related to image downloading and storage.\n\nFurthermore, in contrast to ongoing legal challenges involving generative AI products, CommonPool and DataComp are not commercial products but research artifacts for the scientific community to explore dataset curation in a controlled setting. Moreover, our DataComp benchmark focuses on training CLIP-style classifiers, not generative models.\n\nFinally, we note that legal aspects and research ethics around training AI models on images and text publicly available on the web are evolving. Similarly to existing datasets [4,5], we currently offer the possibility of requesting a takedown of particular instances in our pools due to privacy or any other concerns (see Appendix S, Q32). Overall, **we are committed to keeping CommonPool and DataComp compliant as new legal precedents arise and new standards for research ethics in AI emerge.**\n\nThank you again for bringing up the important topic of licensing. Please let us know if we can further clarify related questions.'}, 'title': {'value': 'Response to Reviewer TaGm (part 1/2)'}}, {'title': {'value': 'Overall response'}, 'comment': {'value': 'We thank the reviewers for their time, constructive comments, and positive feedback. We are particularly grateful for reviewers pointing out that “the amount of consideration put into this paper is exemplary” (N9Hd), that the paper is “great” (pyn4)”,  “big and comprehensive” (TaGm), and that “the work is complete” (GJCx). All reviewers appreciated our experimentation, with many reviewers citing in particular the 300+ baselines that we ran (pyn4, N9Hd, GJCx). All reviewers also noted our attention to dataset safety (e.g., NSFW removal and face blurring). \n\nHere we summarize the major additions in response to the reviews. **We have uploaded a revised draft which includes new experiments and clarifications as suggested by reviewers.** We added details to the paper and data repository about licensing (i.e., we distribute image url-text pairs under a CC-BY-4.0 license). Moreover, we added evaluation on VQA to the paper, finding strong positive correlation with performance on ImageNet. We also explored applications to image generation for purposes of the rebuttal. While our competition focuses on discriminative tasks, we acknowledge that text-conditional image generation is a critical use case for multimodal datasets, and find that fine-tuning StableDiffusion on DataComp-1B is competitive with fine-tuning on LAION-2B. We also added more complex filtering baselines accounting for object categories, object count, and object position to the paper.\n\n**We address all reviewer feedback in more detail in the comments below.** The reviews have already improved our paper substantially and we believe that additional feedback will further strengthen our work. We are eager to engage further with the reviewers and are happy to provide written clarification or additional empirical support!'}}, {'title': {'value': 'Early response?'}, 'comment': {'value': 'Hi DataComp team - Just as a heads up, I will be on vacation with no access to internet starting August 23 for roughly two weeks until September 5. I realize this means you have a somewhat shorter period to respond. If feasible, I would love to have an earlier response so I can incorporate your comments and feedback into my final review and give them full weight.\n\nThanks :)'}}, {'title': {'value': 'Data-centric approach to multi-modal data, many contributions'}, 'rating': {'value': '8: Top 50% of accepted papers, clear accept'}, 'confidence': {'value': '3: The reviewer is fairly confident that the evaluation is correct'}, 'summary_and_contributions': {'value': ""1. Benchmark competition for multi-modal dataset design and a variety of results from that. The data-centric competition idea doesn't appear to be new, but the focus on multi-modal data is new and the scale is novel.\n\n2. Common pool image-text dataset and a dataset filtering competition on it.\n\n3. Look at 'neural scaling laws for data', for the above dataset and filtering.\n\n4. Many experiments and neat results\n\n5. A new dataset created by applying the best filtering approaches.""}, 'strengths': {'value': '1. Data centric approach is good.\n2. Big and comprehensive paper, with a lot packed into it.\n3. Love the attention to multi-modal data, definitely an under-explored area\n4. Cool results'}, 'opportunities_for_improvement': {'value': ""Licensing - please tell the reader the license for the data!\n\nHow do you handle BYOD? Seems like there's lots of potential risks, would love to read about that.""}, 'limitations': {'value': 'Licensing. I hate to sound like a broken record on this topic.'}, 'correctness': {'value': 'Seems good.'}, 'clarity': {'value': 'Yes.'}, 'relation_to_prior_work': {'value': 'Reasonably so.'}, 'documentation': {'value': ""I couldn't tell anything about licensing of the dataset in the paper or by poking around on the website. Is it CC-BY? Unknown? etc.""}, 'ethics': {'value': 'Good news: The authors paid careful attention to issues of safety, PII filtering, etc.\n\nBad news: I see very little / no information on the licensing status of the datasets discussed.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'I have increased my score to 8. I think this is super interesting work, and the fact that the underlying datasets are problematic is important to explicitly acknowledge. This is a tremendous resource but it comes with very real risks.'}}, {'title': {'value': 'Exceptional large scale dataset with high quality analysis and performance'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'summary_and_contributions': {'value': 'The paper introduces five major contributions related to the development of multimodal datasets:\n\nThe main contribution is the development of DataComp, a benchmark for multimodal dataset design. Unlike traditional benchmarks where the dataset is fixed and researchers propose new algorithms, DataComp encourages innovation in creating new training sets. Models are evaluated based on a testbed of various classification and retrieval tasks.\n\nThe paper also introduces CommonPool, a dataset consisting of 12.8 billion image-text pairs collected from the Common Crawl. This is currently the largest public image-text dataset and is aimed at improving the safety of image-text datasets.\n\nThe authors investigate scaling trends in dataset design. DataComp includes four scales, ranging from 12.8M to 12.8B samples, allowing researchers with different resources to participate in the benchmark.\n\nThe paper presents over 300 baseline experiments, including various filtering techniques. One of the key findings is that smaller, more rigorously filtered datasets can often lead to models that generalize better than those trained on larger datasets from the same pool.\n\nLastly, the paper introduces DataComp-1B, a new state-of-the-art multimodal dataset obtained by combining their two most promising filtering baselines. The new dataset enabled them to train a model to an ImageNet zero-shot accuracy of 79.2%, which is a significant computational cost reduction compared to training larger models and it outperforms the original CLIP model by OpenAI.\n'}, 'strengths': {'value': '(1) The proposed CommonPool is the largest openly available dataset for training vision-and-language models.\n\n(2) The data collection and filtering process has been comprehensively discussed to support community investigation and further improvement.\n\n(3) Experiments support that CLIP models trained on DataComp-1B exceed the performance of original CLIP models trained on the private dataset.\n\n(4) Over 300 baseline experiments are conducted to ensure the quality of their dataset and the validity of their conclusions.'}, 'opportunities_for_improvement': {'value': '(1) The task coverage could have been expanded. For example, VQA and image generation are not considered in the paper.\n\n(2) The authors cited a relevant work and conducted experiments to show that face blurring does not lead to performance degradation of a trained model. However, this is likely because the task coverage is limited. If other tasks as image generation are considered, face blurring does have detrimental effect to the performance. \n\n(3) The model coverage could have also been expanded, as only CLIP is considered. Image-conditioned language models and image generation models could have been explored.'}, 'limitations': {'value': 'The authors adequately addressed the limitations and potential negative societal impact of their work.'}, 'correctness': {'value': 'The dataset creation, testing, and evaluation methodology are all sound. This paper appears correct about its claims.\n'}, 'clarity': {'value': 'The paper is well written.'}, 'relation_to_prior_work': {'value': 'The paper clearly discusses how it relates to prior work.'}, 'documentation': {'value': 'The dataset and processing pipeline is open-source and well-documented.'}, 'ethics': {'value': 'The authors have discussed two major preprocessing steps implemented to ensure the safety and privacy of the datasets:\n\nSafety Preprocessing: The authors took rigorous measures to remove unsafe content from the Common Crawl data. They employed Detoxify to remove samples containing unsafe text, such as explicit or threatening language. For images with explicit content, they trained a classifier using the NSFW dataset and CLIP ViT-L/14 features. This resulted in the removal of approximately 19% of image-text pairs, reducing the initial sample size from around 16.8 billion to approximately 13.6 billion.\n\nFace Detection and Blurring: To preserve individual privacy, they used a face detector to find and blur faces in the images. The authors confirmed that this blurring process had minimal impact on the performance of the models, echoing observations made by other researchers.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'Great paper. I believe this paper ranks at least the top 15% of the whole submissions. '}}, {'title': {'value': 'The first step in finding the next generation of multimodal datasets is here!'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': '### Summary\n\nThe main goal of this paper is to discuss dataset curation and the importance of datasets in multimodal models. To this end, the authors have introduced DataComp, a new benchmark and testbed for dataset curation experiments. In this benchmark, the model architect and the training code are fixed, and the participant should find the suitable data, either by applying some filtering mechanism to the provided dataset `CommonPool` or by bringing their own data. This benchmark contains multiple training scales, ranging from *small* (suitable for low-budget tests) up to *xlarge* (industry scale budget).\n\nTo iterate on the main contributions of the paper:\n\n1. Introduction of the DataComp benchmark for designing multimodal (image-text) datasets. \n2. Introduction of `CommonPool`, a curated dataset comprising more than 12 billion image-text pairs.\n3. Extensive evaluation and experiments conducted using various filtering settings.\n4. Study of consistency trends across different scales.\n5. Introduction of `DataComp-1B`, a subset of `CommonPool`, which enables the training of CLIP models that outperform those trained on the `LAION` [1] and `OpenAI’s WIT` [2] datasets.\n\n\n### References: \n- [1] - Schuhmann, Christoph, et al. ""Laion-5b: An open large-scale dataset for training next generation image-text models."" Advances in Neural Information Processing Systems 35 (2022): 25278-25294.\n- [2] - Radford, Alec, et al. ""Learning transferable visual models from natural language supervision."" International conference on machine learning. PMLR, 2021.\n'}, 'strengths': {'value': '### Strengths\n\nThe topic that this paper addresses is becoming increasingly relevant with the advent of new foundation models and open-source models. A lot of papers have investigated model architecture, training methods, and optimization techniques, yet only a few focus on datasets. The recent trend in scaling up models requires massive amounts of data to be put into the models, but the quality of this data has received less attention. For example, from the perspective of language models, we know that high-quality data can lead to better models [1, 2]. This paper focuses on visual language models, in particular CLIP [3], to investigate the quality and importance of the data, something that feels missing from the literature. \n\nThe evaluation conducted in this paper is extensive, containing over 300 baselines over four different scaling power and seven filtering methods. The results leads to introduction of `DataComp-1B` dataset that is not only smaller than `LAION-2B` [4] but also lead to training CLIP-L/14 model that outperforms its LAION variant with $6.1$pp.\n\nThe amount of consideration put into this paper is exemplary. Each section in the main text is accompanied by a corresponding section in the supplementary material, which provides detailed explanations and further insights. Additionally, the paper provides an analysis of fairness and bias in the trained models which is extremely valuable. \n\n### References: \n- [1] - Zhou, Chunting, et al. ""Lima: Less is more for alignment."" arXiv preprint arXiv:2305.11206 (2023).\n- [2] - Mukherjee, Subhabrata, et al. ""Orca: Progressive learning from complex explanation traces of gpt-4."" arXiv preprint arXiv:2306.02707 (2023).\n- [3] - Radford, Alec, et al. ""Learning transferable visual models from natural language supervision."" International conference on machine learning. PMLR, 2021.\n- [4] - Schuhmann, Christoph, et al. ""Laion-5b: An open large-scale dataset for training next generation image-text models."" Advances in Neural Information Processing Systems 35 (2022): 25278-25294.'}, 'opportunities_for_improvement': {'value': 'The experiment conducted in this paper is extremely valuable and perhaps very expensive, but I feel the filtering processes used in this paper are pretty simple and not novel; they are just a collection of things the research community has explored before. I understand the main objective of this paper is something else, but it would be a good addition to have more interesting filtering (such as controlling for number of a particular object or animal in the dataset, number of objects in each image, positioning of objects inside the image, etc). \n'}, 'limitations': {'value': 'Yes. The limitations section of the paper already addressed possible impacts.'}, 'correctness': {'value': 'Yes. The construction of the dataset is based on filtering `CommonCrawl`, which is a pretty standard way to create a large dataset these days. All the models trained in this paper use a fixed training code and are compared against each other on several external validation sets (e.g., ImageNet). During the filtering process, the authors made sure that these validation sets were excluded from the training set.'}, 'clarity': {'value': 'Yes. The paper is clear and easy to read.'}, 'relation_to_prior_work': {'value': 'Yes. The paper has cited previous contributions.\n'}, 'documentation': {'value': ""The main text provides an overview of how the dataset is constructed (both `CommonPool` and `DataComp-1B`), and the appendix contains full details about each filtering step, as well as information about the dataset sheet.\nAll additional details can be found on the [Project's homepage](https://www.datacomp.ai/) or the [Github page](https://github.com/mlfoundations/datacomp).""}, 'ethics': {'value': ""No. The dataset underwent several filtering processes, for example, the removal of NSFW content and blurring of individuals' faces. I don't see any major concerns here.""}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': '- Is there any reason why the leaderboard contains only the baseline models? \n- From my perspective, the `small` scale is the most important, as it is something that most students can afford to run. My only concern is the consistency between the `small` and larger scales. I liked (and appreciated) the analysis conducted in section 5.2, but your filtering methods seem fairly simple. Do we have strong evidence that this trend holds across other filtering processes? btw, why there is not a `small` vs `xlarge` in Table 21?'}}, {'title': {'value': 'DataComp -- A useful work for the next generation of multimodal datasets'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'This work provide DATACOMP, a new benchmark and competition for multimodal dataset design, aiming to find a smaller but more effective subset from  COMMONPOOL(a dataset of 12.8B image-text pairs collected from Common Crawl,  another contribution of this work.).  The authors have done comprehensive experiments on scaling trends and filtering strategies for dataset design. Based on two most promising filtering baselines, they provide DATACOMP-1B, a new state-of-the-art multimodal dataset, which enables training a CLIP ViT-L/14 model with fewer computational cost  but better zero-shot performances compared with  OpenAI’s original CLIP ViT-L/14. '}, 'strengths': {'value': 'This work provide a public environment and massive resources  for the exploration of  the construction of an effective multi-modal dataset.  \nResults for over three hundred baseline experiments are provided, and evaluation is conducted on 38 downstream tasks.\n '}, 'opportunities_for_improvement': {'value': 'As far as I am concerned, this is a complete work. The only problem might be that the training target is only suitable for  understanding  tasks, the resulted dataset may not be the best for generative tasks. In general, this is a valuable work.'}, 'limitations': {'value': '1, The training target is only suitable for  understanding  tasks, the resulted dataset may not be the best for generative tasks.\n2, Only filtering-based methods are included.  However,  In some works, researchers  used a captioning model to augment image captions, like ** LIU, Yulong, ZHU, Guibo, ZHU, Bin, et al. TaiSu: A 166M Large-scale High-Quality Dataset for Chinese Vision-Language Pre-training. Advances in Neural Information Processing Systems, 2022, vol. 35, p. 16705-16717. **'}, 'correctness': {'value': 'Yes, the evaluation methods and experiment design are appropriate.'}, 'clarity': {'value': ""Yes, It' s easy to read and understand.""}, 'relation_to_prior_work': {'value': 'Yes.'}, 'documentation': {'value': 'Yes'}, 'ethics': {'value': 'The authors have considered the protection of privacy and the removal of harmful contents.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'Good job!'}}, {'title': {'value': 'DataComp: In search of the next generation of multimodal datasets'}, 'authors': {'value': ['Samir Yitzhak Gadre', 'Gabriel Ilharco', 'Alex Fang', 'Jonathan Hayase', 'Georgios Smyrnis', 'Thao Nguyen', 'Ryan Marten', 'Mitchell Wortsman', 'Dhruba Ghosh', 'Jieyu Zhang', 'Eyal Orgad', 'Rahim Entezari', 'Giannis Daras', 'Sarah M Pratt', 'Vivek Ramanujan', 'Yonatan Bitton', 'Kalyani Marathe', 'Stephen Mussmann', 'Richard Vencu', 'Mehdi Cherti', 'Ranjay Krishna', 'Pang Wei Koh', 'Olga Saukh', 'Alexander Ratner', 'Shuran Song', 'Hannaneh Hajishirzi', 'Ali Farhadi', 'Romain Beaumont', 'Sewoong Oh', 'Alex Dimakis', 'Jenia Jitsev', 'Yair Carmon', 'Vaishaal Shankar', 'Ludwig Schmidt']}, 'authorids': {'value': ['~Samir_Yitzhak_Gadre1', '~Gabriel_Ilharco1', '~Alex_Fang1', '~Jonathan_Hayase2', '~Georgios_Smyrnis1', '~Thao_Nguyen3', '~Ryan_Marten1', '~Mitchell_Wortsman1', '~Dhruba_Ghosh1', '~Jieyu_Zhang1', '~Eyal_Orgad1', '~Rahim_Entezari1', '~Giannis_Daras1', '~Sarah_M_Pratt1', '~Vivek_Ramanujan1', '~Yonatan_Bitton1', '~Kalyani_Marathe1', '~Stephen_Mussmann1', '~Richard_Vencu1', '~Mehdi_Cherti2', '~Ranjay_Krishna1', '~Pang_Wei_Koh1', '~Olga_Saukh1', '~Alexander_Ratner1', '~Shuran_Song3', '~Hannaneh_Hajishirzi1', '~Ali_Farhadi3', '~Romain_Beaumont1', '~Sewoong_Oh1', '~Alex_Dimakis1', '~Jenia_Jitsev1', '~Yair_Carmon1', '~Vaishaal_Shankar1', '~Ludwig_Schmidt1']}, 'keywords': {'value': ['CLIP', 'zero-shot', 'data curation', 'vision-and-language', 'datasets', 'pre-training', 'benchmark']}, 'abstract': {'value': ""Multimodal datasets are a critical component in recent breakthroughs such as CLIP, Stable Diffusion and GPT-4, yet their design does not receive the same research attention as model architectures or training algorithms. To address this shortcoming in the machine learning ecosystem, we introduce DataComp, a testbed for dataset experiments centered around a new candidate pool of 12.8 billion image-text pairs from Common Crawl. Participants in our benchmark design new filtering techniques or curate new data sources and then evaluate their new dataset by running our standardized CLIP training code and testing the resulting model on 38 downstream test sets. Our benchmark consists of multiple compute scales spanning four orders of magnitude, which enables the study of scaling trends and makes the benchmark accessible to researchers with varying resources. Our baseline experiments show that the DataComp workflow leads to better training sets. Our best baseline, DataComp-1B, enables training a CLIP ViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet, outperforming OpenAI's CLIP ViT-L/14 by 3.7 percentage points while using the same training procedure and compute. We release \\datanet and all accompanying code at www.datacomp.ai.""}, 'venue': {'value': 'NeurIPS 2023 Datasets and Benchmarks Oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Track/Datasets_and_Benchmarks'}, 'TLDR': {'value': 'A image-text dataset benchmark where model training is fixed and participants iterate on data curation strategies.'}, 'pdf': {'value': '/pdf/90caa8fe0e5cb94221e07f5550042b38fa6bd443.pdf'}, 'supplementary_material': {'value': '/attachment/636261a2aa4e37b7c700544b279c7c9a82a89802.pdf'}, '_bibtex': {'value': '@inproceedings{\ngadre2023datacomp,\ntitle={DataComp: In search of the next generation of multimodal datasets},\nauthor={Samir Yitzhak Gadre and Gabriel Ilharco and Alex Fang and Jonathan Hayase and Georgios Smyrnis and Thao Nguyen and Ryan Marten and Mitchell Wortsman and Dhruba Ghosh and Jieyu Zhang and Eyal Orgad and Rahim Entezari and Giannis Daras and Sarah M Pratt and Vivek Ramanujan and Yonatan Bitton and Kalyani Marathe and Stephen Mussmann and Richard Vencu and Mehdi Cherti and Ranjay Krishna and Pang Wei Koh and Olga Saukh and Alexander Ratner and Shuran Song and Hannaneh Hajishirzi and Ali Farhadi and Romain Beaumont and Sewoong Oh and Alex Dimakis and Jenia Jitsev and Yair Carmon and Vaishaal Shankar and Ludwig Schmidt},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\nyear={2023},\nurl={https://openreview.net/forum?id=dVaWCDMBof}\n}'}, 'paperhash': {'value': 'gadre|datacomp_in_search_of_the_next_generation_of_multimodal_datasets'}}]"
"['Saurabh Saxena', 'Charles Herrmann', 'Junhwa Hur', 'Abhishek Kar', 'Mohammad Norouzi', 'Deqing Sun', 'David Fleet']",NeurIPS,The Surprising Effectiveness of Diffusion Models for Optical Flow and Monocular Depth Estimation,https://neurips.cc/virtual/2023/oral/73830,2023," Denoising diffusion probabilistic models have transformed image generation with their impressive fidelity and diversity.We show that they also excel in estimating optical flow and monocular depth, surprisingly without task-specific architectures and loss functions that are predominant for these tasks. Compared to the point estimates of conventional regression-based methods, diffusion models also enable Monte Carlo inference, e.g., capturing uncertainty and ambiguity in flow and depth.With self-supervised pre-training, the combined use of synthetic and real data for supervised training, and technical innovations (infilling and step-unrolled denoising diffusion training) to handle noisy-incomplete training data, one can train state-of-the-art diffusion models for depth and optical flow estimation, with additional zero-shot coarse-to-fine refinement for high resolution estimates. Extensive experiments focus on quantitative performance against benchmarks, ablations, and the model's ability to capture uncertainty and multimodality, and impute missing values. Our model obtains a state-of-the-art relative depth error of 0.074 on the indoor NYU benchmark and an Fl-all score of 3.26\% on the KITTI  optical flow benchmark, about 25\% better than the best published method.",Oral 6C Vision,https://openreview.net/pdf?id=jDIlzSU8wJ,https://openreview.net/forum?id=jDIlzSU8wJ,jDIlzSU8wJ,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The paper has achieved a consensus for acceptance after the rebuttal. The technical contribution, which demonstrates that image diffusion models excel in handling general-purpose dense prediction tasks, is clearly articulated. All reviewers are positive about both the technical novelty and the results presented. The rebuttal addressed most minor concerns and clarity issues; therefore, acceptance should be granted without further discussion. Particularly due to its novelty and the rich insights provided, the AC recommends this paper for a spotlight.'}}, {'comment': {'value': 'Thank you for the very well-written rebuttal. It clarifies the contributions and the other questions about the baselines and training details.'}}, {'comment': {'value': ""Thank you for the detailed responses. It is a very interesting work with valuable insights and practical values. I don't see any major weaknesses in this submission. I maintain my acceptance recommendation and have no further questions.""}}, {'title': {'value': 'Reviewer Response to Rebuttal'}, 'comment': {'value': 'Thanks to the authors for the rebuttal. \n\nAfter reading the rebuttal and other reviews I will keep my rating at 7 - accept. I believe this paper should be accepted because it (1) introduces a simple but interesting method that performs SOTA on competitive benchmarks and (2) is very polished and experiments clearly defend all main contributions of the method. '}}, {'comment': {'value': 'Thank you for your comment. We agree with the reviewer that motion propagation and global motion aggregation are likely the main signals needed. We provide more details below.\n\nBroadly, we see two categories of errors: (1) From out-of-frame motion. As the reviewer suggests, the motion smoothness/propagation priors used in existing works might help with this. (2) Inconsistent flow for texture-less background regions. For example, ambush_1 frame_1 has a foreground that splits the background into two, with texture on one section of the background and almost no texture on the other. This leads to an ambiguity with our model sometimes predicting consistent flow for the entire background but often not (note that for frames with less ambiguity, the diffusion model is able to successfully propagate the motion). We find that the RAFT model also struggles on such sequences, which suggests that smoothness is not a sufficient prior for handling such cases. As the reviewer mentioned, GMA and GMFlow are some of the first models to successfully address this example (and furthermore the ambush_1 sequence) and it seems likely that this is due to their modules for global motion aggregation and motion propagation, since these signals can align the flow in the background. Theoretically, the self attention blocks in our model should be capable of global motion aggregation so it is possible that our training data distribution does not sufficiently cover such scenes. We hypothesize that there may be multiple ways to solve this problem (data, model design, improvements to sampling, i.e., better approaches to aggregation or re-ranking) and are excited to explore this in future work.\n\nThe reason that the parenthetical in our original response starts with cost volume is because in current models the cost volume is the starting point for global motion aggregation modules (for FlowFormer, the aggregation happens as a post processing of the cost volume into a ""cost memory"", for GMA, the cost volume is processed into the ""motion feature encoder"" and then again into the ""global motion aggregation"" module), but the reviewer is correct to point out that the exact mechanism is global motion aggregation / motion propagation, which should have been mentioned.\n'}}, {'comment': {'value': 'Thanks for the detailed responses. Overall I agree with the authors, but would like to have a followup discussion on one small point. \n\nRegrading the limited performance on the Sintel ambush_1 sequence, the authors mentioned that ""FlowFormer’s inductive bias (with the cost volume etc) make it better suited to reason about this sequence’s large out-of-frame motions"". However, I guess the cost volume will also be less effective for out-of-frame motions since the points are not matchable across frames? Thus it seems less likely that encoding the matching cost in the architecture will solve this problem? Maybe leveraging some context information (e.g., motion smoothness/propagation in GMA and GMFlow) would be helpful? I think this is an open question and could be considered as future work.\n\nThis question doesn\'t affect my opinion, I am happy to accept this paper. Thanks.'}}, {'rebuttal': {'value': 'Thank you for your review, and for your thoughtful comments and questions. They will certainly help improve the revised paper. Please see our response below.\n\n> Finetuning performance on real data yields weaker performance on Sintel vs. other methods (minor weakness, but addressing could further strengthen paper!)\n\nIn Table 9 of the supplementary material, we show that we outperform FlowFormer on all Sintel test sequences but one, ambush_1. This sequence has significant ambiguity due to an all-white background, large camera and object motions, and the existence of numerous objects that occlude one another and move out of frame. This forces the model to depend heavily on inductive biases and learned motion priors, which could be challenging for our method. It is possible that FlowFormer’s inductive bias (with the cost volume etc) make it better suited to reason about this sequence’s large out-of-frame motions. In general, we agree with the reviewer that our model’s worse performance on Sintel compared to models such as FlowFormer, which we outperform by a large margin on KITTI, is surprising and deserves further exploration.\n\n> Is it possible to do warm start with diffusion \n\nThere are a couple of ways of doing warm start with diffusion. One would be to use the warped flow as the initial estimate and perform partial denoising as the reviewer suggests. Another would be to guide the denoising process (similar to classifier guidance [19]) using a loss that ensures cross frame consistency. These are interesting directions, but we have not explored them in detail to date.\n\n> (1) it does not handle real data as well as regression methods, even after contributions in this area, or (2) it does not overfit as well to specific datasets given others tend to have task-specific architecture.\n\nAs the reviewer has noted, our model achieves SOTA performance on KITTI (a real dataset) by a large margin (Table 2). Relative to FlowFormer, our model’s weaker test performance on Sintel is somewhat surprising. This may be attributable to the differences in the data used for pre-training the Flowformer model vs our diffusion model, or to the presence of a task-specific bias in the FlowFormer architecture. We agree with the reviewer that this is worthy of future exploration.  \n\n> Minor weaknesses: 1) L1 loss is a design decision, infilling holes using bilinear interpolation is not a substantial contribution in my eyes. So the remaining technical contribution is unrolling. 2) These contributions are nontrivial, but not substantial on their own.\n\nWe agree that L1 loss and bilinear interpolation are not technical novelties by themselves. The paper’s contribution, in this context, is a way to train diffusion models with noisy and incomplete data, where the train-test distribution shift is problematic. We found that a combination of L1, bilinear infilling and step unrolling are effective for diffusion model training with missing data. This enables one to train generic diffusion models that yield remarkably strong performance on both optical flow and monocular depth estimation without the specialized architectures and loss functions that have been common in SOTA models to date.\n\n> Questions:\n\nQ1: Thank you for the suggestion. We will write this more clearly when revising the paper.\n\nQ2: We have included extra examples in Figure 1 in the attachment. We will include more examples in the final version of the paper.\n'}}, {'rebuttal': {'value': ""Thank you for your review, and for your thoughtful comments and questions. They will certainly help improve the revised paper. Please see our response below.\n\n> Due to the uncertainty in diffusion models, a same model might produce different results when running twice. How large is the fluctuation and how's the final quantitative results reported? Are the authors using some averaging?\n\nFigure 1, 2, 3, and 4 in the supplemental show multiple samples from the predictive posterior, along with variance heat maps. As visualized in the variance heat maps, the magnitude of local fluctuation depends on the nature of the multi-modality; variability is common in regions of ambiguity (e.g. transparent/reflective surfaces, object boundaries, or occlusions). \nWe do average multiple samples for both depth and flow (see Section 4.1). Table 3 shows small but consistent improvements in depth estimation as we average more samples. For optical flow, we average 8 samples for the coarse-grained estimate, but we do not use sample averaging in the high resolution refinement. We will clarify this in the final version of the paper.\n\n> How sensitive of the proposed architecture to different image resolutions for both depth and flow tasks? For example, what if the inference image resolution is different from training, will the model still perform reasonably?\n\nLike prior regression methods (Figure 4 of [17]) our model's performance degrades if one naively runs inference at a resolution that is different from the training resolution. However, in the paper we explain how to use the diffusion model within a coarse-to-fine refinement scheme (see Section 3.3). This way we are able to effectively run inference on high resolution images, first at a coarse-resolution, and then patch-wise at high resolution, conditioned on the coarse-grained estimate to provide global context. Table 5 shows the improved performance on optical flow estimation with this approach.\n\n> The optical flow results on KITTI is very strong, but the results on Sintel seem less robust (as also analysed in the supplementary material). What might cause the different behaviours on Sintel and KITTI, could the authors further comment on this?\n\nIn Table 9 of the supplementary material, we show that we outperform FlowFormer on all Sintel test sequences but one, ambush_1. This sequence has significant ambiguity due to an all-white background, large camera and object motions, and the existence of numerous objects that occlude one another and move out of frame. This forces the model to depend heavily on inductive biases and learned motion priors, which is challenging for our method. It is possible that FlowFormer’s inductive bias (with the cost volume etc) make it better suited to reason about this sequence’s large out-of-frame motions.\n\n> RAFT outperforms diffusion models when only using AutoFlow\n\nAs discussed in Section 3.1 (paragraph 2) and shown in Figure 3, we find that when trained solely on AutoFlow the diffusion model learns to reproduce shapes from the AutoFlow data, yielding poorer qualitative and quantitative performance. The denoiser’s bias toward \npolygonal shapes in AutoFlow could partially be explained by recent work (eg section 4.2 of [18]) on shape vs texture bias in neural classifiers.  As a result, using AutoFlow alone causes the model to hallucinate on real data and try to identify the best AutoFlow shapes to represent the real objects. Interestingly, this problem is solved by training with larger, more diverse data.\n\n> I am wondering whether this indicates that diffusion models can benefit more from larger datasets than previous regression methods?\n\nThis is a great question! The finding that diffusion models benefit more from larger datasets is indeed surprising. Like most regression based flow networks, RAFT has several architectural elements which bias the network towards modeling flow; eg, RAFT features an all-pairs cost volume, which compares all the pixels (in encoding space) in frame 1 to frame 2, and then accesses this cost volume through a lookup operation based on the flow. This network element strongly encourages the network to use pixel comparisons to generate the predicted flow. As a result, despite being trained on only AutoFlow (a synthetic dataset), RAFT can quickly learn to use pixel or patch similarity to compute optical flow, an ability which generalizes quickly to real world videos. In contrast, our diffusion pipeline lacks any of these specific model biases and must learn these biases through data. However, it is important to note that RAFT's ability to learn quickly comes with a tradeoff; namely, the inductive biases that are hard coded into its architecture may be suboptimal. Given enough data, learning these biases may be better than designing them through manual architecture design.\n""}}, {'rebuttal': {'value': 'Thank you for your review, and for your thoughtful comments and questions. They will certainly help improve the revised paper. Please see our response below.\n\n> Do the claims hold on higher-level tasks such as semantic segmentation\n\nThe extent to which a generic diffusion model is effective on other vision tasks, including higher-level tasks is a topic of ongoing work. Diffusion models have indeed been shown to work well on panoptic segmentation [15], which is encouraging.\n\n> Theoretical analysis or proof for step-unrolling\n\nOne can view an unrolling step at time t as a Langevin update of a MCMC sampler for which the target distribution is the marginal distribution of the latent $y_t$ (i.e., the distribution of noisy optical flow fields or depth maps). From this perspective unrolling steps act like corrector steps in the predictor-corrector sampler of Song et al [16]. We will include further discussion in the paper.\n\n> Could unrolling more steps bring further improvements\n\nGreat question. For datasets in which the ground truth flow or depth maps have more missing data (e.g., like KITTI) one would expect more unrolling steps to be useful in matching the marginal distribution of the latent $y_t$. In our experiments we did find this to be the case (please see Table 2 in attachment).  For instance, increasing the number of unrolling steps from one to four improves KITTI REL from 0.056 to 0.053, and the RMS from 2.700 to 2.568. On NYU, improvements are marginal (REL improves from 0.075 to 0.074 and RMS from 0.324 to 0.315) as one might expect since the ground truth data have fewer missing depth values.\n\n> how much the use of pallete self-supervised pre-training help\n\nPlease see Tables 5 and 6 in our supplementary material.  They show that self-supervised pre-training clearly improves results for monocular depth estimation. This isn’t entirely surprising since tasks like inpainting and colorization entail some form of ‘semantic understanding’. We expect similar findings for optical flow estimation, but we did not perform this study on optical flow estimation since pre-training is compute intensive.\n'}}, {'rebuttal': {'value': 'Thank you for your review, and for your thoughtful comments and questions. They will certainly help improve the revised paper. Please see our response below.\n\n> limited technical novelty\n\nOne of the main motivations for this paper is to understand how well vanilla diffusion models perform on classical dense computer vision tasks which are traditionally solved using specialized techniques. As a result, we intentionally kept the network design and diffusion formulation simple.\n\nWe do however, identify and solve several issues unique to the application of diffusion models for the tasks of optical flow and monocular depth estimation. For example, innovations in training are necessary for the application of diffusion models on dense regression problems with noisy and incomplete ground truth data. To that end, we introduce infilling and step-unrolling, which greatly  improves the performance.  For optical flow on the KITTI dataset, baseline diffusion tends to diverge and SOTA performance only results from the combination of both these additions. For KITTI depth, infilling and unrolling result in a substantial improvement in REL (0.222 to 0.056). In addition, we find that our optical flow network requires different training data than regression based optical flow techniques and solve this through a new training regime. Beyond these innovations, we also  introduce a coarse-to-fine refinement scheme which provides further performance gains and greater flexibility in the image resolutions to which the model can be applied. We also demonstrate the use of imputation for text-to-3D generation.\n\nBut the main novelty in the paper is the demonstration that it is possible to generate SOTA results on well studied regression problems for which previous methods have relied heavily on specialized techniques such as the use of cost volumes [1] for flow and binning [14] for depth. We propose a common architecture and training procedure across two different dense vision problems. We think this framework is encouraging and motivates new directions for vision research, with a common architecture for many vision problems. Further we show that the diffusion framework is sufficiently powerful to capture the multi-modal predictive distributions (e.g. capturing ambiguity in flow or depth estimation). \n\n> More analysis of multi-modality\n\nThe ability of diffusion models to represent complex multimodal distributions, without excessive mode collapse is arguably one of the key properties that has led to the recent success and excitement around diffusion models. Their ability to capture uncertainty in the predictive posterior distributions over depth and optical flow, including multi-modality in cases of ambiguity, is quite interesting. Figures 1-4 in the supplementary material show examples and variance heat maps of the multi-modal predictions for both depth and flow. For depth we observe multimodality in transparent and reflective surfaces, such as mirrors and windows of cars, and around object boundaries. For flow we observe multimodality in transparent surfaces and shadows, thereby capturing the layered nature of the scene. Notably we also observe multimodality in out-of-frame motion where the flow is ambiguous. We think this is an interesting finding and opens up further avenues of research and also provides a way to measure uncertainty which can be important for downstream applications.\n\n> I did not understand why the pre-training phase needs to be separate.\n\nModel pre-training on large-scale datasets is commonplace for optical flow [1, 2] and monocular  depth  [3, 4]. E.g. for optical flow the training data schedule (e.g. FlyingChairs -> FlyingThings3D -> mixture of Sintel / KITTI / VIPER etc.) has been heavily studied and shown to be crucial to achieve good performance (Table 5 of [12] and Table 1 of [13]).  Considerable effort has recently been spent designing better pre-training datasets [10, 11]. This combination of pre-training and fine-tuning provides the advantages of large-scale datasets, with pre-trained models often yielding good zero-shot performance, with the ability to fine-tune models to a specific dataset to maximize performance (perhaps with some loss of generality).\n\n> I wonder if self-guidance is already good at addressing the domain shift problem\n\nIn our experiments with self-guidance we found that it does not address the domain shift problem (see Table 1 in attachment). This is expected because, even with self-guidance, there remains a training/inference distribution shift for the latent $y_t$, which is what we address through step-unrolled diffusion training.\n\n> Is it possible to fine-tune an existing diffusion model, such as stable diffusion, instead of training one from scratch? Could it help avoid the use of synthetic data?\n\nIndeed, we use an existing self-supervised pre-trained diffusion model (i.e., the Palette model [5]) for image to image translation. As shown in Tables 5 and 6 of our supplementary material, this self-supervised pre-training substantially improves results. \n\nIt may also be possible to use a pre-trained text-conditional image generation model, especially in light of recent works such as [8, 9], which exploit features from pretrained text-to-image models for depth regressors. We briefly considered fine-tuning existing text-to-image models but found that available pixel-space models at the time, such as Imagen [7], were computationally expensive (2B params in the base model) which might limit their utility in practical vision applications and latent space models like Stable Diffusion additionally require dealing with holes in the autoencoder training (like in [6]). Hence, we left this exploration to future work.\n\nIt may be possible that the use of significantly more text-image training data or larger datasets for image to image translation would allow one to avoid training with synthetic data. We have not explored this but we agree that this is important future work.\n'}}, {'rebuttal': {'value': 'References\n\n[1] RAFT: Recurrent All-Pairs Field Transforms for Optical Flow, Teed and Deng, 2020\n\n[2] FlowFormer: A Transformer Architecture for Optical Flow, Huang et al, 2022\n\n[3] Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer, Ranftl et al, 2020\n\n[4] Vision Transformers for Dense Prediction, Ranftl et al, 2021\n\n[5] Palette: Image-to-Image Diffusion Models, Saharia et al, 2022\n\n[6] All in Tokens: Unifying Output Space of Visual Tasks via Soft Token, Ning et al, 2023\n\n[7] Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding, Saharia et al, 2023\n\n[8] Unleashing Text-to-Image Diffusion Models for Visual Perception, Zhao et al, 2023\n\n[9] Beyond Surface Statistics: Scene Representations in a Latent Diffusion Model, Chen at al, 2023\n\n[10] AutoFlow: Learning a better training set for optical flow, Deqing et al 2021\n\n[11] Self-supervised AutoFlow, Huang et al, 2023\n\n[12] Models Matter, So Does Training: An Empirical Study of CNNs for Optical Flow Estimation, Sun et al, 2018\n\n[13] FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks, Ilg et al, 2017\n\n[14] AdaBins: Depth Estimation using Adaptive Bins, Bhat et al, 2020 \n\n[15] A Generalist Framework for Panoptic Segmentation of Images and Videos, Chen et al, 2023\n\n[16] Score-based Generative Modeling through Stochastic Differential Equations. Song et al, 2021\n\n[17] Vision Transformers for Dense Prediction, Ranftl et al, 2021\n\n[18] Text-to-Image Diffusion Models are Zero-Shot Classifiers, Clark and Jaini, 2023\n\n[19] Diffusion Models Beat GANs on Image Synthesis, Dhariwal et al, 2021\n'}, 'pdf': {'value': '/pdf/a592304d4dd61a6d0c2d63f5aada07e86a118220.pdf'}}, {'summary': {'value': 'The paper demonstrates that diffusion models are effective general-purpose solutions for dense optical flow and monocular depth regression tasks. The paper shows that the same architecture and loss functions lead to at-par or better performance on these tasks, compared to existing methods that use domain knowledge and problem-specific architectures. The main insights presented are the use of a pre-training phase for higher quality, and imputation of the missing values, and a step-unrolled diffusion step, for dealing with incomplete GT training data.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': ""The paper is well-written and motivates the contributions perfectly. The simplicity of the architecture and the loss functions are very clear. The results support the claims and show at-par or better results than the state of the art. Extensive experiments on different real datasets help evaluate the method's quality. Multi-modality of the outputs is promising! I would have loved to see some more analysis there.  The presented application is also exciting, showing directions for text to 3D reconstructions.""}, 'weaknesses': {'value': 'While there is limited technical novelty, this is a good paper that demonstrates a simple method for solving two different regression tasks.\n\n- I did not understand why the pre-training phase needs to be separate. The method uses supervised pre-training, that is different for each task. The loss functions are also identical between the pre-training and the fine-tuning states. Why not combine all available datasets and just train the model once (inc. all the tricks used for fine-tuning)? I did not understand this distinction between phases, especially when the experiments are explained and the datasets keep moving from one phase to the other. \n\n- Step-unrolled diffusion is a little similar to self-guidance, introduced in ""Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning"" [Chen et al.] I wonder if self-guidance is already good at addressing the domain shift problem, or whether step-unrolled diffusion is really needed.'}, 'questions': {'value': '- Please answer the questions raised on pre-training, and on self-guidance. \n- Is it possible to fine-tune an existing diffusion model, such as stable diffusion, instead of training one from scratch? Could it help avoid the use of synthetic data?'}, 'limitations': {'value': 'Yes.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors study the use of diffusion models for the tasks of single-image depth estimation and optical flow estimation. Self-supervised pre-training, supervised fine-tuning with synthetic and real data, combined with a couple of tricks to leverage imperfect GT, lead to competitive results with nearly no task-specific modifications to the diffusion models. The authors also demonstrated unique capabilities enabled by the diffusion models, e.g., capturing multimodality and completion from partial data. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""**Originality and significance**: \n\nAs far as I know, this is the first work to study the use of generative diffusion models for optical flow and depth estimation tasks. Training good optical flow and depth models typically requires extensive task-specific knowledge in terms of architecture designs and loss functions, so the authors' finding that diffusion models can compete well on these tasks with almost no task-specific treatments is non-trivial and valuable. The competitive results in various settings further add to the significance of the work. \n\n**Technical quality**: \n\nTraining diffusion models successfully involves many technical details. The authors generally follow best practices and propose reasonable solutions to unique challenges. More specifically, the use of pre-trained PALETTE, further supervised pre-training with mixtures of synthetic and real datasets, addressing imperfect GT with infilling and step-unrolling, etc. are all well-motivated and proven effective. \n\n**Writing quality**: \n\nThe paper is nicely written, with precise language, adequate details, and clear explanations. Conclusions are justified with plenty of results, visualizations, ablation studies, and overall convincing. ""}, 'weaknesses': {'value': ""The authors claim that diffusion models can be a generic framework for vision dense prediction tasks, but only consider the tasks of depth estimation and optical flow in this work. Both these tasks are relatively low-level, and it'd be interesting to offer some insights, discussions, or analyses regarding how higher-level tasks, such as semantic segmentation, differ from them and if the claim still holds. \n\nTwo relatively minor complaints/suggestions: \n* Can authors provide some theoretical analysis or proof for the step-unrolling step? Could unrolling more steps bring further improvements? \n* It's unclear how much the use of pallete self-supervised pre-training help since it's not part of the ablation study. ""}, 'questions': {'value': 'Please refer to the three points in the weakness section above. '}, 'limitations': {'value': 'I agree with the limitation the authors brought up in the supplementary. Optical flow and depth estimation are low-level tasks commonly used at early stages of real-world application systems and therefore demand higher efficiency. As the authors already pointed out, this is where the proposed diffusion models fall short. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes to use diffusion models to solve monocular depth and optical flow estimation tasks. Unlike previous task-specific models for depth and flow, this paper uses a generic diffusion model. This paper studies the effect of training data (synthetic and real) and processing of sparse depth and flow ground truth when training the diffusions models. Experiments are conducted for depth and flow tasks on representative benchmarks, the proposed method achieves state-of-the-art depth performance on NYU and state-of-the-art optical flow performance on KITTI.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""- **The idea of using diffusion models to solve depth and optical flow tasks is interesting.** Depth and optical flow are typically approached as regression tasks, it's unclear how the popular diffusion models will perform for both tasks. This paper explores this direction and shows some interesting results.\n- **Several strategies are proposed to handle the issue of data for training diffusion models.** It's not straightforward to apply diffusion models to depth and flow tasks, the paper proposes data infilling, step-unrolling and an L1 loss to tackle the challenges.\n- **The experiments are extensive and informative.** Training data plays a significant role in training diffusion models, this paper studies the effect of different training datasets for both depth and flow tasks. The performance on KITTI for optical flow task is especially strong, outperforming previous 2-frame optical flow methods by a large margin.\n- **A detailed discussion of limitations is presented in the supplementary material.** This paper gives a deep analysis of the limited performance on Sintel test set and the results indicate that a particular sequence on the test set severely affects the averaged performance, which might provide some hints for further improvement in future.""}, 'weaknesses': {'value': ""I didn't observe major weakness and would put some minor points to the Questions.""}, 'questions': {'value': ""- Due to the uncertainty in diffusion models, a same model might produce different results when running twice. How large is the fluctuation and how's the final quantitative results reported? Are the authors using some averaging?\n- How sensitive of the proposed architecture to different image resolutions for both depth and flow tasks? For example, what if the inference image resolution is different from training, will the model still perform reasonably?\n- The optical flow results on KITTI is very strong, but the results on Sintel seem less robust (as also analysed in the supplementary material). What might cause the different behaviours on Sintel and KITTI, could the authors further comment on this?\n- I think one key message from this paper is that the experiments show the importance of training data. When comparing Table 1 and Table 6 for the results of RAFT and the proposed method, we can observe that RAFT outperforms diffusion models when only using AutoFlow for pre-training. However, diffusion models perform better when more datasets are added to the pre-training stage. I am wondering whether this indicates that diffusion models can benefit more from larger datasets than previous regression methods?""}, 'limitations': {'value': 'Yes, the authors have carefully analyzed the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper approaches the task of predicting optical flow from a pair of images and depth from a single image. It proposes to do so using diffusion models, providing a training pipeline which includes contributions to deal with noisy training data. The proposed method is competitive with SOTA in depth prediction on NYU and KITTI, is similar or better to SOTA in optical flow prediction on Sintel and KITTI zero-shot, and is SOTA in optical flow after finetuning on KITTI. Additional experiments show the proposed pretraining pipeline meaningfully improves RAFT and the proposed model, that contributions dealing with noisy training data are helpful, and that the proposed method can predict multimodal outputs in cases of uncertainty.\n\nEdit: Thanks to the authors for the rebuttal.\n\nAfter reading the rebuttal and other reviews I will keep my rating at 7 - accept. I believe this paper should be accepted because it (1) introduces a simple but interesting method that performs SOTA on competitive benchmarks and (2) is very polished and experiments clearly defend all main contributions of the method.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper provides a simple method that is similar-to or better than SOTA on competitive optical flow and depth tasks\n- A new data pipeline is introduced which significantly boosts performance of prior SOTA e.g. RAFT, while improving further with the proposed method\n- The method is built off a standard image-to-image diffusion method Palette, adds minimal detail needed to handle flow and depth data (e.g. L1 loss, infilling + unrolling, coarse-to-fine), and is competitive across a wide variety of experiments\n- Real data is tricky to handle for diffusion models as it can contain incomplete flow and depth maps. The proposed method has an interesting idea of using its own predictions late in training. Combined with infilling, this is helpful.\n\nThe paper is very polished and experiments clearly defend all main contributions of the method.\n- Writing is very clear, figures and tables are attractive and helpful\n- Choice of training data is very important (Figure 3, Table 6, 7); it even improves RAFT meaningfully (Table 1)\n- The method can also produce Multimodal samples faced with ambiguity e.g. transparent/translucent/reflective (Figure 1, 4, 5)\n- Figure 6 and Table 5 shows the importance of coarse-to-fine refinement, which enables the method to produce better detail than RAFT (Figure 4, 5)\n- Infilling + step-unrolling yields massive improvement on KITTI (Table 4)\n- L1 loss (Supp Table 4), pretraining for depth (Supp Table 5, 6)\n- Zero-shot depth completion is a cool application of the method'}, 'weaknesses': {'value': 'Finetuning performance on real data yields weaker performance on Sintel vs. other methods (minor weakness, but addressing could further strengthen paper!)\n- On Sintel (Table 2), most other methods use warm start, i.e. initializing flow prediction from previous frame. Is it possible to do this with diffusion, i.e. starting from a previous prediction, perhaps denoising fewer steps? If not, this is an important weakness of diffusion models in this setting\n- Given most other method warm-start, it is harder to analyze the ability of the proposed method to finetune on real data. Perhaps it does not do as well relative to FlowFormer because (1) it does not handle real data as well as regression methods, even after contributions in this area, or (2) it does not overfit as well to specific datasets given others tend to have task-specific architecture. A comparison to more methods without warm-start, or by using the proposed method with warm-start, it would be very interesting to see this analyzed.\n\nThe main novel contribution of this paper beyond data pipeline is step-unrolled denoising diffusion training, which yields modest improvement over infilling alone (minor weakness)\n- L1 loss is a design decision, infilling holes using bilinear interpolation is not a substantial contribution in my eyes. So the remaining technical contribution is unrolling.\n- I understand the contributions are deliberately simple, which is a positive given performance gain. However, it is still important to analyze the reasons for the method’s success. In this case, the most novel component, “unroll”, improves optical depth REL from 0.077 to 0.075, RMS from 0.338 to 0.324, KITTI REL from 0.057 to 0.056, RMS from 2.744 to 2.700, AEPE from 1.53 to 1.47, and F1-all from 5.24% 4.74%. These contributions are nontrivial, but not substantial on their own.'}, 'questions': {'value': '- L179 is a bit confusing and could be rewritten “Training high resolution diffusion models is often slow and memory intensive but model performance has been shown to improve with resolution” \n- Figure 4 (top) is dark and indistinct, making it a hard to see. Are there failure cases for RAFT on more easily readable examples?'}, 'limitations': {'value': 'Yes'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'The Surprising Effectiveness of Diffusion Models for Optical Flow and Monocular Depth Estimation'}, 'authors': {'value': ['Saurabh Saxena', 'Charles Herrmann', 'Junhwa Hur', 'Abhishek Kar', 'Mohammad Norouzi', 'Deqing Sun', 'David J. Fleet']}, 'authorids': {'value': ['~Saurabh_Saxena1', '~Charles_Herrmann1', '~Junhwa_Hur1', '~Abhishek_Kar1', '~Mohammad_Norouzi1', '~Deqing_Sun2', '~David_J._Fleet1']}, 'keywords': {'value': ['Monocular depth', 'optical flow', 'diffusion', 'depth', 'flow']}, 'TLDR': {'value': 'Advances in denoising diffusion to handle limited, noisy, incomplete labels of dense vision tasks, specifically monocular depth estimation and optical flow, achieving sota results'}, 'abstract': {'value': ""Denoising diffusion probabilistic models have transformed image generation with their impressive fidelity and diversity.\nWe show that they also excel in estimating optical flow and monocular depth, surprisingly without task-specific architectures and loss functions that are predominant for these tasks. \nCompared to the point estimates of conventional regression-based methods, diffusion models also enable Monte Carlo inference, e.g., capturing uncertainty and ambiguity in flow and depth.\nWith self-supervised pre-training, the combined use of synthetic and real data for supervised training, and technical innovations (infilling and step-unrolled denoising diffusion training) to handle noisy-incomplete training data, one can train state-of-the-art diffusion models for depth and optical flow estimation, with additional zero-shot coarse-to-fine refinement for high resolution estimates. \nExtensive experiments focus on quantitative performance against benchmarks, ablations, and the model's ability to capture uncertainty and multimodality, and impute missing values. Our model obtains a state-of-the-art relative depth error of 0.074 on the indoor NYU benchmark and an Fl-all score of 3.26\\% on the KITTI  optical flow benchmark, about 25\\% better than the best published method.""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/a9803ecc1ba03bbc2373e4eda61e4a21987c6093.pdf'}, '_bibtex': {'value': '@inproceedings{\nsaxena2023the,\ntitle={The Surprising Effectiveness of Diffusion Models for Optical Flow and Monocular Depth Estimation},\nauthor={Saurabh Saxena and Charles Herrmann and Junhwa Hur and Abhishek Kar and Mohammad Norouzi and Deqing Sun and David J. Fleet},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=jDIlzSU8wJ}\n}'}, 'paperhash': {'value': 'saxena|the_surprising_effectiveness_of_diffusion_models_for_optical_flow_and_monocular_depth_estimation'}}]"
"['Rafael Rafailov', 'Archit Sharma', 'Eric Mitchell', 'Christopher D Manning', 'Stefano Ermon', 'Chelsea Finn']",NeurIPS,Direct Preference Optimization_ Your Language Model is Secretly a Reward Model,https://neurips.cc/virtual/2023/oral/73865,2023," While large-scale unsupervised language models (LMs) learn broad world knowledge and some reasoning skills, achieving precise control of their behavior is difficult due to the completely unsupervised nature of their training. Existing methods for gaining such steerability collect human labels of the relative quality of model generations and fine-tune the unsupervised LM to align with these preferences, often with reinforcement learning from human feedback (RLHF). However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model. In this paper, we leverage a mapping between reward functions and optimal policies to show that this constrained reward maximization problem can be optimized exactly with a single stage of policy training, essentially solving a classification problem on the human preference data. The resulting algorithm, which we call Direct Preference Optimization (DPO), is stable, performant, and computationally lightweight, eliminating the need for fitting a reward model, sampling from the LM during fine-tuning, or performing significant hyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align with human preferences as well as or better than existing methods. Notably, fine-tuning with DPO exceeds RLHF's ability to control sentiment of generations and improves response quality in summarization and single-turn dialogue while being substantially simpler to implement and train.",Oral 6B RL,https://openreview.net/pdf?id=HPuSIXJaa9,https://openreview.net/forum?id=HPuSIXJaa9,HPuSIXJaa9,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'Reviewers unanimously agree that the paper addresses an important problem and timely gives an excellent alternative to RLHF to LLMs. Theoretical analysis and thorough experimental results (plus the additional experiments in the rebuttal period) make the paper even stronger. The paper potentially has large impact in the LLM community. Therefore I recommend acceptance as an oral.'}}, {'title': {'value': 'Response to the rebuttal'}, 'comment': {'value': 'Thank you for the rebuttal and the additional experiments. Since the authors have addressed most of my main concerns (generalization performance for unseen prompts and DPO stability), I would like to raise my score. I thank the authors for their response.'}}, {'title': {'value': ""Thanks for authors' rebuttal!""}, 'comment': {'value': 'Reviewer cpnK, did the authors address your concerns about generalization performance for unseen prompts, DPO stability, as well as other concerns? Thanks.'}}, {'comment': {'value': 'I have read the response as well as the common points from the authors. I increase my score to 8.'}}, {'title': {'value': 'IMDb reward model'}, 'comment': {'value': 'Yes, the evaluation is reported using the ground truth reward model.'}}, {'title': {'value': 'Re: rebuttal'}, 'comment': {'value': ""I've read the rebuttal and the authors have addressed my concerns. I am increasing my score.\n\n**Generalization** these are very strong result and do suggest that DPO has some of the generalization properties. I would encourage you to add this to the main paper if possible. \n\n**Lemma 2** I agree that this is true in the limit of infinite data. I assumed that you are using the optimal policies given a finite dataset. If you can specify infinite data, then I have no issue with this.\n\n**Anthropic best of n** This is a sufficiently strong baseline and I think it covers my minor issues with evaluation here.\n\n**ILQL** I was not aware of this result, thank you for referencing it""}}, {'title': {'value': 'Followup question '}, 'comment': {'value': 'Thank you for the extra experiments and details. \n\nTo clarify, for IMDB, are you reporting reward from the ground truth reward model or your learned reward model? (I assume the former)'}}, {'comment': {'value': ""I have read the author's response, and I maintain my score and recommend accepting this paper.""}}, {'rebuttal': {'value': 'Thank you for your detailed summary of the paper, your feedback, and believing that our work is highly significant for researchers!'}}, {'rebuttal': {'value': ""Thanks for your helpful feedback and questions!\n\n### Generalization of DPO vs existing RLHF\n\nFirst, we note that all of the evaluations in the paper already compute test win rates on unseen test prompts.\n\nWe performed a follow-up experiment to assess the performance of PPO and DPO under distribution shifts. We evaluate the summarization policies trained on Reddit TL;DR data on the CNN/DailyMail dataset, and evaluate the win rate of each policy's sample vs the ground truth summary. We use the sampling temperatures that performed best for TL;DR. For space reasons, please see the general comment for full experimental details.\n\n**Overall, DPO shows superior performance to PPO for OOD inputs as well:**\n\n**DPO-0 winrate vs ground truth: 0.359 (+/- 0.030)**\n\n**DPO-0.25 winrate vs ground truth: 0.309 (+/- 0.029)**\n\n**PPO-0 winrate vs ground truth: 0.258 (+/- 0.027)**\n\n**PPO-0.25 winrate vs ground truth: 0.230 (0.026)**\n\n### DPO stability\n\nThanks for the suggestion! To more clearly illustrate DPO's stability across training runs, we trained 4 DPO models using EleutherAI/Pythia-1b on the Anthropic-HH dataset. Please find the training loss curves in Fig. 2 in the rebuttal figure pdf and the classification accuracy of the implicit DPO reward function in Fig. 4. We find that these learning curves are very consistent across training runs. Further, we evaluate the final GPT-4 win rate of each policy against the chosen response for unseen prompts in the test set. The win rates for the final policy from each training run were 0.426, 0.410, 0.414, 0.438 (standard dev: 0.0110). In comparison, sampling from the first policy four times, changing only the random seed used for sampling, we observe a similar distribution of scores, with slightly higher standard deviation: 0.426, 0.412, 0.406, 0.441 (standard dev: 0.0135). These results suggest that the variance in performance of DPO policies across different training seeds is less significant than the variance due to simply using different random seeds for sampling at test time.\n\nAdditionally, we also experiment with how the \\beta hyperparameter controls the KL-divergence, we find that the \\beta hyperparameter very reliably controls the KL-divergence of the final policy, as shown in Fig. 1 in the rebuttal figure pdf. In contrast, PPO implementations typically require an adaptive beta (based on a target KL divergence) because the same fixed beta can lead to very different KLs for different training runs.\n\n### Size of human preference dataset\nThanks for bringing up the missing details. We use publicly available preference datasets for summarization (HuggingFace dataset CarperAI/openai_summarize_comparisons) with 92.5k comparisons and Anthropic HH dialogue (HuggingFace dataset Anthropic/hh-rlhf) with 161k comparisons. We will include these and other details about the preference datasets in the camera ready version. In our experiments, DPO and PPO use the same preference datasets (and thus, the same amount of preference data). While our new experiment evaluating the OOD performance of PPO and DPO gives some reason for optimism about DPO's data efficiency, directly comparing the performance of DPO and PPO as the amount of preference data is varied is an important question for analysis, which we defer to future work. Thank you for this suggestion!\n\n### Why does DPO perform better than PPO-GT even though PPO-GT uses a true reward function?\nIn the controlled sentiment generation problem, we find that the learned PPO reward can achieve accuracy well over 90%. Hence we believe the discrepancy between DPO and PPO is not due to issues with reward modeling, but optimization of the reward. PPO only approximately optimizes the KL-constrained reward problem, while DPO samples from the closed-form optimal policy (without approximation). We hypothesize that PPO is less efficient than DPO, even with the ground truth reward, due to this noisy optimization.\n\n### KL target values scaling\nFigure 2 reports sequence-level KL, which adjusting for sequence length results in per-token KLs of about 0.05, 0.1, 0.15 and 0.2, comparable to those used in Ramamurthy et. al.\n\n### Fluency during training\nDPO has a very stable relationship between the KL divergence of the final policy and the hyperparameter $\\beta$, as shown in the attached Fig. 1. We do not observe any degeneration as training progresses, however, in the limit of $\\beta$ going to zero, the KL constraint vanishes, and DPO would purely maximize the (implicit) learned reward. In this case, optimizing a reward function trained on a small preference dataset would likely show some deterioration.\n\n### Unlikelihood stability\nIndeed, unlikelihood objectives can degrade fluency. As we note in Section 4, the weight scaling the unlikelihood updates in DPO in would be < 1 for all comparisons, but for comparisons where the preferred completion has a higher reward than the dispreferred completion, the weight can be substantially lower, effectively stopping learning on those examples. Thus, the adaptive weights only change the model whenever the preference pair is ordered incorrectly under the LM, which we hypothesize leads to the stable training regime. Further, as beta is larger, this weight goes to zero more rapidly as the example is learned, effectively stopping optimization more quickly. Nonetheless, we cannot rule out the possibility that carefully tuned unlikelihood methods can also be successfully used for fine-tuning LM on comparison pairs.\n\n### Figure 2 star\nStars represent the win rates as computed in human evaluation, and we include 3 stars corresponding to the win rates for DPO @ 0.25, SFT @ 0.25 and PPO @ 0.0, all compared against PPO @ 0.0. We will clarify this in the figure caption.""}}, {'rebuttal': {'value': 'Thanks for assessing our paper to be a significant contribution, and for your feedback!\n\n### Single-turn dialogue experimental results did not compare DPO with a RLHF baseline…\n\nPlease, see Fig. 3 in the rebuttal pdf for an additional baseline to our dialogue experiments, the oracle best-of-N method that uses a reward model learned on all the preference data to pick the best of N samples from the SFT model. We observe that DPO performs comparably to the best-of-N method. Note that best-of-N is computationally infeasible as it requires generating N samples at test-time (for example, 128) and choosing the best one, but this baseline is often used as an oracle proxy for PPO [1] and achieves comparable performance (Table 2 in [2]). We use best-of-N because it is easy to implement, as strong as PPO, and public RLHF checkpoints that we found for Anthropic use undocumented training splits and/or skip the SFT phase, which is non-standard and makes fair comparison with DPO difficult.\n\n[1] Scaling Laws for Reward Model Overoptimization. Gao, Schulman, Hilton.\n\n[2] AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback, Dubois, et. al. \n\n\n### There are very few details on the experimental setup for the IMDB Sentiment Generation task…\n\nThanks for the suggestion! Here are additional details about the IMDB task, which we will add to Section 6.1 of the next revision of the paper:\n\nFollowing the trl library, the prompts are prefixes from the IMDB dataset of length 2-8 tokens. We use the pre-trained sentiment classifier ""siebert/sentiment-roberta-large-english"" as a ground-truth reward model and GPT2-large as a base model. We use these larger models as we found the default ones to generate low-quality text and rewards to be somewhat inaccurate.  We first use supervised fine-tuning on a subset of the IMDB data for 1 epoch. We then use this model to sample 4 completions for 25000 prefixes and create 6 preference pairs for each prefix using the ground-truth reward model. The RLHF reward model is initialized from the GPT2-large model and trained for 3 epochs on the preference datasets, and we take the checkpoint with the highest validation set accuracy. The “TRL” run uses the same hyper-parameters as the trl library implementation. Our implementation uses larger batch samples of 1024 per PPO step.\n\n### Please clarify what dataset, (specifically, whether the “helpful-online” or “helpful-rejection-sampled” data) was used for the single-turn dialogue experiment?\n\nWe used the entire Anthropic/hh-rlhf available on HuggingFace. We will add the details to the paper.\n\n### Why does win-rate in the single-turn dialogue task increase with higher sampling temperature in Figure 3?\nFor low-temperature (0.25) evaluation in the dialogue task, we observe a significant number of responses that get stuck in repetition loops, a common failure mode of smaller LMs being sampled at low temperature. For the two higher-temperature (0.7, 1.0) evaluations, the win rates are within one standard error of each other. We will note this observation of repetition loops at low temperature in Section 6.2 of the revised paper.'}}, {'rebuttal': {'value': ""Thanks for appreciating our work and providing a great summary for it!\n\n### DPO vs PPO generalization.\n\nWe performed a follow-up experiment to assess the performance of PPO and DPO under distribution shifts. We evaluate the summarization policies trained on Reddit TL;DR data on the CNN/DailyMail dataset, and evaluate the win rate of each policy's sample vs the ground truth summary. We use the sampling temperatures that performed best for TL;DR. For space reasons, please see the general comment for full experimental details.\n\n**Overall, DPO shows superior performance to PPO for OOD inputs as well:**\n\n**DPO-0 winrate vs ground truth: 0.359 (+/- 0.030)**\n\n**DPO-0.25 winrate vs ground truth: 0.309 (+/- 0.029)**\n\n**PPO-0 winrate vs ground truth: 0.258 (+/- 0.027)**\n\n**PPO-0.25 winrate vs ground truth: 0.230 (0.026)**\n\n### PPO $y \\sim \\pi_\\theta$ vs DPO $y \\sim D$\n\nWe note that Eq. 3 and Eq. 7 represent different stages of RLHF. Eq. 3 shows the objective of the policy optimization stage, while Eq. 7 shows the reward learning stage (using the DPO parameterization). Thus the interpretation of y is different in these equations. The DPO reward parameterization allows us to extract the optimal solution to the problem in Eq. 3 exactly, in closed form; this parameterization simply means that we don't have to perform any additional RL optimization (such as online learning with PPO), which conventional RLHF does.\n\n### DPO vs PPO optimal policy for finite data\n\nIn the limit of infinite data and perfect optimization, the policy found by PPO will be equivalent to the DPO policy, which is the optimal policy (wrt the learned DPO reward) in Eq. 4, which holds for all prompts & answers (this assumes the PPO reward model agrees with the implicit DPO reward model; Theorem 1 and our empirical findings show that the two reward model classes have equivalent expressiveness, and our empirical findings suggest that the two parameterizations do achieve very similar classification accuracy on held out preference pairs). However, in the case of finite data or imperfect optimization, PPO might not recover the theoretically optimal policy that DPO does (Eq. 4). Our new generalization experiment in the summarization setting further suggests that the DPO policy generalizes at least as well, if not better than, the PPO policy. Finally, Lemma 2 only states equivalence of the optimal policy, but suboptimal policies found from finite data or imperfect optimization may indeed differ for two reward functions in the same equivalence class.\n\n### Substitution in Equation 10\n\nThanks for pointing this out; this is a typo. The optimal policy is the one induced by Eq. 4, not Eq. 7. We apologize for the confusion and will correct the mistake in the final version of the paper. The result (closed-form optimal policy) of Eq 4 holds on all prompts and answers, given a reward function. We agree that the paper would benefit from this discussion, and the points raised about the difference in the PPO / DPO problem settings and the optimal policies being different. Specifically, we will revise Section 5.2 to note the discrepancy between optimal policies.\n\n### IMDb details\n\nThanks for raising the concern about the missing details. We provide the details of the controlled sentiment generation task in the common response, along with the details for the PPO baseline. We follow the TRL library which first does an SFT step before running PPO. This is necessary since the experiment uses shorter prompts and the model might deviate from the movie review task. The evaluation is done on the test set. We will add all the details to the paper in the next revision.\n\n### GPT-4 evaluation sample ordering\n\nOur present evaluation protocol randomly flips options A and B for every evaluation prompt for this reason. We make a brief note of this in Appendix C.1, but will certainly clarify in the main text.\n\n### Anthropic HH baselines\n\nWe have added a comparison of DPO to the oracle best-of-N method using a reward model learned on all the preference data; see Fig. 3 in the attached rebuttal figure pdf. We observe that DPO performs comparably to the best-of-N method. Note, this method is computationally infeasible as it requires generating N samples at test-time (for example, 128) and choosing the best one, but, this baseline is often used as an oracle proxy for PPO [1][2]. We use best-of-N because it is easy to implement, as strong as PPO, and public RLHF checkpoints that we found for Anthropic use undocumented training splits and/or skip the SFT phase (e.g., the reciprocate/ppo_hh_gpt-j checkpoint you mentioned) which is non-standard and makes fair comparison with DPO difficult.\n\n[1] Scaling Laws for Reward Model Overoptimization. Gao, Schulman, Hilton.\n\n[2] AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback, Dubois, et. al. \n\n### PPO vs DPO compute\nDepending on design choices DPO can require as little as half as much accelerator memory than PPO, since it does not maintain separate value function and reward models. In terms of run times, we found that DPO training requires about 5-8 times less compute time than the standard RLHF pipeline, depending on the model and dataset.  \n\n### ILQL baseline\n\nIt is possible to use many different RL algorithms to align a model with the learned reward function and in this work we focused on PPO due to its prevalence. Concurrent work (Appendix D3 in [1]) evaluated several offline RL algorithms on the Anthropic HH datasets using a learned reward model and found that they yielded little to no improvement. \n[1] Fine-Tuning Language Models with Advantage-Induced Policy Alignment, Zhu et. al. \n\n### GPT-4 API details\n\nWe used the `gpt-4-0314` for evaluation. We will add the details to the experiments section of the paper.\n\n### Figure 2/3 positioning\nThanks for the suggestion! We will reformat the paper so that the figures are closer to the text referencing it.""}}, {'rebuttal': {'value': 'We appreciate the detailed feedback provided by the reviewers. We address a few common points in this response. All other questions are addressed in reviewer specific responses.\n\n## Re: Generalization of PPO and DPO\n\nFirst, we note that all of the evaluations in the paper compute test win rates on unseen test prompts.\n\nTo further assess the performance of PPO and DPO under distribution shifts, we evaluated the PPO and DPO policies from our Reddit TL;DR summarization experiment on a different distribution, news articles in the test split of the CNN/DailyMail dataset, using the best sampling temperatures from TL;DR (0 and 0.25). We computed the GPT-4 win rate against the ground-truth summaries in the datasets, using the same GPT-4 (C) prompt we used for Reddit TL;DR, but replacing the words ""forum post"" with ""news article"". We found that for this new distribution, DPO continues to outperform the PPO policy by a significant margin:\n\n**DPO-0 winrate vs ground truth: 0.359 (+/- 0.030)**\n\n**DPO-0.25 winrate vs ground truth: 0.309 (+/- 0.029)**\n\n**PPO-0 winrate vs ground truth: 0.258 (+/- 0.027)**\n\n**PPO-0.25 winrate vs ground truth: 0.230 (0.026)**\n\nWhile it is not a comprehensive evaluation of generalization of different RLHF algorithms, **this experiment suggests that DPO policies can generalize similarly well to PPO policies, even without training on the additional unlabeled Reddit TL;DR prompts that PPO uses**. We will include this experiment in our next revision, and defer a more extensive investigation to future work.\n\n## Re: Baselines on Anthropic-HH dialogue\n\nSome reviewers asked about additional baselines for the dialogue experiment.\n\nWe have added a comparison of DPO to the best-of-N method (i.e., generate N samples, return the one with highest reward under the reward model) using a reward model learned on all the preference data; see Fig. 3 in the attached rebuttal figure pdf. **We observe that DPO performs comparably to the strong best-of-N baseline.** Note, this method is computationally infeasible as it requires generating N samples at test-time (for example, 128) and choosing the best one, but, this baseline is often used as an oracle proxy for PPO [1][2]. We use best-of-N because it is easy to implement, as strong as PPO, and public RLHF checkpoints that we found for Anthropic use undocumented training splits and/or skip the SFT phase (e.g., the reciprocate/ppo_hh_gpt-j checkpoint you mentioned) which is non-standard and makes fair comparison with DPO difficult.\n\n[1] Scaling Laws for Reward Model Overoptimization. Gao, Schulman, Hilton.\n\n[2] AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback, Dubois, et. al. \n\n\n## Re: Details about IMDb sentiment task\n\nWe provide additional details for the IMDb sentiment task, and will revise Section 6.1 to include these details in the next revision of the paper. Following the Transformers Reinforcement Learning (TRL) library, the prompts are prefixes from the IMDB dataset of length 2-8 tokens. We use the pre-trained sentiment classifier ""siebert/sentiment-roberta-large-english"" as a ground-truth reward model and GPT2-large as a base model. We use these larger models as we found the default ones to generate low-quality text and rewards to be somewhat inaccurate.  We first use supervised fine-tuning on a subset of the IMDB data for 1 epoch. We then use this model to sample 4 completions for 25000 prefixes and create 6 preference pairs for each prefix using the ground-truth reward model. The RLHF reward model is initialized from the GPT2-large model and trained for 3 epochs on the preference datasets, and we take the checkpoint with the highest validation set accuracy. The “TRL” run uses the same hyper-parameters as the TRL library implementation. Our implementation uses larger batch samples of 1024 per PPO step.\n'}, 'pdf': {'value': '/pdf/d1619a42fd7c96ce5b41589bd707c15581d3e025.pdf'}}, {'summary': {'value': ""RLHF is generally done by training a reward model on a dataset of preferences and then using on-policy RL to finetune a language model with the reward model. This work proposes to bypass explicit learning of a reward model and finetune the language model directly on the preference dataset. This is conceptually similar to offline RL but the authors derive a direct preference objective such that the training is supervised not RL-based.\n\nUsing a standard preference model, a supervised objective (DPO) is derived, theoretically justified, and compared to PPO. The authors test their method on three tasks: sentiment completion (IMDB), summarization (as in Stiennon et al), and single-turn dialogue with Anthropic's HH dataset. They find that DPO achieves higher reward while staying closer to the reference model (KL) in the IMDB task. Using GPT-4 as a proxy for human judgement on summarization, DPO can match PPO's performance while being less sensitive to sampling temperature. They validate GPT-4 with human annotators and find that DPO is even slightly more preferred over PPO. On dialogue, they find that DPO outperforms supervised and re-ranking (again using GPT-4 eval) but do not compare against PPO.""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The overall idea is relatively simple but the justification and theorems provide an excellent basis. The paper is timely and gives an excellent alternative to RLHF, that should be notably more efficient. The paper is clearly written and has the potential to be very impactful if used at scale in modern methods. GPT-4 evaluations and the follow-up human evaluations are strong and demonstrate both improved performance and robustness which can be notably bad in RLHF. The authors include the minimal code for DPO in the appendix which is commendable and many GPT-4 evaluation details for excellent reproducibility. The presentation is also very clear and breaking down the DPO loss into its components with clear language is an excellent addition. '}, 'weaknesses': {'value': ""The main weakness is the unexplored main difference between DPO and PPO: generalization. The authors note it in limitations but since PPO is trained on-policy and DPO is trained offline, looking at generalization outside the dataset would be helpful. The work, as is, feels sufficient without those experiments but the difference does play into an inconsistency with some theorems. The other major issue are some incongruenties in the evaluation that the authors should respond to.\n\nThe proofs and theorems contain a hidden assumption that is not explicitly stated. In the formulations for PPO, the optimization uses $y \\sim \\pi_\\theta$ whereas in the formulations for DPO $y \\sim D$ i.e. DPO's algorithm is offline and the model learned from its implicit reward has guarantees over the dataset. In contrast, PPO's algorithm is learned over a new set of datapoints sampled from the model during training. This means that Equation 3 is maximized over a different set of data points than Equation 7. So even though Theoerem 1 is correct, Lemma 2 does not fully encompass this situation. With offline DPO vs on-policy PPO, equivalent reward models could induce different optimal policies since they are being optimized over a different set of points. The section seems to imply that PPO and DPO can induce the same optimal policies because of the ambiguity with $y$. Clarifying this would be helpful. This also means that section 5.2 and the substitution used to make Equation 10 is not exactly accurate as the optimal policy for PPO is not the same as the optimal policy for DPO. I still feel the point of section 5.2 is reasonable but the authors should explicitly note the issue with the substitution. \n\nThere are issues with each of the different evaluations, even though the overall picture does suggest that the method is sound. I will increase my score if the authors simply clarify some questions about the evaluations (not even necessary to do changes / re-run experiments)\n\nFor controlled sentiment (IMDB), the authors do not give many details, seem to deviate from previous work on the task without explanation. The GRUE benchmark (RL4LMs) specifically uses GPT-2 base and finds that models should not be supervised-finetuned before RL training. In contrast, the authors use GPT-2 large (not even GPT-2 medium) and do supervised finetuning before PPO. No details of the baseline are given except for the graph legend which implies the PPO baseline comes from the `trl` library, although the authors only claim to use the `trlx` library. It is also unclear whether the evaluation is over the train set or the test set. Since this task is the only one where the authors show the tradeoff between reward achieved and KL, these details seem important.\n\nFor summarization, the issue is relatively minor. GPT-4 may be an unfair evaluator (see Large Language Models are not Fair Evaluators) and the work would benefit from evaluating samples in both positions (i.e. option A then B and option B then A)\n\nFor Anthropic's HH, the authors claim there is no SFT model available but there are many available pretrained models for this benchmark that the authors do not compare against. The most prominent example being a GPT-J 6B model `reciprocate/ppo_hh_gpt-j` hosted on huggingface which also has wandb runs and repro code available on the `trlx` library. The authors have chosen Pythia 2.8B when there exists a similar Pythia 1.6B PPO-trained on the HH dataset and it is unclear why the authors do not compare to this model or another PPO-trained model.\n""}, 'questions': {'value': 'What are the compute differences between DPO and PPO? It feels like DPO should be much more efficient and this information would only strengthen your work.\n\nWhy do you not compare against ILQL for sentiment? As an offline RL method, it seems the closest RL comparison to DPO\n\nFor reproducibility, what exact API are you using for the GPT-4 evaluation (e.g. GPT-0314)\n\nCan you move Figure 2 and 3 to the next pages so it is closer to the text that references it?'}, 'limitations': {'value': 'The authors did quite well to address limitations in the paper, I believe they covered most of my concerns there.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors propose DPO, a method to fine-tune a language model to human preferences that does not use reinforcement learning or learn a reward model, but rather, directly optimizes the language model with preference data.\n\nThrough a change of variables, the authors express the reward function in terms of the optimal policy $\\pi*$ and $\\pi^{ref}$. The authors write the human preference distribution in terms of $\\pi*$ and $\\pi^{ref}$, and thus a maximum likelihood objective can be written in terms of $\\pi_\\theta$ and $\\pi^{ref}$. This formulation allows for a simple DPO gradient update.\n\nThe method is equivalent to fitting a reparameterized Bradley-Terry model. With mild assumptions, DPO does not constrain the class of learned reward models.\n\nExperimental results are run on three different open-ended generation tasks. Baselines include PPO, zero-shot and few-shot prompting, a SFT model, and Preferred-Ft. DPO’s reward/KL tradeoff dominates that of PPO. Furthermore, win-rates of DPO compared to other models (or test-set labels) beat baselines.\n\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The paper is a significant contribution in a high impact area -- namely, fine-tuning language models to human preferences. DPO opens a new paradigm of learning human preferences without RL, and is a viable and performant alternative to the RLHF pipeline, reducing computational demands, and requires little tuning of hyperparameters\n\nDPO is grounded theoretically, equivalent to fitting a reparameterized Bradley-Terry model. The DPO update is simple and interpretable. Theorem 1 shows we do not necessarily constrain ourselves in terms of the reward model after reparameterization.\n\nExperimental results are good. DPO learns a better Reward / KL tradeoff compared to baselines in the sentiment generation task. DPO also has excellent win-rates compared to a number of baselines as evaluated with GPT-4 on the summarization and single-turn dialogue tasks. Human evaluators show as high correlations with each other as compared with the GPT-4 evaluation.'}, 'weaknesses': {'value': 'Single-turn dialogue experimental results did not compare DPO with a RLHF baseline tuned from the same base model, and it appears that helpful-rejection-sampled data from the Anthropic HH dataset was used, a relatively weaker baseline compared to the helpful-online dataset.\n\nThere are very few details on the experimental setup for the IMDB Sentiment Generation task.\n\nImprovements to the clarity of the paper can be made, including more detailed descriptions of experimental setup in the Appendix.'}, 'questions': {'value': 'Please provide experimental details for the IMDB Sentiment Generation task.\n\nPlease clarify what dataset, (specifically, whether the “helpful-online” or “helpful-rejection-sampled” data) was used for the single-turn dialogue experiment?\n\nWhy does win-rate in the single-turn dialogue task increase with higher sampling temperature in Figure 3?'}, 'limitations': {'value': 'Assumes we use Plackett-Luce models to model preferences.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents a new policy optimization algorithm with human preferences, called Direct Preference Optimization (DPO), which eliminates the need for explicitly fitting a reward model. The authors formulate the process of RLHF into a single stage policy learning by leveraging a mapping between reward functions and optimal policies. The main contribution of this paper is that they theoretically derive a new objective function that is equivalent to existing RLHF methods but can be simply learned by a single objective, and experimentally shows that it has better performance.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- This paper presents a new algorithm that can simply learn the policy from a given human preference dataset without explicit reward learning. \n- This paper not only experimentally shows better results than RLHF, but also provides theoretical connections with RLHF.'}, 'weaknesses': {'value': '- Since the reward model is not explicitly learned and the policy is learned only with the given human preference dataset, there is a possibility that the generalization performance for unseen prompts is relatively low compared to the existing RLHF.\n- Experiments are insufficient to show that DPO is more stable than conventional RLHF. In order to show that the DPO can be learned more stably, it seems that the learning curve should be provided together with the results shown in the experiment.\n- A detailed description of the experiment is lacking. (ex. amount of human preference dataset used in the experiment)\n- Depending on the amount of human preference dataset, DPO may have better or worse performance than RLHF, but there is no analysis or explanation about this.'}, 'questions': {'value': '- In Figure 2 of the experiment results, why does DPO perform better than PPO-GT even though PPO-GT uses a true reward function?\n- The values of the target KL used in PPO-GT are large (target KL $\\in$ {3, 6, 9, 12}). Is there a reason why the hyperparameter search range is set this way? In the previous paper (ex. [1]), hyperparameter search was done in a much wider range (target KL $\\in$ {0.02, 0.05, 0.1, inf}), and there were good results at low values, so I wonder if the results of the PPO-GT used in the paper were suboptimally learned.\n- In the results according to the sampling temperature, why does DPO have robust results to the sampling temperature?\n- How does the fluency (or naturalness) of the generated sentences from the learned policy according to training iteration change in the DPO experiment? In the case of RLHF, the fluency of the generated sentence shows a result that is sensitive to the coefficient of the KL divergence term (i.e. Fluency deteriorates as learning progresses in RLHF algorithm). I wonder if DPO does not have a similar problem. \n- Also, it was mentioned in the paper that DPO learning is stable regardless of hyperparameter beta, but I wonder if learning according to various beta values is stable without degeneration issues (i.e. degrading the fluency). \n- Unlikelihood learning (i.e. decreasing the likelihood) objectives are easy to degrade fluency (or naturalness), but how is it possible to stably learn while including unlikelihood learning objectives in DPO? It seems that the main difference between the equation for the gradient of the DPO and unlikelihood learning is that the weight term is multiplied. What exactly does the weight do to make learning stable?\n- What does the star mean in the right plot of Figure 2?\n\n[1] Rajkumar Ramamurthy and Prithviraj Ammanabrolu et al, Is Reinforcement Learning (Not) for Natural Language Processing: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization, ICLR 2023'}, 'limitations': {'value': '- Since the reward model is not explicitly learned and used, generalization to unseen prompts may not work well.\n- A comparison of RLHF and DPO in various experimental settings is lacking.\n- As mentioned in Questions and Weaknesses, it seems that there are still some parts that are not clearly explained or verified.\n- Details of the experimental setup are omitted.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper tackles a very important problem in LLM training, i.e., how to simplify the complex process of reinforcement learning from human feedback? RLHF is different to use, it is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the LLM using RL to maximize this estimated reward. The authors propose DPO, a training paradigm for training language models from preferences without reinforcement learning. DPO identifies a mapping between language model policies and reward functions that enables training a language model to satisfy human preferences directly, with a cross-entropy loss, without reinforcement learning. The experimental results show that DPO can fine-tune LLMs as well or better than existing algorithms.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'This article addresses a crucial issue in LLM training, i.e., how to perform alignment in a simpler way without using RL. The proposed DPO is remarkably simple yet effective, and it exhibits good theoretical properties. I believe DPO is highly significant for researchers in the field and will serve as a powerful tool for their work.'}, 'weaknesses': {'value': ""This is a very solid piece of work. The proposed method is simple yet effective. I don't have any particular concerns or issues with it.""}, 'questions': {'value': 'None'}, 'limitations': {'value': 'Yes'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Direct Preference Optimization: Your Language Model is Secretly a Reward Model'}, 'authors': {'value': ['Rafael Rafailov', 'Archit Sharma', 'Eric Mitchell', 'Christopher D Manning', 'Stefano Ermon', 'Chelsea Finn']}, 'authorids': {'value': ['~Rafael_Rafailov1', '~Archit_Sharma1', '~Eric_Mitchell1', '~Christopher_D_Manning1', '~Stefano_Ermon1', '~Chelsea_Finn1']}, 'keywords': {'value': ['reinforcement learning from human feedback', 'language models', 'RLHF', 'preferences']}, 'abstract': {'value': ""While large-scale unsupervised language models (LMs) learn broad world knowledge and some reasoning skills, achieving precise control of their behavior is difficult due to the completely unsupervised nature of their training. Existing methods for gaining such steerability collect human labels of the relative quality of model generations and fine-tune the unsupervised LM to align with these preferences, often with reinforcement learning from human feedback (RLHF). However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model. In this paper, we leverage a mapping between reward functions and optimal policies to show that this constrained reward maximization problem can be optimized exactly with a single stage of policy training, essentially solving a classification problem on the human preference data. The resulting algorithm, which we call Direct Preference Optimization (DPO), is stable, performant, and computationally lightweight, eliminating the need for fitting a reward model, sampling from the LM during fine-tuning, or performing significant hyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align with human preferences as well as or better than existing methods. Notably, fine-tuning with DPO exceeds RLHF's ability to control sentiment of generations and improves response quality in summarization and single-turn dialogue while being substantially simpler to implement and train.""}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': ""Fine-tuning with RLHF is complicated; we show that it doesn't need to be.""}, 'pdf': {'value': '/pdf/4d127e3396b404865afc9d826a0170a85d17adda.pdf'}, 'supplementary_material': {'value': '/attachment/140240afc2922cc7a2c9479ced99e819c7191f9f.pdf'}, '_bibtex': {'value': '@inproceedings{\nrafailov2023direct,\ntitle={Direct Preference Optimization: Your Language Model is Secretly a Reward Model},\nauthor={Rafael Rafailov and Archit Sharma and Eric Mitchell and Christopher D Manning and Stefano Ermon and Chelsea Finn},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=HPuSIXJaa9}\n}'}, 'paperhash': {'value': 'rafailov|direct_preference_optimization_your_language_model_is_secretly_a_reward_model'}}]"
"['Aravind Gollakota', 'Adam Klivans', 'Konstantinos Stavropoulos', 'Arsen Vasilyan']",NeurIPS,Tester-Learners for Halfspaces_ Universal Algorithms,https://neurips.cc/virtual/2023/oral/73861,2023," We give the first tester-learner for halfspaces that succeeds universally over a wide class of structured distributions. Our universal tester-learner runs in fully polynomial time and has the following guarantee: the learner achieves error $O(\mathrm{opt}) + \epsilon$ on any labeled distribution that the tester accepts, and moreover, the tester accepts whenever the marginal is any distribution that satisfies a Poincare inequality. In contrast to prior work on testable learning, our tester is not tailored to any single target distribution but rather succeeds for an entire target class of distributions. The class of Poincare distributions includes all strongly log-concave distributions, and, assuming the Kannan--Lovasz--Simonovits (KLS) conjecture, includes all log-concave distributions. In the special case where the label noise is known to be Massart, our tester-learner achieves error $\mathrm{opt} + \epsilon$ while accepting all log-concave distributions unconditionally (without assuming KLS).Our tests rely on checking hypercontractivity of the unknown distribution using a sum-of-squares (SOS) program, and crucially make use of the fact that Poincare distributions are certifiably hypercontractive in the SOS framework.",Oral 6D Theory,https://openreview.net/pdf?id=Kv8GJkV19S,https://openreview.net/forum?id=Kv8GJkV19S,Kv8GJkV19S,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This is a strong result about a fundamental, well-motivated problem, requiring interesting and non-trivial ideas.'}}, {'title': {'value': 'Official Comment by Reviewer 9R84'}, 'comment': {'value': 'I thank the authors for their insightful feedback. My reviews and score remain the same.'}}, {'comment': {'value': 'I thank the authors for their clarifications. However, my moderate concerns (listed in the Weaknesses) remain, and I will retain my rating.'}}, {'comment': {'value': 'Thank you for your comments and clarification. I believe it would be useful to include the first one in the submission.'}}, {'rebuttal': {'value': 'We wish to thank the anonymous reviewer for their suggestions and comments!\n\nPrior work in the area has demonstrated that, in the distribution specific setting, assuming that the marginals are “nice” (i.e., that $\\lambda$ is some constant) is sufficient and there is no dependence of the error bound on the Poincare parameter (hence, the error bound would be in that case $\\mathrm{poly}(\\lambda)\\mathrm{opt} + \\epsilon$). We note that the precise dependence on the niceness parameter $\\lambda$ was not stated explicitly in prior work. As for the dependence on the Poincare parameter, it arises due to the need to provide efficiently testable bounds to certain quantities (see Lemma 3.2) which, in the non-testable setting, admit tighter bounds; in other words, the bounds we use involve some slackness due to testability requirements. \n\n  Regarding prior work on regular (non universal) testable learning, prior work only provides results with respect to strongly log-concave marginals (based on the technology of fooling halfspaces via moment matching), where $\\gamma$ is always a constant (see also lines 200-206).\n'}}, {'rebuttal': {'value': 'We thank the reviewer for their constructive feedback. Here are our responses to the questions, which we will aim to incorporate in a future revision:\n\nTheorem 4.1 states that in the Massart noise case, we can achieve the optimal $\\mathrm{opt}+\\epsilon$ guarantee, while in the agnostic setting, we get an approximately optimal guarantee which is proportional to a polynomial of the Poincare parameter ($\\gamma$) of the target class of marginal distributions. Therefore, in the agnostic setting, we obtain a constant approximation factor only when $\\gamma$ is constant (which is true for strongly log-concave distributions and conditionally true for log-concave distributions). In the Massart noise case, however, even when $\\gamma$ is polynomial in the dimension, the guarantee is optimal (and the runtime is still polynomial in the dimension). It is known that the parameter $\\gamma$ that corresponds to isotropic log-concave distributions is indeed bounded by a polynomial in the ambient dimension (see, e.g., [1]). We will add such a discussion in the final version of the paper.\n\nIt is not clear whether there is a more direct approach to providing results in the universal setting based on prior work. Recall that (roughly) the work of [GKSV23] considers the distribution of examples conditioned to a number of strips perpendicular to vector w and compares the moments of each of these conditional distributions to what these moments should be (under a specific distribution). Now, even for a single one of these strips, it is unknown how to determine whether a set of moments indeed matches those that would arise from a strongly log-concave distribution (which is not given to us in advance). \n\nEven the seemingly simpler task of determining whether a set of low-degree moments of a distribution matches those of some unknown strongly log-concave distribution is not known to be achievable efficiently (using a method employing some form of discretization, or any other method). Indeed, such an algorithm would in particular give a novel alternative method for certifying hypercontractivity of an unknown strongly log-concave distribution, which is a task that is only known to be achievable using a highly sophisticated sum-of-squares approach [3].\nHowever, the moment discretization approach might conceivably be useful towards generalizing the results of [2] in the universal setting.\n\n[1] Chen, Y. (2021). An almost constant lower bound of the isoperimetric coefficient in the KLS conjecture. Geometric and Functional Analysis, 31, 34-61.\n\n[2] Gollakota, A., Klivans, A. R., & Kothari, P. K. (2023). A moment-matching approach to testable learning and a new characterization of rademacher complexity. STOC 2023.\n\n[3] Pravesh K Kothari and Jacob Steinhardt. Better agnostic clustering via relaxed tensor\nnorms. arXiv preprint arXiv:1711.07465, 2017.\n'}}, {'rebuttal': {'value': 'We wish to thank the anonymous reviewer for their feedback and for appreciating our work!\n\nThe reviewer is right that it is an interesting open question whether our techniques can be applied to achieve optimal guarantees (i.e., $\\mathrm{opt}+\\epsilon$) for testably learning halfspaces when the noise model is more challenging than Massart. We believe that such results could conceivably be accomplished by future work for other types of noise, e.g., for Tsybakov noise (by adapting Proposition 4.2). But as the reviewer is likely aware, at least under adversarial noise (where we achieve $O(\\mathrm{opt})+\\epsilon$), there is evidence (e.g. see [1], [2], [3], [4]) that achieving optimal guarantees in polynomial time is impossible. \n\n\n[1] Diakonikolas, I., Kane, D.M., & Zarifis, N. (2020). Near-Optimal SQ Lower Bounds for Agnostically Learning Halfspaces and ReLUs under Gaussian Marginals. NeurIPS 2020.\n\n[2] Goel, S., Gollakota, A., & Klivans, A.R. (2020). Statistical-Query Lower Bounds via Functional Gradients. NeurIPS 2020.\n\n[3] Diakonikolas, I., Kane D.M., & Ren, L. (2023). Near-Optimal Cryptographic Hardness of Agnostically Learning Halfspaces and ReLU Regression under Gaussian Marginals. ICML 2023.\n\n[4] Tiegel, S. (2023). Hardness of Agnostically Learning Halfspaces from Worst-Case Lattice Problems. COLT 2023.'}}, {'summary': {'value': 'Learning halfspaces is a very well studied problem in machine learning. In the agnostic (adversarial label noise) and distribution free setting, this problem has been known to be computationally intractable. As a result, there have been several works of agnostic learning in distribution specific settings (where the marginal distribution belongs to a particular family of distributions, say Gaussian or log-concave). In this scenario, the learner has an error of the form $OPT + \\epsilon$, where OPT denotes the optimal 0-1 error. This however has complexity $d^{1/\\epsilon^2}$, and the exponential dependency on $1/\\epsilon$ is tight. This motivates the designing of learning algorithms that have better sample complexity with respect to $1/\\epsilon$, whereas the error becomes $f(OPT) + \\epsilon$ for some function f.\n\nOften these works use a single distribution as the target marginal distribution. In this work, the authors studied this problem with respect to a set of marginal distributions (Universal testable learning, Definition 1.1). The authors studied this problem in the newly introduced Testable learning framework  by Rubinfeld and Vasilyan. Here the goal is if the tester accepts, then with high probability the output of the learning is close to some function of OPT, and if the data satisfies the distributional assumptions, the algorithm accepts with high probability.\n\nHere the authors design a universal tester learner for Halfspaces with respect to distributions with bounded Poincare constant (Definition 2.4) and concentration and anti-concentration properties (Definition 2.1) in Theorem 1.2. Moreover, this class of distributions contains strongly log-concave distributions, and assuming Kannan–Lovasz–Simonovits (KLS) conjecture, contains all log-concave distributions (Definition 2.2-2.6). Later in theorem 1.3, they design a universal tester learner for Halfspaces with Massart noise (the labels are flipped by an adversary with probability $\\eta <1/2$).\n\nSome previous and concurrent works for single distribution D^* assumption use approximate moment matching techniques, where the algorithm tests if the low moments of the input distribution D approximately matches with that of D^*. However it is not clear if this same approach can be applied for a collection of distributions. This has also been discussed in the introduction.\n\nThe authors first design testers for testing bounded disagreement (Lemma 3.1) and of testing anti-concentration properties (Lemma 3.2) which uses a tester for testing hypercontrctivity. It is known that any distribution $D$ with bounded Poincare constant is hypercontractive in Sum-of-Squares (SOS) framework. Thus the authors run a polynomial time semidefinite program for the later purpose. Next in Section 4, the authors design the final tester (Theorem 4.1). They use a surrogate loss minimization technique for the surrogate loss function defined in Equation 4.1. The main idea is that stationary points of surrogate loss are close to some optimal vector corresponding to the halfspace (the related lemma is Lemma 4.3). Lemma 4.3 contains bounds for both Massart and adversarial noise settings.\n\nIt would be interesting if tester-learners can be designed for function classes other than halfspaces. The authors also discusses this at the end of Section 1.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'Overall this is a nice result which generalizes several previous works designed for a single marginal distribution assumption and studies for the setting of a collection of marginal distributions. '}, 'weaknesses': {'value': 'What is the usefulness of the tester-learner model in real life applications. '}, 'questions': {'value': 'None'}, 'limitations': {'value': 'It would be interesting if tester-learners can be designed for function classes other than halfspaces. The authors also discusses this at the end of Section 1.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper proposes the first tester-learner for learning the class of halfspaces universally over a class of strongly log-concave distributions (or the class of all log-concave distributions under the KLS assumption). Unlike prior works that crucially rely on testing a specific given marginal distribution while rejecting other well-behaved distributions, the proposed algorithm can accept the marginal distribution as long as it is in the family $\\mathcal{D}$. The proposed algorithm is motivated by the tester-learner using non-convex SGD [GKSV23] but with a more careful analysis on the anti-concentration property. The algorithm is powered by the SOS program to check the hypercontractivity of the desired random variable $Z$ that exhibits certain anti-concentration properties, which is known suffices for identifying the Poincare distributions ([KS17]).\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'Designing provable tester-learners addresses the issue that traditional learning algorithms crucially rely on distribution assumptions which could be stringent in practice, which is of importance both from the practical and theoretical sides. This paper proposes the first tester-learner that universally accepts any distribution from a broad family of distributions that satisfy a Poincare inequality, largely generalizing those algorithms that only accepts a certain distribution. The technical contribution lies in identifying the Poincare distributions by applying SoS framework to certify a hypercontractive property of the constructed random variable, which generalizes the known results for standard Gaussian to distributions with weak anti-concentration properties. The technique could be of independent interest for testable weak anti-concentration.\n'}, 'weaknesses': {'value': 'From the technical side, the SoS program for checking the hypercontractive already exists in [KS17]. The contrition of this paper is more on the application side of such a framework on the problem of testing-learning halfspaces with additional assumptions of certain concentration and anti-concentration. That being said, it is a novel application of such a framework given that it solves a very interesting and important problem.\n'}, 'questions': {'value': 'While Massart noise is considered in this paper, is it possible to directly apply the techniques to other more challenging types of noise? '}, 'limitations': {'value': 'No concerns.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper develops a tester-learner for halfspaces in the recently proposed testable learning framework of [RV23]. A recent work [GKSV23] had studied the same problem and proposed tester-learners for halfspaces with Massart noise and in the agnostic setting, for any particular strongly-log concave distribution. This work qualitatively improves upon [GKSV23] by developing a tester-learner for a class of strongly log-concave distributions rather than a fixed strongly log-concave distribution, and also provides better algorithmic complexity for the agnostic case. In fact, this work captures $\\gamma$-Poincare distributions which contain strongly log-concave distributions and under the [KLS95] conjecture also all log-concave distributions. In the Massart noise case, their algorithm works for log-concave distributions unconditionally.\n While following the recently developed approach (and used by [GKSV23]) of non-convex SGD for learning halfspaces over certain good distributions, this paper does a more careful analysis of the gradient lower bound leading to the requirement of a certain hypercontractivity property (which holds for Poincare distributions). The paper uses techniques for previous work [KS17] to show that sum-of-squares (SoS) SDP can be used to certify this hypercontractivity which is a main technical novelty.\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': 'The paper proves better and qualitatively more general and stronger bounds for testable learning of halfspaces over a general class of distributions. The technical contributions - the use of properties of Poincare distributions and using SoS to certify hypercontractivity -  are interesting and novel in the context of this problem, and provide for universal tester-learners. The paper is well written and effectively conveys its main contributions and the techniques used. Overall, the paper is technically solid.'}, 'weaknesses': {'value': 'The paper follows the same roadmap of [GKSV23] with better analysis and a new tester (based on previous work [KS17]) for hypercontractivity, and in that sense feels somewhat incremental. The results are also moderate improvements and generalizations of previous results and not entirely unexpected. '}, 'questions': {'value': '1. It may be helpful to clarify why the main Theorem 4.1 also captures log-concave distributions unconditionally for the case with Massart noise, while only capturing strongly log-concave distributions in the agnostic setting. \n\n2. Is it clear that the previous work of [GKSV23] cannot be tweaked (e.g. by discretizing the space of the vector of moments to be matched) to work for the class of strongly log-concave distributions? \n'}, 'limitations': {'value': 'Yes'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work studies the problem of designing tester-learners for halfspaces in the agnostic setting and under Massart noise. In the setting of tester-learners, we do not make distributional assumptions on our samples, but rather require that our algorithm produces an accurate output whenever the input satisfies a sequence of efficiently computable tests. Further, if the samples actually come from a specific target distribution, it is required that the tests pass with high probability.\n\nPrevious tester-learners for noisy halfspaces used tests tailored towards a *specific* distribution, e.g., a specific strongly log-concave distribution. As a consequence, these testers might reject samples from a different strongly log-concave distribution although algorithmically it would have been possible to learn the underlying halfspace. The authors propose a tester which simultaneously accepts for all Poincaré distributions that satisfy some natural niceness conditions. This class includes all isotropic strongly log-concave distributions. When their tester accepts, the tester-learner outputs a halfspace achieving error $O(\\mathrm{opt}) + \\varepsilon$, where $\\mathrm{opt}$ is the error of the optimal halfspace on the distribution of the input. For the Massart setting they can handle all isotropic log-concave distributions and achieve error $\\mathrm{opt} + \\varepsilon$.\n\nThe authors argue that previous works were inherently limited to work with only a single distribution since they were matching moments with this specific distribution. In their work, they overcome this issue by only checking the actual properties they need in the proof of accuracy which are not tied to any specific distribution.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'In my eyes, designing tester learners which simultaneously accept for a large class of distribution is an important step for bringing the framework of testable learning closer to practice. The motivation for testable learning was that designing algorithms that only work under specific distributional assumptions has little value in practice since likely these assumptions will not be met. Thus, we would at least like to know if we can trust the output of our algorithm when we run it on actual data or not. While previous tester-learners did have this benefit, it seems that the proposed testers ""overfit"" to specific distributions. However, the chances that real world data comes from any specific distribution are rather small. Thus, providing testers which work for larger classes of distributions is an important step.\n\nOn a technical level, their tester has a natural explanation that I like: It simply checks the properties that are need in the proof in the non-testable setting. Further, the paper is very well-written (except the point below).'}, 'weaknesses': {'value': 'I feel that the technical overview that the authors provide might be hard to understand if the reader is not familiar with the arguments in previous work or at least the general area. It would be nice if it could be adjusted slightly to make it more accessible to a wider audience.\n\nAlso, specifically for the agnostic setting, it would be useful to compare your approximation factor to (a) testable learners that only work for one specific (or a more restricted class of distributions) and (b) non-testable learners for the same distribution class you consider.'}, 'questions': {'value': 'Related to the above: In the agnostic setting, your error bound scales as $\\mathrm{poly}(\\lambda) (1+\\gamma^4) \\mathrm{opt} + \\varepsilon$, where $\\lambda$ is the niceness parameter of the marginal distribution and $\\gamma$ the Poincaré constant. How does this compare to the non-testable learning error?'}, 'limitations': {'value': 'Limitations were addressed appropriately.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Tester-Learners for Halfspaces: Universal Algorithms'}, 'authors': {'value': ['Aravind Gollakota', 'Adam Klivans', 'Konstantinos Stavropoulos', 'Arsen Vasilyan']}, 'authorids': {'value': ['~Aravind_Gollakota1', '~Adam_Klivans1', '~Konstantinos_Stavropoulos1', '~Arsen_Vasilyan1']}, 'keywords': {'value': ['testable learning', 'pac learning', 'agnostic learning', 'Massart label noise', 'adversarial label noise', 'distribution testing']}, 'abstract': {'value': 'We give the first tester-learner for halfspaces that succeeds universally over a wide class of structured distributions. Our universal tester-learner runs in fully polynomial time and has the following guarantee: the learner achieves error $O(\\mathrm{opt}) + \\epsilon$ on any labeled distribution that the tester accepts, and moreover, the tester accepts whenever the marginal is any distribution that satisfies a Poincare inequality. In contrast to prior work on testable learning, our tester is not tailored to any single target distribution but rather succeeds for an entire target class of distributions. The class of Poincare distributions includes all strongly log-concave distributions, and, assuming the Kannan--Lovasz--Simonovits (KLS) conjecture, includes all log-concave distributions. In the special case where the label noise is known to be Massart, our tester-learner achieves error $\\mathrm{opt} + \\epsilon$ while accepting all log-concave distributions unconditionally (without assuming KLS).\nOur tests rely on checking hypercontractivity of the unknown distribution using a sum-of-squares (SOS) program, and crucially make use of the fact that Poincare distributions are certifiably hypercontractive in the SOS framework.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/60d1fa250f7381027b1c366c889919a927efca7f.pdf'}, '_bibtex': {'value': '@inproceedings{\ngollakota2023testerlearners,\ntitle={Tester-Learners for Halfspaces: Universal Algorithms},\nauthor={Aravind Gollakota and Adam Klivans and Konstantinos Stavropoulos and Arsen Vasilyan},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=Kv8GJkV19S}\n}'}, 'paperhash': {'value': 'gollakota|testerlearners_for_halfspaces_universal_algorithms'}}]"
"['Liyuan Liu', 'Chengyu Dong', 'Xiaodong Liu', 'Bin Yu', 'Jianfeng Gao']",NeurIPS,Bridging Discrete and Backpropagation_ Straight-Through and Beyond,https://neurips.cc/virtual/2023/oral/73827,2023," Backpropagation, the cornerstone of deep learning, is limited to computing gradients for continuous variables. This limitation poses challenges for problems involving discrete latent variables. To address this issue, we propose a novel approach to approximate the gradient of parameters involved in generating discrete latent variables. First, we examine the widely used Straight-Through (ST) heuristic and demonstrate that it works as a first-order approximation of the gradient. Guided by our findings, we propose ReinMax, which achieves second-order accuracy by integrating Heun’s method, a second-order numerical method for solving ODEs. ReinMax does not require Hessian or other second-order derivatives, thus having negligible computation overheads. Extensive experimental results on various tasks demonstrate the superiority of ReinMax over the state of the art.",Oral 2A Efficient Learning,https://openreview.net/pdf?id=mayAyPrhJI,https://openreview.net/forum?id=mayAyPrhJI,mayAyPrhJI,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': ""All six reviewers agreed this paper should be accepted: it is original, high quality, clear, and provides (to the best of my knowledge) the first formal result showing the straight-through estimator is a first-order approximation in the multinomial case. Given that ReinMax has similar computational complexity to straight-through and improves performance it will likely gain traction as a drop-in replacement. This is a clear accept. Authors: you've already indicated that you've updated the submission to respond to reviewer changes, if you could double check their comments for any recommendation you may have missed on accident that would be great! The paper will make a great contribution to the conference!""}}, {'title': {'value': 'Thanks all reviewers for their valuable time, efforts, and constructive suggestions'}, 'comment': {'value': ""We would like to express our gratitude to the reviewers for their valuable time, efforts, and constructive suggestions.\n\nTo briefly recap our primary contributions:\n1. We formally establish that Straight-Through works as a first-order approximation in the general multinomial case.\n2. We propose a novel and sound gradient estimation method ReinMax that achieves second-order accuracy without requiring any second-order derivatives. ReinMax is shown to improve state-of-the-art methods in extensive experiments.\n\nIn our submission, we adhered to the experiment design of the existing study, focusing on small-scale problems for controllability and resource efficiency. In the discussion, we presented additional experiment results across diverse settings, including a real-world application, to further demonstrate the potential of ReinMax. \n\nWe also wish to note that we will utilize the extra space available in the final version to enhance our paper's clarity and presentation.""}}, {'title': {'value': 'Thanks'}, 'comment': {'value': 'Thank you for this feedback authors. This will be taken into account.'}}, {'title': {'value': 'Thanks'}, 'comment': {'value': 'Thank you for this feedback authors. This will be taken into account.'}}, {'title': {'value': 'Author Response'}, 'comment': {'value': ""Thank you for your constructive feedback. We're glad our clarifications were helpful. we will include the discussions and clarifications in the revision.""}}, {'title': {'value': 'Author Response'}, 'comment': {'value': ""Thank you for your feedback. We appreciate your acknowledgment of our work's performance in the experiments, and we will include the discussions and clarifications here. ""}}, {'comment': {'value': 'I thank the authors for their response and for providing further insights on the theoretical aspects of their work. The authors added comparison with the state of the art method for REINFORCE variance reduction and provided insight on the strengths of each method which I found to be helpful for my understanding of their work. I am also happy to know that the authors have acknowledge my point on the novelty of the theoretical perspective and are willing to adjust the writing. With the above concerns addressed, I am bumping up my score to a 7.'}}, {'comment': {'value': 'I thank the authors for taking the time to carefully right each step of their derivation to me. As other reviewers suggested, some details needed for the full derivation should be mentioned in the main text, or I would alternatively suggest to include the derivations in the appendix if the main body run out of space.\n\nSince the proposed contribution consistently outperforms alternative methods in the experiments provided in the paper as well as the additional experiments provided in the global rebuttal, I am increasing my score accordingly.'}}, {'title': {'value': 'Thanks for your comments'}, 'comment': {'value': 'Thank you for acknowledging our contribution. To highlight the significant potential of our proposed method, we provide additional experimental results (as elaborated in our general rebuttal). We will incorporate these discussions in our revised version.'}}, {'title': {'value': 'Response to the Authors'}, 'comment': {'value': ""I have read the other reviews and the authors' rebuttals and have decided to maintain my score. A majority of the reviewers feel that this paper should be accepted; the main contention is over the degree of significance. I hope that the authors include the new experiments, as well as the reviewers' suggestions, in the revised paper.""}}, {'title': {'value': 'Author response'}, 'comment': {'value': 'Thanks again for your timely response and detailed suggestions! We will include these discussions and additional results in the revision. '}}, {'title': {'value': 'Rebuttal follow-up'}, 'comment': {'value': ""Dear authors,\n\nthanks for the rebuttal. I am satisfied with your discussion of ReinMax's applicability/limitations (W1) and the possible extension to higher-order estimators. **Please make sure to include them in the draft**.\n\nYou should also include a footnote that explains the algorithm's name, as this was brought up by multiple reviewers.\n\nBased on the overall positive feedback on your experiments (W2) from the other reviewers, as well as the additional results you provided in the rebuttal, I have decided to raise my score.\n""}}, {'rebuttal': {'value': 'Thank you for your constructive feedback. We value your comments and will address the concerns regarding experimental design in this rebuttal, with further elaborations to be included in the final paper.\n\n**Reply to weakness 1:** Thanks for the suggestions! We will add more elaborations in the revision. \n\n**Reply to weakness 2:** In our submission, we adhered to the experiment design of the existing study, focusing on small-scale problems for controllability and resource efficiency, as our experiments were mainly conducted on P100/P40 GPUs.\n\nTo further demonstrate the generalizability of ReinMax, we conducted additional experiments (detailed in the general rebuttal), including (1) comparisons with the REINFORCE variant that employs the state-of-the-art variance reduction technology, specifically RODEO (SHI 2022), and (2) applications to a real-world scenario, i.e., differentiable neural architecture search on CIFAR10, CIFAR100, and ImageNet-16-120. \n\nReinMax maintained outstanding performance throughout these expanded tests, showing consistent improvements over the baseline.\n\n**Reply to question 1:** In the general rebuttal, we detailed comparisons between ReinMax and RODEO, a REINFORCE variant employing a state-of-the-art variance reduction method. RODEO outperforms ReinMax on simple scenarios (e.g., large batch size, small number of latent variables, Setting A). Meanwhile, ReinMax achieves better performance on complex scenarios (e.g., small batch size, large number of latent variables, VAE, and Setting B). We will add more elaborations and make corresponding revisions in the final version. \n\nWe hope our responses have adequately addressed your concerns and further highlighted the innovations and potential impact of our study. If you have any further questions or need additional information, please do not hesitate to ask.\n'}}, {'rebuttal': {'value': 'Thank you for your constructive feedback. We value your comments and will address your concerns regarding the correctness of the derivation, with further elaborations to be included in the final paper.\n\n\n**Reply to weakness argument 1:** Since $\\sum_i \\pi_i = 1$, we have $\\sum_i E[f(D)] \\frac{d \\pi_i}{d \\theta} = E[f(D)] \\cdot \\frac{d\\sum_i \\pi_i }{d\\theta} = E[f(D)] \\cdot \\frac{d 1}{d\\theta} = 0$\nIn the revision, we will add a simple explanation of this in Eq. (6).\n\n**Reply to weakness argument 2:** Thanks for pointing out the typo, and we will fix the typo and add more elaborations in the revision. Please find the detailed derivation of the last-second equation in Appendix C as below. \n\n\n$\\sum_i \\sum_j \\phi_j \\frac{\\partial f(I_j)}{\\partial I_j} (I_i - I_j) \\frac{d \\pi_i}{d \\theta}$\n\n$= \\sum_j \\Large(\\normalsize \\phi_j\\frac{\\partial f(I_j)}{\\partial I_j} \\sum_i (I_i - I_j) \\frac{d \\pi_i}{d \\theta} \\Large)\\normalsize$ \n\n$= \\sum_j \\Large(\\normalsize \\phi_j\\frac{\\partial f(I_j)}{\\partial I_j} (\\sum_i I_i \\frac{d \\pi_i}{d \\theta} - \\sum_i I_j \\frac{d \\pi_i}{d \\theta} )\\Large)\\normalsize$\n\n$= \\sum_j \\Large(\\normalsize \\phi_j\\frac{\\partial f(I_j)}{\\partial I_j} (\\sum_i I_i \\frac{d \\pi_i}{d \\theta} - I_j \\frac{d \\sum_i \\pi_i}{d \\theta} )\\Large)\\normalsize$\n\n$= \\sum_j \\Large(\\normalsize \\phi_j\\frac{\\partial f(I_j)}{\\partial I_j} (\\sum_i I_i \\frac{d \\pi_i}{d \\theta} - I_j \\frac{d 1}{d \\theta}) \\Large)\\normalsize$\n\n$= \\sum_j \\phi_j\\frac{\\partial f(I_j)}{\\partial I_j} \\sum_i I_i \\frac{d \\pi_i}{d \\theta}$\n\n$= \\sum_j \\frac{\\phi_j}{\\pi_j}\\cdot \\pi_j \\cdot \\frac{\\partial f(I_j)}{\\partial I_j} \\sum_i I_i \\frac{d\\pi_i}{d\\theta}$.\n\n\n**Reply to weakness argument 3 and question 1:**\nIn the revision, we will mention the derivative of the softmax around L171, i.e., for $\\pi = \\mbox{softmax}(\\theta)$, we have $\\partial \\pi_i / \\partial \\theta_k = \\pi_k (\\delta_{ik} - \\pi_i)$. Please find the detailed derivation of equation (8) as below. \n\n$\\frac{\\partial \\mathcal{L}}{\\partial \\theta_k}= \\frac{\\partial \\sum_i \\pi_i f(I_i) }{\\partial \\theta_k}$\n\n$=\\sum_i f(I_i) \\frac{d \\pi_i}{d \\theta_k}$\n\n$= \\sum_i f(I_i) \\pi_k (\\delta_{ik} - \\pi_i)$\n\n$= \\sum_i f(I_i) \\pi_k \\delta_{ik} - \\sum_i f(I_i) \\pi_k \\pi_i$\n\n$= f(I_k) \\pi_k - \\sum_i f(I_i) \\pi_k \\pi_i$\n\n$= f(I_k) \\pi_k \\sum_i \\pi_i - \\sum_i f(I_i) \\pi_k \\pi_i$\n\n$= \\pi_k \\sum_i \\pi_i (f(I_k) - f(I_i))$.\n\nWe hope our responses have adequately addressed your concerns and further highlighted the innovations and potential impact of our study. If you have any further questions or need additional information, please do not hesitate to ask.\n'}}, {'rebuttal': {'value': ""Thank you for your constructive feedback. We value your comments and will address the concerns regarding experimental design and presentation in this rebuttal, with further elaborations to be included in the final paper.\n\n**Reply to weakness 1:** We understand the complexity of ReinMax's exact form may not be immediately intuitive, as it is a result of specific derivations. To alleviate confusion, we will dedicate additional space in the final version to elaborate on the exact form of ReinMax. \n\n**Reply to weakness 2:** In our submission, we adhered to the experiment design of the existing study, focusing on small-scale problems for controllability and resource efficiency, as our experiments were mainly conducted on P100/P40 GPUs.\n\nTo further demonstrate the generalizability of ReinMax, we conducted additional experiments (detailed in the general rebuttal), including (1) comparisons with the REINFORCE variant that employs the state-of-the-art variance reduction technology, specifically RODEO (SHI 2022), and (2) applications to a real-world scenario, i.e., differentiable neural architecture search on CIFAR10, CIFAR100, and ImageNet-16-120. \n\nReinMax maintained outstanding performance throughout these expanded tests, showing consistent improvements over the baseline. These additional experiments should provide a more comprehensive understanding of ReinMax's potential applications.\n\n**Reply to question 1:** We used the paper title and the abstract as the prompt and queried ChatGPT for several names, among which we selected ReinMax, since it concisely implies the method's connection to softmax and REINFORCE, and we believe it is a fitting and appealing term. \n\nWe hope our responses have adequately addressed your concerns and further highlighted the innovations and potential impact of our study. If you have any further questions or need additional information, please do not hesitate to ask.\n""}}, {'rebuttal': {'value': 'Thank you for your constructive feedback. We value your comments and will address the concerns regarding the novelty of our study and experiment design, with further elaborations to be included in the final paper.\n\n**Reply to weakness argument 1:**  While it may be intuitive to some that the straight-through estimator functions as a gradient approximation, no prior work has formally established this for the general multinomial case. \n\nAlso, the derivation of Theorem 3.1, while not overly complicated, is more than a mere expansion of existing results: \n\n- In Tokui & Sato (2017), the authors positioned $\\hat{\\nabla}_{ST}$ as a first-order approximation, but their analysis is exclusively rooted in the properties of Bernoulli variables. As an example, let us consider a Bernoulli random variable $D \\\\in \\\\{ I_1, I_2 \\\\}$. Their approach depends on the property that $\\\\nabla = (f(I_2) - f(I_1)) \\frac{d\\\\pi_1}{d \\\\theta} = (f(I_1) - f(I_2)) \\\\frac{d\\\\pi_2}{d \\\\theta}$, and thus is not applicable to multinomial variables.\n\n- On the other hand, the analyses in Gregor et al. (2014) and Pervez et al. (2020) are applicable to multinomial variables but resort to adding the term $\\\\frac{1}{n \\\\cdot \\\\pi_D}$ in $\\\\hat{\\\\nabla}_{ST}$, an alteration that we believe could induce unwanted instability. This concern is discussed in Section 4.1 and Section 6.4. \n\nIn the revision, we will modify our claim as “our study is the first to formally establish $\\\\hat{\\\\nabla}_{ST}$ works as a first-order approximation in the general multinomial case"".\n\n**Reply to weakness argument 2:**\nIn the general rebuttal, we provide additional experimental results on  (1) comparisons with the REINFORCE variant that employs the state-of-the-art variance reduction technology, specifically RODEO (SHI 2022), and (2) applications to a real-world scenario, i.e., differentiable neural architecture search on CIFAR10, CIFAR100, and ImageNet-16-120. \n\nReinMax maintained outstanding performance throughout these expanded tests, showing consistent improvements over the baseline.\n\n\n**Reply to question 1:**\nIn our experiments, we observed that temperature scaling enhances the stability of both ST and ReinMax algorithms. We conjecture that this scaling acts as a variance reduction method. \n\nAcross all six VAE settings discussed in the general rebuttal, ReinMax achieved the best performance when the temperature was set to 1.1. Adjusting the temperature to 1.0 or 1.2 would lead to a slight performance drop (with an ELBO difference of approximately 1), while ReinMax still outperformed RODEO with these sub-optimal temperatures. \n\n**Reply to question 2.1**\nAs discussed in Section 6.4, the computation overhead of ReinMax is negligible. \n\n**Reply to question 2.2**\nAlthough it\'s possible to apply higher-order ODE solvers, they require more gradient evaluations, leading to undesirable computational overhead. To illustrate this point:\n- The approximation used by ReinMax (as described in Definition 3.2) requires N gradient evaluations, i.e., $\\\\{\\\\frac{\\\\partial f(I_i)}{\\\\partial I_i}\\\\}$.\n- In contrast, the approximation derived by RK4 needs $N^2+N$ gradient evaluations, i.e., $\\\\{\\\\frac{\\\\partial f(I_i)}{\\\\partial I_i}\\\\}$ and $\\\\{\\\\frac{\\\\partial f(I_{ij})}{\\\\partial I_{ij}}\\\\}$, where $I_{ij} = \\\\frac{I_i + I_j}{2}$. \n\nTherefore, while higher-order solvers are applicable, they may not be suitable in our case.\n\nWe hope our responses have adequately addressed your concerns and further highlighted the innovations and potential impact of our study. If you have any further questions or need additional information, please do not hesitate to ask.\n'}}, {'rebuttal': {'value': ""Thank you for your constructive feedback. We value your comments and will address the concerns regarding experimental design, presentation, and limitations of ReinMax in this rebuttal, with further elaborations to be included in the final paper.\n\n**Reply to limitation 1:** While our main text focuses on multinomial distributions, by reparameterizing other categorical distributions into a multinomial distribution, ReinMax can be generally applied to all categorical random variables. \n\nIt is worth mentioning that ReinMax is not applicable to continuous random variables. While extending ReinMax to these cases is possible, it may not be necessary, given that many commonly used distributions can be reparameterized. For example, the normal distribution $z \\sim \\mathcal{N}(\\mu, \\sigma)$ can be re-written as $z = \\mu + \\sigma \\cdot \\mathcal{N} (0, 1)$, making it trivial to compute $\\partial z/\\partial \\mu$ and $\\partial z/\\partial \\sigma$. \n\nFurthermore, ReinMax differs from REINFORCE in that ReinMax requires both the $\\frac{\\partial f(D)}{\\partial D}$ and $\\frac{\\partial p(D)}{\\partial \\theta}$, while REINFORCE only requires $\\frac{\\partial p(D)}{\\partial \\theta}$. Thus, REINFORCE can be applied in cases where $f(D)$ is not differentiable.\n\n**Reply to weakness 2:** In our submission, we adhered to the experiment design of the existing study, focusing on small-scale problems for controllability and resource efficiency, as our experiments were mainly conducted on P100/P40 GPUs.\n\nTo further demonstrate the generalizability of ReinMax, we conducted additional experiments (detailed in the general rebuttal), including (1) comparisons with the REINFORCE variant that employs the state-of-the-art variance reduction technology, specifically RODEO (SHI 2022), and (2) applications to a real-world scenario, i.e., differentiable neural architecture search on CIFAR10, CIFAR100, and ImageNet-16-120. \n\nOur findings showed that ReinMax performs strongly and consistently in these settings. We will add more discussions and elaborations about these experiments in the final version of the paper.\n\n**Reply to weakness 3:** We appreciate your suggestions for improving clarity, and we will incorporate them into our revision.\n\n**Reply to question 1:** We used the paper title and the abstract as the prompt to query ChatGPT for several names, among which we selected ReinMax since it concisely implies the method's connection to softmax and REINFORCE, and we believe it is a fitting and appealing term. \n\n**Reply to question 2** Although it's possible to apply higher-order ODE solvers, they require more gradient evaluations, leading to undesirable computational overhead. To illustrate this point:\n- The approximation used by ReinMax (as described in Definition 3.2) requires N gradient evaluations, i.e., $\\\\{\\\\frac{\\\\partial f(I_i)}{\\\\partial I_i}\\\\}$.\n- In contrast, the approximation derived by RK4 needs $N^2+N$ gradient evaluations, i.e., $\\\\{\\\\frac{\\\\partial f(I_i)}{\\\\partial I_i}\\\\}$ and $\\\\{\\\\frac{\\\\partial f(I_{ij})}{\\\\partial I_{ij}}\\\\}$, where $I_{ij} = \\\\frac{I_i + I_j}{2}$. \n\nTherefore, while higher-order solvers are applicable, they may not be suitable in our case.\n\n**Reply to question 3** $\\phi$ is a distribution over $\\{I_1, \\cdots, I_n\\}$, i.e., $\\sum_i \\phi_i = 1$ and $\\phi_i = P(I_i)$.\n\nWe hope our responses have adequately addressed your concerns and further highlighted the innovations and potential impact of our study. If you have any further questions or need additional information, please do not hesitate to ask.\n""}}, {'rebuttal': {'value': 'Thank you for your constructive feedback. We value your comments and will address the concerns regarding experimental design, applicability, and limitations of ReinMax in this rebuttal, with further elaborations to be included in the final paper.\n\n**Reply to Weakness 1 and Question 1:** In our submission, we adhered to the experiment design of the existing study, focusing on small-scale problems for controllability and resource efficiency, as our experiments were mainly conducted on P100/P40 GPUs.\n\nTo further demonstrate the generalizability of ReinMax, we conducted additional experiments (detailed in the general rebuttal), including (1) comparisons with the REINFORCE variant that employs the state-of-the-art variance reduction technology, specifically RODEO (SHI 2022), and (2) applications to a real-world scenario, i.e., differentiable neural architecture search on CIFAR10, CIFAR100, and ImageNet-16-120. \n\nIn the architecture search application, ReinMax consistently improved performance over the baseline in a plug-and-play manner by:\n- Replacing STGS with ReinMax as the gradient estimator,\n- Conducting a minor change to the temperature hyper-parameters (changing the minimal value of the temperature from 0.1 to 1.1), as guided by our findings (refer to Sections 5 and 6.2).\n\n**Reply to limitation 1:** While our main text focuses on multinomial distributions, by reparameterizing other categorical distributions into a multinomial distribution, ReinMax can be generally applied to all categorical random variables. \n\nIt is worth mentioning that ReinMax is not applicable to continuous random variables. While extending ReinMax to these cases is possible, it may not be necessary, given that many commonly used distributions can be reparameterized. For example, the normal distribution $z \\sim \\mathcal{N}(\\mu, \\sigma)$ can be re-written as $z = \\mu + \\sigma \\cdot \\mathcal{N} (0, 1)$, making it trivial to compute $\\partial z/\\partial \\mu$ and $\\partial z/\\partial \\sigma$. \n\nWe hope our responses have adequately addressed your concerns and further highlighted the innovations and potential impact of our study. If you have any further questions or need additional information, please do not hesitate to ask.\n'}}, {'rebuttal': {'value': '# General Rebuttal\n\nWe thank all reviewers for their thoughtful feedback. In this work, we tackle critical challenges in gradient estimation for discrete variables, and our contributions are notable in two primary areas:\n- we formally established that the straight-through estimator is a first-order approximation of the gradient, \n- we proposed ReinMax, offering a second-order approximation with negligible computational overhead and consistent performance improvements.\n\nIn this general rebuttal, we provide additional experiment results on:\n- Comparisons with the REINFORCE variant that employs the state-of-the-art variance reduction technology, namely RODEO (SHI 2022).\n- Applications of ReinMax on real-world problems, specifically differentiable neural architecture search on CIFAR10, CIFAR100, and ImageNet-16-120.\n\n## Comparisons with RODEO\n\n### Bernoulli VAEs \n\nWe utilized ReinMax to train Bernoulli VAEs on MNIST, Fashion-MNIST, and Omniglot, adhering closely to the experimental settings of RODEO (SHI et al., 2022),  including pre-processing, model architecture, batch size, and training epochs. As summarized in Tables A and B, ReinMax consistently outperforms RODEO across all settings.\n\n**Train A: -ELBO of 2 x 200 VAE on MNIST, Fashion-MNIST, and Omniglot when K=3 (i.e., three evaluations per image). \\* Baseline results are referenced from SHI et al. (2022).**\n||ARMS$^*$|DoubleCV$^*$|RODEO$^*$|RELAX$^*$|ReinMax|\n|-|-|-|-|-|-|\n|MNIST |100.84±0.14|100.94±0.09|100.46±0.13|101.99±0.04|97.83±0.36|\n|Fashion-MNIST|237.05±0.12|237.40±0.11|236.88±0.12|237.74±0.12|234.53±0.42|\n|Omniglot|115.32±0.07|115.06±0.12|115.01±0.05|115.70±0.08|107.51±0.42|\n\n**Train B: -ELBO of 2 x 200 VAE on MNIST, Fashion-MNIST, and Omniglot when K=2 (i.e., two evaluations per image). \\* Baseline results are referenced from SHI et al. (2022).**\n\n||DisARM$^*$|Double CV$^*$|RODEO$^*$|ReinMax|\n|-|-|-|-|-|\n|MNIST |102.75±0.08|102.14±0.06|101.89±0.17|98.05±0.29|\n|Fashion-MNIST|237.68±0.13|237.55±0.16|237.44±0.09|234.86±0.33|\n|Omniglot|116.50±0.04|116.39±0.10|115.93±0.06|107.79±0.27|\n\n### Polynomial Programming\n\nTo better understand the difference between RODEO and ReinMax, we conduct more experiments on polynomial programming, i.e., $\\min_\\theta E_{X} \\Large[\\normalsize \\frac{\\|X - c\\|_p^p}{L}\\Large]\\normalsize$. Specifically, we consider polynomial programming under two different settings that define $c$ differently (the difference between these two settings is elaborated at the end of the part):\n- Setting A: $c = [0.45, \\cdots, 0.45]$. This is the setting we used in the submission. \n- Setting B: $c = [\\frac{0.5}{L}, \\frac{1.5}{L}, \\cdots, \\frac{L-0.5}{L}]$. \n\nWe visualized the training curve of polynomial programming in the attached pdf (Figure 13), together with the training curve of Bernoulli VAE (Figure 12). ReinMax achieves better performance in more challenging scenarios, i.e., smaller batch size, more latent variables, or more complicated problems (Setting B or VAEs). Meanwhile, REINFORCE and RODEO achieve better performance on simpler problem settings, i.e., larger batch size, fewer latent variables, or simpler problems (Setting A). This observation matches our intuition:\n- REIFORCE-style algorithms excel as they provide unbiased gradient estimation but may fall short in complex scenarios, since they only utilize the zero-order information, i.e., a scalar $f(\\cdot)$ for each training instance. \n- ReinMax, using more information (i.e., a vector $\\frac{\\partial f(D)}{\\partial D}$ for each training instance), handles challenging scenarios better. Meanwhile, as a consequence of its estimation bias, ReinMax leads to slower convergence in some simple scenarios. \n\nAs to the difference between the Setting A and the Setting B, we would like to note: \n- In Setting A, since $\\forall i, c_i=0.45$ and $\\theta_i\\sim Uniform(-0.01, 0.01)$ at initialization, $E_{X_i \\sim \\mbox{softmax}(\\theta_i)}\\Large[\\normalsize \\frac{\\|X_i - c_i\\|_p^p}{L}\\Large]\\normalsize$ would have similar values. Therefore, the optimal control variates for $\\theta_i$ are similar across different $i$. \n- In Setting B, we set $c_i$ to different values for different $i$, and thus the optimal control variate for $\\theta_i$ are different across different $i$. \n\nTherefore, Setting A is a simpler setting for applying control variate to REINFORCE. \n\n## Differentiable Neural Architecture Search \n\nWe demonstrate the applicability of ReinMax as a drop-in replacement in differentiable neural architecture search. \n\nGDAS (Dong & Yang, 2019) is an algorithm that employs STGS to estimate the gradient of neural architecture parameters with a temperature schedule (decaying linearly from 10 to 0.1). We replaced STGS with ReinMax as the gradient approximator and changed the minimal temperature from 0.1 to 1.1(as discussed in Section 5 and Section 6.2, temperature scaling plays a different role in ReinMax). \n\nWe evaluate the resulting algorithm with the official implementation under the topology search setting in the NATS-Bench benchmark (Dong et al., 2020), and summarize the results in Table C as below. ReinMax brings consistent performance improvements over the baseline across all three datasets, demonstrating the great potential of ReinMax. We will add more analyses and discussions in the revision. \n\n**Train C: Performance in NATS-Bench.\\* Baseline results are referenced from Dong et al. (2020).**\n\n||CIFAR-10 DEV|CIFAR-10 TEST|CIFAR-100 DEV|CIFAR-100 TEST|ImageNet-16-120|\n|-|-|-|-|-|-|\n|GDAS-Straight-Through Gumbel-Softmax$^*$|89.68±0.72|93.23±0.58|68.35±2.71|68.17±2.50|39.55±0.00|\n|GDAS-ReiMax|89.92±0.27|93.47±0.35|69.40±1.63|69.61±1.71|41.11±2.09|\n\nDong, X. and Yang, Y. Searching for a robust neural architecture in four GPU hours. *CVPR*, 2019.\n\nDong, X., Liu, L., Musial, K., and Gabrys, B. Nats-bench: Benchmarking nas algorithms for 307 architecture topology and size. *TPAMI*, 2020.'}, 'pdf': {'value': '/pdf/5ef08e647facd01a0391b10c5f7f1b844212125c.pdf'}}, {'summary': {'value': 'The paper shows that the straight-through estimator is a first-order approximation of the gradient. The authors then propose a method, called ReinMax, which provides a second-order approximation with negligible computational overhead. Experiments are performed in several settings involving discrete variables (polynomial programming, structured output prediction, and discrete latent variable generative models), showing that ReinMax is more accurate and stable.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '**Originality**\n\nThe originality of the paper is fairly strong. As I see it, the main contributions of the paper are in 1) identifying the straight-through estimator as an instance of the forward Euler method, which is a first-order approximation of the gradient, and 2) using Heun’s method to derive a second-order gradient approximation. To someone mostly outside of the field of gradient approximation, these are non-trivial insights that, to the best of my knowledge, are unique to this paper.\n\n**Quality**\n\nThe paper is high quality. I particularly appreciated the effort that the authors put into the empirical evaluation, performing hyperparameter sweeps to demonstrate stability, as well as empirically verifying that the ReinMax gradient estimator provides improved estimates of the true gradient. Overall, the result is a paper that provides compelling evidence of 1) improved understanding of straight-through and 2) an improved gradient estimator.\n\n**Clarity**\n\nOverall, the paper is quite clear. The authors do an excellent job of presenting mathematical notation to help the reader see the similarities across gradient derivations and estimators. Theoretical results are presented in a clear, logical order. The empirical results are also generally presented well, with clear labeling of tables and plots.\n\n**Significance**\n\nWhile many papers have mentioned that the straight-through estimator is an approximation of the gradient, it appears that none of these papers have formally shown it. If, indeed, this paper is the first to do so, then it is a significant contribution to our theoretical understanding. The proposed improved estimator, ReinMax, also appears to offer some performance improvement over previously proposed (first-order) estimators. Considering that ReinMax has similar computational overhead as straight-through, then this could serve as a drop-in replacement for the straight-through estimator throughout various applications. However, it is unclear to me whether this serves as a drop-in replacement for all existing instances of the straight-through estimator, or merely those that operate on Multinomial distributions.'}, 'weaknesses': {'value': 'I see two relatively minor weaknesses in the paper as-is: larger-scale empirical evaluation and slight improvements to the presentation. These are discussed below.\n\nThe current empirical evaluation involves three settings: quadratic programming, structured output prediction, and latent variable generative modeling with discrete latent variables. While the authors demonstrate ReinMax in all three settings, much of the empirical evaluation revolves around the final setting (categorical VAE on MNIST). These results are a useful indicator of the benefits of ReinMax, however, the empirical setting itself is rather toy-ish compared with modern settings. Given that ReinMax is a drop-in replacement for the straight-through estimator, I would imagine that it should be trivial to replace the ST estimator in an existing scaled-up setting, e.g., vector-quantized VAEs or Hafner et al.’s discrete world models. The authors could alternatively / additionally explore categorical VAEs on more complex data. This would allow the authors to more definitively claim that their proposed gradient estimator leads to tangible empirical improvements.\n\nAdditionally, several minor aspects of the presentation could be improved.\n* The plots in Figure 1 are presented with fairly minimal context in the surrounding text. The caption states “Details are elaborated in Section 6.” Then it may make sense to place this figure closer to Section 6.\n* As far as I can tell, the name “ReinMax” is never actually explained.\n* The labels for the baseline methods, e.g., in Figure 1, 4, etc. are difficult to read; they are various dashed lines. Colors and/or larger lines would make this clearer. \n* The shaded regions in Figure 5 (right) are rather jagged — perhaps there’s an issue with the evaluation interval or the plotting setup.\n* In various tables, e.g., Tables 1, 2, …, the results for ReinMax are bolded, despite falling within the error bounds of the baseline methods. I find this to be somewhat misleading.\n* The citation in the second sentence of the introduction is incorrect.'}, 'questions': {'value': 'Could you please elaborate on the applicability of the ReinMax estimator? Does this estimator (or the insights developed in the theoretical sections of the paper) alleviate the “laborious and time-consuming” work of developing “different ST variants for different applications in a trial-and-error manner”?'}, 'limitations': {'value': 'As mentioned above, I would appreciate a clearer discussion of which existing forms of straight-through estimator the ReinMax estimator can replace.\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""This paper is about designing a new approach to approximating the gradient of parameters in generating discrete random variables.\nThe work first starts with discovering the connection of Straight-Through (ST) estimator and the first-order approximation of the true gradient.\nFrom the insight, the authors aim to improve the ST estimator, by applying second-order approximation of the true gradient. To apply second-order approximation without actually calculating second-order derivatives, the authors use Heun's Method, which approximates second-order derivatives using two first-order derivatives; thus no expensive calculation is needed.\nThe proposed estimator is coined ReinMax.\nThrough mathematical analyses, the effectiveness of using the expected value of function outputs is proven.\nFrom evaluations, the authors empirically prove ReinMax method outperforms other estimators, along with presenting other properties and insights e.g. sensitivity to the number of dimensions, batch size, convergence speed, memory usage, and running time.""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- The paper is well-organized and easy to follow\n- Mathematical background is given thoroughly\n- The method can be applied with minimal change of code'}, 'weaknesses': {'value': '- Equation 6 seems to be one of core findings from the paper; the derivation process may be written more comprehensibly (like in Appendix A)\n- More evaluations on benchmark datasets close to real-world distribution would be beneficial. For instance, how much improvement will be made when we apply the ReinMax estimator into other models for NLI or sentiment analysis instead of ListOps?'}, 'questions': {'value': '- In experiments using the most basic REINFORCE algorithm, not RLOO or DisARM-Tree, is there any baseline subtraction used? If not can the $E[f(I_i)]$ baseline be used also in REINFORCE?'}, 'limitations': {'value': 'As mentioned in the checklist, I suppose no potential negative societal impact will arise by this work. Experiments are done quite fairly, including standard deviations of scores and implementation code.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""This work develops a new method, ReinMax, to compute gradients of parameters\nused to generate discrete random variables; specifically, the parameters of a\nmultinomial's softmax parameterization. It provides a new perspective onto the\nexisting straight-through (ST) gradient estimator as a first-order\napproximation. The new method is a second-order approximation and, in contrast\nto ST, relies on gradient differences rather than a single gradient. The ReinMax\ngradient estimator is compared to other approaches on polynomial programming toy\nproblems, unsupervised parsing on ListOps, and ELBO training of a VAE on MNIST.\n""}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- (S1) The paper provides a new perspective onto the Straight-Through (ST) technique,\n  which simply replaces the backpropagation through a non-differentiable\n  operation by applying the identity. This adds a new theoretical justification\n  why such heuristics work. Framing ST as first-order approximation also naturally\n  suggests an extension to second-order, as presented by the paper.\n\n- (S2) The new method does not seem to add significant overhead to existing\n  approaches. The analysis includes a sensitivity analysis over different\n  problem hyper-parameters which suggests that the estimation works\n  consistently.\n'}, 'weaknesses': {'value': ""- (W1) Limited to softmax parameterization of multinomial: The main text focuses\n  on computing gradients for the parameters of a multinomial parameterized by a\n  softmax. The authors should comment on the (im)possibility to treat other\n  parameterizations or distributions.\n\n- (W2) Experiments: In the presented experiments, ReinMax seems to consistently\n  work well and perform comparably or more favourably than the competitors.\n  However, I do not have the expertise to judge whether the experiments\n  represent state-of-the-art tasks. I am willing to adapt my score and\n  confidence during the discussion phase with the authors and other reviewers.\n\n- (W3) Clarity: Some steps could be easier to follow by providing the required\n  mathematical properties. The figures and tables should be moved closer to\n  where they are referenced in the text. Here is a list of actionable\n  suggestions which I think would improve clarity:\n  - In Eq. (4), explicitly add the term $\\partial D / \\partial \\pi$ that is set\n    to the identity in ST\n  - In Eq. (6), mention that $\\sum_i \\partial \\pi_i / \\partial \\theta = \\partial\n    \\sum_i \\pi_i / \\partial \\theta = \\partial 1 / \\partial \\theta = 0$.\n  - I think it would be helpful to move parts of appendix E to the main text to\n    have a more formal description of first- and second-order approximation in\n    the specific context.\n  - Fix '2rd-order' into '2nd-order' in various places in the main text\n    and the appendix.\n  - Mention the derivative of a softmax around L171, that is $\\partial \\pi_i /\n    \\partial \\theta_k = \\pi_k (\\delta_{ik} - \\pi_i)$\n   - Clarify the notation $\\delta_{\\mathbf{D} k}$ in the appendix\n  - Minor suggestions: Use consistent symbol $\\mathcal{R}$ in L51, 'softmax' in\n    caption of Figure 1, remove 'on' in L84, 'computational efficiency' rather\n    than 'computation efficiency', 'approximation' in L185, use bold symbol for\n    $\\theta_i$ in L210 and add $\\in \\mathcal{R}^2$, 'phenomena' rather than\n    'phenomenon' in L218), add 'that' between 'one' and 'uses' in L264\n\n""}, 'questions': {'value': '- Why is the method called ReinMax?\n\n- ReinMax is a second-order extension of ST. Can this be extended to even higher\n  orders? Would this be beneficial or are there diminishing returns in including\n  higher orders?\n\n- What is $\\phi_i$ in L150 and what are its constraints?\n'}, 'limitations': {'value': 'See  (W1)'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""The paper proves that the straight-through (ST) gradient estimator for the categorical distribution can be viewed as a first-order approaximation of the true gradients. Based on this point of view, a new gradient estimator, ReinMax is proposed based on Heun's method which is a second-order method. Experiments are conducted which show that ReinMax improves upon the state of the art methods.""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""- **The paper has good writing quality.** The background is introduced in a well-organized manner and contributions are stated clearly. Mathematical formulae are also well laided out and are easy to understand. Relationship with existing work (ST, REINFORCE, baseline subtraction) are also expanded upon in good detail and nuance.\n\n- **Solid contribution with a comprehensive set of experiments.** The proposed new method has solid theoretical underpinnings (Heun's method being more accurate than Euler's method), is still very efficient (not requiring the Hessian), and is proven to be effective under multiple different settings (polynomial programming, MNIST, etc.). The new method is compared against many commonly used methods (STGS, DisARM, ...) and there is also discussion of using a different baseline for subtraction. Extensive hyperparameter tuning is performed and advantage of the proposed method is demonstrated well.""}, 'weaknesses': {'value': 'My main concern with this paper is that it **oversells its theoretical contribution**. The view of the straight-through estimator as a first-order Taylor expansion of the unbiased gradients is not news to people who study gradient estimators. The authors are fair in pointing out that previous work (Tokui & Sato 2017) only dealt with the Bernoulli case, but one might argue that The categorical distribution is just a natural extension of the Bernoulli case. Regardless, I think it is **potentially misleading to say that ""ST as a first-order approximation to the gradient"" is a novel perspective**. Despite this, I still consider the proposed approach to be novel enough that the contribution of the paper as a whole is still significant.\n\nAnother concern is the lack of comparison with RODEO (Shi 2022) which as far as I know is the state of the art for REINFORCE methods with variance reduction. The paper only reported numbers on RLOO and DisARM in table 3 but these methods are known to be weaker than RODEO, which is reported to outperform DisARM significantly in terms of gradient variance.'}, 'questions': {'value': ""- What is the effect of temperature scaling on the proposed method? How does it influence the relative performance of ST-type methods when compared with unbiased REINFORCE-based methods?\n- Is there a complexity-efficiency trade-off here? For example, would using 4th-order Runge-Kutta instead of Heun's method yield much better gradient estimations and improve the overall result?""}, 'limitations': {'value': 'The authors do not explicitly discuss the limitations of their work.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper works on gradient approximation for discrete latent variables. The problem is challenging because the discreteness hinders direct backpropagation through the neural networks; hence, an approximation is needed. The authors address the issues from the perspective of a second-order approximation of the gradient. Specifically, the authors proposed ReinMax and showed that ReinMax achieved second-order accuracy with negligible computation overheads. The experiments on Polynomial Programming, MNIST-VAE, and ListOps demonstrated the superiority of ReinMax over the prior methods such as Straight-Through Gumbel-Softmax, Gumbel-Rao Monte Carlo, and Gapped Straight-Through.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""The problem has been challenging for a long time. Most prior work addresses the issue from the perspective of Straight-Through Gumbel Softmax (STGS). To the reader's best knowledge, the perspective of second-order approximation is novel in this field and the performance improvement is believable. Below highlights the strengths of the paper.\n\na) The use of second-order approximation is novel and the theoretical derivation is believable. \n\nb) The performance gain is clear with similar computational overhead as in the prior work.\n\nc) The experimental analysis covers some relevant topics such as temperature scaling and the choice of baseline. The conclusion is clear from the analysis.""}, 'weaknesses': {'value': 'a) The design choice of ReinMax is unclear. \n\nAlthough ReinMax is well-motivated by the second-order approximation, the reader might be confused by the form of ReinMax at Eq. (7). For example, why mixing $\\pi$ and $D$ by introducing $\\pi_D=(\\pi+D)/2$? Why substracts by $\\nabla_{ST}$? Where are the coefficients (2 and 1/2) from? It would be nice if the authors can elaborate more on these.\n\nb) The implication of the experiments remains unclear.\n\nFor a fair comparison with the prior work, the authors follow the literature and run ReinMax on Polynomial Programming, MNIST-VAE, and ListOps. However, these are toy problems with limited implications for the applications. For example, does the good performance of ReinMax on Polynomial Program/MNIST-VAE/ListOps imply any possible applications? Conversely, if we have a reinforcement learning problem with discrete actions or a VQ-VAE model, can ReinMax be helpful? It would be nice if the authors can evaluate more on the application side so that the other practitioners can follow.'}, 'questions': {'value': 'Why the proposed method is called ReinMax?\n\nFor the other questions, see the weakness section.'}, 'limitations': {'value': 'No potential negative social impact.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The presented paper tackles the optimization of the parameter of the distribution of a discrete random variable through stochastic gradient descent by addressing the problem of gradient estimation given samples from the discrete distribution.\nThe authors consider three popular estimators as a starting point for their investigation, namely, the reinforce estimator, the straight-through estimator and the straight-through gumbel-softmax estimator.\n\nThe authors first establish that the straight-through estimator is a first-order approximation of the true gradient, since the difference $f(I_i) - f(I_j)$ in the true gradient is replaced by $\\frac{\\partial f(I_j)}{\\partial I_j}(I_i - I_j)$.\nThe author thus replace the $\\frac{\\partial f(I_j)}{\\partial I_j}(I_i - I_j)$, which gives a first-order approximation of $f(I_i) - f(I_j)$, by $\\frac{1}{2} (\\frac{\\partial f(I_j)}{\\partial I_j} + \\frac{\\partial f(I_i)}{\\partial I_i})(I_i - I_j)$, which yield a second order approximation.\n\nThe authors then empirically evaluates both the baselines and the proposed estimator on a synthetic task (polynomial programming), unsupervised modeling (unsupervised sequence parsing), and structured output prediction (generative modeling).\n\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- The theoretical analysis is well written and intuitively explained.\nThe interpretation of the straight-through estimator as a first-order approximation of the true gradient allows the author to use numerical analysis results to improve the theoretical behavior of their proposed solution.\n- The experiment section is decent, with qualitatively different setups addressing different application domains.\n- The choice of the baseline for the baseline subtraction method as well as the tuning of the temperature parameter is appropriately discussed.'}, 'weaknesses': {'value': ""- Equation (6) does not seem to be valid. I would expect $\\sum_i (f(I_i) - E[f(D)]) \\frac{d \\pi_i}{d\\theta} = \\sum_i \\sum_j \\pi_j(f(I_i) - f(I_j)) \\frac{d \\pi_i}{d\\theta}$, thus I don't understand why the term $\\sum_i E[f(D)] \\frac{d \\pi_i}{d \\theta}$ vanishes.\n- The derivation of remark 4.1 as provided in appendix C does not seem to be valid. I don't understand how\n$\\sum_i \\sum_j \\pi_j \\frac{\\partial f(I_j)}{\\partial I_j}(I_i - I_j)) \\frac{d \\pi_i}{d\\theta} = \\sum_i \\frac{\\phi_D}{\\pi_D} \\pi_D \\frac{\\partial f(I_j)}{\\partial I_j} \\sum_i I_i \\frac{d \\pi_i}{d\\theta}$. Furthermore, there should be a typo at line 155 since it should be $\\pi_D$ who is the output of the softmax and could take very small values. This would be consistent with the fact that it is the denominator of the fraction $\\frac{\\phi_D}{\\pi_D}$.\n- I have no idea how equation (8) has been derived.""}, 'questions': {'value': 'It is said that the derivation of equation (8) leverages the derivative of the softmax function, thus there may be a handy formula about these derivative that I am not aware of and which justify all the equations that do not seem valid to me. Could the authors elaborate on my concern about the validity of their equations ?\n\nI highly doubt that the equations are wrong, given that they coincide with previous work on the topic and the consistent improvements provided in the experiment section. I would be willing to increase my score if the author correctly addresses my concerns.'}, 'limitations': {'value': 'There is a decent discussion about the limitation of the proposed method througout the paper.\nAlbeit, given that high variance is the main limiting factor of the REINFORCE estimator, and given that the other estimators are biased, a focus on bias variance tradeoff would have been welcome.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Bridging Discrete and Backpropagation: Straight-Through and Beyond'}, 'authors': {'value': ['Liyuan Liu', 'Chengyu Dong', 'Xiaodong Liu', 'Bin Yu', 'Jianfeng Gao']}, 'authorids': {'value': ['~Liyuan_Liu3', '~Chengyu_Dong1', '~Xiaodong_Liu1', '~Bin_Yu5', '~Jianfeng_Gao1']}, 'keywords': {'value': ['discrete random variables', 'back-propagation', 'straight through']}, 'abstract': {'value': 'Backpropagation, the cornerstone of deep learning, is limited to computing gradients for continuous variables. This limitation poses challenges for problems involving discrete latent variables. To address this issue, we propose a novel approach to approximate the gradient of parameters involved in generating discrete latent variables. First, we examine the widely used Straight-Through (ST) heuristic and demonstrate that it works as a first-order approximation of the gradient. Guided by our findings, we propose ReinMax, which achieves second-order accuracy by integrating Heun’s method, a second-order numerical method for solving ODEs. ReinMax does not require Hessian or other second-order derivatives, thus having negligible computation overheads. Extensive experimental results on various tasks demonstrate the superiority of ReinMax over the state of the art.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'We show Straight-Through works as a first-order approximation of the gradient and propose ReinMax, which achieves second-order accuracy with negligible computation overheads.'}, 'pdf': {'value': '/pdf/4b7414632febe87b9e460ac7e8c125455e35b54a.pdf'}, 'supplementary_material': {'value': '/attachment/9b106468ce664fbec1e37ba725e427c6f82b6989.zip'}, '_bibtex': {'value': '@inproceedings{\nliu2023bridging,\ntitle={Bridging Discrete and Backpropagation: Straight-Through and Beyond},\nauthor={Liyuan Liu and Chengyu Dong and Xiaodong Liu and Bin Yu and Jianfeng Gao},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=mayAyPrhJI}\n}'}, 'paperhash': {'value': 'liu|bridging_discrete_and_backpropagation_straightthrough_and_beyond'}}]"
"['Tianqin Li', 'Ziqi Wen', 'Yangfan Li', 'Tai Sing Lee']",NeurIPS,Emergence of Shape Bias in Convolutional Neural Networks through Activation Sparsity,https://neurips.cc/virtual/2023/oral/73850,2023," Current deep-learning models for object recognition are known to be heavily biased toward texture. In contrast, human visual systems are known to be biased toward shape and structure. What could be the design principles in human visual systems that led to this difference? How could we introduce more shape bias into the deep learning models? In this paper, we report that sparse coding, a ubiquitous principle in the brain,  can in itself introduce shape bias into the network. We found that enforcing the sparse coding constraint using a non-differential Top-K operation  can lead to the emergence of structural encoding in neurons in convolutional neural networks,  resulting in a smooth decomposition of objects into parts and subparts and endowing the networks with shape bias.  We demonstrated this emergence of shape bias and its functional benefits for different network structures with various datasets. For object recognition convolutional neural networks, the shape bias leads to greater robustness against style and pattern change distraction. For the image synthesis generative adversary networks,  the emerged shape bias leads to more coherent and decomposable structures in the synthesized images. Ablation studies suggest that sparse codes tend to encode structures, whereas the more distributed codes tend to favor texture. Our code is host at the github repository: https://topk-shape-bias.github.io/",Oral 2B Objects/ Neuroscience/Vision,https://openreview.net/pdf?id=QzcZb3fWmW,https://openreview.net/forum?id=QzcZb3fWmW,QzcZb3fWmW,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'The paper shows that enforcing activation sparsity in deep neural networks biases their decision-making towards using shape cues, similar to human perception. All reviewers agree that it is a strong paper that makes a valuable contribution. They noted some minor concerns which were addressed well during the response and discussion period.'}}, {'rebuttal': {'value': 'We thank the reviewer for the insightful comments. The reviewer think our paper is novel and solid. Here we prepare the response to address the reviewer’s questions. \n- Comparison with  Ts w. Top-K only. As for the limitation of the response pages, we put the further experiments under our anonymous github repository: \nhttps://anonymous.4open.science/r/nips2023_shape_vs_texture-1057\n- Apply the Top-K to the transformer architecture. We conducted experiments and observe similar improvements on the shape bias score when applying sparsity to ViT. Please refer to our general response on the details. \n- Dead neurons and implicit regularization. Yes, indeed. We also address this issue in our general response. \n- Margalit et al., 2023: We will certainly include this work as a related work in our camera ready version. \n- Different layer of sparsity. Yes, we indeed apply different Top-K to different layers. We intend to mimic the long range communication yet local dense computation of the brain, i.e. we divide the network to several chunks and apply sparsity at the connections of these chunks. In VGG for example,  we apply the Top-K layer after the 5th, 10th, 17th, 23th, 31th original layers (after each MaxPooling Layer). In AlexNet, we also apply the Top-K layer after the MaxPooling except adding 2 additional Top-K layers at the 8th and 10th layer to make the sparse layer more evenly distributed. For the synthesis network, we only apply the sparsity on the 4th layer out of 8 layers as we observe that applying severe sparsity near the output layer would yield suboptimal performance. \n- Stronger baseline. We agreed on a strong baseline for evaluation. We included the ViT results in the general response. We believe our method is orthogonal to the scaling approach and our further study shows it can be combined with larger models to further improve the shape bias. However, due to the time limitation, we were unable to experiment with other large models that are trained on LION2B for example. We will try our best to apply the proposed method on the extremely large scale trained models in the following discussion period. \n- Accuracy v.s. Shape Bias. Our main manuscript Section 4.3 indicates that a network that is trained with Top-K operation can achieve competitive accuracy while increasing the shape bias robustness. In the general response Table 1, we can observe that Top-K training can lead to significant improvement compared to Top-K inference (see General Response Table 1 (2) v.s. (4)).\nIn terms of accuracy and shape bias trade-off, we agree with the reviewer that applying sparsity directly to inference could lead to degraded classification results. We interpolate between no sparsity and severe sparsity in the general response Figure 2(b). We vary the number of sparsity layers from 0 to 5 and observe that there is a sweet spot for balancing the shape bias and the classification accuracy. Therefore, in practice, we recommend training or fine tuning with Top-K operation to achieve the best performance and shape bias simultaneously. \n- The boxplot in Figure 3 and typos. We appreciate the reviewer’s question. To be specific, the distribution of the box plot is over different image categories. We will make further clarification and also correct the typo in our camera ready version. \n\n'}}, {'rebuttal': {'value': ""We appreciate the reviewer's kind comments and insightful feedbacks. We address the reviewers' concerns as follows:\n\n- ResNet variant of Figure 4. We thank the reviewer for bringing up this point. We conduct experiments on ResNet-50 (See general response Figure 1 (a)) and also on ViT (General response Figure 1 (b)). \n\n- L1 regularization: Indeed, we experimented with another soft version of sparsity, i.e. apply L1 norm to the loss function and document the results in the general response Table1 (5). We observe that the L1 induced sparsity introduces on-par shape bias as the Top-K do. We will perform more experiments on the effect of L1 activation loss on other tasks such as synthesis in the future. \n\n- Hyperparameter K. We currently perform grid search of the parameters but keep the Top-K value the same across different layers. We do observe that in ViT architecture, the fine shape bias would depend on the highest sparse level, e.g. if layer 1 keeps 20% of the activation and layer 2 keeps 40% activities, the final performance would be very similar to the one that both keep 20% of the activities. The underlying reason is still under investigation. \n\n- Editorial suggestion. We will further correct these minor errors and incorporate the suggested related work. \n\n""}}, {'rebuttal': {'value': 'We thank the reviewer for the kind advice and constructive feedback. The reviewer consider our paper is technically solid and has novel contribution as well as good writing. We prepare the following feedback to address the reviewer’s remaining questions:\n\n- Quantitative analysis of the visualization results. We agree with the reviewer however due to the page limits, we will put the further quantitative results in our supplementary. \n\n- Combining the existing solution. We appreciate the comment of the reviewer. Indeed, we generalize our method to more architecture (ResNet and ViT) in the general response. We will apply our methods to SIN in our anonymous github repository during the discussion period to further demonstrate that our method can be combined with existing solutions. \n\n- Non top-k value offset. Our motivation is to mimic the efficient coding principle utilized inside the brain. A learnable offset would introduce further optimization instability. Also during training, setting the non-top-k to zero would make the gradient to become zeros automatically. However, it might improve the inference accuracy if we keep the distribution mean statistics during Top-K inference. However, due to the limited time, we haven’t observed any significant difference in our preliminary experiments and we will do more tests in the following days. \n\n- TopK without training. We appreciate the reviewers’ point. Please refer to our general response Table 1 for more details. In general, we observe that our optimal parameters for Top-K training is not optimal for inference but training with Top-K significantly improves both shape bias and accuracy (as shown in (2) and (4) in the general response Table 1). \n\n- Colors in Figure 7. The white indicates positive and black indicates negative while the gray indicates 0. \n- The limitation of the standard protocols & datasets includes the fixed and limited category as well as its practically in the real world. We will include this limitation and propose more comprehensive in the future work.\n'}}, {'rebuttal': {'value': 'We thank the reviewer for the positive review and constructive feedback. The reviewer thinks our paper is technically solid with excellent contribution to a challenging goal in deep learning. We carefully prepare the following response aiming to address the reviewer’s questions:\n\n- Top-K layer specification:\n\n   We apply the Sparsity layer in a subset of the network. It is based on the intuition that the brain utilizes sparsity for long range communication but can allow local dense computation. We divide the networks into chunks where within each chunk the neuron’s activities are allowed to be dense (keep original) but the communication across different chunks is set to be sparse. To be specific, in the VGG Network, we divides the network into 5 chucks and apply the Top-K layer after each MaxPooling layer. Specifically, across a total of 31 feature layers in VGG, we apply the Top-K layer after the 5th, 10th, 17th, 23th, 31th original layers. In AlexNet, we also apply the Top-K layer after the MaxPooling except adding 2 additional Top-K layers at the 8th and 10th layer to make the sparse layer more evenly distributed. In the ResNet-18 training, we only apply the Top-K layer after the second layer to demonstrate the concept of sparse specialist code. We also apply the Top-K layer only in the 4th layer of the GAN generator as we observe empirically that it induces the best performance across other settings (such as applying multiple Top-K layers or the less severe sparsity). \n\n    Interestingly, our new experiments as shown in the Figure 1 in the general response indicates that ViT architectures seems to requires more dense activation, as we can observe that a moderate to high density (keep 50% - 80% of the original ranking neurons) yield the best performance for most of the classes (best mean shape score is achieved by keeping 60% of the original activation).\n\n- Difference in  Figure 6(b): We apologize for the confusion. Ours 1 and Ours 2 are from the same setting. We add more specification and synthesis examples in the camera ready version. \n\n- Redundancy in the network (Please see the general response).\n\n'}}, {'rebuttal': {'value': ""We appreciate the reviewers’ kind responses and constructive comments. In the following, we provide further experiments to support our paper. \n\nFirst, we generalize section 4.2 to ResNet-50 and ViT-B architectures. The results are documented in Figure 1 of the general response. The ResNet-50’s sparsity definition is the same as AlexNet and VGG. For ViT-B, we reshape the activation response from [n, h * w, d] to [n, d, h * w]  and apply the Top-K selection over dimension 2 before the activation is passed through the multiple head attention (Note that h and w is the height and weight of the latent tensor after reshape it to 2d, for ViT-B with patch size 16 on the 224x224 images, h=w=14). Please refer to our updated code for precise implementation. We observe that the similar shape bias gain from applying Top-K operation to ResNet-50 and ViT-B although ViT-B needs denser activation compared to the ConvNets.\n\nWe further add experiments for 4.3. Specifically, we add experimental results (2), (3) and (5) as highlighted in blue color. We first test how the model behaves when we apply Top-K operation on Non-Top-K trained models as Reviewer ZUQs points out. As the choice of hyper-parameter K in the proposed Top-K operation is critical to the model's performance, we apply the same Top-K parameter setting for (2) and (4). It can be observed that inference with Top-K with sub-optimal setting (2) would sometimes induce performance deficit but the models' performance will improve when applying the same Top-K sparsity during training (3). Second, we test the hypothesis that whether other soft sparsity constraints like L1 regularization would have the same effect (as suggested by Reviewer oHBy). We introduce a L1 term $ + \\lambda || \\texttt{NeuroActivation} ||_{1}$ during training (we tried $\\lambda$ choice of $\\{10, 1, 0.1\\}$ and found $\\lambda=1$ works the best.) and provide its results in (5). We can observe that (5) has similar performance as trained with Top-K layers (4), suggesting that L1 regularization induced sparsity could also help for improve the out-of-domain generalization of the model.\n\nNext, we investigate the internal activation when applying Top-K during training. In General Response Figure 2(a), we find that the Top-K training would lead to “dead neurons”, i.e. the neurons that will not be used across 100k inputs. We produce this plot by logging the frequency of the times each neuron is used. Specifically, we take the GAN generator trained in Section 4.4 and pass 100k random noise from the standard normal distribution. As the network is trained to map the noise to a real image (jeep class), we analyze the activation tensor inside the Top-K layer. We consider each neuron to be used once if it’s inside the Top-K selection. We normalize this utilization number by 100k and get the utilization frequency for each neuron. We can see that 15% of neurons are alive and the rest doesn’t respond at all. Therefore we can understand our proposed method as an implicit regularization to reduce the model size. \n\nFinally, we also provide analysis between the trade-off between shape bias gain and the classification accuracy sacrifice (General Response Figure 2(b)). We vary the number layers we install Top-K during inference on the AlexNet and evaluate the mean shape score as Figure3 in the main text and the normal classification accuracy. We can observe that there is a sweet spot that can balance the shape bias score and the classification accuracy. Combining with the experiments from general response Table1 (2) and (4), where Top-K training could increase both classification accuracy and the shape bias score, we recommend training or fine tuning with Top-K to obtain improvement on both classification accuracy and the shape bias robustness. \n""}, 'pdf': {'value': '/pdf/f7a4fa0fd362d744b7e58f2d10f9a987d12a6b32.pdf'}}, {'summary': {'value': 'This paper proposes enforcing sparsity within a neural network through a top-K mechanism and demonstrates that this leads in an emergent fashion an emphasis on shape rather texture in the learned representations of the network. This in turn leads to improvements in robustness for network behaviour.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- The paper is clearly written and laid out.\n\n- The paper presents a novel and innovative contribution to a challenging goal in deep learning (namely, shifting neural networks more toward shape representations rather than texture representations). Although this topic has been studied before, as the paper points out existing methods to achieve this have significant drawbacks (such as the practicality of style-transfer augmentations), whereas the method proposed in this paper is extremely practical to implement.\n\n- The use of multiple different styles of experimental methods helps round out the conclusions (for example, Section 4.1 is a relatively straightforward qualitative experiment that is nevertheless compelling, naturally leading to the more comprehensive later experiments.\n\n- '}, 'weaknesses': {'value': ""- I found it wasn't always clear whether Top-K was being applied to all layers or a subset of layers. Section 4.4 explicitly mentions that Top-K was used only in the fourth layer; why this layer, and how was this determined?""}, 'questions': {'value': '- In Figure 6(b) is there a difference between Ours 1 and Ours 2, or is that simply two different examples of output?\n\n- Does the use of a top-K mechanism lead to some of the network essentially becoming redundant (i.e. always ignored) and wasted computation?'}, 'limitations': {'value': 'The paper does not have any obvious limitations that were not discussed.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'Current deep learning models are known to have more texture bias for object recognition tasks while humans have more shape bias. They test the hypothesis that sparse coding may improve shape bias in deep learning models. Using Top-K operations, they show improved accuracy in pre-trained vison models as well as improved shape bias in models trained from scratch. Furthermore, in few-shot image systhesis tasks, models with sparsity constraints result in more structurally coherent images. The Top-K operations may be imposing binary masking on object parts, which can induce shape bias. \n\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- Connecting sparsity with shape bias is novel.\n- The authors examine both classification and generative models based on the sparsity operations.\n- Their study has implicaitons in both building computational models and understanding human vision. Their empirical results suggest that sparsity can lead to improved shape bias, making the models potentially make judgments closer to humans. Conversely, their study suggests sparse encodings may play a role in inducing shape bias in human vision. \n- Presentation is clear with helpful figures. I enjoyed reading it.  \n\n'}, 'weaknesses': {'value': '- Section 4.1: Additional comparisons with Ts w. Top-K only will be useful. It is unclear whether less structural information in TS w. Non Top-K is just due to a lack of representational power.  \n- Section 4.2: As noted in line 160, Vision Transformers show improved shape bias. How would you apply Top-K operations to Vision Transformers and do you expect to obtain more shape bias for those models? Since they are a popular model family, I think it\'s worth adding experiments or adding notes on them.\n- Section 4.3: Does the Top-K training lead to many dead neurons, essentially reducing the network size, which would work as an implicit regularization? \n- Section 4.5:  The idea suggested here seems related to models developed with topographic constraints (Margalit et al., 2023), where spatially smooth response patterns are learned. Comments on these models will be useful.\n- Section 4.6: The discussion here implies that an ideal sparsity rate may be different for each layer. Applying different K values depending on layer depth or not applying sparsity to some layers in the experiments (e.g. Figure 3) will be interesting to test the hypothesis further.\n- While I do think the study suggests an interesting perspective on shape bias using sparsity, the study may have less impact if models trained on larger datasets show more shape bias. For instance, in Figure 3, I wonder ConvNexts or ViTs trained on LAION-2B would give a stronger baseline.       \n\n\nMinor comments\n- Line 53 (""indeed can indeed introduce""): indeed is repeated\n- Line 161 (""already can already induced""): already is repeated\n- Figure 4: I assumed it indicates humans, but the label for purple markers is missing. \n   \n\n'}, 'questions': {'value': '- Section 4.2: How does the number of correct recognitions change when sparsity is imposed on the models? Are we sacrificing accrucy a lot for better shape bias?\n- Figure 3: For the boxplots, please explain the distribution, whether it is over multiple image categories or multiple seeds for applying sparsity, etc. \n'}, 'limitations': {'value': 'Currently, the study tested only convolutional architectures. Otherwise, limitations are adequately addressed. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper proposes to use activation sparsity induced by the top-k operation to address the recently identified hard problem in DNNs, the texture bias. The operation is simple yet highly effective, as it shows good structural encoding capability (Sec 4.1), shape bias (even without training, Sec 4.2) and parts/subparts learning dynamics (Sec 4.5). Finally the operation (with training) is validated with tasks including style robustness (ResNet-18, Sec 4.3) and few-shot image synthesis (FastGAN, Sec 4.4) on ImageNet subsets, where it also shows promising results.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '+ [Originality] The paper is sufficiently novel in my opinion. Although the idea of top-k sparsity has been commonly used in various applications (training/inference acceleration, brain-inspired algorithms, etc.), the fact that the simple idea works for this new, challenging topic should be interesting to the community.\n+ [Clarity] The paper is clear and easy to follow. The effort to clearly explain the motivations (e.g. Sec 4.4) and results (e.g. Sec 4.5) of the experiments is relatively noteworthy.\n+ [Quality] The paper is overall of good quality in my opinion. The proposed method is well motivated, simple and effective. The evaluation, though purely empirical, is relatively comprehensive and promising.\n+ [Significance] Given the simplicity and effectiveness of the proposed method, and the relevance of the topic, I think this work is significant and could be valuable to many in the community.'}, 'weaknesses': {'value': '- [Evaluation, Minor] To further improve the impact of the paper, the authors could consider improving the following aspects.\n1) Fig 2 and A.1 are both valuable yet limited. The authors could consider including larger-scale experiments/visualization and quantitative analysis of the results (e.g. textureness [38]).\n2) The authors could consider including experiments combining with existing solutions (e.g. data augmentation based, given the orthogonality) on the benchmark [10, 39] to demonstrate this work’s potential to further boost performance, including on ViT-based architectures.\n\n[38] The Synthesizability of Texture Examples, CVPR, 2014.\\\n[39] https://github.com/bethgelab/model-vs-human/'}, 'questions': {'value': '1) Does the value of non-top-k units (now set to 0 in Eq 1) affect the experimental results (e.g. by overly shifting the mean or other statistics)? Shouldn’t some form of corrective offset (or learnable value other than 0) be applied?\n2) How does the top-k without training performance compare to others in Table 1?\n3) What do the colors mean in Fig 7? '}, 'limitations': {'value': 'The proposed method itself doesn’t seem to have serious limitations as far as I can tell. However, the limitations of the standard protocols & datasets [10] currently used to analyze the results could be discussed in the paper.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work is motivated by the observation that deep neural networks may have a bias towards texture in classification decisions. The paper proposes a top-k sparsity selection process that is shown to result in emergence of shape sensitive neurons while improving performance across a variety of tasks.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. The demonstration that shape encoding occurs when the proposed sparsification is applied even in the absence of training is an important result and contribution.\n2. The paper demonstrates the value of this operation across a variety of tasks from recognition to synthesis and connections to neuroscience.\n3. The paper is generally well presented and gives a variety of examples that present a strong case for the claims made.'}, 'weaknesses': {'value': '1. There are some editorial changes that would benefit the paper (e.g. which numbers are bold in tables, when is SD bold etc.) and some places in the text where the description could be refined.\n2. It would be nice to see something like figure 4 for the ResNet variants given their importance in the literature\n3. Some references might be added (e.g. Md Amirul Islam, Matthew Kowal, Patrick Esser, Sen Jia, Björn Ommer, Konstantinos G. Derpanis, Neil D. B. Bruce, Shape or Texture: Understanding Discriminative Features in CNNs, ICLR, 2021.)'}, 'questions': {'value': ""1. How does the rank based selection for sparsity compare with 'softer' methods for inducing sparsity (e.g. L1 regularization)?\n\n2. Is there any means of knowing the proper value for the k hyperparameter?""}, 'limitations': {'value': 'The authors are clear about limitations of the work.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Emergence of Shape Bias in Convolutional Neural Networks through Activation Sparsity'}, 'authors': {'value': ['Tianqin Li', 'Ziqi Wen', 'Yangfan Li', 'Tai Sing Lee']}, 'authorids': {'value': ['~Tianqin_Li2', '~Ziqi_Wen2', '~Yangfan_Li2', '~Tai_Sing_Lee1']}, 'keywords': {'value': ['neuroscience', 'computer vision', 'shape & texture bias']}, 'TLDR': {'value': 'This study demonstrates that shape bias can emerge through the principle of efficient coding, paving the way for more human-like visual perception in CNNs.'}, 'abstract': {'value': 'Current deep-learning models for object recognition are known to be heavily biased toward texture. In contrast, human visual systems are known to be biased toward shape and structure. What could be the design principles in human visual systems that led to this difference? How could we introduce more shape bias into the deep learning models? In this paper, we report that sparse coding, a ubiquitous principle in the brain,  can in itself introduce shape bias into the network. We found that enforcing the sparse coding constraint using a non-differential Top-K operation  can lead to the emergence of structural encoding in neurons in convolutional neural networks,  resulting in a smooth decomposition of objects into parts and subparts and endowing the networks with shape bias.  We demonstrated this emergence of shape bias and its functional benefits for different network structures with various datasets. For object recognition convolutional neural networks, the shape bias leads to greater robustness against style and pattern change distraction. For the image synthesis generative adversary networks,  the emerged shape bias leads to more coherent and decomposable structures in the synthesized images. Ablation studies suggest that sparse codes tend to encode structures, whereas the more distributed codes tend to favor texture. Our code is host at the github repository: https://topk-shape-bias.github.io/'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/3ac6308ceb6db5c4c21860c34bc6cf10aa901d9a.pdf'}, 'supplementary_material': {'value': '/attachment/4b4991e7a1e1408e5020d1c22373a1bfbc5db1b8.pdf'}, '_bibtex': {'value': '@inproceedings{\nli2023emergence,\ntitle={Emergence of Shape Bias in Convolutional Neural Networks through Activation Sparsity},\nauthor={Tianqin Li and Ziqi Wen and Yangfan Li and Tai Sing Lee},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=QzcZb3fWmW}\n}'}, 'paperhash': {'value': 'li|emergence_of_shape_bias_in_convolutional_neural_networks_through_activation_sparsity'}}]"
"['Badih Ghazi', 'Pritish Kamath', 'Ravi Kumar', 'Pasin Manurangsi', 'Raghu Meka', 'Chiyuan Zhang']",NeurIPS,User-Level Differential Privacy With Few Examples Per User,https://neurips.cc/virtual/2023/oral/73854,2023," Previous work on user-level differential privacy (DP) [Ghazi et al. NeurIPS 2021, Bun et al. STOC 2023] obtained generic algorithms that work for various learning tasks. However, their focus was on the *example-rich* regime, where the users have so many examples that each user could themselves solve the problem. In this work we consider the *example-scarce* regime, where each user has only a few examples, and obtain the following results:* For approximate-DP, we give a generic transformation of any item-level DP algorithm to a user-level DP algorithm. Roughly speaking, the latter gives a (multiplicative) savings of $O_{\varepsilon,\delta}(\sqrt{m})$ in terms of the number of users required for achieving the same utility, where $m$ is the number of examples per user. This algorithm, while recovering most known bounds for specific problems, also gives new bounds, e.g., for PAC learning. * For pure-DP, we present a simple technique for adapting the exponential mechanism [McSherry & Talwar, FOCS 2007] to the user-level setting. This gives new bounds for a variety of tasks, such as private PAC learning, hypothesis selection, and distribution learning. For some of these problems, we show that our bounds are near-optimal.",Oral 2D Privacy,https://openreview.net/pdf?id=PITeSdYQkv,https://openreview.net/forum?id=PITeSdYQkv,PITeSdYQkv,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper gives a generic conversion for any N-sample item-level approx DP algorithm to a user-level approx DP algorithm where each user has m samples. Prior work with such a general conversion required each user having N^2 samples making it practically meaningless and useful bounds were known only for several specific problems. This paper applies to any number m and requires $\\tilde O(n/\\sqrt{m})$ users. This significantly extends our understanding of the relationship of sample complexity of item level and user level DP algorithm. An additional transformation for algorithms based on the exponential mechanism is given. Along the way the paper derives a number of other interesting results such as a strong connection between so called perfect generalization and DP. The main limitation of the work is that the transformation does not lead to efficient algorithms (even if applied to an efficient algorithm).'}}, {'comment': {'value': 'Thank you for the response!'}}, {'comment': {'value': 'Thank you for pointing this out. Yes, you are absolutely correct and really sorry for the confusion caused by our rebuttal. We will make sure that this is very clear in the revision.\n\nNevertheless, we would like to stress that the approach in [BBH+23] does not seem to be able to prove a similar statement as our main theorem (Theorem 9). The reason in that their compilation to achieve PG or DP (Algorithm 2) requires the entire algorithm to be replicable. This is not necessarily possible, especially in the regime where $m \\ll n$--i.e. ""few examples per user"".'}}, {'comment': {'value': 'Note: Please disregard the ""the parameters of two approaches ..."" paragraph in our rebuttal above. As pointed out by reviewer pUZs, the two approaches actually give similar parameters. We stress that the first paragraph (""The main distinction ..."") still holds.'}}, {'comment': {'value': ""Thank you for the additional clarifications.\n\n> We also wish to note that their reduction loses a roughly square factor in the sample complexity. That is, if we start with a DP algorithm with sample complexity $n$, then applying the reduction from [BBH+23] will result in a perfect generalization algorithm with sample complexity \n $\\approx n^2$ (for the same utility guarantee). On the other hand, we do not incur such a loss, since we prove the property directly on the original algorithm.\n\nAssuming you're referring to BGHILPSS'23, I believe that both papers achieve roughly the same quantitative parameters. Combining Corollary 3.18 with Theorem 3.19 from the arXiv version of their paper (https://arxiv.org/pdf/2303.12921.pdf) roughly shows that a $(1/\\sqrt{m}, \\delta)$-DP algorithm using $m$ samples can be converted to a $(\\delta, \\varepsilon, \\delta)$-PG algorithm using $m/\\varepsilon^2$ samples. This reflects the same $\\sqrt{m}$-factor blowup in parameters that one gets by going from DP to PG as appears in your work. The quadratic sample complexity blowup described in your comment follows by taking an $(\\varepsilon, \\delta)$-DP using $n$ samples, applying privacy amplification by subsampling to turn it into a $(1/\\sqrt{m}, \\delta)$-DP algorithm using $m \\approx \\varepsilon^2 n^2$ samples, and then applying the above transformation to get a $(\\delta, \\varepsilon, \\delta)$-PG algorithm using $\\approx n^2$ samples. Similarly applying privacy amplification by subsampling to your Theorem 34 would also incur a quadratic sample complexity blowup when going from a $(\\varepsilon, \\delta)$-DP algorithm to a $(\\delta, \\varepsilon, \\delta)$-PG algorithm.\n\nI'd be happy to be corrected if I've missed something or if you were referring to a different set of parameters!""}}, {'comment': {'value': 'Thank you very much for the response!'}}, {'rebuttal': {'value': 'Thank you for your review and questions. Thank you also for pointing out the typos. We will fix them in the revision. Please find our answers below.\n\n## Re $\\\\sqrt{m}$ lower bound:\n\n\nInterestingly, such a lower bound does not necessarily hold for all problems, even natural ones. For example, taking the class of all functions on $\\\\mathcal{X} = [d]$, our pure-DP upper bound (Theorem 3) is in fact better than our approximate-DP upper bound (Corollary 2) for the following regime of parameters: $\\\\epsilon=1,\\\\alpha=1/m, m \\\\leq d$, which gives $O(d)$ vs $\\\\tilde{O}(d\\\\sqrt{m})$. Thus, the $\\\\sqrt{m}$ lower bound does not hold in this setting. We will add more discussion on this in the revision.\n\n## Re Privacy Parameters in Theorem 16:\n\n\nThe $\\\\epsilon’, \\\\delta’, \\\\epsilon’ r \\\\sqrt{m \\\\log(n/\\\\beta\\\\delta’)}$ values here only have to be smaller than some absolute constant independent of the other parameters. \n\n\n'}}, {'rebuttal': {'value': 'Thank you for your review and questions. Please find our answers below.\n\n## Re [BBH+23]:\nThe main distinction between the two results is that we show that if an algorithm satisfies DP, then that very same algorithm also satisfies PG. On the other hand, [BBH+23] shows that if an algorithm satisfies DP, then there is *a different algorithm* that satisfies PG and maintains a similar utility guarantee.\n\n\nThe parameters of the two approaches are different. In [BBH+23], the reduction loses a roughly square factor in the sample complexity. That is, if we start with a DP algorithm with sample complexity $n$, then applying the reduction from [BBH+23] will result in a PG algorithm with sample complexity $\\\\approx n^2$ (for the same utility guarantee). On the other hand, we do not incur such a loss, since we prove the property directly on the original algorithm.\n\n## Re computational inefficiency:\n\nWe agree that this is a great question and we had included it in our conclusions as well (lines  347-353). We feel this is necessary for such a generic reduction; however, we do not have a formal proof of such a statement, as it is quite challenging (in general) to prove computational lower bounds for DP algorithms.\n'}}, {'rebuttal': {'value': 'Thank you for your detailed review and questions. Please find our answers below.\n\n## Re [BBH+23]:\nThank you for your suggestion. We will add this to the discussion. We also wish to note that their reduction loses a roughly square factor in the sample complexity. That is, if we start with a DP algorithm with sample complexity $n$, then applying the reduction from [BBH+23] will result in a perfect generalization algorithm with sample complexity $\\\\approx n^2$ (for the same utility guarantee). On the other hand, we do not incur such a loss, since we prove the property directly on the original algorithm.\n\n## Description vs formal proof of Lemma 13:\nWe think that the description still roughly reflects the full proof. Namely, while we do indeed use the one-sided perfect generalization result from [BBH+23], we are not aware of a proof using that directly without the aforementioned strengthened version of McDiarmid’s inequality. In particular, in our proof, we need Lemma 35 which is proved using Theorem 29; the latter is indeed the aforementioned result from [Kut02] mentioned in the outline. We will make sure to also mention the use of the one-sided result in the revision for clarity.\n\n## Local deletion DP:\n\nThank you for your suggestion. We will consider changing the name in the revision.\n'}}, {'rebuttal': {'value': 'Thank you for your detailed review and questions. Please find our answers below.\n\n## Re randomness: \nWe are in the standard setting in DP where we assume that the algorithm can sample fresh random coins and that these random coins are not accessible by the adversary.\n\n## Line 9 Algorithm 1: \nThis line of the algorithm is not required if we want just the privacy guarantee. However, we need it due to a technicality in our utility analysis: we need to make sure that in the “good” event, we run $\\mathbb{A}$ on a random subset of the input samples so that the distribution of the output is (almost) the same as running $\\mathbb{A}$ on i.i.d. samples from $\\mathcal{D}$.  (See the proof of Lemma 18 for more details.) \n\n## Pure-vs-Approximate DP: \nThe main challenge in using the approximate-DP approach for pure-DP is that the propose-test-release technique does not work for pure-DP. Namely, even if we know that the local (deletion) sensitivity of a function is very small up to a very large distance, it is still not possible to add a small noise and achieve pure-DP. (For pure-DP, we would need either a global bound or at least a bound that is “smooth” enough.)\n\nAt a higher level, the best sample complexity for pure-DP also often contains a privacy-dependent term that does not converge to zero as $m \\\\to \\\\infty$. (For example, the first term $d/\\\\epsilon$ in Theorem 3.) On the other hand, such a term does not appear in approximate-DP. Such a behavior suggests an inherent difference between the two settings. \n\n## Tightness: \n\nThis is a great question. We do not have a general characterization of the tightness of our results, although, as explained in the Introduction, our results are nearly tight for many problems (up to dependencies on $\\\\log(1/\\\\delta), \\\\epsilon$). Interestingly, however, the approximate-DP approach is *not* tight for PAC learning for some classes. For example, taking the class of all functions on $\\\\mathcal{X} = [d]$, our pure-DP upper bound (Theorem 3) is in fact better than our approximate-DP upper bound (Corollary 2) for some regime of parameters ($\\\\epsilon=1,\\\\alpha=1/m, m \\\\leq d$ gives $O(d)$ vs $\\\\tilde{O}(d\\sqrt{m})$). We will add more discussion on this in the revision.\n\n\nThank you for pointing out the typos; we will fix them in the revision.\n'}}, {'summary': {'value': 'This work develops novel generic algorithms that convert algorithms under item-level differential privacy (DP) to user-level DP in the low user sample regime, where each user holds a small number of samples, and obtains new results for user sample complexity (aka., min # users to achieve a certain utility of the algorithm). Based on a novel observation that connects sample perfect generalization to local deletion DP, the proposed algorithm under approximate-DP leads to tight user sample complexity bound for several privacy-preserving machine learning applications. The proposed algorithm under pure-DP is based on the exponential mechanism with a new score function and it also leads to tight and improved user sample complexity bounds for several applications.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The improved user sample complexity results and proposed algorithms under both approximate DP and pure DP are interesting and are widely applicable to several important privacy preserving machine learning tasks. \n\nThe paper is well presented and intriguing to read. The notations are well-defined throughout the paper. Problems and results are well defined and clearly stated. The contribution and overview of techniques are well summarized. \n\nThe paper tries hard to give the readers intuition on the techniques developed and does a good job explaining the observations.\n\nThe paper also explains well its difference from the previous works, especially why the techniques from previous works do not apply when the number of samples per user is low.\n'}, 'weaknesses': {'value': 'The only places that might need a bit more explanation is why local deletion DP is natural to consider based on sample perfect generalization results, and how local deletion DP is then converted to user level DP?'}, 'questions': {'value': 'This might be a stupid question. How is the randomness of the private algorithms considered in this work? Do we assume that a random seed is given?\n\nIs line 9 in Algorithm 1 for removing the polylog dependence on $n$ users in the proof?\n\nWhat are the major differences between pure DP and approximate DP in changing from item-level DP to user-level DP? What are the challenges that make the techniques to convert from item-level DP to user-level DP for approximate DP not applicable to pure DP?\n\nIn which applications/problems is the user sample complexity bound from this work not tight?\n\nMinor issues: $x_{1, n}$ in line 31 $\\Rightarrow$ $x_{1, m}$. \n\n$\\mathbf{x}_{T}$ in line 265 \n\n$\\Rightarrow$ $\\mathbf{x}_{-T}$. \n\nMight be clearer to add “for some chosen constant $\\kappa$” to the end of line 272. '}, 'limitations': {'value': 'Limitations (esp. the runtime of the proposed algorithm) are well discussed in the paper.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': ""This paper establishes new generic conversions from item-level DP algorithms to user-level DP algorithms, continuing a line of work initiated by Ghazi, Kumar, and Manurangsi. Previous state-of-the-art due to BGHILPSS '23 shows that any item-level $(\\varepsilon, \\delta)$-DP algorithm using N samples can be converted to a user-level DP algorithm with $n = O(\\log(1/\\delta)/\\varepsilon$ users and $m \\approx N^2$ samples per user. The present submission observes that this previous result is just one end of a spectrum of possible item-to-user-level conversions, and generalizes it to hold for the full range of $1 \\le m \\le N^2$. That is, the main result (somewhat simplifying) shows a conversion from any item-level DP algorithm to a user-level DP algorithm with $n \\approx (N/\\sqrt{m}) \\cdot \\log^{O(1)} ({1/\\delta})/\\varepsilon^2$ users and $m$ samples per user. In addition to generalizing the conversions of GKM'21 and BGHILPSS'23 to the regime of few examples per user, this result unifies previous work on specific problems such as mean estimation, stcochastic convex optimization, and discrete distribution learning for which a $n \\propto 1/\\sqrt{m}$ dependence was previously observed.\n\nAs an auxiliary result, the paper also gives a tight characterization of the sample complexity of user-level pure $(\\varepsilon, 0)$-differentially private PAC learning in terms of the probabilistic representation dimension.""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""- This is a nice contribution to the emerging general theory around user-level DP learning, in particular, building a bridge between one thread of work on general item-level vs. user-level connections and another on understanding the sample complexity of user-level DP for specific problems.\n\n- As part of their analysis, the authors more carefully investigate the connection between DP and perfect generalization, in particular giving a clean solution to an old open question of CNLRW'16 that is likely to have further applications.""}, 'weaknesses': {'value': ""- The main technical ideas going into the algorithms and their analysis appeared in prior work on this topic. (E.g., the passage from DP to perfect generalization appears in GKM'21/BGHILPSS'23, and a similar PTR-based argument appeared in KL'21/GKKMMZ'23). This paper's technical contribution is to carefully refine each of these steps and piece them together in the right way.\n\n- Neither of the paper's new algorithms is computationally efficient in general, even if the task admits a computationally efficient item-level DP learner. Note that this is the case for previous general item-to-user-level conversions as well.\n\n- The final main result (Theorem 9) is somewhat messy to state and potentially suboptimal in its dependence on $\\log(1/\\delta)$ and $\\varepsilon$. This is likely in part due to stacking various generic tools (DP => PG, amplification by subsampling, PTR) that could potentially be avoided with a simpler algorithm.""}, 'questions': {'value': '- The prior work of BBGHLISS\'23 also claims to have resolved the open question of CLNRW\'16 on DP vs. perfect generalization, but I believe they did so in a weaker sense. Namely, they only showed that every DP algorithm admits a PG algorithm solving the same problem; whereas this submission shows that the original DP algorithm itself perfectly generalizes. This is an important distinction that I think is worth highlighting.\n\n- I wasn\'t really able to match the informal description of the proof of Lemma 13 (lines 214-226) to the formal proof in appendix B. In particular, the new contribution of the formal proof seems to be to apply a nice symmetrization argument to the previous results of RRST\'16/BGHILPSS\'23 that held for a one-sided version of the DP -> PG connection. Does the informal argument in the main body of the text reflect what\'s going on under the hood of these prior results? And if so, does it suggest a simpler / more direct argument that doesn\'t go through max-information etc.?\n\n- I\'d suggest renaming ""local deletion DP"" (Definition 15) to something else due to the (unfortunate) naming collision that may suggest this definition has to do with local DP. Maybe something like ""pointwise deletion DP""?'}, 'limitations': {'value': 'Limitations (overlapping with points identified as weaknesses) are nicely described as directions for future work in the conclusion.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper studies the problem of user-level differential privacy, giving a generic conversion for any item-level approx DP algorithm to a user-level approx DP algorithm, and a clipped scoring function that allows application of the exponential mechanism to obtain user-level privacy. All results are applicable in the few-samples-per-user setting, significantly extending results beyond the case in which users have enough samples to solve a task independently. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""This work significantly improves our understanding of when user-level privacy is achievable, though it is unfortunate the transformation from item-level to user-level privacy isn't computationally efficient. The intermediate result that approx DP => sample perfect generalization is also a meaningful contribution to our understanding of the relationships between useful algorithmic stability notions. \n\n""}, 'weaknesses': {'value': 'In terms of substance, I think this work is very strong, but the clarity of presentation could maybe be improved a little. That said, I do think the authors did a good job overall of assisting the reader with interpretation of their results. \n\nNotes:\n\nThe first paragraph of the technical overview for the approximate DP result was a bit confusing.\n\nPage 4: “it is sufficient get new user-level pure-DP”\n\nPage 6: \t“For example, g is not Lipschitz everywhere anyway anymore”\n\n\n'}, 'questions': {'value': ""There's a related result from BGHILPSS23 showing that approx DP implies perfect generalization, following from the connections approx DP => one-way perfect generalization, one-way perfect generalization => replicability, replicability => perfect generalization. However, my understanding is that their result is weaker than the one given in this work because it 1) requires correlated sampling and is therefore not necessarily computationally efficient and 2) the transformation from replicability to perfect generalization changes the output distribution of the DP algorithm, whereas the result in this work proves perfect generalization for the same approx DP algorithm A. Is this a correct comparison of these results, or is there any notable distinction between the resulting PG parameters obtained from both results?\n\nIt would be very interesting to understand whether the computational inefficiency is in fact necessary. ""}, 'limitations': {'value': 'Yes, the authors adequately address societal impact of their work. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work designs a generic algorithm that transforms an item-level DP algorithm into a user-level DP one with $\\sqrt{m}$ improvement in user complexity. It recovers previous user complexity bounds on various learning tasks, and the transformation works in the example sparse setting, i.e. does not require sufficient number of samples per user.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '1. Compared to Ghazi et.al. 2021 which requires sufficient number of samples per user, the generic transformation from item-level to user-level DP in this work applies to the example scarce setting. The authors derive new bounds in the example-scarce setting for PAC learning.\n2. The authors recover the $\\sqrt{m}$ factor in many known bounds for various learning tasks through a generic algorithm. \n3. The writing is clear and easy to follow.'}, 'weaknesses': {'value': ""1. The proposed algorithm is not computationally efficient.\n2. Although $\\sqrt{m}$ matches the tight bounds for a variety of problems, it seems that the lower bound is not addressed in this work.\n3. In Theorem 16, it might be helpful to be specific about how sufficiently small should $\\varepsilon', \\delta'$ be. \n\nMinor issues:\n1. In Lemma 4, I feel that it should be $A\\simeq C$ instead of $B$ at the end of the line.\n2. In line 242, it appears that the $\\delta'$ inside the big O should be $\\delta''$, and there should be a factor of $(1+e^{\\varepsilon''})$ for the $\\delta''$ term according to Lemma 4 (even though it does not affect the final bound on $\\delta'$).\n""}, 'questions': {'value': ""1.  I wonder if it is possible show a $\\Omega(\\sqrt{m})$ lower bound as well under some non-trivial conditions?\n2.  In Theorem 16, how sufficiently small are $\\varepsilon', \\delta'$? Is it for some fixed small constant, or some expression that depends on other parameters?""}, 'limitations': {'value': 'Limitations and potential impacts are adequately addressed.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'User-Level Differential Privacy With Few Examples Per User'}, 'authors': {'value': ['Badih Ghazi', 'Pritish Kamath', 'Ravi Kumar', 'Pasin Manurangsi', 'Raghu Meka', 'Chiyuan Zhang']}, 'authorids': {'value': ['~Badih_Ghazi1', '~Pritish_Kamath2', '~Ravi_Kumar1', '~Pasin_Manurangsi2', '~Raghu_Meka1', '~Chiyuan_Zhang1']}, 'keywords': {'value': ['differential privacy', 'user-level privacy', 'PAC learning']}, 'abstract': {'value': 'Previous work on user-level differential privacy (DP) [Ghazi et al. NeurIPS 2021, Bun et al. STOC 2023] obtained generic algorithms that work for various learning tasks. However, their focus was on the *example-rich* regime, where the users have so many examples that each user could themselves solve the problem. In this work we consider the *example-scarce* regime, where each user has only a few examples, and obtain the following results:\n* For approximate-DP, we give a generic transformation of any item-level DP algorithm to a user-level DP algorithm. Roughly speaking, the latter gives a (multiplicative) savings of $O_{\\varepsilon,\\delta}(\\sqrt{m})$ in terms of the number of users required for achieving the same utility, where $m$ is the number of examples per user. This algorithm, while recovering most known bounds for specific problems, also gives new bounds, e.g., for PAC learning. \n* For pure-DP, we present a simple technique for adapting the exponential mechanism [McSherry & Talwar, FOCS 2007] to the user-level setting. This gives new bounds for a variety of tasks, such as private PAC learning, hypothesis selection, and distribution learning. For some of these problems, we show that our bounds are near-optimal.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/3b94a69b2f79f80083b0fd496be78b7836bc2897.pdf'}, '_bibtex': {'value': '@inproceedings{\nghazi2023userlevel,\ntitle={User-Level Differential Privacy With Few Examples Per User},\nauthor={Badih Ghazi and Pritish Kamath and Ravi Kumar and Pasin Manurangsi and Raghu Meka and Chiyuan Zhang},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=PITeSdYQkv}\n}'}, 'TLDR': {'value': 'We give a generic transformation of any item-level DP algorithm to a user-level DP algorithm, that holds even when each user has only a few examples.'}, 'paperhash': {'value': 'ghazi|userlevel_differential_privacy_with_few_examples_per_user'}}]"
"['Adrián Javaloy', 'Pablo Sanchez-Martin', 'Isabel Valera']",NeurIPS,Causal normalizing flows_ from theory to practice,https://neurips.cc/virtual/2023/oral/73851,2023," In this work, we deepen on the use of normalizing flows for causal reasoning. Specifically, we first leverage recent results on non-linear ICA to show that causal models are identifiable from observational data given a causal ordering, and thus can be recovered using autoregressive normalizing flows (NFs). Second, we analyze different design and learning choices for causal normalizing flows to capture the underlying causal data-generating process. Third, we describe how to implement the do-operator in causal NFs, and thus, how to answer interventional and counterfactual questions. Finally, in our experiments, we validate our design and training choices through a comprehensive ablation study; compare causal NFs to other approaches for approximating causal models; and empirically demonstrate that causal NFs can be used to address real-world problems—where the presence of mixed discrete-continuous data and partial knowledge on the causal graph is the norm. The code for this work can be found at https://github.com/psanch21/causal-flows.",Oral 2C Causality,https://openreview.net/pdf?id=QIFoCI7ca1,https://openreview.net/forum?id=QIFoCI7ca1,QIFoCI7ca1,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This work explores the use of normalizing flows in causal inference. Assuming that data has been generated from a causal model and we know the causal graph as well as the causal ordering, the paper presents causal NFs and shows how to implement the do-operator in causal normalzing flows. This is a timely topic, and all reviewers suggest to accept the paper. I fulls support this.'}}, {'comment': {'value': 'Thanks authors for the informative reply. Indeed, the Figures 12, 13, and 15 from the appendix show what I would have liked to see in the main text (or a version of it), such that the effect of the interventions is visualized.\n\nAs for codebase ect. there was a technical issue on my side which omitted those from me. So contrary to my previous assessment, these resources are indeed provided and good. \n\nWith ""analysis implementation"" I intended the scripts in which you perform your analysis. These are provided in your supplementary material as well.\n\nConsidering the information about the reproducibility of this work, I would like to raise my score to strong accept.'}}, {'comment': {'value': 'We would like to thank the reviewer for reading our rebuttal and for the kind words, we _truly_ appreciate them. '}}, {'comment': {'value': 'We thank the reviewer for reading our rebuttal and updating their score accordingly. If there is anything else we could help with during the rebuttal, we will be happy to do so.'}}, {'comment': {'value': 'We are very thankful to the reviewer for their invested effort to revisit all the discussion about our paper and for the positive feedback. '}}, {'title': {'value': 'Clear accept'}, 'comment': {'value': 'Having carefully read all the discussions, I decided to elevate my rating to a clear acceptance (7).'}}, {'title': {'value': 'Response to rebuttal'}, 'comment': {'value': 'I thank the authors for their response. With their clarifications, I upgraded my score.'}}, {'title': {'value': 'Re: rebuttal'}, 'comment': {'value': 'Many thanks to the authors for their comments and clarifications. I still believe my original score of 7 is fair and will keep it as such. Great work on this paper!'}}, {'title': {'value': 'response to authors'}, 'comment': {'value': 'Thank you for the detailed responses. \n\n'}}, {'rebuttal': {'value': 'We thank the reviewer for their valuable comments and for the supportive words. Please see our comments to the reviewer’s comments below:\n\n> I’m unsure how to interpret $\\sum_{n=1}^\\infty G^n$ . Why the infinite sum? The examples in Fig. 4 all appear finite?\n\nThe short and honest answer is that the infinite is there to save space. Since $G$ is acyclic, that sum is always finite as $G^n$ becomes $0$ for $n > \\operatorname{diam}(G)$, but we did not need to define any notation for the diameter of the graph anywhere else. However, we agree that it can be confusing to the reader, and we will rewrite it as a finite sum with $\\operatorname{diam}(G)$ terms in the next revision of the manuscript.\n\n> It appears that the empirical evaluation only considers causal chains. What about more complicated/realistic causal structures?\n\nWe only consider causal chains for the ablation study shown in the main paper, as using causal chains is easy to understand and sufficient to verify the claims we make in Section 4 with respect to the network design. Yet, we do consider more complex SCMs (in terms of causal graphs and structural equations) in Section 6 and Appendix D.4 (see Figure 9 for a reference on the considered graphs). Moreover,   the use-case in Section 7 shows a more realistic scenario with mixed-type data, and a partial causal graph (see Figure 14).\n\n> If I understand Fig. 5 correctly […] This echoes the results summarized in Table 1: Why should a model do better with a causal ordering than it does with the entire graph? Surely the latter is strictly more informative?\n\nIndeed, Figure 5 echoes Table 1. The goal of the ablation study in Section 6.1 is to empirically corroborate the theoretical findings summarized in Table 1 (e.g., that the generative model with the graph needs as many layers as the graph diameter), as well as to motivate the necessity of a network that is causally consistent by design. Since our theory only requires a causal ordering (Section 3), one could reasonably believe that any ANF would suffice, yet we empirically show that in practice we often fall on local optima with spurious correlations, and that a causally-consistent design effectively restricts the search space, easing the optimization process and, ultimately, yielding more accurate estimates of causal inference estimands.\n\nGiven the positive assessment of our paper by the reviewer and, in case we have successfully clarified the questions above, we would appreciate it if  they could consider upgrading the score to better reflect the contributions of our work. Please refer to the [general comment](https://openreview.net/forum?id=QIFoCI7ca1&noteId=3m1mexttyb) for a summary of said contributions.'}}, {'rebuttal': {'value': 'We thank the reviewer for their valuable feedback, detailed summary, and positive comments. Please see our comments regarding the raised weaknesses below:\n\n> The paper would benefit of an example of how a learned causal NF behaves, how the interventions influence the output, and how it matches an SCM.\n\nWe appreciate the comment, and we would appreciate more specific details on said example to properly address it during the rebuttal. To our understanding, the reviewer may be referring to something similar to the pair-plots we provide in Figures 12, 13, and 15 from the appendix, but we are happy to add other examples.\n\n> Consider pushing some of the information from the appendix to the main text. E.g.: …\n\nWe thank the reviewer for the specific feedback, and we will implement these changes in the updated manuscript.\n\n> Some background on TMI maps could be introduced.\n\nWe agree with the reviewer that more background on TMI maps can be helpful to the reader, and we will add it to the next revision of our work.\n\n> No resources such as codebase, trained models, and analysis implementation are provided.\n\nWe would like to point out that we provide the code to reproduce the experiments of our work with the submission, in the same zip file where the appendix was found. We did not consider necessary providing the model weights, given how quick they are to train and run in all our experiments. In addition, we will make all the code necessary to reproduce all our experiments publicly available with the publication of our paper. \n\nAs for the “analysis implementation”, we are unsure what the reviewer refers to exactly. Could the reviewer clarify, please? We could happily address any additional comments they may have. \n\nIn case we have successfully clarified the points raised by the reviewer, we would appreciate it if  they could consider upgrading the score of our paper accordingly. Please refer to the [general comment](https://openreview.net/forum?id=QIFoCI7ca1&noteId=3m1mexttyb) for a summary of the main contributions of our work.\n'}}, {'rebuttal': {'value': 'We thank the reviewer for their valuable comments, as well as the highly detailed summary of our work. Before commenting on the concerns raised by the reviewer, we would like to clarify a few points that may have been overlooked or misunderstood based on the review’s summary:\n\n> [Identifiable] means there is a unique product distribution and TMI maps given the observational dataset.\n\nThis definition would rather correspond to strong identifiability, which only occurs if the base distributions of the flow and SCM are the same. Otherwise, we obtain weak identifability, where the mapping is not unique, but differs on a component-wise transformation (Theorem 1), as depicted in Figure 3, which is sufficient to enable causal inference.  \n\n> … showing that CNFs perform better on a few SCM tasks.\n\nBased on the “few” above, we are unsure whether this passed unnoticed, but we would like to remind that in Appendix D.4 we provide results for 12 different SCMs. We restricted this number to 3 in the main manuscript due to space constraints.\n\nNext, regarding the reviewer’s concerns:\n\n> Assuming knowledge of causal ordering is usually a very strong requirements in applications, since if we have the knowledge of causal ordering, we can use traditional nonlinear regression techniques, e.g. with spline functions, to learn the underlying SCMs.\n\nWe would like to highlight that we focus in our paper in causal inference, i.e., recovering the value of the exogenous variables to then obtain  estimates for interventional and counterfactual queries. For such tasks, and in contrast to causal discovery problems, it is indeed common to assume access to the causal graph in addition to observational data [[1](https://aaai.org/papers/08159-vaca-designing-variational-graph-autoencoders-for-causal-queries/), [2](http://arxiv.org/abs/2302.00860), [3](https://openreview.net/forum?id=vouQcZS8KfW), [4](https://proceedings.mlr.press/v177/sanchez22a.html), [5](http://arxiv.org/abs/2109.04173)], when no other assumptions are considered (e.g., access to interventional data [[6]](https://proceedings.mlr.press/v202/nasr-esfahany23a.html) or to auxiliary variables [[7]](https://proceedings.mlr.press/v108/khemakhem20a.html)).  Importantly, to the best of our understanding, traditional nonlinear regression techniques for causal inference iteratively  fit a  regressor (e.g., spline function) per node, conditioned on its parents. As a consequence, in addition to assume a known causal graph, parameters are not amortized and errors tend to propagate along causal paths (from root nodes to leave nodes). \n\nYet, as we acknowledge that access to the full causal graph may be restrictive in real-world applications, we provide an algorithm to group variables together if only partial knowledge on the causal ordering is available (the description in lines 171-178 are expanded in Appendix A.2.2).\n\n\n\n\n> The identifability results are not novel and therefore the thrust of this work is experimental.\n\nWe respectfully and strongly disagree with this comment by the reviewer. While we do adapt the theory from Xi and Bloem-Reddy [[8]](https://proceedings.mlr.press/v206/xi23a.html) to the problem of causal inference, we would like to stress that their work involves identifiability of latent variable models in an ICA framework, where there is **not any causal consideration.**  Our main contribution lies in the fact that by casting SCMs and ANFs as TMI maps, we can re-formulate a causal inference problem (i.e., recovering the true exogenous variables)  as a blind-source separation problem, and thus leverage their identifiability results. To the best of our knowledge, our work is the first to provide identifiability guarantees for such a broad family of SCMs (lines 110-113). For ease of exposition, we restated Proposition 5.2 from [[8]](https://proceedings.mlr.press/v206/xi23a.html) to match our setting, which may lead to confusions. We will make this more clear in the next revision of the manuscript.\n\nBesides the  aforementioned identifiability result, the characterization of causally-consistent ANF network designs, an efficient implementation of the do-operator suitable for causal NFs, as well as extensions to mixed-type data and partial causal graphs are also theoretical and novel contributions of our work. We make these points more precise in the [general comment](https://openreview.net/forum?id=QIFoCI7ca1&noteId=3m1mexttyb).\n\n\nWe hope to have addressed the main concerns, as well as clarified potential misunderstandings, raised by the reviewer, and thus would  appreciate it if the reviewer could consider upgrading the score of our paper accordingly. Please refer to the [general comment](https://openreview.net/forum?id=QIFoCI7ca1&noteId=3m1mexttyb) for a summary of the main contributions of our work, as well as for a summary of the changes planned for our paper. \n\n---\n\n[1] [VACA: Design of Variational Graph Autoencoders for Interventional and Counterfactual Queries](https://aaai.org/papers/08159-vaca-designing-variational-graph-autoencoders-for-causal-queries/)\n\n[2] [Interventional and Counterfactual Inference with Diffusion Models](http://arxiv.org/abs/2302.00860)\n\n[3] [Neural Causal Models for Counterfactual Identification and Estimation](https://openreview.net/forum?id=vouQcZS8KfW)\n\n[4] [Diffusion Causal Models for Counterfactual Estimation](https://proceedings.mlr.press/v177/sanchez22a.html)\n\n[5] [Relating Graph Neural Networks to Structural Causal Models](http://arxiv.org/abs/2109.04173)\n\n[6] [Counterfactual Identifiability of Bijective Causal Models](https://proceedings.mlr.press/v202/nasr-esfahany23a.html)\n\n[7] [Variational Autoencoders and Nonlinear ICA: A Unifying Framework](https://proceedings.mlr.press/v108/khemakhem20a.html)\n\n[8] [Indeterminacy in Generative Models: Characterization and Strong Identifiability](https://proceedings.mlr.press/v206/xi23a.html)\n'}}, {'rebuttal': {'value': 'We thank the reviewer for their positive comments, and we are flattered to know that the reviewer had a good time reading our work. While there are no specific questions, we would like to add a few clarifications below that we hope helps the reviewer better contextualize our work:\n\n> From my understanding, the previous work has already achieved satisfactory results regarding the identifability of causal normalizing flows.\n\nWe are unsure to which previous work the reviewer refers exactly:\n\n1. If the reviewer refers to the paper by Xi and Bloem-Reddy [[1]](https://proceedings.mlr.press/v206/xi23a.html), from which we adapt Theorem 1, note that their work involves identifiability of latent variable models in an ICA framework, where there is **no causal consideration.** Thus, our main contribution lies in the fact that by casting SCMs and ANFs as TMI maps, we can re-formulate causal inference (i.e., recovering the true exogenous variables)  as a blind-source separation problem, and thus leverage their identifiability results. To the best of our knowledge, our work is the first to provide identifiability guarantees for such a broad family of SCMs (lines 110-113). \n2. If the reviewer refers instead to the work that introduced CAREFL [[2]](http://proceedings.mlr.press/v130/khemakhem21a.html), there are a number of important differences worth pointing out:\n    1. The main focus of CAREFL is causal discovery (i.e., estimating the causal graph), while ours is performing causal inference (given a causal ordering/graph).  These are two related but different problems, each with their own challenges and applications.  Importantly, the main theoretical result of CAREFL regards only the bivariate case (each one being uni-dimensional) with Gaussian exogenous variables. \n    2. Their work assumes affine ANFs, while we allow for any type of ANF. For example, NSFs  [[3]](https://proceedings.neurips.cc/paper/2019/hash/7ac71d433f282034e088473244df8c02-Abstract.html) (which we use in the fairness use-case, Section 7) are non-affine ANFs.\n    3. In a similar note, they assume additive-noise SCMs, which is a subset of the bijective SCMs assumed in our work.\nThat said, we acknowledge that CAREFL indeed hints a connection between ANFs and SCMs, which in this work we: i) properly formalize, generalize, and make this connection precise; ii) provide general identifiability results; and iii) propose a network design to efficiently learn the underlying SCM.\n\n> I think this extension is relatively straightforward, and the challenge presented may not be substantial.\n\nWe respectfully disagree with the reviewer here. While we agree that the final design is straightforward (this is in our opinion a positive outcome of our work), the contributions and challenges should not be overlooked. Specifically, in addition to the novelty of our identifiability results (see our answer on relation to Xi and Bloem-Reddy [[1]](https://proceedings.mlr.press/v206/xi23a.html) above), we first show in Corollary 2  that causal consistency is a necessary condition at the global optima; and then, in Section 4, introduce the necessary conditions to design a  causally consistent ANF, which needs to: i) use the graph information, ii) have a single layer, and iii) be defined from $x$ to $u$. Any other of the possible considered networks will not be causally consistent by design, and thus may lead to poor estimates of interventional and counterfactual queries. Moreover, as acknowledged by reviewer azJz,  the proposed implementation of the do-operator is also non-trivial.\n\n\n> I recommend that the authors consider transferring some crucial conclusions from the supplementary material to the main paper.\n\nWe thank the reviewer for the suggestion, and we will make space to move important remarks back to the main manuscript. Reviewer azJz made a similar comment with specific content to add, and there may be some overlap. We have summarized the changes for the next revision in the [general comment](https://openreview.net/forum?id=QIFoCI7ca1&noteId=3m1mexttyb). If the reviewer has in mind specific parts of the Appendix to be moved to the main paper, please let us know so that we can also address them. \n\nWe would appreciate it if the reviewer could confirm if we have successfully addressed their main comments and thus could consider upgrading the score of our paper accordingly. Please refer to the [general comment](https://openreview.net/forum?id=QIFoCI7ca1&noteId=3m1mexttyb) for a summary of the main contributions of our work.\n\n---\n\n[1] [Indeterminacy in Generative Models: Characterization and Strong Identifiability](https://proceedings.mlr.press/v206/xi23a.html)\n\n[2] [Causal Autoregressive Flows](http://proceedings.mlr.press/v130/khemakhem21a.html)\n\n[3] [Neural Spline Flows](https://proceedings.neurips.cc/paper/2019/hash/7ac71d433f282034e088473244df8c02-Abstract.html)\n'}}, {'rebuttal': {'value': '\nWe thank the reviewer for their valuable feedback, which points out details that we will clarify in the updated manuscript. Please see our responses addressing the specific concerns below:\n\n> The number and characteristics of the given dataset are limited when compared to practical applications. \n\nWe would like to point out that we test our framework in 12 synthetic SCMs (Table 4, App. D.4), including diverse causal graphs with both linear and non-linear structural equations (see Figure 9 in App. D). In addition,  we also use a real-world dataset, the German Credit,  which contains mixed-type data and partial knowledge on the causal graph. Our empirical evaluation is on par, in terms of number and complexity of the considered SCMs, with the one in VACA [[1](https://aaai.org/papers/08159-vaca-designing-variational-graph-autoencoders-for-causal-queries/)], and we believe it is sufficient to show the validity of our theory motivating design choices for causal normalizing flows. We agree with the reviewer that there is an avenue of future works  applying the proposed  causal normalizing flows to many application domains, also involving large dimensional data. \n\n> The ablation analysis misses hyperparameter tuning.\n\nWe are unsure if we fully understand the reviewer comment, but we would like to clarify that the main goal of our ablation study is to validate the claims with respect to the network design in Section 4. Regarding hyperparameter tuning, we test the choice of base distribution for the flow in Appendix D.2, as well as the impact of choosing a different flow architecture in Appendix D.3. Additionally, we provide details on hyperparameter tuning for all experiments in App. D.\n\n > The authors should give the intuition of presenting Fig. 1 in a more clearly way.\n\nThanks for the feedback. We indeed were over-concise in our explanation, and will update it with the following: ""This is exemplified in Fig. 1, where our proposed framework is able to estimate the (unobserved) causal effect of externally intervening on the sensitive attribute $s$, using solely observed data (blue distribution) and partial information about the causal relationship between features.""\n\n> Is it limited to tabular data? Is it possible to use it with high-dimensional data? Any pre-processing steps are necessary?\n\nIn principle there is no limitation on the proposed causal normalizing flow that prevents us from applying it to high-dimensional data. That said, we would like to clarify that our proposed method is tied to the current limitations of normalizing flows and to the extent to which we can define a (potentially partial) causal graph. For example, NFs have been applied in image processing, but to the best of our knowledge are not the state of the art, and at the same time it does not seem sensible to build a causal graph at the level of pixels. However, one could consider using an image as a node in our causal NF, for example in medical applications where the image (e.g., X-ray) is one more dimension in the patient (potentially causal) data.\n\n> It would be viable to learn the causal graph? Is there a necessity of domain knowledge to use the proposed method?\n\nWhile the focus of our paper is not causal discovery, we believe that our work could also be extended for causal discovery. For example, one idea would be to integrate the proposed causal NF into the DECI  framework [[2]](http://arxiv.org/abs/2202.02195), i.e., perform causal discovery by modelling the joint distribution of both the observed data and the causal graph as $P(G, X) = P(G) P(X|G)$, where the causal NF is used to fit $P(X|G)$. Note, however, that DECI only applies to structurally identifiable SCMs, specifically to continuous non-linear additive noise models (ANMs). In general, it is not possible to estimate a causal graph solely from observational data, and either domain knowledge or additional assumptions are needed.\n\n---\n\n[1] [VACA: Design of Variational Graph Autoencoders for Interventional and Counterfactual Queries](https://aaai.org/papers/08159-vaca-designing-variational-graph-autoencoders-for-causal-queries/)\n\n[2] [Deep End-to-end Causal Inference](http://arxiv.org/abs/2202.02195)\n'}}, {'rebuttal': {'value': ""We thank all the reviewers for their useful comments, which will ultimately help us improve the manuscript. We also want to thank them for their reassuring words towards our work. To name just a few, reviewers acknowledged our effort towards good writing and readability:\n> I thoroughly enjoyed reading this paper - Reviewer 515Z\n\n>  Figures 2-4 are very valuable for presentation and understanding - Reviewer azJz\n\nthe interdisciplinary character of our work:\n\n> This work is a nice interplay between these two frameworks - Reviewer yYim\n\nas well as its novelty and importance:\n\n> This is a strong contribution on an important topic - Reviewer p91A\n\nAdditionally, to help during the rebuttal, we would like this general response to serve as a summary of the contributions of our work, as well as a summary of changes to the next updated manuscript.\n\n**List of contributions**\n\nThe contributions of our work can be summarized as follows:\n\n1. We formalize the connection between SCMs and ANFs by rewriting them as members of the same family of data-generating processes (i.e., TMI maps with factorized distributions).\n\n2. Under this family, we rephrase causal inference problems as a specific instance of ICA, for which we can adapt the identifiability results from Xi and Bloem-Reddy [[2]](https://proceedings.mlr.press/v206/xi23a.html).\n\n3. We demonstrate in Corollary 2 that, under the conditions of Theorem 1, being causally consistent is a necessary condition at the global optima when learning causal NFs. We bring such theoretical result into practice by discussing in Section 4 (and empirically validating it in Section 6.1) how to design and learn causally-consistent NFs.\n\n4. We provide a new implementation of the do-operator that is well-suited for any SCM representation beyond its usual recursive formulation, enabling causal inference for the proposed causal NFs. We demonstrate theoretically that this is a proper implementation of the do-operator in App. C, and empirically in App. D.4.\n\n5. We extend the above results to the cases of mixed-type data (App. A.2.1) and partial knowledge on the causal graph/ordering (App. A.2.2) to account for more realistic scenarios and thus make causal NFs applicable in a wide range of domains.\n\n6. Finally, we empirically validate all our findings in 12 datasets (see Section 6 and Appendix D), and demonstrate its potential outreach with a fairness use-case in Section 7.\n\n**Relation to previous work**\n\nFirst, we would like to highlight that we indeed bring the identifiability results on ICA from Xi and Bloem-Reddy [[2]](https://proceedings.mlr.press/v206/xi23a.html) into the causal setting. We consider this contribution novel and significant as the original paper does not have any relationship to causality but only considers latent variable models.\n\nSecond, while CAREFL [[1]](http://proceedings.mlr.press/v130/khemakhem21a.html) focuses on causal discovery, it has hinted a connection between ANFs and SCMs. However, we are the first to: i) properly formalize and generalize (to a broader class of SCMs) this connection using TMI mappings; ii) provide identifiability results for causal NFs; and iii) propose a causal NF network design that is causally-consistent and, hence, can accurately and efficiently learn the underlying SCM generating the data.\n\n\n**List of changes**\n\nFollowing the reviewers' suggestions, we will carry out the following changes:\n\n1. We will more clearly explain the intuition behind Figure 1. See response to reviewer 1x9i.\n2. We will clarify that Theorem 1 has been re-stated from Xi and Bloem-Reddy [[2]](https://proceedings.mlr.press/v206/xi23a.html) to match our particular setting and ease exposition.\n3. We will provide further intuition on the advantage of an abductive network vs. a generative one. In short, causal dependencies from $x$ to $u$ (parents) are sparser than those from $u$ to $x$ (ancestors). See response to reviewer 515Z.\n4. We will revise the appendix and push important conclusions back to the manuscript. Of course, we are open to suggestions during the rebuttal. As suggested by reviewer azJz, we will push the following information to the main paper:\n    1. A sketch of the proof for Corollary 2 to strengthen the line of argumentation of our work.\n    2. A few lines introducing the German Credit dataset in more detail to the reader.\n    3. Background on TMI maps. If this text becomes too lengthy, we will write a separate section in the appendix.\n5. To improve readability, we will substitute the infinite sums $\\sum_{n=1}^\\infty G^n$ by the equivalent $\\sum_{n=1}^{\\operatorname{diam}(G)} G^n$. See response to reviewer p91A.\n6. We will apply external feedback and fix typos and small errors. E.g.:\n    1. In line 113 we call $u$ the endogenous variables, instead of exogenous.\n    2. In the linear examples, we use the letter $G$ for the causal adjacency matrix and the actual linear operation, which can lead to confusions.\n\n---\n\n[1] [Causal Autoregressive Flows](http://proceedings.mlr.press/v130/khemakhem21a.html)\n\n[2] [Indeterminacy in Generative Models: Characterization and Strong Identifiability](https://proceedings.mlr.press/v206/xi23a.html)\n""}}, {'summary': {'value': 'This work explores the use of normalizing flows (NFs) in causal inference. The authors demonstrate that causal models can be identified from observational data using autoregressive NFs. They investigate design choices and implement the do-operator in causal NFs to answer interventional and counterfactual questions. The experiments validate their approach and show that causal NFs can effectively address real-world problems with mixed data types and partial knowledge of the causal graph.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The authors clearly stated the problem of interest as well as compare with relevant previously showed approaches. They also conducts extensive experiments, including ablation analysis. Finally, they discussed practical limitations and present possible lines of investigation as future work.'}, 'weaknesses': {'value': 'The number and characteristics of the given dataset are limited when compared to practical applications. The ablation analysis miss hyperparameter tuning.\n\n'}, 'questions': {'value': 'The authors should give the intuition of presenting Fig. 1 in a more clearly way.\n\nIt is well-known that computational complexity is a challenge when using normalizing flows, especially for high-dimensional data. In this matter, I believe that would be difficult to use the proposed method with such data (e.g. images). Is it limited to tabular data? Is it possible to use it with high-dimensional data? Any pre-processing steps are necessary?\n\nIt would be viable to learn the causal graph (e.g. PC) and use it as input the proposed method? My concern is whether it would be wast of time, given that the information is available in the data. In other words, is there a necessity of domain knowledge to use the proposed method?'}, 'limitations': {'value': 'The datasets used are not strictly representative of practical applications. I believe that there is an avenue of possible developments here turn the proposed method largely applicable.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work explores the use of normalizing flows for causal reasoning. The authors demonstrate that causal models can be identified from observational data using autoregressive normalizing flows. They discuss design choices, learning strategies, and the implementation of the do-operator to handle interventional and counterfactual questions. Through experiments, they validate their approach, compare it to alternative methods, and show its effectiveness in addressing real-world problems with mixed discrete-continuous data and partial causal graph knowledge.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'Novelty: This work introduces a novel approach by employing causal normalizing flows to identify the underlying causal ordering and effectively address interventional and counterfactual queries using the do-operator. To the best of my knowledge, this methodology is both novel and reasonable.\n\nSignificance: The ability to predict the interventional effect of the causal data-generating process is a highly important problem with practical implications.\n\nContribution: The paper presents a clear and comprehensive method, accompanied by necessary conditions that support the theoretical aspects. The overall technical contribution is commendable.\n\nThe writing quality of this paper is good, and it provides ample experimental results to validate its effectiveness. I thoroughly enjoyed reading this paper.'}, 'weaknesses': {'value': 'Challenge: From my understanding, the previous work has already achieved satisfactory results regarding the identifiability of causal normalizing flows. This paper extends these findings to include counterfactual and interventional reasoning. While the theoretical contribution and methodology are commendable, I think this extension is relatively straightforward, and the challenge presented may not be substantial. Consequently, this could be considered the primary weakness of the paper.'}, 'questions': {'value': ""I don't have any specific questions about the main paper, but I recommend that the authors consider transferring some crucial conclusions from the supplementary material to the main paper.""}, 'limitations': {'value': '.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes causal normalizing flows, a method to learn a structural causal model (SCM) using normalizing flows (NFs), when the causal order (and potentially more information about the graph) is available. They consider a general SCM where we have observed variables X which follow the equations X_i = f_i(X_pa(i), u_i) where pa(i) are causal parents of i and u_i is endogenous noise. Then, by unrolling the recurisve definition, the authors propose to model this distribution via NFs. In fact, because of acyclicity, the NFs are actually Triangular Monotonic Increasing (TMI) maps. Under the following assumptions\n- The functions f_i are diffeomorphic\n- the causal graph is acyclic\n- the causal ordering is known (this can be a strong assumption, see below)\n- causal sufficiency, i.e. the endogenous variables u_i are mutually independent\nit follows froms prior works that the model is identifiable (means there is a unique product distribution and TMI maps given the observational dataset). The authors restate this result and use it as a basis for their experimental explorations.\n\nThe main selling point of the work is that with approproate design choices of causal normalizing flows, the causal task of do-operations can be performed efficiently. Different design choices for causal normalizing flows are proposed, including generative (modeling the mixing directly) and abductive (modeling the inverse map) methods. To handle do-operations, the authors propose modifying the endogenous variable directly (since the recursive SCM form is lost). They also show how to adapt their framework when the data is discrete or partial knowledge of the graph is available. For experiments, ablation studies compare the design choices, and the framework is also compared to baselines CAREFL and VACA, showing that CNFs perform better on a few SCM tasks. Finally, a fairness use-case is shown with the German credit dataset. The target audience are people interested in causal inference.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': '- Both structural causal modeling and normalizing flows (by now) are well-studied topics and this work is a nice interplay between these two frameworks.\n\n- The application to deduce credit risk while being unbiased on sex is an interesting and a bit unusual application of their framework.'}, 'weaknesses': {'value': '- Assuming knowledge of causal ordering is usually a very strong requirements in applications, since if we have the knowledge of causal ordering, we can use traditional nonlinear regression techniques, e.g. with spline functions, to learn the underlying SCMs. Therefore, this may potentially be a very limiting assumption in experiments and reduce the usefulness of the proposed method.\n\n- The identifiability results are not novel and therefore the thrust of this work is experimental. As the authors clarify, theorem 1 is taken from Xi and Bloem-Reddy.'}, 'questions': {'value': 'Please comment on the issues above.'}, 'limitations': {'value': 'Limitations have been discussed.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'n this paper, the authors derive and demonstrate the usefulness of normalizing flows (NF) in causal inference. As a first building block of their approach, the authors show that structural causal models (SCMs) can be expressed as triangular monotonic increasing maps.  By this reduction, they show that SCMs can be approximated by autoregressive NFs and that those are causally consistent.\nThey proceed by discussing different architectures to best model the SCM with NFs and conclude that an abductive setup for the NF might be the most suitable architecture.\nIn order to perform interventions on an NF they define the do-operator on those. Due to the recursive representation of their approach, the authors resort to defining an intervention by fixing the exogenous variables accordingly. In empirical evaluations, they show that their approach compares favourably to the SOTA on representing the true data distribution and causal inference tasks w.r.t. to both performance and time efficiency.\nLastly, they show on real-world data that their approach can be used for fairer, but still precise classification.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- The elaboration of the connections between SCMs, TMIs, and ANFs is well executed and can find additional applications in other research.\n- The implementation of interventions as performing them on the exogenous variables is non-trivial and opens up further paths of investigation.\n- Figures 2-4 are very valuable for presentation and understanding.\n- Clear and sound experimental setup.\n- Only mild and standard assumptions.\n- Showcasing the usefulness of causal NFs in ML w.r.t. fairness.'}, 'weaknesses': {'value': '- The paper would benefit of an example of how a learned causal NF behaves, how the interventions influence the output, and how it matches an SCM.\n- Consider pushing some of the information from the appendix to the main text. E.g.:\n\t- 152: A sketch of the proof would strengthen the line of argumentation of this work.\n\t- 327: At least a short sentence on what this data is about.\n- Some background on TMI maps could be introduced to make it easier to follow the content.\n- No resources such as codebase, trained models, and analysis implementation are provided.'}, 'questions': {'value': 'No questions'}, 'limitations': {'value': 'The authors address the limitations of the work clearly and describe how their approach relies on their assumptions. Furthermore, they describe how violating each of their assumptions would affect the overall approach. These observations seem to be complete w.r.t. the possible limitations of this approach.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors propose a normalizing flow (NF) model that incorporates causal information, either via a partial order or complete DAG. They derive identifiability conditions for causal estimands and implement their algorithm on a range of simulated and real-world datasets. The resulting NF can be used to compute treatment effects and counterfactual probabilities, under some reasonable assumptions on the data generating process. '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'This is a strong contribution on an important topic. The manuscript is well-motivated and thoroughly researched. The writing is clear and the experimental validation is convincing. Despite a few minor questions/comments (see below), I am generally supportive of this work.'}, 'weaknesses': {'value': 'There are a few minor points that left me somewhat confused. I suspect these could be cleared up with a few brief lines. \n\n-I’m unsure how to interpret $\\sum_{n=1}^\\infty \\mathbf{G}^n$. Why the infinite sum? The examples in Fig. 4 all appear finite? \n\n\n-It appears that the empirical evaluation only considers causal chains of the form $X_1 \\rightarrow \\dots \\rightarrow X_d$. What about more complicated/realistic causal structures? \n\n\n-If I understand Fig. 5 correctly, the ordering model (green curves) outperforms the graph model (orange curves) by KL-divergence and causal effect estimation in generative models when $L < 3$, while the ordering model dominates effect estimation across all numbers of layers in the abductive model. This echoes the results summarized in Table 1. I feel I must be missing something, however – why should a model do better with a causal ordering than it does with the entire graph? Surely the latter is strictly more informative? \n'}, 'questions': {'value': 'See above.'}, 'limitations': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Causal normalizing flows: from theory to practice'}, 'authors': {'value': ['Adrián Javaloy', 'Pablo Sanchez Martin', 'Isabel Valera']}, 'authorids': {'value': ['~Adrián_Javaloy1', '~Pablo_Sanchez_Martin1', '~Isabel_Valera1']}, 'keywords': {'value': ['causality', 'causal inference', 'normalizing flows', 'identifiability', 'interventions', 'counterfactuals']}, 'abstract': {'value': 'In this work, we deepen on the use of normalizing flows for causal reasoning. Specifically, we first leverage recent results on non-linear ICA to show that causal models are identifiable from observational data given a causal ordering, and thus can be recovered using autoregressive normalizing flows (NFs). Second, we analyze different design and learning choices for *causal normalizing flows* to capture the underlying causal data-generating process. Third, we describe how to implement the *do-operator* in causal NFs, and thus, how to answer interventional and counterfactual questions. Finally, in our experiments, we validate our design and training choices through a comprehensive ablation study; compare causal NFs to other approaches for approximating causal models; and empirically demonstrate that causal NFs can be used to address real-world problems—where the presence of mixed discrete-continuous data and partial knowledge on the causal graph is the norm. The code for this work can be found at https://github.com/psanch21/causal-flows.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'Armed with identifiability results, we demonstraste how to use normalizing flows to capture a causal model and perform causal inference with it.'}, 'pdf': {'value': '/pdf/a2973b5a4a277e34fb1f444c440e839f73d0f992.pdf'}, 'supplementary_material': {'value': '/attachment/9a621aeae59f146973dd162520840e5f8581d9ca.zip'}, '_bibtex': {'value': ""@inproceedings{\njavaloy2023causal,\ntitle={Causal normalizing flows: from theory to practice},\nauthor={Adri{\\'a}n Javaloy and Pablo Sanchez Martin and Isabel Valera},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=QIFoCI7ca1}\n}""}, 'paperhash': {'value': 'javaloy|causal_normalizing_flows_from_theory_to_practice'}}]"
"['Stephanie Milani', 'Anssi Kanervisto', 'Karolis Ramanauskas', 'Sander Schulhoff', 'Brandon Houghton', 'Rohin Shah']",NeurIPS,BEDD_ The MineRL BASALT Evaluation and Demonstrations Dataset for Training and Benchmarking Agents that Solve Fuzzy Tasks,https://neurips.cc/virtual/2023/oral/73745,2023," The MineRL BASALT competition has served to catalyze advances in learning from human feedback through four hard-to-specify tasks in Minecraft, such as create and photograph a waterfall. Given the completion of two years of BASALT competitions, we offer to the community a formalized benchmark through the BASALT Evaluation and Demonstrations Dataset (BEDD), which serves as a resource for algorithm development and performance assessment. BEDD consists of a collection of 26 million image-action pairs from nearly 14,000 videos of human players completing the BASALT tasks in Minecraft. It also includes over 3,000 dense pairwise human evaluations of human and algorithmic agents. These comparisons serve as a fixed, preliminary leaderboard for evaluating newly-developed algorithms.  To enable this comparison, we present a streamlined codebase for benchmarking new algorithms against the leaderboard. In addition to presenting these datasets, we conduct a detailed analysis of the data from both datasets to guide algorithm development and evaluation. The released code and data are available at https://github.com/minerllabs/basalt-benchmark.",Oral 4B Datasets & Benchmarks,https://openreview.net/pdf?id=D1MOK2t2t2,https://openreview.net/forum?id=D1MOK2t2t2,D1MOK2t2t2,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (Oral)'}, 'comment': {'value': ""The paper has received a consistent set of review comments, including two strong acceptance reviews and one weak acceptance review. All reviewers have praised the substantial contributions made in terms of data collection, baseline construction, and codebase. In light of these positive assessments, I believe the paper merits a clear 'accept' recommendation.""}}, {'comment': {'value': 'This addresses my concerns! I will up my score to an 8, I think this dataset will be very useful.'}}, {'comment': {'value': 'We thank the reviewers for their thoughtful comments and the effort spent reviewing our paper. We appreciate that all reviewers saw the value in our carefully-designed and collected dataset(s), as well as our streamlined and open-source codebase for training algorithms that learn from human feedback. We have responded to each review and revised our paper (with changes in orange). We hope that our responses and paper revisions have sufficiently addressed all comments. '}}, {'comment': {'value': 'Thank you for your enthusiastic review! We are pleased that you see the relevance of our data contributions to the community, as well as the effort and resulting quality of our data set. \n\nThank you for your advice to analyze failure cases! In our submission, we took a closer look at our demonstration data. Due to our data collection pipeline, our demonstration dataset is high-quality, with less than 1% of idiosyncratic episodes. As a result, we do not have examples of almost successes in the demonstration dataset. Some examples of failures include players seemingly just playing Minecraft instead of accomplishing the goal or immediately dying (see Appendix C.2.2 for more details). These failure cases are perhaps less interesting, since they would also be captured by the MineRL Diamond dataset, However, these examples, as well as others in the MineDojo and MineRL Diamond datasets, could be used if one wants to include incorrect goals for a contrastive learning approach. \n\nHowever, based on your recommendation, we also took a closer look at the evaluation dataset, which consists of detailed human evaluations of both human and AI agents. We noticed a few interesting findings. In general, we found that the answers to the detailed evaluation questions provided by the human evaluators could be used as labels for different failure cases for training algorithms that explicitly account for negative examples. For example, Figure 4b (MakeWaterfall) in the paper reveals that, although Team GoUp’s algorithm can create waterfalls at a rate more similar to the human players, it struggles along all other criteria, including choosing a good location and taking a high-quality photograph. When decomposed individually, these details could be used as labels to describe a demonstration that creates a waterfall but does not choose a good location. As another example, Figure 4a (FindCave) suggests that, while Team GoUp’s algorithm still struggles to find caves, it can reasonably search for and navigate to areas that are likely to have caves. This finding suggests that the performance bottleneck may be the cave detection system employed by this approach. The videos generated by Team GoUp’s algorithm for FindCave could be used to distinguish between full and partial success on this task. We include these details in the updated version of the paper (Section 5.2 in orange). \n\nWe also appreciate the suggestion to investigate successful episodes in more detail. We would love to understand what would be perceived as useful for a potential user of our dataset. We have included two potentially useful measures: a proxy for the distance traveled and a proxy for the number of blocks placed (details in Section 4). Because our demonstration dataset largely consists of successful episodes, summary statistics of these measures could be useful for measuring the progress of a new approach.\n\nPlease let us know if our response here, along with the updated paper draft, has sufficiently addressed your comments! '}}, {'comment': {'value': 'Thank you for your detailed review! We are pleased that you see the value of this work and acknowledge our detailed analysis and extensive data collection efforts. \n\nBefore responding to the nice suggestions for improvement, we wanted to take a moment to clarify a few points. Maybe this is what you meant; we just want to clarify in case there was a misunderstanding. First, we want to clarify that the demonstration dataset consists of state-action pairs, not state-text pairs. One can view the instructions as a goal described in natural language to annotate the entire video, but we do not release per-state text descriptions. Second, we want to clarify that the human evaluation dataset is not conducted using the data from the demonstration dataset. In our paper, we evaluated a few algorithmic and human players, where the videos of human play were generated separately from the demonstration data. Third, we want to clarify that the challenge of the BASALT tasks is that they do not have corresponding reward functions and cannot be evaluated without the help of human evaluations. We include one task, ObtainDiamondShovel, with a concrete reward function to help researchers develop their methods.\n\nWith that, we would now like to respond to the identified limitations and opportunities for improvement. First, we apologize for any confusion about the availability of the data and resources. We have shared our data openly in the following links (effective immediately), and added the same links to our paper. Our code is on Github at https://github.com/minerllabs/basalt-benchmark , and our evaluation dataset is already available at https://zenodo.org/record/8021960 . The demonstration dataset is available at https://github.com/openai/Video-Pre-Training#basalt-2022-dataset . \n\nSecond, we appreciate the suggestion to better clarify the relationship of this work to MineDojo. We updated the paper with a more extensive comparison (orange text in Related Work). To summarize here, MineDojo aimed to provide a massive dataset covering a variety of possible tasks in Minecraft. Because this data stemmed from various online videos, it is quite diverse, which can prove challenging in settings where high-quality and consistent data is needed (such as training BC-based approaches). In contrast, our demonstration dataset was collected using verified, paid contractors who were instructed how they should play the game. For that reason, researchers can more readily use this data for techniques that rely on high-quality data for training, without the need for extensive data pre-processing and cleaning.\n\nFurthermore, MineDojo evaluates agents based only on binary success and failure conditions, whereas we present more extensive evaluation criteria with individual, decomposed evaluation criteria. We would be remiss to not mention the utility of this more extensive evaluation criteria. Decomposing the evaluation enables better quantitative understanding of the conditions in which certain algorithms fail and opportunities for improvement. For example, Figure 4b in the paper reveals that, although Team GoUp’s algorithm can create waterfalls at a rate more similar to the human players, it struggles along all other criteria, including choosing a good location and taking a high-quality photograph. Only looking at the binary success/failure condition for creating a waterfall, as in MineDojo, would ignore these important nuances in the algorithm’s behavior.\n\nFinally, we open source an end-to-end pipeline for using our curated demonstration data to train an agent and subsequently compare that agent using human feedback against the existing leaderboard. In this sense, our dataset complements MineDojo’s, as one can use MineDojo dataset to pretrain models, then use our demonstration dataset to fine-tune the models for BASALT tasks, and finally use our evaluation pipeline for a more extensive model evaluation.\n\nThird, we would like to address the question about the scale of the data for training large models. BASALT tasks take place in vanilla Minecraft, so any large models trained for this purpose could be used in the training pipeline. Our data can then be used for fine tuning these large models. We believe that the scale of the collected data is sufficient, as it was used by participants in the BASALT 2022 competition in various ways with larger models, such as creating embedding datasets with VPT.  \n\nFourth and finally, thanks for noticing the template! We updated it to the NeurIPS 2023 version.\n\nPlease let us know if our response here, along with the improved and updated draft of the paper, has sufficiently addressed your comments!'}}, {'comment': {'value': 'Thank you for your glowing feedback! We are happy to hear that our efforts in carefully designing and collecting the dataset are not unnoticed. Thank you again.'}}, {'title': {'value': 'A dataset for LfHF algorithm development and performance assessment'}, 'rating': {'value': '10: Top 5% of accepted papers, seminal paper'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'In this paper, the authors introduced BEDD dataset, which consists of a collection of 26 million image-action pairs from nearly 14,000 videos of human players completing the BASALT tasks in Minecraft. It also includes over 3,000 dense pairwise human evaluations of human and algorithmic agents. \n\nThese comparisons serve as a fixed, preliminary leaderboard for evaluating newly-developed algorithms. To enable this comparison, we present a streamlined codebase for benchmarking new algorithms against the leaderboard. In addition to presenting these datasets, we conduct a detailed analysis of the data from both datasets to guide algorithm development and evaluation.'}, 'strengths': {'value': '1. A very strong data set with detailed and carefully design. \n2.  A codebase for further study.'}, 'opportunities_for_improvement': {'value': 'Maybe, the paper could provide more tasks and benchmark on the dataset.'}, 'limitations': {'value': 'Yes,  the authors adequately addressed the limitations and potential negative societal impact of their work.'}, 'correctness': {'value': 'The authors are all vey experienced in this area and the dataset, codebase and the results have matched the practice.'}, 'clarity': {'value': 'Yes'}, 'relation_to_prior_work': {'value': 'Yes, the background  and related work are very concise.'}, 'documentation': {'value': 'Yes'}, 'ethics': {'value': 'No such issue'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'Very nice work.'}}, {'title': {'value': 'Dataset and Benchmark for MineRL BASALT competition'}, 'rating': {'value': '6: Marginally above acceptance threshold'}, 'confidence': {'value': '3: The reviewer is fairly confident that the evaluation is correct'}, 'summary_and_contributions': {'value': 'In their study, authors propose a dataset to enable easy training and evaluation of algorithms settled within Minecraft environment. BASALT Evaluation and Demonstrations Dataset (BEDD) is a formalized benchmark, which authors think of as a resource for algorithm development and performance assessment in MineRL Basalt competition. The authors describe datasets and tasks that make up the benchmark and point out that whole workflow is open and set up to be automatized for users who would like to evaluate their algorithm in MineRL Basalt. They demonstrate the utility of the proposed dataset and benchmark by evaluating several baseline algorithms. Authors observe that there is still a large room for improvement in learning from human feedback on open world environments, and suggest that inclusion of their open code for benchmarking and evaluating agents will encourage the development of more effective approaches.\n\nContributions of the presented work are as following:\n\n- Composing BASALT Evaluation and Demonstrations Dataset (BEDD), to enable systematic and standardized assessment of algorithms that learn from human feedback data within MineRL Basalt competition. Annotations for the dataset contain descriptions related to human performance, eg human-like score, in addition to conventional performance reward based scores\n- Demonstrating utility of the proposed dataset & benchmark by providing analysis of several algorithms.'}, 'strengths': {'value': '- Remarkable data collection effort: 14k videos of human play, with annotations that also score human behavior aspects (eg human-like score, over 3000 annotations of various human and algorithmic agents provided by human evaluators), in addition to conventional reward based scores\n- Relevant topic: providing benchmark for algorithms that learn from human feedback to cope with complex open world environment in Minecraft\n- A streamlined codebase to make it easy for the potential users to evaluate a new model and to compare it to the existing leaderboard\n- Aiming at open sourcing whole dataset and workflows around it'}, 'opportunities_for_improvement': {'value': '- Authors should clarify better in what sense the released dataset and benchmarking procedures will be openly available. It is mentioned in the text, but references to open source repos etc are missing. Authors do provide open source implementation in the supplementary material.\n\n- Authors should discuss in more depth relation to MineDoJo and benchmarks introduced there. It should become more clear what are the main novelties of the proposed work to the elements already existing in MineDoJo'}, 'limitations': {'value': 'It is not clear whether the scale of the collected data (26M image-text pairs from 14k videos) is sufficient to test larger scale models. Authors should elaborate whether this is the case and how does it compare to data amounts employed in MineDojo.'}, 'correctness': {'value': 'The presentation is sound, with some issues mentioned above.'}, 'clarity': {'value': 'The paper is well structured and readable.'}, 'relation_to_prior_work': {'value': 'I think relation to MineDojo should be worked out in the paper better than the very short text piece that I think does not provide the reader information how current work is complementary to what MineDojo already provides.'}, 'documentation': {'value': 'Datasheet for the dataset is provided in the supplementary, with some additional info in the source code from supplementary material.'}, 'ethics': {'value': 'No ethical concerns given here in my opinion.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'The authors use NeurIPS 2022 template as visible in the footnote of the draft. Switching to NeurIPS 2023 one is recommended.'}}, {'title': {'value': 'BEDD: The MineRL BASALT Evaluation and Demonstrations Dataset for Training and Benchmarking Agents that Solve Fuzzy Tasks'}, 'rating': {'value': '8: Top 50% of accepted papers, clear accept'}, 'confidence': {'value': '3: The reviewer is fairly confident that the evaluation is correct'}, 'summary_and_contributions': {'value': 'This paper builds on the Minecraft BASALT dataset by introducing:\n\n1. New evaluation criteria to systematize metrics for methods \n2. Data in the form of human and machine video/action examples which successfully complete certain tasks on MineCraft. They also include some in-depth analysis and annotation of these examples in the form of an evaluations dataset, which is human annotated.\n3. Automated evaluation metrics to improve speed of iteration on BASALT tasks.'}, 'strengths': {'value': 'Overall on all these axes I believe this is a strong submission which will be of use to the community. One caveat to my review is that I do not directly work on Minecraft RL tasks or current RL interaction datasets.\n\n\n1. The main data contributions (video data for behavioral cloning purposes) are highly relevant to the community. \n2. The quality of the analysis of these successful examples goes beyond simple data scraping, with useful human annotations for success and failure cases. The authors appear to have put significant effort into data cleanliness and verification.\n3. The evaluation benchmark and automated evaluation suggestions also seem very useful for quick iteration, as human eval is hard to set up. I did not have a chance to directly evaluate the code for this however.\n4. The standardization of BASALT benchmarks through explicit evaluation criterion is likely useful for the community. Especially for ensuring that certain benchmarks stay rigorous.\n5. Ambiguous tasks with unclear termination criteria are also useful to demonstrate complex behavior. This paper suggested an interesting way to evaluate these methods using direct comparison (TrueSkill, ELO, etc.).'}, 'opportunities_for_improvement': {'value': 'This paper would have been made stronger with annotated examples of failure cases, instead of only successful attempts. This would have provided interesting counterfactual information for people using the dataset. I see why the authors did not do this, as there are many degenerate failure possibilities. This could be a good avenue for future work (e.g. including information about ""almost successes"" in behavioral cloning methods).\n\nMore fine-grained annotation of successful episodes would also have been useful, including critical success keypoints (e.g. how important was a certain action for success?). However, annotation could always be more fine-grained so I consider this a minor complaint.'}, 'limitations': {'value': 'The authors did provide a limitations section in the Appendix. Along with the suggestion above this limitations section seems reasonably thorough.'}, 'correctness': {'value': 'The dataset construction methodology is reasonably sound and thorough (see strengths).'}, 'clarity': {'value': 'The paper is easy to follow and well-structured.'}, 'relation_to_prior_work': {'value': ""This discussion was centered around past MineCraft datasets (e.g. BASALT and MineDojo). This background info seems reasonably thorough, however I'm not an expert in this area.""}, 'documentation': {'value': 'The dataset is accessible. I was able to download the dataset and run a simple evaluation. Maintenance seems unnecessary, although it would be nice to add new examples as leaderboards progress. Documentation is good.'}, 'ethics': {'value': ""Any ethics concerns in this case are so abstract that they're not applicable.""}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'N/A. Stated everything I want to say before. Overall excellent paper, I enjoyed reading it :-)'}}, {'title': {'value': 'BEDD: The MineRL BASALT Evaluation and Demonstrations Dataset for Training and Benchmarking Agents that Solve Fuzzy Tasks'}, 'authors': {'value': ['Stephanie Milani', 'Anssi Kanervisto', 'Karolis Ramanauskas', 'Sander V Schulhoff', 'Brandon Houghton', 'Rohin Shah']}, 'authorids': {'value': ['~Stephanie_Milani1', '~Anssi_Kanervisto1', '~Karolis_Ramanauskas1', '~Sander_V_Schulhoff1', '~Brandon_Houghton1', '~Rohin_Shah1']}, 'keywords': {'value': ['learning from human feedback', 'minecraft', 'human evaluation', 'embodied agents', 'rlhf', 'demonstrations', 'benchmark', 'evaluations']}, 'abstract': {'value': 'The MineRL BASALT competition has served to catalyze advances in learning from human feedback through four hard-to-specify tasks in Minecraft, such as create and photograph a waterfall. Given the completion of two years of BASALT competitions, we offer to the community a formalized benchmark through the BASALT Evaluation and Demonstrations Dataset (BEDD), which serves as a resource for algorithm development and performance assessment. BEDD consists of a collection of 26 million image-action pairs from nearly 14,000 videos of human players completing the BASALT tasks in Minecraft. It also includes over 3,000 dense pairwise human evaluations of human and algorithmic agents. These comparisons serve as a fixed, preliminary leaderboard for evaluating newly-developed algorithms.  To enable this comparison, we present a streamlined codebase for benchmarking new algorithms against the leaderboard. In addition to presenting these datasets, we conduct a detailed analysis of the data from both datasets to guide algorithm development and evaluation. The released code and data are available at https://github.com/minerllabs/basalt-benchmark.'}, 'venue': {'value': 'NeurIPS 2023 Datasets and Benchmarks Oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Track/Datasets_and_Benchmarks'}, 'TLDR': {'value': 'To facilitate algorithm development for the BASALT benchmark, we provide a large-scale dataset of human demonstrations and evaluations, along with a streamlined codebase for training, evaluating, and analyzing algorithms.'}, 'pdf': {'value': '/pdf/4e72d4d2f391475f1704eff68b07b0c5b6b2a40a.pdf'}, 'supplementary_material': {'value': '/attachment/1f949c207dba85aad822acfdf1c1437996bbbf7f.pdf'}, '_bibtex': {'value': '@inproceedings{\nmilani2023bedd,\ntitle={{BEDD}: The Mine{RL} {BASALT} Evaluation and Demonstrations Dataset for Training and Benchmarking Agents that Solve Fuzzy Tasks},\nauthor={Stephanie Milani and Anssi Kanervisto and Karolis Ramanauskas and Sander V Schulhoff and Brandon Houghton and Rohin Shah},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\nyear={2023},\nurl={https://openreview.net/forum?id=D1MOK2t2t2}\n}'}, 'paperhash': {'value': 'milani|bedd_the_minerl_basalt_evaluation_and_demonstrations_dataset_for_training_and_benchmarking_agents_that_solve_fuzzy_tasks'}}]"
"['Sadhika Malladi', 'Tianyu Gao', 'Eshaan Nichani', 'Alex Damian', 'Jason Lee', 'Danqi Chen', 'Sanjeev Arora']",NeurIPS,Fine-Tuning Language Models with Just Forward Passes,https://neurips.cc/virtual/2023/oral/73844,2023," Fine-tuning language models (LMs) has yielded success on diverse downstream tasks, but as LMs grow in size, backpropagation requires a prohibitively large amount of memory. Zeroth-order (ZO) methods can in principle estimate gradients using only two forward passes but are theorized to be catastrophically slow for optimizing large models. In this work, we propose a memory-efficient zerothorder optimizer (MeZO), adapting the classical ZO-SGD method to operate in-place, thereby fine-tuning LMs with the same memory footprint as inference. For example, with a single A100 80GB GPU, MeZO can train a 30-billion parameter model, whereas fine-tuning with backpropagation can train only a 2.7B LM with the same budget. We conduct comprehensive experiments across model types (masked and autoregressive LMs), model scales (up to 66B), and downstream tasks (classification, multiple-choice, and generation). Our results demonstrate that (1) MeZO significantly outperforms in-context learning and linear probing; (2) MeZO achieves comparable performance to fine-tuning with backpropagation across multiple tasks, with up to 12× memory reduction and up to 2× GPU-hour reduction in our implementation; (3) MeZO is compatible with both full-parameter and parameter-efficient tuning techniques such as LoRA and prefix tuning; (4) MeZO can effectively optimize non-differentiable objectives (e.g., maximizing accuracy or F1). We support our empirical findings with theoretical insights, highlighting how adequate pre-training and task prompts enable MeZO to fine-tune huge models, despite classical ZO analyses suggesting otherwise.",Oral 4A Optimization,https://openreview.net/pdf?id=Vota6rFhBQ,https://openreview.net/forum?id=Vota6rFhBQ,Vota6rFhBQ,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper proposed a memory-efficient zeroth-order optimizer that can fine-tune large language models using only forward passes. All reviewers give positive ratings to this paper and mention some merits of this paper such as targeting a not well-understood domain (zero order optimization), with good experiment and theoretical support, and good paper writing. Although reviewers ask several questions including whether it can apply to the generation task, or when the assumption of the low effective rank of the Hessian matrix holds, the authors answer these questions well. Overall, it is a strong paper with a clear problem setting, nice experiment results, theoretical support, and practical application. I recommend accepting this paper as a spotlight.'}}, {'comment': {'value': 'Thank you for your responses'}}, {'comment': {'value': 'Thank you. '}}, {'comment': {'value': 'Thank you for answering my question.'}}, {'comment': {'value': 'Thanks for the great answers!'}}, {'comment': {'value': 'Thanks for kindly answering my questions. '}}, {'rebuttal': {'value': '**Can we study the effective rank assumption in some language models?**\n\nIt is difficult to translate results on very small models, on which we would be able to measure the effective rank, to the large ones that we would find MeZO useful for. We would also likely need to pre-train these very small models ourselves, which is expensive, and they may be so small that they do not achieve meaningful results on the benchmarks we study.\n\n**Can we use simulations to verify the theoretical convergence analysis?**\n\nThanks for the suggestion! We added the simulated experiment in our attached PDF and also reported the results in our general response. In short, we observed that the convergence rate of MeZO does depend on the effective rank in the simulated experiments.\n\n\n**What is the wall-clock efficiency of MeZO compared to fine-tuning with backpropagation?**\n\nPlease see our general response. In short, MeZO reduces the number of GPU-hours needed to train large models, leading to a 2x GPU-hour reduction on a 30B model compared to Adam fine-tuning.\n\n**Do the backpropagation versions of full fine-tuning, prefix tuning, and LoRA optimize at roughly the same rates, as was observed with MeZO? And do the three parameterizations actually have similar effective ranks empirically?**\n\nWe did not measure the empirical effective rank of different methods due to limited compute. We observe that with backpropagation, all three methods converge roughly at a similar speed, with LoRA and prefix-tuning slightly slower on some tasks. The interesting case with MeZO is that classical ZO analyses suggest that full-parameter MeZO would converge much more slowly, but it is not the case empirically. Our theory in Section 4 highlights why the convergence rate does not depend on the number of parameters.\n'}}, {'rebuttal': {'value': '**Can the theoretical convergence analysis of MeZO be compared to backpropagation?**\n\nCorollary 1 directly compares the SGD convergence rate to the convergence rate of MeZO, since the term in brackets in equation 5 is the per-step loss decrease of SGD (see Lemma 1). Two factors make MeZO converge more slowly than standard backpropagation (lines 211-218): (1) MeZO has to be run with a smaller learning rate than SGD in order to reliably decrease the loss at each step, and (2) MeZO reduces the amount that the loss can decrease at each step. \n\n**Why is prompting crucial to MeZO?**\n\nPlease refer to our general response. In short, we hypothesize that using a prompt makes the fine-tuning objective similar to the pre-training one, which likely exhibits a Hessian with low effective rank. \n'}}, {'rebuttal': {'value': '**Why does MeZO require using a prompt? What tasks can MeZO work on? Why do you need the Hessian hypothesis (Assumption 1)?**\n\nPlease refer to our general response. In short, we hypothesize that using a prompt makes the fine-tuning objective similar to the pre-training one, which likely has a Hessian with a low effective rank. Following this, we agree with you that a task that has a lower perplexity (i.e., a more “natural” prompt) will probably work better with MeZO. Once we added a simple prompt, we did not encounter any tasks that MeZO completely failed to train on.\n\n**How does the empirical success of MeZO interact with the theoretical hypothesis that transformers may simulate fine-tuning on a smaller, internal model during inference time?**\n\nMeZO is a useful tool for fine-tuning currently popular LLMs trained with standard pre-training practices. It is not guaranteed to work for models that are designed or trained in new ways, such as the scenario you mention. It may be the case that the internal model is not stable to fine-tuning the large model. Alternatively, it could be stable to fine-tuning in some way (e.g., analogous to noise-tolerant circuits) that allows it to not be destroyed during MeZO. Overall, we are not sure if currently existing pre-trained models are simulating and updating internal models, so we cannot be sure how such constructed models would behave during fine-tuning, whether it is done with backpropagation or MeZO. \n\n**How does MeZO behave with different numbers of examples?**\n\nThanks for your question. We will include experiments ablating against different dataset sizes in a subsequent revision. '}}, {'rebuttal': {'value': 'Thank you for your suggestion, and we will report average numbers in the experiment results in the next revision.\n\n**What is the practical training time compared to standard fine-tuning?**\n\nPlease refer to our general response for a wall clock time analysis. In short, MeZO reduces the number of GPU-hours needed to train large models, leading to a 2x GPU-hour reduction on a 30B model compared to Adam fine-tuning.\n\n**How does MeZO perform with full training data?**\n\nWe choose the fixed number of training example setting because of compute limitations. Some datasets have millions of examples, so fine-tuning on the entire dataset can be very expensive for the model scale we are studying. We will include more ablations showing how MeZO performance changes with the dataset size in the next revision.\n'}}, {'rebuttal': {'value': '**Does MeZO work for generation tasks?**\n\nTable 1 and Figure 1 show the performance of MeZO on DROP and SQuAD, which are two question-answering tasks that are formatted as generation tasks in our experiments. For each task, given the question, we train the model to directly generate the answer text (please see our Table 12 for details). We leave the study of more generation tasks like summarization and translation to future work.\n\n**When does the assumption of the low effective rank of the Hessian hold?**\n\nPlease refer to our general response. We hypothesize that when using a good prompt, the Hessian of the downstream objective likely exhibits a low effective rank.\n\n**How stable is MeZO training? Does it have an advantage over backpropagation?**\n\nMeZO is not very sensitive to hyperparameter choices. As shown in Tables 13 (RoBERTa-large) and 14 (OPT), we restrict the grid searches to a very narrow range of hyperparameters and often test MeZO with fewer configurations than we use to test fine-tuning with backpropagation. Also, as a gradient estimate, MeZO avoids well-known issues with backpropagation such as vanishing and exploding gradients, though these rarely occur when training networks with residual connections. MeZO is unstable in other ways, like if $\\epsilon$ must be set very small. However, in practice, we find that MeZO succeeds with a relatively large $\\epsilon$ and reduces the loss consistently over the course of training.  \n'}}, {'rebuttal': {'value': 'We thank all reviewers for their valuable feedback. We address some shared questions here.\n\n**When can MeZO succeed in fine-tuning? What losses satisfy Assumption 1 (i.e., the Hessian has a low effective rank)? Why is a prompt necessary for MeZO to be able to fine-tune the model? Can you verify the dependence of MeZO convergence rate on the effective rank?**\n\nOur theory in Section 4 provides a sufficient (but not necessary) condition for MeZO to succeed: the Hessian should exhibit a small local effective rank during fine-tuning (Assumption 1). We hypothesize that the Hessian of the pre-training objective likely exhibits low effective rank, because the model has been trained for many steps during pre-training. Ample evidence suggests that training for many steps can make the Hessian have a low effective rank in the case of vision (see lines 222-228). Adding a prompt turns the downstream task into next-word prediction [1] (or masked language modeling [2]). So, the Hessian of the fine-tuning objective when using a prompt (similar to pre-training) likely exhibits a small effective rank like the pre-training one [1, 3]. There is additional empirical evidence that the Hessian of a language model during fine-tuning likely has low rank [4].\n\nAdditionally, per reviewer XvSx’s suggestion, we ran simulations in a simple setting to verify the dependence of MeZO convergence rate on the effective rank and reported the results in the attached PDF. We observed that the slowdown of the convergence scales with the effective rank. We will include these experiments in the next revision of the paper.\n\n[1] Nikunj Saunshi, Sadhika Malladi, Sanjeev Arora. A Mathematical Exploration of Why Language Models Help Solve Downstream Tasks. ICLR 2021.\n\n[2] Tianyu Gao, Adam Fisch, Danqi Chen. Making Pre-trained Language Models Better Few-shot Learners. ACL 2021.\n\n[3] Sadhika Malladi, Alexander Wettig, Dingli Yu, Danqi Chen, Sanjeev Arora. A Kernel-Based View of Language Model Fine-Tuning. ICML 2023.\n\n[4] Armen Aghajanyan, Sonal Gupta, and Luke Zettlemoyer. Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning. ACL 2021.\n\n**What is the wall-clock efficiency of MeZO compared to standard training with backpropagation?**\n\nThe attached PDF with this rebuttal shows the wall-clock efficiency of MeZO compared to fine-tuning. MeZO takes more steps to achieve similar performance than fine-tuning, but requires much less wall-clock time per step and requires fewer GPUs. The gains are more prominent for larger models, which are the ones that require more memory to fine-tune. For example, for a 30B model, we show that MeZO enjoys a 7.74x per-step speed up and a 2x total GPU-hour reduction compared to fine-tuning with Adam. We will include these results in the next revision of the paper.\n\n\n\n\n'}, 'pdf': {'value': '/pdf/68abacc31f632a9fde8c1b86a1ddbaeb848df590.pdf'}}, {'summary': {'value': 'This work introduced a memory-efficient zeroth-order optimizer that can fine-tune large language models with the same memory footprint as inference, using only forward passes and gradient estimates. Comprehensive experiments across model types, scales, and tasks, showing that MeZO outperforms zero-shot, in-context learning, and linear probing, and achieves comparable performance to fine-tuning with backpropagation, while reducing memory cost by up to 12 times. Non-differentiable objectives that MeZO can optimize, such as accuracy or F1 score, which are usually not amenable to backpropagation. Theoretical insights that explain why MeZO can optimize LMs with billions of parameters, despite classical zeroth-order analyses suggesting otherwise.\n'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. It proposes a novel and memory-efficient method to fine-tune large language models without backpropagation, which can save up to 12x memory compared to standard methods.\n\n2. It demonstrates that the proposed method can achieve comparable or superior performance to fine-tuning with backpropagation across various tasks, models, and tuning techniques.\n\n3. It shows that the proposed method can optimize non-differentiable objectives, such as accuracy or F1 score, which are useful for many applications.\n\n4. It provides theoretical insights on why the proposed method can overcome the classical limitations of zeroth-order optimization and leverage the benefits of pre-training and task prompts.\n'}, 'weaknesses': {'value': '1. While the experiments demonstrate good performance on the language understanding tasks, it is unknown whether the method is also applicable to the generation tasks.\n\n2. It relies on the assumption of low effective rank of the Hessian matrix, which may not hold for all loss functions. It would be great to have a discussion about the scope of application for the proposed method.\n'}, 'questions': {'value': 'How is the training stability of MeZO? Does it an advantage over the backpropagation-based methods, especially for the large models?'}, 'limitations': {'value': '1. It would be better to have the experiment results on the generation tasks, e.g. translation and summarization.\n\n2. I suggest the authors to have a discussion about the scope of application for the proposed method.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper proposes an enhanced memory efficient zero-order optimization method named MeZO. MeZO only requires the same memory as inference time and thus can enable model tuning for large LMs with limited memory budget. The authors demonstrate the efficacy of MeZO on multiple NLP benchmarks compared with linear probing, in context learning and fine-tuning in few/low shot learning regime. The authors also provided detailed theoretical proof for MeZO. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': ""0 - The authors targeted a not well understood domain (zero order optimization) and open up new opportunities for future works. In the era of LLMs, this method can enable many future work especially for those who don't have access to large-scale GPU clusters. \n1 - Comprehensive experiments and ablation studies on the proposed method.\n2 - Strong theoretical support on the proposed method.\n3 - Good writing and flow which makes the paper easy to follow and understand. \n4 - Well-articulated future work.""}, 'weaknesses': {'value': 'No major weaknesses. I left some comments in the questions section and hope  the authors can answer and address. '}, 'questions': {'value': '- Can authors also report practical training time compared with standard fine-tuning (e.g., in terms of # steps/ second)?\n\n- Maybe report average numbers as well in experiment results (e.g., Table 1)\n\n- Interested to see how the performance of MeZO compares with fine-tuning in the scenario of full training data (rather than k = 100, 500, etc). '}, 'limitations': {'value': 'The authors have discussed limitations in the conclusion section and aim to explore them in future work.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper present a new optimiser MeZo based on stochastic approximation using gradient perturbation. \nThis optimiser is very memory efficient as it only requires to perform 2 forward passes with different deltas/epsilons on the parameters and multiple gaussian samplings.   These algorithms allows ""finetunning"" large language models to specific tasks very efficiently ( up to 30B on a single A100) yielding between x4 to x12 memory reductions. Since the proposed algorithm is an optimizer it can be combined with other standard techniques such as LORA or prefix tunning. All this is applied in finetunning setups similar to ICL. '}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The algorithm is a new application of well known stochastic gradient approximation but many times forgotten due to their slowness. \nIt is very surprising that this algorithm works, and the authors provide a theoretical justification of why this could be working in this case. \nThey also acknowledge that despite of what it might sound this approach only works in prompting fine-tunning scenario [Appendix B.2]. \n\nThe results are insight full , the baselines are fair and the theoretical analysis is correct to the best of my knowledge.\n\nThis can settle as an alternative to in context learning with prompting, by  fine-tuning with  a limited set of examples (512). \n\nThe proposed technique seems to work on the benchmarks used and seems to surpass other techniques such as Zero-shot, LP, ICL, and approaches very close performance to fine-tunning. This can be set a cheap alternative to ICL for some tasks.\n\n'}, 'weaknesses': {'value': 'While there was a huge and titanic effort in the paper there were many questions that steam from the technique.\nThe first area which has not been explored too much and given as true is the need of having a prompt to apply MeZO.\nThis key ingredient is not well studied but rather given on some preliminary experiments, e.g. Table 5. \nWhy is MeZO not working w/o prompts, even some very simple prompts ? \n\nThe need of the prompt also raises the question of how this is related to ICL , as there are some works that suggest ICL maybe doing some alike to fine-tuning or back-propagation though the attention weights. Is this combination of prompting and MeZo that is guiding the forward propagations ? is there a mixed cooperation between the prompt and the stochastic technique ? How much of the prompt is needed ?\n\nAnother question would be how the different techniques behave as a function of the number of examples k. It would have been nice to see a plot for some models at least between ICL , MeZo, and possible ft on the selected tasks. Why have authors stopped at 512 ? why only 16 or 512 ? there are some dataset that contain more training examples. Why didn\'t they compare fine-tuning and MeZo in other setups with larger examples ?\n\nThere is the relationship between the task itself and the optimiser. It is not clear to me, in which tasks this will work properly. I suspect given the prompting above that this might only work on low-perplexity tasks or task in which prompting or ICL can generate good results and not in other more complex tasks. \n\nClearly this is maybe too much to address in the paper, but all aspects above point toward the little understanding the reader is left with on under which conditions this technique can be applied. The future work seems to already assume the MeZO algorithm is working and proved, but there is just an hypotheses and a very low link between the experiment conditions and the theory. The link is stablished as ""We attribute these phenomena to the Hessian of the loss exhibiting  small local effective rank."" . It would have been nice to strengthen this connection with some experiments or computation. Could this explain when or how this algorithm is applied ? if we remove the prompt does this increases the H effective rank ? would other tasks exhibit larger ranks ?  how can we reduce it for each of the tasks ?\n\n\nPlease, I would kindly ask the authors to read above questions and discussion as a signal of the interest the paper brought to the research field and not as criticism on their very interesting work.\n'}, 'questions': {'value': 'While I have many question none of them affect the paper directly. \nIt would be nice however if some of the weakness could be discussed by authors: \n* in which task will this technique work? do you have a characterisation ?  have you tried other tasks where it failed ? \n* why the Hessian hypotheses ? is this based on some experimental or preliminar analysis ?\n* when ft surpasses this techniques? when we have to ft on hundreds of thousands of examples ? \n* why it only works with prompting ? \n'}, 'limitations': {'value': 'While the author do not focus on the limitations,  they are more or less clear per previous analysis. The focus of the paper is more on the direction of stressing the surprise of the technique with all known drawbacks is actually workig. '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper proposes a new zeroth order optimizer, MeZO, for LM training.  This is proposed as an improvement to ZO-SGD.  The advantage of this approach is a 12x reduction in the amount of memory required for training compared to backpropagation.  This enables the training of much larger models.\n\nThe effectiveness of MeZO is shown across a range of benchmarks and model sizes.  The results compare favorably to linear probing and in context learning.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'The MeZO technique stands to unlock substantial capability for LM training.  This enables training of much larger networks.  The compatibility with LoRA, prefix tuning are important use cases for many LM users.  There is an ability for optimizing non-differentiable objectives which is compelling, and could be expanded in the future.\n\nThe empirical behavior are coupled with a section on theory which effectively describes the both the expected behavior, but elaborates on the expected slow convergence by expanding the theoretical analysis to address low effective rank networks.'}, 'weaknesses': {'value': 'While the analysis refers to the convergence rate of MeZO, there is a very brief treatment of convergence behavior in the paper (Appendix E.2) It might be helpful for this to be expanded and possibly compared to backpropagation, especially in the context of the presentation of Section 4 Theory.'}, 'questions': {'value': 'Appendix A (and Section 3) demonstrate that promoting is crucial to MeZO performance.  Why is this? Much of the other behavior is supported by a theoretical treatment, but this observation stands out as relatively uninterrogated.'}, 'limitations': {'value': 'yes though fairly lightly.  The observation about prompts being critical for training may be a limitation for some (new) tasks or datasets.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'Fine-tuning with backpropogation becomes infeasible for very large language models because it uses too much memory. While zeroth-order optimization uses far less memory and could in principle fine-tune the model with just forward passes, past theory suggested that the learning rate must scale down with the number of parameters, making convergence prohibitively slow. However, this paper finds that zeroth-order optimization actually performs quite well and converges quickly even on very large language models. They provide theory to explain this fast convergence, where they show that under an assumption they call ""low effective rank,"" the learning rate scales down with the rank rather than the number of parameters. They also provide a memory-efficient implementation of zeroth-order optimization that they call MeZO, along with memory efficient zeroth-order versions of SGD with momentum and Adam. In experiments, the method performs similarly to backpropogation with 1/12 the memory usage, while outperforming in-context learning and linear probing.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '(1) The paper is well-written.\n\n(2) The method is simple and easy to understand.\n\n(3) The theory provides useful insights into why zeroth-order optimization works for fine-tuning large pre-trained models.\n\n(4) The experimental results are strong, and the appendix contains thorough ablations.\n\n(5) The idea that zeroth-order optimization works well for fine-tuning LMs seems practically useful and addresses a pressing need in the community for memory-efficient methods.'}, 'weaknesses': {'value': 'The paper seems strong overall, and I support its acceptance regardless of whether the suggested experiments below are run or not during the rebuttal period.\n\n(1) From what I understand, the paper does not verify the low effective rank assumption empirically, nor is it verified in the papers cited (which either study the effective rank / Hessian spectra in non-LLMs, or study the LLMs but not the effective rank and instead study the intrinsic dimensionality of fine-tuning). Therefore, to justify the assumption, it seems useful to study the Hessian spectra of the downstream fine-tuning loss in LLMs, at whatever size is feasible.\n\n(2) Related to (1), to verify the theory and confirm that the effective rank is indeed the quantity that determines convergence rates, it seems useful to run simulated experiments where one constructs a synthetic model + data and varies the effective rank, and examines whether the convergence rate or gradient norm scales with the effective rank as predicted in the theory.'}, 'questions': {'value': ""(1) While MeZO is much more memory efficient, is it slower than backprop in terms of wall-clock time? (The appendix does state that FT used 1K steps while MeZO used 100K steps in the experiments. How much faster is each step of MeZO compared to each step of backprop?)\n\n(2) It's a bit surprising to me that MeZO, MeZO-prefix, and MeZO-LoRA optimize at similar speeds (Figure 5 in the appendix). Do the backprop versions also optimize at similar speeds? And do the three parameterizations actually have similar effective ranks empirically?""}, 'limitations': {'value': 'n/a'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Fine-Tuning Language Models with Just Forward Passes'}, 'authors': {'value': ['Sadhika Malladi', 'Tianyu Gao', 'Eshaan Nichani', 'Alex Damian', 'Jason D. Lee', 'Danqi Chen', 'Sanjeev Arora']}, 'authorids': {'value': ['~Sadhika_Malladi2', '~Tianyu_Gao1', '~Eshaan_Nichani1', '~Alex_Damian1', '~Jason_D._Lee1', '~Danqi_Chen1', '~Sanjeev_Arora1']}, 'keywords': {'value': ['language models', 'fine-tuning', 'zeroth order optimization', 'memory efficiency']}, 'abstract': {'value': 'Fine-tuning language models (LMs) has yielded success on diverse downstream tasks, but as LMs grow in size, backpropagation requires a prohibitively large amount of memory. Zeroth-order (ZO) methods can in principle estimate gradients using only two forward passes but are theorized to be catastrophically slow for optimizing large models. In this work, we propose a memory-efficient zerothorder optimizer (MeZO), adapting the classical ZO-SGD method to operate in-place, thereby fine-tuning LMs with the same memory footprint as inference. For example, with a single A100 80GB GPU, MeZO can train a 30-billion parameter model, whereas fine-tuning with backpropagation can train only a 2.7B LM with the same budget. We conduct comprehensive experiments across model types (masked and autoregressive LMs), model scales (up to 66B), and downstream tasks (classification, multiple-choice, and generation). Our results demonstrate that (1) MeZO significantly outperforms in-context learning and linear probing; (2) MeZO achieves comparable performance to fine-tuning with backpropagation across multiple tasks, with up to 12× memory reduction and up to 2× GPU-hour reduction in our implementation; (3) MeZO is compatible with both full-parameter and parameter-efficient tuning techniques such as LoRA and prefix tuning; (4) MeZO can effectively optimize non-differentiable objectives (e.g., maximizing accuracy or F1). We support our empirical findings with theoretical insights, highlighting how adequate pre-training and task prompts enable MeZO to fine-tune huge models, despite classical ZO analyses suggesting otherwise.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/0cbbbd759c11a9d8c6df40a6e3a298142da7725d.pdf'}, 'supplementary_material': {'value': '/attachment/ee7393dc6772e185bedd07302ab82308bb3409b0.zip'}, '_bibtex': {'value': '@inproceedings{\nmalladi2023finetuning,\ntitle={Fine-Tuning Language Models with Just Forward Passes},\nauthor={Sadhika Malladi and Tianyu Gao and Eshaan Nichani and Alex Damian and Jason D. Lee and Danqi Chen and Sanjeev Arora},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=Vota6rFhBQ}\n}'}, 'paperhash': {'value': 'malladi|finetuning_language_models_with_just_forward_passes'}}]"
"['Guhao Feng', 'Bohang Zhang', 'Yuntian Gu', 'Haotian Ye', 'Di He', 'Liwei Wang']",NeurIPS,Towards Revealing the Mystery behind Chain of Thought_ A Theoretical Perspective,https://neurips.cc/virtual/2023/oral/73822,2023," Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the expressivity of LLMs with CoT in solving fundamental mathematical and decision-making problems. By using circuit complexity theory, we first give impossibility results showing that bounded-depth Transformers are unable to directly produce correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of constant size suffice to solve both tasks by generating CoT derivations using a commonly used math language format. Moreover, we show LLMs with CoT can handle a general class of decision-making problems known as Dynamic Programming, thus justifying their power in tackling complex real-world tasks. Finally, an extensive set of experiments show that, while Transformers always fail to directly predict the answers, they can consistently learn to generate correct solutions step-by-step given sufficient CoT demonstrations.",Oral 4C COT/reasoning,https://openreview.net/pdf?id=qHrADgAdYu,https://openreview.net/forum?id=qHrADgAdYu,qHrADgAdYu,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper provides new theoretical understandings of the Chain-of-Thought (CoT) technique, by proving rigorous separation results between the CoT (autoregressive) mode and the direct mode for transformers to solve arithmetic and linear equation solving problems. The positive results for CoT are further extended to dynamical programming problems. The paper also provides empirical validations.\n\nAll reviewers are strongly positive about the research direction and the contributions of the results, which I agree with. I believe the paper contains multiple results (lower bounds via circuit theory, concrete transformer constructions, the dynamical programming problem framework, and the experiments) that are worthy to be highlighted in the community and may inspire future research. Therefore, I recommend acceptance with oral presentation, and congratulate the authors for the nice work.'}}, {'title': {'value': 'Thank you'}, 'comment': {'value': 'Thanks for your additional feedback! We will definitely incorporate them into the next version of this paper.'}}, {'comment': {'value': 'Thanks for the reply! I think these points are compelling. Assuming all of this is incorporated into the main paper and is appropriately caveated (i.e., something along the lines of the ""indirect"" sentence above), I am raising my score to an 8. I think all of these additions significantly strengthen the paper\'s impact and elevate it from a paper that would primarily benefit the theory community to a paper that will really benefit anyone trying to understand Transformers.'}}, {'title': {'value': 'Thanks for your feedback'}, 'comment': {'value': 'Thank you for your positive feedback and additional comments, and for asking the good question. We are happy to provide additional responses to the insightful question you raised:\n\n> Question: To what extent do you think this theoretical construction is capturing what\'s happening empirically? Do you have any evidence in either direction that you could provide in the body of the paper? \n\nWe believe our theoretical construction can to some extent capture what\'s happening empirically and is more meaningful than several prior works. This is due to the following reasons. First, we use log-precision Transformer instead of infinite precision, which can be precisely implemented in modern GPU architectures in practice. Moreover, the values of weight elements in our constructions are often not large and thus are likely to be learned by gradient descent. Second, the size of the Transformer architecture in our construction is reasonable. For example, we only use no more than 5 layers, 5 heads and a hidden dimension of $O(1)$. Third (and most importantly), prior work has pointed out that the COPY operation, which forms the basic building block in our construction, does appear empirically [1]. Specifically, the authors proposed the concept of ""induction head"", which is a module that can find the position in the sentence where the current token previously appeared and then extract the next token after that position. The authors visualized the attention score matrix for various tasks and found that the Transformer model is indeed performing the induction head. Therefore, based on the above points, we argue that the theoretical construction is capturing some intrinsic characteristics in practical scenarios.\n\nNevertheless, the above evidence is still kind of ""indirect"" since we cannot prove that gradient-descent-based optimizers can learn the construction. But we believe adding the above discussion into the main paper, especially the connection to the ""induction head"" mechanism, can benefit our community and may further enhance the impact of our paper.\n\nFor other suggestions, we will definitely incorporate these insights into the final version of our paper. Finally, we really appreciate your effort in making our paper better and we will be more than happy to discuss more if you have other questions or suggestions. Thank you!\n\n[1] In-context Learning and Induction Heads. Olsson et al.'}}, {'comment': {'value': ""Thanks for the very thoughtful response! I think incorporating these takeaways into the body of the paper and highlighting them as contributions significantly increases the impact of the paper. To what extent do you think this theoretical construction is capturing what's happening empirically? Do you have any evidence in either direction that you could provide in the body of the paper? I strongly support highlighting these takeaways in the body either way, but I also want to make sure the community doesn't latch onto them too prematurely (especially since the focus here is on what can be represented, not what's actually learned through gradient descent). Although negative evidence, to whatever extent it exists, seems like an important caveat, positive evidence would certainly be a very compelling addition to this paper.\n\nWith the additions provided in the authors' response, I'm raising my score to a 7 (under the assumption that they'll be included in the final version).""}}, {'title': {'value': 'Thanks'}, 'comment': {'value': 'Thank you very much for the detailed and enlightening reply! I really appreciate the analysis.'}}, {'title': {'value': 'Thanks for your feedback'}, 'comment': {'value': 'Thank you! We will definitely incorporate them into the next version of this paper.'}}, {'title': {'value': 'Thanks'}, 'comment': {'value': 'Thanks! Would be nice to see these incorporated into the revision.'}}, {'rebuttal': {'value': ""We would like to express our sincere thanks to the reviewers and the area chair for taking the time to review our paper. We have responded to each reviewer's comments separately and will incorporate their suggestions into the next version of our paper. We hope that our response can adequately addresse the reviewers' concerns, and we're happy to provide more details about any questions they may have.""}}, {'rebuttal': {'value': 'We sincerely thank Reviewer 7MZe for the careful reading, thoughtful inquiries, and positive feedback. Below, we are happy to provide further elaboration on each of the points you raised:\n\n> Q1: Is there a specific reason for choosing autoregressive Transformer? Were other models, such as the encoder-decoder architecture like T5 model be considered? Would CoT be equally effective in those models?\n\nThanks for the question. We choose autoregressive Transformer as it is the de facto standard for LLMs (e.g., GPT). It is also simpler than encoder-decoder architectures, which makes our analysis and proof cleaner. Yet, our theoretical results can be easily transferred to an encoder-decoder model (like T5) using the following argument. (a) On one hand, given a bounded-depth polynomial-size log-precision encoder-decoder Transformer, its parallel complexity is still bounded by $\\mathsf{TC}^0$, so our negative results hold. (b) On the other hand, any finite-depth autoregressive Transformer can be mimicked by a finite-depth encoder-decoder Transformer of roughly the same size, since causal masking for the input sequence can be mimicked through the use of positional encoding and joint attention can be mimicked by an integration of cross-attention and self-attention. Thus, all results in this paper are not exclusive to autoregressive Transformers. We can add those discussions into the paper if you think they are helpful.\n\n> Q2: How much does the number of layers affect the performance of CoT, and are there necessary layer numbers for different tasks? Additionally, the difficulty of the datasets for now seem insufficient to explore this question.\n\n\nThanks for the question. We study simple tasks in the paper and found that from both theoretical and practical perspectives, a shallow LLM with CoT already has enough capacity to solve them. We agree and believe deeper LLMs are required to solve more complicated tasks with CoT. For example, it can be easily imagined that a deeper LLM is needed to complete a task if it composes of solving linear equations and arithmetic with dynamic programming. We are working on more general and advanced reasoning tasks and investigating the dependency between task and LLM parameter complexity.\n\n\n> Q3: Does CoT also possess the ability to learn the underlying mechanisms for other tasks beyond Arithmetic Expression Extrapolation? \n\nThanks for the question. During the tight discussion period, we have completed experiments for longest increasing subsequence task. The results of the LIS task are shown in the table below. Here, we train the autoregressive Transformer model with various input length ranging from 1 to 80, and test the model using longer input sequence lengths unseen during training. It can be seen that the model can still extrapolate well to longer sequences. \n\n   | **Length**   | 82 | 84 | 86 | 88 | 90 | \n   | ------------ | -- | -- | -- | -- | -- |\n   | **Accuracy** | 94.3% | 92.8% | 90.7% | 89.6% | 87.4% | \n\nWe are currently running experiments on the linear equation task. But it cannot be finished before the rebuttal deadline given very limited GPU memory resources (the required CoT length is very long even for solving linear equations with 7 variables). We will report the performance when it is finished using more advanced GPUs.\n\n> Q4: Have you considered the impact of the quality of intermediate steps on the performance, such as inserting some invalid intermediate steps or omitting a certain number of intermediate steps?\n\nThis is a good catch as real-world language model training data often involves corrupted or omitted intermediate steps. To assess this, we conducted experiments on arithmetic task with varying rates of corruption and omission, denoted as γ. Specifically, γ = 0.1 indicates that we skip 10% intermediate steps and corrupt 10% steps with a single-token random replacement. The table below presents the experimental results:\n\n   | γ | Accuracy |\n   | ---- | -------- |\n   | 0.1 | 98.5% |\n   | 0.2 | 97.6% |\n   | 0.3 | 95.8% |\n\nThe results clearly demonstrate the robustness of training CoT demonstrations, showcasing its ability to maintain high accuracy even in the presence of imperfect intermediate steps in the training datasets. We will add those robustness evaluation into the final version of the paper.\n\nWe hope these clarifications can address your questions satisfactorily and we are happy to delve further into any \nof these aspects.'}}, {'rebuttal': {'value': 'We sincerely thank Reviewer P6n5 for the positive feedback, valuable suggestions, and two insightful questions regarding the related work and other architectures. Below, we would like to give detailed responses to each of your comments and questions.\n\n**Regarding related work**. Thanks for the valuable suggestions on the related work. We will follow your advice and include these two papers in our related work section. These two papers focus on the Dyck language, a special case of the CFG. The first one shows that the hard-attention transformers can recognize Dyck language with bounded depth. Moreover, a two-layer soft-attention transformer can generate Dyck language. The second paper tries to use RNN to generate bounded-depth Dyck language. This paper demonstrates that RNN can generate the Dyck language with hidden units of reasonable size. Furthermore, the paper proves that the size of the hidden units is optimal. The conclusions of these two papers complement our theorems on the general CFG.\n\nWe also thank you for posing two insightful questions that deserve careful discussion.\n\n> **Question**: Seems ""Self-attention networks can process bounded hierarchical languages"" proved that (2-layer) Transformers can recognize Dyck, yet this papers proves CFG recognition is in general hard?\n\nYes, the problem of general CFG recognition is much harder than the special case of the Dyck language. The paper “Self-attention networks can process bounded hierarchical languages” employs a Transformer encoder that is similar to the auto-regressive Transformer without CoT, except for the causal mask. The complexity of both Transformer encoder and autoregressive Transformer without CoT is upper bounded by the circuit complexity $\\mathsf{TC}^0$. For the special case of Dyck language, it has been proved that the problem of recognizing Dyck language is actually in the complexity class $\\mathsf{TC}^0$ [1]. Therefore, it is possible for a transformer model to recognize the Dyck language. However, general CFG recognition is $\\mathsf{P}$-complete, which is intrinsically hard to be solved by a Transformer without CoT.\n\n[1] On the relative complexity of some languages in NC1. Barrington et al.\n\n> **Question**: Would results hold for RNN or other architectures?\n\nFirst, most of the theorems in this paper can be naturally extended to some popular settings with Transformer, such as the encoder-decoder architectures (e.g., T5). However, as for the RNN, it is actually not the case. We can show that RNNs cannot generate the CoT sequence using the same format proposed in our paper for the arithmetic formula task and the linear equation task unless the hidden dimension of the RNN is at least $O(\\frac{n}{\\log n})$, where $n$ is the input length. The reason is as follows. When the RNN generates the first equal sign, it has to compress the input sequence into a hidden state of $O(D\\log n)$ bits, where $D$ is the hidden dimension and each element is represented by $O(\\log n)$ bits (by definition of log-precision). On the other hand, the first step of the CoT needs to output a sequence of length $O(n)$, which contains $O(n)$ numbers. Therefore, there are at least $2^{O(n)}$ different output sequences, and thus by the Pigeon Hole Principle, to be able to generate all $2^{O(n)}$ different output sequences, we must have $D=\\Omega(\\frac{n}{\\log n})$.\n'}}, {'rebuttal': {'value': 'We sincerely thank Reviewer QoTB for the careful reading, positive feedback, valuable suggestions regarding presentations, and detailed comments. Below, we would like to give detailed responses to each of your comments and questions.\n\n**Regarding the scope of the paper**. Thanks for the suggestion. We connect our work to ""CoT"" because our theory suggests that to solve math/reasoning problems, ""generating intermediate deviations in an autoregressive way"" is easier and much more parameter-efficient. As this generation process is regarded as ""Chain of Thought"" by the community, we leverage the concept during writing. On the other hand, we fully agree that intrinsically, this work is more about the way of using LLMs rather than how to develop specific CoT prompts. We will make this clear in the introduction and are happy to illustrate more and try to come up with a more accurate and appropriate title.\n\n**Regarding notations in Section 4**. We appreciate the constructive suggestions and will revise our manuscript accordingly. In particular, we intend to simplify the notations in Section 4.1 by using a vectorized notation. For example, in equation (5), we will use $s_{\\mathbf{g}(i)}$ to represent the vector $(s_{g_1(i)},\\cdots,s_{g_J(i)})$. In this way, equation (5) can be rewritten in a more concise form, avoiding the problem of double subscript. The original equation and the updated equation are shown below:\n$$\n\\mathsf{dp}(i)=f(i,s_{g_1(i)},\\cdots,s_{g_n(i)},\\mathsf{dp}(h_1(i)),\\cdots,\\mathsf{dp}(h_K(i)))\n$$\n\n$$\n\\mathsf{dp}(i)=f(i,s_{\\mathbf{g}(i)},\\mathsf{dp}(\\mathbf{h}(i)))\n$$\n\n> **Question**: Is there any conceptual takeaway from this theoretical analysis beyond ""generating more tokens is more powerful""? ...... However, I think this could be an especially powerful paper if the intuitions from the theoretical analysis could be further synthesized in this direction (and made accessible to readers).\n\nThanks for raising this good question. It makes us realize that there is still much room for us to improve the writing of the paper. Indeed, our theoretical analysis has a bunch of conceptual takeaways beyond the surface conclusion that ""generating more tokens is more powerful"". We detail these takeaways below:\n\n* **The key role of self-attention in CoT generation**. Our analysis points out two key components that enable CoT generation, which we call **COPY** and **MEAN**. Specifically, the COPY operation extracts the hidden information of a specific previous position that satisfies certain conditions, e.g., extracting the hidden embedding of the last equal sign (=), or the last non-number token. The MEAN operation averages the hidden embedding for a set of previous positions that satisfy certain conditions, e.g., the average hidden embedding of all *number* tokens between the last equal sign and the current token. We prove that **both COPY and MEAN can be realized by a self-attention layer**. We then use exactly the two operations to build entire **parallel algorithms** that can generate CoT sequences for all math and DP problems. Our result highlights the crucial role played by the self-attention and Transformer architecture, and may inspire future research on architectural design in Large Language Models (e.g., more efficient LLMs).\n\n* **Regarding the length of CoT generation**. Our theoretical analysis also gives insights into how many intermediate steps are needed in the CoT generation. In particular, when the Transformer model generates a CoT sequence, we have to ensure that the complexity of generating each step is within $\\mathsf{TC}^0$. Using this argument, one can easily check whether the length of a specific CoT format is sufficient. For more complex problems, we need to decompose it into more subproblems (or more steps), so that each step is within the complexity of $\\mathsf{TC}^0$. Moreover, we give a standard criterion to check whether the $\\mathsf{TC}^0$ expressivity is satisfied: if each CoT step can be represented by a finite composition of **COPY** and **MEAN** operations, then each CoT step will be within the complexity of $\\mathsf{TC}^0$.\n\n* **Regarding dynamic programming**. We theoretically show that CoT allows Transformers to solve general DP problems. Thus, as a direct consequence, Transformers are even capable of solving extremely hard problems that are $\\mathsf{P}$-complete. This provides a deeper understanding of why popular large language models can be so powerful in reasoning. We believe our proposed dynamic programming framework may also be useful for studying and measuring the expressive power of other architectures in the future.\n\nWe will incorporate these discussions into the next version of our paper.\n\nWe hope our response can clarify your concerns and will improve the paper writing according to your suggestions and questions. We are happy to go into more detail regarding any of the above questions and we look forward to your reply.\n'}}, {'rebuttal': {'value': 'We sincerely thank Reviewer C8fV for the positive feedback, appreciation for our work, and insightful questions.\n\n> **Question**: Line 245, the success of solving Dynamic Programming problems critically depends on the input sequences being laid out in topological order. In the two DP experiments (Longest Increasing Subsequence and Edit Distance), the topological order appears to be learnable from the CoT dataset. Could there be any theoretical study about how hard it is to learn this order?\n\nWe thank the reviewer for the insightful question. In our paper, we mainly study CoT from an expressivity perspective, i.e., whether there exists a model that can generate the topological ordering of the DP states and find the correct solution, and we prove that the answer is yes. Your question relates to the generalization ability of CoT training, i,e., why the model behaves well on unseen data. For this question,  we can offer some intuitive insights into why generating the topological ordering is easy for an autoregressive Transformer. In our formulation, the topological ordering can be determined by a function $F$ that takes the current state $i_k$ and the problem scale $n$ as inputs and outputs the next state $i_{k+1}$, i.e., $F(i_k,n)=i_{k+1}$. Assumption 4.4 guarantees that $F$ can be efficiently approximated by a constant-sized perceptron with GeLU activation, by which **the topological order can be easily generated in an autoregressive way by this simple function $F$**. In the Appendix, we give an explicit expression of the function $F$ for each DP problem considered in this paper, all of which are simple:\n$$\n\\text{LIS}: F((j,k),n)=\\begin{cases}\n(j,k+1)\\ \\ \\text{if}\\ \\ k<j-1\\\\\\\\\n(j+1,0)\\ \\ \\text{if}\\ \\ k=j-1\n\\end{cases}\n$$\n$$\n\\text{ED}: F((j,k),(n_1,n_2))=\\begin{cases}\n(j,k+1)\\ \\ \\text{if}\\ \\ k<n_2\\\\\\\\\n(j+1,0)\\ \\ \\text{if}\\ \\ k=n_2\n\\end{cases}\n$$\nIt is easy to see that $F$ can be represented by a small MLP with ReLU (or GeLU) activation. Therefore, it may not be difficult for the model to learn the topological order given sufficient training demonstrations.\n\nOn the other hand, we believe theoretically understanding the generalization ability of CoT learning process is extremely important and we leave it as future work. Although there are some works trying to explain the generalization of modern deep learning models [1,2], they may not provide useful insights for the CoT setting. Studying the generalization ability of large language models from massive data around their reasoning ability should be a very fundamental and practical problem that deserves more attention in the future.\n\n[1] Li, Yingcong, et al. ""Transformers as algorithms: Generalization and implicit model selection in in-context learning."" \n\n[2] Xu, Keyulu, et al. ""How neural networks extrapolate: From feedforward to graph neural networks."" \n'}}, {'summary': {'value': 'This paper studies the theoretical power of the Chain-of-Thought (CoT) prompting. In particular, this paper mathematically confirms that two well-chosen tasks (e.g., arithmetic and equation) and the problem of Dynamic Programming are beyond bounded-depth Transformer models without CoT (unless their size grows prohibitively large); with CoT and generated intermediate derivations, those problems become solvable. The mathematical derivations are under mild assumptions, and empirical results confirms the mathematical study (on four representative tasks).'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': 'Given the prevalence of CoT, theoretical study of the limit of CoT becomes extremely valuable. This paper overcomes several limits in previous studies (e.g., assuming infinite precision) and focuses on the setting of autoregressive Transforms, which is close to the scenario of real-world LLMs. Moreover, the proposed empirical tasks are illustrative and easily reproducible.'}, 'weaknesses': {'value': ""I don't find any noticeable weakness in this paper.""}, 'questions': {'value': 'Line 245, the success of solving Dynamic Programming problems critically depends on the input sequences being laid out in a topological order. In the two DP experiments (Longest Increasing Subsequence and Edit Distance), the topological order appears to be learnable from the CoT dataset. Could there be any theoretical study about how hard it is to learn this order?'}, 'limitations': {'value': 'The authors have adequately addressed the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents various separation results, showing that a Transformer with CoT can solve certain formally-defined reasoning tasks, but a Transformer *without* CoT cannot (assuming bounded depth). This sheds light on the power of CoT. The formal results are supplemented with empirical results that support the claims.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '- Understanding CoT is an important and timely question. This paper is therefore tackling a significant question.\n- To the best of my knowledge, this is the first paper to provide a theoretical explanation of the power of CoT (i.e., originality).\n- In general, the paper is quite clear and high-quality, though I think the notation could be improved (see below).'}, 'weaknesses': {'value': '- I think calling it CoT but focusing on ""CoT generation"" is perhaps misleading. Many people think of CoT as a prompting technique. In my opinion, the generation aspect that this paper focuses on is actually bigger/more important than CoT suggests, and I actually think that - although buzzwordy - CoT diminishes the general power of generation that this paper is getting at (i.e., this paper transcends CoT). I would suggest looking into alternative, more general titles.\n- Section 4.1 has a lot of notation, including double subscripts. I think there\'s a significant lack of accessibility created by the heavy notation. I would really encourage the authors to think about whether the notation could be simplified. I think doing so could substantially increase the long-term impact of this paper.\n- Relatedly, equations (4) and (5) would be clearer if their new objects were introduced and explained conceptually before jumping into equations (4) and (5).\n- Overall, I think the paper could do a better job explaining the significance of the theoretical results. Although this is an important problem to study theoretically, and this paper does a good job of initiating that study, it\'s not entirely clear what can be gained conceptually from this analysis. I think many people already intuitively grasp that generating more tokens gives an LLM more power, and various methods that allow more tokens to be generated before arriving at a final answer are more powerful. It would be nice to understand whether there\'s a conceptual message here that goes any deeper than the aforementioned intuition.'}, 'questions': {'value': '- See CoT naming comment above. Do you agree?\n- See notation comment above. Is there a way to simplify the notation in Section 4.1? Is there a reason it has to be this complicated? If it seems necessary, maybe there\'s a simpler version that can be presented in the body of the paper, with the full version moved to the appendix?\n- My main question is also discussed in the Weaknesses section. Is there any conceptual takeaway from this theoretical analysis beyond ""generating more tokens is more powerful""? Even without that, I think this is a strong paper. However, I think this could be an especially powerful paper if the intuitions from the theoretical analysis could be further synthesized in this direction (and made accessible to readers).'}, 'limitations': {'value': 'The authors do a nice job of discussing some of the limitations of this work. There is no discussion of societal impact, but I do not think this is a problem for this particular paper.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper contributes to theoretical and empirical understanding of Chain-of-thought, i.e. intermediate process generation to assist desired output generation. In the theory part, authors show\n- log-presicion Transformer with bound depth cannot solve simple math tasks (calculate, solve linear equations) unless the model size grows super-polynomially w.r.t. input length. the proof is based on circuit complexity and a bottleneck of parallel complexity (assuming $TC^0 \\neq NC^1$). However, constant-size Transformer can solve both by generating common math intermediate steps.\n- for dynamic programming (DP), Transformers with CoT can generate the correct answer intuitively. In contrast, it is proven that Context-Free Grammar Membership Testing cannot be solved with a bounded-depth Transformer with polynomial depth.\n\nExperiments then validate these results using two math and two DP tasks, showing CoT > no CoT (with more layers even). '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '- CoT has been important in language processing, and its theoretical and empirical understanding is important and timely.\n\n- As far as I can tell, both the theory and experiment parts of the paper is solid, and well-written.\n\n- I like the connection to circuit complexity theory. Though the conclusion and ""intuition"" is not hard to grasp, the theory part is technical and non-trivial to establish.'}, 'weaknesses': {'value': ""- As noted by authors, it's still limited to expressivity (not learning with large corpora, large model).\n\n- Some missing references around Dyck language recognition:\n\nSelf-attention networks can process bounded hierarchical languages. ACL 2021\nRNNs can generate bounded hierarchical languages with optimal memory. EMNLP 2020\n ""}, 'questions': {'value': '- Seems ""Self-attention networks can process bounded hierarchical languages"" proved that (2-layer) Transformers can recognize Dyck, yet this papers proves CFG recognition is in general hard? Some discussion would be nice.\n\n- Would results hold for RNN or other architectures? Some discussion would make the paper stronger.'}, 'limitations': {'value': 'Authors write about limitations fairly.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper mainly focuses on theoretically proving the effectiveness of the CoT in autoregressive Transformer models for solving fundamental mathematical and decision problems through generating intermediate steps. It demonstrates that any finite-depth Transformer model cannot directly output correct answers to these tasks unless the model size grows super-polynomially with the input length. The paper also includes experimental validation using a constructed dataset.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. The paper provides a solid theoretical proof of the effectiveness of CoT, making a valuable contribution to further exploring the underlying mechanisms of CoT operation.\n\n2. The theoretical proofs presented in the paper are comprehensive and well-organized.\n\n3. The research problem addressed in the paper is clearly significant. CoT has shown strong empirical performance but lacks theoretical analysis. Thus, this study is timely and necessary.\n'}, 'weaknesses': {'value': '1. The experimental section seems to be insufficient, for example, the length extrapolation experiment only provides results for one task.\n\n2. The exploration of model architectures is lacking. (see my questions)'}, 'questions': {'value': '1. Is there a specific reason for choosing autoregressive Transformer? Were other models, such as the encoder-decoder architecture like T5 model be considered? Would CoT be equally effective in those models?\n\n2. In the experiments, a Transformer with three layers achieves near-perfect accuracy on each task, but the proofs utilize five layers. How much does the number of layers affect the performance of CoT, and are there necessary layer numbers for different tasks? Additionally, the difficulty of the datasets for now seem insufficient to explore this question.\n\n3. In the Length Extrapolation section, only Arithmetic Expression Extrapolation is explored. Does CoT also possess the ability to learn the underlying mechanisms for other tasks? The conclusion seems to lack sufficient experimental verification and analysis.\n\n4. Have you considered the impact of the quality of intermediate steps on the performance, such as inserting some invalid intermediate steps or omitting a certain number of intermediate steps?'}, 'limitations': {'value': 'Section 7 of the paper provides a thorough discussion of the limitations. Additionally, while CoT demonstrates excellent performance across various tasks, this paper mainly focuses on mathematical tasks and could further explore other types of tasks, such as logic reasoning tasks represented in natural language.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective'}, 'authors': {'value': ['Guhao Feng', 'Bohang Zhang', 'Yuntian Gu', 'Haotian Ye', 'Di He', 'Liwei Wang']}, 'authorids': {'value': ['~Guhao_Feng1', '~Bohang_Zhang1', '~Yuntian_Gu1', '~Haotian_Ye1', '~Di_He1', '~Liwei_Wang1']}, 'keywords': {'value': ['Chain-of-Thought Prompting', 'Large Language Models', 'Theory', 'Circuit Complexity', 'Dynamic Programming']}, 'TLDR': {'value': 'This paper theoretically and empirically show the utility of CoT in LLMs.'}, 'abstract': {'value': 'Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the expressivity of LLMs with CoT in solving fundamental mathematical and decision-making problems. By using circuit complexity theory, we first give impossibility results showing that bounded-depth Transformers are unable to directly produce correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of constant size suffice to solve both tasks by generating CoT derivations using a commonly used math language format. Moreover, we show LLMs with CoT can handle a general class of decision-making problems known as Dynamic Programming, thus justifying their power in tackling complex real-world tasks. Finally, an extensive set of experiments show that, while Transformers always fail to directly predict the answers, they can consistently learn to generate correct solutions step-by-step given sufficient CoT demonstrations.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/b690023791961d10fee22a28790c1000b9a92e4c.pdf'}, '_bibtex': {'value': '@inproceedings{\nfeng2023towards,\ntitle={Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective},\nauthor={Guhao Feng and Bohang Zhang and Yuntian Gu and Haotian Ye and Di He and Liwei Wang},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=qHrADgAdYu}\n}'}, 'paperhash': {'value': 'feng|towards_revealing_the_mystery_behind_chain_of_thought_a_theoretical_perspective'}}]"
"['Alexander Wei', 'Nika Haghtalab', 'Jacob Steinhardt']",NeurIPS,Jailbroken_ How Does LLM Safety Training Fail_,https://neurips.cc/virtual/2023/oral/73831,2023," Large language models trained for safety and harmlessness remain susceptible to adversarial misuse, as evidenced by the prevalence of “jailbreak” attacks on early releases of ChatGPT that elicit undesired behavior. Going beyond recognition of the issue, we investigate why such attacks succeed and how they can be created. We hypothesize two failure modes of safety training: competing objectives and mismatched generalization. Competing objectives arise when a model’s capabilities and safety goals conflict, while mismatched generalization occurs when safety training fails to generalize to a domain for which capabilities exist. We use these failure modes to guide jailbreak design and then evaluate state-of-the-art models, including OpenAI’s GPT-4 and Anthropic’s Claude v1.3, against both existing and newly designed attacks. We find that vulnerabilities persist despite the extensive red-teaming and safety-training efforts behind these models. Notably, new attacks utilizing our failure modes succeed on every prompt in a collection of unsafe requests from the models’ red-teaming evaluation sets and outperform existing ad hoc jailbreaks. Our analysis emphasizes the need for safety-capability parity—that safety mechanisms should be as sophisticated as the underlying model—and argues against the idea that scaling alone can resolve these safety failure modes.",Oral 6A LLMs,https://openreview.net/pdf?id=jA235JGM09,https://openreview.net/forum?id=jA235JGM09,jA235JGM09,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'Reviewers all found this to be a sound and valuable contribution.'}}, {'comment': {'value': 'Reviewer, please confirm that you read this rebuttal and adjusted your score and review if appropriate.'}}, {'comment': {'value': 'Reviewer, please confirm that you read this rebuttal and adjusted your score and review if appropriate.'}}, {'comment': {'value': 'It appeared from your comment that you may have intended to raise your score--just checking that you did not forget.'}}, {'title': {'value': 'Did you mean to raise your score?'}, 'comment': {'value': 'It appeared from your comment that you may have intended to raise your score--just checking that you did not forget.'}}, {'comment': {'value': 'The rebuttal has addressed most of my comments. I will increase the score.'}}, {'comment': {'value': 'The response addresses my concerns, thank you!'}}, {'comment': {'value': 'Thank you for your rebuttal. It addresses my comments. '}}, {'comment': {'value': 'I thank the authors for providing responses to my review. I am still not fully convinced about the discussions provided by the authors on the second point. If authors claim ""Given the success of RLHF, it is very plausible that including examples of Base64 inputs in the safety training set would lead to safety on this category of inputs. "" I would like to see some experiments on this and actual results to prove the point. I feel like there is lack of experimental and ablation studies to support some of the claims made.\n\nRegarding the comment 1 and it being deferred to future work, again this can add significant value to the paper and since currently it is missing from the current work, I am going to keep my score as is.'}}, {'title': {'value': 'Response to rebuttal'}, 'comment': {'value': 'Thank you for your rebuttal. This addresses my questions about these 3 points.'}}, {'rebuttal': {'value': 'Thank you for your review of our paper, and for pointing out areas of concern. Here\'s our response to the issues you raised:\n\n1. **Definition of jailbreak attacks.** We would like to highlight that we present a formal threat model for jailbreak attacks in Section 2.1 in terms of restricted behaviors. On the other hand, a completely mathematical definition of restricted behavior may be an unreasonable expectation, since judging harm (or other undesirable LLM output) is inherently subjective. Nonetheless, the potential of LLMs to cause harm is well documented [1, 2] and is a concrete concern for the deployment of such systems, especially as their capabilities improve in the coming years.  \nTo minimize the degree of subjectivity in our study, we defer the definition of harm to the model creators and follow a clear labeling scheme, detailed in Appendix B. In particular, we find that the tested models refuse to answer almost all of the harmful prompts without jailbreaking (see the performance of the ""none"" attack in Tables 1 and 3). This, along with the fact that the curated dataset was drawn from red-teaming efforts of the model creators, suggest that these prompts were considered harmful by the model creators.\n\n2. **Related work on jailbreaks.** We are not aware of any empirical studies on jailbreaking language models of a similar nature as ours at the time of submission. If you know of any related work we may have missed, please let us know, and we will be sure to cite and discuss them.\n\n3. **Conceptual contributions.** Finally, we would like to emphasize that our conceptual contribution of identifying the failure modes of existing methods goes beyond our empirical study. We believe these insights will push the field forward, as the weaknesses we identify cover almost all known attacks and highlight why current methods fail systematically. Indeed, as part of our responsible disclosure process we shared our results with affected model creators (OpenAI and Anthropic), and their feedback indicated that our results were not only novel, but also interesting and valuable to them.\n\n[1] https://arxiv.org/pdf/2112.04359.pdf  \n[2] https://arxiv.org/pdf/2303.08774.pdf\n'}}, {'rebuttal': {'value': 'Thank you for the thoughtful and detailed review! Responding to each of the points you’ve raised:\n\n\n1. **On defenses and small-scale experiments.** Towards better defenses, in Section 5 we argue that successful defenses may need to move beyond the existing pretrain-then-finetune paradigm. In this vein, the approach of Perez et al. to incorporate human preferences *during pretraining* [1] is a promising example that plausibly addresses both failure modes of standard RLHF.  \nFurthermore, we highlighted white-box studies involving open-source models as a future direction in the Conclusion because no safety-trained open-source large language models existed at the time of writing, so there were no available small-scale models to experiment on. (The first such model, Llama 2 from Meta [2], was released after the end of the NeurIPS review period.) And even with open model weights, there still exists a significant gap between proprietary and open-source datasets/infrastructure for safety training. We nonetheless agree that further investigation with white-box access is an exciting future direction.\n\n2. **On support for claims about competing objectives and mismatched generalization.** We would like to highlight that our ablations (in Section 4) of the simple example attacks (from Section 3) aim to pin down the mechanism of these attacks using only black-box access.  \nFor instance, for prefix injection, we show that the injected prefix matters for the success of the attack. Changing to an innocuous prefix reduces effectiveness significantly. This indicates that the autoregressively decoded prefix plays a key role in determining the refusal (or lack thereof) of the model. This autoregressive decoding behavior is a direct consequence of the pretraining objectives.  \nAnd for Base64, we show that Base64 input suffices for a successful attack: just providing the input in Base64 suffices to escape safety training. This demonstrates that instruction following generalizes to Base64 inputs, but safety training does not. Given the success of RLHF, it is very plausible that including examples of Base64 inputs in the safety training set would lead to safety on this category of inputs. These together suggest that it is indeed mismatched generalization that drives the success of this attack.\n\n[1] https://arxiv.org/abs/2302.08582  \n[2] https://arxiv.org/abs/2307.09288\n'}}, {'rebuttal': {'value': 'Thank you for your detailed review and constructive feedback! To respond to the points you’ve raised:\n1. **On background on LLMs and safety training.** Thanks for the suggestion—we will provide a more comprehensive review of background in the final version to make the paper more accessible for a broader audience.\n2. **Competing objectives vs. mismatched generalization.** You are correct that these two categories are not mutually exclusive—successful attacks often combine strategies that exploit both. On the other hand, our ablation of the Base64 attack shows that encoded input alone suffices to break safety training in many instances. Thus, prefix injection is not a necessary component of the Base64 attack; the fact that the *input* has unusual formatting suffices.\n3. **Clarification on adaptive attack.** We appreciate the feedback and will elaborate on the description of the adaptive attack in the final version: “To model an adaptive adversary who selects an attack based on the specific prompt, we implemented a straightforward `adaptive’ attack strategy. We consider this attack successful if any one of the 28 different evaluated attacks succeeds at eliciting an on-topic response to the harmful prompt.” Please let us know if this clarification addresses your question.'}}, {'rebuttal': {'value': ""Thank you for your thoughtful review and feedback! We're glad you found the writing and hypotheses compelling. To respond to the points raised:\n1. **On the number of prompts evaluated.** We acknowledge the desire for a more extensive set of prompts. However, our choice of 317 prompts for evaluation is consistent with other studies in this area, such as Shaikh et al. [1], who used 200 synthetic prompts. This number of prompts balances statistical power (see Table 2), API usage cost, and labeling effort.\n2. **On data sharing.** We understand the importance of transparency and agree that wider access to our evaluation dataset could benefit the research community. Due to the potential for misuse (a concern shared by the ethics reviewers for this paper), we have been sharing our dataset upon request rather than openly releasing it. We are committed to ensuring access to any group with a legitimate research use and have already shared our dataset with several research groups in academia and industry who have reached out.\n3. **On possible hypotheses for jailbreak.** You are right in that our mechanisms cover a large fraction, but not all, of the diverse set of known attacks. As in any security setting, there can be a long tail of possible vulnerabilities. We view our contribution as identifying prevalent pitfalls, similar in spirit to how OWASP maintains a list of the top vulnerabilities in web security [2]. We will clarify regarding this in the final version.\n\nAgain, thank you for the review, and let us know if you have any further questions!\n\n[1] https://arxiv.org/abs/2212.08061  \n[2] https://owasp.org/www-project-top-ten/""}}, {'rebuttal': {'value': 'Thank you for your thoughtful review and feedback! To respond to the points you raise:\n\n1. **On studying open-source models.** We highlighted white-box studies involving open-source models as a future direction in the Conclusion because no safety-trained open-source large language models existed at the time of writing, so it would not have been possible to study them. (The first such model, Llama 2 from Meta [1], was released after the end of the NeurIPS review period.) And even with open model weights, there still exists a significant gap between proprietary and open-source datasets/infrastructure for safety training. We nonetheless agree that further investigation with white-box access is an exciting future direction.\n2. **On novelty / existing attacks.** While there are many known jailbreak attacks, our work stands apart in tracing the root causes of these attacks back to the design of training processes. This has let us uncover new attacks, guided by the principles we identify, with our best attacks outperforming those in informal public discourse. Unlike the informal literature, which typically involve a small number of handpicked examples, we provide a quantitative, systematic study of these attacks. Finally, we discussed our results with affected model creators as part of our responsible disclosure process, and their feedback indicated that our results were not only novel, but also interesting and valuable to them.\n3. **On safety training interventions.** As discussed in Section 5, our findings suggest that robust solutions may have to come from beyond the existing pretrain-then-finetune paradigm. In this vein, the approach of Perez et al. to incorporate human preferences *during pretraining* [2] is a promising example that plausibly addresses both failure modes of standard RLHF. We view the development and evaluation of such approaches as an exciting domain for future research.\n\nAgain, thank you for the review, and let us know if you have any further questions!\n\n[1] https://arxiv.org/abs/2307.09288  \n[2] https://arxiv.org/abs/2302.08582'}}, {'rebuttal': {'value': 'Thank you for the thoughtful review of our paper! Responding to the points you raise:\n\n1. **On which models were queried.** Attacks were developed by querying GPT-4 and Claude on a subset of the 32 curated prompts, in line with the threat model described in Section 2.1. In addition, attacks from jailbreakchat.com were likely developed by querying GPT-3.5 and GPT-4, but not Claude, given the state of access at the time. The attacks for the 317 synthetic prompts were the same as those on the curated prompts, so they were not adaptive to the prompts (but they were implicitly adaptive to the model, as they transferred from testing on the curated prompts). Please let us know if this addresses your question–we will add this information to the paper in the final version.\n\n2. **On GPT-3.5 attacks.** To clarify about GPT-3.5 on complex inputs, we observe that GPT-3.5 is unable to respond even to a harmless prompt for many of the more complex attacks—see Table 7 in Appendix D. (We will add this more specific pointer in the final version.) Nonetheless, we agree that the top jailbreakchat.com attacks were likely targeted so that GPT-3.5 could respond to them.\n\n3. **On targeted training.** We used ""targeted training"" to refer to training aimed specifically at certain attacks. Specifically, it appears that Anthropic identified roleplay as a failure mode in their red teaming paper [1] and performed roleplay-specific training for Claude [2]. Our evaluation with Claude highlights that this approach did not address the underlying failure modes, and thus Claude remained vulnerable to other forms of attack.\n\n[1] https://arxiv.org/abs/2209.07858  \n[2] See the documentation for “claude-v1.2” at https://web.archive.org/web/20230519130926/https://console.anthropic.com/docs/api/reference'}}, {'rebuttal': {'value': ""Thank you for the thoughtful and comprehensive review! To respond to the weaknesses and questions that you bring up:\n\n1. **On the focus on two failure modes.** We view simplicity here as a strength rather than a weakness, as we identify two core issues that underlie almost all of the diverse set of known attacks. This is akin to how OWASP maintains a simplified list of the top vulnerabilities in web security [1]. We agree with you that a broader taxonomy could be envisioned—as in traditional security settings, there can certainly exist a long tail of exceptions. (E.g., OpenAI models can also be attacked via the system prompt / OpenAI's Chat Markup Language.)\n\n2. **On black-box only access.** We highlighted white-box studies involving open-source models as a future direction in the Conclusion because no safety-trained open-source large language models existed at the time of writing, so it was not possible for us to investigate them. (The first such model, Llama 2 from Meta [2], was released after the end of the NeurIPS review period.) And even with open model weights, there still exists a significant gap between proprietary and open-source datasets/infrastructure for safety training. We agree that further investigation with white-box access is an exciting future direction.\n\n3. **On combinations of attacks.** We believe that training should address underlying failure modes rather than specific attacks. Addressing these fundamental failure modes would likely render combinations of attacks ineffective. As an example, the approach of Perez et al. [3] to incorporate human preferences during pretraining could plausibly address both failure modes.\n\n4. **On safety-capability parity.** By safety-capability parity, we mean that models performing safeguarding should be comparable (or stronger) in capabilities to the model being safeguarded. For instance, we envision language models as a necessary component of the safety pipelines of future systems, which contrasts with more primitive techniques like word filters.\n\n5. **On jailbreakchat.com attacks.** The attacks from jailbreakchat.com are italicized in Table 1. Specifically, they are labeled as AIM, evil_system_prompt, dev_mode_v2, dev_mode_with_rant, and evil_confidant.\n\nWe hope these clarifications address your concerns—we are also happy to engage in further discussions to enhance the paper. Thank you again for the insightful comments!\n\n\n[1] https://owasp.org/www-project-top-ten/  \n[2] https://arxiv.org/abs/2307.09288  \n[3] https://arxiv.org/abs/2302.08582\n""}}, {'summary': {'value': ""The paper investigates two reasons why jailbreak attacks against SOTA LLMs (GPT-4, GPT-3.5 Turbo, Claude v1.3) succeed despite extensive safety training: a) competing training objectives (safety objectives vs. pretraining/instruction tuning) and failure of safety training to generalize to conditions covered by pretraining/instruction training but not safety training. These two modes are then used as guiding principles to design new jailbreak attacks that are empirically evaluated against the above three models, starting from both known and newly synthesized harmful prompts; a large number of these attacks are shown to have a high success rate. The authors provide concluding hypotheses regarding future work to defend against attacks (more sophisticated safety models that match the models' basic capabilities). ""}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper aims to examine jailbreak attacks in a more principled way and presents an empirical evaluation that is broader in scope than previous studies. Though the insights are not entirely surprising, the paper does a good job explaining and exemplifying the two failure modes, evaluating SOTA models along those axes, and providing quantitative results. Although the failure modes are intuitively clear and have been known informally by most developers of LLMs, it is valuable to see a concise formulation of the problems and a fairly thorough experimental study.The paper offers high-level suggestions for how to do red-teaming or safety training more effectively and as such would be valuable for the community. \nThe presentation is very clear; authors observe responsible disclosure practices and have discussed potential ethical considerations (recipes for creating jailbreak attacks).\n\n'}, 'weaknesses': {'value': ""1. The paper focuses on two failure modes only. Arguably these could be the most important ones, but the bigger question is whether one could come up with a more comprehensive taxonomy of failure modes. The paper doesn't discuss this in more detail.  \n2. Many of the observations and conclusions are by necessity tentative and unconfirmed, due to black-box only access to models. The authors could have verified their hypotheses more directly by using a smaller open-source model where more details about training conditions and data resources are available. This setup could also have been used to explore the space of failure modes more systematically (e.g., what role does decoding play?). \n3. The most successful attacks were combinations, but those were not studied in detail from a conceptual point of view- this seems to merit an entirely separate discussion: since there's a combinatorial space of combined attacks, how could models be trained successfully to defend against these? \n4. The 'safety-capability' parity point remains vague - what does this mean for the actual safety model, are there concrete mechanisms you could suggest to make models more 'sophisticated'? \n\nIt would be good to see more discussion of at least points #1 and #3 in the paper. ""}, 'questions': {'value': ""It's not clear to me where the attacks from jailbreakchat.com (p. 7) land in Table 1 -- which ones does this map to? ""}, 'limitations': {'value': 'The authors discuss the limitations (e.g., no access to models themselves, hence tentative conclusions) but in the light of these they could have opted to also include some targeted experiments with open-source models (relegated to future work in the paper). '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper studies jailbreaking of large language models. The authors identify two categories of causes of jailbreaks, competing objectives and mismatched generalization, and use this insight to analyze existing jailbreaks and construct new ones. They empirically study the effectiveness of these jailbreaks on state-of-the-art models that have been trained to refuse unsafe instructions, and draw several conclusions from their analysis.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'Jailbreaks pose an important safety problem for publicly-deployed AI systems. The conceptual analysis is novel and insightful, and the experiments are careful and thorough. The conclusion about safety-capability parity is especially interesting. Moreover, merely demonstrating extremely successful attacks directly helps companies deploying models to make their models safer via responsible disclosure. The paper is also very well-written.'}, 'weaknesses': {'value': 'The main weakness of the paper, which is easily rectified, is that the authors do not clarify (unless I somehow missed it) which if any models were queried as part of the construction of the attacks, or more broadly if the attacks have any particular intended target model. It seems reasonable to query a model when constructing an attack since the threat model allows this, but the information should be provided as it is needed to properly interpret the results of the paper. I don\'t think anything long and detailed is necessary if the process was somewhat ad-hoc, but some indication is necessary I think.\n\nAs a case in point, the paper interprets the results on GPT-3.5 (Table 3) as ""GPT-3.5 not having the capability to understand complex inputs"" (p. 8 line 336). However, I suspect that a more likely explanation of why the top 4 attacks are all attacks from jailbreakchat.com is that they specifically targeted at GPT-3.5 (since that version of ChatGPT is free-to-use and hence likely much more popular).\n\nI also disagreed slightly with some of the claims in the section ""What Scaling Won\'t Solve"" (p. 8 line 350). The authors argue that scaling will not solve the problem of competing objectives, since the objectives will still compete. However, larger models may be able to obtain Pareto improvements on both objectives. Hence even though the competition between the objectives may remain, the models may still perform as well as necessary on the safety objective. Nevertheless, I did agree with the argument that scaling alone will not solve the problem of mismatched generalization (not counting using the models to generate stronger attacks, which is discussed later).\n\nMinor point: in the phrase ""targeted training is insufficient"" (p. 8 line 325), the term ""targeted training"" is not defined. I initially interpreted it to mean ""adversarial training"" (which the results do not demonstrate is necessarily insufficient), whereas I think the authors mean ""adversarial training that only targets a subset of the possible failure modes"" (which it is unsurprising is insufficient, though I suppose it might still be worth noting).'}, 'questions': {'value': 'No questions other than those given above'}, 'limitations': {'value': 'No limitations other than those given above'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper analyzes why safety training of LLMs fail and what could be the root causes for them. They offer two explanations: competing objectives and inadequate coverage of the model capabilities during safety training. They categorize existing attacks and propose some new ones into these two buckets, and evaluate GPT-4 and Claude v1.3. The results show that both the models are susceptible to jailbreaks. \n\nPost-rebuttal comment: The authors addressed my concerns. I am happy to keep my score of weak accept.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': 'I am broadly in agreement with the explanations put forth in this paper. The paper is written quite precisely and in a convincing manner. The experiments show that most of the 317 prompts constructed can be used in combination with one of the methods to successfully jailbreak.'}, 'weaknesses': {'value': ""The paper is mainly about evaluation of the models and the difficulty ahead of the defenses. While it is informative, it would have strengthened the paper to try some experiments and ablations on safety training (e.g., trying to remedy the mismatch in pretraining and safety-tuning in some ways). I can imagine the difficulty of experimenting with large, closed-source models, but some experimentation with small/medium open-source models would have helped.\n\nMy other concern is how much of the material in the paper is novel. Several of the existing attacks may have identified these or equivalent root causes and I am unable to clearly estimate how much of the paper's content is novel/surprising.""}, 'questions': {'value': 'What specific explanations and observations in the paper are novel when the existing attacks are taken in account?\n\nDo you have any analysis of safety training interventions based on your identification of the key limitations of the current methods?'}, 'limitations': {'value': 'The authors have discussed the limitations and societal impact. They have also reported that they have disclosed their findings to the model authors and will coordinate the future release of the specific attacks with them to avoid harm. I appreciate these efforts.'}, 'flag_for_ethics_review': {'value': ['Ethics review needed: Inappropriate Potential Applications & Impact  (e.g., human rights concerns)', 'Ethics review needed: Responsible Research Practice (e.g., IRB, documentation, research ethics)']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper evaluates GPT models and Claude models against Jailbreaks and comes up with two possible explanations for why jailbreaks are successful- 1. competing objectives between pretraining + IF finetuning and safety finetuning; and 2. pretraining+finetuning generalizing better than safety tuning. It also argues for safety-capability parity and that we need to move beyond the pretraining + post-training for safety paradigm to come up with more sophisticated methods for safety training. '}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': ""Strengths:\n1. Very clearly and well written; enjoyable read\n2. Makes intuitive+compelling hypotheses around why jailbreaks are successful and makes them explicit and clear; provides evidence supporting the hypotheses\n3. The safety-capability parity claim the paper makes is important and it's presented well with evidence for why its needed\n4. I think the paper is significant given that it makes a compelling argument for why the current paradigm of safety finetuning won't scale and with good evidence for it. The evaluations and hypotheses are quite intuitive +  based on existing work but I think the presentation of this work in the paper and the narrative it creates is compelling and important.""}, 'weaknesses': {'value': 'Weaknesses: \n1. Evaluations could be more robust and have a higher quantity of prompts\n2. The main claims and methods are interesting and well-presented but not particularly surprising / novel \n3. It should make clear that the two possible hypotheses are two reasons for jailbreaks but not the entire surface area of possible reasons \n'}, 'questions': {'value': 'It would be great if more data is added to evals and the evals are made transparent + available for everyone'}, 'limitations': {'value': 'Yes'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This manuscript provides an initial exploration of the robustness of LLM systems against adversarial misuses, specifically focusing on ""jailbreak"" attacks. The authors successfully summarize existing threats, propose plausible hypotheses, and conduct empirical evaluations on three LLMs: GPT-4, Claude v1.3, and GPT-3.5. They identify two failure modes in the current safety training: Competing Objectives and Mismatched Generalization. The paper concludes by deriving valuable defense implications from their analysis and evaluations. Overall, this submission initiates a constructive discussion on the development of safe LLM systems.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper addresses a timely and significant topic. The authors carefully examined the problem, presented their hypotheses, and supported them with well-designed empirical experiments. Helpful defense implications are also provided following the analyses. '}, 'weaknesses': {'value': ""Certain sections of the writing could be refined to improve comprehension for a general audience. For example, the introduction to the current safety training mechanism and the general LLM training framework lacks sufficient detail, which may hinder readers' understanding of the concepts of Competing Objectives and Mismatched Generalization. Furthermore, the significance of the paper is constrained by the absence of direct access to detailed information regarding LLMs they use in their paper.""}, 'questions': {'value': ""1. Section 2.2 primarily focuses on the detailed description of the models and datasets used in the authors' evaluation. Will it be better placed in Section 4.\n\n2. There appears to be some overlaps between Competing Objectives and Mismatched Generalization. For example, both the use of encoded output in Base64 and requesting unusual output formats may exploit prefix injection. Can you better explain the relationship between these two failure modes?\n\n3. The description of the Adaptive Attack in Section 4.1 lacks clarity.\n""}, 'limitations': {'value': 'The author discussed the limitation arising from the lack of detailed information on LLMs, thus their hypotheses cannot be directly confirmed. '}, 'flag_for_ethics_review': {'value': ['Ethics review needed: Privacy and Security (e.g., consent, surveillance, data storage concern)']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper studies jailbreak attacks. More specifically authors hypothesize two failure modes of LLMs 1. competing objective and 2. mismatched generalization and base their discussion on why jailbreak attacks succeed based on these hypothesis made. They then quantitatively perform experiments on different jailbreak attacks and report the success of each.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': '1. The paper studies a timely and important topic.\n2. The observations/discussion on competing objectives was interesting.'}, 'weaknesses': {'value': '1. I would have liked to see more in depth and concrete discussions on what could be done to improve these systems against jailbreak attacks and even maybe the execution of this idea in small scale would have made the paper very strong.\n\n2. The dataset discussion in section 2.2 could be more organized and clear with more detailed discussions to increase clarity.\n\n3. I felt like the results do not directly support claims made in the paper in the sense that jailbreaks happen due to the two reasons 1.competing objectives And 2.mismatched generalization hypothesized by the authors. The quantitative results mostly show the success of the jailbreaks which is a nice finding on its own and mostly known, but they do not directly support the claims that these attacks are successful and happen due to competing objectives and mismatched generalization. Moreover, there might be other contributors not considered in this work. Although authors provide discussions and tie these jailbreaks to the hypothesized reasons in section 3, in my opinion analysis in section 4 does not strongly and directly support those claims. Maybe the paper needs to be motivated in some other way or written in a different manner so that claims are supported and reflected accurately in the experimental discussions and results.\n\n**Minor comments:**\nTypo line 288 ( such an attack is technically is beyond the scope of our threat model -> such an attack is technically beyond the scope of our threat model).\n'}, 'questions': {'value': 'Addressing my first and third concerns in the weaknesses section would be good.'}, 'limitations': {'value': 'Authors provided a discussion on limitations and broader impacts of their work which is appreciated.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper offers an insightful examination of adversarial misuse, or ""jailbreak"" attacks, against large language models (LLMs) such as OpenAI\'s GPT-4 and Anthropic’s Claude v1.3. By analyzing two proposed failure modes of safety training—competing objectives and mismatched generalization—the authors provide an empirical study of why these attacks can succeed and how they might be created. \nNevertheless, this paper could be critiqued for a lack of novel methodological or technical insights. \n\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': 'This paper provides a comprehensive examination of the vulnerabilities in large language models (LLMs) to ""jailbreak"" attacks.'}, 'weaknesses': {'value': 'I enjoyed reading the extensive experimental results and inspiring observations. The main reason I did not raise a higher score is that the paper seems to lack rigor in defining key concepts and quantifying its statements. \n\nFor example, the paper did not precisely define what a jailbreak attack is in the context of LLM. It is unclear what is safe/unsafe since that can be quite subjective. In making ""analysis"", e.g., ""Competing Objectives"" in Section 3.1, the paper only provided selected examples rather than formalism.  \n\nI feel the empirical studies are not sufficient to publish because there have been many existing empirical studies on jailbreaks and this paper does not distinguish itself from the rest with more in-depth formalism.  \n \nHowever, I could be biased. So I can adjust scores after reading other review comments and authors\' responses.'}, 'questions': {'value': 'none'}, 'limitations': {'value': 'technical insights or novel method '}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Jailbroken: How Does LLM Safety Training Fail?'}, 'authors': {'value': ['Alexander Wei', 'Nika Haghtalab', 'Jacob Steinhardt']}, 'authorids': {'value': ['~Alexander_Wei2', '~Nika_Haghtalab2', '~Jacob_Steinhardt1']}, 'keywords': {'value': ['red teaming', 'safety', 'RLHF', 'large language models']}, 'abstract': {'value': 'Large language models trained for safety and harmlessness remain susceptible to adversarial misuse, as evidenced by the prevalence of “jailbreak” attacks on early releases of ChatGPT that elicit undesired behavior. Going beyond recognition of the issue, we investigate why such attacks succeed and how they can be created. We hypothesize two failure modes of safety training: competing objectives and mismatched generalization. Competing objectives arise when a model’s capabilities and safety goals conflict, while mismatched generalization occurs when safety training fails to generalize to a domain for which capabilities exist. We use these failure modes to guide jailbreak design and then evaluate state-of-the-art models, including OpenAI’s GPT-4 and Anthropic’s Claude v1.3, against both existing and newly designed attacks. We find that vulnerabilities persist despite the extensive red-teaming and safety-training efforts behind these models. Notably, new attacks utilizing our failure modes succeed on every prompt in a collection of unsafe requests from the models’ red-teaming evaluation sets and outperform existing ad hoc jailbreaks. Our analysis emphasizes the need for safety-capability parity—that safety mechanisms should be as sophisticated as the underlying model—and argues against the idea that scaling alone can resolve these safety failure modes.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'Competing objectives and mismatched generalization lead to jailbreak attacks on safety-trained LLMs.'}, 'pdf': {'value': '/pdf/6ef6c4c838351879286475fe5c123aad6815fb02.pdf'}, '_bibtex': {'value': '@inproceedings{\nwei2023jailbroken,\ntitle={Jailbroken: How Does {LLM} Safety Training Fail?},\nauthor={Alexander Wei and Nika Haghtalab and Jacob Steinhardt},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=jA235JGM09}\n}'}, 'paperhash': {'value': 'wei|jailbroken_how_does_llm_safety_training_fail'}}]"
"['Ajay Subramanian', 'Elena Sizikova', 'Najib Majaj', 'Denis Pelli']",NeurIPS,"Spatial-frequency channels, shape bias, and adversarial robustness",https://neurips.cc/virtual/2023/oral/73860,2023," What spatial frequency information do humans and neural networks use to recognize objects? In neuroscience, critical band masking is an established tool that can reveal the frequency-selective filters used for object recognition. Critical band masking measures the sensitivity of recognition performance to noise added at each spatial frequency. Existing critical band masking studies show that humans recognize periodic patterns (gratings) and letters by means of a spatial-frequency filter (or ""channel"") that has a frequency bandwidth of one octave (doubling of frequency). Here, we introduce critical band masking as a task for network-human comparison and test 14 humans and 76 neural networks on 16-way ImageNet categorization in the presence of narrowband noise. We find that humans recognize objects in natural images using the same one-octave-wide channel that they use for letters and gratings, making it a canonical feature of human object recognition. Unlike humans, the neural network channel is very broad, 2-4 times wider than the human channel. This means that the network channel extends to frequencies higher and lower than those that humans are sensitive to. Thus, noise at those frequencies will impair network performance and spare human performance. Adversarial and augmented-image training are commonly used to increase network robustness and shape bias. Does this training align network and human object recognition channels? Three network channel properties (bandwidth, center frequency, peak noise sensitivity) correlate strongly with shape bias (51% variance explained) and robustness of adversarially-trained networks (66% variance explained). Adversarial training increases robustness but expands the channel bandwidth even further beyond the human bandwidth. Thus, critical band masking reveals that the network channel is more than twice as wide as the human channel, and that adversarial training only makes it worse. Networks with narrower channels might be more robust.",Oral 6C Vision,https://openreview.net/pdf?id=KvPwXVcslY,https://openreview.net/forum?id=KvPwXVcslY,KvPwXVcslY,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'In this paper, the authors examine the properties of image recognition systems in order to better understand their divergence from the human visual system. In particular, the authors focus on a well-established procedure from psychophysics, termed critical band masking, to measure the sensitivity to spatial frequencies for humans and deep neural networks. The authors find that humans recognize objects including letters and gratings within one octave of spatial frequency. Conversely, across 76 neural networks the authors find that the networks recognize objects using a much wider bandwidth (i.e. >2x in bandwidth). The result of this observation is that neural networks are more sensitive to noise and adversarial attacks in spatial frequency regimes in which humans are insensitive.\n\nThe authors further identify that the empirically observed channel properties of neural networks may explain a good fraction of shape bias (53%) and robustness in adversarially trained networks. The reviewers commented positively on the motivation and design of the experiments, the quality and strength of the results, and the clarity of presentation. The reviewers also identified some concerns about the applicability of these results to future network design, and the lack of related work in the paper. The authors agreed to add a Related Work section and discuss more about the applicability and impact of these results on future network designs. Given that unanimous consensus of the reviews, this paper will be accepted to this conference. I took the opportunity to review this paper as well and was impressed by the overall experimental design and the potential to provide an important direction for future research in computer vision. For these reasons, I have recommended this paper for an oral presentation.'}}, {'title': {'value': 'Robustness re-evaluation'}, 'comment': {'value': 'Thank you for the reminder and apologies for the delay in running the analysis.\n\nWe re-plotted Figure 6B in the paper (Whitebox accuracy Vs Channel properties) using the adversarial attack hyperparameters that you recommended (20-step PGD with $\\epsilon$=4/255). For non-adversarially trained networks, we see the same trend as before -- bandwidth is lower for networks with higher whitebox accuracy. But for adversarially trained networks, we no longer see what we saw with our previous attack parameters -- there is no significant correlation (with bonferroni correction) between whitebox accuracy and channel bandwidth.\n\nWe think this absence of correlation is mainly because the new attack is much weaker than our old attack (32-step PGD with $\\epsilon$=0.1), and so we see almost no difference in whitebox accuracy for networks with drastically different amounts of adversarial training. In other words, even relatively weak adversarial training is able to make networks robust to the new attack.\n\nGiven that, as you said, the new attack is the more popular one, we will make sure to include this result in the supplementary material and reference it in the results section of the main paper. Thanks again for suggesting it!\n\nAlso, regarding your comment about evaluation only on ImageNet, we will make sure to mention the caveat that our results apply to ImageNet and not to real-world vision, to our Introduction section, although ImageNet is often used as a proxy in existing work for natural-world-like image datasets.'}}, {'title': {'value': 'Robustness?'}, 'comment': {'value': 'Any there any updates on the reevaluated robustness?'}}, {'comment': {'value': 'Thank you for the detailed responses to my questions. The analysis presented in the new Fig2 of the attached pdf is valuable, as it allows the reader to understand that the decrease in accuracy from color to gray and low-contrast gray does not adversely affect the findings for most models. I do not have further questions for the authors.'}}, {'title': {'value': 'rebuttal read!'}, 'comment': {'value': 'Sorry that your rebuttal will not cause me to raise my score! ;-)'}}, {'title': {'value': 'Typo in new related work section'}, 'comment': {'value': 'ImageNet-pretrained convolutional networks, on the other hand, are biased towards shape (Geirhos et al., 2018, Baker et al., 2018).\n->\nImageNet-pretrained convolutional networks, on the other hand, are biased towards texture (Geirhos et al., 2018, Baker et al., 2018).'}}, {'title': {'value': 'Thanks for the answers.'}, 'comment': {'value': 'Dear authors,\nI sincerely thank you for your clear answers, especially regarding putting the significance of your work into perspective. Your rebuttal is very clear and with good argumentations. I also read the reviews made by colleagues, and your rebuttal to them.\nI liked very much the perspective you gave about the relation between neural networks and human visual system, and how your results might be useful to improve networks in the future.\n\nAbout the ethics statement: I realize that my request made no sense wrt confidentiality of the submission. I will remove the flag.\n\nIn summary, I appreciate the clarifications and I am willing to raise my score to Accept. \n'}}, {'comment': {'value': ""Thank you! Yes, fair point, we'll fix these issues.""}}, {'title': {'value': 'Thank you for your efforts!'}, 'comment': {'value': 'Thank you for your efforts! The rebuttal addresses most of my issues. Remaining issues:\n1. I am looking forward to the updated robustness results\n2. Regarding ""Evaluation only on ImageNet"". I am afraid that just updating the conclusion is not enough. There are multiple sections in the paper that strongly suggest that your findings scale to the detection of objects in general (e.g., L38). It would be more honest to clarify the scope of your results early on.'}}, {'title': {'value': 'Thanks'}, 'comment': {'value': 'I would like to thank the authors for their detailed reply.\n\nI particularly appreciated that they corrected the alpha level for multiple comparisons and provided the updated plot, and explanations regarding experimental methods. Overall, I am satisfied with the author\'s response and promised edits to the paper. Some experimental weaknesses remain - e.g. in terms of monitor calibration hoping is great, measuring is better - but those are inherent to the online study design and cannot be expected to be resolved in a rebuttal. My final score is ""7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations."" and I strongly support publication at NeurIPS.'}}, {'rebuttal': {'value': 'Dear Reviewers kLx7, QrRK, 9K3N, vBv1 and TCTa\n\nThank you for your thoughtful reviews, with scores ranging from 4 to 10. The paper seems much improved by our efforts to respond to your questions and comments. We are particularly grateful for the explicit questions asking us how our work can be used by deep learning practitioners. Briefly, our paper provides evidence suggesting that efforts to robust-ify a network should look for ways to narrow its critical band. Most of you requested exposition of limitations and related work, which we now provide. Some of you also requested additional analyses of the statistical significance of our results, which we now provide. Reviewer TCTa had technical questions about online testing, to which we provide detailed responses addressing the concerns. We are planning to look at the influence of training and architecture on our results, similar to what reviewers suggested. Finally, as requested by two reviewers, data from two poorly performing participants was removed. Detailed responses follow.\n\nAdditionally, please find a PDF attached with helper figures. These are referenced and described in our individual responses to reviewers.\n\nFinally, owing to lack of available space in individual responses, we post the modified Related work section as a common response to all reviewers.\n\n**RELATED WORK**\n\n**Spatial-frequency channels.** The visual system detects periodic patterns or gratings by means of parallel visual filters, each tuned to a band of spatial frequency (Campbell & Robson, 1968). Critical band masking  studies (Fletcher, 1940) revealed that the same single, narrow filter also mediates the recognition of letters (Solomon & Pelli, 1994; Majaj et al., 2002; Oruc & Landy, 2009), faces, and novel shapes (Oruc & Barton, 2010). Artificial neural networks also have frequency-based preferences. They are biased towards learning low-frequency functions (Rahaman et al., 2019) and prone to shortcut learning in both spatial and frequency domains (Geirhos et al., 2020; Wang et al., 2022). Existing work also suggests that robustness of a network is related to its spatial-frequency preferences (Wang et al., 2020; Li et al., 2023, Yin et al., 2019, Gavrikov et al., 2023, Abello et al., 2021).\n\n**Shape bias.** Humans are well known to rely mainly on shape features for lexical learning and object recognition tasks (Landau, Smith & James, 1992; Geirhos et al., 2018). ImageNet-pretrained convolutional networks, on the other hand, are biased towards shape (Geirhos et al., 2018, Baker et al., 2018). Although imagenet-pretrained transformers, like humans, are shape-biased (Tuli et al., 2021), texture-vs-shape bias of networks is thought to be influenced mainly by training data and its augmentations rather than network architecture (Hermann et al., 2021).\n\n**Adversarial robustness.** Adversarial attacks are small perturbations that cause inputs to be misclassified. (Szegedy et al., 2014, Nguyen et al., 2015). Although these perturbations are often imperceptible to humans, humans can in some cases decipher adversarial examples (Elsayed et al., 2018, Zhou & Firestone, 2019). Recent work suggests that adversarial robustness of networks relates to their spatial frequency tuning (Bernhard et al., 2021; Li et al., 2023, Maiya et al., 2021). \n\n**Comparing human and neural network vision.** The origins of deep learning are strongly tied to neuroscience (Fukushima, 1982) and the modern convolutional network architecture was inspired by properties of the primate visual cortex (Riesenhuber & Poggio, 1999). More recently, there have been parallel efforts both to use neural networks to improve models of visual neuroscience (Yamins & DiCarlo 2016, Khaligh-Razavi & Kriegeskorte 2016, Schrimpf et al., 2018) and to improve network robustness by taking inspiration from the human visual system (Dapello et al., 2020). These lines of work strongly rely on recent advancements in model-human comparison metrics which compare networks and humans across behavior (Geirhos et al., 2021, Feather et al., 2022) and neural representations (Schrimpf et al., 2018, Kriegeskorte et al., 2008).\n'}, 'pdf': {'value': '/pdf/314509b104690af018e51cd53adccc8c3f2c99f9.pdf'}}, {'rebuttal': {'value': '**Strengths:**\n\n>Overall, I really liked this study...\nThank you!\n\n**Weaknesses:**\n\n>Significance testing:\n\n>Figure 6 does not correct for multiple comparisons...\n\nDone. We applied the correction to our results and do not see any change in any of the results discussed in the paper. There were a few minor changes however, which are reflected in the modified figure Fig. 3 shown in the attached PDF.\n\n>Human experimental weaknesses:\n\n>In human visual perception, spatial frequency is...\n\nGood point. We estimate that the viewing distance of online observers varies over a 2:1 range, 40 to 80 cm because <40 requires an uncomfortable accommodative effort and >80 makes it impossible to reach a laptop keyboard. However, human vision, to a first approximation, scales with image size. Majaj et al. 2002 measured the tuning of spatial frequency channels as a function of letter size and found a slight deviation whereby the channel frequency slightly less-than-doubles ($2^{\\frac{2}{3}}$) when the letter size is halved. Thus, a large 2:1 variation in viewing distance will produce a small ($2^{\\frac{1}{3}}=1.26:1$) variation in channel center frequency in cycles per image. Thus, the uncontrolled variation in viewing distance contributed only slightly to the 2:1 bandwidth that we measured.\n\n>No information on monitor calibration...\n\nWe plan to add the following to Methods.\n\n*Nearly all of our online observers will have been looking at digital displays. The ICC specified standards for color management that require a provision of an ICC profile characterizing the properties of each display (including gamma and color primaries). The HTML <img command in all modern browsers invokes color management (if enabled) to display images faithfully. Thus, the computer screens will have varied in luminance from backgrounds of 200 to 500 nits but we expect contrast to have been accurate.*\n\n*Furthermore, even if the display gamma is other than assumed (because color management was not enabled), the too high or too low contrast will affect both signal and noise equally with practically no effect on signal-to-noise ratio (SNR). It is well established that the human energy threshold grows linearly with noise power spectral density so that when the noise is strong, doubling or halving display contrast hardly affects target recognition (Pelli & Farrell, 1999).*\n\n>Human experiments with reduced contrast...\n\nYes, it is true that the change of background luminance will change the level of light adaptation. However, our results depend on contrast, not luminance, and so will not be affected.\n\n>Given the online study setup, how did the authors...\nWe did ask our participants if they have normal or corrected-to-normal vision. In principle, one could measure acuity as a check. However, this is how most online vision studies are done.\n\n>Two of the 16 observers (supplementary Figure 2)...\n\nYes, good point. We have removed those two observers (9 and 13) from all analyses in the paper. Our main results remain the same.\n\n**Questions:**\n\n>What is going on with the two outlier...\n\nThanks for pointing this out. Answered above.\n\n>Given that some networks have severely...\n\nFig. 2 from the attached PDF will be added to the paper’s supplementary material and will be referenced in the main paper. This figure shows the percent correct values of each network we tested for each of 3 image conditions: color, gray, and low-contrast gray. Of the 88 networks available in our source datasets, 12 were below threshold for low-contrast gray images, which made them impossible to test on our critical band masking task. For the remaining 76, the change in performance from the color to gray to low-contrast gray condition is very small.\n\n>Major opportunities for improvement:\n\n>(The study is already quite solid...\n\n>""we propose that critical band masking...\n\nYes, we strongly intend to do so in the near future.\n\n>The authors show that properties of...\n\n>The reasons for the human-model divergence...\n\nIndeed, we are very interested in examining how our results are influenced by training settings, and this is something we intend to pursue next. We will modify our Discussion and Conclusion sections as follows.\n\n*DISCUSSION: Every one of the 76 networks we tested has a wide critical band. We tested all the networks from Geirhos et al., 2021 which is the largest comparison of networks and humans on object recognition. The Geirhos study included most of the popular network kinds, spanning a wide range of conditions: convolutional networks and transformers, shallow and deep networks, supervised and self-supervised training, standard and adversarially-trained networks. Thus, the conclusions of this paper are based on a representative sample of popular network designs. More work is required to explore the effects of diverse kinds of training data and augmentation.*\n\n*CONCLUSION: … are based on a representative sample of popular network designs. More work is required to explore the effects of diverse kinds of training data and augmentation.*\n\n>Minor questions:\n\n>line 86...\n\nThis will be corrected in the revised manuscript, thanks.\n\n>why ""roughly equally distributed...\n\nWe say roughly distributed because the number of images in our testbed (1100) is not exactly divisible by 16. So we distribute 1088 (16 * 68) images equally and the remaining 12 are chosen at random from all categories. We will modify Methods to include this detail.\n\n**Limitations:**\n\n>The authors don\'t have a section on limitations...\n\nDone. We have added a discussion of limitations to the Conclusion section. Copied below.\n\n*While our results are based on a large, representative sample of popular network designs, more work is required to explore the effects of diverse kinds of training data and augmentations. Additionally, our current results are purely correlational, and such experiments would also help determine if the relationship between channel properties and robustness is also causal.*\n'}}, {'rebuttal': {'value': '**Strengths:**\n\n>Originality\n\nThe paper explores a less common yet highly important research direction. Some ""model"" findings were partially reported in literature, but for the most part the findings are highly original.\n\n>Quality\n\nThe submission is of high quality (minor weaknesses see below). The authors rigorously conduct (well-documented) human experiments and benchmark 76 ImageNet models to arrive at their conclusions.\n\n>Clarity\n\n>The paper is very well written. Key points are communicated clearly through writing and figures.\n\n>Significance\n\n>The authors share many findings, that may be of great interest to the NeurIPS community. In particular, they measure the human critical channel and show that models measure higher bandwidths. Adversarial Training increases the channel even further. Generally, they find correlations between channel properties and shape-bias/robustness that may lead to a new perspective on robustness but also shows another misalignment between humans and models.\n\nThank you!\n\n**Weaknesses:**\n\n>Method\n\n>Evaluation only on ImageNet: I never thought...\n\nThank you for raising this point. Our revised conclusion section will mention this as a limitation, as follows.\n\n*While our results are based on a large, representative sample of popular network designs, more work is required to explore the effects of diverse kinds of training data and augmentations. Additionally, our current results are purely correlational, and such experiments would also help determine if the relationship between channel properties and robustness is also causal.*\n\n>Poor choice of robust networks...\n\n>Minor: uncommon choice of parameters for robustness analysis...\n\nThank you for these suggestions. We are working on running it with these parameters, and will try to share updates during the discussion period.\n\n>Novelty\n\n>Some claims/observations in the submitted draft were already published. This does not invalidate the (exceeding) contributions of this paper, but the respective works should at least be mentioned. [2] already performed band-masking to study the critical bands of CNNs, [1] discussed how frequencies interact with shape-bias.\n\nDone. We have written a Related work section (please see our common response to all reviewers) that will be added to the manuscript.\n\n>Others\n\n>The authors use 76 pretrained models only partially citing them. The Paper Checklist clearly states to cite all the used assets.\n\nDone. All evaluated models will be cited in the revised text.\n\n>Authors do not discuss limitations\n\nDone. We have added a discussion of limitations to the Conclusion section, as mentioned above. Copied below again for your reference.\n\n*While our results are based on a large, representative sample of popular network designs, more work is required to explore the effects of diverse kinds of training data and augmentations. Additionally, our current results are purely correlational, and such experiments would also help determine if the relationship between channel properties and robustness is also causal.*\n\n>Minor: The authors repeatedly claim that transformers are shape-biased...\n\nThank you for pointing this out. We will change all occurrences of this statement to talk about “Imagenet-pretrained transformers)” instead of transformers in general.\n\n**Questions:**\n\n>Are there any insights on whether improving the alignment between the model critical channel compared to humans would improve robustness or shape-bias, i.e. is there evidence of causality and not only correlation?\n\n>Did the authors attempt to encourage alignment in training?\n\nIndeed, we are very interested in examining how our results are influenced by training settings, and this is something we intend to pursue next. We will modify our Discussion and Conclusion sections as follows.\n\n*DISCUSSION: Every one of the 76 networks we tested has a wide critical band. We tested all the networks from Geirhos et al., 2021 which is the largest comparison of networks and humans on object recognition. The Geirhos study included most of the popular network kinds, spanning a wide range of conditions: convolutional networks and transformers, shallow and deep networks, supervised and self-supervised training, standard and adversarially-trained networks. Thus, the conclusions of this paper are based on a representative sample of popular network designs. More work is required to explore the effects of diverse kinds of training data and augmentation.*\n\n*CONCLUSION: … are based on a representative sample of popular network designs. More work is required to explore the effects of diverse kinds of training data and augmentation.*\n\n>Are there any observations on other datasets?\n\nNot yet, but we plan to look at other datasets, as mentioned above in our modified discussion and conclusion sections (above). For now, we have considered only ImageNet since it is the most popular dataset for the evaluation of object recognition systems.\n'}}, {'rebuttal': {'value': '**Strengths:**\n\n>Use of a novel approach to analyze neural networks: the critical band masking…\n\n>Extent of models considered in the analysis …\n\nThank you!\n\n**Weaknesses:**\n\n>Usefulness and outlook of the results: …\n\nThank you for raising this important point. We agree that the significance of the paper for engineering applications isn’t completely clear in the current manuscript. To resolve this, we will add the following text to both the abstract and conclusion of the paper.\n\n*We show that the idea of a critical-band offers a spatial-frequency-based explanation of shape bias and adversarial robustness. Thereby, our paper provides evidence suggesting that efforts to make a network more robust should look for ways to narrow its critical band.*\n\n>Relation between HVS and neural networks…\n\n*When comparing biological vision and artificial neural networks, there are two questions to be asked: what can artificial networks learn from biology, and how can neural networks inform our understanding of biology (LeCun, Bengio & Hinton, 2015; Schrimpf et al., 2018). Needless to say, the origins of deep learning relied heavily on knowledge of biology (Fukushima, 1982). But can biology impact the evolution of neural networks? Dapello et al., (2020) showed that making the first layer’s tuning match biological V1 tuning improves robustness. The critical band idea is central to understanding hearing and vision. Here we show that the critical bands, which are a measure of tuning, are different between humans and networks, and that this difference strongly explains robustness (shape bias and adversarial robustness) of networks. Thus, the results presented here are evidence that narrowing the machine critical band to match that of humans may make neural networks even more robust.*\n\nThis text will be added to the discussion section in the revised manuscript. \n\n>Details about the methodology are missing: e.g. is the…\n\nNoise was generated by making an array of independent identically distributed Gaussian noise samples. This has a white spectrum and random phase. The white noise was then band-pass filtered. We did all of our experiments with random phase noise. Indeed, both machines and humans care a lot about phase while recognizing objects. We will include a sentence about this in the Discussion section.\n\n>Placement in the literature is very limited...\n\nDone. We have written a Related work section (please see our common response to all reviewers) that will be added to the manuscript.\n\n**Questions:**\n\n>Can the authors clarify details about the method and experimental analysis…\n\nAnswered above in the Weaknesses section.\n\n>Can the authors clarify the motivations why neural networks …\n\nAnswered above in the Weaknesses section.\n\n>How does the work related to actual existing work on...\n\nAnswered above, in the newly added related work section.\n\n>and why aspects such as energy efficiency, memory, and ‘training’? are not taken into account?\n\nThank you for raising this point. We agree that these are all interesting points that should be analyzed, and is something we intend to pursue next. The following text (see answer to next question) will be added to the discussion and conclusion sections to address these concerns.\n\n> How the achieved results fall within the current progress in understanding …\n\nThank you for raising this important point. We agree that the significance of the paper for engineering applications isn’t completely clear in the current manuscript. To resolve this, we have added the following text to both the discussion and conclusion of the paper.\n\n*DISCUSSION: Every one of the 76 networks we tested has a wide critical band. We tested all the networks from Geirhos et al., 2021 which is the largest comparison of networks and humans on object recognition. The Geirhos study included most of the popular network kinds, spanning a wide range of conditions: convolutional networks and transformers, shallow and deep networks, supervised and self-supervised training, standard and adversarially-trained networks. Thus, the conclusions of this paper are based on a representative sample of popular network designs. More work is required to explore the effects of diverse kinds of training data and augmentation.*\n\n*CONCLUSION: … are based on a representative sample of popular network designs. More work is required to explore the effects of diverse kinds of training data and augmentation.*\n\n>Are 16 human observers enough to have significant results...\n\nWe are working on analyses showing statistical significance of our human experimental results and will try to share updates during the discussion period.\n\n**Limitations:**\n\n>The authors do not discuss limitations explicitly. \n\nDone. Our revised conclusion section, copied below, will discuss limitations as follows.\n\n*While our results are based on a large, representative sample of popular network designs, more work is required to explore the effects of diverse kinds of training data and augmentations. Additionally, our current results are purely correlational, and such experiments would also help determine if the relationship between channel properties and robustness is also causal.*\n\n>About ethics, the authors say that humans are used for experiments and that a consent form has been signed, but there is no …\n\n>Flag For Ethics Review: Ethics review needed: Compliance (e.g., GDPR, copyright, license, terms of use)\n\nClearly there has been a misunderstanding. As we point out in L128, our study and consent form were approved by the university IRB (Institutional Review Board) which abides by the Helsinki agreement (check). This is the standard protocol for review and publication of human behavior experiments in psychology and neuroscience journals. NeurIPS also follows this standard practice.\n\nIt is highly unusual to request a consent form as part of a scientific review but we would be happy to share it if necessary.\n'}}, {'rebuttal': {'value': '**Strengths:**\n\n>Originality\n\n>Critical band masking-based …\n\n>Quality\n\n>The design of the study is mostly sound: 1100 images from …\n\n>The evidence for the claims of bigger channel bandwidth than humans, inverse correlation of bandwidth and shape bias, and …\n\nThank you!\n\n>Clarity\n\n>The paper is well written and mostly easy to follow. The plots in Figure 5 and 6 are quite condensed, containing a lot of information, but with the text and captions the reader can mostly parse them well.\n\nThank you!\n\n**Weaknesses:**\n\nQuality\n\n>The practical motivation behind using grayscale images reduced to 20% contrast makes sense, …\n\nDone. Fig. 2 from the attached PDF will be added to the paper’s supplementary material and will be referenced in the main paper. This figure shows the percent correct values of each network we tested for each of 3 image conditions: color, gray, and low-contrast gray. Of the 88 networks available in our source datasets, 12 were below threshold for low-contrast gray images (alexnet, squeezenet1_0, squeezenet1_1, shufflenet_v2_x0_5, bagnets 9, 17, 33, resnet50_l2_eps1,3,5, selecsls42b, selectls84), which made them impossible to test on our critical band masking task. This left us with the 76 networks that we report results for in the main paper. Importantly, for these networks, we see in the figure that the change in performance from the color to gray to low-contrast gray condition is very small.\n\n>While the paper does investigate a diverse set of networks, …\n\nThank you for this suggestion. Yes, we totally agree that the influence of training data on these results is interesting to look at. We have clarified this point in the modified discussion and conclusion sections, as follows.\n\n*DISCUSSION: Every one of the 76 networks we tested has a wide critical band. We tested all the networks from Geirhos et al., 2021 which is the largest comparison of networks and humans on object recognition. The Geirhos study included most of the popular network kinds, spanning a wide range of conditions: convolutional networks and transformers, shallow and deep networks, supervised and self-supervised training, standard and adversarially-trained networks. Thus, the conclusions of this paper are based on a representative sample of popular network designs. More work is required to explore the effects of diverse kinds of training data and augmentation.*\n\n*CONCLUSION: … are based on a representative sample of popular network designs. More work is required to explore the effects of diverse kinds of training data and augmentation.*\n\n>The paper lacks a related work section…\n\nDone. We have written a Related work section (please see our common response to all reviewers) that will be added to the manuscript.\n\n>Significance\n\n>While it is interesting to see a comparison…\n\nThank you for raising this important point. We agree that the significance of the paper for engineering applications isn’t completely clear in the current manuscript. To resolve this, we will add the following text to both the abstract and conclusion of the paper.\n\n*We show that the idea of a critical-band offers a spatial-frequency-based explanation of shape bias and adversarial robustness. Thereby, our paper provides evidence suggesting that efforts to make a network more robust should look for ways to narrow its critical band.*\n\n>As mentioned in the quality section, …\n\nPlease refer to our answer above to your comment in the Quality section.\n\n>The observations about adversarial robustness are focused on one type of white-box adversarial attack, which is the least practically plausible.\n\nWe don’t know about real-world or practically plausible attacks. Can you give us a pointer?\n\n**Questions:**\n\n>What exactly is the significance of the findings …\n\nPlease refer to our answer above to your comment in the Significance section.\n\n>Given that filtered noise perturbation significantly …\n\nWhile the filtered noise perturbations to an image are indeed easy to see/detect, they do not affect human categorization decisions. We show in the paper that category decisions of adversarially-trained models are MORE affected by such filtered noise, making their recognition susceptible to a kind of attack that humans are not susceptible to. The significance of this is that more adversarially-robust object recognition networks are more affected by simple frequency-based perturbations which do not affect human decisions, raising questions about the robustness of these networks.\n\n>What is the significance of the current findings abound …\n\nPlease refer to our answer above to your comment in the Significance section.'}}, {'rebuttal': {'value': '**Strengths:**\n\n>-This is one of those papers that one wishes one had written. The result about the human bandwidth is Nature-worthy!\n\n>-The sequence of experiments: First human psychophysics, then network “psychophysics”, then showing that these measurements of noise-sensitivity (mean, std dev., and peak noise sensitivity) account for fairly large amounts of variance in the networks’ adversarial robustness and shape-sensitivity are both logical and surprisingly revealing.\n\n>-The fact that these measurements account for 53% of the variance in shape-bias is remarkable, given that these are relatively low-level, and don’t have any necessary relationship to shape.\n\nThank you for rating our paper so positively! We are glad the significance and contributions of our paper came through.\n\n**Weaknesses:**\n\n>Just a few comments here: Include the heat map key in the supplementary material (figure 2). \n\nDone. The heatmap figure in supplementary material will be modified to include a colorbar and axis labels, as shown in Fig. 1 in the attached PDF.\n\n>You should run some more experiments with adversarially-trained networks (see below).\n\nAnswered below.\n\n**Questions:**\n\n>The x axis for peak noise sensitivity in Figure 6 seems incorrect, based on the definition in Figure 2F, For example, for humans, it looks to be 1/(0.03), or about 33. It’s only after checking the supplementary material that this is made clear. It’s actually 1/(0.02*2^A), where A is the fitted parameter. This should be made clearer in the main text.\n\nDone. The following paragraph describing the fitting procedure will be added to Methods in the main text.\n\n*The fitting procedure is as follows. The threshold values computed earlier are first mapped to linear indices ($[ >0.16,0.16,0.08,0.04,0.02 ]\\rightarrow[ 0,1,2,3,4 ]$). A Gaussian function $f(x) = Ae^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$ having 3 parameters: peak height (A), mean ($\\mu$), and standard deviation ($\\sigma$) is then fit to the thresholds. These fitted parameters are converted back to their original scale and then used to calculate three properties that characterize the channel: peak noise sensitivity (reciprocal of channel height = $\\frac{1}{0.02 \\times 2^A}$), center frequency (frequency for peak noise sensitivity = $\\mu$), and bandwidth in octaves (log full-width at half-max = $\\log_2{2.355\\sigma}$). An octave is a doubling of frequency. Fig. 2F illustrates the rescaled Gaussian channel (black curve) and its three parameters (orange, maroon, green) for a sample observer, along with formulae to calculate the three channel properties.*\n\n>Did you use MTurk’s ratings of workers? It seems like subjects 9 and 13 were only marginally engaged in the task. I would have thrown them out.\n\nDone. Data of subjects 9 and 13 have been discarded and all analyses involving human data have been redone and will be modified in the paper. Our results remain the same with the only significant change being that the human channel bandwidth is now narrower: 1.21 instead of the previously-reported 1.56. This makes our main result, that the network channel is wider than the human bandwidth, stronger. \n\n>I think you should reverse Figures 1 and 2. Also (if possible) 5 & 6. In both cases, you refer to the later one before the other.\n\nDone, thanks. We will remove all references to Figure 2 before those to Figure 1 because they were redundant as you pointed out. Also, the order of Figures 5 and 6 will be reversed.\n\n**Limitations:**\n\n>Despite using 76 different networks, they only use ResNet50 for the adversarially-trained networks. It would be good to add a couple of other networks of different types (e.g., ViT, etc.) to see that this still holds. This could be added to the supplementary material.\n\nThank you for this suggestion. Yes, we agree that it will be interesting to analyze how network architecture and other factors affect our results on adversarial robustness. For this paper, we intended to test only networks that have previously been evaluated on other popular benchmarks (primarily from Geirhos et al. 2021) to observe how networks from those benchmarks fare on our spatial-frequency-based metric. Attributing our results to factors such as architecture, training data etc is interesting and is something we intend to pursue next. We have modified the Discussion and Conclusion sections of the current manuscript as follows, to include this point.\n\n*DISCUSSION: Every one of the 76 networks we tested has a wide critical band. We tested all the networks from Geirhos et al., 2021 which is the largest comparison of networks and humans on object recognition. The Geirhos study included most of the popular network kinds, spanning a wide range of conditions: convolutional networks and transformers, shallow and deep networks, supervised and self-supervised training, standard and adversarially-trained networks. Thus, the conclusions of this paper are based on a representative sample of popular network designs. More work is required to explore the effects of diverse kinds of training data and augmentation.*\n\n*CONCLUSION: … are based on a representative sample of popular network designs. More work is required to explore the effects of diverse kinds of training data and augmentation.*\n'}}, {'summary': {'value': ""I have read the authors' rebuttal and will maintain my already very high rating.\n\nThis paper discovers a new fact (which should be replicated by others) about human vision: That we use the same frequency band for objects as we do for words and gratings. It seems remarkable that this has not been tested before, but a cursory google search didn’t turn up any previous result like this. Second, the paper shows that 76 deep network vision systems use a much wider band of frequencies than humans. Finally, the paper shows that aspects of these frequencies predict both shape bias and robustness against adversarial examples.""}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '-This is one of those papers that one wishes one had written. The result about the human bandwidth is *Nature*-worthy! \n\n-The sequence of experiments: First human psychophysics, then network “psychophysics”, then showing that these measurements of noise-sensitivity (mean, std dev., and peak noise sensitivity) account for fairly large amounts of variance in the networks’ adversarial robustness and shape-sensitivity are both logical and surprisingly revealing. \n\n-The fact that these measurements account for 53% of the variance in shape-bias is remarkable, given that these are relatively low-level, and don’t have any necessary relationship to shape.'}, 'weaknesses': {'value': 'Just a few comments here:\nInclude the heat map key in the supplementary material (figure 2).\nYou should run some more experiments with adversarially-trained networks (see below).'}, 'questions': {'value': 'The x axis for peak noise sensitivity in Figure 6 seems incorrect, based on the definition in Figure 2F, For example, for humans, it looks to be 1/(0.03), or about 33. It’s only after checking the supplementary material that this is made clear. It’s actually 1/(0.02*2^A), where A is the fitted parameter. This should be made clearer in the main text.\n\nDid you use MTurk’s ratings of workers? It seems like subjects 9 and 13 were only marginally engaged in the task. I would have thrown them out. \n\nI think you should reverse Figures 1 and 2. Also (if possible) 5 & 6. In both cases, you refer to the later one before the other.'}, 'limitations': {'value': 'Despite using 76 different networks, they only use ResNet50 for the adversarially-trained networks. It would be good to add a couple of other networks of different types (e.g., ViT, etc.) to see that this still holds. This could be added to the supplementary material.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '10: Award quality: Technically flawless paper with groundbreaking impact, with exceptionally strong evaluation, reproducibility, and resources, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This work presents an empirical analysis of the sensitivity of humans and neural networks to critical band masking. This is the process of perturbing specific spatial frequencies, and determining which frequencies and at what magnitude, will lead to recognition errors. This in turns identifies the frequencies/magnitudes that a visual system “filters out” or “relies on” when performing recognition. The main finding is that neural networks are sensitive to a larger set of noise frequencies/magnitudes than human participants. Further, the paper presents evidence that adversarial-trained networks are sensitive to an even bigger set of frequencies/magnitudes, and correlation-based analyses indicating that more human-like networks that are sensitive to a narrow set of frequencies (smaller bandwidth) have a bigger shape bias.\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': 'Originality\n- Critical band masking-based analysis has previously been done to analyze recognition of letters and gratings. The novelty for this paper comes from its critical band masking-based for ImageNet-like object recognition for 16 humans and 76 different neural networks.\n\nQuality\n- The design of the study is mostly sound: 1100 images from 16 categories of ImageNet with various kinds of added noise are used as the test set. Careful steps were taken to avoid clipping as a result of added noise. 16 participants are sufficient due to the small variability between subjects (Figure 2 in supplement).\n- The evidence for the claims of bigger channel bandwidth than humans, inverse correlation of bandwidth and shape bias, and increased bandwidth with, are sound regarding the 76 networks evaluated in this paper. Figures 4 5 6 contain clear evidence of these claims\n\nClarity\n- The paper is well written and mostly easy to follow. The plots in Figure 5 and 6 are quite condensed, containing a lot of information, but with the text and captions the reader can mostly parse them well.\n'}, 'weaknesses': {'value': 'Quality\n- The practical motivation behind using grayscale images reduced to 20% contrast makes sense, however, this represents a testing condition outside of the training data domain of these neural networks. A control experiment where the performance discrepancy between testing on standard RGB data and contrast reduced grayscale is quantified would justify this choice of test setting.\n- While the paper does investigate a diverse set of networks, one confounding factor that at least should be mentioned and ideally should be investigated in an analysis paper like this is the effect of training data and data augmentation on spatial frequency sensitivity. The design of the neural network itself is not the only factor. \n    * The neural networks used in this paper are primarily trained on ImageNet, but there are other datasets, for example Office-Home, with images from different domains for each object, and therefore different spatial frequency characteristics. Training on such data will likely result in different spatial frequency sensitivity. \n    * There might be straightforward steps like band-pass filtering or adding noise to the input data at training time, that might effectively reduce the range of frequencies a model is sensitive to.\n- The paper lacks a related work section. While it does mention a variety of prior work throughout the draft, it would be beneficial to include a separate section that would cover prior work on topics like: spatial frequency sensitivity of humans and neural networks, shape bias, adversarial robustness, and comparing humans and neural networks more broadly. The main benefit is to help the reader understand exactly where the proposed work lies relative to prior methods.\n\nSignificance\n- While it is interesting to see a comparison of spatial frequency sensitivity of networks to humans for object recognition, and to identify it as an emerging phenomenon for a variety of ImageNet-trained models, I’m concerned about what exactly is the significance of these findings for deep learning practitioners. How should researchers rethink their work going forward as a result of these findings?\n- As mentioned in the quality section, after reading this paper there is a sense of it not going quite far enough in the analysis. How pervasive is the phenomenon of a wider spatial frequency sensitivity of neural networks? It would be more impactful if it is demonstrated that this is a general phenomenon despite training data or simple mitigation strategies.\n- The observations about adversarial robustness are focused on one type of white-box adversarial attack, which is the least practically plausible. \n'}, 'questions': {'value': '- What exactly is the significance of the findings presented in this work? What should be the main takeaway for researchers working on deep learning methodology for visual recognition, regarding how their future work should be affected by these findings? Is it necessarily better if the ""channel"" (as defined in this paper) is more human-like, and if so, why?\n- Given that filtered noise perturbation significantly alters the visual appearance of an image, so much so that it appears to be quite easy to identify images with such an attack, what is the significance of identifying the susceptibility to such attacks of adversarial-trained models (described in L298)?\n- What is the significance of the current findings abound frequency sensitivity, in light of the fact that the effect of training dataset choice and some basic techniques could be used to improve it?. How pervasive is this emerging phenomenon of a wider spatial frequency sensitivity of neural networks?'}, 'limitations': {'value': 'The authors have adequately addressed the limitations.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper presents an analysis of neural network response to object classification from the perspective of frequency components. The authors use an analytic tool based on critical band masking, which is a technique borrowed from neuroscience. \nThe focus of the network to use certain frequency bands for object classification is related to the frequency capabilities of the human visual system, then with shape bias and adversarial robustness of classification networks. \nThe contributions/novelty is in the neuroscientific technique used to analyze the network responses and behavior. The contributions are related to comparison of the frequency bad usage in the human visual system (HSV), neural networks and adversarially-trained networks, with limited contribution in terms of practical insights or indications/suggestions on how these observations would be usable.\n'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'strengths': {'value': '-\tUse of a novel approach to analyze neural networks: the critical band masking technique is borrowed from neuroscience (very popular in auditory system analysis) and used to analyze the response of networks. The approach is novel and interesting.\n-\tExtent of models considered in the analysis (although the transformers are only slightly covered)\n'}, 'weaknesses': {'value': '-\tUsefulness and outlook of the results: while the experimental results present an interesting view on the neural networks frequency selectivity for object classification, their significance and possible usage are not clear nor explicitly covered. Networks have a different behavior/frequency selectivity (not surprisingly I would say) nut no indication of how one should take over these findings and use them.\n-\tRelation between HVS and neural networks: the paper reads with an implicit assumption that the human visual system and neural networks for vision tasks are comparable systems. They are actually very different (with the second showing only some conceptual resemblance with the first), in terms of processing the data, energy-efficiency, ‘training’ etc. The results show that they behave differently (as expected) but do not address substantial differences between the two systems. I see a missed answer to important questions, as ‘why should we compare these systems and what do we gain from this analysis’?\n-\tDetails about the methodology are missing: e.g. is the analysis done taking into account both magnitude and phase of the spectrum, or only the magnitude? Phase is for instance shown important for object classification [1].\n-\tPlacement in the literature is very limited – references are outdated: missing references of works that study the network from a frequency perspective, relating the frequency spectrum with robustness and bias problems ([2,3,4,5], to mention a few).\n\n[1] Chen et al. Amplitude-phase recombination: Rethinking robustness of convolutional neural networks in frequency domain, ICCV 2021. \n\n[2] Yin D. et al. A fourier perspective on model robustness in computer vision. In NeurIPS, 2019.\n\n[3] Maiya et al. A frequency perspective of adversarial robustness, 2022.\n\n[4] Wang et al. Frequency shortcut learning in neural networks.  NeurIPS 2022 Workshop on Distribution Shifts\n\n[5] Wang et al. High-frequency component helps explain the generalization of convolutional neural networks. In CVPR, 2020.\n'}, 'questions': {'value': '-\tCan the authors clarify details about the method and experimental analysis, such as the use of magnitude and phase of the spectrum?\n-\tCan the authors clarify the motivations why neural networks based vision models have to be compared with the human visual system of the brain, and why aspects such as energy efficiency, memory, and ‘training’? are not taken into account?\n-\tHow does the work related to actual existing work on frequency analysis of neural networks in vision tasks?\n-\tHow the achieved results fall within the current progress in understanding neural network learning and application, and how they can be used to improve models for vision task?\n-\tAre 16 human observers enough to have significant results? This is glossed over very briefly in the paper, but not analyses are provided to support the claims.\n'}, 'limitations': {'value': 'The authors do not discuss limitations explicitly.\nAbout ethics, the authors say that humans are used for experiments and that a consent form has been signed, but there is no evidence of how this form is written, what the users agree with, and who approved the experiments.\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The authors propose to measure the differences in how humans and models rely on spectral information to recognize objects by using critical band masking to ablate. They conduct a human study revealing that humans detect objects with the same channels they use to detect letters and grating. On the other hand, models show a significantly wider channel. They further correlate the properties of the channel to robustness and shape bias, e.g. showing that AT results in an even wider channel.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '### Originality\nThe paper explores a less common yet highly important research direction. Some ""model"" findings were partially reported in literature, but for the most part the findings are highly original.\n\n### Quality\nThe submission is of high quality (minor weaknesses see below). The authors rigorously conduct (well-documented) human experiments and benchmark 76 ImageNet models to arrive at their conclusions.\n\n### Clarity\nThe paper is very well written. Key points are communicated clearly through writing and figures.\n\n### Significance\nThe authors share many findings, that may be of great interest to the NeurIPS community. In particular, they measure the human critical channel and show that models measure higher bandwidths. Adversarial Training increases the channel even further. Generally, they find correlations between channel properties and shape-bias/robustness that may lead to a new perspective on robustness but also shows another misalignment between humans and models.\n'}, 'weaknesses': {'value': '### Method\n- Evaluation only on ImageNet: I never thought I would make this as a weakness but here we go ... previous work has shown that the frequency band of adversarial attacks is not always HF (the authors arrive at the same conclusion in L230ff) but also highly depends on the dataset [2,3,4]. Given that this paper ""only"" presents an empirical evaluation I am not sure if the findings (about models and in particular robustness) scale to other datasets. At the very least this is a limitation that should be discussed.\n- Poor choice of robust networks: The authors choose $\\ell_2$-AT trained ResNets as robust networks and attack them with $\\ell_\\infty$ attacks. However, AT is notoriously poor at generalizing to new attacks. A better choice would have been $\\ell_\\infty$-AT trained ResNets. There may also be some differences in the evaluation as [1] showed that the norm differently affects performance on high/lowpass data. I don\'t expect this to flip observations, but it would be a more appropriate choice.\n- Minor: uncommon choice of parameters for robustness analysis. A more common choice would be $\\epsilon=4/255$ via 20-step PGD or better the AutoAttack suite. This probably won\'t impact the observations at all but may be easier to relate to.\n\n### Novelty \n- Some claims/observations in the submitted draft were already published. This does not invalidate the (exceeding) contributions of this paper, but the respective works should at least be mentioned. [2] already performed band-masking to study the critical bands of CNNs, [1] discussed how frequencies interact with shape-bias.\n\n\n### Others\n- The authors use 76 pretrained models only partially citing them. The Paper Checklist clearly states to cite all the used assets.\n\n- Authors do not discuss limitations\n\n- Minor: The authors repeatedly claim that transformers are shape-biased. This is not inherently true. It may hold if pretrained on large datasets such as ImageNet21k, but out of the box they don\'t perform much better, e.g. [1] shows that XCiT just barely performs better than ResNets in shape-bias when only trained on ImageNet1k.\n\n[1] Paul Gavrikov, Janis Keuper, Margret Keuper. ""An Extended Study of Human-Like Behavior Under Adversarial Training"". CVPR-W, 2023.\n[2] Antonio A. Abello, Roberto Hirata, and Zhangyang Wang. ""Dissecting the high-frequency bias in convolutional neural networks"". CVPR-W, 2021.\n[3] Remi Bernhard, Pierre-Alain Moellic, Martial Mermillod, Yannick Bourrier, Romain Cohendet, Miguel Solinas, and Marina Reyboz. ""Impact of spatial frequency based constraints on adversarial robustness"". IJCNN, 2021.\n[4] Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard. ""Hold me tight! influence of discriminative features on deep network boundaries"". NeurIPS, 2020.\n'}, 'questions': {'value': '- Are there any insights on whether improving the alignment between the model critical channel compared to humans would improve robustness or shape-bias, i.e. is there evidence of causality and not only correlation? \n- Did the authors attempt to encourage alignment in training?\n- Are there any observations on other datasets?'}, 'limitations': {'value': ""The authors do not discuss limitations explicitly. One salient limitation is the evaluation of ImageNet. As discussed above certain frequency properties may not carry over to other datasets.\n\nI don't see any potential negative societal impact of their work.""}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This study applies a well-established procedure from psychophysics, critical band masking, to an object recognition task on which human and a wide range of neural networks are compared.\nThe core finding is that while humans use roughly the same spatial frequency channels for object recognition as they do for e.g. letter / grating recognition, all 76 investigated neural networks use much wider channels (more than twice as wide as the human channel).\nThis means that humans and neural networks rely on different spatial frequencies for object recognition.'}, 'soundness': {'value': '2 fair'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '* Overall, I really liked this study - it has a simple yet effective protocol, clear findings, and approaches a novel question through sound experiments.\n* The proposed approach is applicable to the analysis of future networks, i.e. it is sufficiently general such that it can be used by follow-up studies / on general architectures\n* Successful transfer of psychophysical method to the study of neural networks\n* The paper is very well-written, easy to follow, clearly structured and has good visualizations\n* Human data will be made publicly available upon publication'}, 'weaknesses': {'value': 'Significance testing:\n* Figure 6 does not correct for multiple comparisons. I would like to know which of the plotted effects still hold after Bonferroni correction by dividing the alpha level (.05) by 18, i.e. the number of comparisons (6 plots x 3 fits), resulting in a corrected alpha level of 0.0027777. I would encourage the authors to update the figure with a corrected version.\n\nHuman experimental weaknesses:\n* In human visual perception, spatial frequency is measured in cycles per degree of visual angle and depends on the distance to the monitor. If I understand correctly, the setup is employed with unknown distance between observers and monitor.\n* No information on monitor calibration, which is very important in experiments where stimuli of reduced contrast are shown. E.g., many monitors have settings that ""enhance"" contrast, which is not unlikely to have an impact on human experimental performance. Did the authors take this into account?\n* Human experiments with reduced contrast are best performed in a setting where contrast adaptation can take place. In the present study, however, the screen constantly changes from grey to bright white and back to grey again.\n* Given the online study setup, how did the authors ensure normal / corrected-to-normal vision (beyond self-reporting, where online participants have monetary incentives for inaccurate reporting)?\n* Two of the 16 observers (supplementary Figure 2) do not seem to perform well at all on the simple task'}, 'questions': {'value': '### Questions:\n* What is going on with the two outlier observers in Figure 2 (1st column, bottom two rows)?\n* Given that some networks have severely reduced performance at 20% contrast, I\'m wondering whether there might be a possible interaction of the experimental findings with the contrast level. As a supplementary experiment, it might be interesting to test the core findings separately for (a) networks which only show a minor performance detriment when reducing images to 20% contrast and (b) the rest of the networks.\n\n### Major opportunities for improvement:\n(The study is already quite solid, and I am in favor of publication. These suggestions go beyond what is currently done in the paper. If at least one of them can be addressed, I would be happy to increase my score further.)\n* ""we propose that critical band masking should be added to the toolbox of metrics for model-human comparison."": I agree, and I was wondering whether the authors plan to facilitate this. For instance, they could release their stimuli as part of an open-source testbed (e.g., as a fork of  / addition to the model-vs-human toolbox, or in any other way).\n* The authors show that properties of critical bands are correlated with important properties like shape bias / adversarial robustness. Going beyond a correlation, I was wondering whether a causal link could be established, e.g. by reducing the signal-to-noise ratio of non-human channels in the input during training, leading to changed critical bands (e.g., more human-like ones), and then showing that the properties of interest (shape bias / adversarial robustness / ...) change accordingly.\n* The reasons for the human-model divergence are not yet understood. It would be interesting to know why this divergence arises, and whether it is a property of the architecture, the training procedure, or something else.\n\n\n### Minor questions:\n* line 86: should this be ""human object recognition""?\n* why ""roughly equally distributed across all 16 categories""? What was the exact distribution, and why was it not exactly equally distributed? (Background: performance can be above chance level 1/16 when categories aren\'t exactly equally distributed)\n'}, 'limitations': {'value': 'The authors don\'t have a section on limitations. In accordance with the checklist, the authors are encouraged to describe the limitations of their approach, in particular related to the experimental choices mentioned in the ""weaknesses"" section above.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Spatial-frequency channels, shape bias, and adversarial robustness'}, 'authors': {'value': ['Ajay Subramanian', 'Elena Sizikova', 'Najib J. Majaj', 'Denis G. Pelli']}, 'authorids': {'value': ['~Ajay_Subramanian1', '~Elena_Sizikova1', '~Najib_J._Majaj1', 'denis.pelli@nyu.edu']}, 'keywords': {'value': ['object recognition', 'critical band masking', 'spatial-frequency channels', 'shape bias', 'adversarial robustness']}, 'TLDR': {'value': 'Critical band masking, a tool from neuroscience, reveals a large difference in the spatial frequency information used by humans and neural networks to recognize objects in natural images.'}, 'abstract': {'value': 'What spatial frequency information do humans and neural networks use to recognize objects? In neuroscience, critical band masking is an established tool that can reveal the frequency-selective filters used for object recognition. Critical band masking measures the sensitivity of recognition performance to noise added at each spatial frequency. Existing critical band masking studies show that humans recognize periodic patterns (gratings) and letters by means of a spatial-frequency filter (or ""channel"") that has a frequency bandwidth of one octave (doubling of frequency). Here, we introduce critical band masking as a task for network-human comparison and test 14 humans and 76 neural networks on 16-way ImageNet categorization in the presence of narrowband noise. We find that humans recognize objects in natural images using the same one-octave-wide channel that they use for letters and gratings, making it a canonical feature of human object recognition. Unlike humans, the neural network channel is very broad, 2-4 times wider than the human channel. This means that the network channel extends to frequencies higher and lower than those that humans are sensitive to. Thus, noise at those frequencies will impair network performance and spare human performance. Adversarial and augmented-image training are commonly used to increase network robustness and shape bias. Does this training align network and human object recognition channels? Three network channel properties (bandwidth, center frequency, peak noise sensitivity) correlate strongly with shape bias (51% variance explained) and robustness of adversarially-trained networks (66% variance explained). Adversarial training increases robustness but expands the channel bandwidth even further beyond the human bandwidth. Thus, critical band masking reveals that the network channel is more than twice as wide as the human channel, and that adversarial training only makes it worse. Networks with narrower channels might be more robust.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'pdf': {'value': '/pdf/16400c67bce0d09070a4c9624a8deaaec58dc145.pdf'}, 'supplementary_material': {'value': '/attachment/ede11ef43c7ed0ec1a0ea216abbc9b2e579911da.pdf'}, '_bibtex': {'value': '@inproceedings{\nsubramanian2023spatialfrequency,\ntitle={Spatial-frequency channels, shape bias, and adversarial robustness},\nauthor={Ajay Subramanian and Elena Sizikova and Najib J. Majaj and Denis G. Pelli},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=KvPwXVcslY}\n}'}, 'paperhash': {'value': 'subramanian|spatialfrequency_channels_shape_bias_and_adversarial_robustness'}}]"
"['Zeyuan Ma', 'Hongshu Guo', 'Jiacheng Chen', 'Zhenrui Li', 'Guojun Peng', 'Yue-Jiao Gong', 'Yining Ma', 'Zhiguang Cao']",NeurIPS,MetaBox_ A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning,https://neurips.cc/virtual/2023/oral/73737,2023," Recently, Meta-Black-Box Optimization with Reinforcement Learning (MetaBBO-RL) has showcased the power of leveraging RL at the meta-level to mitigate manual fine-tuning of low-level black-box optimizers. However, this field is hindered by the lack of a unified benchmark. To fill this gap, we introduce MetaBox, the first benchmark platform expressly tailored for developing and evaluating MetaBBO-RL methods. MetaBox offers a flexible algorithmic template that allows users to effortlessly implement their unique designs within the platform. Moreover, it provides a broad spectrum of over 300 problem instances, collected from synthetic to realistic scenarios, and an extensive library of 19 baseline methods, including both traditional black-box optimizers and recent MetaBBO-RL methods. Besides, MetaBox introduces three standardized performance metrics, enabling a more thorough assessment of the methods. In a bid to illustrate the utility of MetaBox for facilitating rigorous evaluation and in-depth analysis, we carry out a wide-ranging benchmarking study on existing MetaBBO-RL methods. Our MetaBox is open-source and accessible at: https://github.com/GMC-DRL/MetaBox.",Oral 6B RL,https://openreview.net/pdf?id=j2wasUypqN,https://openreview.net/forum?id=j2wasUypqN,j2wasUypqN,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (Oral)'}, 'comment': {'value': ""This paper investigates benchmark datasets and methods for meta-black-box optimization with reinforcement learning. The reviewers and I agree that the platform is extensive and covers a large set of relevant problem instances and set of algorithms for solving them. And, the code to solve these is well-designed and will serve as a useful tool for the community. This paper will be a great contribution to this year's program. I recommend it for an oral as these benchmarks and methods are well-executed and worth emphasizing to the community.""}}, {'comment': {'value': 'Thank you for the clarifications and for updating your article.\n\nI obviously keep the ranking I initially assigned.'}}, {'title': {'value': 'Thank you for the response'}, 'comment': {'value': ""The authors' response addressed my questions and suggestions. I will increase my score.""}}, {'title': {'value': 'Thank you for your response'}, 'comment': {'value': 'I am generally satisfied with this paper. Thank you for your effort in the responses.'}}, {'comment': {'value': 'We sincerely appreciate the reviewer for acknowledging our work and cranking his/her evaluation up. We will continuously contribute to the BBO community in the future!'}}, {'comment': {'value': ""Thanks for the updates!\n\nI'm actually quite impressed by the results that the author shared. I'm cranking my evaluation up a notch. Looking forward to more insightful work from you in the future!""}}, {'title': {'value': 'Response'}, 'comment': {'value': 'Dear reviewer #t7Zi: \n\nWe sincerely appreciate your thorough review and valuable feedback on our paper. We have carefully addressed each of your comments and provided a point-by-point response below.\n\n**[Difference between MetaBBO and HPO]**  While MetaBBO and HPO share similarities due to their common bi-level optimization structure, it is important to note that HPO can be considered a subset of MetaBBO. HPO focuses primarily on tuning the hyperparameters of the low-level optimizer. In contrast, the scope of MetaBBO extends beyond hyperparameter tuning, encompassing several additional dimensions of optimization. These dimensions could involve applying the meta-level controller for operator selection (e.g.,\xa0[DEDDQN](https://dl.acm.org/doi/abs/10.1145/3321707.3321813)), configuring algorithms by considering both hyperparameters and operators (e.g.,\xa0[RLHPSDE](https://www.sciencedirect.com/science/article/abs/pii/S2210650222001602)), and even generating optimization procedures (e.g.,\xa0[Meta-GA](https://dl.acm.org/doi/abs/10.1145/3583131.3590496)).\n\n**[Difference between MetaBBO and BBO and the Significance of a MetaBBO Benchmark]** We would like to clarify that the focus of MetaBBO is on the meta-level *decision process*, which governs the behavior of the low-level optimizer. This decision process can be formulated as a *Markov Decision Process (MDP)*, allowing optimization through reinforcement learning algorithms (MetaBBO-RL). Compared with traditional BBO methods, MetaBBO methods alleviate the manual fine-tuning burden by automating the optimization of low-level BBO optimizers. They demonstrate the ability to generalize and address previously unseen problems through extensive training on a problem distribution. The development of MetaBBO benchmarks holds the potential for advancing this research direction.\n\nIn MetaBox, we made serval efforts to facilitate the design and testing of new MetaBBO-RL algorithms (Section 3.1). We develop a *MetaBBO-RL coding template* that abstracts two classes: the meta-level reinforcement Agent and the lower-level Optimizer, which are implemented together with a streamlined Train-Test-Log interface, ensuring an automated workflow for design, training, and testing. Additionally, while conventional BBO benchmarks primarily assess optimization performance, MetaBox goes beyond to evaluate *generalization and knowledge transfer capabilities*. We propose two novel metrics, Meta Generalization Decay (MGD) and Meta Transfer Efficiency (MTE) to evaluate learning ability of a MetaBBO method (Section 3.4). The above new features make Metabox different from conventional BBO benchmarks, addressing the lack of a unified benchmark platform for MetaBBO methods. We also compared MetaBox and other BBO benchmarks in Table 1, underscoring the unique characteristics and novelty of our platform.\n\n**[Website Documentation]**  Following your suggestion, we have reorganized the README structure and created a separate user guide documentation, to provide clearer and more comprehensive resources for users. You can find the revised README\xa0[here](https://github.com/GMC-DRL/MetaBox)\xa0and the dedicated user guide documentation\xa0[here](https://gmc-drl.github.io/MetaBox/). Furthermore, we are committed to maintaining and updating the MetaBox platform to provide ongoing support and improvements.'}}, {'title': {'value': 'Response'}, 'comment': {'value': 'Dear reviewer #D9Jb:\n\nWe sincerely appreciate your thorough review and positive feedback on our paper. We have carefully addressed each of your comments and provided a point-by-point response below.\n\n**[Bi-level nature of MetaBBO]** MetaBBO aims to refine the black-box optimizers by identifying optimal configurations that boost the overall performance across various problem instances within a given problem distribution. This paradigm can be naturally defined as a bi-level optimization framework, where the meta-level enhances the performance of lower-level black-box optimizers. In the context of MetaBBO-RL, *the meta level operates as an RL agent, while the lower level encompasses a BBO optimizer*. The RL agent at the meta level estimates an action (algorithmic configuration) for the lower-level optimizer and accumulates rewards (meta performance) observed by executing the lower-level optimizer using the estimated action. Mathematically, the meta objective of the RL agent can be formulated as: $\\mathop{\\max}\\limits_{\\theta} E_{f\\sim D, \\pi_\\theta}[ \\sum_{t=0}^{T}r_t(\\Lambda, f, \\pi_\\theta) ]$, where $D$ denotes the given problem distribution, and $r_t(\\cdot)$ denotes the meta performance of the lower-level optimizer $\\Lambda$ optimizing the target problem $f$, all while adhering to the algorithmic configuration provided by the meta optimizer $\\pi_\\theta$.  We have provided detailed explanations on this matter in the revised Section 2.\n\n**[Pseudocode for Usage]** We acknowledge the value of providing pseudocode on usage. We have taken your feedback into account and included the pseudocode for the core components in our MetaBox (such as Trainer and Tester) in Appendix F, along with corresponding descriptions.'}}, {'title': {'value': 'Response'}, 'comment': {'value': 'Dear reviewer #qtiV:\n\nWe sincerely appreciate your thorough review and positive feedback on our paper. We have carefully addressed each of your comments and provided a point-by-point response below.\n\n**[Detailed Explanation of Benchmarking Algorithms]** The benchmarking algorithms included in this study fall within the realm of MetaBBO, characterized by their bi-level optimization nature. Specifically, MetaBBO aims to refine the black-box optimizers by identifying optimal configurations that boost the overall performance across various problem instances within a given problem distribution. This paradigm can be naturally defined as a bi-level optimization framework, where the meta-level enhances the performance of lower-level black-box optimizers.  At the meta level, the meta optimizer (often parameterized by neural networks, e.g., $\\pi_\\theta$) tailors the configuration of the lower-level optimizer based on the optimization status of the latter at the current time step. Then, the meta optimizer observes the next-step optimization performance (meta performance) of the lower-level optimizer, and trains itself by maximizing the accumulated meta performance. At the lower level, once equipped with the algorithmic configuration, the optimizer carries out optimization for the target task, observes the objective value change between steps, and communicates this change back to the meta optimizer as the meta performance. As per your suggestion, we have incorporated this extended definition at the start of Section 2, along with the inclusion of a conceptual figure (Figure 2). \n\n**[Clarification of Performance Evaluation Limitation]** In MetaBox, we addressed the performance evaluation challenge by implementing three standardized metrics aimed at evaluating both optimization performance and the learning effectiveness of MetaBBO-RL approaches. Notably, we introduce a novel Aggregated Evaluation Indicator (AEI) that offers a holistic view of BBO optimization performance. The AEI scoring system takes into consideration three main aspects: the best objective value achieved, the convergence rate, and the algorithmic complexity. This comprehensive approach covers aspects that have been extensively discussed in the literature. Nevertheless, *it is important to acknowledge that the evaluation of BBO performance is not a one-size-fits-all endeavor.* Different practical applications may have varying preferences and additional concerns. For example, in certain domains, factors such as *solution robustness, solution diversity, parallelization and scalability*, might play a crucial role in assessing the true efficacy of an optimizer. These nuances extend beyond the scope of a single evaluation metric. This is why, in our conclusion section, we stated that the performance evaluation of BBO remains a challenging and open-ended area. In response to your suggestion, we have taken this opportunity to provide additional context and insights about this limitation in our revised paper (Section 5, page 10).\n\n**[Providing Variation Information in Bar Charts]** Thank you for the suggestion. Following it, we have incorporated error bars for each baseline algorithm into the AEI scores bar charts **(Figure 4, page 8; also Figure 1, Appendix, page 4)**. The error range associated with each baseline algorithm is calculated as the standard deviations of its AEI scores $[AEI_k]_{k=1}^{K}$ across the *K* tasks in the testsuites. Algorithm with a smaller error bar performs more stably on the target testsuites. \n\n**[Performance over the Increment of FEs]** We strongly agree with your concern regarding the significance of managing the number of function evaluations (FEs), particularly in high-evaluation-cost scenarios. In MetaBox, the default FEs for Synthetic testsuites is set to $2 \\times 10^4$ (line 19-20 in Appendix). This choice adheres to the standard practice in benchmarking BBO optimizers on Synthetic testsuites. *For the realistic Protein-Docking testsuites in MetaBox, due to its computationally expensive nature, the default FEs is set to $10^3$* (see line 38-39 in Appendix).  Besides, it is important to note that MetaBox offers the flexibility of accommodating user-specific FEs. Users can easily tailor the evaluation process by adjusting the maxFEs parameter within the training or evaluating interface.\n\nWe also appreciate the suggestion of presenting performance over the increment of FEs. We wish to clarify that our platform already incorporates the capability to automatically generate cost curves that showcase the performance of different algorithms relative to varying FEs. But due to the page limit, this information is illustrated in the Appendix D.1, Figure 2, Cost Curve part and the complete results can be accessed through our online webpage [here](https://anonymous.4open.science/r/MetaBox-6F0C/post_processed_data/content.md).'}}, {'title': {'value': 'Response to Reviewer #nMBF'}, 'comment': {'value': 'Dear reviewer **#nMBF**:\n\nWe sincerely appreciate your thorough review and positive feedback on our paper. We have carefully addressed each of your comments and provided a point-by-point response below. We have also uploadedd the revisied version of paper to the system.\n\n**[Definition of Bi-level Optimization in MetaBBO]** MetaBBO aims to refine the black-box optimizers by identifying optimal configurations that boost the overall performance across various problem instances within a given problem distribution. This paradigm can be naturally defined as a bi-level optimization framework, where the meta-level enhances the performance of lower-level black-box optimizers.  Specifically, at the meta level, the meta optimizer (often parameterized by neural networks, e.g., $\\pi_\\theta$) tailors the configuration of the lower-level optimizer based on the optimization status of the latter at the current time step. Then, the meta optimizer observes the next-step optimization performance (meta performance) of the lower-level optimizer, and trains itself by maximizing the accumulated meta performance. At the lower level, once equipped with the algorithmic configuration, the optimizer carries out optimization for the target task, observes the objective value change between steps, and communicates this change back to the meta optimizer as the meta performance. Mathematically,  the bi-level optimization objective can be formulated as: $\\mathop{\\max}\\limits_{\\theta} E_{f\\sim D,  \\pi_\\theta}[ \\sum_{t=0}^{T}r_t(\\Lambda, f, \\pi_\\theta) ]$, where $D$ denotes the given problem distribution, and $r_t(\\cdot)$ denotes the meta performance of the lower-level optimizer $\\Lambda$ optimizing the target problem $f$, all while adhering to the algorithmic configuration provided by the meta optimizer $\\pi_\\theta$. As per your suggestion, we have incorporated this extended definition at the start of Section 2, along with the inclusion of a conceptual figure (Section 2, page 3).\n\n**[Limitations Discussed in Section 5]** Yes, as a pioneering benchmark platform in the MetaBBO field, we acknowledged there are still certain limitations of our MetaBox and outlined them in Section 5. We are fully committed to addressing these limitations by maintaining the platform and regularly updating its Baseline Library, test suites, performance evaluation metrics, and other integral components. We also welcome user feedback to assist us in enhancing the quality and scope of our platform.'}}, {'title': {'value': 'Global Response'}, 'comment': {'value': 'We would like to express our sincere gratitude for the time and effort the reviewers have invested in reviewing our paper. We are also pleased to see the reviewers have recognized our MetaBox platform of being **comprehensive** (all 4 reviewers), **well-written** (all 4 reviewers), **reproducible** (#nMBF), **well-designed** (#qtiV), **unified** (#D9Jb) and **novel** (#nMBF). In this global response, we primarily address a common suggestion shared by the reviewers and provide an overview of the modifications suggested by each reviewer, as follows.\n\n---\n\n**[More elaboration on the Bi-Level Nature of MetaBBO Paradigm]** We thank the reviewers (#nMBF, #qtiV, and #D9Jb) for raising this valuable point, and we apologize for any prior confusion. Following the suggestion, we have included a dedicated paragraph at the beginning of Section 2 (page 3), along with a newly introduced conceptual figure (Figure 2), to provide a clearer illustration of the bi-level nature of the MetaBBO paradigm. Here is the additional elaboration we have incorporated:\n\n*MetaBBO methods operate within a bi-level optimization framework designed to automate the fine-tuning process for a given BBO optimizer. Distinguishing themselves from conventional BBO techniques, MetaBBO methods introduce a novel meta-level as an automatic decision process. The purpose is to alleviate the need for labor-intensive manual fine-tuning of lower-level BBO optimizers. Typically, they require the ability to generalize behaviors to address previously unseen problems through extensive training on a problem distribution.*\n\n- At *the meta level, the meta optimizer (e.g., an RL agent) dynamically configures the lower-level optimizer based on the current optimization status at that particular time step. Then, the meta optimizer evaluates the performance of the low-level optimizer over the subsequent optimization steps, referred to as meta performance. The meta optimizer leverages this observed meta performance to refine its decision-making process, training itself through the maximization of accumulated meta performance, thereby advancing its meta objective.*\n- At *the lower level, the BBO optimizer receives a designated algorithmic configuration from the meta optimizer. With this configuration in hand, the low-level optimizer embarks on the task of optimizing the target objective. It observes the changes in the objective value across consecutive steps and transmits this information back to the meta optimizer, thereby contributing to the meta performance signal.*\n\n**[Other modifications]** We add a paragraph to discuss the remained open-ended question (***#qtiV***) about performance evaluation in BBO (**Section 5, page 10**). Besides, we add error bars to AEI scores bar charts (**Figure 4, page 8; also Figure 1, Appendix, page 4**) to reflect robustness of a baseline algorithm across different problems in a problem distribution (***#qtiV***). We also add detailed pseudo codes (**Appendix F**) aiding for elaborating the complete benchmarking process in MetaBox (***#D9Jb***).'}}, {'title': {'value': 'Valid and well described benchmark platform for Meta-Black-Box Optimization with Reinforcement Learning'}, 'rating': {'value': '9: Top 15% of accepted papers, strong accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'This article introduces MetaBox, a novel benchmark platform for meta-black-box optimization using reinforcement learning.\n\nThe platform comes with a large set of meta-black-box problem instances (more than 300) and a set of 19 baseline optimizers.'}, 'strengths': {'value': 'Comprehensive platform with both a large number of problem instance, a significant number of state of the art optimization algorithms and standardized performance metrics.\n\nThis permits reproducible research in the MetaBBO-RL field.\n\nThe three main contributions constituting the MetaBBO-RL platform, i.e. MetaBBO-RL template approach, a large set of benchmark instances and a representative set of baseline optimization algorithms are clearly introduced and presented in detail in dedicated subsections in section 3.\n\nA comprehensive benchmarking study has been conducted and even if it is not the main purpose of the work, some results did outperform the state-of-the-art, which outlines the potential of the proposed MetaBBO-RL approach.'}, 'opportunities_for_improvement': {'value': 'The definition of bi-level optimization could be (even briefly) introduced.'}, 'limitations': {'value': 'Some limitations have been identified in section 5: lack of performance evaluation for BBO, expanding the number of BBO tasks in the platform and proper maintenance of the platform, keeping it up-to-date with latest algorithms from the literature.'}, 'correctness': {'value': 'Claims are properly backed up with references.\n\nExperiments are conducted with scientific rigour.'}, 'clarity': {'value': 'The article is very well structured and written.\n\nThe basic notions of blackbox optimisation and meta-black box optimisation are clearly introduced.'}, 'relation_to_prior_work': {'value': 'The authors refer to the (limited) previous work in the field of MetaBBO. These are relevant and recent ones.\n\nThe novelty of the proposed platform is clearly outlined, i.e. the lack of a unified benchmark platform for MetaBBO-RL.\n\nExisting BBO benchmarks are listed and compared to the proposed MetaBox.\n\nThe MetaBox platform also takes advantages of existing libraries like for some optimization algorithms thanks to API calls to DEAP and Scikit-Optimizer.'}, 'documentation': {'value': 'A comprehensive documentation is provided on the Github repository. The latter includes a quick start guide, and different “how-to”.\n\nSection 4 also provides a brief overview of the different steps to use the MetaBox platform.\n'}, 'ethics': {'value': 'No ethical concerns raised as only classical optimization benchmarks are involved.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'Interesting contributions for NeurIPS and for the RL for optimisation community.'}}, {'title': {'value': 'Official Review for MetaBox: A Benchmark Plaftform for Meta-Black-Box Optimization with Reinforcement Learning.'}, 'rating': {'value': '8: Top 50% of accepted papers, clear accept'}, 'confidence': {'value': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'summary_and_contributions': {'value': 'This paper proposes MetaBox, a benchmark platform for Meta-Black-Box Optimization (MetaBBO) using Reinforcement Learning (RL). MetaBox offers a unified yet flexible algorithmic template, allowing users to effortlessly interface and evaluate new BBO algorithms in a controlled and standardized manner. The platform includes over 300 BBO problem instances collected from synthetic and realistic scenarios, along with 19 baseline (Meta) BBO methods. Additionally, MetaBox introduces three standardized performance metrics designed to assess the baseline algorithms consistently. Lastly, the authors present the benchmarked results of BBO algorithms conducted using the proposed MetaBox.'}, 'strengths': {'value': ""- The writing is clear; the authors comprehensively describe the benchmarking problems and how the benchmark is composed, both in terms of concepts and code implementation.\n- The benchmark suite is well-designed in terms of code implementation; each module is abstracted effectively, enabling users to focus solely on algorithm implementation without needing to understand the benchmark suite's internals.\n- MetaBox offers a wide range of test suites, including both synthetic and realistic scenarios.""}, 'opportunities_for_improvement': {'value': 'While most components in the paper are self-explanatory, further elaboration on the type of benchmarking algorithms would greatly enhance readability and comprehensibility for readers. As mentioned in lines 32-33, the target benchmarking settings are formulated within a bi-level optimization framework, where the upper level involves optimizing the meta-level optimizers, and the lower level pertains to the optimization routines of black-box optimizers. Although the current writing briefly explains these targets and frameworks in lines 35-37, a more detailed discussion is warranted to provide readers with a deeper understanding of the methodology employed.'}, 'limitations': {'value': 'The authors acknowledge a potential limitation in their paper, specifically regarding the performance evaluation of BBO. They recognize that this aspect remains an open question, meaning that there might not be a definitive or universally accepted method to assess the performance of Black-Box Optimization algorithms.\n\nHowever, they do not specify further details or elaborate on this limitation in the given text. Depending on the context of the paper and the section where this statement is made, it might be useful for the authors to explain why the performance evaluation of BBO is challenging or open-ended. They could also discuss existing approaches or research gaps in this area. Providing more context and insights about this limitation can help readers understand the scope and implications of their work better.'}, 'correctness': {'value': 'Most of the results are well-measured and appear legitimate. However, there are a few areas where the presentation could be improved.\n\nThe bar charts lack information about the variations observed in the experiments. For example, in Figure 3, there is no representation of the performance variations across the runs. It would be beneficial to include error bars or confidence intervals to show the extent of variation exhibited by each baseline algorithm.\n\nBy adding these details, readers would gain a better understanding of the consistency and reliability of the baseline performances. This enhancement would provide a more comprehensive and transparent evaluation of the proposed benchmark platform and algorithms.'}, 'clarity': {'value': 'Yes, the paper is well written.'}, 'relation_to_prior_work': {'value': 'Yes, the authors explain the relationship to prior works while highlighting the distinctive features of MetaBox compared to other works.'}, 'documentation': {'value': 'The authors have provided the code and its appropriate documentation through the shared link. Additionally, in the discussion section of the paper, they offer a brief explanation of the maintenance plan and outline their future implementation plans.'}, 'ethics': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'The main evaluation setting for the number of function evaluations (maxFE) is perceived as quite unrealistic, particularly for black-box optimization involving high evaluation costs, as mentioned in lines 19-20. To address this concern, it would be beneficial to include the performance of the baseline methods over the number of function evaluations. This addition will offer a clearer perspective and enable a better understanding of how the baseline methods behave under different evaluation settings.\n\nBy incorporating this information, readers can gain insights into the effectiveness and efficiency of the baseline algorithms as the number of function evaluations varies, providing a more comprehensive assessment of their performance.'}}, {'title': {'value': 'Good paper.'}, 'rating': {'value': '7: Good paper, accept'}, 'confidence': {'value': ""1: The reviewer's evaluation is an educated guess""}, 'summary_and_contributions': {'value': 'The paper provides a benchmark for identifying low level hyper parameters through an RL setting.  The number of available problem instances are significant, the amount of algorithms available are significant as well. As far as I could sense, the work is novel and in fact, the paper is well written'}, 'strengths': {'value': 'Exhaustive nature of experiments, the availability of problem instances and the number of problem instances available. These are a big plus.\n\nThe paper is very well written and is clearly readable.\n\nI like the unified benchmark that is provided here.'}, 'opportunities_for_improvement': {'value': 'First off, I am someone who has a rudimentary knowledge of black box optimization but is unfamiliar with metaBBO RL. Therefore, before getting into MetaBox section, it will be nice to explain/formulate the problem in showing which part is BBO, which part of the problem is RL and which part is estimated by the MetaBBO-RL estimation. This is attempted in section 2 but, it is too condensed and unclear to me. I suggest a separate background section with maybe a figure.\n\nA pseudocode on usage would also benefit this paper.\n\n\n\n'}, 'limitations': {'value': 'The limitations are fairly generic and written as an afterthought. However, this is standard practice in most papers now and therefore, not a criticism but an observation'}, 'correctness': {'value': 'Appears correct and detailed'}, 'clarity': {'value': 'Well written and clear.'}, 'relation_to_prior_work': {'value': 'Good amount of literature review.'}, 'documentation': {'value': 'Very detailed documentation. '}, 'ethics': {'value': 'None that I could find.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'I liked the paper,  In my opinion, any benchmark should be exhaustive in its potential for diversity in problem instances and baseline methods. This is a side, this paper handles very well and therefore should be accepted.\n'}}, {'title': {'value': 'Review'}, 'rating': {'value': '7: Good paper, accept'}, 'confidence': {'value': '3: The reviewer is fairly confident that the evaluation is correct'}, 'summary_and_contributions': {'value': 'This paper introduces a benchmark for Meta-Black-Box Optimization with Reinforcement Learning, which aims to tune the black-box optimizers by optimizing the configurations. The key contribution of this paper is providing a template to simplify and standardize the development process. It also provides a large number of instances and baselines.'}, 'strengths': {'value': '1. The benchmark is comprehensive, with numerous instances and baselines for comparison.\n2. The documentation (README) provides sufficient details for users to use the package.\n3. The benchmark provides a standardized way to evaluate the methods in this domain.'}, 'opportunities_for_improvement': {'value': '1. It is not very clear the difference between Meta BBO tasks and traditional hyperparameter search methods. Can the existing hyperparameter search methods also be used in this task?\n2. Meta BBO seems to be also a BBO problem. Since there are already several BBO benchmarks, the value of the current benchmark could not be significant.\n3. It would be great if the authors could provide a website document instead of just README.'}, 'limitations': {'value': 'Yes'}, 'correctness': {'value': 'Yes'}, 'clarity': {'value': 'Yes'}, 'relation_to_prior_work': {'value': 'Yes'}, 'documentation': {'value': 'It would be great if the authors could provide a website document instead of just README.'}, 'ethics': {'value': 'No.'}, 'flag_for_ethics_review': {'value': '2: No, there are no or only very minor ethics concerns'}, 'additional_feedback': {'value': 'The benchmark is well-developed. The task is similar to hyperparameter search and BBO. Since there are already benchmarks for these similar tasks. The practical value of this benchmark could be limited.'}}, {'title': {'value': 'MetaBox: A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning'}, 'authors': {'value': ['Zeyuan Ma', 'Hongshu Guo', 'Jiacheng Chen', 'Zhenrui Li', 'Guojun Peng', 'Yue-Jiao Gong', 'Yining Ma', 'Zhiguang Cao']}, 'authorids': {'value': ['~Zeyuan_Ma1', '~Hongshu_Guo1', '~Jiacheng_Chen4', '~Zhenrui_Li1', '~Guojun_Peng3', '~Yue-Jiao_Gong1', '~Yining_Ma1', '~Zhiguang_Cao1']}, 'keywords': {'value': ['Black-Box Optimization', 'Meta-Black-Box Optimization', 'Reinforcement Learning', 'Benchmark Platform']}, 'TLDR': {'value': 'A novel, extendable and user-friendly Benchmark Platform for MetaBBO with Reinforcement Learning.'}, 'abstract': {'value': 'Recently, Meta-Black-Box Optimization with Reinforcement Learning (MetaBBO-RL) has showcased the power of leveraging RL at the meta-level to mitigate manual fine-tuning of low-level black-box optimizers. However, this field is hindered by the lack of a unified benchmark. To fill this gap, we introduce MetaBox, the first benchmark platform expressly tailored for developing and evaluating MetaBBO-RL methods. MetaBox offers a flexible algorithmic template that allows users to effortlessly implement their unique designs within the platform. Moreover, it provides a broad spectrum of over 300 problem instances, collected from synthetic to realistic scenarios, and an extensive library of 19 baseline methods, including both traditional black-box optimizers and recent MetaBBO-RL methods. Besides, MetaBox introduces three standardized performance metrics, enabling a more thorough assessment of the methods. In a bid to illustrate the utility of MetaBox for facilitating rigorous evaluation and in-depth analysis, we carry out a wide-ranging benchmarking study on existing MetaBBO-RL methods. Our MetaBox is open-source and accessible at: https://github.com/GMC-DRL/MetaBox.'}, 'venue': {'value': 'NeurIPS 2023 Datasets and Benchmarks Oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Track/Datasets_and_Benchmarks'}, 'pdf': {'value': '/pdf/d310e713ba14dade21b8efdd65f18d138ad5b45c.pdf'}, '_bibtex': {'value': '@inproceedings{\nma2023metabox,\ntitle={MetaBox: A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning},\nauthor={Zeyuan Ma and Hongshu Guo and Jiacheng Chen and Zhenrui Li and Guojun Peng and Yue-Jiao Gong and Yining Ma and Zhiguang Cao},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\nyear={2023},\nurl={https://openreview.net/forum?id=j2wasUypqN}\n}'}, 'paperhash': {'value': 'ma|metabox_a_benchmark_platform_for_metablackbox_optimization_with_reinforcement_learning'}}]"
"['Hamish Flynn', 'David Reeb', 'Melih Kandemir', 'Jan Peters']",NeurIPS,Improved Algorithms for Stochastic Linear Bandits Using Tail Bounds for Martingale Mixtures,https://neurips.cc/virtual/2023/oral/73845,2023," We present improved algorithms with worst-case regret guarantees for the stochastic linear bandit problem. The widely used ""optimism in the face of uncertainty"" principle reduces a stochastic bandit problem to the construction of a confidence sequence for the unknown reward function. The performance of the resulting bandit algorithm depends on the size of the confidence sequence, with smaller confidence sets yielding better empirical performance and stronger regret guarantees. In this work, we use a novel tail bound for adaptive martingale mixtures to construct confidence sequences which are suitable for stochastic bandits. These confidence sequences allow for efficient action selection via convex programming. We prove that a linear bandit algorithm based on our confidence sequences is guaranteed to achieve competitive worst-case regret. We show that our confidence sequences are tighter than competitors, both empirically and theoretically. Finally, we demonstrate that our tighter confidence sequences give improved performance in several hyperparameter tuning tasks.",Oral 6D Theory,https://openreview.net/pdf?id=TXoZiUZywf,https://openreview.net/forum?id=TXoZiUZywf,TXoZiUZywf,"[{'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Accept (oral)'}, 'comment': {'value': 'This paper proposes novel confidence bounds form martingale sequences motivated by UCB-type algorithms for contextual bandits, in the spirit of the seminal work of Abbasi-Yadkori et al. While the method also leverages mixing distributions to obtain any-time bounds via Ville’s inequality, these mixing distributions are potentially data-driven, opening the door to empirical Bayes type estimators. Even without these improved predictors, they demonstrate data-dependent and independent regret bounds using their new bounds, and demonstrate empirically that choosing data-dependent predictors can improve performance (in E.2). While regret for contextual bandits is the main motivation, the tools introduced in Abbasi-Yadkori et al have found very broad applications and this work is sure to expand this scope even further.'}}, {'comment': {'value': 'Thank you for responding to our rebuttal. Your response is a good summary of the theoretical results in the paper.\n\nThank you for raising your score and recommending acceptance.'}}, {'comment': {'value': 'Thank you for responding to our rebuttal, raising your score and recommending acceptance.'}}, {'comment': {'value': 'Thank you for responding to our rebuttal and recommending acceptance.'}}, {'comment': {'value': 'Thank you for responding to our rebuttal and raising your score.'}}, {'comment': {'value': 'Thanks for the clarifications. As the authors have clearly addressed my concerns, I am increasing my score.Thank you for the clarifications. As the authors have clearly addressed my concerns, I have increased my score.'}}, {'comment': {'value': 'I appreciate the authors addressing my concerns. Based on my understanding, while your meta-algorithm may have tighter UCBs than OFUL through appropriate parameter selection, this doesn\'t necessarily demonstrate that the current approach achieves tighter (asymptotic) worst-case regrets than OFUL (e.g., removing the  $\\ln T$ factor from the regret). However, I concur that the ""adaptive"" strategy outlined in Appendix E appears to be a promising route for attaining a tight dependency on $T$.\n\nI agree that the current work is significant enough to justify acceptance, and I\'m happy to recommend it for acceptance.'}}, {'title': {'value': 'thank you'}, 'comment': {'value': 'Thank you for the response! All comments make perfect sense. I am keeping my score and will continue to support acceptance of the paper.'}}, {'title': {'value': '...'}, 'comment': {'value': 'please share the link to this ""excellent paper"" once you remember it, all of us would be interested :)))'}}, {'comment': {'value': ""Oh, I seem to have failed to paste the paper I had in mind in, and now I had no idea what it was. My apologies.\n\nI've increased my score to 8, I believe this paper should absolutely be accepted.""}}, {'rebuttal': {'value': 'We thank the reviewer for their comments and questions.\n\nWe respond to the reviewer\'s points:\n\n* *The downside of the paper lies in its inability to improve upon the theoretical worst-case bound as shown in Abbasi-Yadkori et al., 2011. The strength of this paper would be significantly enhanced if the authors could demonstrate that employing the methodology from their current work could theoretically offer improved bounds compared to previous results (or new results in novel settings).*\n\n   While our worst-case regret bound in Thm. 7.6 only matches the equivalent regret bound for the OFUL algorithm by Abassi-Yadkori et al., we can prove that our UCBs are tighter than the OFUL UCBs. In App. C.2, we show that for any value of the OFUL regularization parameter (similar to our $\\alpha$ parameter), there are valid (and simple) choices of $\\alpha$, $\\mu_t$ and $T_t$ (which are not necessarily the optimal choices) such that our analytic UCBs (and therefore also our numerical UCBs) are always strictly tighter than the OFUL UCBs.\n\n   We believe that there is potential to obtain worst-case regret bounds with improved dependence on $T$ using our methodology. In App. E.2, we investigate “more adaptive” choices for the mixture distributions, which depend on previously observed rewards. We observe that the radius quantity grows at a slower rate (in $T$) when using these more adaptive mixture distributions. This means that the data-dependent regret bound (in Thm. 7.5) also grows at a slower rate. In future work, we would like to search for improved data-independent bounds on the radius (which would give improved worst-case regret bounds).\n\n* *I\'m curious, how would the present work compare to the general approach as in ""The Statistical Complexity of Interactive Decision Making"" by D. J. Foster, S. M. Kakade, J. Qian and A. Rakhlin.?*\n\n   The present work gives a new and improved way to *construct confidence sets* for bandits, which are turned into improved bandit algorithms with guarantees *via the UCB/LinUCB meta-algorithm* (Sec. 4). The cited work by Foster et al. turns *any online predictor* (with guarantees) into a bandit/RL algorithm (with guarantees) *via the E2D meta-algorithm*. While Foster et al. aim to establish a complexity measure for general interactive decision making, we focus on providing as tight as possible confidence statements for a given bandit task. There are many further differences between both works in the scope and in the techniques.\n\nThank you for pointing out the typos.\n\nWe hope that this addresses the reviewer\'s points. We are open to discussion.'}}, {'rebuttal': {'value': 'We thank the reviewer very much for their careful and helpful comments!\n\nWe address the reviewer\'s points under ""Weaknesses"":\n\n* *One issue I feel strongly about, but that can be easily addressed: you advertise that your confidence intervals are robust to misspecification (abstract, line 12). ...*\n\n   We understand the reviewer\'s point, thank you for pointing this out. We will remove the claim about misspecification from the abstract, and in the main text of the paper we will clarify this term by writing ""Bayesian prior misspecification"". We hope that this makes clear that we make no claim about the frequentist notion of misspecification.\n\n* *Another issue is that your plots are unreadable when printed in grayscale (all lines look the same). ...*\n\n   We will use a more grayscale-friendly color scheme for the revised version of the paper.\n\n* *High level: please reiterate in the introduction, e.g. on line 44, that your UCBs are tighter in an empirical sense; that you have not (to my understanding) shown them to be tighter in a theoretical sense. ...*\n\n   Our UCBs are tighter in a theoretical sense. In App. C.2, we show that for any value of the OFUL regularization parameter (similar to our $\\alpha$ parameter), there are valid (and simple) choices of $\\alpha$, $\\mu_t$ and $T_t$ (which are not necessarily the optimal choices) such that our analytic UCBs (and therefore also our numerical UCBs) are always strictly tighter than the OFUL UCBs. We will add a pointer to App. C.2 in the paragraph on line 44.\n\n* *High level: your method is highly related to the rather excellent paper*\n\n   We would be curious to know which excellent paper the reviewer is referring to here, especially if we haven\'t cited it in our paper yet.\n\n* *Lines 97-98, ...*\n\n   We will replace our previous statement about $\\mathcal{H}_t$-measurability with: ""each $\\Theta_t$ can be calculated using the data $a_1, r_1, \\dots, a_t, r_t$.""\n\n* *Lines 95 to 100: ...*\n\n   After this paragraph we will add the sentence: ""We remark that the confidence sets $\\Theta_t$ in this paper are random closed sets in the sense of [Molchanov, Def. 1.1.1], which implies that the event $\\theta\\in\\Theta_t$ is actually measurable for any $\\theta\\in\\mathbb{R}^d$.""\n\n* *On your assumptions 7.1-7.4: It seems to me that 7.2+7.3 together imply a bound of the form asked for in 7.4; is there a good reason you have a separate assumption 7.4?*\n\n   We agree that 7.2 + 7.3 imply assumption 7.4 with $C = LB$. Our reasons for stating a separate assumption are: (a) this is in line with the conventions of other linear bandit analyses (e.g. [Lattimore and Szepesvári, Section 19.3]); (b) this leaves open the possibility that a better (than $LB$) value for $C$ is known.\n\nThe reviewer\'s other minor points under ""Weaknesses"" which we did not address above, we will directly fix in the paper as suggested.\n\n[Lattimore and Szepesvári] Lattimore, T. and Szepesvári, C., *Bandit algorithms.* Cambridge University Press. 2020.\n\n'}}, {'rebuttal': {'value': 'We thank the reviewer for their comments. We are very happy to receive such an enthusiastic review!\n\nWe now address the reviewer\'s points under ""Weaknesses"":\n\n* *how one should choose the predictions mu_t and T_t ... I still wonder how the choice will impact the quality of the guarantees ... For instance, is setting mu_t as the least squares estimator and T_t as the Grammian a good idea? It feels somewhat unsatisfying to introduce all the possibilities for adaptivity and then simply set a constant lambda_t and go with the standard choice of mu and T ...*\n\n   The effects of $\\mu_t$ and $T_t$ on the tightness of the UCBs and the regret guarantees are determined by their effects on the squared radius $R_{\\mathrm{MM}, t}^2$, which is defined in Eq. (5). Based on Eq. (5), we can treat the mean vector $\\mu_t$ as a prediction of the reward vector $r_t$. The covariance matrix $T_t$ can be thought of as the uncertainty associated with this prediction. If the distance between $\\mu_t$ and $r_t$ is close to 0 (i.e. $\\mu_t$ is a good predictor of $r_t$), then the quadratic ""prediction error"" term in (5) will be close to 0, and we can afford to choose $T_t$ close to zero to minimize the log determinant term.\n\n   Unfortunately, we cannot simply choose $\\mu_t = r_t$, because then the mixture distributions would not satisfy the conditions in lines 812-816 (i.e. each component of $\\mu_t$ can only depend on the *preceding* rewards). Hence, we can think of the $k$th component of $\\mu_t$ a prediction/guess/bet for the $k$th reward.\n\n   We agree that it is exciting to consider more adaptive choices of $\\lambda_t$, $\\mu_t$ and $T_t$. In App. E.2, we investigate a generic method for setting $\\mu_t$ and $T_t$ based on previously observed actions and rewards; this results in somewhat lower regret in an experiment (Fig. 6 in App. E.2) and possibly better regret bounds. In App. B.1, we derive the radius $R_{\\mathrm{MM}, t}$ for more general choices of $\\lambda_t$. However, we don\'t analyze these choices of $\\lambda_t$, $\\mu_t$ and $T_t$ in the main paper because: (a) these choices make the resulting bandit algorithms very difficult to analyze theoretically; (b) we already struggled to fit everything into the 9 page limit. We view the analysis of more adaptive versions of our method as an exciting challenge to address in future work.\n\n* *Also, the confidence set proposed in Section 6.2 doesn\'t seem all that different from the standard tail bound popularized by Abbasi-Yadkori et al. Accordingly, the regret bounds of Theorem 7.5 and 7.6 also take the same for as previous bounds, which is not unexpected given how the theorems are stated for rather generic choices of mu and T. I can see that the new bounds could be tighter, but at the moment the theory does not reflect this, which is somewhat disappointing.*\n\n   In App. C.2, we compare our analytic UCBs (from Thm. 6.1) to the OFUL UCBs. We prove that for any value of the OFUL regularization parameter (similar to our $\\alpha$ parameter), there are valid (and simple) choices of $\\alpha$, $\\mu_t$ and $T_t$ (which are not necessarily the optimal choices) such that our analytic UCBs (and therefore also our convex-program UCBs from Eq. (6)) are always strictly tighter than the OFUL UCBs. Furthermore, there is hope that more the adaptive choices for $\\mu_t$ and $T_t$ described in App. E.2 could lead to regret bounds with an improved growth rate in $T$. See Fig. 6 in App. E.2 and the discussion below it for more.\n\n* *One additional thing that I would like to comment on is the computational complexity of the resulting method. ... This is generally true for all UCB-like methods I can think of, so perhaps it is a bit odd to avoid discussing this question altogether ... I think it would be nice to add a comment on this in order to not mislead more casual readers who may not be familiar with this computational difficulty.*\n\n   We fully agree with the reviewer on this point. We will add a comment on this in the revised paper.'}}, {'rebuttal': {'value': 'We thank the reviewer for their kind and constructive comments.\n\nWe now address the reviewer\'s points under ""Weaknesses"":\n\n1. The reason for choosing Gaussian mixture distributions is that the expected value just above Eq. (5) can be calculated analytically when $P_t$ is a Gaussian, which is convenient for running the algorithm and for proving regret bounds. Restricting the mixture distributions to be Gaussian does not impose any assumptions on the ground truth reward function or the bandit problem. The mixture distributions can simply be thought of as hyperparameters of our bandit algorithm.  \n\n2. Our bandit algorithm applies to kernel bandits with minor modifications. The main challenge is in obtaining data-independent regret bounds analogous to the one in Thm. 7.6, since the feature dimension is $d=\\infty$ for interesting kernels.\n\n   In more detail, our confidence sequences in Corollary 5.2 can be immediately extended to non-linear reward functions $f^*$, simply by replacing $\\phi(a_t)^\\top\\theta^*$ with $f^*(a_t)$ in the definition of $Z_t(f_t)$. The result is a confidence set, as in Corollary 5.2, with a squared error constraint for non-linear functions $f$ and a suitable boundedness constraint $\\Vert f\\Vert\\leq B$. For kernel bandits, the corresponding UCB is still the solution of a convex program, so we can run our CMM-UCB and AMM-UCB algorithms in kernel bandit problems. While the data-dependent regret bound in Thm. 7.5 remains basically unaltered, the (derivation of the) data-independent regret bound in Thm. 7.6 must be modified. The main challenge is that the regret bound must now depend on quantities like the effective dimension or the maximum information gain of the kernel instead of the dimension $d$ of the feature vectors (which is $d=\\infty$ for interesting kernels).\n\n   We will explain this in more detail in the revised version of the paper.\n\n3. i. The random variables $Z_t(f_t)$ in our submission play a similar role to the random variables $Z_t$ in [Russo and Van Roy, App. B.1].\n\n   ii. A standard choice is $\\mu_t\\equiv 0$ and $T_t = \\Phi_t\\Phi_t^\\top$, which can be motivated by choosing $\\theta\\sim{\\mathcal N}(0,I)$ and then considering the distribution of the function values $\\Phi_t\\theta$. In general, $\\boldsymbol{\\mu}_t$ and $\\boldsymbol{T}_t$ can be freely chosen as long as the sequence of mixture distributions $(\\mathcal{N}(\\boldsymbol{\\mu}_t, \\boldsymbol{T}_t) |t \\in \\mathbb{N})$ satisfies the requirements for being a sequence of adaptive mixture distributions; see lines 126-130 for general mixture distributions and lines 812-816 for Gaussian mixture distributions. A particular adaptive choice of $\\mu_t$ and $T_t$ is examined in App. E.2 (i.e. such that the entries of $\\mu_t$ and $T_t$ depend on the previously observed rewards, namely they are predictors of the reward at the newly selected action), and shown to yield good results.\n\n   iii. The growth rate in $T$ of the regret bound in Thm. 7.5 is determined by the growth rate of the radius and the sum of norms. If we upper bound each of these terms by quantities with explicit dependence on $T$, then we arrive at the data-independent bound in Thm. 7.6. We can therefore say that the dependence on $T$ of the regret bound in Thm. 7.5 is no worse than that of the regret bound in Thm. 7.6 (i.e. no worse than $\\mathcal{O}(\\sqrt{T}\\ln(T))$).\n\n   iv. There are at least two good choices of $c$. In all of our experiments, we used $c = 1$, which is a simple choice that appears to work well. Alternatively, one can choose $c = B$. With this choice, the data-independent regret bound in Thm. 7.6. has improved dependence on the norm bound $B$ (roughly $\\mathcal{O}(\\sqrt{B})$ instead of $\\mathcal{O}(B)$).\n\n   v. One can think of the real number $\\sigma_0$ as a guess for the distance between the observed reward vector $\\boldsymbol{r}_t$ and the predictions $\\Phi_t\\boldsymbol{\\theta}_0$. Consider Eq. (5) with $\\boldsymbol{\\mu}_t = \\Phi_t\\boldsymbol{\\theta}_0$ and $\\boldsymbol{T}_t = \\sigma_0^2\\Phi_t\\Phi_t^{\\top}$. If the distance between $\\Phi_t\\boldsymbol{\\theta}_0$ and $\\boldsymbol{r}_t$ is close to 0, then we should choose $\\sigma_0$ to be close to 0, since both the quadratic and log determinant terms in Eq. (5) will then be close to 0. Alternatively, if the distance between $\\Phi_t\\boldsymbol{\\theta}_0$ and $\\boldsymbol{r}_t$ is large, we should choose a larger $\\sigma_0$ so that the quadratic term in (5) is not too large. We call $\\sigma_0$ a guess because it has to be chosen *before* observing $\\Phi_t\\boldsymbol{\\theta}_0$ and $\\boldsymbol{r}_t$.\n\nThank you for pointing out the typo on line 303.\n\nWe hope that the reviewer can now recommend acceptance of the paper.\n\n[Russo and Van Roy] Russo, D. and Van Roy, B., Eluder dimension and the sample complexity of optimistic exploration. *Advances in Neural Information Processing Systems*, 26. 2013.\n'}}, {'summary': {'value': 'This paper studies the stochastic linear bandits problem and proposes an improved algorithm with sub-linear regret guarantees. The improvement is achieved using a novel tail bound for adaptive martingale mixtures to construct tighter upper confidence bounds, which leads to a smaller regret than existing algorithms for linear bandits. The authors also verify the performance of the proposed algorithm via experiments on hyperparameter tuning tasks. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '4 excellent'}, 'strengths': {'value': '#### **The following are the strengths of the paper:**\n1. The performance of any upper confidence bound (UCB) based bandit algorithm depends on the tightness of the confidence bounds. This paper proposes a novel way (using the tail bound for adaptive martingale mixtures) to improve the upper confidence bound, leading to an improved UCB-based bandit algorithm with a smaller regret.\n\n2. The authors propose two novel methods for computing the confidence bounds: Convex Martingale Mixture UCB (CMM-UCB) and Analytic Martingale Mixture UCB (AMM-UCB). CMM-UCB uses a convex solver for the UCB maximization (gradient differentiable convex optimization), whereas AMM-UCB uses a weak Lagrangian duality to obtain an analytic UCB (gradient can be computed in closed-form or via standard automatic differentiation procedures). \n\n3. When the mixture distribution is a Gaussian distribution, the authors showed the sub-linear data dependent/ independent cumulative regret for CMM_UCB and AMM-UCB. The author also empirically validated the performance gain of the proposed methods over existing linear bandit algorithms. '}, 'weaknesses': {'value': ""#### **The following are the weaknesses of the paper:**\n1. Assumption of mixture distribution having Gaussian distributions: The regret bounds stated in the paper hold only when the mixture distribution is Gaussian. It is unclear from the paper how practical this assumption is and what the consequences are (especially in analysis) if this assumption does not hold. \n\n2. Linearity assumption: Assuming a linear relationship between the reward and action's features (in high dimensional space using a known feature map) restricts the applications of proposed methods. Even though authors claim their tail bounds can be used to derive confidence sequences for non-linear reward functions, it is unclear what are the challenges of extending their work to non-linear reward functions (or kernelized bandits).\n\n\n3. Unexplained notations: Many notations are not properly defined in the paper. For examples: \\\ni. Line 145: What is $Z_t(f_t)$ connection with existing regret analysis (e.g., OFUL)? \\\nii. Line 149: How are the parameters ($\\boldsymbol{\\mu}_t, \\boldsymbol{T}_t$) of Gaussian distribution computed? \\\niii. In Theorem 7.5: what is the regret upper bound in terms of $T$? \\\niv. Line 234: How to set the value of $c$? \\\nv: Line 248: What is $\\sigma_0$ and how to set its value? ""}, 'questions': {'value': ""Please address the weakness raised in ***Weaknesses**. \n\nMinor comment:\n1. Line  303: FTS: Freq-TS\n\nI can change my score based on the authors' responses.""}, 'limitations': {'value': 'I have raised a few limitations of the paper in my response to the ***Weaknesses**. Since the paper is a theoretical contribution to linear bandits literature, I do not find any potential negative societal impact of this work.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'The paper considers the problem of stochastic linear contextual bandits, and proposes an improvement of the classic LinUCB / OFUL algorithmic template via a more sophisticated construction of the confidence sets for the hidden reward vector. The improvement comes from replacing the confidence ellipsoid used since the classic work of Abbasi-Yadkori et al. (based on the method of mixtures) with a tighter confidence set based on what the authors call ""adaptive martingale mixtures"". The authors eventually derive a confidence ellipsoid resembling the ones used by Russo and Van Roy, which enjoys the useful property of having a potentially data-dependent radius, and can also be turned into a confidence sequence very easily via an application of Ville\'s inequality. Using two different methods (an exact convex solver and an approximation of the optimal width), the authors then turn these confidence sets for theta into confidence bounds for the rewards of each action, and use the resulting bounds in a UCB scheme. The algorithms are then shown to outperform standard LinUCB in some simple experiments.'}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'The paper is superbly written and presents a very interesting technique, improving one of the main building blocks of UCB algorithms that have been used for over a decade without any substantial changes. The proposed techniques make use of techniques that have recently gained popularity for mean estimation and proving PAC-Bayesian generalization bounds. The derivations up until the end of Section 5 are very neat and satisfying, and I believe that everyone interested in confidence ellipsoids and linear bandits should find them interesting.\n'}, 'weaknesses': {'value': 'The concrete approaches proposed in Section 6 are also nice but leave something to be desired. Perhaps it is my fault, but I have missed how one should choose the predictions mu_t and T_t. From what I understand, both approaches in Sections 6.1 and 6.2 should give valid results irrespective of the choice of these parameters, but I still wonder how the choice will impact the quality of the guarantees. The authors only suggest that choosing mu and T that ""are good predictors of the (stochastic) reward r"" will yield good results, but do not elaborate further. For instance, is setting mu_t as the least squares estimator and T_t as the Grammian a good idea? It feels somewhat unsatisfying to introduce all the possibilities for adaptivity and then simply set a constant lambda_t and go with the standard choice of mu and T... Also, the confidence set proposed in Section 6.2 doesn\'t seem all that different from the standard tail bound popularized by Abbasi-Yadkori et al. Accordingly, the regret bounds of Theorem 7.5 and 7.6 also take the same for as previous bounds, which is not unexpected given how the theorems are stated for rather generic choices of mu and T. I can see that the new bounds *could* be tighter, but at the moment the theory does not reflect this, which is somewhat disappointing.\n\nOne additional thing that I would like to comment on is the computational complexity of the resulting method. I understand that the UCB\'s obtained from the method are always convex in the feature representation of the actions (given how they are a maximum of linear functions). Thus, calculating the action with maximal UCB is a convex maximization problem, which is NP-hard in general. This is generally true for all UCB-like methods I can think of, so perhaps it is a bit odd to avoid discussing this question altogether in the paper and suggest that the gradient-based optimization scheme for finding the optimistic actions is a theoretically well-justified idea. (It is not, but I understand that it often still works in practice.) I think it would be nice to add a comment on this in order to not mislead more casual readers who may not be familiar with this computational difficulty.\n\nDespite all my criticism above, I am happy to support acceptance of this paper to the NeurIPS program. I am looking forward to future literature addressing the current limitations of the approach proposed in this otherwise very nice paper.'}, 'questions': {'value': 'See above.'}, 'limitations': {'value': 'N/A'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'A very well written paper introducing a slightly different way of constructing confidence sets for $\\theta^\\star$ in the adaptive regression setting. The two main differences are that the paper bounds the norm of the observation noises $\\epsilon_t$ directly, rather than the projection of the noises that features in the standard bound. This is done by showing that the method of mixtures can be used with a suitably adapted sequence of mixing measures, and choosing that mixture appropriately. '}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': 'Paper is _very_ well written. Method introduced is neat and the perspective taken in deriving it will be of interest to other researchers in adaptive regression/design. '}, 'weaknesses': {'value': ""I don't believe the paper has any significant weaknesses. One could argue that it has, perhaps, limited scope: but bandits and adaptive regression/design are very popular topics nowadays, and this is an interesting read for many people interested in those.\n\nOne issue I feel strongly about, but that can be easily addressed: you advertise that your confidence intervals are robust to misspecification (abstract, line 12). I was very disappointed to see, when I got to section 8.1 and particularly lines 282-289, that you mean misspecification to a prior in a Bayesian setting. The general setting of your work is frequentist, and in the frequentist setting, misspecification has a well understood meaning which, of course, does not coincide with that which you show. It is unclear that your method is any better in this respect than the standard concentration inequality used in OFUL (Yasin's original work); and indeed, that's a generous interpretation: it is generally accepted that bounds derived under frequentist assumptions work well in a misspecified Bayesian setting. Please remove this claim from your abstract.\n\nAnother issue is that your plots are unreadable when printed in grayscale (all lines look the same). I'm reviewing a grayscale printed version of this paper, so cannot asses empirical performance from plots. Fortunately for you, I also happen to care little for empirical results.\n\nI have some minor feedback, solely for the purpose of improving the manuscript:\n\n-High level: please reiterate in the introduction, e.g. on line 44, that your UCBs are tighter in an empirical sense; that you have not (to my understanding) shown them to be tighter in a theoretical sense. Your results are neat: by risking the perception that you might be overclaiming/misleading you'd be doing yourself a disservice. \n\n-High level: your method is highly related to the rather excellent paper \n\n-Line 65: the result you cite Chowdhury & Gopalan 2017 for is implied directly by theorem 4.1 in Yasin Abbasi-Yadkori's PhD thesis (2012); that the result of Chowdhury & Gopalan was novel is an error in the literature that ought not be propagated.\n\n-Lines 97-98, you state that $\\mathcal{H}_t$-measurability equates to 'can be calculated using the data available just after reward $r_t$ is revealed'. From the rest of the paper, I know that you know that this isn't true. It may seem like a nice simplifying explanation, but its misleading, and often inexperienced authors make a mess of things because they take that to be the definition. Indeed, in your setting, the event $\\{ \\theta^\\star \\in \\Theta_t\\}$ is $\\mathcal{H}_t$ measurable (assuming $\\Theta_t$ is a closed set, see next comment), since $\\theta^\\star$ is a constant and $\\Theta_t$ is a measurable random set. But $\\theta^\\star$ is explicitly unknown at the end of the $t$th iteration, and so the indicator of $\\theta^\\star \\in \\Theta_t$  _cannot_ be computed with the information available at that point. Please remove that statement, and if you feel the reader might need a primer on measurability, please include a reference to any standard measure/probability textbook.\n\n-Lines 95 to 100: you define what are effectively random sets with a certain property. One has to be careful around the definitions of random sets to ensure they behave in a way that one would expect. For example, we'd usually like that for a random set $A'$ subset of $A$, for any $a \\in A$, the event $\\{a \\in A'\\}$ is measurable. Your sets are closed and you work on a Polish space, so this is true; but I would point out that this is so (and indeed, you might run into trouble if the confidence sets were open). See Molchanov, Ilya: Theory of Random Sets. Springer London. 2017, 2nd edition. Proposition 1.1.2; that should be all you need.\n\n-Eq (5), I would point out that this is just the 2-norm of $\\epsilon_t$; this makes it much clearer, for example, where your naive bound of line 158 comes from.\n\n-On your assumptions 7.1-7.4: It seems to me that 7.2+7.3 together imply a bound of the form asked for in 7.4; is there a good reason you have a separate assumption 7.4? \n\nPS: I have not read the appendix. I am confident from the sketches in the main text that the result claimed goes through.""}, 'questions': {'value': 'I included some minor questions in the weaknesses section. I have no major questions for the authors.'}, 'limitations': {'value': 'Some aspects of the writing could be thought to overclaim, specifically when it comes to robustness to misspecification. I feel strongly that this ought to be addressed. But this is also easily fixable; I hope the authors do so.\n\n'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, {'summary': {'value': 'This paper studies the stochastic linear bandits as introduced in Abbasi-Yadkori et al., 2011. Here, at each time step $t$, an action set $\\mathcal{A}_t$ is given. The learner then selects an action $a_t \\in \\mathcal{A}_t$, which maps to a feature vector $\\phi(a_t)$, and subsequently receives a reward $\\phi(a_t)^{\\mathsf{T}}\\pmb{\\theta}^*+\\epsilon_t$. The objective is to maximize the cumulative rewards over a designated time horizon $T$.\n\nThe main contributions of this paper can be summarized as:\n\n1. The authors propose a general approach based on the notion of Martingale Mixtures to create confidence sets. These are subsequently utilized in the meta LinUCB algorithm to derive the bandit algorithms. It is further demonstrated that such algorithms can be efficiently computed via convex optimization.\n\n2. The paper shows that such bandit algorithm derived from a suitable selection of mixture distributions $P_t$ attains the same worst-case regret as found in Abbasi-Yadkori et al., 2011.\n\n3. Evidence is presented to show that the algorithm derived in this paper outperforms the approach proposed in Abbasi-Yadkori et al., 2011 when applied to several real-world datasets.'}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '3 good'}, 'strengths': {'value': ""While I'm not thoroughly acquainted with the most recent literature on stochastic linear bandits, this paper appears to present compelling results. The idea of using mixture martingales to derive linear bandit algorithms is innovative and provides a general methodology for generating new algorithms. The authors supplement their theoretical contributions with empirical evidence showing that their algorithm outperforms those presented in previous literature, further strengthening their findings.""}, 'weaknesses': {'value': 'The downside of the paper lies in its inability to improve upon the theoretical worst-case bound as shown in Abbasi-Yadkori et al., 2011. The strength of this paper would be significantly enhanced if the authors could demonstrate that employing the methodology from their current work could theoretically offer improved bounds compared to previous results (or new results in novel settings).\n\nTypos:\n- Line 216,  $\\sum_{t=1}^T$ is missing\n- Line 696,  AUCB appeared twice'}, 'questions': {'value': 'I\'m curious, how would the present work compare to the general approach as in ""The Statistical Complexity of Interactive Decision Making"" by D. J. Foster, S. M. Kakade, J. Qian and A. Rakhlin.?'}, 'limitations': {'value': 'No issue with negative societal impact.'}, 'flag_for_ethics_review': {'value': ['No ethics review needed.']}, 'rating': {'value': '7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, {'title': {'value': 'Improved Algorithms for Stochastic Linear Bandits Using Tail Bounds for Martingale Mixtures'}, 'authors': {'value': ['Hamish Flynn', 'David Reeb', 'Melih Kandemir', 'Jan Peters']}, 'authorids': {'value': ['~Hamish_Flynn1', '~David_Reeb2', '~Melih_Kandemir1', '~Jan_Peters3']}, 'keywords': {'value': ['Linear bandits', 'confidence sequences', 'martingales', 'convex optimization', 'cumulative regret', 'regret analysis']}, 'abstract': {'value': 'We present improved algorithms with worst-case regret guarantees for the stochastic linear bandit problem. The widely used ""optimism in the face of uncertainty"" principle reduces a stochastic bandit problem to the construction of a confidence sequence for the unknown reward function. The performance of the resulting bandit algorithm depends on the size of the confidence sequence, with smaller confidence sets yielding better empirical performance and stronger regret guarantees. In this work, we use a novel tail bound for adaptive martingale mixtures to construct confidence sequences which are suitable for stochastic bandits. These confidence sequences allow for efficient action selection via convex programming. We prove that a linear bandit algorithm based on our confidence sequences is guaranteed to achieve competitive worst-case regret. We show that our confidence sequences are tighter than competitors, both empirically and theoretically. Finally, we demonstrate that our tighter confidence sequences give improved performance in several hyperparameter tuning tasks.'}, 'venue': {'value': 'NeurIPS 2023 oral'}, 'venueid': {'value': 'NeurIPS.cc/2023/Conference'}, 'TLDR': {'value': 'Based on novel mixture martingales, we obtain tighter confidence bounds for linear bandits resulting in better algorithms with performance guarantees.'}, 'pdf': {'value': '/pdf/3a71f29ab9ae45f25289a53b54d94f20e1b477dd.pdf'}, '_bibtex': {'value': '@inproceedings{\nflynn2023improved,\ntitle={Improved Algorithms for Stochastic Linear Bandits Using Tail Bounds for Martingale Mixtures},\nauthor={Hamish Flynn and David Reeb and Melih Kandemir and Jan Peters},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=TXoZiUZywf}\n}'}, 'paperhash': {'value': 'flynn|improved_algorithms_for_stochastic_linear_bandits_using_tail_bounds_for_martingale_mixtures'}}]"
