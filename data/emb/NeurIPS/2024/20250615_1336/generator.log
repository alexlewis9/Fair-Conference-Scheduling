2025-06-15 13:36:43,706 - root - INFO - Generating embeddings for data/unified_text/NeurIPS/NeurIPS_2024.json
2025-06-15 13:36:43,768 - src.data_processing.generate_embeddings - INFO - Embedding started
2025-06-15 13:36:43,768 - src.data_processing.generate_embeddings - INFO - Model: gemini-embedding-exp-03-07
2025-06-15 13:36:43,768 - src.data_processing.generate_embeddings - INFO - Input file: data/unified_text/NeurIPS/NeurIPS_2024.json
2025-06-15 13:36:43,768 - src.data_processing.generate_embeddings - INFO - Encoding entry: aVh9KRZdRk
2025-06-15 13:36:43,768 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:43,843 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:43,953 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:44,002 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:44,109 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:44,165 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:44,265 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:44,316 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:44,420 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:44,422 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:44,422 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:44,964 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:44,973 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:44,974 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:44,975 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:44,976 - src.data_processing.generate_embeddings - INFO - [OK] aVh9KRZdRk
2025-06-15 13:36:44,976 - src.data_processing.generate_embeddings - INFO - Encoding entry: m1a4CrRJR7
2025-06-15 13:36:44,976 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:45,020 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:45,130 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:45,170 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:45,282 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:45,326 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:45,438 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:45,485 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:45,596 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:45,597 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:45,597 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:46,133 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:46,138 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:46,138 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:46,139 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:46,139 - src.data_processing.generate_embeddings - INFO - [OK] m1a4CrRJR7
2025-06-15 13:36:46,139 - src.data_processing.generate_embeddings - INFO - Encoding entry: 0XeNkkENuI
2025-06-15 13:36:46,139 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:46,182 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:46,291 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:46,339 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:46,454 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:46,504 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:46,613 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:46,662 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:46,767 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:46,769 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:46,769 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:47,318 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:47,320 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:47,320 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:47,320 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:47,320 - src.data_processing.generate_embeddings - INFO - [OK] 0XeNkkENuI
2025-06-15 13:36:47,320 - src.data_processing.generate_embeddings - INFO - Encoding entry: wpGJ2AX6SZ
2025-06-15 13:36:47,320 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:47,363 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:47,480 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:47,537 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:47,638 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:47,686 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:47,794 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:47,838 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:47,947 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:47,947 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:47,948 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:48,471 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:48,475 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:48,475 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:48,475 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:48,476 - src.data_processing.generate_embeddings - INFO - [OK] wpGJ2AX6SZ
2025-06-15 13:36:48,476 - src.data_processing.generate_embeddings - INFO - Encoding entry: aIPwlkdOut
2025-06-15 13:36:48,476 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:48,517 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:48,628 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:48,669 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:48,782 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:48,824 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:48,947 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:48,988 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:49,100 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:49,102 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:49,102 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:49,646 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:49,649 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:49,650 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:49,650 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:49,650 - src.data_processing.generate_embeddings - INFO - [OK] aIPwlkdOut
2025-06-15 13:36:49,651 - src.data_processing.generate_embeddings - INFO - Encoding entry: UdxpjKO2F9
2025-06-15 13:36:49,651 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:49,695 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:49,804 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:49,847 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:49,961 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:50,004 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:50,119 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:50,163 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:50,275 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:50,277 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:50,277 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:50,812 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:50,815 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:50,816 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:50,816 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:50,816 - src.data_processing.generate_embeddings - INFO - [OK] UdxpjKO2F9
2025-06-15 13:36:50,816 - src.data_processing.generate_embeddings - INFO - Encoding entry: LEzx6QRkRH
2025-06-15 13:36:50,817 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:50,857 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:50,966 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:51,012 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:51,125 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:51,175 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:51,280 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:51,327 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:51,431 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:51,432 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:51,432 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:51,964 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:51,969 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:51,969 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:51,970 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:51,970 - src.data_processing.generate_embeddings - INFO - [OK] LEzx6QRkRH
2025-06-15 13:36:51,970 - src.data_processing.generate_embeddings - INFO - Encoding entry: pGEY8JQ3qx
2025-06-15 13:36:51,970 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:52,009 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:52,127 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:52,176 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:52,281 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:52,328 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:52,439 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:52,483 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:52,595 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:52,597 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:52,597 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:53,116 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:53,119 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:53,120 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:53,120 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:53,120 - src.data_processing.generate_embeddings - INFO - [OK] pGEY8JQ3qx
2025-06-15 13:36:53,120 - src.data_processing.generate_embeddings - INFO - Encoding entry: 0NMzBwqaAJ
2025-06-15 13:36:53,120 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:53,165 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:53,266 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:53,318 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:53,416 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:53,470 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:53,572 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:53,621 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:53,732 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:53,733 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:53,733 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:54,243 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:54,247 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:54,247 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:54,248 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:54,248 - src.data_processing.generate_embeddings - INFO - [OK] 0NMzBwqaAJ
2025-06-15 13:36:54,248 - src.data_processing.generate_embeddings - INFO - Encoding entry: bCMpdaQCNW
2025-06-15 13:36:54,248 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:54,290 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:54,400 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:54,446 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:54,561 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:54,605 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:54,717 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:54,763 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:54,876 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:54,879 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:54,879 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:55,411 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:55,415 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:55,415 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:55,416 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:55,416 - src.data_processing.generate_embeddings - INFO - [OK] bCMpdaQCNW
2025-06-15 13:36:55,416 - src.data_processing.generate_embeddings - INFO - Encoding entry: YvA8UF0I37
2025-06-15 13:36:55,416 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:55,456 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:55,500 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:55,613 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:55,656 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:55,698 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:55,741 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:55,781 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:55,821 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:55,822 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:55,822 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:56,341 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:56,346 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:56,346 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:56,346 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:56,347 - src.data_processing.generate_embeddings - INFO - [OK] YvA8UF0I37
2025-06-15 13:36:56,347 - src.data_processing.generate_embeddings - INFO - Encoding entry: cFqAANINgW
2025-06-15 13:36:56,347 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:56,387 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:56,437 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:56,480 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:56,525 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:56,568 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:56,611 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:56,651 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:56,728 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:56,730 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:56,730 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:57,255 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:57,258 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:57,258 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:57,259 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:57,259 - src.data_processing.generate_embeddings - INFO - [OK] cFqAANINgW
2025-06-15 13:36:57,259 - src.data_processing.generate_embeddings - INFO - Encoding entry: TFZlFRl9Ks
2025-06-15 13:36:57,259 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:57,299 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:57,338 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:57,379 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:57,419 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:57,463 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:57,507 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:57,550 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:57,597 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:57,599 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:57,599 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:58,135 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:58,138 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:58,138 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:58,138 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:58,138 - src.data_processing.generate_embeddings - INFO - [OK] TFZlFRl9Ks
2025-06-15 13:36:58,138 - src.data_processing.generate_embeddings - INFO - Encoding entry: OycU0bAus6
2025-06-15 13:36:58,138 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:58,176 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:58,215 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:58,255 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:58,295 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:58,336 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:58,380 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:58,420 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:58,461 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:58,462 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:58,462 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:58,967 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:58,969 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:58,969 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:58,969 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:58,969 - src.data_processing.generate_embeddings - INFO - [OK] OycU0bAus6
2025-06-15 13:36:58,969 - src.data_processing.generate_embeddings - INFO - Encoding entry: QDYts5dYgq
2025-06-15 13:36:58,969 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:59,008 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:59,049 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:59,091 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:59,133 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:59,178 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:59,217 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:59,258 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:59,297 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:59,298 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:36:59,298 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:36:59,814 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:36:59,817 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:36:59,817 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:36:59,818 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:36:59,818 - src.data_processing.generate_embeddings - INFO - [OK] QDYts5dYgq
2025-06-15 13:36:59,818 - src.data_processing.generate_embeddings - INFO - Encoding entry: SSCtCq2MH2
2025-06-15 13:36:59,818 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:36:59,863 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:59,904 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:59,945 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:36:59,987 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:00,031 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:00,072 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:00,119 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:00,159 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:00,161 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:00,161 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:00,703 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:00,705 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:00,705 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:00,706 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:00,706 - src.data_processing.generate_embeddings - INFO - [OK] SSCtCq2MH2
2025-06-15 13:37:00,706 - src.data_processing.generate_embeddings - INFO - Encoding entry: R8SolCx62K
2025-06-15 13:37:00,706 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:00,751 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:00,793 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:00,834 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:00,876 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:00,917 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:00,963 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:01,006 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:01,051 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:01,054 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:01,054 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:01,582 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:01,587 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:01,587 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:01,588 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:01,588 - src.data_processing.generate_embeddings - INFO - [OK] R8SolCx62K
2025-06-15 13:37:01,588 - src.data_processing.generate_embeddings - INFO - Encoding entry: C4NbtYnyQg
2025-06-15 13:37:01,588 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:01,633 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:01,678 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:01,722 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:01,763 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:01,806 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:01,846 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:01,884 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:01,922 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:01,922 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:01,923 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:02,459 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:02,462 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:02,462 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:02,462 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:02,462 - src.data_processing.generate_embeddings - INFO - [OK] C4NbtYnyQg
2025-06-15 13:37:02,462 - src.data_processing.generate_embeddings - INFO - Encoding entry: tnh4LK72yj
2025-06-15 13:37:02,462 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:02,503 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:02,547 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:02,587 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:02,629 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:02,672 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:02,712 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:02,754 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:02,796 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:02,845 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:02,846 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:02,846 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:03,382 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:03,386 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:03,386 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:03,386 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:03,386 - src.data_processing.generate_embeddings - INFO - [OK] tnh4LK72yj
2025-06-15 13:37:03,387 - src.data_processing.generate_embeddings - INFO - Encoding entry: HRkniCWM3E
2025-06-15 13:37:03,387 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:03,425 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:03,471 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:03,510 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:03,549 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:03,592 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:03,629 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:03,667 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:03,705 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:03,706 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:03,706 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:04,238 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:04,240 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:04,240 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:04,241 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:04,241 - src.data_processing.generate_embeddings - INFO - [OK] HRkniCWM3E
2025-06-15 13:37:04,241 - src.data_processing.generate_embeddings - INFO - Encoding entry: kq166jACVP
2025-06-15 13:37:04,241 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:04,276 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:04,313 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:04,349 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:04,395 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:04,435 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:04,475 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:04,519 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:04,560 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:04,561 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:04,562 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:05,103 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:05,105 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:05,106 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:05,106 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:05,106 - src.data_processing.generate_embeddings - INFO - [OK] kq166jACVP
2025-06-15 13:37:05,106 - src.data_processing.generate_embeddings - INFO - Encoding entry: Pezt0xttae
2025-06-15 13:37:05,106 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:05,145 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:05,182 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:05,231 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:05,276 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:05,325 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:05,367 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:05,408 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:05,448 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:05,449 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:05,449 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:05,984 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:05,985 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:05,985 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:05,985 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:05,985 - src.data_processing.generate_embeddings - INFO - [OK] Pezt0xttae
2025-06-15 13:37:05,985 - src.data_processing.generate_embeddings - INFO - Encoding entry: REIK4SZMJt
2025-06-15 13:37:05,985 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:06,026 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:06,064 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:06,106 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:06,149 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:06,190 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:06,229 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:06,266 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:06,303 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:06,346 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:06,346 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:06,346 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:06,879 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:06,884 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:06,884 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:06,885 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:06,885 - src.data_processing.generate_embeddings - INFO - [OK] REIK4SZMJt
2025-06-15 13:37:06,885 - src.data_processing.generate_embeddings - INFO - Encoding entry: rtz4df9IF1
2025-06-15 13:37:06,885 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:06,928 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:06,971 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:07,011 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:07,048 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:07,087 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:07,126 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:07,169 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:07,207 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:07,208 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:07,208 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:07,706 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:07,710 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:07,710 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:07,710 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:07,711 - src.data_processing.generate_embeddings - INFO - [OK] rtz4df9IF1
2025-06-15 13:37:07,711 - src.data_processing.generate_embeddings - INFO - Encoding entry: y10avdRFNK
2025-06-15 13:37:07,711 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:07,754 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:07,793 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:07,837 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:07,879 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:07,922 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:07,960 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:07,997 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:08,040 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:08,041 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:08,041 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:08,546 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:08,548 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:08,548 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:08,548 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:08,549 - src.data_processing.generate_embeddings - INFO - [OK] y10avdRFNK
2025-06-15 13:37:08,549 - src.data_processing.generate_embeddings - INFO - Encoding entry: r5spnrY6H3
2025-06-15 13:37:08,549 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:08,588 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:08,633 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:08,677 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:08,722 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:08,760 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:08,803 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:08,842 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:08,881 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:08,881 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:08,881 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:09,416 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:09,418 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:09,418 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:09,418 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:09,418 - src.data_processing.generate_embeddings - INFO - [OK] r5spnrY6H3
2025-06-15 13:37:09,419 - src.data_processing.generate_embeddings - INFO - Encoding entry: 6YIpvnkjUK
2025-06-15 13:37:09,419 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:09,460 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:09,505 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:09,545 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:09,582 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:09,621 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:09,662 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:09,701 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:09,741 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:09,743 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:09,743 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:10,276 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:10,277 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:10,277 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:10,277 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:10,277 - src.data_processing.generate_embeddings - INFO - [OK] 6YIpvnkjUK
2025-06-15 13:37:10,277 - src.data_processing.generate_embeddings - INFO - Encoding entry: eWUM5hRYgH
2025-06-15 13:37:10,277 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:10,318 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:10,359 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:10,401 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:10,446 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:10,490 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:10,536 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:10,584 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:10,628 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:10,629 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:10,629 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:11,137 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:11,140 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:11,141 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:11,141 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:11,141 - src.data_processing.generate_embeddings - INFO - [OK] eWUM5hRYgH
2025-06-15 13:37:11,141 - src.data_processing.generate_embeddings - INFO - Encoding entry: NPKZF1WDjZ
2025-06-15 13:37:11,141 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:11,182 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:11,228 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:11,270 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:11,311 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:11,353 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:11,429 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:11,468 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:11,513 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:11,515 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:11,515 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:12,058 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:12,063 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:12,063 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:12,064 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:12,064 - src.data_processing.generate_embeddings - INFO - [OK] NPKZF1WDjZ
2025-06-15 13:37:12,064 - src.data_processing.generate_embeddings - INFO - Encoding entry: 5zSCSE0k41
2025-06-15 13:37:12,064 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:12,109 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:12,153 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:12,197 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:12,242 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:12,285 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:12,328 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:12,374 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:12,420 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:12,421 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:12,422 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:12,939 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:12,944 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:12,944 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:12,944 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:12,944 - src.data_processing.generate_embeddings - INFO - [OK] 5zSCSE0k41
2025-06-15 13:37:12,944 - src.data_processing.generate_embeddings - INFO - Encoding entry: clTa4JFBML
2025-06-15 13:37:12,944 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:12,984 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:13,026 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:13,069 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:13,109 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:13,148 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:13,189 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:13,233 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:13,274 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:13,276 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:13,276 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:13,808 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:13,811 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:13,812 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:13,812 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:13,812 - src.data_processing.generate_embeddings - INFO - [OK] clTa4JFBML
2025-06-15 13:37:13,812 - src.data_processing.generate_embeddings - INFO - Encoding entry: zogaeVpbaE
2025-06-15 13:37:13,812 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:13,853 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:13,892 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:13,936 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:13,978 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:14,022 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:14,063 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:14,107 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:14,147 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:14,148 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:14,149 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:14,674 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:14,678 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:14,678 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:14,679 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:14,679 - src.data_processing.generate_embeddings - INFO - [OK] zogaeVpbaE
2025-06-15 13:37:14,679 - src.data_processing.generate_embeddings - INFO - Encoding entry: 4NJBV6Wp0h
2025-06-15 13:37:14,679 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:14,721 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:14,761 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:14,801 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:14,842 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:14,883 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:14,930 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:14,975 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:15,017 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:15,019 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:15,019 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:15,539 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:15,542 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:15,542 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:15,543 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:15,543 - src.data_processing.generate_embeddings - INFO - [OK] 4NJBV6Wp0h
2025-06-15 13:37:15,543 - src.data_processing.generate_embeddings - INFO - Encoding entry: mp8u2Pcmqz
2025-06-15 13:37:15,543 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:15,581 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:15,618 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:15,656 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:15,699 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:15,741 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:15,781 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:15,822 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:15,860 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:15,863 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:15,863 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:16,551 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:16,554 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:16,554 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:16,555 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:16,555 - src.data_processing.generate_embeddings - INFO - [OK] mp8u2Pcmqz
2025-06-15 13:37:16,555 - src.data_processing.generate_embeddings - INFO - Encoding entry: 3Odq2tGSpp
2025-06-15 13:37:16,555 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:16,594 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:16,636 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:16,677 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:16,721 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:16,762 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:16,803 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:16,845 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:16,885 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:16,886 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:16,887 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:17,481 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:17,484 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:17,484 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:17,485 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:17,486 - src.data_processing.generate_embeddings - INFO - [OK] 3Odq2tGSpp
2025-06-15 13:37:17,486 - src.data_processing.generate_embeddings - INFO - Encoding entry: tQukGCDaNT
2025-06-15 13:37:17,486 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:17,526 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:17,569 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:17,613 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:17,657 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:17,702 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:17,746 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:17,789 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:17,830 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:17,872 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:17,874 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:17,874 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:18,411 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:18,416 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:18,416 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:18,416 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:18,416 - src.data_processing.generate_embeddings - INFO - [OK] tQukGCDaNT
2025-06-15 13:37:18,416 - src.data_processing.generate_embeddings - INFO - Encoding entry: 9O2sVnEHor
2025-06-15 13:37:18,416 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:18,456 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:18,502 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:18,542 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:18,586 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:18,627 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:18,669 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:18,713 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:18,714 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:18,714 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:19,615 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:19,619 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:19,619 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:19,620 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:19,620 - src.data_processing.generate_embeddings - INFO - [OK] 9O2sVnEHor
2025-06-15 13:37:19,620 - src.data_processing.generate_embeddings - INFO - Encoding entry: x7pjdDod6Z
2025-06-15 13:37:19,620 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:19,665 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:19,713 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:19,755 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:19,801 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:19,845 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:19,887 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:19,931 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:19,981 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:19,982 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:19,983 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:21,044 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:21,048 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:21,048 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:21,049 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:21,049 - src.data_processing.generate_embeddings - INFO - [OK] x7pjdDod6Z
2025-06-15 13:37:21,049 - src.data_processing.generate_embeddings - INFO - Encoding entry: 4rCZeCZAON
2025-06-15 13:37:21,049 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:21,096 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:21,135 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:21,188 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:21,230 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:21,276 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:21,322 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:21,366 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:21,410 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:21,412 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:21,412 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:21,954 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:21,958 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:21,958 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:21,958 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:21,958 - src.data_processing.generate_embeddings - INFO - [OK] 4rCZeCZAON
2025-06-15 13:37:21,959 - src.data_processing.generate_embeddings - INFO - Encoding entry: 4bKEFyUHT4
2025-06-15 13:37:21,959 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:21,999 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:22,041 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:22,086 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:22,127 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:22,171 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:22,216 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:22,259 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:22,300 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:22,302 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:22,302 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:22,817 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:22,822 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:22,822 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:22,822 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:22,823 - src.data_processing.generate_embeddings - INFO - [OK] 4bKEFyUHT4
2025-06-15 13:37:22,823 - src.data_processing.generate_embeddings - INFO - Encoding entry: EKdk4vxKO4
2025-06-15 13:37:22,823 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:22,864 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:22,919 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:22,960 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:23,004 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:23,054 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:23,094 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:23,142 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:23,185 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:23,187 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:23,187 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:23,709 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:23,712 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:23,712 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:23,712 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:23,713 - src.data_processing.generate_embeddings - INFO - [OK] EKdk4vxKO4
2025-06-15 13:37:23,713 - src.data_processing.generate_embeddings - INFO - Encoding entry: VXohja0vrQ
2025-06-15 13:37:23,713 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:23,751 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:23,794 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:23,835 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:23,879 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:23,920 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:23,962 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:24,005 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:24,047 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:24,049 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:24,049 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:24,591 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:24,597 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:24,597 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:24,598 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:24,598 - src.data_processing.generate_embeddings - INFO - [OK] VXohja0vrQ
2025-06-15 13:37:24,598 - src.data_processing.generate_embeddings - INFO - Encoding entry: J2wI2rCG2u
2025-06-15 13:37:24,598 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:24,636 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:24,680 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:24,721 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:24,762 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:24,806 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:24,851 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:24,895 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:24,941 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:24,943 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:24,943 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:25,477 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:25,480 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:25,480 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:25,481 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:25,481 - src.data_processing.generate_embeddings - INFO - [OK] J2wI2rCG2u
2025-06-15 13:37:25,481 - src.data_processing.generate_embeddings - INFO - Encoding entry: 135eKqDoRR
2025-06-15 13:37:25,481 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:25,520 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:25,561 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:25,604 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:25,648 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:25,693 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:25,737 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:25,784 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:25,830 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:25,832 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:25,832 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:26,342 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:26,344 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:26,344 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:26,345 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:26,345 - src.data_processing.generate_embeddings - INFO - [OK] 135eKqDoRR
2025-06-15 13:37:26,345 - src.data_processing.generate_embeddings - INFO - Encoding entry: 8qu52Fl1Dt
2025-06-15 13:37:26,345 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:26,385 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:26,427 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:26,467 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:26,511 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:26,555 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:26,595 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:26,636 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:26,675 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:26,676 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:26,677 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:27,182 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:27,187 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:27,187 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:27,187 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:27,188 - src.data_processing.generate_embeddings - INFO - [OK] 8qu52Fl1Dt
2025-06-15 13:37:27,188 - src.data_processing.generate_embeddings - INFO - Encoding entry: 25Ioxw576r
2025-06-15 13:37:27,188 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:27,229 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:27,273 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:27,323 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:27,368 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:27,414 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:27,456 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:27,499 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:27,539 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:27,541 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:27,541 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:28,078 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:28,081 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:28,081 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:28,082 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:28,082 - src.data_processing.generate_embeddings - INFO - [OK] 25Ioxw576r
2025-06-15 13:37:28,082 - src.data_processing.generate_embeddings - INFO - Encoding entry: ge8GZn8Gtu
2025-06-15 13:37:28,082 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:28,127 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:28,166 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:28,205 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:28,245 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:28,283 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:28,326 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:28,365 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:28,404 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:28,406 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:28,406 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:28,938 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:28,942 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:28,942 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:28,943 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:28,943 - src.data_processing.generate_embeddings - INFO - [OK] ge8GZn8Gtu
2025-06-15 13:37:28,943 - src.data_processing.generate_embeddings - INFO - Encoding entry: iSwK1YqO7v
2025-06-15 13:37:28,943 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:28,984 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:29,030 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:29,070 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:29,113 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:29,155 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:29,198 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:29,237 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:29,279 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:29,321 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:29,322 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:29,323 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:29,855 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:29,859 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:29,859 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:29,860 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:29,860 - src.data_processing.generate_embeddings - INFO - [OK] iSwK1YqO7v
2025-06-15 13:37:29,860 - src.data_processing.generate_embeddings - INFO - Encoding entry: qf2uZAdy1N
2025-06-15 13:37:29,860 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:29,899 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:29,939 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:29,979 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:30,021 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:30,064 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:30,107 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:30,148 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:30,192 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:30,193 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:30,194 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:30,707 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:30,709 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:30,709 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:30,710 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:30,710 - src.data_processing.generate_embeddings - INFO - [OK] qf2uZAdy1N
2025-06-15 13:37:30,710 - src.data_processing.generate_embeddings - INFO - Encoding entry: Ddak3nSqQM
2025-06-15 13:37:30,710 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:30,750 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:30,790 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:30,831 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:30,874 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:30,921 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:30,968 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:31,011 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:31,056 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:31,064 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:31,064 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:31,593 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:31,597 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:31,597 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:31,598 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:31,598 - src.data_processing.generate_embeddings - INFO - [OK] Ddak3nSqQM
2025-06-15 13:37:31,598 - src.data_processing.generate_embeddings - INFO - Encoding entry: mSaqxZVZW8
2025-06-15 13:37:31,598 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:31,641 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:31,683 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:31,723 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:31,773 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:31,813 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:31,860 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:31,900 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:31,942 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:31,980 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:31,981 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:31,982 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:32,520 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:37:32,525 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:37:32,525 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:37:32,525 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:37:32,525 - src.data_processing.generate_embeddings - INFO - [OK] mSaqxZVZW8
2025-06-15 13:37:32,525 - src.data_processing.generate_embeddings - INFO - Encoding entry: Oo7dlLgqQX
2025-06-15 13:37:32,525 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:37:32,567 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:32,611 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:32,655 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:32,697 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:32,741 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:32,786 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:32,827 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:32,869 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:37:32,871 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:37:32,871 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:37:32,913 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 429 Too Many Requests"
2025-06-15 13:37:32,915 - src.data_processing.encoder - WARNING - Rate Limit exceeded. Sleeping for 75 seconds... (Attempt 1)
2025-06-15 13:38:47,920 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 2)
2025-06-15 13:38:48,500 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:38:48,505 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 2)
2025-06-15 13:38:48,505 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:38:48,505 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:38:48,506 - src.data_processing.generate_embeddings - INFO - [OK] Oo7dlLgqQX
2025-06-15 13:38:48,506 - src.data_processing.generate_embeddings - INFO - Encoding entry: gojL67CfS8
2025-06-15 13:38:48,506 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:38:48,551 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:48,668 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:48,737 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:48,838 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:48,897 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:48,992 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:49,054 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:49,152 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:49,154 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:38:49,155 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:38:49,699 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:38:49,704 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:38:49,704 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:38:49,704 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:38:49,705 - src.data_processing.generate_embeddings - INFO - [OK] gojL67CfS8
2025-06-15 13:38:49,705 - src.data_processing.generate_embeddings - INFO - Encoding entry: qEpi8uWX3N
2025-06-15 13:38:49,705 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:38:49,749 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:49,880 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:49,927 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:50,034 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:50,076 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:50,188 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:50,235 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:50,348 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:50,350 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:38:50,350 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:38:50,874 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:38:50,878 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:38:50,879 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:38:50,879 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:38:50,879 - src.data_processing.generate_embeddings - INFO - [OK] qEpi8uWX3N
2025-06-15 13:38:50,879 - src.data_processing.generate_embeddings - INFO - Encoding entry: bg6fVPVs3s
2025-06-15 13:38:50,879 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:38:50,919 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:51,031 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:51,074 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:51,185 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:51,226 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:51,345 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:51,389 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:51,494 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:51,498 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:38:51,498 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:38:52,038 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:38:52,042 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:38:52,042 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:38:52,043 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:38:52,043 - src.data_processing.generate_embeddings - INFO - [OK] bg6fVPVs3s
2025-06-15 13:38:52,043 - src.data_processing.generate_embeddings - INFO - Encoding entry: pC44UMwy2v
2025-06-15 13:38:52,043 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:38:52,084 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:52,199 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:52,244 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:52,357 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:52,402 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:52,518 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:52,562 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:52,672 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:52,674 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:38:52,674 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:38:53,211 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:38:53,215 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:38:53,215 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:38:53,216 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:38:53,216 - src.data_processing.generate_embeddings - INFO - [OK] pC44UMwy2v
2025-06-15 13:38:53,216 - src.data_processing.generate_embeddings - INFO - Encoding entry: V0oJaLqY4E
2025-06-15 13:38:53,216 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:38:53,261 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:53,369 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:53,414 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:53,527 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:53,581 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:53,682 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:53,731 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:53,843 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:53,844 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:38:53,845 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:38:54,381 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:38:54,385 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:38:54,385 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:38:54,386 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:38:54,386 - src.data_processing.generate_embeddings - INFO - [OK] V0oJaLqY4E
2025-06-15 13:38:54,386 - src.data_processing.generate_embeddings - INFO - Encoding entry: 8Fxqn1tZM1
2025-06-15 13:38:54,386 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:38:54,425 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:54,539 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:54,583 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:54,694 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:54,737 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:54,853 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:54,899 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:55,002 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:55,004 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:38:55,004 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:38:55,550 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:38:55,553 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:38:55,554 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:38:55,554 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:38:55,554 - src.data_processing.generate_embeddings - INFO - [OK] 8Fxqn1tZM1
2025-06-15 13:38:55,554 - src.data_processing.generate_embeddings - INFO - Encoding entry: 47loYmzxep
2025-06-15 13:38:55,554 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:38:55,599 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:55,706 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:55,756 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:55,864 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:55,909 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:56,017 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:56,058 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:56,173 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:56,175 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:38:56,175 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:38:56,698 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:38:56,702 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:38:56,702 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:38:56,703 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:38:56,703 - src.data_processing.generate_embeddings - INFO - [OK] 47loYmzxep
2025-06-15 13:38:56,703 - src.data_processing.generate_embeddings - INFO - Encoding entry: S2P6KPLtm8
2025-06-15 13:38:56,703 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:38:56,741 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:56,854 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:56,903 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:56,942 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:57,054 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:57,101 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:57,144 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:57,208 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:57,210 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:38:57,210 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:38:57,713 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:38:57,716 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:38:57,717 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:38:57,717 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:38:57,717 - src.data_processing.generate_embeddings - INFO - [OK] S2P6KPLtm8
2025-06-15 13:38:57,717 - src.data_processing.generate_embeddings - INFO - Encoding entry: Vi8AepAXGy
2025-06-15 13:38:57,717 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:38:57,762 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:57,802 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:57,925 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:57,966 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:58,006 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:58,046 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:58,088 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:58,131 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:58,133 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:38:58,133 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:38:58,666 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:38:58,668 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:38:58,668 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:38:58,669 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:38:58,669 - src.data_processing.generate_embeddings - INFO - [OK] Vi8AepAXGy
2025-06-15 13:38:58,669 - src.data_processing.generate_embeddings - INFO - Encoding entry: cfrDLD1wfO
2025-06-15 13:38:58,669 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:38:58,706 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:58,752 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:58,860 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:58,909 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:58,947 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:58,989 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:59,035 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:59,076 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:59,078 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:38:59,078 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:38:59,604 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:38:59,609 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:38:59,609 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:38:59,609 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:38:59,610 - src.data_processing.generate_embeddings - INFO - [OK] cfrDLD1wfO
2025-06-15 13:38:59,610 - src.data_processing.generate_embeddings - INFO - Encoding entry: uNKlTQ8mBD
2025-06-15 13:38:59,610 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:38:59,647 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:59,694 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:59,762 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:59,802 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:59,846 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:38:59,958 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:00,000 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:00,071 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:00,073 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:39:00,073 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:39:00,611 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:39:00,614 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:39:00,614 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:39:00,615 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:39:00,615 - src.data_processing.generate_embeddings - INFO - [OK] uNKlTQ8mBD
2025-06-15 13:39:00,615 - src.data_processing.generate_embeddings - INFO - Encoding entry: DFr5hteojx
2025-06-15 13:39:00,615 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:39:00,659 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:00,710 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:00,755 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:00,796 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:00,841 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:00,889 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:00,932 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:00,973 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:00,975 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:39:00,975 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:39:01,492 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:39:01,495 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:39:01,495 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:39:01,496 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:39:01,496 - src.data_processing.generate_embeddings - INFO - [OK] DFr5hteojx
2025-06-15 13:39:01,496 - src.data_processing.generate_embeddings - INFO - Encoding entry: E18kRXTGmV
2025-06-15 13:39:01,496 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:39:01,536 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:01,588 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:01,643 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:01,685 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:01,735 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:01,778 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:01,830 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:01,875 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:01,925 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:01,927 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:39:01,928 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:39:02,470 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:39:02,473 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:39:02,473 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:39:02,474 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:39:02,474 - src.data_processing.generate_embeddings - INFO - [OK] E18kRXTGmV
2025-06-15 13:39:02,474 - src.data_processing.generate_embeddings - INFO - Encoding entry: Mbd3QxXjq5
2025-06-15 13:39:02,474 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:39:02,521 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:02,563 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:02,610 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:02,652 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:02,694 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:02,740 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:02,784 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:02,821 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:02,823 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:39:02,823 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:39:03,355 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:39:03,359 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:39:03,359 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:39:03,360 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:39:03,360 - src.data_processing.generate_embeddings - INFO - [OK] Mbd3QxXjq5
2025-06-15 13:39:03,360 - src.data_processing.generate_embeddings - INFO - Encoding entry: KZlJF8kguO
2025-06-15 13:39:03,360 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:39:03,400 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:03,440 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:03,482 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:03,527 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:03,571 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:03,617 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:03,660 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:03,703 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:03,704 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:39:03,705 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:39:04,236 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:39:04,240 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:39:04,240 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:39:04,240 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:39:04,240 - src.data_processing.generate_embeddings - INFO - [OK] KZlJF8kguO
2025-06-15 13:39:04,241 - src.data_processing.generate_embeddings - INFO - Encoding entry: cu8FfaYriU
2025-06-15 13:39:04,241 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:39:04,294 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:04,337 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:04,378 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:04,418 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:04,466 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:04,509 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:04,548 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:04,550 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:39:04,550 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:39:05,091 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:39:05,095 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:39:05,095 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:39:05,096 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:39:05,096 - src.data_processing.generate_embeddings - INFO - [OK] cu8FfaYriU
2025-06-15 13:39:05,096 - src.data_processing.generate_embeddings - INFO - Encoding entry: Y8YVCOMEpz
2025-06-15 13:39:05,096 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:39:05,140 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:05,180 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:05,222 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:05,264 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:05,306 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:05,347 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:05,388 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:05,432 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:05,434 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:39:05,434 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:39:05,954 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:39:05,957 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:39:05,957 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:39:05,958 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:39:05,958 - src.data_processing.generate_embeddings - INFO - [OK] Y8YVCOMEpz
2025-06-15 13:39:05,958 - src.data_processing.generate_embeddings - INFO - Encoding entry: cLga8GStdk
2025-06-15 13:39:05,958 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:39:05,999 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:06,043 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:06,082 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:06,123 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:06,169 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:06,208 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:06,253 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:06,294 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:06,296 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:39:06,296 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:39:06,811 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:39:06,815 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:39:06,815 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:39:06,815 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:39:06,816 - src.data_processing.generate_embeddings - INFO - [OK] cLga8GStdk
2025-06-15 13:39:06,816 - src.data_processing.generate_embeddings - INFO - Encoding entry: 4S8agvKjle
2025-06-15 13:39:06,816 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:39:06,857 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:06,899 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:06,939 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:06,986 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:07,027 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:07,069 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:07,123 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:07,170 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:07,172 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:39:07,172 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:39:07,711 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:39:07,716 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:39:07,716 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:39:07,717 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:39:07,717 - src.data_processing.generate_embeddings - INFO - [OK] 4S8agvKjle
2025-06-15 13:39:07,718 - src.data_processing.generate_embeddings - INFO - Encoding entry: s1K5Z5QPog
2025-06-15 13:39:07,718 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:39:07,757 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:07,872 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:07,917 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:07,965 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:08,004 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:08,117 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:08,166 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:08,211 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:08,317 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:39:08,320 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:39:08,320 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:39:08,864 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:39:08,871 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:39:08,872 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:39:08,872 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:39:08,872 - src.data_processing.generate_embeddings - INFO - [OK] s1K5Z5QPog
2025-06-15 13:39:08,991 - root - INFO - [OK] exported to raw_emb.json
2025-06-15 13:39:09,080 - root - INFO - [OK] exported to emb.json
