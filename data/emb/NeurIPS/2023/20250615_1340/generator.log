2025-06-15 13:40:45,653 - root - INFO - Generating embeddings for data/unified_text/NeurIPS/NeurIPS_2023.json
2025-06-15 13:40:45,702 - src.data_processing.generate_embeddings - INFO - Embedding started
2025-06-15 13:40:45,702 - src.data_processing.generate_embeddings - INFO - Model: gemini-embedding-exp-03-07
2025-06-15 13:40:45,702 - src.data_processing.generate_embeddings - INFO - Input file: data/unified_text/NeurIPS/NeurIPS_2023.json
2025-06-15 13:40:45,702 - src.data_processing.generate_embeddings - INFO - Encoding entry: sW8yGZ4uVJ
2025-06-15 13:40:45,702 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:40:45,772 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:45,883 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:45,925 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:46,040 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:46,087 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:46,200 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:46,247 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:46,360 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:46,361 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:40:46,362 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:40:46,899 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:40:46,904 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:40:46,905 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:40:46,905 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:40:46,905 - src.data_processing.generate_embeddings - INFO - [OK] sW8yGZ4uVJ
2025-06-15 13:40:46,906 - src.data_processing.generate_embeddings - INFO - Encoding entry: Dkmpa6wCIx
2025-06-15 13:40:46,906 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:40:46,948 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:47,059 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:47,107 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:47,215 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:47,260 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:47,380 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:47,425 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:47,536 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:47,538 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:40:47,539 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:40:48,063 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:40:48,065 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:40:48,065 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:40:48,065 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:40:48,065 - src.data_processing.generate_embeddings - INFO - [OK] Dkmpa6wCIx
2025-06-15 13:40:48,065 - src.data_processing.generate_embeddings - INFO - Encoding entry: RSGNGiB1q4
2025-06-15 13:40:48,065 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:40:48,106 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:48,217 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:48,264 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:48,370 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:48,419 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:48,526 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:48,576 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:48,684 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:48,686 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:40:48,686 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:40:49,205 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:40:49,209 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:40:49,209 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:40:49,210 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:40:49,210 - src.data_processing.generate_embeddings - INFO - [OK] RSGNGiB1q4
2025-06-15 13:40:49,210 - src.data_processing.generate_embeddings - INFO - Encoding entry: g7OX2sOJtn
2025-06-15 13:40:49,210 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:40:49,251 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:49,371 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:49,421 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:49,536 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:49,576 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:49,690 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:49,735 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:49,848 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:49,891 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:49,893 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:40:49,893 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:40:50,498 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:40:50,501 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:40:50,502 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:40:50,502 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:40:50,503 - src.data_processing.generate_embeddings - INFO - [OK] g7OX2sOJtn
2025-06-15 13:40:50,503 - src.data_processing.generate_embeddings - INFO - Encoding entry: cB0BImqSS9
2025-06-15 13:40:50,503 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:40:50,542 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:50,654 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:50,702 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:50,809 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:50,854 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:50,959 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:51,007 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:51,115 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:51,159 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:51,160 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:40:51,161 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:40:51,764 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:40:51,766 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:40:51,766 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:40:51,767 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:40:51,767 - src.data_processing.generate_embeddings - INFO - [OK] cB0BImqSS9
2025-06-15 13:40:51,767 - src.data_processing.generate_embeddings - INFO - Encoding entry: fg7iyNK81W
2025-06-15 13:40:51,767 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:40:51,806 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:51,917 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:51,973 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:52,072 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:52,130 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:52,222 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:52,279 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:52,377 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:52,379 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:40:52,379 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:40:52,931 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:40:52,935 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:40:52,935 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:40:52,935 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:40:52,936 - src.data_processing.generate_embeddings - INFO - [OK] fg7iyNK81W
2025-06-15 13:40:52,936 - src.data_processing.generate_embeddings - INFO - Encoding entry: q131tA7HCT
2025-06-15 13:40:52,936 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:40:52,976 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:53,088 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:53,133 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:53,242 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:53,289 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:53,397 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:53,446 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:53,555 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:53,558 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:40:53,558 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:40:54,104 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:40:54,107 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:40:54,107 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:40:54,108 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:40:54,108 - src.data_processing.generate_embeddings - INFO - [OK] q131tA7HCT
2025-06-15 13:40:54,108 - src.data_processing.generate_embeddings - INFO - Encoding entry: QDByreuQyk
2025-06-15 13:40:54,108 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:40:54,150 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:54,258 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:54,304 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:54,409 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:54,460 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:54,564 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:54,616 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:54,718 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:54,720 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:40:54,721 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:40:55,264 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:40:55,269 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:40:55,269 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:40:55,269 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:40:55,270 - src.data_processing.generate_embeddings - INFO - [OK] QDByreuQyk
2025-06-15 13:40:55,270 - src.data_processing.generate_embeddings - INFO - Encoding entry: 9VqMaSjf7U
2025-06-15 13:40:55,270 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:40:55,309 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:55,427 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:55,466 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:55,584 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:55,627 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:55,741 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:55,782 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:55,897 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:55,899 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:40:55,899 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:40:56,663 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:40:56,668 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:40:56,668 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:40:56,668 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:40:56,669 - src.data_processing.generate_embeddings - INFO - [OK] 9VqMaSjf7U
2025-06-15 13:40:56,669 - src.data_processing.generate_embeddings - INFO - Encoding entry: BHXsb69bSx
2025-06-15 13:40:56,669 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:40:56,710 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:56,751 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:56,795 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:56,838 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:56,881 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:56,997 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:57,043 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:57,149 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:57,151 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:40:57,151 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:40:57,698 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:40:57,702 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:40:57,702 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:40:57,703 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:40:57,703 - src.data_processing.generate_embeddings - INFO - [OK] BHXsb69bSx
2025-06-15 13:40:57,703 - src.data_processing.generate_embeddings - INFO - Encoding entry: NnMEadcdyD
2025-06-15 13:40:57,703 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:40:57,741 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:57,789 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:57,830 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:57,873 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:57,917 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:57,960 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:58,000 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:58,045 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:58,046 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:40:58,046 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:40:58,553 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:40:58,556 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:40:58,556 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:40:58,556 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:40:58,556 - src.data_processing.generate_embeddings - INFO - [OK] NnMEadcdyD
2025-06-15 13:40:58,556 - src.data_processing.generate_embeddings - INFO - Encoding entry: wIlmx4bHrO
2025-06-15 13:40:58,556 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:40:58,596 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:58,636 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:58,676 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:58,719 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:58,762 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:58,806 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:58,845 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:58,889 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:58,891 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:40:58,891 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:40:59,433 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:40:59,440 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:40:59,440 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:40:59,441 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:40:59,441 - src.data_processing.generate_embeddings - INFO - [OK] wIlmx4bHrO
2025-06-15 13:40:59,441 - src.data_processing.generate_embeddings - INFO - Encoding entry: VH1vxapUTs
2025-06-15 13:40:59,441 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:40:59,479 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:59,532 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:59,573 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:59,623 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:59,663 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:59,708 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:59,770 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:59,814 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:40:59,815 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:40:59,816 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:00,347 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:00,351 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:00,351 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:00,352 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:00,352 - src.data_processing.generate_embeddings - INFO - [OK] VH1vxapUTs
2025-06-15 13:41:00,352 - src.data_processing.generate_embeddings - INFO - Encoding entry: a2Yg9Za6Rb
2025-06-15 13:41:00,353 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:00,400 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:00,443 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:00,488 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:00,530 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:00,571 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:00,615 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:00,660 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:00,705 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:00,707 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:00,707 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:01,236 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:01,240 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:01,240 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:01,240 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:01,240 - src.data_processing.generate_embeddings - INFO - [OK] a2Yg9Za6Rb
2025-06-15 13:41:01,241 - src.data_processing.generate_embeddings - INFO - Encoding entry: rcXXNFVlEn
2025-06-15 13:41:01,241 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:01,281 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:01,323 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:01,368 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:01,410 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:01,457 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:01,499 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:01,538 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:01,579 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:01,626 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:01,627 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:01,627 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:02,157 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:02,161 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:02,161 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:02,162 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:02,162 - src.data_processing.generate_embeddings - INFO - [OK] rcXXNFVlEn
2025-06-15 13:41:02,162 - src.data_processing.generate_embeddings - INFO - Encoding entry: 27TdrEvqLD
2025-06-15 13:41:02,162 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:02,206 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:02,250 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:02,292 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:02,335 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:02,376 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:02,418 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:02,464 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:02,508 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:02,509 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:02,510 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:03,051 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:03,056 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:03,056 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:03,057 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:03,057 - src.data_processing.generate_embeddings - INFO - [OK] 27TdrEvqLD
2025-06-15 13:41:03,057 - src.data_processing.generate_embeddings - INFO - Encoding entry: Sf9goJtTCE
2025-06-15 13:41:03,058 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:03,095 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:03,137 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:03,178 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:03,220 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:03,260 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:03,304 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:03,345 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:03,387 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:03,389 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:03,389 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:03,913 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:03,918 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:03,919 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:03,919 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:03,919 - src.data_processing.generate_embeddings - INFO - [OK] Sf9goJtTCE
2025-06-15 13:41:03,919 - src.data_processing.generate_embeddings - INFO - Encoding entry: ITw9edRDlD
2025-06-15 13:41:03,919 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:03,960 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:04,004 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:04,045 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:04,089 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:04,136 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:04,179 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:04,228 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:04,277 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:04,279 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:04,279 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:04,794 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:04,799 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:04,799 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:04,800 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:04,800 - src.data_processing.generate_embeddings - INFO - [OK] ITw9edRDlD
2025-06-15 13:41:04,800 - src.data_processing.generate_embeddings - INFO - Encoding entry: w0H2xGHlkw
2025-06-15 13:41:04,800 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:04,845 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:04,885 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:04,926 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:04,970 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:05,015 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:05,060 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:05,104 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:05,149 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:05,152 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:05,152 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:05,683 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:05,687 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:05,687 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:05,688 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:05,688 - src.data_processing.generate_embeddings - INFO - [OK] w0H2xGHlkw
2025-06-15 13:41:05,689 - src.data_processing.generate_embeddings - INFO - Encoding entry: yC3q7vInux
2025-06-15 13:41:05,689 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:05,730 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:05,774 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:05,815 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:05,860 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:05,903 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:05,942 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:05,983 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:06,025 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:06,027 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:06,027 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:06,546 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:06,550 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:06,550 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:06,551 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:06,551 - src.data_processing.generate_embeddings - INFO - [OK] yC3q7vInux
2025-06-15 13:41:06,552 - src.data_processing.generate_embeddings - INFO - Encoding entry: APGXBNkt6h
2025-06-15 13:41:06,552 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:06,596 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:06,701 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:06,764 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:06,861 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:06,909 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:06,956 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:07,004 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:07,050 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:07,052 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:07,053 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:07,590 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:07,593 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:07,593 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:07,594 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:07,594 - src.data_processing.generate_embeddings - INFO - [OK] APGXBNkt6h
2025-06-15 13:41:07,594 - src.data_processing.generate_embeddings - INFO - Encoding entry: oML3v2cFg2
2025-06-15 13:41:07,594 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:07,637 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:07,749 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:07,790 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:07,836 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:07,910 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:07,949 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:07,991 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:08,037 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:08,038 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:08,039 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:08,547 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:08,551 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:08,551 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:08,552 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:08,552 - src.data_processing.generate_embeddings - INFO - [OK] oML3v2cFg2
2025-06-15 13:41:08,552 - src.data_processing.generate_embeddings - INFO - Encoding entry: w116w62fxH
2025-06-15 13:41:08,552 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:08,592 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:08,640 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:08,679 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:08,715 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:08,761 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:08,808 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:08,855 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:08,902 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:08,906 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:08,906 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:09,443 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:09,447 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:09,447 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:09,448 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:09,448 - src.data_processing.generate_embeddings - INFO - [OK] w116w62fxH
2025-06-15 13:41:09,448 - src.data_processing.generate_embeddings - INFO - Encoding entry: kMueEV8Eyy
2025-06-15 13:41:09,448 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:09,486 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:09,530 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:09,571 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:09,615 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:09,657 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:09,702 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:09,747 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:09,794 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:09,797 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:09,797 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:10,323 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:10,327 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:10,328 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:10,328 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:10,328 - src.data_processing.generate_embeddings - INFO - [OK] kMueEV8Eyy
2025-06-15 13:41:10,328 - src.data_processing.generate_embeddings - INFO - Encoding entry: FtNruwFEs3
2025-06-15 13:41:10,329 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:10,371 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:10,416 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:10,456 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:10,498 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:10,542 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:10,588 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:10,635 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:10,678 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:10,680 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:10,680 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:11,216 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:11,219 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:11,220 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:11,220 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:11,220 - src.data_processing.generate_embeddings - INFO - [OK] FtNruwFEs3
2025-06-15 13:41:11,220 - src.data_processing.generate_embeddings - INFO - Encoding entry: VSJotgbPHF
2025-06-15 13:41:11,220 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:11,264 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:11,305 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:11,346 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:11,386 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:11,427 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:11,470 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:11,512 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:11,554 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:11,556 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:11,556 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:12,072 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:12,076 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:12,076 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:12,077 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:12,077 - src.data_processing.generate_embeddings - INFO - [OK] VSJotgbPHF
2025-06-15 13:41:12,077 - src.data_processing.generate_embeddings - INFO - Encoding entry: OUIFPHEgJU
2025-06-15 13:41:12,077 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:12,120 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:12,176 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:12,220 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:12,259 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:12,302 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:12,346 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:12,389 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:12,476 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:12,516 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:12,518 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:12,518 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:13,018 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:13,021 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:13,022 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:13,022 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:13,022 - src.data_processing.generate_embeddings - INFO - [OK] OUIFPHEgJU
2025-06-15 13:41:13,022 - src.data_processing.generate_embeddings - INFO - Encoding entry: AOKU4nRw1W
2025-06-15 13:41:13,022 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:13,066 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:13,108 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:13,148 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:13,194 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:13,235 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:13,276 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:13,317 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:13,361 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:13,363 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:13,363 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:13,881 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:13,884 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:13,885 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:13,885 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:13,885 - src.data_processing.generate_embeddings - INFO - [OK] AOKU4nRw1W
2025-06-15 13:41:13,886 - src.data_processing.generate_embeddings - INFO - Encoding entry: f38EY21lBw
2025-06-15 13:41:13,886 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:13,926 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:13,963 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:14,009 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:14,051 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:14,093 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:14,134 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:14,177 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:14,178 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:14,178 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:14,704 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:14,708 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:14,708 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:14,708 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:14,708 - src.data_processing.generate_embeddings - INFO - [OK] f38EY21lBw
2025-06-15 13:41:14,709 - src.data_processing.generate_embeddings - INFO - Encoding entry: sPLTQSf6GI
2025-06-15 13:41:14,709 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:14,749 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:14,796 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:14,836 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:14,878 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:14,920 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:14,965 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:15,009 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:15,053 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:15,054 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:15,055 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:15,592 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:15,596 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:15,596 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:15,597 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:15,597 - src.data_processing.generate_embeddings - INFO - [OK] sPLTQSf6GI
2025-06-15 13:41:15,597 - src.data_processing.generate_embeddings - INFO - Encoding entry: i913TUOvTK
2025-06-15 13:41:15,597 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:15,638 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:15,681 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:15,726 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:15,763 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:15,806 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:15,850 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:15,894 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:15,932 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:15,934 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:15,934 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:16,439 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:16,444 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:16,444 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:16,445 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:16,445 - src.data_processing.generate_embeddings - INFO - [OK] i913TUOvTK
2025-06-15 13:41:16,445 - src.data_processing.generate_embeddings - INFO - Encoding entry: Yacmpz84TH
2025-06-15 13:41:16,446 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:16,486 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:16,533 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:16,571 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:16,614 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:16,655 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:16,696 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:16,736 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:16,779 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:16,781 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:16,781 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:17,306 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:17,309 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:17,309 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:17,310 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:17,310 - src.data_processing.generate_embeddings - INFO - [OK] Yacmpz84TH
2025-06-15 13:41:17,310 - src.data_processing.generate_embeddings - INFO - Encoding entry: fHyLsfMDIs
2025-06-15 13:41:17,310 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:17,349 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:17,405 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:17,447 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:17,487 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:17,529 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:17,580 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:17,617 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:17,660 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:17,661 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:17,661 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:18,203 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:18,205 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:18,205 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:18,206 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:18,206 - src.data_processing.generate_embeddings - INFO - [OK] fHyLsfMDIs
2025-06-15 13:41:18,206 - src.data_processing.generate_embeddings - INFO - Encoding entry: 73XPopmbXH
2025-06-15 13:41:18,206 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:18,244 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:18,287 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:18,338 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:18,377 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:18,417 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:18,461 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:18,502 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:18,542 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:18,544 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:18,544 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:19,058 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:19,063 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:19,063 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:19,063 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:19,064 - src.data_processing.generate_embeddings - INFO - [OK] 73XPopmbXH
2025-06-15 13:41:19,064 - src.data_processing.generate_embeddings - INFO - Encoding entry: W5If9P1xqO
2025-06-15 13:41:19,064 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:19,100 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:19,145 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:19,192 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:19,247 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:19,293 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:19,339 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:19,380 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:19,424 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:19,469 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:19,471 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:19,471 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:19,988 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:19,993 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:19,993 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:19,994 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:19,994 - src.data_processing.generate_embeddings - INFO - [OK] W5If9P1xqO
2025-06-15 13:41:19,994 - src.data_processing.generate_embeddings - INFO - Encoding entry: 1vzF4zWQ1E
2025-06-15 13:41:19,994 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:20,035 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:20,084 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:20,130 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:20,178 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:20,232 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:20,279 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:20,323 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:20,381 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:20,381 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:20,381 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:20,904 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:20,908 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:20,909 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:20,909 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:20,910 - src.data_processing.generate_embeddings - INFO - [OK] 1vzF4zWQ1E
2025-06-15 13:41:20,910 - src.data_processing.generate_embeddings - INFO - Encoding entry: 5Xc1ecxO1h
2025-06-15 13:41:20,910 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:20,956 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:20,997 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:21,041 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:21,093 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:21,133 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:21,174 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:21,215 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:21,267 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:21,268 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:21,269 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:21,815 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:21,819 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:21,819 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:21,820 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:21,820 - src.data_processing.generate_embeddings - INFO - [OK] 5Xc1ecxO1h
2025-06-15 13:41:21,820 - src.data_processing.generate_embeddings - INFO - Encoding entry: eTHawKFT4h
2025-06-15 13:41:21,820 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:21,861 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:21,902 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:21,946 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:21,989 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:22,032 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:22,075 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:22,114 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:22,158 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:22,159 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:22,159 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:22,695 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:22,698 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:22,699 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:22,699 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:22,700 - src.data_processing.generate_embeddings - INFO - [OK] eTHawKFT4h
2025-06-15 13:41:22,700 - src.data_processing.generate_embeddings - INFO - Encoding entry: n84bzMrGUD
2025-06-15 13:41:22,700 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:22,742 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:22,781 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:22,835 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:22,878 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:22,921 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:22,963 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:22,999 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:23,039 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:23,042 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:23,042 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:23,559 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:23,562 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:23,562 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:23,562 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:23,563 - src.data_processing.generate_embeddings - INFO - [OK] n84bzMrGUD
2025-06-15 13:41:23,563 - src.data_processing.generate_embeddings - INFO - Encoding entry: 0A9f2jZDGW
2025-06-15 13:41:23,563 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:23,605 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:23,646 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:23,683 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:23,726 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:23,767 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:23,811 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:23,855 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:23,902 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:23,903 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:23,903 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:24,440 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:24,444 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:24,444 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:24,444 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:24,444 - src.data_processing.generate_embeddings - INFO - [OK] 0A9f2jZDGW
2025-06-15 13:41:24,444 - src.data_processing.generate_embeddings - INFO - Encoding entry: rybsHQ4DXy
2025-06-15 13:41:24,444 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:24,490 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:24,537 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:24,584 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:24,621 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:24,663 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:24,709 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:24,751 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:24,794 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:24,796 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:24,796 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:25,328 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:25,332 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:25,332 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:25,332 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:25,332 - src.data_processing.generate_embeddings - INFO - [OK] rybsHQ4DXy
2025-06-15 13:41:25,333 - src.data_processing.generate_embeddings - INFO - Encoding entry: A7feCufBhL
2025-06-15 13:41:25,333 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:25,372 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:25,411 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:25,455 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:25,492 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:25,529 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:25,571 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:25,611 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:25,651 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:25,654 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:25,654 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:26,189 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:26,193 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:26,193 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:26,193 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:26,194 - src.data_processing.generate_embeddings - INFO - [OK] A7feCufBhL
2025-06-15 13:41:26,194 - src.data_processing.generate_embeddings - INFO - Encoding entry: Lr2swAfwff
2025-06-15 13:41:26,194 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:26,235 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:26,277 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:26,316 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:26,361 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:26,408 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:26,449 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:26,490 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:26,531 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:26,572 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:26,573 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:26,574 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:27,105 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:27,109 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:27,109 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:27,110 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:27,110 - src.data_processing.generate_embeddings - INFO - [OK] Lr2swAfwff
2025-06-15 13:41:27,110 - src.data_processing.generate_embeddings - INFO - Encoding entry: HV85SiyrsV
2025-06-15 13:41:27,110 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:27,152 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:27,196 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:27,236 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:27,280 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:27,315 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:27,356 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:27,395 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:27,434 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:27,436 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:27,437 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:27,972 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:27,976 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:27,976 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:27,977 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:27,977 - src.data_processing.generate_embeddings - INFO - [OK] HV85SiyrsV
2025-06-15 13:41:27,977 - src.data_processing.generate_embeddings - INFO - Encoding entry: MFWgLCWgUB
2025-06-15 13:41:27,977 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:28,013 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:28,053 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:28,098 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:28,139 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:28,181 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:28,224 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:28,262 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:28,264 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:28,264 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:28,771 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:28,776 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:28,776 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:28,776 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:28,777 - src.data_processing.generate_embeddings - INFO - [OK] MFWgLCWgUB
2025-06-15 13:41:28,777 - src.data_processing.generate_embeddings - INFO - Encoding entry: O0Lz8XZT2b
2025-06-15 13:41:28,777 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:28,817 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:28,860 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:28,901 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:28,937 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:28,977 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:29,017 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:29,057 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:29,101 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:29,149 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:29,151 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:29,152 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:29,691 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:29,694 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:29,694 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:29,695 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:29,695 - src.data_processing.generate_embeddings - INFO - [OK] O0Lz8XZT2b
2025-06-15 13:41:29,695 - src.data_processing.generate_embeddings - INFO - Encoding entry: kaHpo8OZw2
2025-06-15 13:41:29,695 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:29,732 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:29,778 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:29,820 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:29,862 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:29,903 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:29,944 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:29,998 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:30,192 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:30,193 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:30,194 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:30,726 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:30,729 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:30,729 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:30,730 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:30,730 - src.data_processing.generate_embeddings - INFO - [OK] kaHpo8OZw2
2025-06-15 13:41:30,730 - src.data_processing.generate_embeddings - INFO - Encoding entry: 5W7cXno10k
2025-06-15 13:41:30,730 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:30,770 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:30,813 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:30,855 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:30,893 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:30,932 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:30,976 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:31,017 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:31,057 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:31,059 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:31,059 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:31,597 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:31,602 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:31,602 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:31,603 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:31,603 - src.data_processing.generate_embeddings - INFO - [OK] 5W7cXno10k
2025-06-15 13:41:31,603 - src.data_processing.generate_embeddings - INFO - Encoding entry: j5BuTrEj35
2025-06-15 13:41:31,603 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:31,646 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:31,692 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:31,732 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:31,772 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:31,818 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:31,856 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:31,899 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:31,942 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:31,944 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:31,944 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:32,446 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:32,450 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:32,450 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:32,450 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:32,451 - src.data_processing.generate_embeddings - INFO - [OK] j5BuTrEj35
2025-06-15 13:41:32,452 - src.data_processing.generate_embeddings - INFO - Encoding entry: R6KJN1AUAR
2025-06-15 13:41:32,452 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:32,488 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:32,525 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:32,567 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:32,604 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:32,644 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:32,684 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:32,723 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:32,766 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:32,770 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:32,771 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:33,296 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:41:33,300 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:41:33,300 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:41:33,301 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:41:33,302 - src.data_processing.generate_embeddings - INFO - [OK] R6KJN1AUAR
2025-06-15 13:41:33,302 - src.data_processing.generate_embeddings - INFO - Encoding entry: y8UAQQHVTX
2025-06-15 13:41:33,302 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:41:33,342 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:33,388 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:33,428 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:33,475 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:33,517 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:33,557 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:33,598 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:33,639 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:33,681 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:41:33,683 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:41:33,683 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:41:33,730 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 429 Too Many Requests"
2025-06-15 13:41:33,731 - src.data_processing.encoder - WARNING - Rate Limit exceeded. Sleeping for 75 seconds... (Attempt 1)
2025-06-15 13:42:48,737 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 2)
2025-06-15 13:42:49,310 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:42:49,314 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 2)
2025-06-15 13:42:49,314 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:42:49,315 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:42:49,315 - src.data_processing.generate_embeddings - INFO - [OK] y8UAQQHVTX
2025-06-15 13:42:49,315 - src.data_processing.generate_embeddings - INFO - Encoding entry: IwnINorSZ5
2025-06-15 13:42:49,315 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:42:49,359 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:49,471 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:49,517 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:49,627 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:49,675 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:49,787 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:49,829 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:49,943 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:49,945 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:42:49,945 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:42:50,474 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:42:50,478 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:42:50,478 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:42:50,478 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:42:50,478 - src.data_processing.generate_embeddings - INFO - [OK] IwnINorSZ5
2025-06-15 13:42:50,478 - src.data_processing.generate_embeddings - INFO - Encoding entry: dVnhdm9MIg
2025-06-15 13:42:50,478 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:42:50,520 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:50,630 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:50,675 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:50,786 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:50,829 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:50,944 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:50,987 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:50,989 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:42:50,989 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:42:51,579 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:42:51,582 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:42:51,583 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:42:51,583 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:42:51,583 - src.data_processing.generate_embeddings - INFO - [OK] dVnhdm9MIg
2025-06-15 13:42:51,583 - src.data_processing.generate_embeddings - INFO - Encoding entry: Pe9WxkN8Ff
2025-06-15 13:42:51,583 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:42:51,626 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:51,734 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:51,779 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:51,887 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:51,931 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:52,039 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:52,083 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:52,195 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:52,197 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:42:52,197 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:42:53,139 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:42:53,143 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:42:53,143 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:42:53,144 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:42:53,144 - src.data_processing.generate_embeddings - INFO - [OK] Pe9WxkN8Ff
2025-06-15 13:42:53,144 - src.data_processing.generate_embeddings - INFO - Encoding entry: 1zo4iioUEs
2025-06-15 13:42:53,144 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:42:53,186 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:53,298 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:53,339 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:53,446 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:53,491 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:53,598 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:53,655 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:53,750 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:53,752 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:42:53,752 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:42:54,300 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:42:54,304 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:42:54,304 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:42:54,304 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:42:54,305 - src.data_processing.generate_embeddings - INFO - [OK] 1zo4iioUEs
2025-06-15 13:42:54,305 - src.data_processing.generate_embeddings - INFO - Encoding entry: OL2JQoO0kq
2025-06-15 13:42:54,305 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:42:54,347 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:54,456 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:54,501 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:54,608 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:54,652 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:54,762 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:54,819 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:54,916 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:54,918 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:42:54,919 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:42:55,453 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:42:55,458 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:42:55,458 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:42:55,459 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:42:55,459 - src.data_processing.generate_embeddings - INFO - [OK] OL2JQoO0kq
2025-06-15 13:42:55,459 - src.data_processing.generate_embeddings - INFO - Encoding entry: gI1SOgW3kw
2025-06-15 13:42:55,459 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:42:55,502 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:55,609 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:55,663 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:55,764 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:55,823 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:55,923 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:55,979 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:56,077 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:56,079 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:42:56,079 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:42:56,610 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:42:56,614 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:42:56,615 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:42:56,615 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:42:56,615 - src.data_processing.generate_embeddings - INFO - [OK] gI1SOgW3kw
2025-06-15 13:42:56,615 - src.data_processing.generate_embeddings - INFO - Encoding entry: Qf8uzIT1OK
2025-06-15 13:42:56,615 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:42:56,653 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:56,768 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:56,809 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:56,922 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:56,963 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:57,073 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:57,111 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:57,112 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:42:57,112 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:42:57,707 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:42:57,711 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:42:57,711 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:42:57,711 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:42:57,712 - src.data_processing.generate_embeddings - INFO - [OK] Qf8uzIT1OK
2025-06-15 13:42:57,712 - src.data_processing.generate_embeddings - INFO - Encoding entry: mmTy1iyU5G
2025-06-15 13:42:57,712 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:42:57,751 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:57,867 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:57,909 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:57,953 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:57,996 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:58,039 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:58,080 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:58,149 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:58,151 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:42:58,151 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:42:58,668 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:42:58,672 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:42:58,672 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:42:58,673 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:42:58,673 - src.data_processing.generate_embeddings - INFO - [OK] mmTy1iyU5G
2025-06-15 13:42:58,673 - src.data_processing.generate_embeddings - INFO - Encoding entry: liMSqUuVg9
2025-06-15 13:42:58,673 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:42:58,713 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:58,755 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:58,796 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:58,838 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:58,885 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:58,930 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:58,974 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:59,021 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:59,064 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:59,066 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:42:59,066 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:42:59,583 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:42:59,588 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:42:59,588 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:42:59,589 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:42:59,589 - src.data_processing.generate_embeddings - INFO - [OK] liMSqUuVg9
2025-06-15 13:42:59,589 - src.data_processing.generate_embeddings - INFO - Encoding entry: eD534mPhAg
2025-06-15 13:42:59,589 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:42:59,631 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:59,670 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:59,710 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:59,754 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:59,801 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:59,908 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:42:59,963 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:00,091 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:00,093 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:00,093 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:00,625 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:00,629 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:00,629 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:00,630 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:00,630 - src.data_processing.generate_embeddings - INFO - [OK] eD534mPhAg
2025-06-15 13:43:00,630 - src.data_processing.generate_embeddings - INFO - Encoding entry: S5wmbQc1We
2025-06-15 13:43:00,630 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:00,671 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:00,780 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:00,820 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:00,866 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:00,909 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:00,948 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:00,992 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:01,036 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:01,038 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:01,038 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:01,588 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:01,597 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:01,597 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:01,598 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:01,598 - src.data_processing.generate_embeddings - INFO - [OK] S5wmbQc1We
2025-06-15 13:43:01,598 - src.data_processing.generate_embeddings - INFO - Encoding entry: dVaWCDMBof
2025-06-15 13:43:01,599 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:01,637 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:01,676 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:01,720 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:01,764 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:01,808 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:01,853 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:01,896 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:01,941 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:01,982 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:01,985 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:01,985 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:02,508 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:02,514 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:02,514 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:02,515 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:02,515 - src.data_processing.generate_embeddings - INFO - [OK] dVaWCDMBof
2025-06-15 13:43:02,516 - src.data_processing.generate_embeddings - INFO - Encoding entry: jDIlzSU8wJ
2025-06-15 13:43:02,516 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:02,557 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:02,598 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:02,642 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:02,682 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:02,724 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:02,764 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:02,806 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:02,850 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:02,853 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:02,853 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:03,377 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:03,380 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:03,380 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:03,381 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:03,381 - src.data_processing.generate_embeddings - INFO - [OK] jDIlzSU8wJ
2025-06-15 13:43:03,381 - src.data_processing.generate_embeddings - INFO - Encoding entry: HPuSIXJaa9
2025-06-15 13:43:03,381 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:03,424 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:03,463 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:03,503 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:03,545 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:03,581 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:03,622 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:03,660 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:03,706 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:03,750 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:03,754 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:03,755 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:04,300 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:04,305 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:04,305 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:04,305 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:04,306 - src.data_processing.generate_embeddings - INFO - [OK] HPuSIXJaa9
2025-06-15 13:43:04,306 - src.data_processing.generate_embeddings - INFO - Encoding entry: Kv8GJkV19S
2025-06-15 13:43:04,306 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:04,351 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:04,395 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:04,437 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:04,474 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:04,519 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:04,563 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:04,607 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:04,652 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:04,653 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:04,654 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:05,189 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:05,195 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:05,195 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:05,196 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:05,196 - src.data_processing.generate_embeddings - INFO - [OK] Kv8GJkV19S
2025-06-15 13:43:05,196 - src.data_processing.generate_embeddings - INFO - Encoding entry: mayAyPrhJI
2025-06-15 13:43:05,196 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:05,233 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:05,280 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:05,327 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:05,374 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:05,417 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:05,463 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:05,503 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:05,547 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:05,549 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:05,550 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:06,084 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:06,088 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:06,088 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:06,088 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:06,089 - src.data_processing.generate_embeddings - INFO - [OK] mayAyPrhJI
2025-06-15 13:43:06,089 - src.data_processing.generate_embeddings - INFO - Encoding entry: QzcZb3fWmW
2025-06-15 13:43:06,089 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:06,131 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:06,169 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:06,214 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:06,255 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:06,297 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:06,337 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:06,383 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:06,425 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:06,426 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:06,426 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:06,943 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:06,948 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:06,949 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:06,949 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:06,949 - src.data_processing.generate_embeddings - INFO - [OK] QzcZb3fWmW
2025-06-15 13:43:06,949 - src.data_processing.generate_embeddings - INFO - Encoding entry: PITeSdYQkv
2025-06-15 13:43:06,949 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:06,987 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:07,028 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:07,073 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:07,115 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:07,155 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:07,199 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:07,241 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:07,286 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:07,288 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:07,289 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:07,821 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:07,824 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:07,825 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:07,825 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:07,825 - src.data_processing.generate_embeddings - INFO - [OK] PITeSdYQkv
2025-06-15 13:43:07,825 - src.data_processing.generate_embeddings - INFO - Encoding entry: QIFoCI7ca1
2025-06-15 13:43:07,825 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:07,865 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:07,909 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:08,019 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:08,060 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:08,106 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:08,148 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:08,213 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:08,302 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:08,304 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:08,305 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:08,846 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:08,851 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:08,852 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:08,853 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:08,853 - src.data_processing.generate_embeddings - INFO - [OK] QIFoCI7ca1
2025-06-15 13:43:08,853 - src.data_processing.generate_embeddings - INFO - Encoding entry: D1MOK2t2t2
2025-06-15 13:43:08,853 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:08,890 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:09,006 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:09,050 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:09,093 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:09,202 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:09,244 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:09,355 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:09,396 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:09,397 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:09,398 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:09,938 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:09,941 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:09,942 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:09,943 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:09,943 - src.data_processing.generate_embeddings - INFO - [OK] D1MOK2t2t2
2025-06-15 13:43:09,943 - src.data_processing.generate_embeddings - INFO - Encoding entry: Vota6rFhBQ
2025-06-15 13:43:09,943 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:09,980 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:10,134 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:10,181 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:10,223 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:10,269 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:10,316 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:10,356 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:10,399 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:10,401 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:10,402 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:10,921 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:10,926 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:10,926 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:10,926 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:10,926 - src.data_processing.generate_embeddings - INFO - [OK] Vota6rFhBQ
2025-06-15 13:43:10,926 - src.data_processing.generate_embeddings - INFO - Encoding entry: qHrADgAdYu
2025-06-15 13:43:10,927 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:10,971 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:11,009 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:11,052 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:11,091 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:11,137 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:11,177 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:11,219 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:11,258 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:11,259 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:11,260 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:11,778 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:11,783 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:11,783 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:11,784 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:11,784 - src.data_processing.generate_embeddings - INFO - [OK] qHrADgAdYu
2025-06-15 13:43:11,784 - src.data_processing.generate_embeddings - INFO - Encoding entry: jA235JGM09
2025-06-15 13:43:11,784 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:11,824 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:11,866 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:11,908 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:11,953 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:11,995 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:12,041 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:12,084 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:12,131 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:12,133 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:12,133 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:12,677 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:12,682 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:12,682 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:12,683 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:12,683 - src.data_processing.generate_embeddings - INFO - [OK] jA235JGM09
2025-06-15 13:43:12,683 - src.data_processing.generate_embeddings - INFO - Encoding entry: KvPwXVcslY
2025-06-15 13:43:12,683 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:12,723 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:12,765 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:12,805 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:12,849 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:12,894 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:12,935 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:12,978 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:13,029 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:13,072 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:13,074 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:13,074 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:13,614 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:13,617 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:13,618 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:13,618 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:13,618 - src.data_processing.generate_embeddings - INFO - [OK] KvPwXVcslY
2025-06-15 13:43:13,618 - src.data_processing.generate_embeddings - INFO - Encoding entry: j2wasUypqN
2025-06-15 13:43:13,618 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:13,657 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:13,700 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:13,752 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:13,794 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:13,837 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:13,879 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:13,922 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:13,964 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:13,966 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:13,966 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:14,482 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:14,487 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:14,487 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:14,487 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:14,488 - src.data_processing.generate_embeddings - INFO - [OK] j2wasUypqN
2025-06-15 13:43:14,488 - src.data_processing.generate_embeddings - INFO - Encoding entry: TXoZiUZywf
2025-06-15 13:43:14,488 - src.data_processing.encoder - INFO - chunking
2025-06-15 13:43:14,530 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:14,572 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:14,614 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:14,655 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:14,699 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:14,740 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:14,782 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:14,825 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:countTokens "HTTP/1.1 200 OK"
2025-06-15 13:43:14,826 - src.data_processing.encoder - INFO - chunked: 1
2025-06-15 13:43:14,826 - src.data_processing.encoder - INFO - embedding chunk 1- (Attempt 1)
2025-06-15 13:43:15,342 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-exp-03-07:batchEmbedContents "HTTP/1.1 200 OK"
2025-06-15 13:43:15,345 - src.data_processing.encoder - INFO - embedded chunk 1- (Attempt 1)
2025-06-15 13:43:15,346 - src.data_processing.encoder - INFO - finished embedding chunks
2025-06-15 13:43:15,346 - src.data_processing.encoder - INFO - reconstructed
2025-06-15 13:43:15,346 - src.data_processing.generate_embeddings - INFO - [OK] TXoZiUZywf
2025-06-15 13:43:15,474 - root - INFO - [OK] exported to raw_emb.json
2025-06-15 13:43:15,572 - root - INFO - [OK] exported to emb.json
