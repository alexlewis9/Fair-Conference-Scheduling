Published as a conference paper at ICLR 2024
ACCELERATING
DISTRIBUTED
STOCHASTIC
OPTI-
MIZATION VIA SELF-REPELLENT RANDOM WALKS
Jie Hu‚àó1, Vishwaraj Doshi‚àó2, Do Young Eun1
1North Carolina State University, 2IQVIA Inc.
{jhu29,dyeun}@ncsu.edu, vishwaraj.doshi@iqvia.com
ABSTRACT
We study a family of distributed stochastic optimization algorithms where gradi-
ents are sampled by a token traversing a network of agents in random-walk fash-
ion. Typically, these random-walks are chosen to be Markov chains that asymp-
totically sample from a desired target distribution, and play a critical role in the
convergence of the optimization iterates. In this paper, we take a novel approach
by replacing the standard linear Markovian token by one which follows a non-
linear Markov chain - namely the Self-Repellent Radom Walk (SRRW). Defined
for any given ‚Äòbase‚Äô Markov chain, the SRRW, parameterized by a positive scalar
Œ±, is less likely to transition to states that were highly visited in the past, thus
the name. In the context of MCMC sampling on a graph, a recent breakthrough in
Doshi et al. (2023) shows that the SRRW achieves O(1/Œ±) decrease in the asymp-
totic variance for sampling. We propose the use of a ‚Äògeneralized‚Äô version of the
SRRW to drive token algorithms for distributed stochastic optimization in the form
of stochastic approximation, termed SA-SRRW. We prove that the optimization it-
erate errors of the resulting SA-SRRW converge to zero almost surely and prove a
central limit theorem, deriving the explicit form of the resulting asymptotic covari-
ance matrix corresponding to iterate errors. This asymptotic covariance is always
smaller than that of an algorithm driven by the base Markov chain and decreases
at rate O(1/Œ±2) - the performance benefit of using SRRW thereby amplified in the
stochastic optimization context. Empirical results support our theoretical findings.
1
INTRODUCTION
Stochastic optimization algorithms solve optimization problems of the form
Œ∏‚àó‚ààarg min
Œ∏‚ààRd
f(Œ∏),
where f(Œ∏) ‚âúEX‚àº¬µ [F(Œ∏, X)] =
X
i‚ààN
¬µiF(Œ∏, i),
(1)
with the objective function f : Rd ‚ÜíR and X taking values in a finite state space N with distri-
bution ¬µ ‚âú[¬µi]i‚ààN . Leveraging partial gradient information per iteration, these algorithms have
been recognized for their scalability and efficiency with large datasets (Bottou et al., 2018; Even,
2023). For any given noise sequence {Xn}n‚â•0 ‚äÇN, and step size sequence {Œ≤n}n‚â•0 ‚äÇR+, most
stochastic optimization algorithms can be classified as stochastic approximations (SA) of the form
Œ∏n+1 = Œ∏n + Œ≤n+1H(Œ∏n, Xn+1),
‚àÄn ‚â•0,
(2)
where, roughly speaking, H(Œ∏, i) contains gradient information ‚àáŒ∏F(Œ∏, i), such that Œ∏‚àósolves
h(Œ∏) ‚âúEX‚àº¬µ[H(Œ∏, X)] = P
i‚ààN ¬µiH(Œ∏, i) = 0. Such SA iterations include the well-known
stochastic gradient descent (SGD), stochastic heavy ball (SHB) (Gadat et al., 2018; Li et al., 2022),
and some SGD-type algorithms employing additional auxiliary variables (Barakat et al., 2021).1
These algorithms typically have the stochastic noise term Xn generated by i.i.d. random variables
with probability distribution ¬µ in each iteration. In this paper, we study a stochastic optimization
algorithm where the noise sequence governing access to the gradient information is generated from
general stochastic processes in place of i.i.d. random variables.
*Equal contributors.
1Further illustrations of stochastic optimization algorithms of the form (2) are deferred to Appendix A.
1

Published as a conference paper at ICLR 2024
This is commonly the case in distributed learning, where {Xn} is a (typically Markovian) random
walk, and should asymptotically be able to sample the gradients from the desired probability dis-
tribution ¬µ. This is equivalent to saying that the random walker‚Äôs empirical distribution converges
to ¬µ almost surely (a.s.); that is, xn ‚âú
1
n+1
Pn
k=0 Œ¥Xk
a.s.
‚àí‚àí‚àí‚àí‚Üí
n‚Üí‚àû¬µ for any initial X0 ‚ààN, where
Œ¥Xk is the delta measure whose Xk‚Äôth entry is one, the rest being zero. Such convergence is most
commonly achieved by employing the Metropolis Hastings random walk (MHRW) which can be
designed to sample from any target measure ¬µ and implemented in a scalable manner (Sun et al.,
2018). Unsurprisingly, convergence characteristics of the employed Markov chain affect that of the
SA sequence (2), and appear in both finite-time and asymptotic analyses. Finite-time bounds typ-
ically involve the second largest eigenvalue in modulus (SLEM) of the Markov chain‚Äôs transition
kernel P, which is critically connected to the mixing time of a Markov chain (Levin & Peres, 2017);
whereas asymptotic results such as central limit theorems (CLT) involve asymptotic covariance ma-
trices that embed information regarding the entire spectrum of P, i.e., all eigenvalues as well as
eigenvectors (Br¬¥emaud, 2013), which are key to understanding the sampling efficiency of a Markov
chain. Thus, the choice of random walker can significantly impact the performance of (2), and sim-
ply ensuring that it samples from ¬µ asymptotically is not enough to achieve optimal algorithmic
performance. In this paper, we take a closer look at the distributed stochastic optimization problem
through the lens of a non-linear Markov chain, known as the Self Repellent Random Walk (SRRW),
which was shown in Doshi et al. (2023) to achieve asymptotically minimal sampling variance for
large values of Œ±, a positive scalar controlling the strength of the random walker‚Äôs self-repellence
behaviour. Our proposed modification of (2) can be implemented within the settings of decentral-
ized learning applications in a scalable manner, while also enjoying significant performance benefit
over distributed stochastic optimization algorithms driven by vanilla Markov chains.
Token Algorithms for Decentralized Learning. In decentralized learning, agents like smartphones
or IoT devices, each containing a subset of data, collaboratively train models on a graph G(N, E) by
sharing information locally without a central server (McMahan et al., 2017). In this setup, N =|N|
agents correspond to nodes i ‚ààN, and an edge (i, j) ‚ààE indicates direct communication between
agents i and j. This decentralized approach offers several advantages compared to the traditional
centralized learning setting, promoting data privacy and security by eliminating the need for raw data
to be aggregated centrally and thus reducing the risk of data breach or misuse (Bottou et al., 2018;
Nedic, 2020). Additionally, decentralized approaches are more scalable and can handle vast amounts
of heterogeneous data from distributed agents without overwhelming a central server, alleviating
concerns about single point of failure (Vogels et al., 2021).
Among decentralized learning approaches, the class of ‚ÄòToken‚Äô algorithms can be expressed as
stochastic approximation iterations of the type (2), wherein the sequence {Xn} is realized as the
sample path of a token that stochastically traverses the graph G, carrying with it the iterate Œ∏n for any
time n ‚â•0 and allowing each visited node (agent) to incrementally update Œ∏n using locally available
gradient information. Token algorithms have gained popularity in recent years (Hu et al., 2022; Tri-
astcyn et al., 2022; Hendrikx, 2023), and are provably more communication efficient (Even, 2023)
when compared to consensus-based algorithms - another popular approach for solving distributed
optimization problems (Boyd et al., 2006; Morral et al., 2017; Olshevsky, 2022). The construction
of token algorithms means that they do not suffer from expensive costs of synchronization and com-
munication that are typical of consensus-based approaches, where all agents (or a subset of agents
selected by a coordinator (Boyd et al., 2006; Wang et al., 2019)) on the graph are required to take
simultaneous actions, such as communicating on the graph at each iteration. While decentralized
Federated learning has indeed helped mitigate the communication overhead by processing multiple
SGD iterations prior to each aggregation (Lalitha et al., 2018; Ye et al., 2022; Chellapandi et al.,
2023), they still cannot overcome challenges such as synchronization and straggler issues.
Self Repellent Random Walk. As mentioned earlier, sample paths {Xn} of token algorithms are
usually generated using Markov chains with ¬µ ‚ààInt(Œ£) as their limiting distribution. Here, Œ£
denotes the N-dimensional probability simplex, with Int(Œ£) representing its interior. A recent work
by Doshi et al. (2023) pioneers the use of non-linear Markov chains to, in some sense, improve upon
any given time-reversible Markov chain with transition kernel P whose stationary distribution is ¬µ.
2

Published as a conference paper at ICLR 2024
They show that the non-linear transition kernel2 K[¬∑] : Int(Œ£) ‚Üí[0, 1]N√óN, given by
Kij[x] ‚âú
Pij(xj/¬µj)‚àíŒ±
P
k‚ààN Pik(xk/¬µk)‚àíŒ± ,
‚àÄi, j ‚ààN,
(3)
for any x ‚ààInt(Œ£), when simulated as a self-interacting random walk (Del Moral & Miclo, 2006;
Del Moral & Doucet, 2010), can achieve smaller asymptotic variance than the base Markov chain
when sampling over a graph G, for all Œ± > 0. The argument x for the kernel K[x] is taken to
be the empirical distribution xn at each time step n ‚â•0. For instance, if node j has been visited
more often than other nodes so far, the entry xj becomes larger (than target value ¬µj), resulting in
a smaller transition probability from i to j under K[x] in (3) compared to Pij. This ensures that
a random walker prioritizes more seldom visited nodes in the process, and is thus ‚Äòself-repellent‚Äô.
This effect is made more drastic by increasing Œ±, and leads to asymptotically near-zero variance at
a rate of O(1/Œ±). Moreover, the polynomial function (xi/¬µi)‚àíŒ± chosen to encode self-repellent
behaviour is shown in Doshi et al. (2023) to be the only one that allows the SRRW to inherit the so-
called ‚Äòscale-invariance‚Äô property of the underlying Markov chain ‚Äì a necessary component for the
scalable implementation of a random walker over a large network without requiring knowledge of
any graph-related global constants. Conclusively, such attributes render SRRW especially suitable
for distributed optimization.3
Effect of Stochastic Noise - Finite time and Asymptotic Approaches. Most contemporary token
algorithms driven by Markov chains are analyzed using the finite-time bounds approach for obtain-
ing insights into their convergence rates (Sun et al., 2018; Doan et al., 2019; 2020; Triastcyn et al.,
2022; Hendrikx, 2023). However, as also explained in Even (2023), in most cases these bounds are
overly dependent on mixing time properties of the specific Markov chain employed therein. This
makes them largely ineffective in capturing the exact contribution of the underlying random walk
in a manner which is qualitative enough to be used for algorithm design; and performance enhance-
ments are typically achieved via application of techniques such as variance reduction (Defazio et al.,
2014; Schmidt et al., 2017), momentum/Nesterov‚Äôs acceleration (Gadat et al., 2018; Li et al., 2022),
adaptive step size (Kingma & Ba, 2015; Reddi et al., 2018), which work by modifying the algorithm
iterations themselves, and never consider potential improvements to the stochastic input itself.
Complement to finite-time approaches, asymptotic analysis using CLT has proven to be an excellent
tool to approach the design of stochastic algorithms (Hu et al., 2022; Devraj & Meyn, 2017; Morral
et al., 2017; Chen et al., 2020a; Mou et al., 2020; Devraj & Meyn, 2021). Hu et al. (2022) shows
how asymptotic analysis can be used to compare the performance of SGD algorithms for various
stochastic inputs using their notion of efficiency ordering, and, as mentioned in Devraj & Meyn
(2017), the asymptotic benefits from minimizing the limiting covariance matrix are known to be a
good predictor of finite-time algorithmic performance, also observed empirically in Section 4.
From the perspective of both finite-time analysis as well as asymptotic analysis of token algorithms,
it is now well established that employing ‚Äòbetter‚Äô Markov chains can enhance the performance of
stochastic optimization algorithm. For instance, Markov chains with smaller SLEMs yield tighter
finite-time upper bounds (Sun et al., 2018; Ayache & El Rouayheb, 2021; Even, 2023). Similarly,
Markov chains with smaller asymptotic variance for MCMC sampling tasks also provide better
performance, resulting in smaller covariance matrix of SGD algorithms (Hu et al., 2022). Therefore,
with these breakthrough results via SRRW achieving near-zero sampling variance, it is within reason
to ask: Can we achieve near-zero variance in distributed stochastic optimization driven by SRRW-
like token algorithms on any general graph?4 In this paper, we answer in the affirmative.
SRRW Driven Algorithm and Analysis Approach. For any ergodic time-reversible Markov chain
with transition probability matrix P ‚âú[Pij]i,j‚ààN and stationary distribution ¬µ ‚ààInt(Œ£), we con-
sider a general step size version of the SRRW stochastic process analysed in Doshi et al. (2023) and
2Here, non-linearity in the transition kernel implies that K[x] takes probability distribution x as the argu-
ment (Andrieu et al., 2007), as opposed to the kernel being a linear operator K[x] = P for a constant stochastic
matrix P in a standard (linear) Markovian setting.
3Recently, Guo et al. (2020) introduce an optimization scheme, which designs self-repellence into the per-
turbation of the gradient descent iterates (Jin et al., 2017; 2018; 2021) with the goal of escaping saddle points.
This notion of self-repellence is distinct from the SRRW, which is a probability kernel designed specifically for
a token to sample from a target distribution ¬µ over a set of nodes on an arbitrary graph.
4This near-zero sampling variance implies a significantly smaller variance than even an i.i.d. sampling
counterpart, while adhering to graph topological constraints of token algorithms.
3

Published as a conference paper at ICLR 2024
Stochastic 
Optimization 
Algorithm
Asymptotic Covariance ùëΩùúÉ
High Variance
Near-Zero Variance (Our Result)
ùúÉùëõ+1 = ùúÉùëõ+ ùõΩùëõ+1ùêªùúÉùëõ, ùëãùëõ+1
ùõΩùëõ
‚àí1/2 ùúÉùëõ‚àíùúÉ‚àó’ú
ùëëùëÅ(0, ùëΩùúÉ)
Nonlinear MC (SRRW [Doshi et al. 2023])
Traditional MC, e.g., MHRW
1
2
4
1
1
4
1
2
4
1
1
4
Token‚Äôs trajectory ùëãùëõùëõ‚â•0
?
Figure 1: Visualization of token algorithms using SRRW versus traditional MC in distributed learn-
ing. Our CLT analysis, extended from SRRW itself to distributed stochastic approximation, leads to
near-zero variance for the SA iteration Œ∏n. Node numbers on the left denote visit counts.
use it to drive the noise sequence in (2). Our SA-SRRW algorithm is as follows:
Draw:
Xn+1 ‚àºKXn,¬∑[xn]
(4a)
Update:
xn+1 = xn + Œ≥n+1(Œ¥Xn+1 ‚àíxn),
(4b)
Œ∏n+1 = Œ∏n + Œ≤n+1H(Œ∏n, Xn+1),
(4c)
where {Œ≤n} and {Œ≥n} are step size sequences decreasing to zero, and K[x] is the SRRW kernel in
(3). Current non-asymptotic analyses require globally Lipschitz mean field function (Chen et al.,
2020b; Doan, 2021; Zeng et al., 2021; Even, 2023) and is thus inapplicable to SA-SRRW since
the mean field function of the SRRW iterates (4b) is only locally Lipschitz (details deferred to
Appendix B). Instead, we successfully obtain non-trivial results by taking an asymptotic CLT-based
approach to analyze (4). This goes beyond just analyzing the asymptotic sampling covariance5 as
in Doshi et al. (2023), the result therein forming a special case of ours by setting Œ≥n =1/(n+1) and
considering only (4a) and (4b), that is, in the absence of optimization iteration (4c). Specifically,
we capture the effect of SRRW‚Äôs hyper-parameter Œ± on the asymptotic speed of convergence of the
optimization error term Œ∏n ‚àíŒ∏‚àóto zero via explicit deduction of its asymptotic covariance matrix.
See Figure 1 for illustration.
Our Contributions.
1. Given any time-reversible ‚Äòbase‚Äô Markov chain with transition kernel P and stationary distribution
¬µ, we generalize first and second order convergence results of xn to target measure ¬µ (Theorems
4.1 and 4.2 in Doshi et al., 2023) to a class of weighted empirical measures, through the use of more
general step sizes Œ≥n. This includes showing that the asymptotic sampling covariance terms decrease
to zero at rate O(1/Œ±), thus quantifying the effect of self-repellent on xn. Our generalization is not
for the sake thereof and is shown in Section 3 to be crucial for the design of step sizes Œ≤n, Œ≥n.
2. Building upon the convergence results for iterates xn, we analyze the algorithm (4) driven by the
SRRW kernel in (3) with step sizes Œ≤n and Œ≥n separated into three disjoint cases:
(i) Œ≤n = o(Œ≥n), and we say that Œ∏n is on the slower timescale compared to xn;
(ii) Œ≤n =Œ≥n, and we say that Œ∏n and xn are on the same timescale;
(iii) Œ≥n = o(Œ≤n), and we say that Œ∏n is on the faster timescale compared to xn.
For any Œ± ‚â•0 and let k = 1, 2 and 3 refer to the corresponding cases (i), (ii) and (iii), we show that
Œ∏n
a.s.
‚àí‚àí‚àí‚àí‚Üí
n‚Üí‚àûŒ∏‚àó
and
(Œ∏n ‚àíŒ∏‚àó)/
p
Œ≤n
dist.
‚àí‚àí‚àí‚àí‚Üí
n‚Üí‚àûN

0, V(k)
Œ∏ (Œ±)

,
featuring distinct asymptotic covariance matrices V(1)
Œ∏ (Œ±), V(2)
Œ∏ (Œ±) and V(3)
Œ∏ (Œ±), respectively. The
three matrices coincide when Œ± = 0,6. Moreover, the derivation of the CLT for cases (i) and (iii),
for which (4) corresponds to two-timescale SA with controlled Markov noise, is the first of its kind
and thus a key technical contribution in this paper, as expanded upon in Section 3.
3. For case (i), we show that V(1)
Œ∏ (Œ±) decreases to zero (in the sense of Loewner ordering introduced
in Section 2.1) as Œ± increases, with rate O(1/Œ±2). This is especially surprising, since the asymptotic
performance benefit from using the SRRW kernel with Œ± in (3), to drive the noise terms Xn, is
amplified in the context of distributed learning and estimating Œ∏‚àó; compared to the sampling case,
for which the rate is O(1/Œ±) as mentioned earlier. For case (iii), we show that V(3)
Œ∏ (Œ±) = V(3)
Œ∏ (0)
for all Œ± ‚â•0, implying that using the SRRW in this case provides no asymptotic benefit than the
5Sampling covariance corresponds to only the empirical distribution xn in (4b).
6The Œ± = 0 case is equivalent to simply running the base Markov chain, since from (3) we have K[¬∑] = P,
thus bypassing the SRRW‚Äôs effect and rendering all three cases nearly the same.
4

Published as a conference paper at ICLR 2024
original base Markov chain, and thus performs worse than case (i). In summary, we deduce that
V(1)
Œ∏ (Œ±2)<L V(1)
Œ∏ (Œ±1)<L V(1)
Œ∏ (0)=V(3)
Œ∏ (0)=V(3)
Œ∏ (Œ±) for all Œ±2 > Œ±1 > 0 and Œ± > 0.7
4. We numerically simulate our SA-SRRW algorithm on various real-world datasets, focusing on
a binary classification task, to evaluate its performance across all three cases. By carefully choos-
ing the function H in SA-SRRW, we test the SGD and algorithms driven by SRRW. Our findings
consistently highlight the superiority of case (i) over cases (ii) and (iii) for diverse Œ± values, even in
their finite time performance. Notably, our tests validate the variance reduction at a rate of O(1/Œ±2)
for case (i), suggesting it as the best algorithmic choice among the three cases.
2
PRELIMINARIES AND MODEL SETUP
In Section 2.1, we first standardize the notations used throughout the paper, and define key mathe-
matical terms and quantities used in our theoretical analyses. Then, in Section 2.2, we consolidate
the model assumptions of our SA-SRRW algorithm (4). We then go on to discuss our assumptions,
and provide additional interpretations of our use of generalized step-sizes.
2.1
BASIC NOTATIONS AND DEFINITIONS
Vectors are denoted by lower-case bold letters, e.g., v ‚âú[vi] ‚ààRD, and matrices by upper-case
bold, e.g., M ‚âú[Mij] ‚ààRD√óD. M‚àíT is the transpose of the matrix inverse M‚àí1. The diagonal
matrix Dv is formed by vector v with vi as the i‚Äôth diagonal entry. Let 1 and 0 denote vectors of
all ones and zeros, respectively. The identity matrix is represented by I, with subscripts indicating
dimensions as needed. A matrix is Hurwitz if all its eigenvalues possess strictly negative real parts.
1{¬∑} denotes an indicator function with condition in parentheses. We use ‚à•¬∑‚à•to denote both the
Euclidean norm of vectors and the spectral norm of matrices. Two symmetric matrices M1, M2
follow Loewner ordering M1 <L M2 if M2 ‚àíM1 is positive semi-definite and M1 Ã∏= M2. This
slightly differs from the conventional definition with ‚â§L, which allows M1 =M2.
Throughout the paper, the matrix P ‚âú[Pi,j]i,j‚ààN and vector ¬µ ‚âú[¬µi]i‚ààN are used exclusively
to denote an N √ó N-dimensional transition kernel of an ergodic Markov chain, and its stationary
distribution, respectively. Without loss of generality, we assume Pij > 0 if and only if aij > 0.
Markov chains satisfying the detailed balance equation, where ¬µiPij = ¬µjPji for all i, j ‚ààN, are
termed time-reversible. For such chains, we use (Œªi, ui) (resp. (Œªi, vi)) to denote the i‚Äôth left (resp.
right) eigenpair where the eigenvalues are ordered: ‚àí1 < Œª1 ‚â§¬∑ ¬∑ ¬∑ ‚â§ŒªN‚àí1 < ŒªN = 1, with uN = ¬µ
and vN = 1 in RN. We assume eigenvectors to be normalized such that uT
i vi = 1 for all i, and we
have ui =D¬µvi and uT
i vj =0 for all i, j ‚ààN. We direct the reader to Aldous & Fill (2002, Chapter
3.4) for a detailed exposition on spectral properties of time-reversible Markov chains.
2.2
SA-SRRW: KEY ASSUMPTIONS AND DISCUSSIONS
Assumptions: All results in our paper are proved under the following assumptions.
(A1) The function H : RD √ó N ‚ÜíRD, is a continuous at every Œ∏ ‚ààRD, and there exists a
positive constant L such that ‚à•H(Œ∏, i)‚à•‚â§L(1 + ‚à•Œ∏‚à•) for every Œ∏ ‚ààRD, i ‚ààN.
(A2) Step sizes Œ≤n and Œ≥n follow Œ≤n =(n+1)‚àíb, and Œ≥n =(n+1)‚àía, where a, b ‚àà(0.5, 1].
(A3) Roots of function h(¬∑) are disjoint, which comprise the globally attracting set Œò ‚âú
n
Œ∏‚àó|h(Œ∏‚àó)=0, ‚àáh(Œ∏‚àó) +
1{b=1}
2
I is Hurwitz
o
Ã∏= ‚àÖof the associated ordinary differential
equation (ODE) for iteration (4c), given by dŒ∏(t)/dt=h(Œ∏(t)).
(A4) For any (Œ∏0, x0, X0) ‚ààRD √ó Int(Œ£) √ó N, the iterate sequence {Œ∏n}n‚â•0 (resp. {xn}n‚â•0)
is PŒ∏0,x0,X0-almost surely contained within a compact subset of RD (resp. Int(Œ£)).
Discussions on Assumptions: Assumption A1 requires H to only be locally Lipschitz albeit with
linear growth, and is less stringent than the globally Lipschitz assumption prevalent in optimization
literature (Li & Wai, 2022; Hendrikx, 2023; Even, 2023).
7In particular, this is the reason why we advocate for a more general step size Œ≥n = (n+1)‚àía in the SRRW
iterates with a < 1, allowing us to choose Œ≤n = (n + 1)‚àíb with b ‚àà(a, 1] to satisfy Œ≤n = o(Œ≥n) for case (i).
5

Published as a conference paper at ICLR 2024
Assumption A2 is the general umbrella assumption under which cases (i), (ii) and (iii) mentioned
in Section 1 are extracted by setting: (i) a < b, (ii) a = b, and (iii) a > b. Cases (i) and (iii)
render Œ∏n, xn on different timescales; the polynomial form of Œ≤n, Œ≥n widely assumed in the two-
timescale SA literature (Mokkadem & Pelletier, 2006; Zeng et al., 2021; Hong et al., 2023). Case (ii)
characterizes the SA-SRRW algorithm (4) as a single-timescale SA with polynomially decreasing
step size, and is among the most common assumptions in the SA literature (Borkar, 2022; Fort,
2015; Li et al., 2023). In all three cases, the form of Œ≥n ensures Œ≥n ‚â§1 such that the SRRW iterates
xn in (4b) is within Int(Œ£), ensuring that K[xn] is well-defined for all n ‚â•0.
In Assumption A3, limiting dynamics of SA iterations {Œ∏n}n‚â•0 closely follow trajectories
{Œ∏(t)}t‚â•0 of their associated ODE, and assuming the existence of globally stable equilibria is stan-
dard (Borkar, 2022; Fort, 2015; Li et al., 2023). In optimization problems, this is equivalent to
assuming the existence of at most countably many local minima.
Assumption A4 assumes almost sure boundedness of iterates Œ∏n and xn, which is a common as-
sumption in SA algorithms (Kushner & Yin, 2003; Chen, 2006; Borkar, 2022; Karmakar & Bhatna-
gar, 2018; Li et al., 2023) for the stability of the SA iterations by ensuring the well-definiteness of all
quantities involved. Stability of the weighted empirical measure xn of the SRRW process is prac-
tically ensured by studying (4b) with a truncation-based procedure (see Doshi et al., 2023, Remark
4.5 and Appendix E for a comprehensive explanation), while that for Œ∏n is usually ensured either as
a by-product of the algorithm design, or via mechanisms such as projections onto a compact subset
of RD, depending on the application context. We now provide additional discussions regarding the
step-size assumptions and their implications on the SRRW iteration (4b).
SRRW with General Step Size: As shown in Benaim & Cloez (2015, Remark 1.1), albeit for a
completely different non-linear Markov kernel driving the algorithm therein, iterates xn of (4b) can
also be expressed as weighted empirical measures of {Xn}n‚â•0, in the following form:
xn =
Pn
i=1 œâiŒ¥Xi + œâ0x0
Pn
i=0 œâi
,
where œâ0 = 1, and œân =
Œ≥n
Qn
i=1(1 ‚àíŒ≥i),
(5)
for all n > 0. For the special case when Œ≥n = 1/(n+1) as in Doshi et al. (2023), we have œân = 1 for
all n ‚â•0 and xn is the typical, unweighted empirical measure. For the additional case considered
in our paper, when a < 1 for Œ≥n as in assumption A2, we can approximate 1 ‚àíŒ≥n ‚âàe‚àíŒ≥n and
œân ‚âàn‚àíaen(1‚àía)/(1‚àía). This implies that œân will increase at sub-exponential rate, giving more
weight to recent visit counts and allowing it to quickly ‚Äòforget‚Äô the poor initial measure x0 and shed
the correlation with the initial choice of X0. This ‚Äòspeed up‚Äô effect by setting a < 1 is guaranteed
in case (i) irrespective of the choice of b in Assumption A2, and in Section 3 we show how this can
lead to further reduction in covariance of optimization error Œ∏n = Œ∏‚àóin the asymptotic regime.
Additional assumption for case (iii): Before moving on to Section 3, we take another look at the
case when Œ≥n = o(Œ≤n), and replace A3 with the following, stronger assumption only for case (iii).
(A3‚Ä≤) For any x‚ààInt(Œ£), there exists a function œÅ : Int(Œ£)‚ÜíRD such that ‚à•œÅ(x)‚à•‚â§L2(1+‚à•x‚à•)
for some L2 >0, Ei‚àºœÄ[x][H(œÅ(x), i)]=0 and Ei‚àºœÄ[x][‚àáH(œÅ(x), i)] +
1{b=1}
2
I is Hurwitz.
While Assumption A3‚Ä≤ for case (iii) is much stronger than A3, it is not detrimental to the overall
results of our paper, since case (i) is of far greater interest as impressed upon in Section 1. This is
discussed further in Appendix C.
3
ASYMPTOTIC ANALYSIS OF THE SA-SRRW ALGORITHM
In this section, we provide the main results for the SA-SRRW algorithm (4). We first present the
a.s. convergence and the CLT result for SRRW with generalized step size, extending the results in
Doshi et al. (2023). Building upon this, we present the a.s. convergence and the CLT result for the
SA iterate Œ∏n under different settings of step sizes. We then shift our focus to the analysis of the
different asymptotic covariance matrices emerging out of the CLT result, and capture the effect of Œ±
and the step sizes, particularly in cases (i) and (iii), on Œ∏n ‚àíŒ∏‚àóvia performance ordering.
Almost Sure convergence and CLT: The following result establishes first and second order conver-
gence of the sequence {xn}n‚â•0, which represents the weighted empirical measures of the SRRW
process {Xn}n‚â•0, based on the update rule in (4b).
6

Published as a conference paper at ICLR 2024
Lemma 3.1. Under Assumptions A1, A2 and A4, for the SRRW iterates (4b), we have
xn
a.s.
‚àí‚àí‚àí‚àí‚Üí
n‚Üí‚àû¬µ,
and
Œ≥‚àí1/2
n
(xn ‚àí¬µ)
dist.
‚àí‚àí‚àí‚àí‚Üí
n‚Üí‚àûN(0, Vx(Œ±)),
where
Vx(Œ±) =
N‚àí1
X
i=1
1
2Œ±(1 + Œªi) + 2 ‚àí1{a=1}
¬∑ 1 + Œªi
1 ‚àíŒªi
uiuT
i .
(6)
Moreover, for all Œ±2 > Œ±1 > 0, we have Vx(Œ±2) <L Vx(Œ±1) <L Vx(0).
Lemma 3.1 shows that the SRRW iterates xn converges to the target distribution ¬µ a.s. even under
the general step size Œ≥n = (n+1)‚àía for a ‚àà(0.5, 1]. We also observe that the asymptotic covariance
matrix Vx(Œ±) decreases at rate O(1/Œ±). Lemma 3.1 aligns with Doshi et al. (2023, Theorem 4.2
and Corollary 4.3) for the special case of a = 1, and is therefore more general. Critically, it helps us
establish our next result regarding the first-order convergence for the optimization iterate sequence
{Œ∏n}n‚â•0 following update rule (4c), as well as its second-order convergence result, which follows
shortly after. The proofs of Lemma 3.1 and our next result, Theorem 3.2, are deferred to Appendix
D. In what follows, k = 1, 2, and 3 refer to cases (i), (ii), and (iii) in Section 2.2, respectively. All
subsequent results are proven under Assumptions A1 to A4, with A3‚Ä≤ replacing A3 only when the
step sizes Œ≤n, Œ≥n satisfy case (iii).
Theorem 3.2. For k ‚àà{1, 2, 3}, and any initial (Œ∏0, x0, X0) ‚ààRD√óInt(Œ£)√óN, we have Œ∏n ‚ÜíŒ∏‚àó
as n ‚Üí‚àûfor some Œ∏‚àó‚ààŒò, PŒ∏0,x0,X0-almost surely.
In the stochastic optimization context, the above result ensures convergence of iterates Œ∏n to a local
minimizer Œ∏‚àó. Loosely speaking, the first-order convergence of xn in Lemma 3.1 as well as that of
Œ∏n are closely related to the convergence of trajectories {z(t) ‚âú(Œ∏(t), x(t))}t‚â•0 of the (coupled)
mean-field ODE, written in a matrix-vector form as
d
dtz(t) = g(z(t)) ‚âú

H(Œ∏(t))T œÄ[x(t)]
œÄ[x(t)] ‚àíx(t)

‚ààRD+N.
(7)
where matrix H(Œ∏) ‚âú[H(Œ∏, 1),¬∑ ¬∑ ¬∑, H(Œ∏, N)]T ‚ààRN√óD for any Œ∏ ‚ààRD. Here, œÄ[x] ‚ààInt(Œ£)
is the stationary distribution of the SRRW kernel K[x] and is shown in Doshi et al. (2023) to be
given by œÄi[x] ‚àùP
j‚ààN ¬µiPij(xi/¬µi)‚àíŒ±(xj/¬µj)‚àíŒ±. The Jacobian matrix of (7) when evaluated at
equilibria z‚àó= (Œ∏‚àó, ¬µ) for Œ∏‚àó‚ààŒò captures the behaviour of solutions of the mean-field in their
vicinity, and plays an important role in the asymptotic covariance matrices arising out of our CLT
results. We evaluate this Jacobian matrix J(Œ±) as a function of Œ± ‚â•0 to be given by
J(Œ±)‚âú‚àág(z‚àó)=

‚àáh(Œ∏‚àó)
‚àíŒ±H(Œ∏‚àó)T (PT+ I)
0N√óD
2Œ±¬µ1T‚àíŒ±PT‚àí(Œ±+1)I

‚âú

J11
J12(Œ±)
J21
J22(Œ±)

.
(8)
The derivation of J(Œ±) is referred to Appendix E.1.8 Here, J21 is a zero matrix since œÄ[x] ‚àíx
is devoid of Œ∏. While matrix J22(Œ±) is exactly of the form in Doshi et al. (2023, Lemma 3.4)
to characterize the SRRW performance, our analysis includes an additional matrix J12(Œ±), which
captures the effect of x(t) on Œ∏(t) in the ODE (7), which translates to the influence of our generalized
SRRW empirical measure xn on the SA iterates Œ∏n in (4).
For notational simplicity, and without loss of generality, all our remaining results are stated while
conditioning on the event that {Œ∏n ‚ÜíŒ∏‚àó}, for some Œ∏‚àó‚ààŒò. We also adopt the shorthand notation
H to represent H(Œ∏‚àó). Our main CLT result is as follows, with its proof deferred to Appendix E.
Theorem 3.3. For any Œ± ‚â•0, we have: (a) There exists V(k)(Œ±) for all k ‚àà{1, 2, 3} such that
"
Œ≤‚àí1/2
n
(Œ∏n ‚àíŒ∏‚àó)
Œ≥‚àí1/2
n
(xn ‚àí¬µ)
#
dist.
‚àí‚àí‚àí‚àí‚Üí
n‚Üí‚àûN

0, V(k)(Œ±)

.
(b) For k = 2, matrix V(2)(Œ±) solves the Lyapunov equation J(Œ±)V(2)(Œ±) + V(2)(Œ±)J(Œ±)T +
1{b=1}V(2)(Œ±) = ‚àíU, where the Jacobian matrix J(Œ±) is in (8), and
U ‚âú
N‚àí1
X
i=1
1 + Œªi
1 ‚àíŒªi
¬∑

HT uiuT
i H
HT uiuT
i
uiuT
i H
uiuT
i

‚âú

U11
U12
U21
U22

.
(9)
(c) For k ‚àà{1, 3}, V(k)(Œ±) becomes block diagonal, which is given by
V(k)(Œ±) =

V(k)
Œ∏ (Œ±)
0D√óN
0N√óD
Vx(Œ±)

,
(10)
8The Jacobian J(Œ±) is (D+N)√ó(D+N)‚Äì dimensional, with J11 ‚ààRD√óD and J22(Œ±)‚ààRN√óN. Following
this, all matrices written in a block form, such as matrix U in (9), will inherit the same dimensional structure.
7

Published as a conference paper at ICLR 2024
where Vx(Œ±) is as in (6), and V(1)
Œ∏ (Œ±) and V(3)
Œ∏ (Œ±) can be written in the following explicit form:
V(1)
Œ∏ (Œ±) =
R ‚àû
0
et(‚àáŒ∏h(Œ∏‚àó)+
1{b=1}
2
I)UŒ∏(Œ±)et(‚àáŒ∏h(Œ∏‚àó)+
1{b=1}
2
I)T dt,
V(3)
Œ∏ (Œ±) =
R ‚àû
0
et‚àáŒ∏h(Œ∏‚àó)U11et‚àáŒ∏h(Œ∏‚àó)dt,
where UŒ∏(Œ±) =
N‚àí1
X
i=1
1
(Œ±(1 + Œªi) + 1)2 ¬∑ 1 + Œªi
1 ‚àíŒªi
HT uiuT
i H.
(11)
For k ‚àà{1, 3}, SA-SRRW in (4) is a two-timescale SA with controlled Markov noise. While a few
works study the CLT of two-timescale SA with the stochastic input being a martingale-difference
(i.i.d.) noise (Konda & Tsitsiklis, 2004; Mokkadem & Pelletier, 2006), a CLT result covering the
case of controlled Markov noise (e.g., k ‚àà{1, 3}), a far more general setting than martingale-
difference noise, is still an open problem. Thus, we here prove our CLT for k ‚àà{1, 3} from scratch
by a series of careful decompositions of the Markovian noise, ultimately into a martingale-difference
term and several non-vanishing noise terms through repeated application of the Poisson equation
(Benveniste et al., 2012; Fort, 2015). Although the form of the resulting asymptotic covariance
looks similar to that for the martingale-difference case in (Konda & Tsitsiklis, 2004; Mokkadem
& Pelletier, 2006) at first glance, they are not equivalent. Specifically, V(k)
Œ∏ (Œ±) captures both the
effect of SRRW hyper-parameter Œ±, as well as that of the underlying base Markov chain via eigen-
pairs (Œªi, ui) of its transition probability matrix P in matrix U, whereas the latter only covers the
martingale-difference noise terms as a special case.
When k = 2, that is, Œ≤n = Œ≥n, algorithm (4) can be regarded as a single-timescale SA algorithm.
In this case, we utilize the CLT in Fort (2015, Theorem 2.1) to obtain the implicit form of V(2)(Œ±)
as shown in Theorem 3.3. However, J12(Œ±) being non-zero for Œ± > 0 restricts us from obtaining
an explicit form for the covariance term corresponding to SA iterate errors Œ∏n ‚àíŒ∏‚àó. On the other
hand, for k ‚àà{1, 3}, the nature of two-timescale structure causes Œ∏n and xn to become asymptoti-
cally independent with zero correlation terms inside V(k)(Œ±) in (10), and we can explicitly deduce
V(k)
Œ∏ (Œ±). We now take a deeper dive into Œ± and study its effect on V(k)
Œ∏ (Œ±).
Covariance Ordering of SA-SRRW: We refer the reader to Appendix F for proofs of all remaining
results. We begin by focusing on case (i) and capturing the impact of Œ± on V(1)
Œ∏ (Œ±).
Proposition 3.4. For all Œ±2 > Œ±1 > 0, we have V(1)
Œ∏ (Œ±2) <L V(1)
Œ∏ (Œ±1) <L V(1)
Œ∏ (0). Furthermore,
V(1)
Œ∏ (Œ±) decreases to zero at a rate of O(1/Œ±2).
Proposition 3.4 proves a monotonic reduction (in terms of Loewner ordering) of V(1)
Œ∏ (Œ±) as Œ± in-
creases. Moreover, the decrease rate O(1/Œ±2) surpasses the O(1/Œ±) rate seen in Vx(Œ±) and the
sampling application in Doshi et al. (2023, Corollary 4.7), and is also empirically observed in our
simulation in Section 4.9 Suppose we consider the same SA now driven by an i.i.d. sequence {Xn}
with the same marginal distribution ¬µ. Then, our Proposition 3.4 asserts that a token algorithm em-
ploying SRRW (walk on a graph) with large enough Œ± on a general graph can actually produce better
SA iterates with its asymptotic covariance going down to zero, than a ‚Äòhypothetical situation‚Äô where
the walker is able to access any node j with probability ¬µj from anywhere in one step (more like a
random jumper). This can be seen by noting that for large time n, the scaled MSE E[‚à•Œ∏n‚àíŒ∏‚àó‚à•2]/Œ≤n
is composed of the diagonal entries of the covariance matrix VŒ∏, which, as we discuss in detail in
Appendix F.2, are decreasing in Œ± as a consequence of the Loewner ordering in Proposition 3.4. For
large enough Œ±, the scaled MSE for SA-SRRW becomes smaller than its i.i.d. counterpart, which is
always a constant. Although Doshi et al. (2023) alluded this for sampling applications with Vx(Œ±),
we broaden its horizons to distributed optimization problem with VŒ∏(Œ±) using tokens on graphs.
Our subsequent result concerns the performance comparison between cases (i) and (iii).
Corollary 3.5. For any Œ± > 0, we have V(1)
Œ∏ (Œ±) <L V(3)
Œ∏ (Œ±) = V(3)
Œ∏ (0).
We show that case (i) is asymptotically better than case (iii) for Œ± > 0. In view of Proposition 3.4
and Corollary 3.5, the advantages of case (i) become prominent.
9Further insights of O(1/Œ±2) are tied to the two-timescale structure, particularly Œ≤n = o(Œ≥n) in case (i),
which places Œ∏n on the slow timescale so that the correlation terms J12(Œ±), J22(Œ±) in the Jacobian matrix
J(Œ±) in (8) come into play. Technical details are referred to Appendix E.2, where we show the form of UŒ∏(Œ±).
8

Published as a conference paper at ICLR 2024
102
103
104
105
106
Number of steps (n)
10
3
10
2
10
1
100
MSE 
n
*
2
CASE (i): a = 0.8, b = 0.9
MHRW (
= 0)
= 1
= 5
= 10
= 20
i.i.d. sampling
(a) SGD-SRRW.
102
103
104
105
106
Number of steps (n)
10
3
10
2
10
1
100
MSE 
n
*
2
CASE (i): a = 0.8, b = 0.9
MHRW (
= 0)
= 1
= 5
= 10
= 20
i.i.d. sampling
(b) SHB-SRRW.
0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0
value of 
0.0005
0.0010
0.0015
0.0020
0.0025
0.0030
0.0035
MSE 
n
*
2 at n = 107
(
MSE points 
Fitted curve 
g( ) = 
       
0.0078
+ 1.588)2 + 0.0003
(c) Curve fitting for MSE.
Figure 2: Simulation results under case (i): (a) and (b) show the performance of SGD-SRRW and
SHB-SRRW for various Œ± values. (c) shows that MSE decreases at O(1/Œ±2) speed.
102
103
104
105
106
Number of steps (n)
10
2
10
1
MSE 
n
*
2
CASE (i):a = 0.8, b = 0.9
CASE (ii):a = 0.9, b = 0.9
CASE (iii):a = 1, b = 0.9
(a) Œ± = 1, SGD-SRRW
102
103
104
105
106
Number of steps (n)
10
2
10
1
MSE 
n
*
2
CASE (i):a = 0.8, b = 0.9
CASE (ii):a = 0.9, b = 0.9
CASE (iii):a = 1, b = 0.9
(b) Œ± = 5, SGD-SRRW
102
103
104
105
106
Number of steps (n)
10
2
10
1
MSE 
n
*
2
CASE (i):a = 0.8, b = 0.9
CASE (ii):a = 0.9, b = 0.9
CASE (iii):a = 1, b = 0.9
(c) Œ± = 10, SGD-SRRW
Figure 3: Comparison of the performance among cases (i) - (iii) for Œ± ‚àà{1, 5, 10}.
4
SIMULATION
In this section, we simulate our SA-SRRW algorithm on the wikiVote graph (Leskovec & Krevl,
2014), comprising 889 nodes and 2914 edges. We configure the SRRW‚Äôs base Markov chain P as
the MHRW with a uniform target distribution ¬µ =
1
N 1. For distributed optimization, we consider
the following L2 regularized binary classification problem:
minŒ∏‚ààRD
n
f(Œ∏) ‚âú1
N
PN
i=1 log

1 + eŒ∏T si

‚àíyi
 Œ∏T si

+ Œ∫
2 ‚à•Œ∏‚à•2o
,
(12)
where {(si, yi)}N
i=1 is the ijcnn1 dataset (with 22 features, i.e., si ‚ààR22) from LIBSVM (Chang
& Lin, 2011), and penalty parameter Œ∫ = 1. Each node in the wikiVote graph is assigned one
data point, thus 889 data points in total. We perform SRRW driven SGD (SGD-SRRW) and SRRW
driven stochastic heavy ball (SHB-SRRW) algorithms (see (13) in Appendix A for its algorithm).
We fix the step size Œ≤n = (n + 1)‚àí0.9 for the SA iterates and adjust Œ≥n = (n + 1)‚àía in the SRRW
iterates to cover all three cases discussed in this paper: (i) a = 0.8; (ii) a = 0.9; (iii) a = 1. We use
mean square error (MSE), i.e., E[‚à•Œ∏n‚àíŒ∏‚àó‚à•2], to measure the error on the SA iterates.
Our results are presented in Figures 2 and 3, where each experiment is repeated 100 times. Figures
2a and 2b, based on wikiVote graph, highlight the consistent performance ordering across different
Œ± values for both algorithms over almost all time (not just asymptotically). Notably, curves for
Œ± ‚â•5 outperform that of the i.i.d. sampling (in black) even under the graph constraints. Figure 2c
on the smaller Dolphins graph (Rossi & Ahmed, 2015) - 62 nodes and 159 edges - illustrates that
the points of (Œ±, MSE) pair arising from SGD-SRRW at time n = 107 align with a curve in the form
of g(x)=
c1
(x+c2)2 +c3 to showcase O(1/Œ±2) rates. This smaller graph allows for longer simulations
to observe the asymptotic behaviour. Additionally, among the three cases examined at identical Œ±
values, Figures 3a - 3c confirm that case (i) performs consistently better than the rest, underscoring
its superiority in practice. Further results, including those from non-convex functions and additional
datasets, are deferred to Appendix H due to space constraints.
5
CONCLUSION
In this paper, we show both theoretically and empirically that the SRRW as a drop-in replacement
for Markov chains can provide significant performance improvements when used for token algo-
rithms, where the acceleration comes purely from the careful analysis of the stochastic input of the
algorithm, without changing the optimization iteration itself. Our paper is an instance where the
asymptotic analysis approach allows the design of better algorithms despite the usage of uncon-
ventional noise sequences such as nonlinear Markov chains like the SRRW, for which traditional
finite-time analytical approaches fall short, thus advocating their wider adoption.
9

Published as a conference paper at ICLR 2024
6
ACKNOWLEDGMENTS AND DISCLOSURE OF FUNDING
We thank the anonymous reviewers for their constructive comments, especially Reviewer DxLx for
raising future directions. This work was supported in part by National Science Foundation under
Grant Nos. CNS-2007423 and IIS-1910749.
REFERENCES
David Aldous and James Allen Fill. Reversible markov chains and random walks on graphs, 2002.
Unfinished monograph, recompiled 2014, available at http://www.stat.berkeley.
edu/Àúaldous/RWG/book.html.
Christophe Andrieu, Ajay Jasra, Arnaud Doucet, and Pierre Del Moral. Non-linear markov chain
monte carlo. In Esaim: Proceedings, volume 19, pp. 79‚Äì84. EDP Sciences, 2007.
Ghadir Ayache and Salim El Rouayheb. Private weighted random walk stochastic gradient descent.
IEEE Journal on Selected Areas in Information Theory, 2(1):452‚Äì463, 2021.
Anas Barakat and Pascal Bianchi. Convergence and dynamical behavior of the adam algorithm for
nonconvex stochastic optimization. SIAM Journal on Optimization, 31(1):244‚Äì274, 2021.
Anas Barakat, Pascal Bianchi, Walid Hachem, and Sholom Schechtman. Stochastic optimization
with momentum: convergence, fluctuations, and traps avoidance. Electronic Journal of Statistics,
15(2):3892‚Äì3947, 2021.
M Benaim and Bertrand Cloez. A stochastic approximation approach to quasi-stationary distribu-
tions on finite spaces. Electronic Communications in Probability 37 (20), 1-14.(2015), 2015.
Albert Benveniste, Michel M¬¥etivier, and Pierre Priouret. Adaptive algorithms and stochastic ap-
proximations, volume 22. Springer Science & Business Media, 2012.
V.S. Borkar. Stochastic Approximation: A Dynamical Systems Viewpoint: Second Edition. Texts
and Readings in Mathematics. Hindustan Book Agency, 2022. ISBN 9788195196111.
L¬¥eon Bottou, Frank E Curtis, and Jorge Nocedal. Optimization methods for large-scale machine
learning. SIAM review, 60(2):223‚Äì311, 2018.
Stephen Boyd, Arpita Ghosh, Balaji Prabhakar, and Devavrat Shah. Randomized gossip algorithms.
IEEE transactions on information theory, 52(6):2508‚Äì2530, 2006.
Pierre Br¬¥emaud. Markov chains: Gibbs fields, Monte Carlo simulation, and queues, volume 31.
Springer Science & Business Media, 2013.
Chih-Chung Chang and Chih-Jen Lin. Libsvm: a library for support vector machines. ACM trans-
actions on intelligent systems and technology (TIST), 2(3):1‚Äì27, 2011.
VijaySekhar Chellaboina and Wassim M Haddad. Nonlinear dynamical systems and control: A
Lyapunov-based approach. Princeton University Press, 2008.
Vishnu Pandi Chellapandi, Antesh Upadhyay, Abolfazl Hashemi, and Stanislaw H Zak. On the con-
vergence of decentralized federated learning under imperfect information sharing. arXiv preprint
arXiv:2303.10695, 2023.
Han-Fu Chen.
Stochastic approximation and its applications, volume 64.
Springer Science &
Business Media, 2006.
Shuhang Chen, Adithya Devraj, Ana Busic, and Sean Meyn. Explicit mean-square error bounds
for monte-carlo and linear stochastic approximation. In International Conference on Artificial
Intelligence and Statistics, pp. 4173‚Äì4183. PMLR, 2020a.
Zaiwei Chen, Siva Theja Maguluri, Sanjay Shakkottai, and Karthikeyan Shanmugam.
Finite-
sample analysis of stochastic approximation using smooth convex envelopes.
arXiv preprint
arXiv:2002.00874, 2020b.
10

Published as a conference paper at ICLR 2024
Zaiwei Chen, Sheng Zhang, Thinh T Doan, John-Paul Clarke, and Siva Theja Maguluri. Finite-
sample analysis of nonlinear stochastic approximation with applications in reinforcement learn-
ing. Automatica, 146:110623, 2022.
Burgess Davis. On the intergrability of the martingale square function. Israel Journal of Mathemat-
ics, 8:187‚Äì190, 1970.
Aaron Defazio, Francis Bach, and Simon Lacoste-Julien. Saga: a fast incremental gradient method
with support for non-strongly convex composite objectives. In Advances in neural information
processing systems, volume 1, 2014.
Pierre Del Moral and Arnaud Doucet. Interacting markov chain monte carlo methods for solving
nonlinear measure-valued equations1. The Annals of Applied Probability, 20(2):593‚Äì639, 2010.
Pierre Del Moral and Laurent Miclo.
Self-interacting markov chains.
Stochastic Analysis and
Applications, 24(3):615‚Äì660, 2006.
Bernard Delyon. Stochastic approximation with decreasing gain: Convergence and asymptotic the-
ory. Technical report, Universit¬¥e de Rennes, 2000.
Bernard Delyon, Marc Lavielle, and Eric Moulines. Convergence of a stochastic approximation
version of the em algorithm. Annals of statistics, pp. 94‚Äì128, 1999.
Adithya M Devraj and Sean P Meyn. Zap q-learning. In Proceedings of the 31st International
Conference on Neural Information Processing Systems, pp. 2232‚Äì2241, 2017.
Adithya M. Devraj and Sean P. Meyn. Q-learning with uniformly bounded variance. IEEE Trans-
actions on Automatic Control, 2021.
Thinh Doan, Siva Maguluri, and Justin Romberg. Finite-time analysis of distributed td (0) with linear
function approximation on multi-agent reinforcement learning. In International Conference on
Machine Learning, pp. 1626‚Äì1635. PMLR, 2019.
Thinh T Doan. Finite-time convergence rates of nonlinear two-time-scale stochastic approximation
under markovian noise. arXiv preprint arXiv:2104.01627, 2021.
Thinh T Doan, Lam M Nguyen, Nhan H Pham, and Justin Romberg. Convergence rates of ac-
celerated markov gradient descent with applications in reinforcement learning. arXiv preprint
arXiv:2002.02873, 2020.
Vishwaraj Doshi, Jie Hu, and Do Young Eun. Self-repellent random walks on general graphs‚Äì
achieving minimal sampling variance via nonlinear markov chains. In International Conference
on Machine Learning. PMLR, 2023.
Marie Duflo. Algorithmes stochastiques, volume 23. Springer, 1996.
Mathieu Even. Stochastic gradient descent under markovian sampling schemes. In International
Conference on Machine Learning, 2023.
Gersende Fort. Central limit theorems for stochastic approximation with controlled markov chain
dynamics. ESAIM: Probability and Statistics, 19:60‚Äì80, 2015.
S¬¥ebastien Gadat, Fabien Panloup, and Sofiane Saadane. Stochastic heavy ball. Electronic Journal
of Statistics, 12:461‚Äì529, 2018.
Xin Guo, Jiequn Han, Mahan Tajrobehkar, and Wenpin Tang. Escaping saddle points efficiently
with occupation-time-adapted perturbations. arXiv preprint arXiv:2005.04507, 2020.
P. Hall, C.C. Heyde, Z.W. Birnbauam, and E. Lukacs. Martingale Limit Theory and Its Application.
Communication and Behavior. Elsevier Science, 2014.
Hadrien Hendrikx. A principled framework for the design and analysis of token algorithms. In
International Conference on Artificial Intelligence and Statistics, pp. 470‚Äì489. PMLR, 2023.
11

Published as a conference paper at ICLR 2024
Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. A two-timescale stochastic algorithm
framework for bilevel optimization: Complexity analysis and application to actor-critic. SIAM
Journal on Optimization, 33(1):147‚Äì180, 2023.
Jie Hu, Vishwaraj Doshi, and Do Young Eun. Efficiency ordering of stochastic gradient descent. In
Advances in Neural Information Processing Systems, 2022.
Chi Jin, Rong Ge, Praneeth Netrapalli, Sham M Kakade, and Michael I Jordan. How to escape saddle
points efficiently. In International conference on machine learning, pp. 1724‚Äì1732. PMLR, 2017.
Chi Jin, Praneeth Netrapalli, and Michael I Jordan. Accelerated gradient descent escapes saddle
points faster than gradient descent. In Conference On Learning Theory, pp. 1042‚Äì1085. PMLR,
2018.
Chi Jin, Praneeth Netrapalli, Rong Ge, Sham M Kakade, and Michael I Jordan. On nonconvex
optimization for machine learning: Gradients, stochasticity, and saddle points. Journal of the
ACM (JACM), 68(2):1‚Äì29, 2021.
Belhal Karimi, Blazej Miasojedow, Eric Moulines, and Hoi-To Wai. Non-asymptotic analysis of
biased stochastic approximation scheme. In Conference on Learning Theory, pp. 1944‚Äì1974.
PMLR, 2019.
Prasenjit Karmakar and Shalabh Bhatnagar. Two time-scale stochastic approximation with con-
trolled markov noise and off-policy temporal-difference learning. Mathematics of Operations
Research, 43(1):130‚Äì151, 2018.
Ahmed Khaled and Peter Richt¬¥arik. Better theory for SGD in the nonconvex world. Transactions
on Machine Learning Research, 2023. ISSN 2835-8856.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.
Vijay R Konda and John N Tsitsiklis. Convergence rate of linear two-time-scale stochastic approxi-
mation. The Annals of Applied Probability, 14(2):796‚Äì819, 2004.
Harold Kushner and G George Yin. Stochastic approximation and recursive algorithms and appli-
cations, volume 35. Springer Science & Business Media, 2003.
Anusha Lalitha, Shubhanshu Shekhar, Tara Javidi, and Farinaz Koushanfar. Fully decentralized
federated learning. In Advances in neural information processing systems, 2018.
Jure Leskovec and Andrej Krevl. Snap datasets: Stanford large network dataset collection, 2014.
David A Levin and Yuval Peres. Markov chains and mixing times, volume 107. American Mathe-
matical Soc., 2017.
Qiang Li and Hoi-To Wai. State dependent performative prediction with stochastic approximation.
In International Conference on Artificial Intelligence and Statistics, pp. 3164‚Äì3186. PMLR, 2022.
Tiejun Li, Tiannan Xiao, and Guoguo Yang. Revisiting the central limit theorems for the sgd-type
methods. arXiv preprint arXiv:2207.11755, 2022.
Xiang Li, Jiadong Liang, and Zhihua Zhang. Online statistical inference for nonlinear stochastic
approximation with markovian data. arXiv preprint arXiv:2302.07690, 2023.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial intelli-
gence and statistics, pp. 1273‚Äì1282. PMLR, 2017.
Sean Meyn. Control systems and reinforcement learning. Cambridge University Press, 2022.
Abdelkader Mokkadem and Mariane Pelletier. The compact law of the iterated logarithm for mul-
tivariate stochastic approximation algorithms. Stochastic analysis and applications, 23(1):181‚Äì
203, 2005.
12

Published as a conference paper at ICLR 2024
Abdelkader Mokkadem and Mariane Pelletier. Convergence rate and averaging of nonlinear two-
time-scale stochastic approximation algorithms. Annals of Applied Probability, 16(3):1671‚Äì1702,
2006.
Gemma Morral, Pascal Bianchi, and Gersende Fort. Success and failure of adaptation-diffusion
algorithms with decaying step size in multiagent networks. IEEE Transactions on Signal Pro-
cessing, 65(11):2798‚Äì2813, 2017.
Wenlong Mou, Chris Junchi Li, Martin J Wainwright, Peter L Bartlett, and Michael I Jordan. On
linear stochastic approximation: Fine-grained polyak-ruppert and non-asymptotic concentration.
In Conference on Learning Theory, pp. 2947‚Äì2997. PMLR, 2020.
Angelia Nedic. Distributed gradient methods for convex machine learning problems in networks:
Distributed optimization. IEEE Signal Processing Magazine, 37(3):92‚Äì101, 2020.
Alex Olshevsky.
Asymptotic network independence and step-size for a distributed subgradient
method. Journal of Machine Learning Research, 23(69):1‚Äì32, 2022.
Mariane Pelletier. On the almost sure asymptotic behaviour of stochastic algorithms. Stochastic
processes and their applications, 78(2):217‚Äì244, 1998.
Sashank J. Reddi, Satyen Kale, and Sanjiv Kumar. On the convergence of adam and beyond. In
International Conference on Learning Representations, 2018.
Ryan A. Rossi and Nesreen K. Ahmed. The network data repository with interactive graph analytics
and visualization. In AAAI, 2015.
Mark Schmidt, Nicolas Le Roux, and Francis Bach. Minimizing finite sums with the stochastic
average gradient. Mathematical Programming, 162:83‚Äì112, 2017.
Tao Sun, Yuejiao Sun, and Wotao Yin. On markov chain gradient descent. In Advances in neural
information processing systems, volume 31, 2018.
Aleksei Triastcyn, Matthias Reisser, and Christos Louizos. Decentralized learning with random
walks and communication-efficient adaptive optimization. In Workshop on Federated Learning:
Recent Advances and New Challenges (in Conjunction with NeurIPS 2022), 2022.
Thijs Vogels, Lie He, Anastasiia Koloskova, Sai Praneeth Karimireddy, Tao Lin, Sebastian U Stich,
and Martin Jaggi. Relaysum for decentralized deep learning on heterogeneous data. In Advances
in Neural Information Processing Systems, volume 34, pp. 28004‚Äì28015, 2021.
Jianyu Wang, Anit Kumar Sahu, Zhouyi Yang, Gauri Joshi, and Soummya Kar. Matcha: Speed-
ing up decentralized sgd via matching decomposition sampling. In 2019 Sixth Indian Control
Conference (ICC), pp. 299‚Äì300. IEEE, 2019.
Vinayaka G Yaji and Shalabh Bhatnagar. Stochastic recursive inclusions in two timescales with
nonadditive iterate-dependent markov noise. Mathematics of Operations Research, 45(4):1405‚Äì
1444, 2020.
Hao Ye, Le Liang, and Geoffrey Ye Li. Decentralized federated learning with unreliable communi-
cations. IEEE Journal of Selected Topics in Signal Processing, 16(3):487‚Äì500, 2022.
Sihan Zeng, Thinh T Doan, and Justin Romberg. A two-time-scale stochastic optimization frame-
work with applications in control and reinforcement learning. arXiv preprint arXiv:2109.14756,
2021.
13

Published as a conference paper at ICLR 2024
A
EXAMPLES OF STOCHASTIC ALGORITHMS OF THE FORM (2).
In the literature of stochastic optimizations, many SGD variants have been proposed by introducing
an auxiliary variable to improve convergence. In what follows, we present two SGD variants with
decreasing step size that can be presented in the form of (2): SHB (Gadat et al., 2018; Li et al., 2022)
and momentum-based algorithm (Barakat et al., 2021; Barakat & Bianchi, 2021).
Œ∏n+1 =Œ∏n‚àíŒ≤n+1mn
mn+1 =mn+Œ≤n+1(‚àáF(Œ∏n, Xn+1)‚àímn),
Ô£±
Ô£≤
Ô£≥
vn+1 =vn+Œ≤n+1(‚àáF(Œ∏n, Xn+1)2‚àívn),
mn+1 =mn+Œ≤n+1(‚àáF(Œ∏n, Xn+1)‚àímn),
Œ∏n+1 =Œ∏n‚àíŒ≤n+1mn/‚àövn + œµ,
(a). SHB
(b). Momentum-based Algorithm
(13)
where œµ > 0, Œ∏n, mn, vn, ‚àáF(Œ∏, X) ‚ààRd, and the square and square root in (13) (b) are element-
wise operators.10
For SHB, we introduce an augmented variable zn and function H(zn, Xn+1) defined as follows:
zn ‚âú

Œ∏n
mn

‚ààR2d,
H(zn, Xn+1) ‚âú

‚àímn
‚àáF(Œ∏n, Xn+1) ‚àímn

‚ààR2d.
For the general momentum-based algorithm, we define
zn ‚âú
" vn
mn
Œ∏n
#
‚ààR3d,
H(zn, X) ‚âú
Ô£Æ
Ô£∞
‚àáF(Œ∏n, Xn+1)2 ‚àívn
‚àáF(Œ∏n, Xn+1) ‚àímn
‚àímn/‚àövn + œµ
Ô£π
Ô£ª‚ààR3d.
Thus, we can reformulate both algorithms in (13) as zn+1 = zn + Œ≤n+1H(zn, Xn+1). This aug-
mentation approach was previously adopted in (Gadat et al., 2018; Barakat et al., 2021; Barakat &
Bianchi, 2021; Li et al., 2022) to analyze the asymptotic performance of algorithms in (13) using an
i.i.d. sequence {Xn}n‚â•0. Consequently, the general SA iteration (2) includes these SGD variants.
However, we mainly focus on the CLT for the general SA driven by SRRW in this paper. Pursuing
the explicit CLT results of these SGD variants with specific form of function H(Œ∏, X) driven by the
SRRW sequence {Xn} is out of the scope of this paper.
When we numerically test the SHB algorithm in Section 4, we use the exact form of (13) (a) and
the stochastic sequence {Xn} is now driven by the SRRW. Specifically, we consider MHRW with
transition kernel P as the base Markov chain of the SRRW process, e.g.,
Pij =
(
min
n
1
di , 1
dj
o
if node j is the neighbor of node i,
0
otherwise,
Pii = 1 ‚àí
X
j‚ààN
Pij.
Then, at each time step n,
Draw:
Xn+1 ‚àºKXn,¬∑[xn],
where
Kij[x] ‚âú
Pij(xj/¬µj)‚àíŒ±
P
k‚ààN Pik(xk/¬µk)‚àíŒ± ,
‚àÄi, j ‚ààN,
Update:
xn+1 = xn + Œ≥n+1(Œ¥Xn+1 ‚àíxn),
Œ∏n+1 = Œ∏n ‚àíŒ≤n+1mn,
mn+1 = mn + Œ≤n+1(‚àáF(Œ∏n, Xn+1) ‚àímn).
10For ease of expression, we simplify the original SHB and momentum-based algorithms from Gadat et al.
(2018); Li et al. (2022); Barakat et al. (2021); Barakat & Bianchi (2021), setting all tunable parameters to 1 and
resulting in (13).
14

Published as a conference paper at ICLR 2024
B
DISCUSSION ON MEAN FIELD FUNCTION OF SRRW ITERATES (4b)
Non-asymptotic analyses have seen extensive attention recently in both single-timescale SA litera-
ture (Sun et al., 2018; Karimi et al., 2019; Chen et al., 2020b; 2022) and two-timescale SA literature
(Doan, 2021; Zeng et al., 2021). Specifically, single-timescale SA has the following form:
xn+1 = xn + Œ≤n+1H(xn, Xn+1),
and function h(x) ‚âúEX‚àº¬µ[H(x, X)] is the mean field of function H(x, X). Similarly, for two-
timescale SA, we have the following recursions:
xn+1 = xn + Œ≤n+1H1(xn, yn, Xn+1),
yn+1 = yn + Œ≥n+1H2(xn, yn, Xn+1),
where {Œ≤n} and {Œ≥n} are on different timescales, and function hi(x, y) ‚âúEX‚àº¬µ[Hi(x, y, X)] is
the mean field of function Hi(x, y, X) for i = {1, 2}. All the aforementioned works require the
mean field function h(x) in the single-timescale SA (or h1(x, y), h2(x, y) in the two-timescale SA)
to be globally Lipschitz with a Lipschitz constant L to proceed with the derivation of finite-time
bounds including the constant L.
Here, we show that the mean field function œÄ[x] ‚àíx in the SRRW iterates (4b) is not globally
Lipschitz, where œÄ[x] is the stationary distribution of the SRRW kernel K[x] defined in (3). To this
end, we show that each entry of Jacobian matrix of œÄ[x]‚àíx goes unbounded because a multivariate
function is Lipschitz if and only if it has bounded partial derivatives. Note that from Doshi et al.
(2023, Proposition 2.1), for the i-th entry of œÄ[x], we have
œÄi[x] =
P
j‚ààN ¬µiPij (xi/¬µi)‚àíŒ± (xj/¬µj)‚àíŒ±
P
i‚ààN
P
j‚ààN ¬µiPij (xi/¬µi)‚àíŒ± (xj/¬µj)‚àíŒ± .
(16)
Then, the Jacobian matrix of the mean field function œÄ[x] ‚àíx , which has been derived in Doshi
et al. (2023, Proof of Lemma 3.4 in Appendix B), is given as follows:
‚àÇ(œÄi[x] ‚àíxi)
‚àÇxj
= 2Œ±
xj
¬∑ (P
k‚ààN ¬µiPik (xi/¬µi)‚àíŒ± (xk/¬µk)‚àíŒ±)(P
k‚ààN ¬µjPjk (xj/¬µj)‚àíŒ± (xk/¬µk)‚àíŒ±)
(P
l‚ààN
P
k‚ààN ¬µlPlk (xl/¬µl)‚àíŒ± (xk/¬µk)‚àíŒ±)2
‚àíŒ±
xj
¬∑
¬µiPij (xi/¬µi)‚àíŒ± (xj/¬µj)‚àíŒ±
P
l‚ààN
P
k‚ààN ¬µlPlk (xl/¬µl)‚àíŒ± (xk/¬µk)‚àíŒ±
(17)
for i, j ‚ààN, i Ã∏= j, and
‚àÇ(œÄi[x] ‚àíxi)
‚àÇxi
= 2Œ±
xi
¬∑
(P
k‚ààN ¬µiPik (xi/¬µi)‚àíŒ± (xk/¬µk)‚àíŒ±)2
(P
l‚ààN
P
k‚ààN ¬µlPlk (xl/¬µl)‚àíŒ± (xk/¬µk)‚àíŒ±)2
‚àíŒ±
xi
¬∑
P
k‚ààN ¬µiPik (xi/¬µi)‚àíŒ± (xk/¬µk)‚àíŒ± + ¬µiPii(xi/¬µi)‚àí2Œ±
P
l‚ààN
P
k‚ààN ¬µlPlk (xl/¬µl)‚àíŒ± (xk/¬µk)‚àíŒ±
‚àí1
(18)
for i ‚ààN. Since the empirical distribution x ‚ààInt(Œ£), we have xi ‚àà(0, 1) for all i ‚ààN. For
fixed i, assume xi = xj and as they approach zero, the terms (xi/¬µi)‚àíŒ±, (xj/¬µj)‚àíŒ± dominate the
fraction in (17) and both the numerator and the denominator of the fraction have the same order in
terms of xi, xj. Thus, we have
‚àÇ(œÄi[x] ‚àíxi)
‚àÇxj
= O
 1
xj

such that the (i, j)-th entry of the Jacobian matrix can go unbounded as xj ‚Üí0. Consequently,
œÄ[x] ‚àíx is not globally Lipschitz for x ‚ààInt(Œ£).
15

Published as a conference paper at ICLR 2024
C
DISCUSSION ON ASSUMPTION A3‚Ä≤
When Œ≥n = o(Œ≤n), iterates xn has smaller step size compared to Œ∏n, thus converges ‚Äòslower‚Äô than
Œ∏n. From Assumption A3‚Ä≤, Œ∏n will intuitively converge to some point œÅ(x) with the current value
x from the iteration xn, i.e., EX‚àºœÄ[x][H(œÅ(x), X)] = 0, while the Hurwitz condition is to ensure
the stability around œÅ(x). We can see that Assumption A3 is less stringent than A3‚Ä≤ in that it only
assumes such condition when x = ¬µ such that œÅ(¬µ) = Œ∏‚àórather than for all x ‚ààInt(Œ£).
One special instance of Assumption A3‚Ä≤ is by assuming the linear SA, e.g., H(Œ∏, i) = AiŒ∏ + bi. In
this case, EX‚àºœÄ[x][H(œÅ(x), X)] = 0 is equivalent to Ei‚àºœÄ[x][Ai]œÅ(x)+Ei‚àºœÄ[x][bi] = 0. Under the
condition that for every x ‚ààInt(Œ£), matrix Ei‚àºœÄ[x][Ai] is invertible, we then have
œÅ(x) = ‚àí(Ei‚àºœÄ[x][Ai])‚àí1 ¬∑ Ei‚àºœÄ[x][bi].
However, this condition is quite strict. Loosely speaking, Ei‚àºœÄ[x][Ai] being invertible for any x
is similar to saying that any convex combination of {Ai} is invertible. For example, if we assume
{Ai}i‚ààN are negative definite and they all share the same eigenbasis {ui}, e.g., Ai = PD
j=1 Œªi
juiuT
i
and Œªi
j < 0 for all i ‚ààN, j ‚àà[D]. Then, Ei‚àºœÄ[x][Ai] is invertible.
Another example for Assumption A3‚Ä≤ is when H(Œ∏, i) = H(Œ∏, j) for all i, j ‚ààN, which implies
that each agent in the distributed learning has the same local dataset to collaboratively train the
model. In this example, œÅ(x) = Œ∏‚àósuch that
Ei‚àºœÄ[x][H(œÅ(x), i)] = h(Œ∏‚àó) = 0,
Ei‚àºœÄ[x][‚àáH(œÅ(x), i)] + 1{b=1}
2
I = ‚àáh(Œ∏‚àó) + 1{b=1}
2
I
being Hurwitz.
D
PROOF OF LEMMA 3.1 AND LEMMA 3.2
In this section, we demonstrate the almost sure convergence of both Œ∏n and xn together. This proof
naturally incorporates the almost certain convergence of the SRRW iteration in Lemma 3.1, since
xn is independent of Œ∏n (as indicated in (4)), allowing us to separate out its asymptotic results. The
same reason applies to the CLT analysis of SRRW iterates and we refer the reader to Section E.1 for
the CLT result of xn in Lemma 3.1.
We will use different techniques for different settings of step sizes in Assumption A2. Specifically,
for step sizes Œ≥n = (n + 1)‚àía, Œ≤n = (n + 1)‚àíb, we consider the following scenarios:
Scenario 1: We consider case(ii): 1/2 < a = b ‚â§1, and will apply the almost sure convergence
result of the single-timescale stochastic approximation in Theorem G.8 and verify all the
conditions therein.
Scenario 2: We consider both case(i): 1/2 < a < b ‚â§1 and case (iii): 1/2 < b < a ‚â§1. In these
two cases, step sizes Œ≥n, Œ≤n decrease at different rates, thereby putting iterates xn, Œ∏n on
different timescales and resulting in a two-timescale structure. We will apply the existing
almost sure convergence result of the two-timescale stochastic approximation with iterate-
dependent Markov chain in Yaji & Bhatnagar (2020, Theorem 4) where our SA-SRRW
algorithm can be regarded as a special instance.11
D.1
SCENARIO 1
In Scenario 1, we have Œ≤n = Œ≥n. First, we rewrite (4) as

Œ∏n+1
xn+1

=

Œ∏n
xn

+ Œ≥n+1

H(Œ∏n.Xn+1)
Œ¥Xn+1 ‚àíxn

.
(19)
11However, Yaji & Bhatnagar (2020) paper only analysed the almost sure convergence. The central limit
theorem analysis remains unknown in the literature for the two-timescale stochastic approximation with iterate-
dependent Markov chains. Thus, our CLT analysis in Section E for this two-timescale structure with iterate-
dependent Markov chain is still novel and recognized as our contribution.
16

Published as a conference paper at ICLR 2024
By augmentations, we define the variable zn ‚âú

Œ∏n
xn

‚ààR(N+D)√ó1 and the function G(zn, i) ‚âú

H(Œ∏n, i)
Œ¥i ‚àíxn

‚ààR(N+d)√ó1. In addition, we define a new Markov chain {Yn}n‚â•0 in the same state
space N as SRRW sequence {Xn}n‚â•0. With slight abuse of notation, the transition kernel of {Yn}
is denoted by K‚Ä≤[zn] ‚â°K[xn] and its stationary distribution œÄ‚Ä≤[zn] ‚â°œÄ[xn], where K[xn] and
œÄ(xn) are the transition kernel and its corresponding stationary distribution of SRRW, with œÄ[x] of
the form
œÄi[x] ‚àù
X
j‚ààN
¬µiPij(xi/¬µi)‚àíŒ±(xj/¬µj)‚àíŒ±.
(20)
Recall that ¬µ is the fixed point, i.e., œÄ[¬µ] = ¬µ, and P is the base Markov chain inside SRRW (see
(3)). Then, the mean field
g(z) = EY ‚àºœÄ‚Ä≤(z)[G(z, Y )] =
P
i‚ààN œÄi[x]H(Œ∏, i)
œÄ[x] ‚àíx

,
and z‚àó= (Œ∏‚àó, ¬µ) for Œ∏‚àó‚ààŒò in Assumption A3 is the root of g(z), i.e., g(z‚àó) = 0. The augmented
iteration (19) becomes
zn+1 = zn + Œ≥n+1G(zn, Yn+1)
(21)
with the goal of solving g(z) = 0. Therefore, we can treat (21) as an SA algorithm driven by
a Markov chain {Yn}n‚â•0 with its kernel K‚Ä≤[z] and stationary distribution œÄ‚Ä≤[z], which has been
widely studied in the literature (e.g., Delyon (2000); Benveniste et al. (2012); Fort (2015); Li et al.
(2023)). In what follows, we demonstrate that for any initial point z0 = (Œ∏0, x0) ‚ààRD √ó Int(Œ£),
the SRRW iteration {xn}n‚â•0 will almost surely converge to the target distribution ¬µ, and the SA
iteration {Œ∏n}n‚â•0 will almost surely converge to the set Œò.
Now we verify conditions C1 - C4 in Theorem G.8. Our assumption A4 is equivalent to condition
C1 and assumption A2 corresponds to condition C2. For condition C3, we set ‚àáw(z) ‚â°‚àíg(z),
and the set S ‚â°{z‚àó|Œ∏‚àó‚ààŒò, x‚àó= ¬µ}, including disjoint points. For condition C4, since K‚Ä≤[z],
or equivalently K[x], is ergodic and time-reversible for a given z, as shown in the SRRW work
Doshi et al. (2023), it automatically ensures a solution to the Poisson equation, which has been well
discussed in Chen et al. (2020a, Section 2) and Benveniste et al. (2012); Meyn (2022). To show (97)
and (98) in condition C4, for each given z and any i ‚ààN, we need to give the explicit solution mz(i)
to the Poisson equation mz(i) ‚àí(K‚Ä≤
zmz)(i) = G(z, i) ‚àíg(z) in (96). The notation (K‚Ä≤
zmz)(i) is
defined as follows.
(K‚Ä≤
zmz)(i) =
X
j‚ààN
K‚Ä≤
z(i, j)m(z, j).
Let G(z) ‚âú[G(z, 1), ¬∑ ¬∑ ¬∑ , G(z, N)]T ‚ààRN√óD. We use [A]:,i to denote the i-th column of matrix
A. Then, we let mz(i) such that
mz(i) =
‚àû
X
k=0
 [G(z)(K‚Ä≤[z]k)T ][:,i] ‚àíg(z)

=
‚àû
X
k=0
[G(z)((K‚Ä≤[z]k)T ‚àíœÄ‚Ä≤[z]1T )][:,i].
(22)
In addition,
(K‚Ä≤
zmz)(i) =
‚àû
X
k=1
[G(z)(K‚Ä≤[z]T ‚àíœÄ‚Ä≤[z]1T )][:,i].
(23)
We can check that the mz(i) form in (22) is indeed the solution of the above Poisson equation.
Now, by induction, we get K‚Ä≤[z]k ‚àí1œÄ‚Ä≤[z]T = (K‚Ä≤[z] ‚àí1œÄ‚Ä≤[z]T )k for k ‚â•1 and for k = 0,
K‚Ä≤[z]0 ‚àí1œÄ‚Ä≤[z]T = (K‚Ä≤[z] ‚àí1œÄ‚Ä≤[z]T )0 ‚àí1œÄ‚Ä≤[z]T . Then,
mz(i) =
‚àû
X
k=0
[G(z)(K‚Ä≤[z]T ‚àíœÄ‚Ä≤[z]1T )k][:,i] ‚àíg(z)
=
"
G(z)
‚àû
X
k=0
(K‚Ä≤[z]T ‚àíœÄ‚Ä≤[z]1T )k
#
[:,i]
‚àíg(z)
=

G(z)(I ‚àíK‚Ä≤[z]T + œÄ‚Ä≤[z]1T )‚àí1
[:,i] ‚àíg(z)
=
X
j‚ààN
(I ‚àíK‚Ä≤[z] + 1œÄ‚Ä≤[z]T )‚àí1(i, j)G(z, j) ‚àíg(z).
(24)
17

Published as a conference paper at ICLR 2024
Here, (I ‚àíK‚Ä≤[z] + 1œÄ‚Ä≤[z]T )‚àí1 is well defined because K‚Ä≤[z] is ergodic and time-reversible for any
given z (proved in Doshi et al. (2023, Appendix A)). Now that both functions H(Œ∏, i) and Œ¥i ‚àíx
are bounded for each compact subset of RD √ó Œ£ by our assumption A1, function G(z, i) is also
bounded within the compact subset of its domain. Thus, function mz(i) is bounded, and (97) is
verified. Moreover, for a fixed i ‚ààN,
X
j‚ààN
(I ‚àíK‚Ä≤[z] + 1œÄ‚Ä≤[z]T )‚àí1(i, j)Œ¥j = (I ‚àíK‚Ä≤[z] + 1œÄ‚Ä≤[z]T )‚àí1
[:,i] = (I ‚àíK[x] + 1œÄ[x]T )‚àí1
[:,i]
and this vector-valued function is continuous in x because K[x], œÄ[x] are continuous. We then
rewrite (24) as
mz(i) =
"P
j‚ààN (I ‚àíK[x] + 1œÄ[x]T )‚àí1(i, j)H(x, j)
(I ‚àíK[x]T + œÄ[x]1T )‚àí1
[:,i]
#
‚àí
P
i‚ààN œÄi[x]H(Œ∏, i)
œÄ[x] ‚àíx

.
With continuous functions H(Œ∏, i), K[x], œÄ[x], we have mz(i) continuous with respect to z, so does
(K‚Ä≤
zmz)(i). This implies that functions mz(i) and (K‚Ä≤
zmz)(i) are locally Lipschitz, which satisfies
(98) with œïC(x) = CCx for some constant CC that depends on the compact set C. Therefore,
condition C4 is checked, and we can apply Theorem G.8 to show the almost convergence result of
(19), i.e., almost surely,
lim
n‚Üí‚àûxn = ¬µ,
and
lim sup
n‚Üí‚àû
inf
Œ∏‚àó‚ààŒò ‚à•Œ∏n ‚àíŒ∏‚àó‚à•= 0.
Therefore, the almost sure convergence of xn in Lemma 3.1 is also proved. This finishes the proof
in Scenario 1.
D.2
SCENARIO 2
Now in this subsection, we consider the steps sizes Œ≥n, Œ≤n with 1/2 < a < b ‚â§1 and 1/2 < b <
a ‚â§1. We will frequently use assumptions (B1) - (B5) in Section G.3 and Theorem G.10 to prove
the almost sure convergence.
D.2.1
CASE (I): 1/2 < a < b ‚â§1
In case (i), Œ∏n is on the slow timescale and xn is on the fast timescale because iteration Œ∏n has
smaller step size than xn, making Œ∏n converge slower than xn. Here, we consider the two-timescale
SA of the form:
Œ∏n+1 = Œ∏n + Œ≤n+1H(Œ∏, Xn+1),
xn+1 = xn + Œ≥n+1(Œ¥Xn+1 ‚àíx).
Now, we verify assumptions (B1) - (B5) listed in Section G.3.
‚Ä¢ Assumptions (B1) and (B5) are satisfied by our assumptions A2 and A4.
‚Ä¢ Our assumption A3 shows that the function H(Œ∏, X) is continuous and differentiable w.r.t
Œ∏ and grows linearly with ‚à•Œ∏‚à•. In addition, Œ¥X ‚àíx also satisfies this property. Therefore,
(B2) is satisfied.
‚Ä¢ Now that the function œÄ[x] ‚àíx is independent of Œ∏, we can set œÅ(Œ∏) = ¬µ for any Œ∏ ‚ààRD
such that œÄ[¬µ] ‚àí¬µ = 0 from Doshi et al. (2023, Proposition 3.1), and
‚àáx(œÄ(x) ‚àíx)|x=¬µ = 2Œ±u1T ‚àíŒ±PT ‚àí(Œ± + 1)I
from Doshi et al. (2023, Lemma 3.4), which is Hurwitz. Furthermore, œÅ(Œ∏) = ¬µ inherently
satisfies the condition ‚à•œÅ(Œ∏)‚à•‚â§L2(1+‚à•Œ∏‚à•) for any L2 ‚â•‚à•¬µ‚à•. Thus, conditions (i) - (iii)
in (B3) are satisfied. Additionally, P
i‚ààN œÄi[œÅ(Œ∏)]H(Œ∏, i) = P
i‚ààN œÄi[x] = h(Œ∏) such
that for Œ∏‚àó‚ààŒò defined in assumption A3, P
i‚ààN œÄi[œÅ(Œ∏‚àó)]H(Œ∏‚àó, i) = h(Œ∏‚àó) = 0, and
‚àáŒ∏h(Œ∏‚àó) is Hurwitz. Therefore, (B3) is checked.
‚Ä¢ Assumption (B4) is verified by the nature of SRRW, i.e., its transition kernel K[x] and the
corresponding stationary distribution œÄ[x] with œÄ[¬µ] = ¬µ.
18

Published as a conference paper at ICLR 2024
Consequently, assumptions (B1) - (B5) are satisfied by our assumptoins A1 - A4 and by Theorem
G.10, we have limn‚Üí‚àûxn = ¬µ and Œ∏n ‚ÜíŒò almost surely.
Next, we consider 1/2 < b < a ‚â§1. As discussed before, (B1), (B2), (B4) and (B5) are satisfied by
our assumptions A1 - A4 and the properties of SRRW. The only difference for this step size setting,
compared to the previous one 1/2 < a < b ‚â§1, is that the roles of Œ∏n, xn are now flipped, that is,
Œ∏n is now on the fast timescale while xn is on the slow timescale. By a much stronger Assumption
A3‚Ä≤, for any x ‚ààInt(Œ£), (i) EX‚àºœÄ[x][H(œÅ(x), X)] = 0; (ii) EX‚àºœÄ[x][‚àáH(œÅ(x), X)] is Hurwitz;
(iii) ‚à•œÅ(x)‚à•‚â§L2(1 + ‚à•x‚à•). Hence, conditions (i) - (iii) in (B3) are satisfied. Moreover, we have
œÄ[¬µ] ‚àí¬µ = 0, ‚àá(œÄ[x] ‚àíx)|x=¬µ being Hurwitz, as mentioned in the previous part. Therefore, (B3)
is verified. Accordingly, (B1) - (B5) are checked by our assumptions A1, A2, A3‚Ä≤, A4. By Theorem
G.10, we have limn‚Üí‚àûxn = ¬µ and Œ∏n ‚ÜíŒò almost surely.
E
PROOF OF THEOREM 3.3
This section is devoted to the proof of Theorem 3.3, which also includes the proof of the CLT results
for the SRRW iteration xn in Lemma 3.1. We will use different techniques depending on the step
sizes in Assumption A2. Specifically, for step sizes Œ≥n = (n + 1)‚àía, Œ≤n = (n + 1)‚àíb, we will
consider three cases: case (i): Œ≤n = o(Œ≥n); case (ii): Œ≤n = Œ≥n; and case (iii): Œ≥n = o(Œ≤n). For case
(ii), we will use the existing CLT result for single-timescale SA in Theorem G.9. For cases (i) and
(iii), we will construct our own CLT analysis for the two-timescale structure. We start with case (ii).
E.1
CASE (II): Œ≤n = Œ≥n
In this part, we stick to the notations for single-timescale SA studied in Section D.1. To utilize
Theorem G.9, apart from Conditions C1 - C4 that have been checked in Section D.1, we still need
to check conditions C5 and C6 listed in Section G.2.
Assumption A3 corresponds to condition C5. For condition C6, we need to obtain the explicit form
of function Qz to the Poisson equation defined in (96), that is,
Qz(i) ‚àí(K‚Ä≤
zQz)(i) = œà(z, i) ‚àíEj‚àºœÄ[z][œà(z, j)]
where
œà(z, i) ‚âú
X
j‚ààN
K‚Ä≤
z(i, j)mz(j)mz(j)T ‚àí(K‚Ä≤
zmz)(i)(K‚Ä≤
zmz)(i)T .
Following the similar steps in the derivation of mz(i) from (22) to (24), we have
Qz(i) =
X
j‚ààN
(I ‚àíK‚Ä≤[z] + 1œÄ‚Ä≤[z]T )‚àí1(i, j)mz(j) ‚àíœÄ‚Ä≤
j[z]mz(j).
We also know that Qz(i) and (K‚Ä≤
zQz)(i) are continuous in z for any i ‚ààN. For any z in a compact
set ‚Ñ¶, Qz(i) and (K‚Ä≤
zQz)(i) are bounded because function mz(i) is bounded. Therefore, C6 is
checked. By Theorem G.9, assume zn =

Œ∏n
xn

converges to a point z‚àó=

Œ∏‚àó
¬µ

for Œ∏‚àó‚ààŒò, we
have
Œ≥‚àí1/2
n
(zn ‚àíz‚àó)
dist.
‚àí‚àí‚àí‚àí‚Üí
n‚Üí‚àûN(0, V),
(26)
where V is the solution of the following Lyapunov equation
V
1{b=1}
2
I + ‚àág(z‚àó)T

+
1{b=1}
2
I + ‚àág(z‚àó)

V + U = 0,
(27)
and U = P
i‚ààN ¬µi
 mz‚àó(i)mz‚àó(i)T ‚àí(Kz‚àómz‚àó)(i)(Kz‚àómz‚àó)(i)T 
.
19

Published as a conference paper at ICLR 2024
By algebraic calculations of derivative of œÄ[x] with respect to x in (20),12 we can rewrite ‚àág(z‚àó) in
terms of x, Œ∏, i.e.,
J(Œ±) ‚âú‚àág(z‚àó) =
"
‚àÇP
i‚ààN œÄi[x]H(Œ∏,i)
‚àÇŒ∏
‚àÇP
i‚ààN œÄi[x]H(Œ∏,i)
‚àÇx
‚àÇ(œÄ[x]‚àíx)
‚àÇŒ∏
‚àÇœÄ[x]‚àíx
‚àÇx
#
z=z‚àó
=

‚àáh(Œ∏‚àó)
‚àíŒ±HT (PT + I)
0
2Œ±¬µ1T ‚àíŒ±PT ‚àí(Œ± + 1)I

‚âú

J11
J12(Œ±)
J21
J22(Œ±)

,
where matrix H = [H(Œ∏‚àó, 1), ¬∑ ¬∑ ¬∑ , H(Œ∏, N)]T . Then, we further clarify the matrix U. Note that
mz‚àó(i) =
‚àû
X
k=0
[G(z‚àó)((Pk)T ‚àí¬µ1T )][:,i] =
‚àû
X
k=0
[G(z‚àó)(Pk)T ][:,i] = E
" ‚àû
X
k=0
[G(z‚àó, Xk)]
 X0 = i
#
,
(28)
where the first equality holds because K‚Ä≤[¬µ] = P from the definition of SRRW kernel (3), the
second equality stems from G(z‚àó)¬µ = g(z‚àó) = 0, and the last term is a conditional expectation
over the base Markov chain {Xk}k‚â•0 (with transition kernel P) conditioned on X0 = i. Similarly,
with (K‚Ä≤
zmz)(i) in the form of (23), we have
(K‚Ä≤
zmz)(i) = E
" ‚àû
X
k=1
[G(z‚àó, Xk)]
 X0 = i
#
.
From the form ‚ÄòP
i‚ààN ¬µi‚Äô inside the matrix U, the Markov chain {Xk}k‚â•0 is in its stationary regime
from the beginning, i.e., Xk ‚àº¬µ for any k ‚â•0. Hence,
U = E
Ô£Æ
Ô£∞
 ‚àû
X
k=0
[G(z‚àó, Xk)]
!  ‚àû
X
k=0
[G(z‚àó, Xk)]
!T Ô£π
Ô£ª
‚àíE
Ô£Æ
Ô£∞
 ‚àû
X
k=1
[G(z‚àó, Xk)]
!  ‚àû
X
k=1
[G(z‚àó, Xk)]
!T Ô£π
Ô£ª
= E

G(z‚àó, X0)G(z‚àó, X0)T 
+E
Ô£Æ
Ô£∞G(z‚àó, X0)
 ‚àû
X
k=1
G(z‚àó, Xk)
!T Ô£π
Ô£ª
+ E
" ‚àû
X
k=1
G(z‚àó, Xk)
!
G(z‚àó, X0)T
#
= Cov(G(z‚àó, X0), G(z‚àó, X0))
+
‚àû
X
k=1
[Cov(G(z‚àó, X0), G(z‚àó, Xk)) + Cov(G(z‚àó, Xk), G(z‚àó, X0))] ,
(29)
where the covariance between G(z‚àó, X0) and G(z‚àó, Xk) for the Markov chain {Xn} in the station-
ary regime is Cov(G(z‚àó, X0), G(z‚àó, Xk)). By Br¬¥emaud (2013, Theorem 6.3.7), it is demonstrated
that U is the sampling covariance of the base Markov chain P for the test function G(z‚àó, ¬∑). More-
over, Br¬¥emaud (2013, equation (6.34)) states that this sampling covariance U can be rewritten in the
following form:
U =
N‚àí1
X
i=1
G(z‚àó)T uiuiG(z‚àó) =
N‚àí1
X
i=1
1 + Œªi
1 ‚àíŒªi

HT uiuT
i H
HT uiuT
i
uiuT
i H
uiuT
i

‚âú

U11
U12
U21
U22

,
(30)
where {(Œªi, ui)}i‚ààN is the eigenpair of the transition kernel P of the ergodic and time-reversible
base Markov chain. This completes the proof of case 1.
12One may refer to Doshi et al. (2023, Appendix B, Proof of Lemma 3.4) for the computation of ‚àÇœÄ[x]‚àíx
‚àÇx
.
20

Published as a conference paper at ICLR 2024
Remark E.1. For the CLT result (26), we can look further into the asymptotic covariance matrix V
as in (27). For convenience, we denote V =

V11
V12
V21
V22

and U in the form of (30) such that

V11
V12
V21
V22
 1{b=1}
2
I + J(Œ±)T

+
1{b=1}
2
I + J(Œ±)
 
V11
V12
V21
V22

+ U = 0.
(31)
For the SRRW iteration xn, from (26) we know that Œ≥‚àí1/2
n
(xn ‚àí¬µ)
dist.
‚àí‚àí‚àí‚àí‚Üí
n‚Üí‚àûN(0, V4). Thus, in this
remark, we want to obtain the closed form of V22. By algebraic computations of the bottom-right
sub-block matrix, we have

2Œ±¬µ1T ‚àíŒ±PT ‚àí

Œ± + 1‚àí1{a=1}
2

I

V22
+ V22

2Œ±¬µ1T ‚àíŒ±PT ‚àí

Œ± + 1‚àí1{a=1}
2

I
T
+ U22 = 0.
By using result of the closed form solution to the Lyapunov equation (e.g., Lemma G.1) and the
eigendecomposition of P, we have
V22 =
N‚àí1
X
i=1
1
2Œ±(1 + Œªi) + 2 ‚àí1{a=1}
¬∑ 1 + Œªi
1 ‚àíŒªi
uiuT
i .
(32)
E.2
CASE (I): Œ≤n = o(Œ≥n)
In this part, we mainly focus on the CLT of the SA iteration Œ∏n because the SRRW iteration xn is
independent of Œ∏n and its CLT result has been shown in Remark E.1.
E.2.1
DECOMPOSITION OF SA-SRRW ITERATION (4)
We slightly abuse the math notation and define the function
h(Œ∏, x) ‚âúEi‚àºœÄ[x]H(Œ∏, i) =
X
i‚ààN
œÄi[x]H(Œ∏, i)
such that h(Œ∏, ¬µ) ‚â°h(Œ∏). Then, we reformulate (25) as
Œ∏n+1 = Œ∏n + Œ≤n+1h(Œ∏n, xn) + Œ≤n+1(H(Œ∏n, Xn+1) ‚àíh(Œ∏n, xn)).
(33a)
xn+1 = xn + Œ≥n+1(œÄ[xn] ‚àíxn) + Œ≥n+1(Œ¥Xn+1) ‚àíœÄ[xn]).
(33b)
There exist functions qx : N ‚ÜíRN, ÀúHŒ∏,x : N ‚ÜíRD satisfying the following Poisson equations
Œ¥i ‚àíœÄ(x) = qx(i) ‚àí(Kxqx)(i)
(34a)
H(Œ∏, i) ‚àíh(Œ∏, x) = ÀúHŒ∏,x(i) ‚àí(Kx ÀúHŒ∏,x)(i),
(34b)
for any Œ∏ ‚ààRD, x ‚ààInt(Œ£) and i ‚ààN, where (Kxqx)(i) ‚âúP
j‚ààN Kij[x]qx(j), (Kx ÀúHŒ∏,x)(j) ‚âú
P
j‚ààN Kij[x] ÀúHŒ∏,x(j). The existence and explicit form of the solutions qx, ÀúHŒ∏,x, which are contin-
uous w.r.t x, Œ∏, follow the similar steps that can be found in Section D.1 from (22) to (24). Thus, we
can further decompose (33) into
Œ∏n+1 =Œ∏n + Œ≤n+1h(Œ∏n, xn) + Œ≤n+1 ( ÀúHŒ∏n,xn(Xn+1) ‚àí(Kxn ÀúHŒ∏n,xn)(Xn))
|
{z
}
M (Œ∏)
n+1
+ Œ≤n+1 ((Kxn+1 ÀúHŒ∏n+1,xn+1)(Xn+1) ‚àí(Kxn ÀúHŒ∏n,xn)(Xn+1))
|
{z
}
r(Œ∏,1)
n
+ Œ≤n+1 ((Kxn ÀúHŒ∏n,xn)(Xn) ‚àí(Kxn+1 ÀúHŒ∏n+1,xn+1)(Xn+1))
|
{z
}
r(Œ∏,2)
n
,
(35a)
21

Published as a conference paper at ICLR 2024
xn+1 =xn + Œ≥n+1(œÄ(xn) ‚àíxn) + Œ≥n+1 (qxn(Xn+1) ‚àí(Kxnqxn)(Xn))
|
{z
}
M (x)
n+1
+ Œ≥n+1 ([Kxnqxn](Xn+1) ‚àí[Kxnqxn+1](Xn+1))
|
{z
}
r(x,1)
n
+ Œ≥n+1 ((Kxnqxn)(Xn) ‚àí(Kxn+1qxn+1)(Xn+1))
|
{z
}
r(x,2)
n
.
(35b)
such that
Œ∏n+1 = Œ∏n + Œ≤n+1h(Œ∏n, xn) + Œ≤n+1M (Œ∏)
n+1 + Œ≤n+1r(Œ∏,1)
n
+ Œ≤n+1r(Œ∏,2)
n
,
(36a)
xn+1 = xn + Œ≥n+1(œÄ(xn) ‚àíxn) + Œ≥n+1M (x)
n+1 + Œ≥n+1r(x,1)
n
+ Œ≥n+1r(x,2)
n
.
(36b)
We can observe that (36) differs from the expression in Konda & Tsitsiklis (2004); Mokkadem &
Pelletier (2006), which studied the two-timescale SA with Martingale difference noise. Here, due to
the presence of the iterate-dependent Markovian noise and the application of the Poisson equation
technique, we have additional non-vanishing terms r(Œ∏,2)
n
, r(x,2)
n
, which will be further examined in
Lemma E.2. Additionally, when we apply the Poisson equation to the Martingale difference terms
M (Œ∏)
n+1, M (x)
n+1, we find that there are some covariances that are also non-vanishing as in Lemma E.1.
We will mention this again when we obtain those covariances. These extra non-zero noise terms
make our analysis distinct from the previous ones since the key assumption (A4) in Mokkadem &
Pelletier (2006) is not satisfied. We demonstrate that the long-term average performance of these
terms can be managed so that they do not affect the final CLT result.
Analysis of Terms M (Œ∏)
n+1, M (x)
n+1
Consider the filtration Fn ‚âúœÉ(Œ∏0, x0, X0, ¬∑ ¬∑ ¬∑ , Œ∏n, xn, Xn), it is evident that M (Œ∏)
n+1, M (x)
n+1 are
Martingale difference sequences adapted to Fn. Then, we have
E
h
M (x)
n+1(M (x)
n+1)T  Fn
i
= E[qxn(Xn+1)qxn(Xn+1)T |Fn] + (Kxnqxn)(Xn) ((Kxnqxn)(Xn))T
‚àíE[qxn(Xn+1)|Fn] (Kxnqxn)(Xn))T ‚àí(Kxnqxn)(Xn)E[qxn(Xn+1)T |Fn]
= E[qxn(Xn+1)qxn(Xn+1)T |Fn] ‚àí(Kxnqxn)(Xn) ((Kxnqxn)(Xn))T .
(37)
Similarly, we have
E
h
M (Œ∏)
n+1(M (Œ∏)
n+1)T  Fn
i
= E[ ÀúHŒ∏n,xn(Xn+1) ÀúHŒ∏n,xn(Xn+1)T |Fn] ‚àí(Kxn ÀúHŒ∏n,xn)(Xn)

(Kxn ÀúHŒ∏n,xn)(Xn)
T
,
(38)
and
E
h
M (x)
n+1(M (Œ∏)
n+1)T  Fn
i
= E[qxn(Xn+1) ÀúHŒ∏n,xn(Xn+1)T |Fn] ‚àí(Kxnqxn)(Xn)

(Kxn ÀúHŒ∏n,xn)(Xn)
T
.
We now focus on E
h
M (x)
n+1(M (x)
n+1)T  Fn
i
. Denote by
V1(x, i) ‚âú
X
j‚ààN
Ki,j[x]qx(j)qx(j)T ‚àí(Kxqx)(i) ((Kxqx)(i))T ,
(39)
and let its expectation w.r.t the stationary distribution œÄ(x) be v1(x) ‚âúEi‚àºœÄ(x)[V1(x, i)], we can
construct another Poisson equation, i.e.,
E
h
M (x)
n+1(M (x)
n+1)T  Fn
i
‚àí
X
Xn‚ààN
œÄXn(xn)E
h
M (x)
n+1(M (x)
n+1)T  Fn
i
= V1(xn, Xn+1) ‚àív1(xn)
= œÜ(1)
x (Xn+1) ‚àí(KxnœÜ(1)
xn )(Xn+1),
22

Published as a conference paper at ICLR 2024
for some matrix-valued function œÜ(1)
x
: N ‚ÜíRN√óN. Since qx and K[x] are continuous in x,
functions V1, v1 are also continuous in x. Then, we can decompose (39) into
V1(xn, Xn+1) = v1(¬µ)
| {z }
U22
+ v1(xn) ‚àív1(¬µ)
|
{z
}
D(1)
n
+ œÜ(1)
xn (Xn+1) ‚àí(KxnœÜ(1)
xn )(Xn)
|
{z
}
J(1,a)
n
+ (KxnœÜ(1)
xn )(Xn) ‚àí(KxnœÜ(1)
xn )(Xn+1)
|
{z
}
J(1,b)
n
.
(40)
Thus, we have
E[M (x)
n+1(M (x)
n+1)T |Fn] = U22 + D(1)
n
+ J(1)
n ,
(41)
where J(1)
n
= J(1,a)
n
+ J(1,b)
n
.
Following
the
similar
steps
above,
we
can
decompose
E
h
M (x)
n+1(M (Œ∏)
n+1)T  Fn
i
and
E
h
M (Œ∏)
n+1(M (Œ∏)
n+1)T  Fn
i
as
E
h
M (x)
n+1(M (Œ∏)
n+1)T  Fn
i
= U21 + D(2)
n
+ J(2)
n ,
(42a)
E
h
M (Œ∏)
n+1(M (Œ∏)
n+1)T  Fn
i
= U11 + D(3)
n
+ J(3)
n .
(42b)
where J(2)
n
= J(2,a)
n
+J(2,b)
n
and J(3)
n
= J(3,a)
n
+J(3,b)
n
. Here, we note that matrices Ji
n for i = 1, 2, 3
are in presence of the current CLT analysis of the two-timescale SA with Martingale difference noise.
In addition, U11, U12 and U22 inherently include the information of the underlying Markov chain
(with its eigenpair (Œªi, ui)), which is an extension of the previous works (Konda & Tsitsiklis, 2004;
Mokkadem & Pelletier, 2006).
Lemma E.1. For M (Œ∏)
n+1, M (x)
n+1 defined in (35) and their decomposition in (41) and (42), we have
U11 =
N‚àí1
X
i=1
1 + Œªi
1 ‚àíŒªi
uiuT
i ,
U21 =
N‚àí1
X
i=1
1 + Œªi
1 ‚àíŒªi
uiuT
i H,
U11 =
N‚àí1
X
i=1
1 + Œªi
1 ‚àíŒªi
HT uiuT
i H,
(43a)
lim
n‚Üí‚àûD(i)
n = 0 a.s.
for
i = 1, 2, 3,
(43b)
lim
n‚Üí‚àûŒ≥nE
"
n
X
k=1
J(i)
k

#
= 0,
for
i = 1, 2, 3.
(43c)
Proof. We now provide the properties of the four terms inside (41) as an example. Note that
U11 = Ei‚àº¬µ[V1(¬µ, i)] =
X
i‚ààN
¬µi
Ô£Æ
Ô£∞X
j‚ààN
P(i, j)q¬µ(j)q¬µ(j)T ‚àí(Pq¬µ)(i) ((Pq¬µ)(i))T
Ô£π
Ô£ª
=
X
j‚ààN
¬µjq¬µ(j)q¬µ(j)T ‚àí(Pq¬µ)(j) ((Pq¬µ)(j))T .
We can see that it has exactly the same structure as matrix U in (27). Following the similar steps in
deducing the explicit form of U from (28) to (30), we get
U11 =
N‚àí1
X
i=1
1 + Œªi
1 ‚àíŒªi
uiuT
i .
(44)
By the almost sure convergence result xn ‚Üí¬µ in Lemma 3.1, v1(xn) ‚Üív1(¬µ) a.s. such that
limn‚Üí‚àûD(1)
n
= 0 a.s.
We next prove that limn‚Üí‚àûŒ≥nE
hPn
k=1 J(1,a)
k

i
= 0 and limn‚Üí‚àûŒ≥nE
hPn
k=1 J(1,b)
k

i
= 0.
23

Published as a conference paper at ICLR 2024
Since {J(1,a)
n
} is a Martingale difference sequence adapted to Fn, with the Burkholder inequality in
Lemma G.2 and p = 1, we show that
E
"
n
X
k=1
J(1,a)
k

#
‚â§C1E
Ô£Æ
Ô£∞
v
u
u
t
 n
X
k=1
J(1,a)
k

2
!Ô£π
Ô£ª.
(45)
By assumption A4, xn is always within some compact set ‚Ñ¶such that supn ‚à•J(1,a)
n
‚à•‚â§C‚Ñ¶< ‚àû
and for a given trajectory œâ of xn(œâ),
Œ≥nCp
v
u
u
t
 n
X
k=1
J(1,a)
k

2
!
‚â§CpC‚Ñ¶Œ≥n
‚àön,
(46)
and the last term decreases to zero in n since a > 1/2.
For J(1,b)
n
, we use Abel transformation and obtain
n
X
k=1
J(1,b)
k
=
n
X
k=1
((KxkœÜ(1)
xk )(Xk‚àí1) ‚àí(Kxk‚àí1œÜ(1)
xk‚àí1)(Xk‚àí1))
+ (Kx0œÜ(1)
x0 )(X0) ‚àí(KxnœÜ(1)
xn )(Xn).
Since (KxœÜ(1)
x )(X) is continuous in x, for xn within a compact set ‚Ñ¶(assumption A4), it is local
Lipschitz with a constant L‚Ñ¶such that
‚à•(KxkœÜ(1)
xk )(Xk‚àí1) ‚àíKxk‚àí1œÜ(1)
xk‚àí1)(Xk‚àí1)‚à•‚â§L‚Ñ¶‚à•xk ‚àíxk‚àí1‚à•‚â§2L‚Ñ¶Œ≥k.
where the last inequality arises from (4b), i.e., xk‚àíxk‚àí1 = Œ≥k(Œ¥Xk ‚àíxk‚àí1) and ‚à•Œ¥Xk ‚àíxk‚àí1‚à•‚â§2
because xn ‚ààInt(Œ£). Also, ‚à•(Kx0œÜ(1)
x0 )(X0)‚à•+ ‚à•(KxnœÜ(1)
xn )(Xn)‚à•are upper-bounded by some
positive constant C‚Ä≤
‚Ñ¶. This implies that

n
X
k=1
J(1,b)
k
 ‚â§C‚Ä≤
‚Ñ¶+ 2L‚Ñ¶
n
X
k=1
Œ≥k.
Note that
Œ≥n

n
X
k=1
J(1,b)
k
 ‚â§Œ≥nC‚Ä≤
‚Ñ¶+ 2L‚Ñ¶Œ≥n
n
X
k=1
Œ≥k ‚â§Œ≥nC‚Ä≤
‚Ñ¶+ 2L‚Ñ¶
a n1‚àí2a,
(47)
where the last inequality is from Pn
k=1 Œ≥k <
1
an1‚àía. We observe that the last term in (47) is
decreasing to zero in n because a > 1/2.
Note that J(1)
k
= J(1,a)
k
+ J(1,b)
k
, by triangular inequality we have
Œ≥nE
"
n
X
k=1
J(11)
k

#
‚â§Œ≥nE
"
n
X
k=1
J(11,A)
k

#
+ Œ≥nE
"
n
X
k=1
J(11,B)
k

#
‚â§Œ≥nC1E
Ô£Æ
Ô£∞
v
u
u
t
 n
X
k=1
J(11,A)
k

2
!Ô£π
Ô£ª+ Œ≥nE
"
n
X
k=1
J(11,B)
k

#
= E
Ô£Æ
Ô£∞Œ≥nC1
v
u
u
t
 n
X
k=1
J(11,A)
k

2
!
+ Œ≥n

n
X
k=1
J(11,B)
k

Ô£π
Ô£ª,
(48)
where the second inequality comes from (45). By (46) and (47) we know that both terms in the last
line of (48) are uniformly bounded by constants over time n that depend on the set ‚Ñ¶. Therefore, by
dominated convergence theorem, taking the limit over the last line of (48) gives
lim
n‚Üí‚àûE
Ô£Æ
Ô£∞Œ≥nC1
v
u
u
t
 n
X
k=1
J(11,A)
k

2
!
+Œ≥n

n
X
k=1
J(11,B)
k

Ô£π
Ô£ª
= E
Ô£Æ
Ô£∞lim
n‚Üí‚àûŒ≥nC1
v
u
u
t
 n
X
k=1
J(11,A)
k

2
!
+Œ≥n

n
X
k=1
J(11,B)
k

Ô£π
Ô£ª=0.
24

Published as a conference paper at ICLR 2024
Therefore, we have
lim
n‚Üí‚àûŒ≥nE
"
n
X
k=1
J(1)
k

#
= 0,
In sum, in terms of E[M (x)
n+1(M (x)
n+1)T |Fn] in (41), we have U11 in (44), limn‚Üí‚àûD(1)
n
= 0 a.s. and
limn‚Üí‚àûŒ≥nE
hPn
k=1 J(1)
k

i
= 0.
We can apply the same steps as above for the other two terms i = 2, 3 in (42) and obtain the
results.
Analysis of Terms r(Œ∏,1)
n
, r(Œ∏,2)
n
, r(x,1)
n
, r(x,2)
n
Lemma E.2. For r(Œ∏,1)
n
, r(Œ∏,2)
n
, r(x,1)
n
, r(x,2)
n
defined in (35), we have the following results:
‚à•r(Œ∏,1)
n
‚à•= O(Œ≥n) = o(
p
Œ≤n),
‚àöŒ≥n

n
X
k=1
r(Œ∏,2)
k
 = O(‚àöŒ≥n) = o(1).
(49a)
‚à•r(x,1)
n
‚à•= O(Œ≥n) = o(
p
Œ≤n),
‚àöŒ≥n

n
X
k=1
r(x,2)
k
 = O(‚àöŒ≥n) = o(1).
(49b)
Proof. For r(Œ∏,1)
n
, note that
r(Œ∏,1)
n
= (Kxn+1 ÀúHŒ∏n+1,xn+1)(Xn+1) ‚àí(Kxn ÀúHŒ∏n,xn)(Xn+1)
=
X
j‚ààN

KXn,j[xn+1] ÀúHŒ∏n+1,xn+1(j) ‚àíKXn,j[xn] ÀúHŒ∏n,xn(j)

‚â§
X
j‚ààN
LC(‚à•Œ∏n+1 ‚àíŒ∏n‚à•+ ‚à•xn+1 ‚àíxn‚à•)
‚â§NLC(CCŒ≤n+1 + 2Œ≥n+1)
(50)
where the second last inequality is because Ki,j[x] ÀúHŒ∏,x(j) is continuous in Œ∏, x K[x], which
stems from continuous functions K[x] and ÀúHŒ∏,x. The last inequality is from update rules (4) and
(Œ∏n, xn) ‚àà‚Ñ¶for some compact subset ‚Ñ¶by assumption A4. Then, we have ‚à•r(Œ∏,1)
n
‚à•= O(Œ≥n) =
o(‚àöŒ≤n) because of a > 1/2 ‚â•b/2 by assumption A2.
We let ŒΩn ‚âú(Kxn ÀúHŒ∏n,xn)(Xn) such that r(Œ∏,2)
n
= ŒΩn ‚àíŒΩn+1. Note that Pn
k=1 r(Œ∏,2)
k
= ŒΩ1 ‚àíŒΩn+1,
and by assumption A4, ‚à•ŒΩn‚à•is upper bounded by a constant dependent on the compact set, which
leads to
‚àöŒ≥n

n
X
k=1
r(Œ∏,2)
k
 = ‚àöŒ≥n‚à•ŒΩ1 ‚àíŒΩn+1‚à•= O(‚àöŒ≥n) = o(1).
Similarly, we can also obtain ‚à•r(x,1)
n
‚à•= o(‚àöŒ≤n) and ‚àöŒ≥n
Pn
k=1 r(x,2)
k
 = O(‚àöŒ≥n) = o(1).
E.2.2
EFFECT OF SRRW ITERATION ON SA ITERATION
In view of the almost sure convergence results in Lemma 3.1 and Lemma 3.2, for large enough n so
that both iterations Œ∏n, xn are close to the equilibrium (Œ∏‚àó, ¬µ), we can apply the Taylor expansion
to functions h(Œ∏, x) and œÄ[x] ‚àíx in (36) at the point (Œ∏‚àó, ¬µ), which results in
h(Œ∏, x) = h(Œ∏‚àó, ¬µ)+‚àáŒ∏h(Œ∏‚àó, ¬µ)(Œ∏‚àíŒ∏‚àó)+‚àáxh(Œ∏‚àó, ¬µ)(x‚àí¬µ)+O(‚à•Œ∏‚àíŒ∏‚àó‚à•2+‚à•x‚àí¬µ‚à•2), (51a)
œÄ[x] ‚àíx = œÄ[¬µ] ‚àí¬µ + ‚àáx(œÄ(x) ‚àíx)|x=¬µ(x ‚àí¬µ) + O(‚à•x ‚àí¬µ‚à•2).
(51b)
With matrix J(Œ±), we have the following:
J11 = ‚àáŒ∏h(Œ∏‚àó, ¬µ) = ‚àáh(Œ∏‚àó),
J12(Œ±) = ‚àáxh(Œ∏‚àó, ¬µ) = ‚àíŒ±HT (PT + I),
J22(Œ±) = ‚àáx(œÄ(x) ‚àíx)|x=¬µ = 2Œ±¬µ1T ‚àíŒ±PT ‚àí(Œ± + 1)I.
(52)
25

Published as a conference paper at ICLR 2024
Then, (36) becomes
Œ∏n+1 = Œ∏n + Œ≤n+1(J11(Œ∏n ‚àíŒ∏‚àó) + J12(Œ±)(xn ‚àí¬µ) + r(Œ∏,1)
n
+ r(Œ∏,2)
n
+ M (Œ∏)
n+1 + Œ∑(Œ∏)
n ), (53a)
xn+1 = xn + Œ≥n+1(J22(Œ±)(xn ‚àí¬µ) + r(x,1)
n
+ r(x,2)
n
+ M (x)
n+1 + Œ∑(x)
n ),
(53b)
where Œ∑(Œ∏)
n
= O(‚à•xn‚à•2 + ‚à•Œ∏n‚à•2) and Œ∑(x)
n
= O(‚à•xn‚à•2).
Then, inspired by Mokkadem & Pelletier (2006), we decompose iterates {xn} and {Œ∏n} into xn =
L(x)
n
+ ‚àÜ(x)
n
and Œ∏n = L(Œ∏)
n
+ R(Œ∏)
n
+ ‚àÜ(Œ∏)
n . Rewriting (53b) gives
xn ‚àí¬µ = Œ≥‚àí1
n+1J22(Œ±)‚àí1(xn+1 ‚àíxn) ‚àíJ22(Œ±)‚àí1(r(x,1)
n
+ r(x,2)
n
+ M (x)
n+1 + Œ∑(x)
n ),
and substituting the above equation back in (53a) gives
Œ∏n+1 ‚àíŒ∏‚àó= Œ∏n ‚àíŒ∏‚àó+ Œ≤n+1

J11(Œ∏n ‚àíŒ∏‚àó) + Œ≥‚àí1
n+1J12(Œ±)J22(Œ±)‚àí1(xn+1 ‚àíxn)
‚àíJ12(Œ±)J22(Œ±)‚àí1(r(x,1)
n
+ r(x,2)
n
+ M (x)
n+1 + Œ∑(x)
n ) + r(Œ∏,1)
n
+ r(Œ∏,2)
n
+ M (Œ∏)
n+1 + Œ∑(Œ∏)
n

= (I + Œ≤n+1J11)(Œ∏n ‚àíŒ∏‚àó) + [Œ≤n+1Œ≥‚àí1
n+1J12(Œ±)J22(Œ±)‚àí1(xn+1 ‚àíxn)]
+ Œ≤n+1(M (Œ∏)
n+1 ‚àíJ12(Œ±)J22(Œ±)‚àí1M (x)
n+1)
+ Œ≤n+1(r(Œ∏,1)
n
+ r(Œ∏,2)
n
+ Œ∑(Œ∏)
n
‚àíJ12(Œ±)J22(Œ±)‚àí1(r(x,1)
n
+ r(x,2)
n
+ Œ∑(x)
n )),
(54)
From (54) we can see the iteration {Œ∏n} implicitly embeds the recursions of three sequences
‚Ä¢ Œ≤n+1Œ≥‚àí1
n+1J12(Œ±)J22(Œ±)‚àí1(xn+1 ‚àíxn);
‚Ä¢ Œ≤n+1(M (Œ∏)
n+1 ‚àíJ12(Œ±)J22(Œ±)‚àí1M (x)
n+1);
‚Ä¢ Œ≤n+1(r(Œ∏,1)
n
+ r(Œ∏,2)
n
+ Œ∑(Œ∏)
n
‚àíJ12(Œ±)J22(Œ±)‚àí1(r(x,1)
n
+ r(x,2)
n
+ Œ∑(x)
n ))).
Let un ‚âúPn
k=1 Œ≤k and sn ‚âúPn
k=1 Œ≥k. Below we define two iterations:
L(Œ∏)
n
= eŒ≤nJ11L(Œ∏)
n‚àí1 + Œ≤n(M (Œ∏)
n
‚àíJ12(Œ±)J22(Œ±)‚àí1M (x)
n )
=
n
X
k=1
e(un‚àíuk)J11Œ≤k(M (Œ∏)
k
‚àíJ12(Œ±)J22(Œ±)‚àí1M (x)
k
)
(55a)
R(Œ∏)
n
= eŒ≤nJ11R(Œ∏)
n‚àí1 + Œ≤nŒ≥‚àí1
n J12(Œ±)J22(Œ±)‚àí1(xn ‚àíxn‚àí1)
=
n
X
k=1
e(un‚àíuk)J11Œ≤kŒ≥‚àí1
k J12(Œ±)J22(Œ±)‚àí1(xk ‚àíxk‚àí1)
(55b)
and a remaining term ‚àÜ(Œ∏)
n
‚âúŒ∏n ‚àíŒ∏‚àó‚àíL(Œ∏)
n
‚àíR(Œ∏)
n .
Similarly, for iteration xn, define the sequence L(x)
n
such that
L(x)
n
= eŒ≥nJ22(Œ±)L(x)
n‚àí1 + Œ≥nM (x)
n
=
n
X
k=1
e(sn‚àísk)J22(Œ±)Œ≥kM (x)
k
,
(56)
and a remaining term
‚àÜ(x)
n
‚âúxn ‚àí¬µ ‚àíL(Œ∏)
n
(57)
The decomposition of Œ∏n ‚àíŒ∏‚àóand xn ‚àí¬µ in the above form is also standard in the single-timescale
SA literature (Delyon, 2000; Fort, 2015).
Characterization of Sequences {L(Œ∏)
n } and {L(x)
n }
we set a Martingale Z(n) = {Z(n)
k
}k‚â•1 such that
Z(n)
k
=
 
Œ≤‚àí1/2
n
eunJ11
0
0
Œ≥‚àí1/2
n
esnJ22(Œ±)
!
√ó
k
X
j=1
 
e‚àíukJ11Œ≤k(M (Œ∏)
k
‚àíJ12(Œ±)J22(Œ±)‚àí1M (x)
k
)
e‚àískJ22(Œ±)Œ≥kM (x)
k
!
.
26

Published as a conference paper at ICLR 2024
Then, the Martingale difference array Z(n)
k
‚àíZ(n)
k‚àí1 becomes
Z(n)
k
‚àíZ(n)
k‚àí1 =
 
Œ≤‚àí1/2
n
e(un‚àíuk)J11Œ≤k(M (Œ∏)
k
‚àíJ12(Œ±)J22(Œ±)‚àí1M (x)
k
)
Œ≥‚àí1/2
n
e(sn‚àísk)J22(Œ±)Œ≥kM (x)
k
!
and
n
X
k=1
E
h
(Z(n)
k
‚àíZ(n)
k‚àí1)(Z(n)
k
‚àíZ(n)
k‚àí1)T |Fk‚àí1
i
=
A1,n
A2,n
AT
2,n
A4,n

,
where, in view of decomposition of M (Œ∏)
n
and M (x)
n
in (41) and (42), respectively,
A1,n = Œ≤‚àí1
n
n
X
k=1
Œ≤2
ke(un‚àíuk)J11

U22+D(1)
k +J(1)
k ‚àí(U21+D(2)
k +J(2)
k )(J12(Œ±)J22(Œ±)‚àí1)T
+ J12(Œ±)J22(Œ±)‚àí1(U11 + D(3)
k
+ J(3)
k )(J12(Œ±)J22(Œ±)‚àí1)T
‚àíJ12(Œ±)J22(Œ±)‚àí1(U21 + D(2)
k
+ J(2)
k )T

e(un‚àíuk)(J11)T ,
(58a)
A2,n = Œ≤‚àí1/2
n
Œ≥‚àí1/2
n
n
X
k=1
Œ≤kŒ≥ke(un‚àíuk)J11(U21 ‚àíJ12(Œ±)J22(Œ±)‚àí1U11)e(sn‚àísk)J22(Œ±)T ,
(58b)
A4,n = Œ≥‚àí1
n
n
X
k=1
Œ≥2
ke(sn‚àísk)J22(Œ±)(U11 + D(3)
k
+ J(3)
k )e(sn‚àísk)J22(Œ±)T .
(58c)
We further decompose A1,n into three parts:
A1,n =Œ≤‚àí1
n
n
X
k=1

Œ≤2
ke(un‚àíuk)J11(U22 ‚àíU21(J12(Œ±)J22(Œ±)‚àí1)T
‚àíJ12(Œ±)J22(Œ±)‚àí1U12 + J12(Œ±)J22(Œ±)‚àí1U11(J12(Œ±)J22(Œ±)‚àí1)T )e(un‚àíuk)(J11)T 
+ Œ≤‚àí1
n
n
X
k=1

Œ≤2
ke(un‚àíuk)J11(D(1)
k
+ J12(Œ±)J22(Œ±)‚àí1D(3)
k (J12(Œ±)J22(Œ±)‚àí1)T
‚àíD(2)
k (J12(Œ±)J22(Œ±)‚àí1)T ‚àíJ12(Œ±)J22(Œ±)‚àí1(D(2)
k )T )e(un‚àíuk)(J11)T 
+ Œ≤‚àí1
n
n
X
k=1

Œ≤2
ke(un‚àíuk)J11(J(1)
k
+ J12(Œ±)J22(Œ±)‚àí1J(3)
k (J12(Œ±)J22(Œ±)‚àí1)T
‚àíJ(2)
k (J12(Œ±)J22(Œ±)‚àí1)T ‚àíJ12(Œ±)J22(Œ±)‚àí1(J(2)
k )T )e(un‚àíuk)(J11)T 
‚âúA(a)
1,n + A(b)
1,n + A(c)
1,n.
(59)
Here,
we define UŒ∏(Œ±)
‚âú
U22 ‚àíU21(J12(Œ±)J22(Œ±)‚àí1)T ‚àíJ12(Œ±)J22(Œ±)‚àí1U12 +
J12(Œ±)J22(Œ±)‚àí1U11(J12(Œ±)J22(Œ±)‚àí1)T . By (52) and (43a) in Lemma E.1, we have
UŒ∏(Œ±) =
N‚àí1
X
i=1
1
(Œ±(1 + Œªi) + 1)2 ¬∑ 1 + Œªi
1 ‚àíŒªi
HT uiuT
i H.
(60)
Then, we have the following lemma.
Lemma E.3. For A(a)
1,n, A(b)
1,n, A(c)
1,n defined in (59), we have
lim
n‚Üí‚àûA(a)
1,n = VŒ∏(Œ±),
lim
n‚Üí‚àû‚à•A(b)
1,n‚à•= 0,
lim
n‚Üí‚àû‚à•A(c)
1,n‚à•= 0,
(61)
where VŒ∏(Œ±) is the solution to the Lyapunov equation

J11 + 1{b=1}
2
I

VŒ∏(Œ±) + VŒ∏(Œ±)

J11 + 1{b=1}
2
I
T
+ UŒ∏(Œ±) = 0.
27

Published as a conference paper at ICLR 2024
Proof. First, from Lemma G.4, we have for some c, T > 0 such that
‚à•A(b)
1,n‚à•‚â§Œ≤‚àí1
n
n
X
k=1
D(1)
k
+ J12(Œ±)J22(Œ±)‚àí1D(3)
k (J12(Œ±)J22(Œ±)‚àí1)T ‚àíD(2)
k (J12(Œ±)J22(Œ±)‚àí1)T
‚àíJ12(Œ±)J22(Œ±)‚àí1(D(2)
k )T
 ¬∑ Œ≤2
kc2e‚àí2T (un‚àíuk).
Applying Lemma G.6, together with D(i)
n ‚Üí0 a.s. in Lemma E.1, gives
lim sup
n
‚à•A(b)
1,n‚à•
‚â§
1
C(b, p) lim sup
n
‚à•(D(1)
n
+ J12(Œ±)J22(Œ±)‚àí1D(4)
n (J12(Œ±)J22(Œ±)‚àí1)T
‚àíD(2)
n (J12(Œ±)J22(Œ±)‚àí1)T ‚àíJ12(Œ±)J22(Œ±)‚àí1D(3)
n )‚à•
= 0.
We now consider ‚à•A(c)
1,n‚à•. Set
Œûn ‚âú
n
X
k=1
 J(1)
n
+ J12(Œ±)J22(Œ±)‚àí1J(3)
k (J12(Œ±)J22(Œ±)‚àí1)T
‚àíJ(2)
k (J12(Œ±)J22(Œ±)‚àí1)T ‚àíJ12(Œ±)J22(Œ±)‚àí1(J(2)
k )T 
,
we can rewrite A(c)
1,n as
A(c)
1,n = Œ≤‚àí1
n
n
X
k=1
Œ≤2
ke(un‚àíuk)J11(Œûk ‚àíŒûk‚àí1)e(un‚àíuk)(J11)T .
By the Abel transformation, we have
A(c)
1,n = Œ≤nŒûn + Œ≤‚àí1
n
n‚àí1
X
k=1
h
Œ≤2
ke(un‚àíuk)J11Œûke(un‚àíuk)(J11)T
‚àíŒ≤2
k+1e(un‚àíuk+1)J11Œûke(un‚àíuk+1)(J11)T i
.
(62)
We know from Lemma E.1 that Œ≤nŒûn ‚Üí0 a.s. because Œûn = o(Œ≥‚àí1
n ). Besides,
‚à•Œ≤ke(un‚àíuk)J11 ‚àíŒ≤k+1e(un‚àíuk+1)J11‚à•
= ‚à•(Œ≤k ‚àíŒ≤k+1)e(un‚àíuk)J11 + Œ≤k+1e(un‚àíuk)J11(I ‚àíe‚àíŒ≤k+1J11)‚à•
‚â§C1Œ≤2
ke‚àí(un‚àíuk)T
for some constant C1 > 0 because Œ≤n ‚àíŒ≤n+1 ‚â§C2Œ≤2
n and ‚à•I ‚àíe‚àíŒ≤k+1J11‚à•‚â§C3Œ≤k+1. Moreover,
‚à•Œ≤ke(un‚àíuk)J11‚à•+ ‚à•Œ≤k+1e(un‚àíuk+1)J11‚à•
‚â§Œ≤k‚à•e(un‚àíuk)J11‚à•+ Œ≤k‚à•e(un‚àíuk)J11‚à•¬∑ ‚à•e‚àíŒ≤k+1J11‚à•
‚â§C4Œ≤ke‚àí(un‚àíuk)T .
Using Lemma G.7 on (62) gives
‚à•A(c)
1,n‚à•‚â§C1C4Œ≤‚àí1
n
n‚àí1
X
k=1
Œ≤2
ke‚àí2(un‚àíuk)T ‚à•Œ≤kŒûk‚à•+ ‚à•Œ≤nŒûn‚à•.
Applying Lemma G.6 again gives
lim sup
n
‚à•A(c)
1,n‚à•‚â§C5 lim sup
n
‚à•Œ≤nŒûn‚à•= 0
for some constant C5 > 0.
Finally, we provide an existing lemma below.
28

Published as a conference paper at ICLR 2024
Lemma E.4 (Mokkadem & Pelletier (2005) Lemma 4). For a sequence with decreasing step size
Œ≤n = (n + 1)‚àíb for b ‚àà(1/2, 1], un = Pn
k=1 Œ≤k, a positive semi-definite matrix Œì and a Hurwitz
matrix Q, which is given by
Œ≤‚àí1
n
n
X
k=1
Œ≤2
ne(un‚àíuk)QŒìe(un‚àíuk)QT ,
we have
lim
n‚Üí‚àûŒ≤‚àí1
n
n
X
k=1
Œ≤2
ne(un‚àíuk)QŒìe(un‚àíuk)QT = V
where V is the solution of the Lyapunov equation

Q + 1{b=1}
2
I

V + V

QT + 1{b=1}
2
I

+ Œì = 0.
Then, limn‚Üí‚àûA(a)
1,n = VŒ∏(Œ±) is a direct application of Lemma E.4.
We can follow the similar steps in Lemma E.3 to obtain
lim
n‚Üí‚àûA4,n = Vx(Œ±),
where Vx(Œ±) is in the form of (32).
The last step is to show limn‚Üí‚àûA2,n = 0. Note that
‚à•A2,n‚à•= O
 
Œ≤‚àí1/2
n
Œ≥‚àí1/2
n
n
X
k=1
Œ≤kŒ≥k‚à•e(un‚àíuk)J11‚à•‚à•e(sn‚àísk)J22(Œ±)T ‚à•
!
= O
 
Œ≤‚àí1/2
n
Œ≥‚àí1/2
n
n
X
k=1
Œ≤kŒ≥ke‚àí(un‚àíuk)T e‚àí(sn‚àísk)T ‚Ä≤
!
= O
 
Œ≤‚àí1/2
n
Œ≥‚àí1/2
n
n
X
k=1
Œ≤kŒ≥ke‚àí(sn‚àísk)T ‚Ä≤
!
,
where the second equality is from Lemma G.4. Then, we use Lemma G.6 with p = 0 to obtain
n
X
k=1
Œ≤kŒ≥ke‚àí(sn‚àísk)T ‚Ä≤ = O(Œ≤n)
(63)
Additionally, since Œ≤n = o(Œ≥n), we have
Œ≤‚àí1/2
n
Œ≥‚àí1/2
n
n
X
k=1
Œ≤kŒ≥‚àí1/2
k
Œ≥3/2
k
e‚àí(sn‚àísk)T ‚Ä≤ = O(Œ≤1/2
n
Œ≥‚àí1/2
n
) = o(1).
Then, it follows that limn‚Üí‚àûA2,n = 0. Therefore, we obtain
lim
n‚Üí‚àû
n
X
k=1
E
h
(Z(n)
k
‚àíZ(n)
k‚àí1)(Z(n)
k
‚àíZ(n)
k‚àí1)T |Fk‚àí1
i
=

VŒ∏(Œ±)
0
0
Vx(Œ±)

.
Now, we turn to verifying the conditions in Theorem G.3. For some œÑ > 0, we have
n
X
k=1
E
h
‚à•Z(n)
k
‚àíZ(n)
k‚àí1‚à•2+œÑ|Fk‚àí1
i
= O
 
Œ≤
‚àí(1+ œÑ
2 )
n
n
X
k=1
Œ≤
2+ œÑ
2
k
Œ≤
œÑ
2
k e‚àí(2+œÑ)(un‚àíuk)T + Œ≥
‚àí(1+ œÑ
2 )
n
n
X
k=1
Œ≥
2+ œÑ
2
k
Œ≥
œÑ
2
k e‚àí(2+œÑ)(sn‚àísk)T ‚Ä≤
!
= O

Œ≤
œÑ
2n + Œ≥
œÑ
2n

(64)
29

Published as a conference paper at ICLR 2024
where the last equality comes from Lemma G.6. Since (64) also holds for œÑ = 0, we have
n
X
k=1
E
h
‚à•Z(n)
k
‚àíZ(n)
k‚àí1‚à•2|Fk‚àí1
i
= O(1) < ‚àû.
Therefore, all the conditions in Theorem G.3 are satisfied and its application then gives
Z(n) =
 p
Œ≤‚àí1
n L(Œ∏)
n
p
Œ≥‚àí1
n L(x)
n
!
n‚Üí‚àû
‚àí‚àí‚àí‚àí‚Üí
dist.
N

0,

VŒ∏(Œ±)
0
0
Vx(Œ±)

.
(65)
Furthermore, we have the following lemma about the strong convergence rate of {L(Œ∏)
n } and {L(x)
n }.
Lemma E.5.
‚à•L(Œ∏)
n ‚à•= O
p
Œ≤n log(un)

a.s.
(66a)
‚à•L(x)
n ‚à•= O
p
Œ≥n log(sn)

a.s.
(66b)
Proof. This proof follows Pelletier (1998, Lemma 1). We only need the special case of Pelletier
(1998, Lemma 1) that fits our scenario; e.g., we let the two types of step sizes therein to be the same.
Specifically, we attach the following lemma.
Lemma E.6 (Pelletier (1998) Lemma 1). Consider a sequence
Ln+1 = eunH
n
X
k=1
e‚àíukHŒ≤kMk+1,
where Œ≤n = n‚àíb, 1/2 < b ‚â§1, and {Mn} is a Martingale difference sequence adapted to the
filtration F such that, almost surely, lim supn E[‚à•Mn+1‚à•2|Fn] ‚â§M 2 and there exists œÑ ‚àà(0, 2),
b(2 + œÑ) > 2, such that supn E[‚à•Mn+1‚à•2+œÑ|Fn] < ‚àû. Then, almost surely,
lim sup
n
‚à•Ln‚à•
p
Œ≤n log(un)
‚â§CM,
(67)
where CM is a constant dependent on M.
By assumption A4, the iterates (Œ∏n, xn) are bounded within a compact subset ‚Ñ¶. Recall the form
of M (Œ∏)
n+1, M (x)
n+1 defined in (35), it comprises the functions ÀúHŒ∏n,xn(i) and (Kxn ÀúHŒ∏n,xn)(i), which
in turn include the function H(Œ∏, i). We know that H(Œ∏, i) is bounded for Œ∏ in some compact set
C. Thus, for any (Œ∏n, xn) ‚àà‚Ñ¶for some compact set ‚Ñ¶, M (Œ∏)
n+1, M (x)
n+1 are bounded and we denote
by cŒ∏ and cx as their upper bounds, i.e., E[‚à•M (Œ∏)
n+1‚à•2|Fn] ‚â§c(Œ∏)
‚Ñ¶
and E[‚à•M (x)
n+1‚à•2|Fn] ‚â§c(x)
‚Ñ¶. We
only need to replace the upper bound c in Lemma E.6 by c(Œ∏)
‚Ñ¶
for the sequence {L(Œ∏)
n } (resp. c(x)
‚Ñ¶
for the sequence {L(x)
n }), i.e.,
lim sup
n
‚à•L(Œ∏)
n ‚à•
p
Œ≤n log(un)
‚â§C(Œ∏)
‚Ñ¶,
(68a)
lim sup
n
‚à•L(x)
n ‚à•
p
Œ≥n log(sn)
‚â§C(x)
‚Ñ¶,
(68b)
such that ‚à•L(Œ∏)
n ‚à•= O(
p
Œ≤n log(un)) a.s. and ‚à•L(x)
n ‚à•= O(
p
Œ≥n log(sn)) a.s. which completes the
proof.
Note that we have xn ‚àí¬µ and L(x)
n
weakly converge to the same Gaussian distribution from Remark
E.1 and (65). Then, Œ≥‚àí1/2
n
‚àÜ(x)
n
weakly converges to zero, implying that Œ≥‚àí1/2
n
‚àÜ(x)
n
converges to
zero with probability 1. Therefore, together with {Œ≥n} being strictly positive, we have
‚àÜ(x)
n
= o(‚àöŒ≥n)
a.s.
(69)
30

Published as a conference paper at ICLR 2024
Characterization of Sequences {R(Œ∏)
n } and {‚àÜ(Œ∏)
n }
We first consider the sequence {R(Œ∏)
n }. We assume a positive real-valued bounded sequence {wn}
under the same conditions as in Mokkadem & Pelletier (2006, Definition 1), i.e.,
Definition E.1. In the case b < 1,
wn
wn+1 = 1 + o(Œ≤n), which also implies
wn
wn+1 = 1 + o(Œ≥n).
In the case b = 1, there exist œµ ‚â•0 and a nondecreasing slowly varying function l(n) such that
wn = n‚àíœµl(n). When œµ = 0, we require function l(n) to be bounded.
Since ‚à•xn ‚àí¬µ‚à•= o(1) by a.s. convergence result, we can assume that there exists {wn} such that
‚à•xn ‚àí¬µ‚à•= O(wn). Then, from (55b), we can use the Abel transformation and obtain
R(Œ∏)
n
= Œ≤nŒ≥‚àí1
n J12(Œ±)J22(Œ±)‚àí1(xn ‚àí¬µ) ‚àíe(un‚àíu1)J11Œ≤1Œ≥‚àí1
1 U11J12(Œ±)J22(Œ±)‚àí1(x1 ‚àí¬µ)
+ eunJ11
n‚àí1
X
k=1
 e‚àíukJ11Œ≤kŒ≥‚àí1
k
‚àíe‚àíuk+1J11Œ≤k+1Œ≥‚àí1
k+1

J12(Œ±)J22(Œ±)‚àí1(xk+1 ‚àí¬µ),
where the last term on the RHS can be rewritten as
Wn =
n‚àí1
X
k=1
e(un‚àíuk+1)J11Œ≤k+1Œ≥‚àí1
k+1
 eŒ≤k+1J11Œ≤kŒ≤‚àí1
k+1Œ≥‚àí1
k Œ≥k+1 ‚àíI

J12(Œ±)J22(Œ±)‚àí1(xk+1 ‚àí¬µ).
Using Lemma G.6 on Wn gives ‚à•Wn‚à•= O(Œ≥‚àí1
n ‚à•eŒ≤nJ11 ‚àíI‚à•‚à•xn ‚àí¬µ‚à•) = O(Œ≥‚àí1
n Œ≤nœân). Then,
it follows that for some T > 0,
‚à•R(Œ∏)
n ‚à•= O
 Œ≤nŒ≥‚àí1
n œân + ‚à•eunJ11‚à•

= O(Œ≤nŒ≥‚àí1
n œân + e‚àíunT )
(70)
with the application of Lemma G.4 to the second equality.
Then, we shift our focus on {‚àÜ(Œ∏)
n }. Specifically, we take (54), (55a), and (56) back to ‚àÜ(Œ∏)
n
=
Œ∏n ‚àíŒ∏‚àó‚àíL(Œ∏)
n
‚àíR(Œ∏)
n , and obtain
‚àÜ(Œ∏)
n+1 =(I + Œ≤n+1J11)(Œ∏n ‚àíŒ∏‚àó)
+ Œ≤n+1(r(Œ∏,1)
n
+ r(Œ∏,2)
n
+ Œ∑(Œ∏)
n
‚àíJ12(Œ±)J22(Œ±)‚àí1(r(x,1)
n
+ r(x,2)
n
+ Œ∑(x)
n ))
‚àíeŒ≤n+1J11L(Œ∏)
n
‚àíeŒ≤n+1J11R(Œ∏)
n
=(I + Œ≤n+1J11)(Œ∏n ‚àíŒ∏‚àó)
+ Œ≤n+1(r(Œ∏,1)
n
+ r(Œ∏,2)
n
+ Œ∑(Œ∏)
n
‚àíJ12(Œ±)J22(Œ±)‚àí1(r(x,1)
n
+ r(x,2)
n
+ Œ∑(x)
n ))
‚àí(I + Œ≤n+1J11 + O(Œ≤2
n+1))L(Œ∏)
n
‚àí(I + Œ≤n+1J11 + O(Œ≤2
n+1))R(Œ∏)
n
=(I + Œ≤n+1J11)‚àÜ(Œ∏)
n
+ O(Œ≤2
n+1)(L(Œ∏)
n
+ R(Œ∏))
n
)
+ Œ≤n+1(r(Œ∏,1)
n
+ r(Œ∏,2)
n
+ Œ∑(Œ∏)
n
‚àíJ12(Œ±)J22(Œ±)‚àí1(r(x,1)
n
+ r(x,2)
n
+ Œ∑(x)
n )),
(71)
where the second equality is by taking the Taylor expansion eŒ≤n+1J11 = I + Œ≤n+1J11 + O(Œ≤2
n+1).
Define Œ¶k,n ‚âúQn
j=k+1(I + Œ≤jJ11) and by convention Œ¶n,n = I. Then, we rewrite (71) as
‚àÜ(Œ∏)
n+1 =
n
X
k=1
Œ¶k,nŒ≤k+1

O(Œ≤k+1)L(Œ∏)
k
+ O(Œ≤k+1)R(Œ∏)
k

+
n
X
k=1
Œ¶k,nŒ≤k+1(r(Œ∏,1)
k
+ r(Œ∏,2)
k
+ Œ∑(Œ∏)
k
‚àíJ12(Œ±)J22(Œ±)‚àí1(r(x,1)
k
+ r(x,2)
k
+ Œ∑(x)
k ))
=
n
X
k=1
Œ¶k,nŒ≤k+1

O(Œ≤k+1)L(Œ∏)
k
+ O(Œ≤k+1)R(Œ∏)
k

+
n
X
k=1
Œ¶k,nŒ≤k+1(r(Œ∏,1)
k
+ Œ∑(Œ∏)
k
‚àíJ12(Œ±)J22(Œ±)‚àí1(r(x,1)
k
+ Œ∑(x)
k ))
+
n
X
k=1
Œ¶k,nŒ≤k+1(r(Œ∏,2)
k
‚àíJ12(Œ±)J22(Œ±)‚àí1r(x,2)
k
).
(72)
31

Published as a conference paper at ICLR 2024
From (72), we can indeed decompose ‚àÜ(x)
n+1 into two parts ‚àÜ(Œ∏)
n+1 = ‚àÜ(Œ∏,1)
n+1 + ‚àÜ(Œ∏,2)
n+1 , where
‚àÜ(Œ∏,1)
n+1 ‚âú
n
X
k=1
Œ¶k,nŒ≤k+1

O(Œ≤k+1)L(Œ∏)
k
+ O(Œ≤k+1)R(Œ∏)
k

+
n
X
k=1
Œ¶k,nŒ≤k+1(r(Œ∏,1)
k
+ Œ∑(Œ∏)
k
‚àíJ12(Œ±)J22(Œ±)‚àí1(r(x,1)
k
+ Œ∑(x)
k )),
(73a)
‚àÜ(Œ∏,2)
n+1 ‚âú
n
X
k=1
Œ¶k,nŒ≤k+1(r(Œ∏,2)
k
‚àíJ12(Œ±)J22(Œ±)‚àí1r(x,2)
k
).
(73b)
This term ‚àÜ(Œ∏,1)
n+1 shares the same recursive form as in the sequence defined in Mokkadem & Pelletier
(2006, Lemma 6), which is given below.
Lemma E.7 (Mokkadem & Pelletier (2006) Lemma 6). For ‚àÜ(Œ∏,1)
n+1 in the form of (73a), assume
‚à•xn ‚àí¬µ‚à•= O(œân) and ‚à•‚àÜ(x)
n ‚à•= O(Œ¥n) for the sequences œân, Œ¥n defined in (E.1). Then, we have
‚à•‚àÜ(Œ∏,1)
n+1 ‚à•= O(Œ≤2
nŒ≥‚àí2
n œâ2
n + Œ≤nŒ≥‚àí1
n Œ¥n) + o(
p
Œ≤n)
a.s.
Since we already have ‚àÜ(x)
n
= o(‚àöŒ≥n) in (69), together with Lemma E.7, we have
‚à•‚àÜ(Œ∏,1)
n+1 ‚à•= O(Œ≤2
nŒ≥‚àí2
n œâ2
n) + o(Œ≤nŒ≥‚àí1/2
n
) + o(
p
Œ≤n) = O(Œ≤2
nŒ≥‚àí2
n œâ2
n) + o(
p
Œ≤n)
where the second equality comes from o(Œ≤nŒ≥‚àí1/2
n
) = o(Œ≤1/2
n
(Œ≤nŒ≥‚àí1
n )1/2) = o(Œ≤1/2
n
).
We now focus on ‚àÜ(Œ∏,2)
n+1 . Define a sequence
Œ®n ‚âú
n
X
k=1
r(Œ∏,2)
k
‚àíJ12(Œ±)J22(Œ±)‚àí1r(x,2)
k
,
(74)
and we have
Œ≤‚àí1/2
n+1
n
X
k=1
Œ¶k,nŒ≤k+1(r(Œ∏,2)
k
‚àíJ12(Œ±)J22(Œ±)‚àí1r(x,2)
k
)
=Œ≤‚àí1/2
n+1
n
X
k=1
Œ¶k,nŒ≤k+1(Œ®k ‚àíŒ®k‚àí1)
=Œ≤1/2
n+1Œ®n + Œ≤‚àí1/2
n+1
n‚àí1
X
k=1
(Œ≤kŒ¶k,n ‚àíŒ≤k+1Œ¶k+1,n)Œ®k
where the last equality comes from the Abel transformation. Note that
‚à•Œ≤kŒ¶k,n ‚àíŒ≤k+1Œ¶k+1,n‚à•‚â§Œ≤k+1‚à•Œ¶k,n ‚àíŒ¶k+1,n‚à•+ (Œ≤k ‚àíŒ≤k+1)‚à•Œ¶k,n‚à•
‚â§Œ≤k+1‚à•Œ¶k+1,n‚à•Œ≤k‚à•J11‚à•+ C7Œ≤2
k‚à•Œ¶k,n‚à•
‚â§C8Œ≤2
ke‚àí(un‚àíuk)T
for some constant C7, C8 > 0, where the last inequality is from Lemma G.4 and ‚à•Œ¶k+1,n‚à•‚â§
C9‚à•Œ¶k,n‚à•for some constant C9 > 0 that depends on eŒ≤0T . Then,
Œ≤‚àí1/2
n+1

n
X
k=1
Œ¶k,nŒ≤k+1(r(Œ∏,2)
k
‚àíJ12(Œ±)J22(Œ±)‚àí1r(x,2)
k
)

‚â§‚à•Œ≤1/2
n+1Œ®n‚à•+
Œ≤n+1
Œ≤n
1/2
Œ≤‚àí1/2
n
n
X
k=1
‚à•Œ≤kŒ¶k,n ‚àíŒ≤k+1Œ¶k+1,n‚à•‚à•Œ®k‚à•
‚â§‚à•Œ≤1/2
n+1Œ®n‚à•+ C8
Œ≤n+1
Œ≤n
1/2
Œ≤‚àí1/2
n
n
X
k=1
Œ≤3/2
k
e‚àí(un‚àíuk)T ‚à•Œ≤1/2
k
Œ®k‚à•.
32

Published as a conference paper at ICLR 2024
By Lemma E.1, we have Œ≤1/2
n
Œ®n ‚Üí0 a.s. such that by Lemma G.6, it follows that
lim sup
n
Œ≤‚àí1/2
n+1

n
X
k=1
Œ¶k,nŒ≤k+1(r(Œ∏,2)
k
‚àíJ12(Œ±)J22(Œ±)‚àí1r(x,2)
k
)
 ‚â§lim supn ‚à•Œ≤1/2
n
Œ®n‚à•
C(T, 1/2)
= 0.
Therefore, we have
‚àÜ(Œ∏,2)
n+1 =
n
X
k=1
Œ¶k,nŒ≤k+1(r(Œ∏,2)
k
‚àíJ12(Œ±)J22(Œ±)‚àí1r(x,2)
k
) = o(
p
Œ≤n).
(75)
Consequently, ‚àÜ(Œ∏)
n+1 = O(Œ≤2
nŒ≥‚àí2
n œâ2
n) + o(‚àöŒ≤n) almost surely.
Now we are dealing with xn ‚àí¬µ and its related sequence œân. Note that by Lemma E.5 and (69),
we have almost surely,
‚à•xn ‚àí¬µ‚à•= O(‚à•L(x)
n ‚à•+ ‚à•‚àÜx
n‚à•)
= O(
p
Œ≥n log(sn) + o(‚àöŒ≥n))
= O(
p
Œ≥n log(sn)).
(76)
Thus, we can set œân ‚â°O(
p
Œ≥n log(sn)) such that ‚à•R(Œ∏)
n ‚à•in (70) can be written as
‚à•R(Œ∏)
n ‚à•= O(na/2‚àíbp
log(sn) + e‚àíunT ),
and
‚à•‚àÜ(Œ∏)
n+1‚à•= O(na‚àí2blog(sn)) + o(
p
Œ≤n).
In view of assumption A2 and Œ≤n = o(Œ≥n), a/2‚àíb < ‚àíb/2 and a‚àí2b < ‚àíb, there exists a c > b/2
such that almost surely,
‚à•R(Œ∏)
n ‚à•= O(n‚àís),
‚à•‚àÜ(Œ∏)
n+1‚à•= o(
p
Œ≤n).
Therefore, Œ≤‚àí1/2
n
(R(Œ∏)
n
+ ‚àÜ(Œ∏)
n+1) ‚Üí0 almost surely. This completes the proof of Scenario 2.
E.3
CASE (III): Œ≥n = o(Œ≤n)
For Œ≥n = o(Œ≤n), we can see that the roles of Œ∏n and xn are flipped, i.e., Œ∏n is now on fast timescale
while xn is on slow timescale.
We still decompose xn as xn ‚àí¬µ = L(x)
n
+ ‚àÜ(x)
n , where L(x)
n , ‚àÜ(x)
n
are defined in (56) and (57),
respectively. Since xn is independent of Œ∏n, the results of L(x)
n
and ‚àÜ(x)
n
remain the same, i.e.,
almost surely, L(x)
n
= O(
p
Œ≥n log(sn)) from Lemma E.5 and ‚àÜ(x)
n
= o(‚àöŒ≥n) from (69). Then, we
define sequences ÀÜL(Œ∏)
n
and ÀÜR(Œ∏)
n
as follows.
ÀÜL(Œ∏)
n
‚âúeŒ≤nJ11 ÀÜL(Œ∏)
n‚àí1 + Œ≤nM (Œ∏)
n
=
n
X
k=1
e(un‚àíuk)J11Œ≤kM (Œ∏)
k
,
(77a)
ÀÜR(Œ∏)
n
‚âúeŒ≤nJ11 ÀÜR(Œ∏)
n‚àí1 + Œ≤nJ12(Œ±)(L(x)
n‚àí1 + R(x)
n‚àí1) =
n
X
k=1
e(un‚àíuk)J11Œ≤kJ12(Œ±)(L(x)
k‚àí1 + R(x)
k‚àí1).
(77b)
Moreover, the remaining term ÀÜ‚àÜ(Œ∏)
n
‚âúŒ∏n ‚àíŒ∏‚àó‚àíÀÜL(Œ∏)
n
‚àíÀÜR(Œ∏)
n .
The proof outline is the same as in the previous scenario:
‚Ä¢ We first show Œ≤‚àí1/2
n
ÀÜ‚àÜ(Œ∏)
n
weakly converges to the distribution N(0, V(3)
Œ∏ )(Œ±);
‚Ä¢ We analyse ÀÜL(Œ∏)
n
and ÀÜR(Œ∏)
n
to ensure that these two terms decrease faster than the CLT scale
Œ≤‚àí1/2
n
, i.e., limn‚Üí‚àûŒ≤‚àí1/2
n
(ÀÜL(Œ∏)
n
‚àíÀÜR(Œ∏)
n ) = 0;
33

Published as a conference paper at ICLR 2024
‚Ä¢ With above two steps, we can show that Œ≤‚àí1/2
n
(Œ∏n ‚àíŒ∏‚àó) weakly converges to the distribu-
tion N(0, V(3)
Œ∏ )(Œ±).
Analysis of ÀÜL(Œ∏)
n
We first focus on ÀÜL(Œ∏)
n
and follow similar steps as we did when we analysed L(Œ∏)
n
in the previous
scenario. We set a Martingale Z(n) = {Z(n)
k
}k‚â•1 such that
Z(n)
k
= Œ≤‚àí1/2
n
n
X
k=1
e(un‚àíuk)J11Œ≤kM (Œ∏)
k .
Then,
An ‚âú
n
X
k=1
E
h
(Z(n)
k
‚àíZ(n)
k‚àí1)(Z(n)
k
‚àíZ(n)
k‚àí1)T  Fk‚àí1
i
.
Following the similar steps in (59) to decompose M (Œ∏)
k
with (42b), we have
An = Œ≤‚àí1
n
n
X
k=1
Œ≤2
ke(un‚àíuk)J11 
U11 + D(3)
k
+ J(3)
k

e(un‚àíuk)JT
11
= Œ≤‚àí1
n
n
X
k=1
Œ≤2
ke(un‚àíuk)J11U11e(un‚àíuk)JT
11
|
{z
}
A(a)
n
+ Œ≤‚àí1
n
n
X
k=1
Œ≤2
ke(un‚àíuk)J11D(3)
k e(un‚àíuk)JT
11
|
{z
}
A(b)
n
+ Œ≤‚àí1
n
n
X
k=1
Œ≤2
ke(un‚àíuk)J11J(3)
k e(un‚àíuk)JT
11
|
{z
}
A(c)
n
(78)
Since A(a)
n , A(b)
n , A(c)
n
share similar forms as in Lemma E.3, we follow the same steps as the proof
therein, with the application of Lemma E.1. To avoid repetition, we omit the proof and directly give
the following lemma.
Lemma E.8. For A(a)
n , A(b)
n , A(c)
n defined in (78), we have
lim
n‚Üí‚àûA(a)
n
= V(3)
Œ∏ (Œ±),
lim
n‚Üí‚àû‚à•A(b)
n ‚à•= 0,
lim
n‚Üí‚àû‚à•A(c)
n ‚à•= 0,
(79)
where V(3)
Œ∏ (Œ±) is the solution to the Lyapunov equation
J11V + VJT
11 + U11 = 0.
Note that here we don‚Äôt have the term
1{b=1}
2
I in above lemma, compared to Lemma E.3, because
in the case of Œ≥n = o(Œ≤n), b < 1 such that 1{b=1} = 0. Then, applying Lemma G.1 to derive the
closed form of V(3)
Œ∏ (Œ±) gives
V(3)
Œ∏ (Œ±) =
R ‚àû
0
et‚àáŒ∏h(Œ∏‚àó)U11et‚àáŒ∏h(Œ∏‚àó)dt.
Thus, it follows that
lim
n‚Üí‚àû
n
X
k=1
E
h
(Z(n)
k
‚àíZ(n)
k‚àí1)(Z(n)
k
‚àíZ(n)
k‚àí1)T |Fk‚àí1
i
= V(3)
Œ∏ (Œ±).
Again, we use the Martingale CLT result in Theorem G.3 and have the following result.
Zn = Œ≤‚àí1/2
n
ÀÜL(Œ∏)
n
n‚Üí‚àû
‚àí‚àí‚àí‚àí‚Üí
dist.
N

0, V(3)
Œ∏ (Œ±)

.
Moreover, similar to the tighter upper bound of L(x)
n
proved in Lemma E.5, we utilize the tighter
upper bound Lemma E.6 in the proof thereof, and obtain ÀÜL(Œ∏)
n
= O(
p
Œ≤n log(un)).
34

Published as a conference paper at ICLR 2024
Analysis of ÀÜR(Œ∏)
n
Next, we turn to the term ÀÜR(Œ∏)
n
in (77b). Taking the norm gives the following inequality for some
constant C, T > 0 by applying Lemma G.4,
‚à•ÀÜR(Œ∏)
n ‚à•‚â§C
n
X
k=1
e‚àí(un‚àíuk)T Œ≤k(‚à•L(x)
k‚àí1‚à•+ ‚à•R(x)
k‚àí1‚à•).
Using Lemma G.6 gives
n
X
k=1
e‚àí(un‚àíuk)T Œ≤k(‚à•L(x)
k‚àí1‚à•+ ‚à•R(x)
k‚àí1‚à•) = O(‚à•L(x)
k‚àí1‚à•+ ‚à•R(x)
n‚àí1‚à•).
Thus, Œ≤‚àí1/2
n
‚à•ÀÜR(Œ∏)
n ‚à•= o(
p
Œ≥nŒ≤‚àí1
n ) + O
q
Œ≥nŒ≤‚àí1
n log(sn)

. Since Œ≥n = o(Œ≤n), Œ≥nŒ≤‚àí1
n
= (n +
1)b‚àía, where b ‚àía < 0. Then, there exists some s > 0 such that b ‚àía < ‚àís < 0. Together with
log(sn) = O(log(n)), we have O
q
Œ≥nŒ≤‚àí1
n log(sn)

= O(
p
n‚àís log(n)) = o(1). Therefore, we
have
lim
n‚Üí‚àûŒ≤‚àí1/2
n
ÀÜR(Œ∏)
n
= 0.
Analysis of ÀÜ‚àÜ(Œ∏)
n
Lastly, let‚Äôs focus on the term ÀÜ‚àÜ(Œ∏)
n . We have
ÀÜ‚àÜ(Œ∏)
n+1 = Œ∏n+1 ‚àíŒ∏‚àó‚àíÀÜL(Œ∏)
n+1 ‚àíÀÜR(Œ∏)
n+1
= Œ∏n ‚àíŒ∏‚àó+ Œ≤n+1

J11(Œ∏n ‚àíŒ∏‚àó) + J12(Œ±)(xn ‚àí¬µ) + M (Œ∏)
n+1 + r(Œ∏,1)
n
+ r(Œ∏,2)
n
+ Œ∑(Œ∏)
n

‚àíeŒ≤n+1J11 ÀÜL(Œ∏)
n
‚àíŒ≤n+1M (Œ∏)
n+1 ‚àíeŒ≤n+1J11 ÀÜR(Œ∏)
n
‚àíŒ≤n+1J12(Œ±)(L(x)
n
+ R(x)
n )
= (I + Œ≤n+1J11)(Œ∏n ‚àíŒ∏‚àó) + Œ≤n+1J12(Œ±)‚àÜ(x)
n
+ Œ≤n+1(r(Œ∏,1)
n
+ r(Œ∏,2)
n
+ Œ∑(Œ∏)
n )
‚àí(I + Œ≤n+1J11 + O(Œ≤2
n+1))(ÀÜL(Œ∏)
n
+ ÀÜR(Œ∏)
n )
= (I + Œ≤n+1J11) ÀÜ‚àÜ(Œ∏)
n
+ Œ≤n+1J12(Œ±)‚àÜ(x)
n
+ Œ≤n+1(r(Œ∏,1)
n
+ r(Œ∏,2)
n
+ Œ∑(Œ∏)
n )
+ O(Œ≤2
n+1)(ÀÜL(Œ∏)
n
+ ÀÜR(Œ∏)
n ).
where the second equality is from (53a), the third equality stems from the approximation of eŒ≤n+1J11.
Then, we again use the definition Œ¶k,n ‚âúQn
j=k+1(I + Œ≤jJ11) and reiterate the above equation as
ÀÜ‚àÜ(Œ∏)
n+1 =
n
X
k=1
Œ¶k,nŒ≤k+1

O(Œ≤k+1)L(Œ∏)
k
+ O(Œ≤k+1)R(Œ∏)
k

+
n
X
k=1
Œ¶k,nŒ≤k+1J12(Œ±)‚àÜ(x)
n
+
n
X
k=1
Œ¶k,nŒ≤k+1(r(Œ∏,1)
k
+ Œ∑(Œ∏)
k )
+
n
X
k=1
Œ¶k,nŒ≤k+1r(Œ∏,2)
k
‚âúÀÜ‚àÜ(Œ∏,1)
n+1 + ÀÜ‚àÜ(Œ∏,2)
n+1 ,
where ÀÜ‚àÜ(Œ∏,2)
n+1 = Pn
k=1 Œ¶k,nŒ≤k+1r(Œ∏,2)
k
and
ÀÜ‚àÜ(Œ∏,1)
n+1 =
n
X
k=1
Œ¶k,nŒ≤k+1

O(Œ≤k+1)L(Œ∏)
k
+ O(Œ≤k+1)R(Œ∏)
k

+
n
X
k=1
Œ¶k,nŒ≤k+1(r(Œ∏,1)
k
+ Œ∑(Œ∏)
k
+ J12(Œ±)‚àÜ(x)
n ).
(80)
35

Published as a conference paper at ICLR 2024
For ÀÜ‚àÜ(Œ∏,2)
n+1 , we follow the same steps from (74) to (75), and obtain ÀÜ‚àÜ(Œ∏,2)
n+1 = o(‚àöŒ≤n).
Next, we consider ÀÜ‚àÜ(Œ∏,1)
n+1 and want to show that ÀÜ‚àÜ(Œ∏,1)
n+1 = o(‚àöŒ≤n). Again, we utilize Mokkadem &
Pelletier (2006, Lemma 6) for ÀÜ‚àÜ(Œ∏,1)
n+1 and adapt the notation here for the case Œ≥n = o(Œ≤n).
Lemma E.9. For ÀÜ‚àÜ(Œ∏,1)
n+1 in the form of (80), assume ‚à•Œ∏n ‚àíŒ∏‚àó‚à•= O(œân) and ‚à•ÀÜ‚àÜ(Œ∏,1)
n
‚à•= O(Œ¥n)
for the sequences œân, Œ¥n defined in (E.1). Then, we have
‚à•ÀÜ‚àÜ(Œ∏,1)
n+1 ‚à•= O(Œ≥2
nŒ≤‚àí2
n œâ2
n + Œ≥nŒ≤‚àí1
n Œ¥n) + o(‚àöŒ≥n)
a.s.
(81)
Now we need to further analyse Œ¥n and tighten its big O form, starting from Œ¥n ‚â°1, so that we
can finally obtain the big O form of ‚à•ÀÜ‚àÜ(Œ∏,1)
n+1 ‚à•. The following steps are borrowed from the ideas in
Mokkadem & Pelletier (2006, Section 2.3.2).
By almost sure convergence result limn‚Üí‚àûŒ∏n = Œ∏‚àó, we have limn‚Üí‚àû‚àÜ(Œ∏)
n
= 0 a.s. such that we
can first set Œ¥n ‚â°1, and ‚à•ÀÜ‚àÜ(Œ∏,1)
n+1 ‚à•= O(Œ≥2
nŒ≤‚àí2
n œâ2
n + Œ≥nŒ≤‚àí1
n ) + o(‚àöŒ≥n). Then, we redefine
Œ¥n ‚â°O(Œ≥2
nŒ≤‚àí2
n œâ2
n + Œ≥nŒ≤‚àí1
n ) + o(‚àöŒ≥n),
and notice that it still satisfies definition E.1. Then, reapplying this Œ¥n form to (81) gives
‚à•ÀÜ‚àÜ(Œ∏,1)
n+1 ‚à•= O(Œ≥2
nŒ≤‚àí2
n œâ2
n + [Œ≥nŒ≤‚àí1
n ]2) + o(‚àöŒ≥n)
and by induction we have for all integers k ‚â•1,
‚à•ÀÜ‚àÜ(Œ∏,1)
n+1 ‚à•= O(Œ≥2
nŒ≤‚àí2
n œâ2
n + [Œ≥nŒ≤‚àí1
n ]k) + o(‚àöŒ≥n).
Since [Œ≥nŒ≤‚àí1
n ]k = n(b‚àía)k, there exists k0 > a/2(a ‚àíb) such that [Œ≥nŒ≤‚àí1
n ]k0 = o(‚àöŒ≥n), and
‚à•ÀÜ‚àÜ(Œ∏,1)
n+1 ‚à•= O(Œ≥2
nŒ≤‚àí2
n œâ2
n) + o(‚àöŒ≥n).
(82)
Then, as suggested in Mokkadem & Pelletier (2006, Section 2.3.2), we can choose œân
=
O(
p
Œ≤n log(un) + [Œ≥nŒ≤‚àí1
n ]k), which also satisfies definition E.1. Then,
‚à•Œ∏n ‚àíŒ∏‚àó‚à•= ‚à•ÀÜL(Œ∏)
n
+ ÀÜR(Œ∏)
n
+ ÀÜ‚àÜ(Œ∏)
n ‚à•
=O
p
Œ≤n log(un)+
q
Œ≥nŒ≤‚àí1
n log(sn)+

[Œ≥nŒ≤‚àí1
n ]k+1+Œ≥nŒ≤‚àí1
n
p
Œ≤n log(un)
2
+ o(
p
Œ≤n + ‚àöŒ≥n)
=O(
p
Œ≤n log(un) + [Œ≥nŒ≤‚àí1
n ]k+1).
By induction, this holds for all k ‚â•1 such that there exists k0, [Œ≥nŒ≤‚àí1
n ]k0 = o(‚àöŒ≤n) and ‚à•Œ∏n ‚àí
Œ∏‚àó‚à•= O(
p
Œ≤n log(un)). Equivalently, œân =
p
Œ≤n log(un). Therefore, from (82) we have
‚à•ÀÜ‚àÜ(Œ∏,1)
n+1 ‚à•= O(Œ≥2
nŒ≤‚àí1
n log(un)) + o(‚àöŒ≥n) = o(‚àöŒ≥n).
Together with ‚à•ÀÜ‚àÜ(Œ∏,2)
n+1 ‚à•= o(‚àöŒ≤n), we have Œ≤‚àí1/2
n
‚à•ÀÜ‚àÜ(Œ∏)
n+1‚à•= o(
p
Œ≥nŒ≤‚àí1
n ) + 1) such that
lim
n‚Üí‚àûŒ≤‚àí1/2
n
ÀÜ‚àÜ(Œ∏)
n+1 = 0.
Thus, we have finished the proof according to the proof outline mentioned at the beginning of this
part.
F
DISCUSSION OF COVARIANCE ORDERING OF SA-SRRW
F.1
PROOF OF PROPOSITION 3.4
For any Œ± > 0 and any vector x ‚ààRd, we have
xT V(1)
Œ∏ (Œ±)x =
Z ‚àû
0
xT et(‚àáŒ∏h(Œ∏‚àó)+
1{b=1}
2
I)UŒ∏(Œ±)et(‚àáŒ∏h(Œ∏‚àó)+
1{b=1}
2
I)T x dt
36

Published as a conference paper at ICLR 2024
where the first equality is from the form of V(1)
Œ∏ (Œ±) in Theorem 3.3. Let y ‚âúet(‚àáŒ∏h(Œ∏‚àó)+
1{b=1}
2
I)x,
with the dependence on variable t left implicit. The matrix UŒ∏(Œ±), given explicitly in (11) positive
semi definite, since Œªi ‚àà(‚àí1, 1) for all i ‚àà{1, ¬∑ ¬∑ ¬∑ , N ‚àí1}. Thus, the terms yT UŒ∏(Œ±)y inside the
integral are non-negative, and it is enough to provide an ordering on yT UŒ∏(Œ±)y with respect to Œ±.
For any Œ±2 > Œ±1 > 0,
yT UŒ∏(Œ±2)y =
N‚àí1
X
i=1
1
(Œ±2(1 + Œªi) + 1)2 ¬∑ 1 + Œªi
1 ‚àíŒªi
yT HT uiuT
i Hy
<
N‚àí1
X
i=1
1
(Œ±1(1 + Œªi) + 1)2 ¬∑ 1 + Œªi
1 ‚àíŒªi
yT HT uiuT
i Hy = yT UŒ∏(Œ±1)y
<
N‚àí1
X
i=1
¬∑1 + Œªi
1 ‚àíŒªi
yT HT uiuT
i Hy = yT UŒ∏(0)y,
where the inequality13 is because Œ±(1 + Œªi) > 0 for all i ‚àà{1, ¬∑ ¬∑ ¬∑ , N} and any Œ± > 0. In fact,
the ordering is monotone in Œ±, and yT UŒ∏(Œ±2)y decreases at rate 1/Œ±2 as seen form its form in the
equation above. This completes the proof.
F.2
DISCUSSION REGARDING PROPOSITION 3.4 AND MSE ORDERING
We can use Proposition 3.4 to show that the MSE of SA iterates of (4c) driven by SRRW eventually
becomes smaller than that SA iterates when the stochastic noise is driven by an i.i.d. sequence of ran-
dom variables. The diagonal entries of V(1)
Œ∏ (Œ±) are obtained by evaluating eT
i V(1)
Œ∏ (Œ±)ei, where ei is
the i‚Äôth standard basis vector.14 These diagonal entries are the asymptotic variance corresponding to
the element-wise iterate errors, and for large enough n, we have eT
i V(1)
Œ∏ (Œ±)ei ‚âàE[(Œ∏n ‚àíŒ∏‚àó)2
i ]/Œ≤n
for all i ‚àà{1, ¬∑ ¬∑ ¬∑ , D}. Thus, the trace of matrix V(1)
Œ∏ (Œ±) approximates the scaled MSE, that is
Tr(V(1)
Œ∏ (Œ±)) = P
i eT
i V(1)
Œ∏ (Œ±)ei ‚âàP
i E[(Œ∏n ‚àíŒ∏‚àó)2
i ]/Œ≤n = E[‚à•Œ∏n ‚àíŒ∏‚àó‚à•2]/Œ≤n for large n. Since
all entries of V(1)
Œ∏ (Œ±) go to zero as Œ± increases, they get smaller than the corresponding term for the
SA algorithm with i.i.d. input for large enough Œ±, which achieves a constant MSE in the similarly
scaled limit, since the asymptotic covariance is not a function of Œ±. Moreover, the value of Œ± only
needs to be moderately large, since the asymptotic covariance terms decrease at rate O(1/Œ±2) as
shown in Proposition 3.4.
F.3
PROOF OF COROLLARY 3.5
We see that V(3)
Œ∏ (Œ±) = V(3)
Œ∏ (0) for all Œ± > 0, because the form of V(3)
Œ∏ (Œ±) in Theorem 3.3 is
independent of Œ±. To prove that V(1)
Œ∏ (Œ±) <L V(3)
Œ∏ (0), it is enough to show that V(1)
Œ∏ (0) = V(3)
Œ∏ (0),
since V(1)
Œ∏ (Œ±) <L V(1)
Œ∏ (0) from Proposition 3.4. This is easily checked by substituting Œ± = 0 in 11,
for which UŒ∏(0) = U11. Substituting in the respective forms of V(1)
Œ∏ (0) and V(3)
Œ∏ (0) in Theorem
3.3, we get equivalence. This completes the proof.
G
BACKGROUND THEORY
G.1
TECHNICAL LEMMAS
Lemma G.1 (Solution to the Lyapunov Equation). If all the eigenvalues of matrix M have negative
real part, then for every positive semi-definite matrix U there exists a unique positive semi-definite
13The inequality may not be strict when H is low rank, however it will always be true for some choice of x,
since H is not a zero matrix. Thus, the ordering derived still follows our definition of <L in Section 1, footnote
6.
14D-dimensional vector of all zeros except at the i‚Äôth position which is 1.
37

Published as a conference paper at ICLR 2024
matrix V satisfying the Lyapunov equation U+MV+VMT = 0. The explicit solution V is given
as
V =
Z ‚àû
0
eMtUe(MT )tdt.
(83)
Chellaboina & Haddad (2008, Theorem 3.16) states that for a positive definite matrix U, there exists
a positive definite matrix V. The reason they focus on the positive definite matrix U is that they
require the related autonomous ODE system to be asymptotically stable. However, in this paper we
don‚Äôt need this requirement. The same steps therein can be used to prove Lemma G.1 and show that
if U is positive semi-definite, then V in the form of (83) is unique and also positive semi-definite.
Lemma G.2 (Burkholder Inequality, Davis (1970), Hall et al. (2014) Theorem 2.10). Given a Mar-
tingale difference sequence {Mi,n}n
i=1, for p ‚â•1 and some positive constant Cp, we have
E
"
n
X
i=1
Mi,n

p#
‚â§CpE
Ô£Æ
Ô£∞
 n
X
i=1
‚à•Mi,n‚à•2
!p/2Ô£π
Ô£ª
(84)
Theorem G.3 (Martingale CLT, Delyon (2000) Theorem 30). If a Martingale difference array
{Xn,i} satisfies the following condition: for some œÑ > 0,
n
X
k=1
E

‚à•Xn,k‚à•2+œÑ|Fk‚àí1
 P‚àí‚Üí0,
(85)
sup
n
n
X
k=1
E

‚à•Xn,k‚à•2|Fk‚àí1

< ‚àû,
(86)
and
n
X
k=1
E

Xn,kXT
n,k|Fk‚àí1
 P‚àí‚ÜíV ,
(87)
then
n
X
i=1
Xn,i
dist.
‚àí‚àí‚àí‚ÜíN(0, V ).
(88)
Lemma G.4 (Duflo (1996) Proposition 3.I.2). For a Hurwitz matrix H, there exist some positive
constants C, b such that for any n,
eHn ‚â§Ce‚àíbn.
(89)
Lemma G.5 (Fort (2015) Lemma 5.8). For a Hurwitz matrix A, denote by ‚àír, r > 0, the largest
real part of its eigenvalues. Let a positive sequence {Œ≥n} such that limn Œ≥n = 0. Then for any
0 < r‚Ä≤ < r, there exists a positive constant C such that for any k < n,

n
Y
j=k
(I + Œ≥jA)

‚â§Ce‚àír‚Ä≤ Pn
j=k Œ≥j.
(90)
Lemma G.6 (Fort (2015) Lemma 5.9, Mokkadem & Pelletier (2006) Lemma 10). Let {Œ≥n} be a
positive sequence such that limn Œ≥n = 0 and P
n Œ≥n = ‚àû. Let {œµn, n ‚â•0} be a nonnegative
sequence. Then, for b > 0, p ‚â•0,
lim sup
n
Œ≥‚àíp
n
n
X
k=1
Œ≥p+1
k
e‚àíb Pn
j=k+1 Œ≥jœµk ‚â§
1
C(b, p) lim sup
n
œµn
(91)
for some constant C(b, p) > 0.
When p = 0 and define a positive sequence {wn} satisfying wn‚àí1/wn = 1 + o(Œ≥n), we have
n
X
k=1
Œ≥ke‚àíb Pn
j=k+1 Œ≥jœµk =
O(wn),
if œµn = O(wn),
o(wn),
if œµn = o(wn).
(92)
Lemma G.7 (Fort (2015) Lemma 5.10). For any matrices A, B, C,
‚à•ABAT ‚àíCBCT ‚à•‚â§‚à•A ‚àíC‚à•‚à•B‚à•(‚à•A‚à•+ ‚à•C‚à•).
(93)
38

Published as a conference paper at ICLR 2024
G.2
ASYMPTOTIC RESULTS OF SINGLE-TIMESCALE SA
Consider the stochastic approximation in the form of
zn+1 = zn + Œ≥n+1G(zn, Xn+1).
(94)
Let Kz be the transition kernel of the underlying Markov chain {Xn}n‚â•0 with stationary distribu-
tion œÄ(z) such that g(z) ‚âúEX‚àºœÄ(z)[G(z, X)] with domain O ‚äÜRd. Define an operator Kzf for
any function f : N ‚ÜíRD such that
(Kzf)(i) =
X
j‚ààN
f(j)Kz(i, j).
(95)
Assume that
C1. W.p.1, the closure of {zn}n‚â•0 is a compact subset of O.
C2. Œ≥n = Œ≥0/na, a ‚àà(1/2, 1].
C3. Function g is continuous on O and there exists a non-negative C1 function w and a compact
set K ‚äÇO such that
‚Ä¢ ‚àáw(z)T g(z) ‚â§0 for all z ‚ààO and ‚àáw(z)T g(z) < 0 if z /‚ààK;
‚Ä¢ the set S ‚âú{z | ‚àáw(z)T g(z) = 0} is such that w(S) has an empty interior;
C4. For every z, there exists a solution mz : N ‚ÜíRd for the following Poisson equation
mz(i) ‚àí(Kzmz)(i) = G(z, i) ‚àíg(z)
(96)
for any i ‚ààN; for any compact set C ‚äÇO,
sup
z‚ààC,i‚ààN
‚à•(Kzmz)(i)‚à•+ ‚à•mz(i)‚à•< ‚àû
(97)
and there exist a continuous function œïC, œïC(0) = 0, such that for any z, z‚Ä≤ ‚ààC,
sup
i‚ààN
‚à•(Kzmz)(i) ‚àí(Kz‚Ä≤mz‚Ä≤)(i)‚à•‚â§œïC(‚à•z ‚àíz‚Ä≤‚à•).
(98)
C5. Denote by ‚àír the largest real part of the eigenvalues of the Jacobian matrix ‚àág(z‚àó) and
assume r >
1{a=1}
2
.
C6. For every z, there exists a solution Qz : N ‚ÜíRd√ód for the following Poisson equation
Qz(i) ‚àí(KzQz)(i) = F(z, i) ‚àíEj‚àºœÄ(z)[F(z, j)]
(99)
for any i ‚ààN, where
F(z, i) ‚âú
X
j‚ààN
mz(j)mz(j)T Kz(i, j) ‚àí(Kzmz)(i)(Kzmz)(i)T .
(100)
For any compact set C ‚äÇO,
sup
z‚ààC,i‚ààN
‚à•Qz(i)‚à•+ ‚à•(KzQz)(i)‚à•< ‚àû
(101)
and there exist p, CC > 0, such that for any z, z‚Ä≤ ‚ààC,
sup
i‚ààN
‚à•(KzQz)(i) ‚àí(Kz‚Ä≤Qz‚Ä≤)(i)‚à•‚â§CC‚à•z ‚àíz‚Ä≤‚à•p.
(102)
Theorem G.8 (Delyon et al. (1999) Theorem 2). Consider (94) and assume C1 - C4. Then, w.p.1,
lim supn d(zn, S) = 0.
Theorem G.9 (Fort (2015) Theorem 2.1 & Proposition 4.1). Consider (94) and assume C1 - C6.
Then, given the condition that zn converges to one point z‚àó‚ààS, we have
Œ≥‚àí1/2
n
(zn ‚àíz‚àó)
dist.
‚àí‚àí‚àí‚àí‚Üí
n‚Üí‚àûN(0, V),
(103)
where
V
1{b=1}
2
I + ‚àág(z‚àó)T

+
1{b=1}
2
I + ‚àág(z‚àó)

V + U = 0,
(104)
and
U ‚âú
X
i‚ààN
¬µi
 mz‚àó(i)mz‚àó(i)T ‚àí(Kz‚àómz‚àó)(i)(Kz‚àómz‚àó)(i)T 
.
(105)
39

Published as a conference paper at ICLR 2024
G.3
ASYMPTOTIC RESULTS OF TWO-TIMESCALE SA
For the two-timescale SA with iterate-dependent Markov chain, we have the following iterations:
zn+1 = zn + Œ≤n+1G1(zn, ynXn+1),
(106a)
yn+1 = yn + Œ≥n+1G2(zn, yn, Xn+1),
(106b)
with the goal of finding the root (z‚àó, y‚àó) such that
g1(z‚àó, y‚àó) = EX‚àº¬µ[G1(z‚àó, y‚àó, X)] = 0,
g2(z‚àó, y‚àó) = EX‚àº¬µ[G2(z‚àó, y‚àó, X)] = 0.
(107)
We present here a simplified version of the assumptions for single-valued functions G1, G2 that
are necessary for the almost sure convergence result in Yaji & Bhatnagar (2020, Theorem 4). The
original assumptions are intended for more general set-valued functions G1, G2.
(B1) The step sizes Œ≤n ‚âún‚àíb and Œ≥n ‚âún‚àía, where 0.5 < a < b ‚â§1.
(B2) Assume the function G1(z, y, X) is continuous and differentiable with respect to z, y.
There exists a positive constant L1 such that ‚à•G1(z, y, X)‚à•‚â§L1(1 + ‚à•z‚à•+ ‚à•y‚à•) for
every z ‚ààRd1, y ‚ààRd2, X ‚ààN. The same condition holds for the function G2 as well.
(B3) Assume there exists a function œÅ : Rd1 ‚ÜíRd2 such that the following three properties hold:
(i) ‚à•œÅ(z)‚à•‚â§L2(1 + ‚à•z‚à•) for some positive constant L2; (ii) the ODE Àôy = g2(z, y) has
a globally asymptotically stable equilibrium Œª(z) such that g2(z, œÅ(z)) = 0. Additionally,
let ÀÜg1(z) ‚âúg1(z, œÅ(z)), there exists a set of disjoint roots Œõ ‚âú{z‚àó: ÀÜg1(z‚àó) = 0}, which
is the set of globally asymptotically stable equilibria of the ODE Àôz = ÀÜg1(z).
(B4) {Xn}n‚â•0 is an iterate-dependent Markov process in finite state space N.
For every
n ‚â•0, P(Xn+1 = j|zm, ym, Xm, 0 ‚â§m ‚â§n) = P(Xn+1 = j|zn, yn, Xn = i) =
Pi,j[zn, yn], where the transition kernel P[z, y] is continuous in z, y, and the Markov
chain generated by P[z, y] is ergodic so that it admits a stationary distribution œÄ(z, y), and
œÄ(z‚àó, œÅ(z‚àó)) = ¬µ.
(B5) supn‚â•0(‚à•zn‚à•+ ‚à•yn‚à•) < ‚àûa.s.
Yaji & Bhatnagar (2020) included assumptions A1 - A9 and A11 for the following Theorem G.10.
We briefly show the correspondence of our assumptions (B1) - (B5) and theirs: (B1) with A5, (B2)
with A1 and A2, (B3) with A9 and A11, (B4) with A3 and A4, and (B5) with A8. Given that our
two-timescale SA framework (106) excludes additional noises (setting them to zero), A6 and A7
therein are inherently met.
Theorem G.10 (Yaji & Bhatnagar (2020) Theorem 4). Under Assumptions (B1) - (B5), iterations
(zn, yn) in (106) almost surely converge to a set of roots, i.e., (zn, yn) ‚ÜíS
z‚àó‚ààŒõ(z‚àó, œÅ(z‚àó)) a.s.
H
ADDITIONAL SIMULATION RESULTS
H.1
BINARY CLASSIFICATION ON ADDITIONAL DATASETS
In this part, we perform the binary classification task as in Section 4 on additional datasets, i.e.,
a9a (with 123 features) and splice (with 60 features) from LIBSVM (Chang & Lin, 2011). Figure
4 provides the performance ordering of different Œ± values, and we empirically demonstrate that the
curves with Œ± ‚â•5 still outperform the i.i.d. counterpart. Additionally, Figure 5 compare cases (i) -
(iii) under both a9a and splice datasets, and case (i) consistently perform the best.
H.2
NON-CONVEX LINEAR REGRESSION
We further test SGD-SRRW and SHB-SRRW algorithms with a non-convex function to demonstrate
the efficiency of our SA-SRRW algorithm beyond the convex setting. In this task, we simulate the
following linear regression problem in Khaled & Richt¬¥arik (2023) with non-convex regularization
min
Œ∏‚ààRd
Ô£±
Ô£≤
Ô£≥f(Œ∏) ‚âú1
N
N
X
i=1
li(Œ∏) + Œ∫
d
X
j=1
Œ∏2
j
Œ∏2
j + 1
Ô£º
Ô£Ω
Ô£æ
(108)
40

Published as a conference paper at ICLR 2024
102
103
104
105
Number of steps (n)
10
2
10
1
100
MSE 
n
*
2
CASE (i): a = 0.8, b = 0.9
MHRW (
= 0)
= 1
= 5
= 10
= 20
i.i.d. sampling
(a) SGD-SRRW, a9a
102
103
104
105
Number of steps (n)
10
1
100
101
MSE 
n
*
2
CASE (i): a = 0.8, b = 0.9
MHRW (
= 0)
= 1
= 5
= 10
= 20
i.i.d. sampling
(b) SGD-SRRW, splice
Figure 4: Simulation results with various Œ± values in a9a and splice datasets.
102
103
104
105
Number of steps (n)
10
1
100
MSE 
n
*
2
CASE (i):a = 0.8, b = 0.9
CASE (ii):a = 0.9, b = 0.9
CASE (iii):a = 1, b = 0.9
(a) Œ± = 5, SGD-SRRW, a9a
102
103
104
105
Number of steps (n)
10
1
100
MSE 
n
*
2
CASE (i):a = 0.8, b = 0.9
CASE (ii):a = 0.9, b = 0.9
CASE (iii):a = 1, b = 0.9
(b) Œ± = 10, SGD-SRRW, a9a
102
103
104
105
Number of steps (n)
10
2
10
1
100
MSE 
n
*
2
CASE (i):a = 0.8, b = 0.9
CASE (ii):a = 0.9, b = 0.9
CASE (iii):a = 1, b = 0.9
(c) Œ± = 20, SGD-SRRW, a9a
102
103
104
105
Number of steps (n)
10
1
100
MSE 
n
*
2
CASE (i):a = 0.8, b = 0.9
CASE (ii):a = 0.9, b = 0.9
CASE (iii):a = 1, b = 0.9
(d) Œ± = 5, SGD-SRRW, splice
102
103
104
105
Number of steps (n)
10
1
100
MSE 
n
*
2
CASE (i):a = 0.8, b = 0.9
CASE (ii):a = 0.9, b = 0.9
CASE (iii):a = 1, b = 0.9
(e) Œ± = 10, SGD-SRRW, splice
102
103
104
105
Number of steps (n)
10
1
100
MSE 
n
*
2
CASE (i):a = 0.8, b = 0.9
CASE (ii):a = 0.9, b = 0.9
CASE (iii):a = 1, b = 0.9
(f) Œ± = 20, SGD-SRRW, splice
Figure 5: Performance comparison among cases (i) - (iii) for Œ± ‚àà{5, 10, 20} in a9a and splice
datasets.
where the loss function li(Œ∏) = ‚à•sT
i Œ∏ ‚àíyi‚à•2 and Œ∫ = 1, with the data points {(si, yi)}i‚ààN from the
ijcnn1 dataset of LIBVIM (Chang & Lin, 2011). We still perform the optimization over the wikiVote
graph, as done in Section 4.
The numerical results for the non-convex linear regression taks are presented in Figures 6 and 7,
where each experiment is repeated 100 times. Figures 6a and 6b show that the performance ordering
across different Œ± values is still preserved for both algorithms over almost all time, and curves
for Œ± ‚â•5 outperform that of the i.i.d. sampling (in black) under the graph topological constraints.
Additionally, among the three cases examined at identical Œ± values, Figures 7a - 7c confirm that case
(i) performs consistently better than the other two cases, implying that case (i) can even become the
best choice for non-convex distributed optimization tasks.
41

Published as a conference paper at ICLR 2024
102
103
104
105
Number of steps (n)
10
2
10
1
MSE 
n
*
2
CASE (i): a = 0.8, b = 0.9
MHRW (
= 0)
= 1
= 5
= 10
= 20
i.i.d. sampling
(a) SGD-SRRW
102
103
104
105
Number of steps (n)
10
3
10
2
10
1
MSE 
n
*
2
CASE (i): a = 0.8, b = 0.9
MHRW (
= 0)
= 1
= 5
= 10
= 20
i.i.d. sampling
(b) SHB-SRRW
Figure 6: Simulation results for non-convex linear regression under case (i) with various Œ± values.
102
103
104
105
Number of steps (n)
10
2
10
1
MSE 
n
*
2
CASE (i):a = 0.8, b = 0.9
CASE (ii):a = 0.9, b = 0.9
CASE (iii):a = 1, b = 0.9
(a) Œ± = 5, SGD-SRRW
102
103
104
105
Number of steps (n)
10
2
10
1
MSE 
n
*
2
CASE (i):a = 0.8, b = 0.9
CASE (ii):a = 0.9, b = 0.9
CASE (iii):a = 1, b = 0.9
(b) Œ± = 10, SGD-SRRW
102
103
104
105
Number of steps (n)
10
2
10
1
MSE 
n
*
2
CASE (i):a = 0.8, b = 0.9
CASE (ii):a = 0.9, b = 0.9
CASE (iii):a = 1, b = 0.9
(c) Œ± = 20, SGD-SRRW
Figure 7: Performance comparison among cases (i) - (iii) for non-convex regression.
42

