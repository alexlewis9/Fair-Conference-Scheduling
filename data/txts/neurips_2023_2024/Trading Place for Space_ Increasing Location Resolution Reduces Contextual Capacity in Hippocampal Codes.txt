Trading Place for Space: Increasing Location
Resolution Reduces Contextual Capacity in
Hippocampal Codes
Spencer Rooke1
Zhaoze Wang2
Ronald W. Di Tullio3∗
Vijay Balasubramanian1,4,5∗
1Departments of Physics
2 of Computer and Information Science and 3 Neuroscience
University of Pennsylvania; 4Rudolf Peierls Centre for Theoretical Physics, University of Oxford;
and 5Santa Fe Institute
∗: Equal contribution
srooke@sas.upenn.edu
zhaoze@seas.upenn.edu
ron.w.ditullio@gmail.com
vijay@physics.upenn.edu
Abstract
Many animals learn cognitive maps of their environment - a simultaneous represen-
tation of context, experience, and position. Place cells in the hippocampus, named
for their explicit encoding of position, are believed to be a neural substrate of
these maps, with place cell "remapping" explaining how this system can represent
different contexts. Briefly, place cells alter their firing properties, or "remap", in
response to changes in experiential or sensory cues. Substantial sensory changes,
produced, e.g., by moving between environments, cause large subpopulations of
place cells to change their tuning entirely. While many studies have looked at the
physiological basis of remapping, we lack explicit calculations of how the contex-
tual capacity of the place cell system changes as a function of place field firing
properties. Here, we propose a geometric approach to understanding population
level activity of place cells. Using known firing field statistics, we investigate how
changes to place cell firing properties affect the distances between representations
of different environments within firing rate space. Using this approach, we find
that the number of contexts storable by the hippocampus grows exponentially with
the number of place cells, and calculate this exponent for environments of different
sizes. We identify a fundamental trade-off between high resolution encoding of
position and the number of storable contexts. This trade-off is tuned by place cell
width, which might explain the change in firing field scale along the dorsal-ventral
axis of the hippocampus. We demonstrate that clustering of place cells near likely
points of confusion, such as boundaries, increases the contextual capacity of the
place system within our framework and conclude by discussing how our geometric
approach could be extended to include other cell types and abstract spaces.
1
Introduction
Decades of experiments suggest that the mammalian hippocampus is crucial for the formation of
episodic memories and spatial navigation [1, 2, 3]. Neural recordings of rodents during active
navigation led to the discovery of place cells by John O’keefe [4], named for their spatially localized
firing patterns. These place cells were quickly theorized to be the substrate of the cognitive map - an
animal’s simultaneous and abstract representation of context, experience, and position [3, 5]. Further
experiments led to the discovery of remapping [6, 7, 8], during which place cells alter their firing
properties in response to changes in sensory and contextual cues. Large contextual changes lead to
global remapping, in which population level maps of activity appearing in different contexts are nearly
orthogonal, independent of correlations within an environment [9, 10]. Many have speculated that
38th Conference on Neural Information Processing Systems (NeurIPS 2024).

Figure 1: Place cell firing fields remap in one (A) and two (C) dimensions. (B) The maps fA, fB
of one dimensional contexts correspond to curves in neural population activity space, parametrized
by position. With constant Gaussian noise, we require that these curves be a distance 2σ(
√
N + q)
apart in order to discriminate contexts. (D) The maps fA, fB of two dimensional contexts correspond
to surfaces in activity space, parametrized by position in physical space. With activity dependent,
Poisson-like noise, firing patterns exponentially localize to characteristic ellipsoids. We require that
these thickened surfaces do not intersect in order to discriminate contexts.
the place cell system encodes context via global remapping and that this encoding scheme should be
able to store a large number of contexts [11, 12], but precise calculations backing these speculations
are lacking. Here, we analyze the geometry of hippocampal codes to approximate the capacity and
properties of context encoding by place cells.
We treat place cell population activity as a high dimensional space into which we can embed
contexts (Fig. 1 ,B). Since a large fraction of hippocampal neurons are place cells [13, 14], we
expect this activity space to have thousands of dimensions, depending on the species. While the
defining features that distinguish context are not fully known [6, 7, 8], we define it as a choice of
surrounding environment, as is often done in practice in experiments [9, 11, 15, 16, 17, 18, 19].
Embedding an environment in the firing rate space produces a neural manifold, with position on
the manifold corresponding to particular patterns of neural population activity that reflect location
in real space. Without noise, the dimensionality of this manifold matches the dimensions of the
encoded environment. For example, different linear tracks would be encoded as different 1D curves
embedded in the population activity space (Fig. 1B). In this geometric framework, the distance
between two manifolds indicates how differently the neural populations encode each environment
[20] (Fig. 1B); and if two manifolds do not overlap at any point, the underlying context can always be
determined without confusion. In the noiseless case, we expect that it is trivial to discriminate context
because pairs of very low dimensional manifolds are unlikely to overlap in such a high dimensional
space. Real neurons, however, will have noisy responses which "blur" our manifolds, giving them a
characteristic width around the noiseless, low dimensional embedding of an environment. As such,
our criterion for separability of contexts requires that these thickened manifolds for each context do
not overlap extensively in rate space (Fig. 1D). We consider two models of neuronal noise for our rate
based neurons: one in which noise is additive and constant, and a second in which noise is additive,
but with variance scaling with neural activity. The latter mirrors an underlying Poisson-like process
of spike generation that is often assumed for hippocampal neurons. We investigate the effect of these
different noise models on pairwise overlap, and from this extrapolate the probability that multiple
contexts are discriminable.
When the number of neurons N is large, these manifolds grow far apart, and are more easily distin-
guished. In weak to moderate noise regimes, we find that the number of contexts that can be stored
by a place-like coding scheme grows exponentially in N, even when we enforce strict requirements
that the system can discriminate between contexts at any position within an environment. We further
find that place cell width tunes both the ability to decode local position and the typical distance
between contextual manifolds. Large place cell widths generate greater overlap between firing
fields, which in turn increases discriminability between contexts. Conversely, small place cell widths
increase the spatial resolution of encodings, but decrease the separability of contextual manifolds.
This leads to a fundamental trade-off between decoding context and local position. We propose that
this trade-off accounts for the observed change in firing field width across the dorsal-ventral axis
in the rodent hippocampus, and predict that selective inhibition along the hippocampus will lead to
2

different types of memory impairment for spatial tasks, consistent with existing experimental evidence
[21, 22, 23, 24, 25, 26]. Finally, we find that when fields are uniformly distributed, confusion between
contexts is most likely to occur near boundaries. This effect can be compensated for by biasing the
density of place field centers towards the boundary, recreating a known feature of rodent place coding
[27, 28]. We predict that the observed place cell clustering near boundaries allows the place system
to segregate different contexts with greater efficiency, and the extent of this clustering is additionally
a function of cell location along the ventral-dorsal axis.
1.1
Model Description
We consider a population of N place cells, indexed by j, with activity described by a population
activity vector ⃗r. We treat this vector as a random variable that depends both on context (A), and
position within a context (xA). We consider physical environments in one or two dimensions, as this
is common experimentally, so that xA is either a one or two dimensional vector describing location.
Each context A is equipped with a place map fA, which defines the tuning of each neuron when the
animal is within A. That is, fA sets the mean firing rate of each neuron, ⟨rj(xA, A)⟩= fA,j(xA).
Each map fA can be viewed as an encoding for a particular context that embeds xA into a certain
set of population activity vectors ⃗r (Fig. 1A,B). We restrict our analysis to rate coding models of
population activity, where ⃗r represents population firing rates (rather than spike counts) and has
additive noise.
We assume that place maps are constructed stochastically for each environment, consistently with
known properties of place cells. Within an environment, each place cell has aj distinct firing fields,
where aj is drawn from a gamma-poisson distribution, following recent experimental observations in
rodents [29, 30], (Supplemental). For small environments (1-2 m), typical place cells have 0-2 firing
fields under these statistics, with greater recruitment as environment size increases. We give each
firing field a gaussian shape, and vary the widths parametrically. The tuning curve of each neuron is
then a sum of gaussians:
fA,j(xA) = .1Hz + Cj,A
aj
X
i
exp −
1
2(wi/2)2 (⃗xA −⃗µA,i)2
(1)
For simplicity, the normalization Cj,A is chosen so that all neurons have a baseline firing rate of
.1Hz, and a maximum firing rate of 30Hz in environments in which they are active.
With additive noise, neural activity is given by rj(xA, A) = fA,j(xA) + ξj. We consider two noise
model. In the first, ξ is gaussian distributed, and noise is not correlated between place cells, so
that ⃗ξ ∼N(0, σ2I). Note that σ2 is the variance in noise magnitude and thus has units of Hz2. In
the second model, we scale the noise variance of each place cell with activity to match underlying
Poisson-like statistics associated with spike generation. In this case, ξj ∼N(0, ϕfA,j(xA)). Here,
ϕ is a dispersion coefficient that sets how noisy the place system is, and has units of Hz. We
can write our two models of place cell activity as ⃗r(xA, A) ∼N(fA(xA), σ2I) and ⃗r(xA, A) ∼
N(fA(xA), ϕdiag[fA(xA)]), respectively. Additive noise can generate negative firing rates, and so
we rectify all negative firing rates to 0 Hz.
2
Results
2.1
Place Coding Can Store Exponentially Many Contexts
With the above model in hand, we sought to explore the context coding capacity of the place cell
network. To do so, we first defined what it means to discriminate two contexts A and B. In our
formulation, fA(xA) and fB(xB) define two manifolds in the space of neural activity (Fig. 1).
Without noise, if these two manifolds do not intersect, then the firing patterns that arise in each
environment are unique to that environment. In this case, both position and context can be uniquely
determined from population activity, and so the contexts A and B are discriminable so long as fA
and fB do not intersect. For the moment, we disregard considerations of computational complexity
required for manifold discrimination, such as requiring linear separability as in [31, 32].
When there is no noise, there is a very low probability that the surfaces defined by fA and fB intersect
at any point in our high-dimensional firing rate space, and the intersection criterion is trivial to fulfil.
3

The introduction of noise gives the manifolds defined by fA and fB a characteristic width, whose
scale and geometry depends on the nature of the noise. In the model where noise variance σ2 is
constant, the characteristic manifold width scales like σ
√
N when N is sufficiently large. This is due
to a well known characteristic of gaussians in high dimensions, in which normal distributions have
the majority of their mass sitting near a thin annulus of radius σ
√
N [33, 34] (Supplemental). That
is, the probability density for the radius of vectors pulled from high dimensional spherical gaussians
peaks at σ
√
N, and falls off exponentially away from this shell as pR(σ
√
N +qσ) ≈pR(σ
√
N)e−q2.
For example, when q = 2 this leads an approximate four e-fold decrease in the probability density,
so that the majority of the probability mass (> 99% for large N) is within a radius of σ
√
N + qσ.
Importantly, this exponential fall off is independent of N, and so the width of the annulus is of order
1 in N. In the rate dependent noise model, we instead get a probability mass that is exponentially
localized to an ellipsoid with major axes whose lengths depend on firing rates,
p
Nϕf i
A(xA).
We would then like a way to determine the effect of both noise models on manifold overlap, and by
extension, decrease in context discriminability. We solve this problem geometrically. For the rate
independent (gaussian) noise model, the manifold fA(xA) acquires a width of σ(
√
N + q) in every
direction. Here, q accounts for the non-zero width of the noise annulus. In any case, our condition
that two contexts A and B be distinguishable then becomes a requirement that the minimum distance
between fA(xA) and fB(xB) in rate space overcomes this width set by noise (Fig. 1C):
min
xA,xB d(fA(xA), fB(xB)) > 2σ(
√
N + q)
(2)
The manifold width acquired from the rate dependent (Poisson-like) noise model will vary in each
direction of the firing rate space with the neural firing rate. Intuitively, we can think of this widening
of the manifold as placing an ellipsoid at each point along our manifold, with principle axes set
by the firing rates of each neuron (Fig. 1D). We then check if our thickened manifolds overlap.
Unlike the case with constant noise, where it sufficed to check that the distance between points
between different manifolds is greater than the minimum distance set by noise, we must check that the
ellipsoids centered at fA(xA) and fB(xB) do not overlap for any pair xA, xB on the two manifolds.
For ellipsoids with centers ⃗µA = fA(xA) and ⃗µB = fB(xB) and covariances ΣA and ΣB, we can
define the set:
Es = {s(⃗r −⃗µA)T ΣA(⃗r −⃗µA) + (1 −s)(⃗r −⃗µB)T ΣB(⃗r −⃗µB) ≤1}
(3)
Here, s ∈[0, 1]. For s = 0 or s = 1, this set describes the interior of the ellipsoid centered at ⃗µA
or ⃗µB, respectively, and varying s interpolates between the two. For other values of s, Es is either
empty, a single point, or the interior of an ellipse. We also note that, for any s, the intersection of the
two ellipsoids is always contained in Es, and so if there is an s for which this set disappears, then the
two ellipsoids do not intersect [35]. We can rewrite Es as
Es = {(⃗r −⃗µs)T Σs(⃗r −⃗µs) ≤K(s)}
(4)
where Σs = sΣA + (1 −s)ΣB and ⃗µs = Σ−1
s (sΣA⃗µa + (1 −s)ΣB⃗µb). Thus, the two ellipsoids
centered at ⃗µA and ⃗µB do not intersect if and only if K(s) is negative for some s ∈[0, 1]; i.e., Es is
empty for some s. As the centers of each ellipsoid are a function of position within their respective
contexts, we find that (Supplemental):
K(s, xA, xB) = 1 −
1
ϕ(
√
N + q)2
N
X
i
(f i
B(xB) −f i
A(xA))2
(
1
1−sf i
A(xA) + 1
sf i
B(xB))
(5)
If for every pair xA, xB, there is an s for which this is negative, then our two thickened manifolds do
not intersect. As such, we let s∗(xA, xB) minimize K(s, xA, xB) for each choice of xA, xB. To put
this condition in a similar form as equation (2), we define ϕ∗:
ϕ∗(xA, xB) = 1
N
N
X
i
(f i
B(xB) −f i
A(xA))2
(
1
1−s∗(xA,xB)f i
A(xA) +
1
s∗(xA,xB)f i
B(xB))
(6)
Our condition on K(s, xA, xB) can then be written in a similar form to the simpler noise model:
min
xA,xB Nϕ∗(xA, xB) > (
√
N + q)2ϕ
(7)
4

Figure 2: (A) The distributions for the minimum distance in rate space of δmin (Top) and the analogue
used for the rate dependent noise model, Nϕ∗
min (Bottom), constructed from kernel density estimates.
At large N, these approach gaussian. Plots are for one dimensional rooms, with room length L = 1m
and firing field widths W = 1/3m. (B) The probability that two contexts are distinguishable as a
function of the number of neurons and at different noise levels, for the rate independent (Top) and
dependent (Bottom) noise models. (C) The logarithm of M(N), the number of storable contexts as a
function of N, at PM = .95% confidence. In black is the predicted large N scaling, γN + 1
4 ln N.
Here, q again accounts for the nonzero width of the noise annulus. For both models, the width of
the annulus q is O(1) in N, and so makes no contribution to our final results at large N. Indeed, we
performed the numerical calculations for multiple values of q, and find that at large N our results are
unchanged. In generating our figures, we use q = 2. Note that we are enforcing a very strict definition
of separability for both noise models. When separation between the two manifolds is greater than
the threshold distance, the probability of confusing the two contexts is vanishingly small. Less strict
conditions would still allow for good (in a practical sense) performance in context discrimination, but
our stricter definition engenders several advantages. First, the geometric approach we are using to
assess capacity allows us to easily generalize to more than two contexts. Second, it is important to be
as conservative as possible in capacity calculations and such strictness should prevent overestimation
of the number of decodable contexts. Finally, our approach avoids ceiling effects for changing
parameters of the model; that is, by making the task as hard as possible we can observe impacts of
changing different parameters on performance that would be hidden by performance plateaus on
easier tasks.
Having these pairwise separability conditions for two contexts, we then wanted to determine how
many contexts M are storable by the place cell system. To do so, we first replace our statements
for particular environments A and B with probabilistic statements for any pair of rooms A and B
generated at random. The probability that two rooms are distinguishable is then the probability that
the following pairwise separation conditions are true:
Constant Noise: P(2 Rooms are Separable) = P( min
xA,xB d(fA(xA), fB(xB)) > 2σ(
√
N + q)) (8)
Variable Noise: P(2 Rooms are Separable) = P( min
xA,xB Nϕ∗(xA, xB) > (
√
N + q)2ϕ)
(9)
For notational convenience, we define δmin ≡minxA,xB d(fA(xA), fB(xB)) and ϕ∗
min ≡
minxA,xB ϕ∗(xA, xB). The probability that two rooms are distinguishable can then be written
in terms of distributions over these variables as:
Constant Noise: P2 = 1 −
Z 2σ(
√
N+q)
0
P(δmin)dδmin
(10)
Variable Noise: P2 = 1 −
Z ϕ(
√
N+q)2
0
P(Nϕ∗
min)Ndϕ∗
min
(11)
That is, we can determine P2 as long as we can calculate the distributions P(δmin) and P(ϕ∗
min).
These distributions approach normal distributions for large N (Fig. 2A, Supplemental). We use
5

numerical methods to find the mean and variance of these distributions. That is, we generate
many pairs of rooms with unique place maps for each room and then reconstruct these underlying
distributions using normalized Kernel Density Estimation (KDE) while varying the value of N (the
number of neurons). Finally we can use these reconstructed distributions to calculate P2 for both
noise models as a function of N and the strength of the noise (Fig. 2B).
Given the above, we can estimate the total number of storable contexts, M, of the place system as
a function of key parameters of the system. First, we determine how M scales with the number of
neurons N. Given the probability that any pair of rooms is distinguishable, we can estimate the
probability that M environments are distinguishable, PM, via a union bound:
P(M rooms are distinguishable) = P(∪i̸=j rooms i and j are distinguishable) ≤P(
M
2 )
2
(12)
In weak to moderate noise regimes, this inequality becomes approximately saturated (Supplemental).
Thus, we have PM ≈P
M(M−1)
2
2
. To find the number of storable contexts given N neurons, M(N),
we can increase M until PM falls below a desired confidence or allowable error, and call the M
where this occurs the number of storable contexts. For numerically derived values, we use PM = .95,
but note that this only changes prefactors, and the scaling behaviour is independent of this choice.
Equivalently, we can simply invert PM ≈P
M(M−1)
2
2
to find M(N) for a given confidence PM
(Supplemental):
M(N) ≈
s
2 log(PM)
log(P2(N)) + 1
4 + 1/2 ∼(N 1/4 + O(N 1/8))eγN
(13)
In the limit of a system dominated by noise, we can never meet our geometric constraints, and
M(N) = 1. However, if the noise is more reasonable, we find that M scales exponentially with N
for both noise models (Fig. 2C, Supplemental). Here, γ is a constant that depends on firing field
widths, noise, and room geometry but, critically, is independent of N at large N. We can calculate γ
in terms of the distributions of δmin and Nϕ∗
min as (Supplemental):
γδ = (E[δmin]/
√
N −2σ
2
p
Var[δmin]
)2
γϕ = ( E[ϕ∗
min] −ϕ
2
p
NVar[ϕ∗
min]
)2
(14)
Here, γδ and γϕ refer to the exponents in the fixed noise model and variable noise model, respectively.
One can readily show that at large N, the equations for gamma for both noise models will become
independent of N (Supplemental). In this large N regime, we can then characterize the number of
storable contexts solely using the mean and variance of the distributions P(δmin) and P(Nϕ∗
min).
We accordingly calculated the number of distinguishable contexts numerically, and compared with
the predicted large N behaviour (Fig. 2C), finding good agreement. Our results demonstrate that
place coding allows encoding of exponentially many contexts with an exponent controlled by the
amount of neuronal noise (Fig. 3).
2.2
A Trade-off Between Spatial Specificity and Context Segregation
Realistic hippocampal place cells have tuning curves of varying widths. Indeed, across the dorso-
ventral axis of the hippocampus, place field widths can vary by nearly an order of magnitude [21, 24],
with ventral place cells having wider tuning than dorsal cells. As such, we next explored how
the exponent of the number of stored contexts γ scales as a function of firing field width (Fig. 3,
Supplemental). To do so, we numerically reconstructed the distributions P(δmin) and P(Nϕ∗
min)
for various place cell widths. In our model, increasing the widths of place field tunings starting from
small sizes generally leads to an increase in the distance between representations of environments.
That is because, especially in small environments, a relatively small number of place cells will show
place fields, and hence small place fields lead to sparse population activity, reducing the absolute
distance between firing vectors in different environments. Increasing place field widths increases
the average neuronal activity within an environment, thus pushing the encoding manifolds apart.
As a result, we expect larger fields to increase contextual capacity. In fact, in small environments
(1m −4m), optimal context discrimination performance occurs with firing fields that are about the
size of the environment (Fig. 3). We can get a sense of why this happens as follows. Consider
smaller environments in which less than half of all place cells are active due to the Gamma-Poisson
6

Figure 3: The calculated value of the exponential γ at large N of equation (14), as a function of firing
field width and neuronal noise. The environments are 1m (A and B) and 1m2 (C and D). (A and
C) represent the rate independent noise model (Gaussian), while (B and D) are the noise dependent
model (Poisson-like). White lines demarcate the transition into the non-separable regime. We find
better performance for the lower dimensional environments and the Poisson-like model. For larger
environments, smaller relative widths become preferable (Supplemental, Fig. 8).
statistics of place cell activation [29, 30]. When place cells have extremely large widths in this
regime, each neuron is either completely on or off within a given environment, and so each context
becomes associated with a random binary identifier, that will be unique with high probability. Thus
the environmental context can be read off simply by noting which place cells are active, although
there is no location resolution at all. By contrast, in larger rooms, most place cells will have at least
one firing field. So, although the sparse firing of narrow place fields makes it harder to discriminate
contexts based on their responses, the largest, environment-sized firing fields also become useless in
this case because essentially all cells will be active in every room (Supplemental). In either case, we
expect a tradeoff between the twin goals of context and location discrimination that depends directly
on place field size, and indirectly on environment size due to the gamma-poisson statistics used to
generate place field centers.
Tuning the firing field widths lets us explore the trade-off between two presumed objectives for
hippocampal function; encoding of position and encoding of multiple contexts. While wider fields
are generally better for context segregation, it is clear that they are not optimal for spatial specificity,
as wider fields result in less variation in population level firing between locations. Thus we expect a
trade-off between spatial information encoded within a context, and the ability to separate contexts,
tuned by the widths of place cell firing fields. To formalize this trade-off, we must determine how we
will explicitly characterize both spatial specificity and context segregation. To characterize spatial
specificity, we chose to utilize average decoding performance on decoding current position ˆx from
the firing rates ⃗r(x) of the place cell system. Naturally, good performance occurs when the decoded
position typically agrees with the true position, or ⟨(ˆx −x)2⟩⃗r|x is small at most positions. To avoid
a particular choice of decoder, we invoke the Cramer-Rao bound, which lower bounds the covariance
of any estimator by the inverse Fisher Information:
⟨(ˆx −x)(ˆx −x)T ⟩P (r|x) ≥I−1(x) = (Er[(∇xl) ⊗(∇xl)])−1
(15)
⟨(ˆx −x)2⟩P (r|x) ≥Tr[I−1(x)]
(16)
When x represents position in a one dimensional context, the inverse Fisher Information is a scalar. If
x is not one dimensional, then the inequality is a statement about the difference between the covariance
and the inverse of the Fisher Information being positive semi-definite, so that a bound on the mean
squared error can be found by taking a trace. In both noise models, the Fisher Information can be
calculated exactly in terms of the tunings of each neuron within an environment as (Supplemental):
Iδ = 1
σ2
X
i
∇xf i
A ⊗∇xf i
A
Iϕ =
X
i
(
1
ϕf i
A(x) +
1
2f i
A(x)2 )∇xf i
A ⊗∇xf i
A
(17)
We can now characterize spatial specificity by calculating the average spatial resolution by averaging
the Cramer-Rao bound with respect to both position and context. The objective for maximizing the
spatial resolution can be formalized by minimizing ln⟨⟨Tr[I−1(x)]⟩x⟩A (Fig. 4A). Tuning firing
fields for high spatial resolution drives the firing field widths to a minimum set by the population size.
Clearly, this is at odds with the first objective for storing many contexts, which drives firing fields to
be larger. Here we find our anticipated firing field width trade-off between these two objectives. The
character of this trade-off depends on how we formalize an objective function with respect to firing
7

Figure 4: (A) The Cramer Rao Bound for both noise models. (Top) represents the rate independent
model, while (Bottom) represents the rate dependent model. (B-C) The optimal width as a function
of the relative importance between the two objectives. Using ln M to characterize context decoding
leads to a sharp change in the optimal width, while ln P2 leads to a more gradual change. In both
cases, there is a trade-off between storing high resolution information and storing many contexts,
tuned by firing field width.
field width W. We consider two objective functions:
L1 = λ(−1) log(M(N, W)) + (1 −λ) log⟨⟨Tr[I−1]⟩x⟩A
(18)
L2 = λ(−1) log(P2(N, W)) + (1 −λ) log⟨⟨Tr[I−1]⟩x⟩A
(19)
Here λ ∈[0, 1] interpolates between the two objectives by setting the relative importance of each,
N is the number of neurons, W is the width of the firing fields, P2 is the probability that 2 rooms
are separable given N and W, and M(N, W) is the number of storable contexts (see discussion
below eq. 12). As the relative importance shifts from a high contextual capacity to high contextual
resolution, the optimal firing field width shrinks to a minimum set by the averaged Cramer-Rao
bound. Such capacity-resolution trade-offs are consistent with those demonstrated in recurrent neural
networks [36]. For the first choice of objective function, the optimal width jumps abruptly as we vary
λ (Fig. 4B). The second choice of objective function, on the other hand, strongly penalizes widths for
which context segregation becomes impossible, leading to a smooth transition of the optimal firing
field as we vary λ (Fig. 4C). Regardless, we see the same clear trade-off between our two objectives
for each choice of formalization. This result suggests that the difference in field size across the
dorsal-ventral axis of the hippocampus may reflect a segregation of coding function by optimizing for
different objectives rather than just a gradient of spatial resolution as is commonly posited [17, 11].
This is also consistent with experimental evidence that dorsal hippocampus is largely recruited for
spatial tasks, while ventral hippocampus typically shapes contextual response [22, 23, 24, 25, 26].
2.3
Field Clustering near Boundaries improves Context Segregation
So far, we have assumed that the firing field centers are uniformly distributed. In reality, place cells
often drift near positions of interest and frequented locations, such as boundaries or rewards. If
place cells form a compressed representation of experience, then we can reasonably propose that the
density of place cells at a location should reflect an increased resolution for memory formation near
that location. This clustering could also have an effect on context separability. Indeed, we predict
that such clustering improves context segregation, and demonstrate that biasing place cells towards
the boundaries of contexts can improve the ability of the place system to discriminate between them.
A uniformly distributed place cell population will, in general, have less overlapping fields near the
boundaries of an environment. Since discrimination between contexts critically depends on the
overlap between place cell firing fields, this lack of density by the boundaries increases the probability
of confusion between contexts. This observation matches perceptual intuition. In the center of
environments, animals are able to reference distal cues as well as different proximal cues in the
8

Figure 5: (A) An example surface swept out between distances in code space by positions xA,xB,
d(fA(xA), fB(xB)). We have analagous surfaces for the rate dependent noise model. (B) The height,
on average, of the minimum of the this surface for both noise models, and various firing field widths.
(C) The optimal values of α derived from this approach, for both noise models and an approximation
from equalizing firing ratios from the boundary and the bulk (Supplemental). (D) The sample to
sample average of the surface removes variations due to the random choice of fA. The minimum of
this surface is near the boundaries at α = 1, but jumps discontinuously the center as α decreases.
environment. Adjacent to a boundary, the boundary is the dominate cue and likely obscures other cues
that could potentially distinguish environments. In our model, we can add an in-homogeneity to the
point process for generating place field centers to increase place field density near the boundaries. For
one dimensional contexts, we can parameterize this in-homogeneity via a symmetric beta distribution,
β(x/L; α, α) (Supplemental) over space. Here α acts as a ’uniformity’ parameter. With α = 1 we
recover the homogeneous process and have uniformly distributed place cells. Values of α < 1 will
progressively bias firing field centers towards the boundaries.
To understand the effect of the bias α on discrimination of pairs of contexts A and B, we can look
at where the distance in rate space is smallest. These distances are given by d(fA(xA), fB(xB))
and K(s(xA, xB), xA, xB) for each noise model, respectively. For one dimensional contexts, these
can be viewed as two dimensional surfaces swept out by xA and xB (Fig. 5A), while for two
dimensional contexts these could be viewed as four dimensional surfaces. We take the sample to
sample (annealed) average first, to find where, on average, the minimum of this surface is likely to be
found (Fig. 5D). With α = 1 this minimum occurs most often near the boundaries of either context A
or B. As we decrease α, the minimum of the averaged surface near the boundaries increases until it
eventually jumps discontinuously to the center (Fig. 5D). The value of α for which this jump occurs
is dependent on firing field width and the noise model under consideration, but is independent of
N at large N (Fig. 5B). Wider firing fields tend to lead to a larger optimal bias (Fig. 5C). In two
dimensions, we considered a distribution of firing field centers that is a product of beta distributions,
β(x/L; αx, αx)β(y/L; αy, αy). The analysis for the x direction and y direction separate, which
leads to identical optimal values for the uniformity parameter α as in the 1-D case.
3
Discussion
Many researchers have proposed that the place system in the neural substrate of the cognitive map
and that global place cell remapping plays a critical role in storing information about environmental
context [11, 15, 16, 17, 6, 7, 8]. Further, recent work may implicate the role of place maps in general,
short term memory formation [11, 37, 38, 39, 40], which might explain the need for such a large
contextual capacity. In this work, we have built upon these proposals by explicitly demonstrating
under realistic firing statistics that the place cell system’s context storage capacity grows exponentially
9

with the number of neurons, and by calculating the associated exponents. This large capacity is
consistent with the notion that the hippocampus is capable of pattern separating context and encoding
many experiences [41, 42, 43], and here we demonstrate that a place-like coding scheme alone is
sufficient in this regard. To achieve this result, we developed a geometric model of place cell activity,
which allowed us to explore how this capacity changes as a function of the number of place cells in
the system and of place cell firing field properties. While our strict conditions on pairwise separability
leads to a coding scheme that is robust to noise, we note that less strict conditions may be more
realistic, and better suit an animals behavioural needs. We primarily focused on global remapping
here, but conjecture that the qualitative structure of our results remain unchanged by including the
effects of partial remapping. Including these effects will give each manifold an additional width
along a few dimensions due to variations that are not due to neural noise, but rather due to partial
or rate remapping. Additionally, we have not considered here the complexity of decoders of the
hippocampus. Although we show that context separation is achievable, the requirement of simple
decoding, as well as the architecture of the underlying hippocampal network, will further constrain
the contextual capacity [31, 32, 36].
We then explored implications of this model as it pertains to various objectives of the hippocampal
code. In particular, we revealed a trade-off between precise encoding of local position and discrim-
ination between different contexts. We found that tuning individual place cells for encoding local
position leads to smaller place field widths, while increasing place field widths leads to improved per-
formance for context discrimination. The size of place fields increases from the dorsal hippocampus
to the ventral hippocampus [21, 24], and we suggest that this mixed population of neurons allows
the hippocampus to perform both objectives efficiently. That is, our model suggests that place cells
of the dorsal hippocampus are better tuned for fine grained memory, while the more widely tuned
ventral cells are better tuned for pattern separation and storage of many contexts. This is consistent
with experimental evidence, in which dorsal lesion typically impair spatial memory, while ventral
lesions do not. Conversely, ventral lesions have been demonstrated to impair contextual memory, for
example decreasing response in contextual fear experiments, but have minimal affect on spatial tasks
[22, 23, 24, 25, 26].
We also found that biasing place cell centers to cluster near environmental borders improves context
discrimination. Over-representation of place field activity near boundaries is well documented [27],
and we predict that this bias will systematically vary across the dorsal-ventral axis of the hippocampus,
with the more widely tuned ventral place cells displaying greater bias than dorsal place cells. As
rodents typically explore near boundaries of an environment, the need for higher spatial resolution in
these locations may also lead to a similar bias. In fact it is well established that developmental and
self-organization mechanisms can produce efficient structural and functional optimizations (vision:
[44, 45, 46]; audition: [47, 48, 49]; olfaction: [50, 51]; spatial cognition: [52]) and here we are
suggesting that similar processes may operate in the place system.
While we have explored hippocampal codes in isolation, interactions with other spatially tuned cells,
such a egocentric and allocentric border cells, likely have an effect on this bias not explored here,
suggesting yet another intricate interaction between allocentric-egocentric representations in the
hippocampus [53]. If place cells are implicated for general episodic memory, such an interaction may
imply that boundary cells play a role in general memory. Exploring this interaction is a topic for
future work, and our approach provides a foundation for exploring these avenues.
Finally, we have also focused on physical one and two dimensional contexts in this work, but our
geometric formulation generalizes to higher dimensional and abstract spaces. Our derivation of the
exponential scaling is independent of the dimension, and so we predict that the hippocampus should
also be able to segregate context and distinguish locations in more abstract spaces efficiently. It is
worth noting however that there is still an appreciable drop in performance when moving from one to
two dimensional spaces, and so the system is likely incentivized to encode abstract spaces with lower
dimensional structures when possible.
Acknowledgments: We thank Dori Derdikman, Genela Morris, and Shai Abramson for many
illuminating discussions in the course of this work, which was supported in part by NIH CRCNS
grant 1R01MH125544-01 and by the NSF and DoD OUSD (R&E) under Agreement PHY-2229929
(The NSF AI Institute for Artificial and Natural Intelligence). VB was supported in part by the
Eastman Professorship at Balliol College, Oxford.
10

References
[1] L R Squire. Memory and the hippocampus: a synthesis from findings with rats, monkeys, and
humans. Psychol Rev, 99(2):195–231, April 1992.
[2] W B Scoville and B Milner. Loss of recent memory after bilateral hippocampal lesions. J
Neurol Neurosurg Psychiatry, 20(1):11–21, February 1957.
[3] John O’Keefe and Lynn Nadel. The Hippocampus as a Cognitive Map. Oxford: Clarendon
Press, 1978.
[4] J O’Keefe and J Dostrovsky. The hippocampus as a spatial map. preliminary evidence from
unit activity in the freely-moving rat. Brain Res, 34(1):171–175, November 1971.
[5] John L Kubie, Eliott R J Levy, and André A Fenton. Is hippocampal remapping the physiological
basis for context? Hippocampus, 30(8):851–864, September 2019.
[6] R U Muller and J L Kubie. The effects of changes in the environment on the spatial firing of
hippocampal complex-spike cells. J Neurosci, 7(7):1951–1968, July 1987.
[7] E Bostock, R U Muller, and J L Kubie. Experience-dependent modifications of hippocampal
place cell firing. Hippocampus, 1(2):193–205, April 1991.
[8] E R Wood, P A Dudchenko, R J Robitsek, and H Eichenbaum. Hippocampal neurons encode
information about different types of memory episodes occurring in the same location. Neuron,
27(3):623–633, September 2000.
[9] Charlotte B. Alme, Chenglin Miao, Karel Jezek, Alessandro Treves, Edvard I. Moser, and
May-Britt Moser. Place cells in the hippocampus: Eleven maps for eleven rooms. Proceedings
of the National Academy of Sciences, 111(52):18428–18435, 2014.
[10] Stefan Leutgeb, Jill K Leutgeb, Alessandro Treves, May-Britt Moser, and Edvard I Moser.
Distinct ensemble codes in hippocampal areas CA3 and CA1. Science, 305(5688):1295–1298,
July 2004.
[11] May-Britt Moser, David C Rowland, and Edvard I Moser. Place cells, grid cells, and memory.
Cold Spring Harb Perspect Biol, 7(2):a021808, February 2015.
[12] Man Yi Yim, Lorenzo A Sadun, Ila R Fiete, and Thibaud Taillefumier. Place-cell capacity and
volatility with grid-like inputs. eLife, 10:e62702, may 2021.
[13] L T Thompson and P J Best. Place cells and silent cells in the hippocampus of freely-behaving
rats. J Neurosci, 9(7):2382–2390, July 1989.
[14] Kenji Mizuseki, Sebastien Royer, Kamran Diba, and György Buzsáki. Activity dynamics
and behavioral correlates of ca3 and ca1 hippocampal pyramidal neurons. Hippocampus,
22(8):1659–1680, 2012.
[15] James J Knierim. Dynamic interactions between local surface cues, distal landmarks, and
intrinsic circuitry in hippocampal place cells. Journal of Neuroscience, 22(14):6254–6264,
2002.
[16] James J Knierim. Hippocampal remapping: implications for spatial learning and navigation.
The neurobiology of spatial behaviour. Oxford University Press, Oxford, pages 226–239, 2003.
[17] James J Knierim. The hippocampus. Current Biology, 25(23):R1116–R1121, 2015.
[18] Heekyung Lee, Douglas GoodSmith, and James J Knierim. Parallel processing streams in the
hippocampus. Current opinion in neurobiology, 64:127–134, 2020.
[19] Sang Hoon Kim, Douglas GoodSmith, Stephanie J Temme, Fumika Moriya, Guo-li Ming,
Kimberly M Christian, Hongjun Song, and James J Knierim. Global remapping in granule cells
and mossy cells of the mouse dentate gyrus. Cell reports, 42(4), 2023.
11

[20] Nikolaus Kriegeskorte, Marieke Mur, and Peter A Bandettini. Representational similarity
analysis-connecting the branches of systems neuroscience. Frontiers in systems neuroscience,
2:249, 2008.
[21] Kirsten Brun Kjelstrup, Trygve Solstad, Vegard Heimly Brun, Torkel Hafting, Stefan Leutgeb,
Menno P Witter, Edvard I Moser, and May-Britt Moser. Finite scale of spatial representation in
the hippocampus. Science, 321(5885):140–143, July 2008.
[22] Brian J. Hock and Michael D. Bunsey. Differential effects of dorsal and ventral hippocampal
lesions. Journal of Neuroscience, 18(17):7027–7032, 1998.
[23] M A Richmond, B K Yee, B Pouzet, L Veenman, J N Rawlins, J Feldon, and D M Bannerman.
Dissociating context and space within the hippocampus: effects of complete, dorsal, and ventral
excitotoxic hippocampal lesions on conditioned freezing and spatial learning. Behav Neurosci,
113(6):1189–1203, December 1999.
[24] Robert W Komorowski, Carolyn G Garcia, Alix Wilson, Shoai Hattori, Marc W Howard, and
Howard Eichenbaum. Ventral hippocampal neurons are shaped by experience to represent
behaviorally relevant contexts. J Neurosci, 33(18):8079–8087, May 2013.
[25] Kirsten G Kjelstrup, Frode A Tuvnes, Hill-Aina Steffenach, Robert Murison, Edvard I Moser,
and May-Britt Moser. Reduced fear expression after lesions of the ventral hippocampus. Proc
Natl Acad Sci U S A, 99(16):10825–10830, July 2002.
[26] M B Moser, E I Moser, E Forrest, P Andersen, and R G Morris. Spatial learning with a minislab
in the dorsal hippocampus. Proc Natl Acad Sci U S A, 92(21):9697–9701, October 1995.
[27] SI Wiener, CA Paul, and H Eichenbaum. Spatial and behavioral correlates of hippocampal
neuronal activity. Journal of Neuroscience, 9(8):2737–2763, 1989.
[28] Stig A. Hollup, Sturla Molden, James G. Donnett, May-Britt Moser, and Edvard I. Moser.
Accumulation of hippocampal place fields at the goal location in an annular watermaze task.
Journal of Neuroscience, 21(5):1635–1644, 2001.
[29] Jae Sung Lee, John J. Briguglio, Jeremy D. Cohen, Sandro Romani, and Albert K. Lee. The
statistical structure of the hippocampal code for space as a function of time, context, and value.
Cell, 183(3):620–635.e22, 2020.
[30] Sander Tanni, William de Cothi, and Caswell Barry. State transitions in the statistically stable
place cell population correspond to rate of perceptual change. Curr Biol, 32(16):3505–3514.e7,
July 2022.
[31] SueYeon Chung, Daniel D. Lee, and Haim Sompolinsky. Classification and geometry of general
perceptual manifolds. Phys. Rev. X, 8:031003, Jul 2018.
[32] Uri Cohen, SueYeon Chung, Daniel D. Lee, and Haim Sompolinsky. Separability and geometry
of object manifolds in deep neural networks. Nature Communications, 11(1):746, Feb 2020.
[33] Christopher M. Bishop. Pattern recognition and machine learning. New York : Springer, [2006]
©2006, [2006]. Textbook for graduates.;Includes bibliographical references (pages 711-728)
and index.
[34] Avrim Blum, John Hopcroft, and Ravindran Kannan. Foundations of Data Science. Cambridge
University Press, 2020.
[35] Igor Gilitschenski and Uwe D. Hanebeck. A robust computational test for overlap of two
arbitrary-dimensional ellipsoids in fault-detection of kalman filters. In 2012 15th International
Conference on Information Fusion, pages 396–401, 2012.
[36] Aldo Battista and Rémi Monasson. Capacity-resolution trade-off in the optimal learning of
multiple low-dimensional manifolds by attractor neural networks. Phys. Rev. Lett., 124:048302,
Jan 2020.
12

[37] Marcus K. Benna and Stefano Fusi.
Place cells may simply be memory cells: Memory
compression leads to spatial tuning and history dependence. Proceedings of the National
Academy of Sciences, 118(51):e2018422118, 2021.
[38] Howard Eichenbaum and Neal J Cohen. Can we reconcile the declarative memory and spatial
navigation views on hippocampal function? Neuron, 83(4):764–770, August 2014.
[39] Howard Eichenbaum, Paul Dudchenko, Emma Wood, Matthew Shapiro, and Heikki Tanila.
The hippocampus, memory, and place cells: Is it spatial memory or a memory space? Neuron,
23(2):209–226, 1999.
[40] Zhaoze Wang, Ronald W Di Tullio, Spencer Rooke, and Vijay Balasubramanian. Time makes
space: Emergence of place fields in networks encoding temporally continuous sensory experi-
ences. August 2024.
[41] Arnold Bakker, C Brock Kirwan, Michael Miller, and Craig E L Stark. Pattern separation in the
human hippocampal CA3 and dentate gyrus. Science, 319(5870):1640–1642, March 2008.
[42] Michael A Yassa and Craig E L Stark. Pattern separation in the hippocampus. Trends Neurosci,
34(10):515–525, July 2011.
[43] Edmund Rolls. The mechanisms for pattern completion and pattern separation in the hippocam-
pus. Frontiers in Systems Neuroscience, 7, 2013.
[44] Charles P Ratliff, Bart G Borghuis, Yen-Hong Kao, Peter Sterling, and Vijay Balasubramanian.
Retina is structured to process an excess of darkness in natural scenes. Proceedings of the
National Academy of Sciences, 107(40):17368–17373, 2010.
[45] Patrick Garrigan, Charles P Ratliff, Jennifer M Klein, Peter Sterling, David H Brainard, and
Vijay Balasubramanian. Design of a trichromatic cone array. PLoS computational biology,
6(2):e1000677, 2010.
[46] Ann M Hermundstad, John J Briguglio, Mary M Conte, Jonathan D Victor, Vijay Balasubra-
manian, and Gašper Tkaˇcik. Variance predicts salience in central sensory processing. Elife,
3:e03722, 2014.
[47] Michael S Lewicki. Efficient coding of natural sounds. Nature neuroscience, 5(4):356–363,
2002.
[48] Evan C Smith and Michael S Lewicki. Efficient auditory coding. Nature, 439(7079):978–982,
2006.
[49] Ronald W Di Tullio, Linran Wei, and Vijay Balasubramanian. Slow and steady: auditory
features for discriminating animal vocalizations. bioRxiv, doi: 10.1101/2024.06.20.599962,
page doi: 10.1101/2024.06.20.599962, 2024.
[50] Tiberiu Te¸sileanu, Simona Cocco, Remi Monasson, and Vijay Balasubramanian. Adaptation of
olfactory receptor abundances for efficient coding. Elife, 8:e39279, 2019.
[51] Kamesh Krishnamurthy, Ann M Hermundstad, Thierry Mora, Aleksandra M Walczak, and
Vijay Balasubramanian. Disorder and the neural representation of complex odors. Frontiers in
Computational Neuroscience, 16:917786, 2022.
[52] Xue-Xin Wei, Jason Prentice, and Vijay Balasubramanian. A principle of economy predicts the
functional architecture of grid cells. Elife, 4:e08362, 2015.
[53] Cheng Wang, Xiaojing Chen, and James J Knierim. Egocentric and allocentric representations
of space in the rodent brain. Current opinion in neurobiology, 60:12–20, 2020.
[54] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in
pytorch. 2017.
[55] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel,
P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher,
M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine
Learning Research, 12:2825–2830, 2011.
13

A
Supplemental
A.1
Simulation Distributions and Firing Fields
A.1.1
Gamma-Poisson Distributions
The number of firing fields each place cell has is determined by a gamma-poisson distribution, as
described in [29, 30]. This is a mixed poisson model, with a gamma distribution acting as the mixing
distribution. That is, the rate variable of the poisson model is gamma distributed with parameters
α, β. We use α = 1.5 and α = 2.25 in one and two dimensions, respectively. We use β = 4m/L and
β = 8m2/A in one and two dimensions, respectively. These create distributions consistent with those
seen in experiment, as below [29, 30]. The total number of neurons for generating these distributions
was 200 :
Figure 6: The number of firing fields per neuron that arise from the gamma-poisson distribution. Top
is one dimensional rooms that vary in length from 1m to 8m. Bottom is two dimensional rooms that
vary in size from 1m2 to 8m2. As rooms get larger, neurons are recruited for representations more
often
Under these statistics, most neurons are silent in small rooms, so two contexts will share few active
neurons. In large rooms, few neurons have no firing fields, and so two contexts will share many active
neurons.
A.1.2
Field Definitions
For each randomly generated room, each neuron, indexed by j, has aj fields drawn from the gamma-
poisson distribution described above. Each firing field center is placed according to a homogeneous
(first two parts) or nonhomogeneous (last part) poisson process over space. Firing fields are gaussian,
so that the total spatial tuning is given by a sum of gaussians:
fA,j(xA) = .1Hz + Cj,A
aj
X
i
exp −
1
2(wi/2)2 (⃗xA −⃗µA,i)2
(20)
All neurons are given base firing rate of .1Hz, and Cj,A is chosen so that active neurons have a max
firing rate of 30Hz for simplicity. Max firing rates are not drawn from a distribution, to speed up pdf
convergence times. Likewise, widths are not chosen stochastically, and have equal fixed width. This
also speeds up pdf convergence times, and additionally lets us study the effect of changing firing field
widths in isolation.
A.1.3
High Dimensional Gaussians
Here we outline a standard method of demonstrating the exponential localization of gaussians to
shells in high dimensions [33, 34]. If z is distributed according to a normal N dimensional spherical
14

gaussian with variance σ2, and R = |z|2 is its norm, then the distribution of R is
p(R) = SNRN−1
(2πσ2)N/2 exp{−R2
2σ2 }
(21)
where SN is the area of the N dimensional unit sphere. Setting
∂
∂Rp(R) = 0, we find this distribution
has a maximum at σ
√
N. Now for any σq << σ
√
N, we have that
pR(σ
√
N + σq) = SN(σ
√
N + σq)N−1
(2πσ2)N/2
e−(σ
√
N+qσ)2
2σ2
(22)
=
SN
(2πσ2)N/2 e−N
2 −q
√
N−q2
2 +(N−1) ln(σ
√
N+σq)
(23)
=
SN
(2πσ2)N/2 e−N
2 +(N−1) ln(σ
√
N)e−q
√
N−q2
2 +(N−1) ln(1+
q
√
N )
(24)
= pR(σ
√
N) exp{−q
√
N −q2
2 + (N −1) ln(1 +
q
√
N
)}
(25)
= pR(σ
√
N) exp{−q
√
N −q2
2 + (N −1)( q
√
N
−q2
2N + O(N −3/2))}
(26)
= pR(σ
√
N) exp{−q2 + O(N −1/2)}
(27)
And so the mass of a high dimension gaussian is exponentially localized to an annulus of radius
σ
√
N. We can choose a q such that the majority of the probability mass of z is within a a sphere
of radius σ(
√
N + q). For all the figures in the main text, we use q = 2, which leads to ≈99.8%
of the mass of p(z) being within a sphere of radius σ(
√
N + q). As q is of order 1 in N, choosing
larger values leads to a negligible effect on derived values at large N, which we additionally verified
numerically.
For the variable noise model, ξ ∼N(0, ϕdiag{fA(xA)}). We have then that ξ at any position xA is
exponentially localized to an ellipsoid with major axis of length
p
Nϕf i
A(xA). Including the annulus
width, we have that the ellipsoid width in a particular direction is
p
ϕf i
A(xA)(
√
N + q).
A.1.4
Ellipsoid Intersection
We want to check if the manifolds widened out by noise intersect. For the simple noise model,
checking if the spheres centered at fA(xA) and fB(xB) for some pair xA,xB is equivalent to checking
if the distance between their centers is greater than twice their radius, or d(fA(xA), fB(xB)) >
2σ(
√
N + q). For the variable noise model, we need an efficient way to check if two ellipsoids
intersect.
From [35], two ellipsoids in a high dimensional euclidean space, defined by centers µA, µB and
covariance matrices ΣA, ΣB intersect if and only if the convex function
K(s) = 1 −sµT
a ΣAµa −(1 −s)µT
b ΣBµb + µT
∩Σsµ∩
(28)
becomes negative for any choice of s ∈[0, 1]. The proof is given in [35]. Here,
Σs = sΣA + (1 −s)ΣB
(29)
µ∩= Σ−1
s (sΣAµa + (1 −s)ΣBµb)
(30)
In the Poisson-like noise model, we check if the ellipsoids centered at fA(xA), fB(xB) in rate space
intersect. These ellipsoids are given by:
(r −fA(xA))T ((
√
N + q)2ϕΣA(xA))−1(r −fA(xA)) ≤1
(31)
(r −fB(xB))T ((
√
N + q)2ϕΣB(xB))−1(r −fB(xB)) ≤1
(32)
Here, ΣA(xA) = diag[fA(xA)]. I will drop the xA and xB for conciseness, with the understanding
that there is an implicit dependence. To check for intersection, we plug these into the form of the
convex function K(s):
K(s, xA, xB) = 1 −(fB −f T
A)[
1
1 −s(
√
N + q)2ϕΣA + 1
s(
√
N + q)2ϕΣB]−1(fB −fA)
15

The ellispoids centered at fA(xA), fB(xB) do not intersect if and only if there exists an s∗∈[0, 1]
such that K(s∗, xA, xB) < 0 [35]. Rearranging, we can write this as:
K(s, xA, xB) = 1 −
1
ϕ(
√
N + q)2
N
X
i
(f i
B(xB) −f i
A(xA))2
(
1
1−sf i
A(xA) + 1
sf i
B(xB))
The choice that of s that minimizes K(s, xA, xB) changes with xa, xb, and so we can let s∗(xA, xB)
represent this value. We define ϕ∗(xA, xB) by
ϕ∗(xA, xB) = 1
N
N
X
i
(f i
B(xB) −f i
A(xA))2
(
1
1−s∗(xA,xB)f i
A(xA) +
1
s∗(xA,xB)f i
B(xB))
(33)
This definition lets us write:
K(s∗(xA, xB), xA, xB) = 1 −
1
ϕ(
√
N + q)2 ϕ∗(xA, xB)
(34)
Now we want ellipsoids centered at fA(xA), fB(xB) to not intersect for any xA, xB,
which amounts to requiring that K(s∗(xA, xB), xA, xB) < 0 for all xA, xB, or equivalently
maxxA∈A,xB∈B K(s∗(xA, xB), xA, xB) < 0. To put this in a similar form as the gaussian case, we
can write this as the requirement that
min
xA,xB Nϕ∗(xA, xB) > (
√
N + q)2ϕ
(35)
A.2
Gaussian Distributed Miminum Distances
A.2.1
Gaussian Model
We define δmin = minxA,xB d(fA(xA), fB(xB)). δmin is a function of the maps fA, fB, which are
chosen at random with respect to a Gamma-Poisson distribution. Here, we find how the mean and
scale of δmin scale with N.
The distance in rate space evaluated at some pair of positions XA, XB for large N will look like
the square root of the sum of the square of many random variables, as the firing fields are randomly
chosen. In particular, each term in the sum itself is independent of N, so to get the rough shape as a
function of N of this distribution, we can discard some of the finer details of fA, fB.
d(fA(XA), fB(XB)) =
v
u
u
t
N
X
i
(f i
A(XA) −f i
B(XB))2
(36)
The construction of the firing fields of each neuron occurs independently, so Yi = (f i
A(XA) −
f i
B(XB))2 represent a set of i.i.d. random variables with some mean an variance which is independent
of N, allowing us to use the central limit theorem. We can write then
d(fA(XA), fB(XB)) =
v
u
u
t
N
X
i
(f i
A(XA) −f i
B(XB))2
(37)
=
p
N ˜µδ + Z1
(38)
=
p
N ˜µδ
p
1 + Z2
(39)
Where ˜µδ = E[Yi], and Z1 is a normally distributed random variable with mean zero and variance
NVar[Yi], by the central limit theorem, and Z2 is normally distributed with zero mean and variance
Var[Yi]
N ˜µ2
δ . As ˜µδ is independent of N, at large N, we can expand the square root around small Z2:
d(fA(XA), fB(XB)) ≈
p
N ˜µδ + 1
2Z2
(40)
We find then that the distance in rate space between XA and XB is distributed normally at large N,
with mean scaling like
√
N and variance that is independent of N,
d(fA(XA), fB(XB)) ∼N(˜µδ
√
N, ˜λ2
δ)
16

The constants are not determined here, though will be calculated in a simpler case later, and fit to
simulations. Now ˜µδ and ˜λδ may depend on the particular choice of positions XA and XB, but this
will still hold at positions where the minimum is most likely to be found, and so P(δmin) will also
have a mean that grows with
√
N and unit variance,
δmin ∼N(µδ
√
N, λ2
δ)
(41)
for yet determined constants.
A.2.2
Rate dependent model
We also need to calculate the behavior for P(Nϕ∗) at large N. We start with the definition of ϕ∗, and
want to show that it is gaussian distributed
Nϕ∗(xA, xB) =
N
X
i
(f i
B(xB) −f i
A(xA))2
(
1
1−s∗(xA,xB)f i
A(xA) +
1
s∗(xA,xB)f i
B(xB))
(42)
Again, we consider any particular fixed XA, XB. Then the content of the sum can be viewed as just
some random variable with respect to the distributions on fA, fB. The elements of the sum have
non-zero mean and variance and are i.i.d. This is because in constructing neural firing fields, the
placement of fields for neurons i and j are assumed to be independent. By the central limit theorem,
we have then that
Nϕ∗(XA, XB) ∼N(˜µϕN, ˜λ2
ϕN)
(43)
or equivalently
ϕ∗(XA, XB) ∼N(˜µϕ, ˜λ2
ϕ/N)
(44)
for some constants ˜µϕ, ˜λϕ. The values of ˜µϕ, ˜λϕ may depend on the exact position , but will be
independent of N at sufficiently large N, and so in particular, fluctuations of ϕ∗will mostly be due
to position. This implies that, as before, the minimum value Nϕ∗
min will have a distribution with the
same scaling as Nϕ∗at any position, but with different constants.
Nϕ∗
min ∼N(µϕN, λ2
ϕN)
(45)
Figure 7: Numerical demonstration that the constants µδ, λδ, µϕ, λϕ are independent of N for large
N in 1-d, as predicted.
17

A.3
Union Bound and Product Ansatz
In the main text, we assume that the probability that M contexts are distinguishable is approximately
a function of the probability that any pair is, via a saturation of the union bound PM = P(
M
2 )
2
. More
transparently, we assume:
P(M Contexts are distinguishable) ≈
Y
(ij)
P(i and j are distinguishable) = P M(M−1)/2
2
(46)
Strictly speaking this is a union bound PM ≤P M(M−1)/2
2
, as the probability that rooms 1 and 2 are
distinguishable and rooms 2 and 3 are is not independent. We argue that this bound is approximately
saturated at large N if noise is not too strong, by demonstrating each context occupies a vanishingly
small relative volume in rate space as N gets large. This argument is a rough reason to think that the
ansatz is true, but not an exact proof.
We consider the rate independent noise model to start. The total available volume in rate space is
≈F N
max. How we have incorporated noise lets neuron firing rates extend past Fmax, as it is a max
set before noise, and so firing rates can "spill out" of this N dimensional box. For one dimensional
rooms, fA carves out a curve of length l =
R
dx
qP
i( df i
dx )2 in rate space. For D dimensional rooms,
fA defines a surface, which has area
S =
Z
ddx
p
det g
(47)
Here g = JT
f Jf, with Jf being the jacobian Jf = ∂xif j. In D dimensional rooms, g will be a
matrix, with each element scaling no faster than linearly in N. The determinant then can scale no
faster than N D/2, so at worst, we expect the surface area to scale in N like
S ∝cDN D/2
(48)
where c is some constant. To go from the surfaces carved out by the maps f to the volumes occupied
by the firing rates of the neurons, we need to consider the effect of adding noise. Now we can roughly
approximate the effect of noise by putting an N −D spherical cross section to each point along the
surface. We avoid exact integrals as we primarily care about the scaling. The radius of each cross
section is σ
√
N, and so each cross section has a volume:
VN−D(σ
√
N) =
πN/2
Γ( N
2 + 1)(σ
√
N)N−D
Or, using stirlings approximation to get the scaling in N,
VN−D(σ
√
N) ∼
1
p
(N −D)π
(
2πe
N −D)N/2−D/2(σ2N)N/2−D/2
(49)
=
1
p
(N −D)π
(2πeσ2
N
N −D)
N−D
2
(50)
The approximate volume in rate space of the thickened manifolds then scales no faster in N than
Vr ∝cDN D/2
1
p
(N −D)π
(2πeσ2
N
N −D)
N−D
2
(51)
Assuming the dimension of the environment D is small (for physical environments, D is 1, 2, or 3,
but we might be interested in higher dimensional abstract ’environments’) compared to N and N is
large, then at worst the scaling is
Vr ∝N
D−1
2 (2πeσ2)
N−D
2
(52)
We have neglected the volume of the "caps" of these manifolds. For example, the one dimensional
rooms define a tube in rate space, and have half-spherical caps on each end. The volume of the
N dimensional sphere of radius
√
Nσ2 is
1
√
Nπ(2πeσ2)N/2. In higher dimensions, this additional
18

component would scale very roughly like the length of the boundary of the surface S times the
volume of the N −D + 1 sphere.
The proportion of the volume of the thickened manifold to the total volume of rate space, Vr/F N
max,
is then vanishing in N provided that the neurons are not too noisy. We get an approximate condition
of the form
√
2πeσ < Fmax. A more precise calculation might improve or deteriorate this bound,
but interestingly this mimics typical conditions on signal to noise ratios. Each room occupies a
vanishingly small fraction of the total volume in rate space as N grows large. Similar arguments hold
for the ellipsoidal noise model, as each ellipsoid occupies a smaller volume than its osculating sphere.
A.4
Exponentially Many Rooms
Here, we find the scaling of the number of rooms M with respect to the number of neurons N. We
will use the product ansatz:
PM = P M(M−1)/2
2
We can invert this equation by taking the logarithm of both side, then solving the quadratic formula
for M, to find that
M(N) =
s
2 log(PM)
log(P2(N)) + 1
4 + 1/2
(53)
Here, we can let PM represent a confidence. For example, if we are okay with being 95% percent
confident in storing multiple rooms, then M(N) becomes an equation purely dependent on P2(N).
Now P2(N) is, at large N, equal to an integral of a gaussian for both noise models. We start with the
simpler noise model. We have that
P2 = P(δ > 2σ(
√
N + q))
(54)
= 1 −F(2σ(
√
N + q))
(55)
≈1 −Φ(2σ(
√
N + q) −µδ
√
N
λδ
)
(56)
Here, F represents the cumulative distribution, and Φ is the cumulative distribution of the standard
normal distribution. The approximation comes from the central limit theorem at large N, with
µδ = E(δmin)/
√
N and λ2
δ = Var(δmin) are both independent of N. This can be written in terms of
the error function for the first noise model as
P2,δ(N) →1
2(1 −erf(2σ(
√
N + q) −µδ
√
N
√
2λδ
))
(57)
= 1
2(1 + erf((
√
Nµδ −2σ(
√
N + q))
√
2λδ
))
(58)
We can bring the second noise model into a similar form:
P2,ϕ = P( min
xA,xB Nϕ∗(xA, xB) > (
√
N + q)2ϕ)
(59)
= 1 −F((
√
N + q)2ϕ)
(60)
→1 −Φ((
√
N + q)2ϕ −Nµϕ
λϕ
√
N
)
(61)
= 1
2(1 −erf((
√
N + q)2ϕ −Nµϕ
√
2λϕ
√
N
))
(62)
= 1
2(1 + erf(Nµϕ −(
√
N + q)2ϕ
√
2λϕ
√
N
))
(63)
Here, F is the cumulative distribution for ϕ∗
minN, µϕ = E(ϕ∗
min)/N and λ2
ϕ = Var(ϕ∗
min)/N are
both independent of N.
19

In both noise models, we can write P2 = 1
2(1 + erf(u)), with u given in equation 58 and 63 for the
two noise models, respectively. P2 approaches either 1 or 0 for large N, depending on the strength of
the noise with respect to the mean distance µ. We have then:
M(N) =
s
2
log(PM)
log( 1
2(1 + erf(u))) + 1
4 + 1/2
(64)
In the noisy regime, this approaches 1 at large N. In the weak to moderate noise regime, we have
that u approaches ∞as N approaches ∞in both models, and the error function approaches 1. We
are interested in its asymptotic behaviour. We can use the following expansion at large u:
erfu = 1 −e−u2
√π (u−1 −1
2u−3 + ...)
(65)
Expanding to leading order in u then gives:
M(N) ≈
v
u
u
t2
log(PM)
log(1 −1
2
exp (−u2)
√π
(u−1 + O(u−3))
(66)
Now we can expand the logarithm by noticing that for small values,
s
−
A
ln(1 −x) + B ≈
r
A
x + O(x
1
2 )
(67)
So to leading order, we have:
M(N) ≈
v
u
u
t−2
log(1/PM)
log(1 −1
2
exp (−u2)
√π
u−1)
(68)
≈
p
2 log 1/Pm[1
2
exp (−u2)
√π
u−1]−1/2
(69)
= 2
q√π log(1/Pm)√ue
1
2 u2
(70)
At large N, the constant q is negligible, and so we can drop it, giving u for the rate independent and
the rate dependent model as u = µδ−2σ
√
2λδ
√
N, and u = µϕ−ϕ
√
2λϕ
√
N, respectively. Plugging in for both
noise models gives
Model 1: M(N) ≈
r
ln(1/PM)µδ −2σ
λδ
(8πN)1/4 exp [1
4(µδ −2σ
λδ
)2N]
(71)
Model 2: M(N) ≈
s
ln(1/PM)µϕ −ϕ
λϕ
(8πN)1/4 exp [1
4(µϕ −ϕ
λϕ
)2N]
(72)
In both noise models, the number of storable contexts as a function of N scales like
M(N) ∼N 1/4eγN
(73)
with the constant γ in each noise model being given by
γδ = (E[δmin]/
√
N −2σ
2
p
Var(δmin)
)2
γϕ = (
E[ϕ∗
min] −ϕ
2
p
NVar([ϕ∗
min])
)2
(74)
These values are shown for various noise levels, firing field widths, and room sizes in the main text
figure 3 and the supplemental figure 8.
20

Figure 8: The value of the exponential γ at large N as a function of firing field width and noise. From
left to right are 1d rooms, Gaussian noise; 1d rooms, Poisson-like noise; 2d rooms, Gaussian noise;
and 2d rooms, Poisson-like noise. Rooms increase in size from top to bottom (1m, 2m, 4m, 8m, and
16m rooms, and 1m2, 2m2, 4m2, 8m2, and 16m2 rooms). Under our Poisson Gamma statistics for
the number of active fields, we expect in smaller rooms, where the number of active fields is small, to
preference large fields for the objective of context segragation. Conversely, in large rooms, extremely
large fields become harmful for context segregation. White demarcates the region where decoding
multiple contexts is possible. The Poisson-like model is generally much more robust to noise.
21

A.4.1
Infinite Width Derivations
For neurons with infinite width, the number of storable contexts is purely a function of the number
of neurons which have active fields. In this limit, if there are N neurons, each context gets a binary
identifier. Consider two contexts A and B. If each neuron has a probability θ of being active, the
distribution of the hamming distance between these two contexts is given by
P(H = k) =
N
k

[θ2 + (1 −θ)2]N−k[2θ(1 −θ)]k
(75)
Now we are interested in P(min d(fA(xA), fB(xB)) > 2σ
√
N). In the infinite width limit, the
spatial depedence is lost, and d →fmax
√
H. We can write then that the probability that two rooms
are separable is
P(H > 4σ2
f 2max
N) =
N
X
k=⌈
4σ2
f2max N⌉
P(H = k)
(76)
The distribution P(H) is well approximated by a gaussian at large N, with mean µ = 2Nq(1 −q)
and variance σ2 = 2N(1 −θ)θ[(1 −θ)2 + θ]. From this, we get an integral similar to the one
arrived at in the main text. At large N, the probability that two rooms are separable approaches one if
2θ(1 −θ) >
4σ2
f 2
max . Rooms are optimally separable in the infinite width limit when θ = 1/2.
A.5
The Cramer-Rao Bound
To quantify a population level code for position, we consider estimators ˆx of position constructed
from population level firing, and compare to true position. In one dimension, the quality of any
estimator ˆx at a particular position is bounded below by the inverse Fisher information:
⟨(ˆx −x)2⟩r|x = Var(ˆx) ≥I−1(x)
(77)
In one dimension, the Fisher metric is given by:
I = Er[( ∂
∂xl)2]
(78)
Where l is the log likelihood of firing rates given position.
In higher dimensions, this Cramer-Rao bound is a statement about covariance:
⟨(ˆx −x)(ˆx −x)T ⟩≥I−1(x)
(79)
Here, ≥indicates that the difference of the LH and RH side is positive semi-definite. To get the
mean-squared error, we need to take a trace over the inverse Fisher information metric:
⟨(ˆx −x)2⟩= Tr ⟨(ˆx −x)(ˆx −x)T ⟩
(80)
= Tr Cov(ˆx) ≥Tr(I−1(x))
(81)
In higher dimensions, Cov(ˆx) ≥I−1(x) is a statement about the difference being positive semi-
definite, which leads to our trace condition above. The Fisher Metric is given by:
I = nEr[(∇xl)(∇xl)T ] = −nEr[∇x∇T
x l]
(82)
The averages in the Cramer-Rao bound are taken with respect to firing rates given positions. As we
are interested in having good spatial resolution across positions and contexts, we additionally take
averages over both. Below, we plug in the log-likelihoods for both noise models.
A.5.1
Gaussian Noise
In 1 dimension, we have that
l =
X
i
ln P(ri|x) = −
X
i
1
2σ2 (ri −f i
A(x))2
(83)
22

The Fisher Information then is given by
I = nEr[( ∂
∂xl)2]
(84)
= 1
σ4 Er[
X
i
f i
A
′(x)(ri −f i
A(x))
X
j
f j
A
′(x)(rj −f j
A(x))]
(85)
We have that
Er[rirj] = f i
A(x)f j
A(x) + δijσ2
;
Er[ri] = f i
A(x)
(86)
So the fisher information is
I = nEr[( ∂
∂xl)2]
(87)
= 1
σ4 Er[
X
i,j
f i
A
′(x)f j
A
′(x)(rirj −rjf i
A(x) −rif j
A(x) + f i
A(x)f j
A(x))]
(88)
= 1
σ4 [
X
i,j
f i
A
′(x)f j
A
′(x)(f j
A(x)f i
A(x) + σ2δij −2f j
A(x)f i
A(x) + f i
A(x)f j
A(x))]
(89)
= 1
σ2 [
X
i
f i
A
′(x)2]
(90)
The CR bound will be small when this is large. This implies that, the wider the firing fields, the
smaller the derivatives of f i
A will be at most locations, which leads to a smaller Fisher Information,
and so a worse bound. This leads to typically narrow fields. However, if we are in a region where all
firing fields are zero, the FI vanishes, and the bound explodes. This implies that the widths shouldn’t
be so small that there are regions with no firing fields. We also have that as the noise increase, the
information decreases, and the bound gets worse, as we expect.
In 2d, we replace derivatives with divergences, and take a trace at the end. We have:
∇xl = −∇x
X
i
1
2σ2 (ri −f i
A(x))2
(91)
= −
X
i
1
σ2 (ri −f i
A(x))∇f i
A(x)
(92)
Going through the same steps as before, we find that we just replace the ordinary product from before
with an outer product:
I = 1
σ2 [
X
i
(∇f i
A(x))(∇f i
A(x))T ]
(93)
A.5.2
Rate Dependent Noise
In the second noise model,
P(ri|x) =
1
p
2πϕf i
A(x)
exp −
1
2ϕf i
A(x)(ri −f i
A(x))2
(94)
Our log likelihood is
l =
X
i
[−
1
2ϕf i
A(x)(ri −f i
A(x))2 −ln
q
2πϕf i
A(x)]
(95)
=
X
i
[−
1
2ϕf i
A(x)(ri −f i
A(x))2 −1
2 ln f i
A(x)] + ...
(96)
23

This time, we will start with divergences, and demote them for 1d rooms. We have:
∇xl =
X
i
[−1
ϕf i
A
(ri −f i
A)∇f i
A +
1
2ϕf i
A
2 (ri −f i
A)2∇f i
A −
1
2f i
A
∇f i
A]
(97)
=
X
i
[−(f i
A(x)2 + ϕf i
A(x) −r2
i )
2ϕf i
A(x)2
∇f i
A]
(98)
The Fisher Information then is
X
ij
Er[((f i
A(x)2 + ϕf i
A(x) −r2
i )
2ϕf i
A(x)2
)((f j
A(x)2 + ϕf j
A(x) −r2
j)
2ϕf j
A(x)2
)]∇f i
A ⊗∇f j
A
(99)
We have that
Er[r2
i ] = f i
A(x)2 + ϕf i
A(x)
(100)
Er[r2
i r2
j]|i̸=j = (f i
A(x)2 + ϕf i
A(x))(f j
A(x)2 + ϕf j
A(x))
(101)
Er[r4
i ] = f i
A(x)4 + 3ϕ2f i
A(x)2 + 6f i
A(x)2ϕf i
A(x)2
(102)
= (f i
A(x)2 + ϕf i
A(x))(f i
A(x)2 + ϕf i
A(x)) + 4ϕf i
A(x)3 + 2ϕ2f i
A(x)2
(103)
Er[r2
i r2
j] = (f i
A(x)2 + ϕf i
A(x))(f j
A(x)2 + ϕf j
A(x)) + δij[4ϕf i
A(x)3 + 2ϕ2f i
A(x)2]
(104)
(105)
Most terms in the expectation cancel, except for where i = j:
I =
X
i
(4ϕf i
A(x)3 + 2ϕ2f i
A(x)2
(2ϕf i
A(x)2)2
∇f i
A ⊗∇f i
A
(106)
=
X
i
(
1
ϕf i
A(x) +
1
2f i
A(x)2 )∇f i
A ⊗∇f i
A
(107)
In 1-d, we replace the outer product and the divergences with ordinary scalar product and derivatives,
respectively.
A.6
Biasing Towards Boundaries
We investigated the effect of biasing place cell centers towards the boundary of environments. In
1-d, we bias the place cell centers toward boundaries by drawing centers from a symmetric beta
distribution, so that the bias can be characterized by the 1 parameter family of distributions:
P(µ) = β(µ/L; α, α) = Γ(2α)
Γ(α)2 (µ/L)α−1(1 −µ/L)α−1
(108)
We expect an improvement in decoding multiple contexts when the total squared activity near the
bulk and near the center is, on average, equal within a context. In one dimension, for an environment
of length L, we want then approximate equality:
⟨
X
i
fi(0)2⟩A = ⟨
X
i
fi(L/2)2⟩A
(109)
The average is with respect to number of firing fields centers and their location. If we assume for
simplicity that each neuron has exactly one firing field, then we have equality when
⟨f 2
maxe−
4
w2 µ2⟩µ = ⟨f 2
maxe−
4
w2 (µ−L/2)2⟩
(110)
Taking the average with respect to the beta distribution, the optimal bias can be found then by finding
where the following integral is zero:
Γ(2α)
Γ(α)2
Z L
0
dµ(µ/L)α−1(1 −µ/L)α−1(e−
4
w2 µ2 −e−
4
w2 (µ−L/2)2)
(111)
Or,
Z 1
0
dxxα−1(1 −x)α−1(e−4L2
w2 x −e−4L2
w2 (x−1/2)2) = 0
(112)
24

Figure 9: Beta distribution, from which we draw place cell centers. α is a degree of uniformity, with
α = 1 reproducing the uniform distribution.
To make this calculation numerically stable, we do the integral over an interior region (small ϵ)
Z 1−ϵ
ϵ
dxxα−1(1 −x)α−1(e−4L2
w2 x −e−4L2
w2 (x−1/2)2) = 0
(113)
We can invert this numerically to get an approximation of the optimal α based on equalization of firing
densities in the bulk and at the boundary. We find decent agreement between this rough calculation
and the true optimal bias found in the main text for both noise models, slightly overestimating and
underestimating the rate independent and the rate dependent model, respectively (Fig 5 C of the Main
Text).
A.7
Additional Computational Details
To reconstruct probability distributions for distances, we generate a large number of pairs of rooms
with a fixed number of neurons and widths, calculate distances in rate space, and then find the one
dimensional distributions over distances by taking a kernel density estimate over these generated
distances. Although the space of possible curves in our rate space is large, since we only need to
reconstruct the 1 dimensional distributions in δmin and ϕmin, which are asymptotically gaussian,
sampling this space suffices. We create between 1000 and 10000 samples in each numerical experi-
ment. To speed up calculations, we perform the sampling of surfaces in parallel using PyTorch [54].
We then use scikit learns’s built in Kernel density estimator with a gaussian kernel to reproduce the
distributions in δmin and ϕmin [55]. As the reconstructed distribution can depend heavily on the
choice of bandwidth used for the kernel, we calculate the kernel density multiple times for various
choices of the bandwidth, and pick the best bandwidth via 5-fold cross validation. All code was run
on a machine with an Intel Xeon-2145 processor and with a Titan Xp GPU for parallelized workflows.
25

NeurIPS Paper Checklist
1. Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: There are three main claims layed out in the abstract. These are about the
exponential capacity of the place code, the tradeoff between resolution and capacity, and
imporved performance due to biasing towards boundaries. All of these points are addressed
in the main text.
Guidelines:
• The answer NA means that the abstract and introduction do not include the claims
made in the paper.
• The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2. Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: The main limitations of the work, as well as future directions that might
address some of these limitations, are layed out in the discussion portion of the paper.
Guidelines:
• The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3. Theory Assumptions and Proofs
26

Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: The proof of most statements are layed out in the supplemental, to save on
space.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
• The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4. Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [NA]
Justification: We don’t perform any experiments with data. However, how all numerical
results are arrived at are sufficiently explained so that they could be reproduced.
Guidelines:
• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
27

5. Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [No]
Justification: All numerical experiments performed are simple enough to reproduce without
access to code. Code is available upon request.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
public/guides/CodeSubmissionPolicy) for more details.
• While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines (https:
//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
• The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
• The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
• At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
• Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6. Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [NA]
Justification: We do not have training or test data sets.
Guidelines:
• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material.
7. Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [NA]
Justification: Statistical significance is not a part of our theoretical analysis.
Guidelines:
• The answer NA means that the paper does not include experiments.
• The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
28

• The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
• It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8. Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: As the numerics are not the focus of the paper, numerical details and compute
resources are provided in the supplemental
Guidelines:
• The answer NA means that the paper does not include experiments.
• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9. Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
Answer: [Yes]
Justification: We do not believe that our work has any harmful consequences as layed out in
the Code of Ethics.
Guidelines:
• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
• If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10. Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: In this work, we primarily study hippocampal coding, which likely will not
have societal impacts past a better understanding of the hippocampus.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
• If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
29

• Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
• The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11. Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: No such models or datasets are involved.
Guidelines:
• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
• We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12. Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: We use the latest versions of both PyTorch and SciKit-Learn, and cite both in
the supplemental.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
30

• If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
• For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
• If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13. New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: No such assets are introduced.
Guidelines:
• The answer NA means that the paper does not release new assets.
• Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
• The paper should discuss whether and how consent was obtained from people whose
asset is used.
• At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14. Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: No such models or datasets are involved.
Guidelines:
• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: We have no human participants in our study.
Guidelines:
• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
31

• We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
• For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
32

