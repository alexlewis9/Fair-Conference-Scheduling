Optimizing Solution-Samplers for Combinatorial
Problems: The Landscape of Policy-Gradient Methods
Constantine Caramanis
UT Austin & Archimedes / Athena RC
constantine@utexas.edu
Dimitris Fotakis
NTUA & Archimedes / Athena RC
fotakis@cs.ntua.gr
Alkis Kalavasis
Yale University
alvertos.kalavasis@yale.edu
Vasilis Kontonis
UT Austin
vkonton@gmail.com
Christos Tzamos
UOA & Archimedes / Athena RC
tzamos@wisc.edu
Abstract
Deep Neural Networks and Reinforcement Learning methods have empirically
shown great promise in tackling challenging combinatorial problems. In those
methods a deep neural network is used as a solution generator which is then trained
by gradient-based methods (e.g., policy gradient) to successively obtain better
solution distributions. In this work we introduce a novel theoretical framework for
analyzing the effectiveness of such methods. We ask whether there exist generative
models that (i) are expressive enough to generate approximately optimal solutions;
(ii) have a tractable, i.e, polynomial in the size of the input, number of parameters;
(iii) their optimization landscape is benign in the sense that it does not contain
sub-optimal stationary points. Our main contribution is a positive answer to this
question. Our result holds for a broad class of combinatorial problems including
Max- and Min-Cut, Max-ğ‘˜-CSP, Maximum-Weight-Bipartite-Matching, and the
Traveling Salesman Problem. As a byproduct of our analysis we introduce a novel
regularization process over vanilla gradient descent and provide theoretical and
experimental evidence that it helps address vanishing-gradient issues and escape
bad stationary points.
1
Introduction
Gradient descent has proven remarkably effective for diverse optimization problems in neural net-
works. From the early days of neural networks, this has motivated their use for combinatorial
optimization [HT85, Smi99, VFJ15, BPL+16]. More recently, an approach by [BPL+16], where a
neural network is used to generate (sample) solutions for the combinatorial problem. The parameters
of the neural network thus parameterize the space of distributions. This allows one to perform gradient
steps in this distribution space. In several interesting settings, including the Traveling Salesman Prob-
lem, they have shown that this approach works remarkably well. Given the widespread application but
also the notorious difficulty of combinatorial optimization [GLS12, PS98, S+03, Sch05, CLS+95],
approaches that provide a more general solution framework are appealing.
This is the point of departure of this paper. We investigate whether gradient descent can succeed in a
general setting that encompasses the problems studied in [BPL+16]. This requires a parameterization
37th Conference on Neural Information Processing Systems (NeurIPS 2023).

of distributions over solutions with a â€œniceâ€ optimization landscape (intuitively, that gradient descent
does not get stuck in local minima or points of vanishing gradient) and that has a polynomial
number of parameters. Satisfying both requirements simultaneously is non-trivial. As we show
precisely below, a simple lifting to the exponential-size probability simplex on all solutions guarantees
convexity; and, on the other hand, compressed parameterizations with â€œbadâ€ optimization landscapes
are also easy to come by (we give a natural example for Max-Cut in Remark 1). Hence, we seek to
understand the parametric complexity of gradient-based methods, i.e., how many parameters suffice
for a benign optimization landscape in the sense that it does not contain â€œbadâ€ stationary points.
We thus theoretically investigate whether there exist solution generators with a tractable number
of parameters that are also efficiently optimizable, i.e., gradient descent requires a small number
of steps to reach a near-optimal solution. We provide a positive answer under general assumptions
and specialize our results for several classes of hard and easy combinatorial optimization problems,
including Max-Cut and Min-Cut, Max-ğ‘˜-CSP, Maximum-Weighted-Bipartite-Matching and Traveling
Salesman. We remark that a key difference between (computationally) easy and hard problems is not
the ability to find a compressed and efficiently optimizable generative model but rather the ability to
efficiently draw samples from the parameterized distributions.
1.1
Our Framework
We introduce a theoretical framework for analyzing the effectiveness of gradient-based methods on
the optimization of solution generators in combinatorial optimization, inspired by [BPL+16].
Let â„be a collection of instances of a combinatorial problem with common solution space ğ‘†and
ğ¿(Â·; ğ¼) : ğ‘†â†’R be the cost function associated with an instance ğ¼âˆˆâ„, i.e., ğ¿(ğ‘ ; ğ¼) is the cost of
solution ğ‘ given the instance ğ¼. For example, for the Max-Cut problem the collection of instances â„
corresponds to all graphs with ğ‘›nodes, the solution space ğ‘†consists of all subsets of nodes, and the
loss ğ¿(ğ‘ ; ğ¼) is equal to (minus) the weight of the cut (ğ‘ , [ğ‘›] âˆ–ğ‘ ) corresponding to the subset of nodes
ğ‘ âˆˆğ‘†(our goal is to minimize ğ¿).
Definition 1 (Solution Cost Oracle). For a given instance ğ¼we assume that we have access to an
oracle ğ’ª(Â·; ğ¼) to the cost of any given solution ğ‘ âˆˆğ‘†, i.e., ğ’ª(ğ‘ ; ğ¼) = ğ¿(ğ‘ ; ğ¼).
The above oracle is standard in combinatorial optimization and query-efficient algorithms are provided
for various problems [RSW17, GPRW19, LSZ21, AEG+22, PRW22]. We remark that the goal of
this work is not to design algorithms that solve combinatorial problems using access to the solution
cost oracle (as the aforementioned works do). This paper focuses on landscape design: the algorithm
is fixed, namely (stochastic) gradient descent; the question is how to design a generative model that
has a small number of parameters and the induced optimization landscape allows gradient-based
methods to converge to the optimal solution without getting trapped at local minima or vanishing
gradient points.
Let â„›be some prior distribution over the instance space â„and ğ’²be the space of parameters of the
model. We now define the class of solution generators. The solution generator ğ‘(ğ‘¤) with parameter
ğ‘¤âˆˆğ’²takes as input an instance ğ¼and generates a random solution ğ‘ in ğ‘†. To distinguish between
the output, the input, and the parameter of the solution generator, we use the notation ğ‘(Â·; ğ¼; ğ‘¤) to
denote the distribution over solutions and ğ‘(ğ‘ ; ğ¼; ğ‘¤) to denote the probability of an individual solution
ğ‘ âˆˆğ‘†. We denote by ğ’«= {ğ‘(ğ‘¤) : ğ‘¤âˆˆğ’²} the above parametric class of solution generators. For
some parameter ğ‘¤, the loss corresponding to the solutions sampled by ğ‘(Â·; ğ¼; ğ‘¤) is equal to
â„’(ğ‘¤) = E
ğ¼âˆ¼â„›[â„’ğ¼(ğ‘¤)] , â„’ğ¼(ğ‘¤) =
E
ğ‘ âˆ¼ğ‘(Â·;ğ¼;ğ‘¤)[ğ¿(ğ‘ ; ğ¼)] .
(1)
Our goal is to optimize the parameter ğ‘¤âˆˆğ’²in order to find a sampler ğ‘(Â·; ğ¼; ğ‘¤) whose loss â„’(ğ‘¤)
is close to the expected optimal value opt:
opt = E
ğ¼âˆ¼â„›
[ï¸‚
min
ğ‘ âˆˆğ‘†ğ¿(ğ‘ ; ğ¼)
]ï¸‚
.
(2)
The policy gradient method [Kak01] expresses the gradient of â„’as follows
âˆ‡ğ‘¤â„’(ğ‘¤) = E
ğ¼âˆ¼â„›
E
ğ‘ âˆ¼ğ‘(Â·;ğ¼;ğ‘¤)[ğ¿(ğ‘ ; ğ¼) âˆ‡ğ‘¤log ğ‘(ğ‘ ; ğ¼; ğ‘¤)] ,
and updates the parameter ğ‘¤using the gradient descent update. Observe that a (stochastic) policy
gradient update can be implemented using only access to a solution cost oracle of Definition 1.
2

Solution Generators.
In [BPL+16] the authors used neural networks as parametric solution gen-
erators for the TSP problem. They provided empirical evidence that optimizing the parameters of
the neural network using the policy gradient method results to samplers that generate very good
solutions for (Euclidean) TSP instances. Parameterizing the solution generators using neural networks
essentially compresses the description of distributions over solutions (the full parameterization would
require assigning a parameter to every solution-instance pair (ğ‘ , ğ¼)). Since for most combinatorial
problems the size of the solution space is exponentially large (compared to the description of the
instance), it is crucial that for such methods to succeed the parameterization must be compressed in
the sense that the description of the parameter space ğ’²is polynomial in the size of the description
of the instance family â„. Apart from having a tractable number of parameters, it is important that
the optimization objective corresponding to the parametric class ğ’«can provably be optimized using
some first-order method in polynomial (in the size of the input) iterations.
We collect these desiderata in the following definition. We denote by [â„] the description size of â„, i.e.,
the number of bits required to identify any element of â„. For instance, if â„is the space of unweighted
graphs with at most ğ‘›nodes, [â„] = ğ‘‚(ğ‘›2).
Definition 2 (Complete, Compressed and Efficiently Optimizable Solution Generator). Fix a prior
â„›over â„, a family of solution generators ğ’«= {ğ‘(ğ‘¤) : ğ‘¤âˆˆğ’²}, a loss function â„’as in Equation
(1) and some ğœ–> 0.
1. We say that ğ’«is complete if there exists some ğ‘¤âˆˆğ’²such that â„’(ğ‘¤) â‰¤opt + ğœ€, where
opt is defined in (2).
2. We say that ğ’«is compressed if the description size of the parameter space ğ’²is polynomial
in [â„] and in log(1/ğœ€).
3. We say that ğ’«is efficiently optimizable if there exists a first-order method applied on the
objective â„’such that after ğ‘‡= poly([ğ’²], 1/ğœ€) many updates on the parameter vectors,
finds an (at most) ğœ–-sub-optimal vector Ì‚ï¸€ğ‘¤, i.e., â„’( Ì‚ï¸€ğ‘¤) â‰¤â„’(ğ‘¤) + ğœ–.
Remark 1. We remark that constructing parametric families that are complete and compressed,
complete and efficiently optimizable, or compressed and efficiently optimizable (i.e., satisfying any
pair of assumptions of Question 1 but not all 3) is usually a much easier task. Consider, for example,
the Max-Cut problem on a fixed (unweighted) graph with ğ‘›nodes. Note that â„has description size
ğ‘‚(ğ‘›2). Solutions of the Max-Cut for a graph with ğ‘›nodes are represented by vertices on the binary
hypercube {Â±1}ğ‘›(coordinate ğ‘–dictates the side of the cut that we put node ğ‘–). One may consider
the full parameterization of all distributions over the hypercube. It is not hard to see that this is a
complete and efficiently optimizable family (the optimization landscape corresponds to optimizing
a linear objective). However, it is not compressed, since it requires 2ğ‘›parameters. On the other
extreme, considering a product distribution over coordinates, i.e., we set the value of node ğ‘–to be +1
with probability ğ‘ğ‘–and âˆ’1 with 1âˆ’ğ‘ğ‘–gives a complete and compressed family. However, as we show
in Appendix B, the landscape of this compressed parameterization suffers from highly sub-optimal
local minima and therefore, it is not efficiently optimizable.
Therefore, in this work we investigate whether it is possible to have all 3 desiderata of Definition 2 at
the same time.
Question 1. Are there complete, compressed, and efficiently optimizable solution generators (i.e.,
satisfying Definition 2) for challenging combinatorial tasks?
1.2
Our Results
Our Contributions.
Before we present our results formally, we summarize the contributions of
this work.
â€¢ Our main contribution is a positive answer (Theorem 1) to Question 1 under general
assumptions that capture many combinatorial tasks. We identify a set of conditions (see
Assumption 1) that allow us to design a family of solution generators that are complete,
compressed and efficiently optimizable.
â€¢ The conditions are motivated by obstacles that are important for any approach of this nature.
This includes solutions that escape to infinity, and also parts of the landscape with vanishing
gradient. See the discussion in Section 3 and Figure 1.
3

â€¢ We specialize our framework to several important combinatorial problems, some of which
are NP-hard, and others tractable: Max-Cut, Min-Cut, Max-ğ‘˜-CSP, Maximum-Weight-
Bipartite-Matching, and the Traveling Salesman Problem.
â€¢ Finally, we investigate experimentally the effect of the entropy regularizer and the fast/slow
mixture scheme that we introduced (see Section 3) and provide evidence that it leads to
better solution generators.
We begin with the formal presentation of our assumptions on the feature mappings of the instances
and solutions and on the structure of cost function of the combinatorial problem.
Assumption 1 (Structured Feature Mappings). Let ğ‘†be the solution space and â„be the instance
space. There exist feature mappings ğœ“ğ‘†: ğ‘†â†’ğ‘‹, for the solutions, and, ğœ“â„: â„â†’ğ‘, for the
instances, where ğ‘‹, ğ‘are Euclidean vector spaces of dimension ğ‘›ğ‘‹and ğ‘›ğ‘, such that
1. (Bounded Feature Spaces) The feature and instance mappings are bounded, i.e., there exist
ğ·ğ‘†, ğ·â„> 0 such that â€–ğœ“ğ‘†(ğ‘ )â€–2 â‰¤ğ·ğ‘†, for all ğ‘ âˆˆğ‘†and â€–ğœ“â„(ğ¼)â€–2 â‰¤ğ·â„, for all ğ¼âˆˆâ„.
2. (Bilinear Cost Oracle) The cost of a solution ğ‘ under instance ğ¼can be expressed as a
bilinear function of the corresponding feature vector ğœ“ğ‘†(ğ‘ ) and instance vector ğœ“â„(ğ¼), i.e.,
the solution oracle can be expressed as ğ’ª(ğ‘ , ğ¼) = ğœ“â„(ğ¼)âŠ¤ğ‘€ğœ“ğ‘†(ğ‘ ) for any ğ‘ âˆˆğ‘†, ğ¼âˆˆâ„,
for some matrix ğ‘€with â€–ğ‘€â€–F â‰¤ğ¶.
3. (Variance Preserving Features) There exists ğ›¼> 0 such that Varğ‘ âˆ¼ğ‘ˆ(ğ‘†)[ğ‘£Â·ğœ“ğ‘†(ğ‘ )] â‰¥ğ›¼â€–ğ‘£â€–2
2
for any ğ‘£âˆˆğ‘‹, where ğ‘ˆ(ğ‘†) is the uniform distribution over the solution space ğ‘†.
4. (Bounded Dimensions/Diameters) The feature dimensions ğ‘›ğ‘‹, ğ‘›ğ‘, and the diameter bounds
ğ·ğ‘†, ğ·â„, ğ¶are bounded above by a polynomial of the description size of the instance space
â„. The variance lower bound ğ›¼is bounded below by 1/poly([â„]).
Remark 2 (Boundedness and Bilinear Cost Assumptions). We remark that Items 1, 4 are simply
boundedness assumptions for the corresponding feauture mappings and usually follow easily assum-
ing that we consider reasonable feature mappings. At a high-level, the assumption that the solution
is a bilinear function of the solution and instance features (Item 2) prescribes that â€œgoodâ€ feature
mappings should enable a simple (i.e., bilinear) expression for the cost function. In the sequel we see
that this is satisfied by natural feature mappings for important classes of combinatorial problems.
Remark 3 (Variance Preservation Assumption). In Item 3 (variance preservation) we require that the
solution feature mapping has variance along every direction, i.e., the feature vectors corresponding to
the solutions must be â€œspread-outâ€ when the underlying solution generator is the uniform distribution.
As we show, this assumption is crucial so that the gradients of the resulting optimization objective are
not-vanishing, allowing for its efficient optimization.
We mention that various important combinatorial problems satisfy Assumption 1. For instance,
Assumption 1 is satisfied by Max-Cut, Min-Cut, Max-ğ‘˜-CSP, Maximum-Weight-Bipartite-Matching
and Traveling Salesman. We refer the reader to the upcoming Section 2 for an explicit description of
the structured feature mappings for these problems. Having discussed Assumption 1, we are ready to
state our main abstract result which resolves Question 1.
Theorem 1. Consider a combinatorial problem with instance space â„that satisfies Assumption 1.
For any prior â„›over â„and ğœ–> 0, there exists a family of solution generators ğ’«= {ğ‘(ğ‘¤) : ğ‘¤âˆˆğ’²}
with parameter space ğ’²that is complete, compressed and, efficiently optimizable.
A sketch behind the design of the family ğ’«can be found in Section 3 and Section 4.
Remark 4 (Computational Barriers in Sampling). We note that the families of generative models
(a.k.a., solution generators) that we provide have polynomial parameter complexity and are opti-
mizable in a small number of steps using gradient-based methods. Hence, in a small number of
iterations, gradient-based methods converge to distributions whose mass is concentrated on nearly
optimal solutions. This holds, as we show, even for challenging (NP-hard) combinatorial problems.
Our results do not, however, prove P = NP, as it may be computationally hard to sample from our
generative models. We remark that while such approaches are in theory hard, such models seem to
perform remarkably well experimentally where sampling is based on Langevin dynamics techniques
[SE20, SSDK+20]. Though as our theory predicts, and simulations support, landscape problems
seem to be a direct impediment even to obtain good approximate solutions.
4

Remark 5 (Neural Networks as Solution Samplers). A natural question would be whether our results
can be extended to the case where neural networks are (efficient) solution samplers, as in [BPL+16].
Unfortunately, a benign landscape result for neural network solution generators most likely cannot
exist. It is well-known that end-to-end theoretical guarantees for training neural networks are out of
reach since the corresponding optimization tasks are provably computationally intractable, see, e.g.,
[CGKM22] and the references therein.
Finally, we would like to mention an interesting aspect of Assumption 1. Given a combinatorial
problem, Assumption 1 essentially asks for the design of feature mappings for the solutions and the
instances that satisfy desiderata such as boundedness and variance preservation. Max-Cut, Min-Cut,
TSP and Max-ğ‘˜-CSP and other problems satisfy Assumption 1 because we managed to design
appropriate (problem-specific) feature mappings that satisfy the requirements of Assumption 1. There
are interesting combinatorial problems for which we do not know how to design such good feature
mappings. For instance, the "natural" feature mapping for the Satisfiability problem (SAT) (similar
to the one we used for Max-ğ‘˜-CSPs) would require feature dimension exponential in the size of the
instance (we need all possible monomials of ğ‘›variables and degree at most ğ‘›) and therefore, would
violate Item 4 of Assumption 1.
1.3
Related Work
Neural Combinatorial Optimization.
Tackling combinatorial optimization problems constitutes
one of the most fundamental tasks of theoretical computer science [GLS12, PS98, S+03, Sch05,
CLS+95] and various approaches have been studied for these problems such as local search methods,
branch-and-bound algorithms and meta-heuristics such as genetic algorithms and simulated annealing.
Starting from the seminal work of [HT85], researchers apply neural networks [Smi99, VFJ15,
BPL+16] to solve combinatorial optimization tasks. In particular, researchers have explored the power
of machine learning, reinforcement learning and deep learning methods for solving combinatorial
optimization problems [BPL+16, YW20, LZ09, DCL+18, BLP21, MSIB21, NOST18, SHM+16,
MKS+13, SSS+17, ER18, KVHW18, ZCH+20, CCK+21, MGH+19, GCF+19, KLMS19].
The use of neural networks in combinatorial problems is extensive [SLB+18, JLB19, GCF+19,
YGS20, MSIB21, BPL+16, KDZ+17, YP19, CT19, YBV19, KCK+20, KCY+21, DAT20, NJS+20,
TRWG21, AMW18, KL20, Jeg22, SBK22, ART23] and various papers aim to understand the the-
oretical ability of neural networks to solve such problems [HS23b, HS23a, Gam23]. Our paper
builds on the framework of the influential experimental work of [BPL+16] to tackle combinatorial
optimization problems such as TSP using neural networks and reinforcement learning. [KP+21]
uses an entropy maximization scheme in order to generate diversified candidate solutions. This
experimental heuristic is quite close to our theoretical idea for entropy regularization. In our work,
entropy regularization allows us to design quasar-convex landscapes and the fast/slow mixing scheme
to obtain diversification of solutions. Among other related applied works, [KCK+20, KPP22] study
the use of Transformer architectures combined with the Reinforce algorithm employing symmetries
(i.e., the existence of multiple optimal solutions of a CO problem) improving the generalization
capability of Deep RL NCO and [MLC+21] studies Transformer architectures and aims to learn
improvement heuristics for routing problems using RL.
Gradient Descent Dynamics.
Our work provides theoretical understanding on the gradient-descent
landscape arising in NCO problems. Similar questions regarding the dynamics of gradient descent
have been studied in prior work concerning neural networks; for instance, [AS20] and [AKM+21]
fix the algorithm (SGD on neural networks) and aim to understand the power of this approach (which
function classes can be learned). Various other works study gradient descent dynamics in neural
networks. We refer to [AS18, AS20, ABAB+21, MYSSS21, BEG+22, DLS22, ABA22, AAM22,
BBSS22, ABAM23, AKM+21, EGK+23] (and the references therein) for a small sample of this line
of research.
2
Combinatorial Applications
We now consider concrete combinatorial problems and show that there exist appropriate and natural
feature mappings for the solutions and instances that satisfy Assumption 1; so Theorem 1 is applicable
for any such combinatorial task. For a more detailed treatment, we refer to Appendix G.
5

Min-Cut and Max-Cut. Min-Cut (resp. Max-Cut) are central graph combinatorial problems where
the task is to split the nodes of the graph in two subsets so that the number of edges from one subset
to the other (edges of the cut) is minimized (resp. maximized). Given a graph ğºwith ğ‘›nodes
represented by its Laplacian matrix ğ¿ğº= ğ·âˆ’ğ´, where ğ·is the diagonal degree matrix and ğ´
is the adjacency matrix of the graph, the goal in the Min-Cut (resp. Max-Cut) problem is to find a
solution vector ğ‘ âˆˆ{Â±1}ğ‘›so that ğ‘ âŠ¤ğ¿ğºğ‘ /4 is minimized (resp. maximized).
We first show that there exist natural feature mappings so that the cost of every solution ğ‘ under
any instance/graph ğºis a bilinear function of the feature vectors, see Item 2 of Assumption 1.
We consider the correlation-based feature mapping ğœ“ğ‘†(ğ‘ ) = (ğ‘ ğ‘ âŠ¤)â™­âˆˆRğ‘›2, where by (Â·)â™­we
denote the vectorization/flattening operation and the Laplacian for the instance (graph), ğœ“â„(ğº) =
(ğ¿ğº)â™­âˆˆRğ‘›2. Then simply setting the matrix ğ‘€to be the identity ğ¼âˆˆRğ‘›2Ã—ğ‘›2 the cost of any
solution ğ‘ can be expressed as the bilinear function ğœ“â„(ğº)âŠ¤ğ‘€ğœ“ğ‘†(ğ‘ ) = (ğ¿â™­
ğº)âŠ¤(ğ‘ ğ‘ âŠ¤)â™­= ğ‘ âŠ¤ğ¿ğºğ‘ .
We observe that for (unweighted) graphs with ğ‘›nodes the description size of the family of all
instances â„is roughly ğ‘‚(ğ‘›2), and therefore the dimensions of the feature mappings ğœ“ğ‘†, ğœ“â„are
clearly polynomial in the description size of â„. Moreover, considering unweighted graphs, it holds
that â€–ğœ“â„(ğº)â€–2, â€–ğœ“ğ‘†(ğ‘ )â€–2, â€–ğ‘€â€–F â‰¤poly(ğ‘›). Therefore, the constants ğ·ğ‘†, ğ·â„, ğ¶are polynomial in
the description size of the instance family.
It remains to show that our solution feature mapping satisfies the variance preservation assumption,
i.e., Item 3 in Assumption 1. A uniformly random solution vector ğ‘ âˆˆ{Â±1}ğ‘›is sampled by setting
each ğ‘ ğ‘–= 1 with probability 1/2 independently. In that case, we have E[ğ‘£Â· ğ‘¥] = 0 and therefore
Var(ğ‘£Â· ğ‘¥) = E[(ğ‘£Â· ğ‘¥)2] = âˆ‘ï¸€
ğ‘–Ì¸=ğ‘—ğ‘£ğ‘–ğ‘£ğ‘—E[ğ‘¥ğ‘–ğ‘¥ğ‘—] = âˆ‘ï¸€
ğ‘–ğ‘£2
ğ‘–= â€–ğ‘£â€–2
2, since, by the independence of
ğ‘¥ğ‘–, ğ‘¥ğ‘—, the cross-terms of the sum vanish. We observe that the same hold true for the Max-Cut problem
and therefore, structured feature mappings exist for Max-Cut as well (where ğ¿(ğ‘ ; ğº) = âˆ’ğ‘ âŠ¤ğ¿ğºğ‘ ).
We shortly mention that there also exist structured feature mappings for Max-ğ‘˜-CSP. We refer to
Theorem 4 for further details.
Remark 6 (Partial Instance Information/Instance Context). We remark that Assumption 1 allows for
the â€œinstanceâ€ ğ¼to only contain partial information about the actual cost function. For example,
consider the setting where each sampled instance is an unweighted graph ğºbut the cost oracle takes
the form ğ’ª(ğº, ğ‘ ) = (ğ¿ğº)â™­ğ‘€(ğ‘ ğ‘ âŠ¤)â™­for a matrix ğ‘€ğ‘–ğ‘—= ğ‘ğ‘–when ğ‘–= ğ‘—and ğ‘€ğ‘–ğ‘—= 0 otherwise.
This cost function models having a unknown weight function, i.e., the weight of edge ğ‘–of ğºis ğ‘ğ‘–if
edge ğ‘–exists in the observed instance ğº, on the edges of the observed unweighted graph ğº, that the
algorithm has to learn in order to be able to find the minimum or maximum cut. For simplicity, in
what follows, we will continue referring to ğ¼as the instance even though it may only contain partial
information about the cost function of the underlying combinatorial problem.
Maximum-Weight-Bipartite-Matching and TSP. The Maximum-Weight-Bipartite-Matching
(MWBP) problem is another graph problem that, given a bipartite graph ğºwith ğ‘›nodes and
ğ‘šedges, asks for the maximum-weight matching. The feature vector corresponding to a matching
can be represented as a binary matrix ğ‘…âˆˆ{0, 1}ğ‘›Ã—ğ‘›with âˆ‘ï¸€
ğ‘—ğ‘…ğ‘–ğ‘—= 1 for all ğ‘–and âˆ‘ï¸€
ğ‘–ğ‘…ğ‘–ğ‘—= 1
for all ğ‘—, i.e., ğ‘…is a permutation matrix. Therefore, for a candidate matching ğ‘ , we set ğœ“ğ‘†(ğ‘ ) to be
the matrix ğ‘…defined above. Moreover, the feature vector of the graph is the (negative flattened)
adjacency matrix ğ¸â™­. The cost oracle is then ğ¿(ğ‘…; ğ¸) = âˆ‘ï¸€
ğ‘–ğ‘—ğ¸ğ‘–ğ‘—ğ‘€ğ‘–ğ‘—ğ‘…ğ‘–ğ‘—perhaps for an unknown
weight matrix ğ‘€ğ‘–ğ‘—(see Remark 6). For the Traveling Salesman Problem (TSP) the feature vector is
again a matrix ğ‘…with the additional constraint that ğ‘…has to represent a single cycle (a tour over all
cities). The cost function for TSP is again ğ¿(ğ‘…; ğ¸) = âˆ‘ï¸€
ğ‘–ğ‘—ğ¸ğ‘–ğ‘—ğ‘€ğ‘–ğ‘—ğ‘…ğ‘–ğ‘—. One can check that those
representations of the instance and solution satisfy the assumptions of Items 1 and 4. Showing that
the variance of those representations has a polynomial lower bound is more subtle and we refer the
reader to the Supplementary Material.
We shortly mention that the solution generators for Min-Cut and Maximum-Weight-Bipartite-
Matching are also efficiently samplable.
3
Optimization Landscape
Exponential Families as Solution Generators.
A natural candidate to construct our family of
solution generators is to consider the distribution that assigns to each solution ğ‘ âˆˆğ‘†and instance ğ¼âˆˆ
â„mass proportional to its score exp(âˆ’ğœğ¿(ğ‘ ; ğ¼)) = exp(âˆ’ğœğœ“â„(ğ¼)âŠ¤ğ‘€ğœ“ğ‘†(ğ‘ )) = exp(âˆ’ğœğ‘§âŠ¤ğ‘€ğ‘¥)
6

Figure 1: In the left plot, we show the landscape of the â€œvanillaâ€ objective of Eq.(1) for the feature domain
ğ‘‹= {(1, 0), (2, 2), (0, 2)} and linear cost oracle ğ‘Â· ğ‘¥for ğ‘= (âˆ’3, âˆ’3). We see that the â€œvanillaâ€ objective
is minimized at the direction of âˆ’ğ‘, i.e., along the direction ğœ(1, 1) for ğœâ†’+âˆ. We observe the two issues
described in Section 3, i.e., that the true minimizer is a point at infinity, and that gradients vanish so gradient
descent may get trapped in sub-optimal solutions, (e.g., in the upper-right corner if initialized in the top corner).
In the middle plot, we show the landscape of the entropy-regularized objective of Eq.(3) that makes the minimizer
finite and brings it closer to the origin. Observe that even if a gradient iteration is initialized in the top corner it
will eventually converge to the minimizer; however the rate of convergence may be very slow. The right plot
corresponds to the loss objective where we combine a mixture of exponential families as solution generator, as in
Eq.(5), and the entropy regularization approach. We observe that we are able to obtain a benign (quasar-convex)
landscape via the entropy regularization while the mixture-generator guarantees non-vanishing gradients.
for some â€œtemperatureâ€ parameter ğœ, where ğœ“â„and ğœ“ğ‘†are the feature mappings promised to exist
due to Assumption 1, ğ‘§= ğœ“â„(ğ¼), and, ğ‘¥= ğœ“ğ‘†(ğ‘ ). Note that as long as ğœâ†’+âˆ, this distribution
tends to concentrate on solutions that achieve small loss.
Remark 7. To construct the above solution sampler one could artificially query specific solutions to
the cost oracle of Definition 1 and try to learn the cost matrix ğ‘€. However, we remark that our goal
(see Definition 2) is to show that we can train a parametric family via gradient-based methods so that
it generates (approximately) optimal solutions and not to simply learn the cost matrix ğ‘€via some
other method and then use it to generate good solutions.
Obstacle I: Minimizers at Infinity.
One could naturally consider the parametric family
ğœ‘(ğ‘¥; ğ‘§; ğ‘Š) âˆexp(ğ‘§âŠ¤ğ‘Šğ‘¥) (note that with ğ‘Š= âˆ’ğœğ‘€, we recover the distribution of the previous
paragraph) and try to perform gradient-based methods on the loss (recall that ğ¿(ğ‘¥; ğ‘§) = ğ‘§âŠ¤ğ‘€ğ‘¥)1
â„’(ğ‘Š) = E
ğ‘§âˆ¼â„›
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘§;ğ‘Š)[ğ‘§âŠ¤ğ‘€ğ‘¥] .
(1)
The question is whether gradient updates on the parameter ğ‘Ševentually converge to a matrix ğ‘Š
whose associated distribution ğœ‘(ğ‘Š) generates near-optimal solutions (note that the matrix âˆ’ğœğ‘€
with ğœâ†’+âˆis such a solution). After computing the gradient of â„’, we observe that
âˆ‡ğ‘Šâ„’(ğ‘Š) Â· ğ‘€= Varğ‘§âˆ¼â„›,ğ‘¥âˆ¼ğœ‘(Â·;ğ‘§;ğ‘Š)[ğ‘§âŠ¤ğ‘€ğ‘¥] â‰¥0 ,
where the inner product between two matrices ğ´Â· ğµis the trace Tr(ğ´âŠ¤ğµ) = âˆ‘ï¸€
ğ‘–,ğ‘—ğ´ğ‘–ğ‘—ğµğ‘–ğ‘—. This
means that the gradient field of â„’always has a contribution to the direction of ğ‘€. Nevertheless the
actual minimizer is at infinity, i.e., it corresponds to the point ğ‘Š= âˆ’ğœğ‘€when ğœâ†’+âˆ. While
the correlation with the optimal point is positive (which is encouraging), having such contribution
to this direction is not a sufficient condition for actually reaching ğ‘Š. The objective has vanishing
gradients at infinity and gradient descent may get trapped in sub-optimal stationary points, see the
left plot in Figure 1.
Solution I: Quasar Convexity via Entropy Regularization.
Our plan is to try and make the
objective landscape more benign by adding an entropy-regularizer. Instead of trying to make the
objective convex (which may be too much to ask in the first place) we are able obtain a much better
landscape with a finite global minimizer and a gradient field that guides gradient descent to the
minimizer. Those properties are described by the so-called class of â€œquasar-convexâ€ functions. Quasar
convexity (or weak quasi-convexity [HMR16]) is a well-studied notion in optimization [HMR16,
HSS20, LV16, ZMB+17, HLSS15] and can be considered as a high-dimensional generalization of
unimodality.
1We note that we overload the notation and assume that our distributions generate directly the featurizations
ğ‘§(resp. ğ‘¥) of ğ¼(resp. ğ‘ ).
7

Definition 3 (Quasar Convexity [HMR16, HSS20]). Let ğ›¾âˆˆ(0, 1] and let ğ‘¥be a minimizer of the
differentiable function ğ‘“: Rğ‘›â†’R. The function ğ‘“is ğ›¾-quasar-convex with respect to ğ‘¥on a
domain ğ·âŠ†Rğ‘›if for all ğ‘¥âˆˆğ·, âˆ‡ğ‘“(ğ‘¥) Â· (ğ‘¥âˆ’ğ‘¥) â‰¥ğ›¾(ğ‘“(ğ‘¥) âˆ’ğ‘“(ğ‘¥)).
In the above definition, notice that the main property that we need to establish is that the gradient
field of our objective correlates positively with the direction ğ‘Šâˆ’ğ‘Š, where ğ‘Šis its minimizer. We
denote by ğ»: ğ’²â†’R the negative entropy of ğœ‘(ğ‘Š), i.e.,
ğ»(ğ‘Š) = E
ğ‘§âˆ¼â„›
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘§;ğ‘Š)[log ğœ‘(ğ‘¥; ğ‘§; ğ‘Š)] ,
(2)
and consider the regularized objective
â„’ğœ†(ğ‘Š) = â„’(ğ‘Š) + ğœ†ğ»(ğ‘Š) ,
(3)
for some ğœ†> 0. We show (follows from Lemma 4) that the gradient-field of the regularized objective
indeed â€œpointsâ€ towards a finite minimizer (the matrix ğ‘Š= âˆ’ğ‘€/ğœ†):
âˆ‡ğ‘Šâ„’ğœ†(ğ‘Š) Â· (ğ‘Š+ ğ‘€/ğœ†) =
Var[ğ‘§âŠ¤(ğ‘Š+ ğ‘€/ğœ†)ğ‘¥] â‰¥0 ,
(4)
where the randomness is over ğ‘§âˆ¼â„›, ğ‘¥âˆ¼ğœ‘(Â·; ğ‘§; ğ‘Š). Observe that now the minimizer of â„’ğœ†
is the point âˆ’ğ‘€/ğœ†, which for ğœ†= poly(ğœ–, ğ›¼, 1/ğ¶, 1/ğ·ğ‘†, 1/ğ·â„) (these are the parameters of
Assumption 1) is promised to yield a solution sampler that generates ğœ–-sub-optimal solutions (see
also Proposition 2 and Appendix C). Having the property of Equation (4) suffices for showing that
a gradient descent iteration (with an appropriately small step-size) will eventually converge to the
minimizer.
Obstacle II: Vanishing Gradients.
While we have established that the gradient field of the
regularized objective â€œpointsâ€ towards the right direction, the regularized objective still suffers from
vanishing gradients, see the middle plot in Figure 1. In other words, ğ›¾in the definition of quasar
convexity (Definition 3) may be exponentially small, as it is proportional to the variance of the random
variable ğ‘§âŠ¤(ğ‘Š+ ğ‘€/ğœ†)ğ‘¥, see Equation (4). As we see in the middle plot of Figure 1, the main issue
is the vanishing gradient when ğ‘Šgets closer to the minimizer âˆ’ğ‘€/ğœ†(towards the front-corner).
For simplicity, consider the variance along the direction of ğ‘Š, i.e., Var[ğ‘§âŠ¤ğ‘Šğ‘¥] and recall that ğ‘¥is
generated by the density exp(ğ‘§âŠ¤ğ‘Šğ‘¥)/(âˆ‘ï¸€
ğ‘¥âˆˆğ‘‹exp(ğ‘§âŠ¤ğ‘Šğ‘¥)). When â€–ğ‘Šâ€–2 â†’+âˆwe observe that
the value ğ‘§âŠ¤ğ‘Šğ‘¥concentrates exponentially fast to maxğ‘¥âˆˆğ‘‹ğ‘§âŠ¤ğ‘Šğ‘¥(think of the convergence of the
soft-max to the max function). Therefore, the variance Var[ğ‘§âŠ¤ğ‘Šğ‘¥] may vanish exponentially fast
making the convergence of gradient descent slow.
Solution II: Non-Vanishing Gradients via Fast/Slow Mixture Generators.
We propose a fix to
the vanishing gradients issue by using a mixture of exponential families as a solution generator. We
define the family of solution generators ğ’«= {ğ‘(ğ‘Š) : ğ‘Šâˆˆğ’²} to be
ğ’«= {(1 âˆ’ğ›½â‹†)ğœ‘(ğ‘Š) + ğ›½â‹†ğœ‘(ğœŒâ‹†ğ‘Š) : ğ‘Šâˆˆğ’²} ,
(5)
for a (fixed) mixing parameter ğ›½â‹†and a (fixed) temperature parameter ğœŒâ‹†. The main idea is to have the
first component of the mixture to converge fast to the optimal solution (to âˆ’ğ‘€/ğœ†) while the second
â€œslowâ€ component that has parameter ğœŒâ‹†ğ‘Šstays closer to the uniform distribution over solutions that
guarantees non-trivial variance (and therefore non-vanishing gradients).
More precisely, taking ğœŒâ‹†to be sufficiently small, the distribution ğœ‘(ğœŒâ‹†ğ‘Š) is almost uniform over
the solution space ğœ“ğ‘†(ğ‘†). Therefore, in Equation (4), the almost uniform distribution component
of the mixture will add to the variance and allow us to show a lower bound. This is where Item 3
of Assumption 1 comes into play and gives us the desired non-trivial variance lower bound under
the uniform distribution. We view this fast/slow mixture technique as an interesting insight of our
work: we use the â€œfastâ€ component (the one with parameter ğ‘Š) to actually reach the optimal solution
âˆ’ğ‘€/ğœ†and and we use the â€œslowâ€ component (the one with parameter ğœŒâ‹†ğ‘Šthat essentially generates
random solutions) to preserve a non-trivial variance lower bound during optimization.
4
Complete, Compressed and Efficiently Optimizable Solution Generators
In this section, we discuss the main results that imply Theorem 1: the family ğ’«of Equation (5) is
complete, compressed and efficiently optimizable (for some choice of ğ›½â‹†, ğœŒâ‹†and ğ’²).
8

Completeness. First, we show that the family of solution generators of Equation (5) is complete. For
the proof, we refer to Proposition 2 in Appendix C. At a high-level, we to pick ğ›½â‹†, ğœŒâ‹†to be of order
poly(ğœ–, ğ›¼, 1/ğ¶, 1/ğ·ğ‘†, 1/ğ·â„). This yields that the matrix ğ‘Š= âˆ’ğ‘€/ğœ†is such that â„’(ğ‘Š) â‰¤opt+ğœ–,
where ğ‘€is the matrix of Item 2 in Assumption 1 and ğœ†is poly(ğœ–/[â„]). To give some intuition about
this choice of matrix, let us see how â„’(ğ‘Š) behaves. By definition, we have that
â„’(ğ‘Š) = E
ğ‘§âˆ¼â„›
E
ğ‘¥âˆ¼ğ‘(Â·;ğ‘§;ğ‘Š)
[ï¸€
ğ‘§âŠ¤ğ‘€ğ‘¥
]ï¸€
,
where the distribution ğ‘belongs to the family of Equation (5), i.e., ğ‘(ğ‘Š) = (1 âˆ’ğ›½â‹†)ğœ‘(ğ‘Š) +
ğ›½â‹†ğœ‘(ğœŒâ‹†ğ‘Š). Since the mixing weight ğ›½â‹†is small, we have that ğ‘(ğ‘Š) is approximately equal to
ğœ‘(ğ‘Š). This means that our solution generator draws samples from the distribution whose mass at ğ‘¥
given instance ğ‘§is proportional to exp(âˆ’ğ‘§âŠ¤ğ‘€ğ‘¥/ğœ†) and, since ğœ†> 0 is very small, the distribution
concentrates to solutions ğ‘¥that tend to minimize the objective ğ‘§âŠ¤ğ‘€ğ‘¥. This is the reason why
ğ‘Š= âˆ’ğ‘€/ğœ†is close to opt in the sense that â„’(ğ‘Š) â‰¤opt + ğœ–.
Compression. As a second step, we show (in Proposition 3, see Appendix D) that ğ’«is a compressed
family of solution generators. This result follows immediately from the structure of Equation (5)
(observe that ğ‘Šhas ğ‘›ğ‘‹ğ‘›ğ‘parameters) and the boundedness of ğ‘Š= âˆ’ğ‘€/ğœ†.
Efficiently Optimizable. The proof of this result essentially corresponds to the discussion provided
in Section 3. Our main structural result shows that the landscape of the regularized objective with the
fast/slow mixture solution-generator is quasar convex. More precisely, we consider the following
objective:
â„’ğœ†(ğ‘Š) = E
ğ‘§âˆ¼â„›
E
ğ‘¥âˆ¼ğ‘(Â·;ğ‘§;ğ‘Š)[ğ‘§âŠ¤ğ‘€ğ‘¥] + ğœ†ğ‘…(ğ‘Š) ,
(1)
where ğ‘(ğ‘Š) belongs in the family ğ’«of Equation (5) and ğ‘…is a weighted sum of two negative entropy
regularizers (to be in accordance with the mixture structure of ğ’«), i.e., ğ‘…(ğ‘Š) = (1 âˆ’ğ›½â‹†)ğ»(ğ‘Š) +
ğ›½â‹†/ğœŒâ‹†ğ»(ğœŒâ‹†ğ‘Š). Our main structural results follows (for the proof, see Appendix E.1).
Proposition 1 (Quasar Convexity). Consider ğœ–> 0 and a prior â„›over â„. Assume that Assumption 1
holds. The function â„’ğœ†of Equation (1) with domain ğ’²is poly(ğœ–, ğ›¼, 1/ğ¶, 1/ğ·ğ‘†, 1/ğ·â„)-quasar
convex with respect to âˆ’ğ‘€/ğœ†on the domain ğ’².
Since ğœŒâ‹†is small (by Proposition 2), ğ»(ğœŒâ‹†ğ‘Š) is essentially constant and close in value to the negative
entropy of the uniform distribution. Hence, the effect of ğ‘…(ğ‘Š) during optimization is essentially the
same as that of ğ»(ğ‘Š) (since ğ›½â‹†is close to 0). We show that â„’ğœ†is quasar convex with a non-trivial
parameter ğ›¾(see Proposition 1). We can then apply (in a black-box manner) the convergence results
from [HMR16] to optimize it using projected SGD. We show that SGD finds a weight matrix Ì‚ï¸
ğ‘Šsuch
that the solution generator ğ‘(Ì‚ï¸
ğ‘Š) generates solutions achieving actual loss â„’close to that of the near
optimal matrix ğ‘Š= âˆ’ğ‘€/ğœ†, i.e., â„’(Ì‚ï¸
ğ‘Š) â‰¤â„’(ğ‘Š) + ğœ–. For further details, see Appendix E.3.
5
Experimental Evaluation
In this section, we investigate experimentally the effect of our main theoretical contributions, the
entropy regularizer (see Equation (2)) and the fast/slow mixture scheme (see Equation (5)). We try to
find the Max-Cut of a fixed graph ğº, i.e., the support of the prior â„›is a single graph. Similarly to our
theoretical results, our sampler is of the form ğ‘’score(ğ‘ ;ğ‘¤), where ğ‘ âˆˆ{âˆ’1, 1}ğ‘›(here ğ‘›is the number
of nodes in the graph) is a candidate solution of the Max-Cut problem. For the score function we
used a simple linear layer (left plot of Figure 2) and a 3-layer ReLU network (right plot of Figure 2).
Small Graph Instances.
Focusing on instances where the number of nodes ğ‘›is small (say ğ‘›= 15),
we can explicitly compute the density function and work with an exact sampler. We generate 100
random ğº(ğ‘›, ğ‘) graphs with ğ‘›= 15 nodes and ğ‘= 0.5 and train solution generators using both the
â€vanillaâ€ loss â„’and the entropy-regularized loss â„’ğœ†with the fast/slow mixture scheme. We perform
600 iterations and, for the entropy regularization, we progressively decrease the regularization weight,
starting from 10, and dividing it by 2 every 60 iterations. Out of the 100 trials we found that our
proposed objective was always able to find the optimal cut while the model trained with the vanilla
loss was able to find it for approximately 65% of the graphs (for 65 out of 100 using the linear
network and for 66 using the ReLU network).
9

Hence, our experiments demonstrate that while the unregularized objective is often â€œstuckâ€ at sub-
optimal solutions â€“ and this happens even for very small instances (ğ‘›=15 nodes) â€“ of the Max-Cut
problem, the objective motivated by our theoretical results is able to find the optimal solutions. For
further details, see Appendix I.
Figure 2: Plot of the Max-Cut value trajectory of the â€œvanillaâ€ objective and entropy-regularized
objective with the slow/fast mixture scheme. We remark that we plot the value of the cut of each
iteration (and not the value of the regularized-loss). On the horizontal axis we plot the number of
iterations and on the vertical axis we plot the achieved value of the cut. Both graphs used were
random ğº(ğ‘›, ğ‘) graphs generated with ğ‘›= 15 nodes and edge probabilitdy ğ‘= 0.5. For the left
plot we used a linear network (the same exponential family as the one used in our theoretical results).
For the right plot we used a simple 3-Layer ReLU network to generate the scores. We observe that
the â€vanillaâ€ loss gets stuck on sub-optimal solutions.
Large Graph Instances.
A natural question is whether this improvement is also apparent in
larger graphs. We focus on the case of random ğ‘‘-regular graphs with ğ‘›nodes. It is well-known
that for this family of graphs, with high probability as ğ‘›â†’âˆ, the size of the maximum cut
satisfies MaxCut(ğº(ğ‘›, ğ‘‘)) = ğ‘›(ğ‘‘/4 + ğ‘ƒâ‹†
âˆšï¸€
ğ‘‘/4 + ğ‘œğ‘‘(
âˆš
ğ‘‘)) + ğ‘œ(ğ‘›), where ğ‘ƒâ‹†â‰ˆ0.7632 is a
universal constant [DMS17]. We aim to find a good approximation for the normalized cut-value,
defined as (cut_value/ğ‘›âˆ’ğ‘‘/4)/
âˆšï¸€
ğ‘‘/4, which (roughly speaking) takes values in [0, ğ‘ƒâ‹†]. We
obtain approximate random samples from the density ğ‘’ğ‘“using the Metropolis-Adjusted Langevin
Algorithm (MALA). In particular, an approximate sample from this density is obtained by the
Eulerâ€“Maruyama method for simulating the Langevin diffusion: ğ‘¥ğ‘˜+1 = ğ‘¥ğ‘˜+ ğœâˆ‡ğ‘“(ğ‘¥ğ‘˜) +
âˆš
2ğœğœ‰ğ‘˜,
where ğœ‰ğ‘˜is an independent Gaussian vector ğ’©(0, ğ¼). MALA incorporates an additional step based
on the Metropolis-Hastings algorithm (see [Bes94, SK21]). In our case, the score function ğ‘“is a
simple 3-layer ReLU network. In our experiments for 3 larger random regular graphs (600 nodes)
using the fast/slow mixing technique along entropy regularization we see that our method leads to
improvements over the vanilla objective. Plots of the trajectories of the vanilla and our method can
be found in Figure 3. In the horizontal axis we plot the iterations and in the vertical axis we plot the
normalized cut score of each method (higher is better) â€“ we stop the plot of the vanilla trajectory after
200 iterations because we observed that its output has fully converged and is stuck.
Figure 3: Plot of the Max-Cut value trajectory of the â€œvanillaâ€ objective and entropy-regularized
objective with the slow/fast mixture scheme on large instances. On the horizontal axis we plot the
number of iterations and on the vertical axis we plot the achieved value of the normalized cut-value.
The 3 graphs used were random ğº(ğ‘›, ğ‘) graphs generated with ğ‘›= 600 nodes and edge probability
ğ‘= 0.5. We stop the plot of the vanilla trajectory after 200 iterations because we observed that its
output has fully converged and is stuck.
10

Acknowledgements
This work has been partially supported by project MIS 5154714 of the National Recovery and
Resilience Plan Greece 2.0 funded by the European Union under the NextGenerationEU Program.
Constantine Caramanis was partially supported by the NSF IFML Institute (NSF 2019844), and the
NSF AI-EDGE Institute (NSF 2112471).
Dimitris Fotakis has been partially supported by the Hellenic Foundation for Research and Innovation
(H.F.R.I.) under the â€œFirst Call for H.F.R.I. Research Projects to support Faculty members and
Researchers and the procurement of high-cost research equipment grantâ€, project BALSAM, HFRI-
FM17-1424.
Christos Tzamos was partially supported by the NSF IFML Institute (NSF 2144298).
References
[AAM22] Emmanuel Abbe, Enric Boix Adsera, and Theodor Misiakiewicz. The merged-staircase
property: a necessary and nearly sufficient condition for sgd learning of sparse functions
on two-layer neural networks. In Conference on Learning Theory, pages 4782â€“4887.
PMLR, 2022. 5
[ABA22] Emmanuel Abbe and Enric Boix-Adsera. On the non-universality of deep learning:
quantifying the cost of symmetry. arXiv preprint arXiv:2208.03113, 2022. 5
[ABAB+21] Emmanuel Abbe, Enric Boix-Adsera, Matthew S Brennan, Guy Bresler, and Dheeraj
Nagaraj. The staircase property: How hierarchical structure can guide deep learning.
Advances in Neural Information Processing Systems, 34:26989â€“27002, 2021. 5
[ABAM23] Emmanuel Abbe, Enric Boix-Adsera, and Theodor Misiakiewicz. Sgd learning on
neural networks: leap complexity and saddle-to-saddle dynamics. arXiv preprint
arXiv:2302.11055, 2023. 5
[AEG+22] Simon Apers, Yuval Efron, Pawel Gawrychowski, Troy Lee, Sagnik Mukhopadhyay,
and Danupon Nanongkai. Cut query algorithms with star contraction. arXiv preprint
arXiv:2201.05674, 2022. 2
[AKM+21] Emmanuel Abbe, Pritish Kamath, Eran Malach, Colin Sandon, and Nathan Srebro. On
the power of differentiable learning versus pac and sq learning. Advances in Neural
Information Processing Systems, 34:24340â€“24351, 2021. 5
[AMW18] Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. Learning to solve circuit-
sat: An unsupervised differentiable approach. In International Conference on Learning
Representations, 2018. 5
[ART23] Maria Chiara Angelini and Federico Ricci-Tersenghi. Modern graph neural networks do
worse than classical greedy algorithms in solving combinatorial optimization problems
like maximum independent set. Nature Machine Intelligence, 5(1):29â€“31, 2023. 5
[AS18] Emmanuel Abbe and Colin Sandon. Provable limitations of deep learning. arXiv
preprint arXiv:1812.06369, 2018. 5
[AS20] Emmanuel Abbe and Colin Sandon. On the universality of deep learning. Advances in
Neural Information Processing Systems, 33:20061â€“20072, 2020. 5
[BBSS22] Alberto Bietti, Joan Bruna, Clayton Sanford, and Min Jae Song. Learning single-index
models with shallow neural networks. Advances in Neural Information Processing
Systems, 35:9768â€“9783, 2022. 5
[BEG+22] Boaz Barak, Benjamin L Edelman, Surbhi Goel, Sham Kakade, Eran Malach, and Cyril
Zhang. Hidden progress in deep learning: Sgd learns parities near the computational
limit. arXiv preprint arXiv:2207.08799, 2022. 5
11

[Bes94] Julian Besag. Comments on â€œrepresentations of knowledge in complex systemsâ€ by u.
grenander and mi miller. J. Roy. Statist. Soc. Ser. B, 56(591-592):4, 1994. 10
[BLP21] Yoshua Bengio, Andrea Lodi, and Antoine Prouvost. Machine learning for combinato-
rial optimization: a methodological tour dâ€™horizon. European Journal of Operational
Research, 290(2):405â€“421, 2021. 5
[BPL+16] Irwan Bello, Hieu Pham, Quoc V Le, Mohammad Norouzi, and Samy Bengio.
Neural combinatorial optimization with reinforcement learning.
arXiv preprint
arXiv:1611.09940, 2016. 1, 2, 3, 5
[CCK+21] Quentin Cappart, Didier ChÃ©telat, Elias Khalil, Andrea Lodi, Christopher Morris,
and Petar VeliË‡ckoviÂ´c. Combinatorial optimization and reasoning with graph neural
networks. arXiv preprint arXiv:2102.09544, 2021. 5
[CGG+19] Zongchen Chen, Andreas Galanis, Leslie Ann Goldberg, Will Perkins, James Stewart,
and Eric Vigoda. Fast algorithms at low temperatures via markov chains. arXiv preprint
arXiv:1901.06653, 2019. 27
[CGKM22] Sitan Chen, Aravind Gollakota, Adam Klivans, and Raghu Meka. Hardness of noise-
free learning for two-hidden-layer neural networks. Advances in Neural Information
Processing Systems, 35:10709â€“10724, 2022. 5
[CLS+95] William Cook, LÃ¡szlÃ³ LovÃ¡sz, Paul D Seymour, et al. Combinatorial optimization:
papers from the DIMACS Special Year, volume 20. American Mathematical Soc., 1995.
1, 5
[CLV22] Zongchen Chen, Kuikui Liu, and Eric Vigoda. Spectral independence via stability
and applications to holant-type problems. In 2021 IEEE 62nd Annual Symposium on
Foundations of Computer Science (FOCS), pages 149â€“160. IEEE, 2022. 27
[COLMS22] Amin Coja-Oghlan, Philipp Loick, BalÃ¡zs F Mezei, and Gregory B Sorkin. The ising
antiferromagnet and max cut on random regular graphs. SIAM Journal on Discrete
Mathematics, 36(2):1306â€“1342, 2022. 27
[CT19] Xinyun Chen and Yuandong Tian. Learning to perform local rewriting for combinatorial
optimization. Advances in Neural Information Processing Systems, 32, 2019. 5
[CZ22] Xiaoyu Chen and Xinyuan Zhang. A near-linear time sampler for the ising model.
arXiv preprint arXiv:2207.09391, 2022. 27
[dâ€™A08] Alexandre dâ€™Aspremont. Smooth optimization with approximate gradient. SIAM
Journal on Optimization, 19(3):1171â€“1183, 2008. 28
[DAT20] Arthur Delarue, Ross Anderson, and Christian Tjandraatmadja. Reinforcement learning
with combinatorial actions: An application to vehicle routing. Advances in Neural
Information Processing Systems, 33:609â€“620, 2020. 5
[DCL+18] Michel Deudon, Pierre Cournut, Alexandre Lacoste, Yossiri Adulyasak, and Louis-
Martin Rousseau. Learning heuristics for the tsp by policy gradient. In International
conference on the integration of constraint programming, artificial intelligence, and
operations research, pages 170â€“181. Springer, 2018. 5
[DLS22] Alexandru Damian, Jason Lee, and Mahdi Soltanolkotabi. Neural networks can learn
representations with gradient descent. In Conference on Learning Theory, pages
5413â€“5452. PMLR, 2022. 5
[DMS17] Amir Dembo, Andrea Montanari, and Subhabrata Sen. Extremal cuts of sparse random
graphs. The Annals of Probability, 45(2):1190â€“1217, 2017. 10
[dPS97] JC AnglÃ¨s dâ€™Auriac, M Preissmann, and A SebÃ¶. Optimal cuts in graphs and statistical
mechanics. Mathematical and Computer Modelling, 26(8-10):1â€“11, 1997. 27
[Edm65] Jack Edmonds. Maximum matching and a polyhedron with 0, 1-vertices. Journal of
research of the National Bureau of Standards B, 69(125-130):55â€“56, 1965. 29
12

[EGK+23] Benjamin L Edelman, Surbhi Goel, Sham Kakade, Eran Malach, and Cyril Zhang.
Pareto frontiers in neural feature learning: Data, compute, width, and luck. arXiv
preprint arXiv:2309.03800, 2023. 5
[ER18] Patrick Emami and Sanjay Ranka. Learning permutations with sinkhorn policy gradient.
arXiv preprint arXiv:1805.07010, 2018. 5
[Gam23] David Gamarnik. Barriers for the performance of graph neural networks (gnn) in
discrete random structures. a comment on âˆ–cite {schuetz2022combinatorial},âˆ–cite
{angelini2023modern},âˆ–cite {schuetz2023reply}. arXiv preprint arXiv:2306.02555,
2023. 5
[GCF+19] Maxime Gasse, Didier ChÃ©telat, Nicola Ferroni, Laurent Charlin, and Andrea Lodi.
Exact combinatorial optimization with graph convolutional neural networks. Advances
in Neural Information Processing Systems, 32, 2019. 5
[GLS12] Martin GrÃ¶tschel, LÃ¡szlÃ³ LovÃ¡sz, and Alexander Schrijver. Geometric algorithms and
combinatorial optimization, volume 2. Springer Science & Business Media, 2012. 1, 5
[GPRW19] Andrei Graur, Tristan Pollner, Vidhya Ramaswamy, and S Matthew Weinberg.
New query lower bounds for submodular function minimization.
arXiv preprint
arXiv:1911.06889, 2019. 2
[HLSS15] Elad Hazan, Kfir Levy, and Shai Shalev-Shwartz. Beyond convexity: Stochastic quasi-
convex optimization. Advances in neural information processing systems, 28, 2015.
7
[HMR16] Moritz Hardt, Tengyu Ma, and Benjamin Recht. Gradient descent learns linear dynami-
cal systems. arXiv preprint arXiv:1609.05191, 2016. 7, 8, 9, 17, 23, 24
[HS23a] Christoph Hertrich and Leon Sering. Relu neural networks of polynomial size for exact
maximum flow computation. In International Conference on Integer Programming
and Combinatorial Optimization, pages 187â€“202. Springer, 2023. 5
[HS23b] Christoph Hertrich and Martin Skutella. Provably good solutions to the knapsack
problem via neural networks of bounded size. INFORMS Journal on Computing, 2023.
5
[HSS20] Oliver Hinder, Aaron Sidford, and Nimit Sohoni. Near-optimal methods for minimizing
star-convex functions and beyond. In Conference on learning theory, pages 1894â€“1938.
PMLR, 2020. 7, 8
[HT85] John J Hopfield and David W Tank. â€œneuralâ€ computation of decisions in optimization
problems. Biological cybernetics, 52(3):141â€“152, 1985. 1, 5
[Jeg22] Stefanie Jegelka. Theory of graph neural networks: Representation and learning. arXiv
preprint arXiv:2204.07697, 2022. 5
[Jer03] Mark Jerrum. Counting, sampling and integrating: algorithms and complexity. Springer
Science & Business Media, 2003. 30
[JLB19] Chaitanya K Joshi, Thomas Laurent, and Xavier Bresson. An efficient graph con-
volutional network technique for the travelling salesman problem. arXiv preprint
arXiv:1906.01227, 2019. 5
[JS93] Mark Jerrum and Alistair Sinclair. Polynomial-time approximation algorithms for the
ising model. SIAM Journal on computing, 22(5):1087â€“1116, 1993. 27
[JSV04] Mark Jerrum, Alistair Sinclair, and Eric Vigoda. A polynomial-time approximation
algorithm for the permanent of a matrix with nonnegative entries. Journal of the ACM
(JACM), 51(4):671â€“697, 2004. 30
[Kak01] Sham M Kakade. A natural policy gradient. Advances in neural information processing
systems, 14, 2001. 2
13

[KCK+20] Yeong-Dae Kwon, Jinho Choo, Byoungjip Kim, Iljoo Yoon, Youngjune Gwon, and
Seungjai Min. Pomo: Policy optimization with multiple optima for reinforcement
learning. Advances in Neural Information Processing Systems, 33:21188â€“21198, 2020.
5
[KCY+21] Yeong-Dae Kwon, Jinho Choo, Iljoo Yoon, Minah Park, Duwon Park, and Youngjune
Gwon. Matrix encoding networks for neural combinatorial optimization. Advances in
Neural Information Processing Systems, 34:5138â€“5149, 2021. 5
[KDZ+17] Elias Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, and Le Song. Learning combina-
torial optimization algorithms over graphs. Advances in neural information processing
systems, 30, 2017. 5
[KL20] Nikolaos Karalias and Andreas Loukas. Erdos goes neural: an unsupervised learning
framework for combinatorial optimization on graphs. Advances in Neural Information
Processing Systems, 33:6659â€“6672, 2020. 5
[KLMS19] Weiwei Kong, Christopher Liaw, Aranyak Mehta, and D Sivakumar. A new dog learns
old tricks: Rl finds classic optimization algorithms. In International conference on
learning representations, 2019. 5
[KP+21] Minsu Kim, Jinkyoo Park, et al. Learning collaborative policies to solve np-hard routing
problems. Advances in Neural Information Processing Systems, 34:10418â€“10430, 2021.
5
[KPP22] Minsu Kim, Junyoung Park, and Jinkyoo Park. Sym-nco: Leveraging symmetricity for
neural combinatorial optimization. arXiv preprint arXiv:2205.13209, 2022. 5
[KVHW18] Wouter Kool, Herke Van Hoof, and Max Welling. Attention, learn to solve routing
problems! arXiv preprint arXiv:1803.08475, 2018. 5
[LSS19] Jingcheng Liu, Alistair Sinclair, and Piyush Srivastava. The ising partition function:
Zeros and deterministic approximation. Journal of Statistical Physics, 174(2):287â€“315,
2019. 27
[LSZ21] Troy Lee, Miklos Santha, and Shengyu Zhang. Quantum algorithms for graph problems
with cut queries. In Proceedings of the 2021 ACM-SIAM Symposium on Discrete
Algorithms (SODA), pages 939â€“958. SIAM, 2021. 2
[LV16] Jasper CH Lee and Paul Valiant. Optimizing star-convex functions. In 2016 IEEE
57th Annual Symposium on Foundations of Computer Science (FOCS), pages 603â€“614.
IEEE, 2016. 7
[LZ09] Fei Liu and Guangzhou Zeng. Study of genetic algorithm with reinforcement learning
to solve the tsp. Expert Systems with Applications, 36(3):6995â€“7001, 2009. 5
[MGH+19] Qiang Ma, Suwen Ge, Danyang He, Darshan Thaker, and Iddo Drori. Combinatorial
optimization by graph pointer networks and hierarchical reinforcement learning. arXiv
preprint arXiv:1911.04936, 2019. 5
[MKS+13] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou,
Daan Wierstra, and Martin Riedmiller. Playing atari with deep reinforcement learning.
arXiv preprint arXiv:1312.5602, 2013. 5
[MLC+21] Yining Ma, Jingwen Li, Zhiguang Cao, Wen Song, Le Zhang, Zhenghua Chen, and
Jing Tang. Learning to iteratively solve routing problems with dual-aspect collaborative
transformer. Advances in Neural Information Processing Systems, 34:11096â€“11107,
2021. 5
[MSIB21] Nina Mazyavkina, Sergey Sviridov, Sergei Ivanov, and Evgeny Burnaev. Reinforcement
learning for combinatorial optimization: A survey. Computers & Operations Research,
134:105400, 2021. 5
14

[MYSSS21] Eran Malach, Gilad Yehudai, Shai Shalev-Schwartz, and Ohad Shamir. The connection
between approximation, depth separation and learnability in neural networks. In
Conference on Learning Theory, pages 3265â€“3295. PMLR, 2021. 5
[NJS+20] Yatin Nandwani, Deepanshu Jindal, Parag Singla, et al. Neural learning of one-of-
many solutions for combinatorial problems in structured output spaces. arXiv preprint
arXiv:2008.11990, 2020. 5
[NOST18] Mohammadreza Nazari, Afshin Oroojlooy, Lawrence Snyder, and Martin TakÃ¡c. Re-
inforcement learning for solving the vehicle routing problem. Advances in neural
information processing systems, 31, 2018. 5
[PRW22] Orestis Plevrakis, Seyoon Ragavan, and S Matthew Weinberg. On the cut-query
complexity of approximating max-cut. arXiv preprint arXiv:2211.04506, 2022. 2
[PS98] Christos H Papadimitriou and Kenneth Steiglitz. Combinatorial optimization: algo-
rithms and complexity. Courier Corporation, 1998. 1, 5
[RSW17] Aviad Rubinstein, Tselil Schramm, and S Matthew Weinberg.
Computing exact
minimum cuts without knowing the graph. arXiv preprint arXiv:1711.03165, 2017. 2
[S+03] Alexander Schrijver et al. Combinatorial optimization: polyhedra and efficiency,
volume 24. Springer, 2003. 1, 5
[SBK22] Martin JA Schuetz, J Kyle Brubaker, and Helmut G Katzgraber. Combinatorial opti-
mization with physics-inspired graph neural networks. Nature Machine Intelligence,
4(4):367â€“377, 2022. 5
[Sch05] Alexander Schrijver. On the history of combinatorial optimization (till 1960). Hand-
books in operations research and management science, 12:1â€“68, 2005. 1, 5
[SE20] Yang Song and Stefano Ermon. Improved techniques for training score-based generative
models. Advances in neural information processing systems, 33:12438â€“12448, 2020. 4
[SHM+16] David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van
Den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc
Lanctot, et al. Mastering the game of go with deep neural networks and tree search.
nature, 529(7587):484â€“489, 2016. 5
[Sin12] Alistair Sinclair. Algorithms for random generation and counting: a Markov chain
approach. Springer Science & Business Media, 2012. 30, 33
[SK21] Yang Song and Diederik P Kingma. How to train your energy-based models. arXiv
preprint arXiv:2101.03288, 2021. 10
[SLB+18] Daniel Selsam, Matthew Lamm, Benedikt BÃ¼nz, Percy Liang, Leonardo de Moura,
and David L Dill. Learning a sat solver from single-bit supervision. arXiv preprint
arXiv:1802.03685, 2018. 5
[Smi99] Kate A Smith. Neural networks for combinatorial optimization: a review of more than
a decade of research. Informs journal on Computing, 11(1):15â€“34, 1999. 1, 5
[SSDK+20] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano
Ermon, and Ben Poole. Score-based generative modeling through stochastic differential
equations. arXiv preprint arXiv:2011.13456, 2020. 4
[SSS+17] David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang,
Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, et al. Mas-
tering the game of go without human knowledge. nature, 550(7676):354â€“359, 2017.
5
[TRWG21] Jan Toenshoff, Martin Ritzert, Hinrikus Wolf, and Martin Grohe. Graph neural networks
for maximum constraint satisfaction. Frontiers in artificial intelligence, 3:580607, 2021.
5
15

[VFJ15] Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. Pointer networks. Advances in
neural information processing systems, 28, 2015. 1, 5
[YBV19] Weichi Yao, Afonso S Bandeira, and Soledad Villar. Experimental performance of
graph neural networks on random instances of max-cut. In Wavelets and Sparsity XVIII,
volume 11138, pages 242â€“251. SPIE, 2019. 5
[YGS20] Gal Yehuda, Moshe Gabel, and Assaf Schuster. Itâ€™s not what machines can learn,
itâ€™s what we cannot teach. In International conference on machine learning, pages
10831â€“10841. PMLR, 2020. 5
[YP19] Emre Yolcu and BarnabÃ¡s PÃ³czos. Learning local search heuristics for boolean satisfia-
bility. Advances in Neural Information Processing Systems, 32, 2019. 5
[YW20] Yunhao Yang and Andrew Whinston. A survey on reinforcement learning for combina-
torial optimization. arXiv preprint arXiv:2008.12248, 2020. 5
[ZCH+20] Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu,
Lifeng Wang, Changcheng Li, and Maosong Sun. Graph neural networks: A review of
methods and applications. AI Open, 1:57â€“81, 2020. 5
[ZMB+17] Zhengyuan Zhou, Panayotis Mertikopoulos, Nicholas Bambos, Stephen Boyd, and
Peter W Glynn. Stochastic mirror descent in variationally coherent optimization
problems. Advances in Neural Information Processing Systems, 30, 2017. 7
16

A
Preliminaries and Notation
This lemma is a useful tool for quasar convex functions.
Lemma 1 ([HMR16]). Suppose that the functions ğ‘“1, . . . , ğ‘“ğ‘›are individually ğ›¾-quasar convex in ğ‘‹
with respect to a common global minimum ğ‘¥. Then for non-negative weights ğ‘1, . . . , ğ‘ğ‘›, the linear
combination ğ‘“= âˆ‘ï¸€
ğ‘–âˆˆ[ğ‘›] ğ‘ğ‘–ğ‘“ğ‘–is also ğ›¾-quasar convex with respect to ğ‘¥in ğ‘‹.
In the proofs, we use the following notation: for a matrix ğ‘Šand vectors ğ‘¥, ğ‘§, we let
ğœ‘(ğ‘¥; ğ‘§; ğ‘Š) =
exp(ğ‘§âŠ¤ğ‘Šğ‘§)
âˆ‘ï¸€
ğ‘¦âˆˆğ‘‹exp(ğ‘§âŠ¤ğ‘Šğ‘¦) ,
(1)
be a probability mass function over ğ‘‹and we overload the notation as
ğœ‘(ğ‘¥; ğ‘¤) =
exp(ğ‘¤Â· ğ‘¥)
âˆ‘ï¸€
ğ‘¦âˆˆğ‘‹exp(ğ‘¤Â· ğ‘¦) .
(2)
B
The Proof of Remark 1
Proof. Let ğ‘¥1, . . . , ğ‘¥ğ‘›be the variables of the Max-Cut problem of interest and ğ‘†= {âˆ’1, 1}ğ‘›be
the solution space. Consider ğ’«to be the collection of product distributions over ğ‘†, i.e., for any
ğ‘âˆˆğ’«, it holds that, for any ğ‘ âˆˆğ‘†, Prğ‘¥âˆ¼ğ‘[ğ‘¥= ğ‘ ] = âˆï¸€
ğ‘–âˆˆ[ğ‘›] ğ‘
1+ğ‘ ğ‘–
2
ğ‘–
(1 âˆ’ğ‘ğ‘–)
1âˆ’ğ‘ ğ‘–
2 . Let us consider
the cube [ğœ–, 1 âˆ’ğœ–]ğ‘›. This family is complete since the ğ‘‚(ğœ–)-sub-optimal solution of ğ¼belongs to ğ’«
and is compressed since the description size is poly(ğ‘›, log(1/ğœ–)). We show that in this setting there
exist bad stationary points. Let ğ¿ğºbe the Laplacian matrix of the input graph. For some product
distribution ğ‘âˆˆğ’«, it holds that
â„’(ğ‘) = âˆ’
E
ğ‘¥âˆ¼ğ‘(Â·)[ğ‘¥âŠ¤ğ¿ğºğ‘¥] = âˆ’(2ğ‘âˆ’1)âŠ¤ğ¿ğº(2ğ‘âˆ’1) ,
âˆ‡ğ‘â„’(ğ‘) = âˆ’4ğ¿ğº(2ğ‘âˆ’1) ,
where ğ¿ğºis zero in the diagonal and equal to the Laplacian otherwise. Let us consider a vertex of the
cube ğ‘âˆˆ[ğœ–, 1 âˆ’ğœ–]ğ‘›which is highly and strictly sub-optimal, i.e., any single change of a node would
strictly improve the number of edges in the cut and the score attained in ğ‘is very large compared to
minğ‘¥âˆˆğ‘†âˆ’ğ‘¥âŠ¤ğ¿ğºğ‘¥. For any ğ‘–âˆˆ[ğ‘›], we show that
(âˆ‡â„’(ğ‘) Â· ğ‘’ğ‘–)((2ğ‘âˆ’1) Â· ğ‘’ğ‘–) < 0 .
This means that if ğ‘ğ‘–is large (i.e., 1 âˆ’ğœ–), then the ğ‘–-th coordinate of the gradient of â„’(ğ‘) should be
negative since this would imply that the negative gradient would preserve ğ‘ğ‘–to the right boundary.
Similarly for the case where ğ‘ğ‘–is small. This means that this point is a stationary point and is highly
sub-optimal by assumption.
Let ğ‘ƒ(resp. ğ‘) be the set of indices in [ğ‘›] where ğ‘takes the value 1 âˆ’ğœ–(resp. ğœ–). For any ğ‘–âˆˆ[ğ‘›],
let ğ’©(ğ‘–) be its neighborhood in ğº. Let us consider ğ‘–âˆˆğ‘ƒ. We have that (2ğ‘âˆ’1) Â· ğ‘’ğ‘–> 0 and so it
suffices to show that
(ğ¿ğº(2ğ‘âˆ’1)) Â· ğ‘’ğ‘–> 0 ,
which corresponds to showing that
âˆ‘ï¸
ğ‘—âˆˆğ’©(ğ‘–)âˆ©ğ‘ƒ
ğ¿ğº(ğ‘–, ğ‘—)(1 âˆ’2ğœ–) +
âˆ‘ï¸
ğ‘—âˆˆğ’©(ğ‘–)âˆ©ğ‘
ğ¿ğº(ğ‘–, ğ‘—)(2ğœ–âˆ’1) > 0 ,
and so we would like to have
âˆ‘ï¸
ğ‘—âˆˆğ‘ƒ
ğ¿ğº(ğ‘–, ğ‘—) âˆ’
âˆ‘ï¸
ğ‘—âˆˆğ‘
ğ¿ğº(ğ‘–, ğ‘—) > 0 .
Note that this is true for any ğ‘–âˆˆ[ğ‘›] since the current solution is a strict local optimum. The same
holds if ğ‘–âˆˆğ‘.
17

C
Completeness
Proposition 2 (Completeness). Consider ğœ–> 0 and a prior â„›over â„. Assume that Assumption 1
holds. There exist ğ›½â‹†, ğœŒâ‹†âˆˆ(0, 1) and ğ’²such that the family of solution generators ğ’«of Equation (5)
is complete.
Proof. Assume that ğ’ª(ğ‘ , ğ¼) = ğœ“â„(ğ¼)âŠ¤ğ‘€ğœ“ğ‘†(ğ‘ ) and let ğ‘§= ğœ“â„(ğ¼) and ğ‘¥= ğœ“ğ‘†(ğ‘ ). Moreover, let
ğ›¼, ğ¶, ğ·ğ‘†, ğ·â„be the parameters promised by Assumption 1. Let us consider the family ğ’«= {ğ‘(ğ‘Š) :
ğ‘Šâˆˆğ’²} with
ğ‘(ğ‘¥; ğ‘§; ğ‘Š) = (1 âˆ’ğ›½â‹†)
ğ‘’ğ‘§âŠ¤ğ‘Šğ‘¥
âˆ‘ï¸€
ğ‘¦âˆˆğ‘‹ğ‘’ğ‘§âŠ¤ğ‘Šğ‘¦+ ğ›½â‹†
ğ‘’ğ‘§âŠ¤ğœŒâ‹†ğ‘Šğ‘¥
âˆ‘ï¸€
ğ‘¦âˆˆğ‘‹ğ‘’ğ‘§âŠ¤ğœŒâ‹†ğ‘Šğ‘¦,
where the mixing weight ğ›½â‹†âˆˆ(0, 1) and the inverse temperate ğœŒâ‹†are to be decided. Recall that
â„’(ğ‘Š) = E
ğ‘§âˆ¼â„›
E
ğ‘¥âˆ¼ğ‘(Â·;ğ‘§;ğ‘Š)[ğ¿(ğ‘¥; ğ‘§)] = E
ğ‘§âˆ¼â„›
E
ğ‘¥âˆ¼ğ‘(Â·;ğ‘§;ğ‘Š)[ğ‘§âŠ¤ğ‘€ğ‘¥] .
Let us pick the parameter matrix ğ‘Š= âˆ’ğ‘€/ğœ†. Let us now fix a ğ‘§âˆˆğœ“â„(â„). For the given matrix
ğ‘€, we can consider the finite set of values ğ‘‰obtained by the quadratic forms {ğ‘§âŠ¤ğ‘€ğ‘¥}ğ‘¥âˆˆğœ“ğ‘†(ğ‘†). We
further cluster these values so that they have distance at least ğœ–between each other. We consider the
level sets ğ¶ğ‘–where ğ¶1 is the subset of ğ‘†with minimum value ğ‘£1(= ğ‘£1(ğ‘§)) âˆˆğ‘‰, ğ¶2 is the subset
with the second smallest ğ‘£2(= ğ‘£2(ğ‘§)) âˆˆğ‘‰, etc. For fixed ğ‘§âˆˆğœ“â„(â„), we have that
E
ğ‘¥âˆ¼ğ‘(Â·;ğ‘§;âˆ’ğ‘€/ğœ†)[ğ‘§âŠ¤ğ‘€ğ‘¥] = (1 âˆ’ğ›½â‹†)
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘§;âˆ’ğ‘€/ğœ†)[ğ‘§âŠ¤ğ‘€ğ‘¥] + ğ›½â‹†
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘§;âˆ’ğœŒâ‹†ğ‘€/ğœ†)[ğ‘§âŠ¤ğ‘€ğ‘¥] ,
where ğœ‘comes from (1). We note that
Pr
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘§;âˆ’ğ‘€/ğœ†)[ğ‘§âŠ¤ğ‘€ğ‘¥âˆˆğ¶ğ‘–] =
|ğ¶ğ‘–|ğ‘’âˆ’ğ‘£ğ‘–/ğœ†
âˆ‘ï¸€
ğ‘—|ğ¶ğ‘—|ğ‘’âˆ’ğ‘£ğ‘—/ğœ†.
We claim that, by letting ğœ†â†’0, the above measure concentrates uniformly on ğ¶1. The worst case
scenario is when |ğ¶2| = |ğ‘†| âˆ’|ğ¶1| and ğ‘£2 = ğ‘£1 + ğœ–. Then we have that
Pr
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘§;âˆ’ğ‘€/ğœ†)[ğ‘§âŠ¤ğ‘€ğ‘¥âˆˆğ¶2] =
|ğ¶2|/|ğ¶1|ğ‘’(âˆ’ğ‘£2+ğ‘£1)/ğœ†
1 + |ğ¶2|/|ğ¶1|ğ‘’(âˆ’ğ‘£2+ğ‘£1)/ğœ†â‰¤ğ›¿,
when 1/ğœ†> log(|ğœ“ğ‘†(ğ‘†)|/ğ›¿)/ğœ–, since in the worst case |ğ¶2|/|ğ¶1| = â„¦(|ğœ“ğ‘†(ğ‘†)|). Using this choice
of ğœ†and taking expectation over ğ‘§, we get that
E
ğ‘§âˆ¼â„›
E
ğ‘¥âˆ¼ğ‘(Â·;ğ‘§;âˆ’ğ‘€/ğœ†)[ğ‘§âŠ¤ğ‘€ğ‘¥] â‰¤(1âˆ’ğ›½â‹†) E
ğ‘§âˆ¼â„›
[ï¸‚
(1 âˆ’ğ›¿)
min
ğ‘¥âˆˆğœ“ğ‘†(ğ‘†) ğ¿(ğ‘¥; ğ‘§) + ğ›¿ğ‘£2(ğ‘§)
]ï¸‚
+ğ›½â‹†
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘§;âˆ’ğœŒâ‹†ğ‘€/ğœ†)[ğ‘§âŠ¤ğ‘€ğ‘¥] .
First, we remark that by taking ğœŒâ‹†= poly(ğ›¼, 1/ğ¶, 1/ğ·ğ‘†, 1/ğ·â„), the last term in the right-hand side
of the above expression can be replaced by the expected score of an almost-uniform solution (see
Lemma 3 and Proposition 8), which is at most poly(ğ·ğ‘†, ğ·â„, ğ¶)2âˆ’|ğœ“ğ‘†(ğ‘†)| (and which is essentially
negligible). Finally, one can pick ğ›½â‹†, ğ›¿= poly(ğœ–, 1/ğ¶, 1/ğ·ğ‘†, 1/ğ·â„) so that
â„’(âˆ’ğ‘€/ğœ†) = E
ğ‘§âˆ¼â„›
E
ğ‘¥âˆ¼ğ‘(Â·;ğ‘§;âˆ’ğ‘€/ğœ†)[ğ‘§âŠ¤ğ‘€ğ‘¥] â‰¤E
ğ‘§âˆ¼â„›
[ï¸‚
min
ğ‘¥âˆˆğœ“ğ‘†(ğ‘†) ğ¿(ğ‘¥; ğ‘§)
]ï¸‚
+ ğœ–.
This implies that ğ’«is complete by letting ğ‘Š= âˆ’ğ‘€/ğœ†âˆˆğ’². This means that one can take ğ’²be a
ball centered at 0 with radius (of ğœ–-sub-optimality) to be of order at least ğµ= â€–ğ‘€â€–F/ğœ†.
D
Compression
Proposition 3 (Compression). Consider ğœ–> 0 and a prior â„›over â„. Assume that Assumption 1
holds. There exist ğ›½â‹†, ğœŒâ‹†âˆˆ(0, 1) and ğ’²such that the family of solution generators ğ’«of Equation (5)
is compressed.
Proof. We have that the bit complexity to represent the mixing weight ğ›½â‹†is polylog(ğ·ğ‘†, ğ·â„, ğ¶, 1/ğœ–)
and the description size of ğ’²is polynomial in [â„] and in log(1/ğœ–). This follows from Assumption 1
since the feature dimensions ğ‘›ğ‘‹and ğ‘›ğ‘are poly([â„]) and ğ’²is a ball centered at 0 with radius
ğ‘‚(ğµ), where ğµ= â€–ğ‘€â€–F/ğœ†â‰¤ğ¶/ğœ†, which are also poly([â„]/ğœ–).
18

E
Efficiently Optimizable
Proposition 4 (Efficiently Optimizable). Consider ğœ–> 0 and a prior â„›over â„. Assume that
Assumption 1 holds. There exist ğ›½â‹†, ğœŒâ‹†âˆˆ(0, 1) and ğ’²such that family of solution generators ğ’«of
Equation (5) is efficiently optimizable using Projected SGD, where the projection set is ğ’².
The proof of this proposition is essentially decomposed into two parts: first, we show that the
entropy-reularized loss of Equation (2) is quasar convex and then apply the projected SGD algorithm
to â„’ğœ†.
Recall that ğ»(ğ‘Š) = Eğ‘§âˆ¼â„›Eğ‘¥âˆ¼ğœ‘(Â·;ğ‘§;ğ‘Š)[log ğœ‘(ğ‘¥; ğ‘§; ğ‘Š)]. Let ğ‘…be a weighted sum (to be in
accordance with the mixture structure of ğ’«) of negative entropy regularizers
ğ‘…(ğ‘Š) = (1 âˆ’ğ›½â‹†)ğ»(ğ‘Š) + ğ›½â‹†
ğœŒâ‹†ğ»(ğœŒâ‹†ğ‘Š) ,
(1)
where ğ›½â‹†, ğœŒâ‹†are the fixed parameters of ğ’«(recall Equation (5)). We define the regularized loss
â„’ğœ†(ğ‘Š) = â„’(ğ‘Š) + ğœ†ğ‘…(ğ‘Š) ,
(2)
where
â„’(ğ‘Š) = E
ğ‘§âˆ¼â„›
E
ğ‘¥âˆ¼ğ‘(Â·;ğ‘§;ğ‘Š)[ğ¿(ğ‘§; ğ‘¥)] , ğ‘(ğ‘Š) âˆˆğ’«.
E.1
Quasar Convexity of the Regularized Loss
In this section, we show that â„’ğœ†of Equation (2) is quasar convex. We restate Proposition 1.
Proposition 5 (Quasar Convexity). Consider ğœ–> 0 and a prior â„›over â„. Assume that Assumption 1
holds. The function â„’ğœ†of Equation (2) with domain ğ’²is poly(ğ¶, ğ·ğ‘†, ğ·â„, 1/ğœ–, 1/ğ›¼)-quasar convex
with respect to âˆ’ğ‘€/ğœ†on the domain ğ’².
Proof. We can write the loss â„’ğœ†as
â„’ğœ†(ğ‘Š) = E
ğ‘§âˆ¼â„›[â„’ğœ†,ğ‘§(ğ‘Š)] = E
ğ‘§âˆ¼â„›[â„’ğ‘§(ğ‘Š) + ğœ†ğ‘…ğ‘§(ğ‘Š)] ,
where the mappings â„’ğ‘§and ğ‘…ğ‘§are instance-specific (i.e., we have fixed ğ‘§). We can make use of
Lemma 1, which states that linear combinations of quasar convex (with the same minimizer) remain
quasar convex. Hence, since the functions â„’ğœ†,ğ‘§have the same minimizer âˆ’ğ‘€/ğœ†, it suffices to show
quasar convexity for a particular fixed instance mapping, i.e., it sufffices to show that the function
â„’ğœ†,ğ‘§(ğ‘Š) = â„’ğ‘§(ğ‘Š) + ğœ†ğ‘…ğ‘§(ğ‘Š)
is quasar convex. Recall that ğ‘Šis a matrix of dimension ğ‘›ğ‘Ã— ğ‘›ğ‘‹. To deal with the function â„’ğœ†,ğ‘§,
we consider the simpler function that maps vectors instead of matrices to real numbers. For some
vector ğ‘, let â„’vec
ğœ†
: Rğ‘›ğ‘‹â†’R be
â„’vec
ğœ†(ğ‘¤) =
E
ğ‘¥âˆ¼ğ‘(Â·;ğ‘¤)[ğ‘Â· ğ‘¥] + ğœ†ğ‘…vec(ğ‘¤) ,
(3)
where for any vector ğ‘¤âˆˆRğ‘›ğ‘‹, we define the probability distribution ğœ‘(Â·; ğ‘¤) over the solution space
ğ‘‹= ğœ“ğ‘†(ğ‘†) with probability mass function
ğœ‘(ğ‘¥; ğ‘¤) =
ğ‘’ğ‘¤Â·ğ‘¥
âˆ‘ï¸€
ğ‘¦âˆˆğ‘‹ğ‘’ğ‘¤Â·ğ‘¦.
We then define
ğ‘(Â·; ğ‘¤) = (1 âˆ’ğ›½â‹†)ğœ‘(Â·; ğ‘¤) + ğ›½â‹†ğœ‘(Â·; ğœŒâ‹†ğ‘¤) ,
and ğ‘…vec(ğ‘¤) = (1 âˆ’ğ›½â‹†)ğ»(ğ‘¤) + ğ›½â‹†
ğœŒâ‹†ğ»(ğœŒâ‹†ğ‘¤) (this is a essentially a weighted sum of regularizers,
needed to simplify the proof) with ğ»(ğ‘¤) = Eğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤) log ğœ‘(ğ‘¥, ğ‘¤). These quantities are essentially
the fixed-instance analogues of Equations (5) and (2). The crucial observation is that by taking
ğ‘= ğ‘§âŠ¤ğ‘€and applying the chain rule we have that
âˆ‡ğ‘Šâ„’ğœ†,ğ‘§(ğ‘Š) = ğ‘§Â·
[ï¸€
âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘§âŠ¤ğ‘Š)
]ï¸€âŠ¤.
(4)
19

This means that the gradient of the fixed-instance objective â„’ğœ†,ğ‘§is a matrix of dimension ğ‘›ğ‘Ã— ğ‘›ğ‘‹
that is equal to the outer product of the instance featurization ğ‘§and the gradient of the simpler
function â„’vec
ğ‘¤
evaluated at ğ‘§âŠ¤ğ‘Š. Let us now return on showing that â„’ğœ†,ğ‘§is quasar convex. To this
end, we observe that
âˆ‡ğ‘Šâ„’ğœ†,ğ‘§(ğ‘Š) Â·
(ï¸‚
ğ‘Š+ ğ‘€
ğœ†
)ï¸‚
= âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘§âŠ¤ğ‘Š) Â·
(ï¸‚
ğ‘§âŠ¤ğ‘Š+ ğ‘§âŠ¤ğ‘€
ğœ†
)ï¸‚
.
This means that, since ğ‘§is fixed, it suffices to show that the function â„’vec
ğœ†
is quasar convex. We
provide the next key proposition that deals with issue. This result is one the main technical aspects of
this work and its proof can be found in Appendix E.2.
In the following, intuitively ğ’³is the post-featurization instance space and ğ’µis the parameter space.
Proposition 6. Consider ğœ–, ğœ†> 0. Let â€–ğ‘â€–2 â‰¤ğ¶1. Let ğ’µbe an open ball centered at 0 with
diameter 2ğ¶1/ğœ†. Let ğ’³be a space of diameter ğ·and let Varğ‘¥âˆ¼ğ‘ˆ(ğ’³)[ğ‘£Â· ğ‘¥] â‰¥ğ›¼â€–ğ‘£â€–2
2 for any ğ‘£âˆˆğ’µ.
The function â„’vec
ğœ†(ğ‘¤) = Eğ‘¥âˆ¼ğ‘(Â·;ğ‘¤)[ğ‘Â· ğ‘¥] + ğœ†ğ‘…vec(ğ‘¤) is poly(1/ğ¶1, 1/ğ·, ğœ–, ğ›¼)-quasar convex with
respect to âˆ’ğ‘/ğœ†on ğ’µ.
We can apply the above result with ğ‘= ğ‘§âŠ¤ğ‘€, ğ‘¤= ğ‘§âŠ¤ğ‘Š, ğ·= ğ·ğ‘†and ğ¶1 = ğ·â„ğ¶. These give that
the quasar convexity parameter ğ›¾is of order ğ›¾= poly(ğœ–, ğ›¼, 1/ğ¶, 1/ğ·ğ‘†, 1/ğ·â„). Since we have that
â„’vec
ğœ†(ğ‘§âŠ¤ğ‘Š) = â„’ğœ†,ğ‘§(ğ‘Š), we get that
âˆ‡ğ‘Šâ„’ğœ†,ğ‘§(ğ‘Š) Â· (ğ‘Š+ ğ‘€/ğœ†) â‰¥ğ›¾(â„’ğœ†,ğ‘§(ğ‘Š) âˆ’â„’ğœ†,ğ‘§(âˆ’ğ‘€/ğœ†)) .
This implies that â„’ğœ†,ğ‘§is ğ›¾-quasar convex with respect to the minimizer âˆ’ğ‘€/ğœ†and completes the
proof using Lemma 1.
E.2
The Proof of Proposition 6
Let us consider â„’vec
ğœ†
to be a real-valued differentiable function defined on ğ’µ. Let ğ‘¤, âˆ’ğ‘/ğœ†âˆˆğ’µand
let ğ¿be the line segment between them with ğ¿âˆˆğ’µ. The mean value theorem implies that there
exists ğ‘¤â€² âˆˆğ¿such that
â„’vec
ğœ†(ğ‘¤) âˆ’â„’vec
ğœ†(âˆ’ğ‘/ğœ†) = âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘¤â€²) Â· (ğ‘¤+ ğ‘/ğœ†) â‰¤â€–âˆ‡â„’vec
ğœ†(ğ‘¤â€²)â€–2â€–ğ‘¤+ ğ‘/ğœ†â€–2 .
Now we have that â„’vec
ğœ†
has bounded gradient (see Lemma 2) and so we get that
â€–âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘¤â€²)â€–2 â‰¤ğ·2â€–ğ‘+ ğœ†ğ‘¤â€²â€–2 = ğ·2ğœ†â€–ğ‘¤â€² + ğ‘/ğœ†â€–2 â‰¤ğ·2ğœ†â€–ğ‘¤+ ğ‘/ğœ†â€–2 ,
since ğ‘¤â€² âˆˆğ¿. This implies that
â„’vec
ğœ†(ğ‘¤) âˆ’â„’vec
ğœ†(âˆ’ğ‘/ğœ†) â‰¤ğ·2ğœ†â€–ğ‘¤+ ğ‘/ğœ†â€–2
2 â‰¤1
ğ›¾âˆ‡â„’vec
ğœ†(ğ‘¤) Â· (ğ‘¤+ ğ‘/ğœ†) ,
where 1/ğ›¾= poly(ğ¶1,ğ·)
ğœ–3ğ›¼2
. The last inequality is an application of the correlation lower bound (see
Lemma 3).
In the above proof, we used two key lemmas: a bound for the norm of the gradient and a lower bound
for the correlation. In the upcoming subsections, we prove these two results.
E.2.1
Bounded Gradient Lemma and Proof
Lemma 2 (Bounded Gradient Norm of â„’vec
ğœ†). Consider ğœ–, ğœ†> 0. Let ğ’µbe the domain of â„’vec
ğœ†
of
(3). Let ğ’³be a space of diameter ğ·. For any ğ‘¤âˆˆğ’µ, it holds that
â€–âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘¤)â€–2 â‰¤ğ‘‚(ğ·2)â€–ğ‘+ ğœ†ğ‘¤â€–2 .
Proof. We have that
âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘¤) = (1 âˆ’ğ›½â‹†)ğºğ‘¤+ ğ›½â‹†ğœŒâ‹†ğºğœŒâ‹†ğ‘¤,
where
ğºğ‘¤=
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[((ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥)ğ‘¥] âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥]
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[ğ‘¥] ,
20

and
ğºğœŒâ‹†ğ‘¤=
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[((ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥)ğ‘¥] âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥]
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[ğ‘¥] .
Note that since ğ‘¥âˆˆğ’³, it holds that â€–ğ‘¥â€–2 â‰¤ğ·. Hence
â€–ğºğ‘¤â€–2 =
sup
ğ‘£:â€–ğ‘£â€–2=1
|ğ‘£Â· ğºğ‘¤| â‰¤2ğ·2â€–ğ‘+ ğœ†ğ‘¤â€–2 .
Moreover, we have that
â€–ğºğœŒâ‹†ğ‘¤â€–2 â‰¤2ğ·2â€–ğ‘+ ğœ†ğ‘¤â€–2 .
This means that
â€–âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘¤)â€–2 â‰¤2(1 âˆ’ğ›½â‹†)â€–ğ‘+ ğœ†ğ‘¤â€–2ğ·2 + 2ğ›½â‹†ğœŒâ‹†â€–ğ‘+ ğœ†ğ‘¤â€–2ğ·2 = ğ‘‚(ğ·2)â€–ğ‘+ ğœ†ğ‘¤â€–2 .
E.2.2
Correlation Lower Bound Lemma and Proof
The following lemma is the second ingredient in order to show Proposition 6.
Lemma 3 (Correlation Lower Bound for â„’vec
ğœ†). Let ğœ†> 0. Let â€–ğ‘â€–2 â‰¤ğ¶1. Let ğ’µbe an open ball
centered at 0 with diameter ğµ= 2ğ¶1/ğœ†. Let ğ’³be a space of diameter ğ·. Assume that ğ‘¤âˆˆğ’µand
Varğ‘¥âˆ¼ğ‘ˆ(ğ’³)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥] â‰¥ğ›¼â€–ğ‘+ ğœ†ğ‘¤â€–2
2 for some ğ›¼> 0. Then, for any ğ›½â‹†âˆˆ(0, 1), there exists
ğœŒâ‹†> 0 such that it holds that
âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘¤) Â· (ğ‘+ ğœ†ğ‘¤) = â„¦
(ï¸€
ğ›½â‹†ğ›¼2/(ğµğ·3)â€–ğ‘+ ğœ†ğ‘¤â€–2
2
)ï¸€
,
where â„’vec
ğœ†
is the regularized loss of Proposition 6, ğœŒâ‹†is the scale in the second component of the
mixture of (5) and ğ›½â‹†âˆˆ(0, 1) is the mixture weight.
First, in Lemma 4 and Lemma 5, we give a formula for the desired correlation âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘¤) Â· (ğ‘+ ğœ†ğ‘¤)
and, then we can provide a proof for Lemma 3 by lower bounding this formula.
Lemma 4 (Correlation with Regularization). Consider the function ğ‘”(ğ‘¤) = Eğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[ğ‘Â·ğ‘¥]+ğœ†ğ»(ğ‘¤),
where ğ»is the negative entropy regularizer. Then it holds that
âˆ‡ğ‘¤ğ‘”(ğ‘¤) Â· (ğ‘+ ğœ†ğ‘¤) = Varğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥] .
Proof. Let us consider the following objective function:
ğ‘”(ğ‘¤) =
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[ğ‘Â· ğ‘¥] + ğœ†ğ»(ğ‘¤) ,
ğœ‘(ğ‘¥; ğ‘¤) =
exp(ğ‘¤Â· ğ‘¥)
âˆ‘ï¸€
ğ‘¦âˆˆğ’³exp(ğ‘¤Â· ğ‘¦) ,
where ğ»is the negative entropy regularizer, i.e.,
ğ»(ğ‘¤) =
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤) [log ğœ‘(ğ‘¥; ğ‘¤)] =
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[ğ‘¤Â· ğ‘¥] âˆ’log
â›
ââˆ‘ï¸
ğ‘¦âˆˆğ’³
ğ‘’ğ‘¤Â·ğ‘¦
â
â .
The gradient of ğ‘”with respect to ğ‘¤âˆˆğ’²is equal to
âˆ‡ğ‘¤ğ‘”(ğ‘¤) =
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[(ğ‘Â· ğ‘¥)âˆ‡ğ‘¤log ğœ‘(ğ‘¥; ğ‘¤)] + ğœ†âˆ‡ğ‘¤ğ»(ğ‘¤) .
It holds that
âˆ‡ğ‘¤log ğœ‘(ğ‘¥; ğ‘¤) = âˆ‡ğ‘¤
â›
âğ‘¤Â· ğ‘¥âˆ’log
âˆ‘ï¸
ğ‘¦âˆˆğ’³
ğ‘’ğ‘¤Â·ğ‘¦
â
â = ğ‘¥âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[ğ‘¥] ,
and
âˆ‡ğ»(ğ‘¤) =
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[ğ‘¥]+
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[(ğ‘¤Â·ğ‘¥)âˆ‡ğ‘¤log ğœ‘(ğ‘¥; ğ‘¤)]âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[ğ‘¥] =
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[(ğ‘¤Â·ğ‘¥)âˆ‡ğ‘¤log ğœ‘(ğ‘¥; ğ‘¤)] .
So, we get that
âˆ‡ğ‘¤ğ‘”(ğ‘¤) =
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[((ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥)ğ‘¥] âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥]
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[ğ‘¥] .
Note that
âˆ‡ğ‘¤ğ‘”(ğ‘¤) Â· (ğ‘+ ğœ†ğ‘¤) = Varğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥] .
21

Lemma 5 (Gradient with Regularization and Mixing). For any ğœ–> 0, for the family of solution
generators ğ’«= {ğ‘(Â·; ğ‘¤) = (1 âˆ’ğ›½â‹†)ğœ‘(Â·; ğ‘¤) + ğ›½â‹†ğœ‘(Â·; ğœŒâ‹†ğ‘¤) : ğ‘¤âˆˆğ’²} and the objective â„’vec
ğœ†
of
Equation (3), it holds that
âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘¤) Â· (ğ‘+ ğœ†ğ‘¤) = (1 âˆ’ğ›½â‹†) Varğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥] + ğ›½â‹†ğœŒâ‹†Varğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥] ,
for any ğœ†> 0.
Proof. Let us first consider the scaled parameter ğœŒğ‘¤âˆˆğ’²for some ğœŒ> 0. Then it holds that
âˆ‡ğ‘¤
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[ğ‘Â·ğ‘¥] =
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)
[ï¸‚
(ğ‘Â· ğ‘¥)
(ï¸‚
ğœŒğ‘¥âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[ğœŒğ‘¥]
)ï¸‚]ï¸‚
= ğœŒ
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)
[ï¸‚
(ğ‘Â· ğ‘¥)
(ï¸‚
ğ‘¥âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[ğ‘¥]
)ï¸‚]ï¸‚
.
Moreover, the negative entropy regularizer at ğœŒğ‘¤is
ğ»(ğœŒğ‘¤) =
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[(ğœŒğ‘¤) Â· ğ‘¥] âˆ’log
âˆ‘ï¸
ğ‘¦âˆˆğ’³
ğ‘’(ğœŒğ‘¤)Â·ğ‘¦.
It holds that
âˆ‡ğ‘¤ğ»(ğœŒğ‘¤) =
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[(ğœŒğ‘¤Â·ğ‘¥)âˆ‡ğ‘¤log ğœ‘(ğ‘¥; ğœŒğ‘¤)] = ğœŒ2
(ï¸‚
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[(ğ‘¤Â· ğ‘¥)ğ‘¥] âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[ğ‘¤Â· ğ‘¥]
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[ğ‘¥]
)ï¸‚
.
We consider the objective function â„’vec
ğœ†
to be defined as follows: first, we take
ğ‘(Â·; ğ‘¤) = (1 âˆ’ğ›½â‹†)ğœ‘(Â·; ğ‘¤) + ğ›½â‹†ğœ‘(Â·; ğœŒâ‹†ğ‘¤) ,
i.e., ğ‘(Â·; ğ‘¤) is the mixture of the probability measures ğœ‘(Â·; ğ‘¤) and ğœ‘(Â·; ğœŒâ‹†ğ‘¤) with weights 1 âˆ’ğ›½â‹†and
ğ›½â‹†respectively for some scale ğœŒâ‹†> 0. Moreover, we take ğ‘…vec(ğ‘¤) = (1 âˆ’ğ›½â‹†)ğ»(ğ‘¤) + ğ›½â‹†
ğœŒâ‹†ğ»(ğœŒâ‹†ğ‘¤).
Then we define our regularized loss â„’vec
ğœ†
to be
â„’vec
ğœ†(ğ‘¤) =
E
ğ‘¥âˆ¼ğ‘(Â·;ğ‘¤)[ğ‘Â· ğ‘¥] + ğœ†ğ‘…vec(ğ‘¤) .
Using Lemma 4 and the above calculations, we have that
âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘¤) = (1 âˆ’ğ›½â‹†)âˆ‡ğ‘¤
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[ğ‘Â· ğ‘¥] + ğœ†(1 âˆ’ğ›½â‹†)âˆ‡ğ‘¤ğ»(ğ‘¤) + ğ›½â‹†âˆ‡
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¥)[ğ‘Â· ğ‘¥] + ğœ†ğ›½â‹†
ğœŒâ‹†âˆ‡ğ‘¤ğ»(ğœŒâ‹†ğ‘¤)
= (1 âˆ’ğ›½â‹†)
(ï¸‚
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[((ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥)ğ‘¥] âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥]
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[ğ‘¥]
)ï¸‚
+
+ ğ›½â‹†ğœŒâ‹†
(ï¸‚
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[((ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥)ğ‘¥] âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥]
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[ğ‘¥]
)ï¸‚
.
The above calculations yield
âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘¤) Â· (ğ‘+ ğœ†ğ‘¤) = (1 âˆ’ğ›½â‹†) Varğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥] + ğ›½â‹†ğœŒâ‹†Varğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥] ,
and this concludes the proof.
The above correlation being positive intuitively means that performing gradient descent to â„’vec
ğœ†
gives
that the parameter ğ‘¤converges to âˆ’ğ‘/ğœ†, the point that achieves completeness for that objective.
However, to obtain fast convergence, we need to show that the above correlation is non-trivial.
This means that our goal in order to prove Lemma 3 is to provide a lower bound for the above
quantity, i.e., it suffices to give a non-trivial lower bound for the variance of the random variable
(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥with respect to the probability measure ğœ‘(Â·; ğœŒâ‹†ğ‘¤). It is important to note that in the
above statement we did not fix the value of ğœŒâ‹†. We can now make use of Proposition 8. Intuitively,
by taking the scale parameter appearing in the mixture ğœŒâ‹†to be sufficiently small, we can manage
to provide a lower bound for the variance of (ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥with respect to the almost uniform
measure, i.e, the second summand of the above right-hand side expression has significant contribution.
We remark that ğœŒcorresponds to the inverse temperature parameter. Hence, our previous analysis
essentially implies that policy gradient on combinatorial optimization potentially works if the variance
Varğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥] is non-vanishing at high temperatures 1/ğœŒ.
22

The proof of Lemma 3. Recall that
ğœ‘(ğ‘¥; ğ‘¤) =
ğ‘’ğ‘¤Â·ğ‘¥
âˆ‘ï¸€
ğ‘¦âˆˆğ’³ğ‘’ğ‘¤Â·ğ‘¦.
Let also ğ·be the diameter of ğ’³and ğµthe diameter of ğ’µ. Recall from Lemma 5 that we have that
âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘¤) Â· (ğ‘+ ğœ†ğ‘¤) = (1 âˆ’ğ›½â‹†) Varğ‘¥âˆ¼ğ‘(Â·;ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥] + ğ›½â‹†ğœŒâ‹†Varğ‘¥âˆ¼ğ‘(Â·;ğœŒâ‹†ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥] ,
where the scale parameter ğœŒâ‹†> 0 is to be decided. This means that
âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘¤) Â· (ğ‘+ ğœ†ğ‘¤) â‰¥ğ›½â‹†ğœŒâ‹†Varğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥] .
Our goal is now to apply Proposition 8 in order to lower bound the above variance. Applying
Proposition 8 for ğœ‡â†ğœ‘(Â·; ğœŒâ‹†ğ‘¤), ğ‘â†ğ‘+ ğœ†ğ‘¤âˆˆğ’µand, so for some absolute constant ğ¶0, we can
pick
ğœŒâ‹†= ğ¶0
ğ›¼
ğµğ·3 .
Thus, we have that
Varğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥] â‰¥â„¦(ğ›¼â€–ğ‘+ ğœ†ğ‘¤â€–2
2) .
This implies the desired result since
âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘¤) Â· (ğ‘+ ğœ†ğ‘¤) â‰¥ğ¶0ğ›½â‹†ğ›¼2/(ğµğ·3)â€–ğ‘+ ğœ†ğ‘¤â€–2
2 .
E.3
Convergence for Quasar Convex Functions
The fact that â„’ğœ†is quasar convex with respect to âˆ’ğ‘€/ğœ†implies that projected SGD converges to
that point in a small number if steps and hence the family ğ’«is efficiently optimizable. The analysis
is standard (see e.g., [HMR16]). For completeness a proof can be found in Appendix E.3.
Proposition 7 (Convergence). Consider ğœ–> 0 and a prior â„›over â„. Assume that Assumption 1
holds with parameters ğ¶, ğ·ğ‘†, ğ·â„, ğ›¼. Let ğ‘Š1, . . . , ğ‘Šğ‘‡be the updates of the SGD algorithm with
projection set ğ’²performed on â„’ğœ†of Equation (2) with appropriate step size and parameter ğœ†. Then,
for the non-regularized objective â„’, it holds that
E
ğ‘¡âˆ¼ğ‘ˆ([ğ‘‡])[â„’(ğ‘Šğ‘¡)] â‰¤â„’(âˆ’ğ‘€/ğœ†) + ğœ–,
when ğ‘‡â‰¥poly(1/ğœ–, 1/ğ›¼, ğ¶, ğ·ğ‘†, ğ·â„, â€–ğ‘Š0 + ğ‘€/ğœ†â€–F).
Our next goal is to use Proposition 1 and show that standard projected SGD on the objective â„’ğœ†
converges in a polynomial number of steps. The intuition behind this result is that since the correlation
between âˆ‡â„’ğœ†(ğ‘Š) and the direction ğ‘€+ ğœ†ğ‘Šis positive and non-trivial, the gradient field drives the
optimization method towards the point âˆ’ğ‘€/ğœ†.
Proof. Consider the sequence of matrices ğ‘Š1, . . . , ğ‘Šğ‘¡, . . . , ğ‘Šğ‘‡generated by applying PSGD on â„’ğœ†
with step size ğœ‚(to be decided) and initial parameter vector ğ‘Š0 âˆˆğ’². We have that â„’ğœ†is ğ›¾-quasar
convex and is also ğ‘‚(Î“)-weakly smooth2 since we now show that it is Î“-smooth.
Lemma 6. â„’ğœ†is poly(ğ·ğ‘†, ğ·â„, ğ¶)-smooth.
Proof. We have that
â€–âˆ‡â„’ğœ†(ğ‘Š)â€–2
F = â€– E
ğ‘§âˆ¼â„›[âˆ‡â„’ğœ†,ğ‘§(ğ‘Š)]â€–2
F â‰¤E
ğ‘§âˆ¼â„›â€–ğ‘§â€–2
2â€–âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘§âŠ¤ğ‘Š)â€–2
F .
It suffices to show that â„’vec
ğœ†
is smooth. Recall that
âˆ‡ğ‘¤â„’vec
ğœ†(ğ‘¤) = (1 âˆ’ğ›½â‹†)
(ï¸‚
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[((ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥)ğ‘¥] âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥]
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[ğ‘¥]
)ï¸‚
+
+ ğ›½â‹†ğœŒâ‹†
(ï¸‚
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[((ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥)ğ‘¥] âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥]
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[ğ‘¥]
)ï¸‚
.
2As mentioned in [HMR16], a function ğ‘“is Î“-weakly smooth if for any point ğœƒ, â€–âˆ‡ğ‘“(ğœƒ)â€–2 â‰¤Î“(ğ‘“(ğœƒ) âˆ’
ğ‘“(ğœƒâ‹†)). Moreover, a function ğ‘“that is Î“-smooth (in the sense â€–âˆ‡2ğ‘“â€– â‰¤Î“), is also ğ‘‚(Î“)-weakly smooth.
23

This means that
â€–âˆ‡2
ğ‘¤â„’vec
ğœ†(ğ‘¤)â€–2
F â‰¤(1 âˆ’ğ›½â‹†)(ğ´1 + ğ´2) + ğ›½â‹†ğœŒâ‹†(ğ´3 + ğ´4) ,
where
ğ´1 =
âƒ¦âƒ¦âƒ¦âƒ¦âˆ‡ğ‘¤
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[((ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥)ğ‘¥]
âƒ¦âƒ¦âƒ¦âƒ¦
2
F
, ğ´2 =
âƒ¦âƒ¦âƒ¦âƒ¦âˆ‡ğ‘¤
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥]
E
ğ‘¥âˆ¼ğœ‘(Â·;ğ‘¤)[ğ‘¥]
âƒ¦âƒ¦âƒ¦âƒ¦
2
F
,
ğ´3 =
âƒ¦âƒ¦âƒ¦âƒ¦âˆ‡ğ‘¤
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[((ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥)ğ‘¥]
âƒ¦âƒ¦âƒ¦âƒ¦
2
F
, ğ´4 =
âƒ¦âƒ¦âƒ¦âƒ¦âˆ‡ğ‘¤
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[(ğ‘+ ğœ†ğ‘¤) Â· ğ‘¥]
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[ğ‘¥]
âƒ¦âƒ¦âƒ¦âƒ¦
2
F
.
Standard computation of these values yields that, since ğ·ğ‘†and ğ·â„are bounds to ğ‘¥and ğ‘§respectively,
we have that â„’ğœ†is smooth with parameter poly(ğ·ğ‘†, ğ·â„, ğ¶).
Let ğ‘‰be the variance of the unbiased estimator used for âˆ‡ğ‘Šâ„’ğœ†(ğ‘Š). We can apply the next result of
[HMR16].
Lemma 7 ([HMR16]). Suppose the objective function ğ‘“is ğ›¾-weakly quasi convex and Î“-weakly
smooth, and let ğ‘Ÿ(Â·) be an unbiased estimator for âˆ‡ğ‘“(ğœƒ) with variance ğ‘‰. Moreover, suppose the
global minimum ğœƒbelongs to ğ’², and the initial point ğœƒ0 satisfies â€–ğœƒ0 âˆ’ğœƒâ€–2 â‰¤ğ‘…. Then projected
stochastic gradient descent with a proper learning rate returns ğœƒğ‘‡in ğ‘‡iterations with expected error
E
ğ‘¡âˆ¼ğ‘ˆ([ğ‘‡]) ğ‘“(ğœƒğ‘¡) âˆ’ğ‘“(ğœƒ) â‰¤max
{ï¸ƒ
Î“ğ‘…2
ğ›¾2ğ‘‡, ğ‘…
âˆš
ğ‘‰
ğ›¾
âˆš
ğ‘‡
}ï¸ƒ
.
We apply the above result to â„’ğœ†in order to find matrices ğ‘Š1, ..., ğ‘Šğ‘‡that achieve good loss on average
compared to âˆ’ğ‘€/ğœ†. Moreover, using a batch SGD update, we can take ğ‘‰to be also polynomial
in the crucial parameters of the problem. We note that one can adapt the above convergence proof
and show that the actual loss â„’(and not the loss â„’ğœ†) are close after sufficiently many iterations (as
indicated by the above lemma). We know that the Frobenius norm of the gradient of â„’(ğ‘Š) is at most
of order ğ‘‚(ğ·2
â„ğ¶ğ·2
ğ‘†). We can apply the mean value theorem in high dimensions (by taking ğ’²to
be an open ball of radius ğ‘‚(ğµ)) and this yields that the difference between the values of â„’(ğ‘Šğ‘‡)
and â„’(âˆ’ğ‘€/ğœ†) is at most ğ·2
â„ğ¶ğ·2
ğ‘†â€–ğ‘Šğ‘¡+ ğ‘€/ğœ†â€–2
F. However, the right-hand side is upper bounded
by the correlation between âˆ‡â„’ğœ†(ğ‘Šğ‘¡) and ğ‘Šğ‘¡+ ğ‘€/ğœ†. Hence, we can still use this correlation as a
potential in order to minimize â„’. This implies that the desired convergence guarantee holds as long
as ğ‘‡â‰¥poly(1/ğœ–, 1/ğ›¼, ğ¶, ğ·ğ‘†, ğ·â„, â€–ğ‘Š0 + ğ‘€/ğœ†â€–F) .
F
Deferred Proofs: Variance under Almost Uniform Distributions
This section is a technical section that states some properties of exponential families. We use some
standard notation, such as ğ‘¤and ğ‘¥, for the statements and the proofs but we underline that these
symbols do not correspond to the notation in the main body of the paper.
We consider the parameter space Î˜ and for any parameter ğ‘¤âˆˆÎ˜, we define the probability
distribution ğœ‘(Â·; ğ‘¤) over a space ğ’³with density
ğœ‘(ğ‘¥; ğ‘¤) =
ğ‘’ğ‘¤Â·ğ‘¥
âˆ‘ï¸€
ğ‘¦âˆˆğ’³ğ‘’ğ‘¤Â·ğ‘¦.
In this section, our goal is to relate the variance of ğ‘Â· ğ‘¥under the measure ğœ‘(Â·; 0) (uniform case) and
ğœ‘(Â·; ğœŒâ‹†ğ‘¤) for some ğ‘¤âˆˆğ’²and some sufficiently small ğœŒâ‹†(almost uniform case). The main result of
this section follows.
Proposition 8 (Variance Lower Bound Under Almost Uniform Distributions). Assume that the
variance of ğ‘Â· ğ‘¥under the uniform distribution over ğ’³, whose diameter is ğ·, is lower bounded by
ğ›¼â€–ğ‘â€–2
2. Moreover assume that ğ‘¤âˆˆÎ˜ with â€–ğ‘¤â€–2 â‰¤ğµ. Then, setting ğœŒâ‹†= ğ‘‚(ğ›¼/(ğµğ·3)), it holds
that Varğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[ğ‘Â· ğ‘¥] = â„¦(ğ›¼â€–ğ‘â€–2
2).
We first provide a general abstract lemma that relates the variance of the uniform distribution ğ‘ˆover
ğ’³to the variance of an almost uniform probability measure ğœ‡. For simplicity, we denote the uniform
distribution over ğ’³with ğ‘ˆ= ğ‘ˆ(ğ’³).
24

Lemma 8. Let ğ‘¤âˆˆÎ˜ and ğ‘¥âˆˆğ’³with â€–ğ‘¥â€–2 â‰¤ğ·. Consider the uniform probability measure ğ‘ˆ
over ğ’³and let ğœ‡over ğ’³be such that there exist ğœ–1, ğœ–2 > 0 with:
â€¢ â€–Eğ‘¥âˆ¼ğ‘ˆ[ğ‘¥] âˆ’Eğ‘¥âˆ¼ğœ‡[ğ‘¥]â€–2 â‰¤ğœ–1, and,
â€¢ ğ‘¤âŠ¤Eğ‘¥âˆ¼ğœ‡[ğ‘¥ğ‘¥âŠ¤]ğ‘¤â‰¥ğ‘¤âŠ¤Eğ‘¥âˆ¼ğ‘ˆ[ğ‘¥ğ‘¥âŠ¤]ğ‘¤âˆ’ğœ–2â€–ğ‘¤â€–2
2.
Then it holds that Varğ‘¥âˆ¼ğœ‡[ğ‘¤Â· ğ‘¥] â‰¥Varğ‘¥âˆ¼ğ‘ˆ[ğ‘¤Â· ğ‘¥] âˆ’3 max{ğœ–2
1, ğœ–1ğ·, ğœ–2}â€–ğ‘¤â€–2
2.
Proof. We have that
Varğ‘¥âˆ¼ğœ‡[ğ‘¤Â· ğ‘¥] = E
ğ‘¥âˆ¼ğœ‡
[ï¸€
(ğ‘¤Â· ğ‘¥)2]ï¸€
âˆ’
(ï¸‚
E
ğ‘¥âˆ¼ğœ‡[ğ‘¤Â· ğ‘¥]
)ï¸‚2
.
We first deal with upper-bounding the square of the first moment. Note that
ğ‘¤Â·
(ï¸‚
E
ğ‘¥âˆ¼ğœ‡[ğ‘¥] âˆ’E
ğ‘¥âˆ¼ğ‘ˆ[ğ‘¥]
)ï¸‚
â‰¤â€–ğ‘¤â€–2
âƒ¦âƒ¦âƒ¦âƒ¦E
ğ‘¥âˆ¼ğœ‡[ğ‘¥] âˆ’E
ğ‘¥âˆ¼ğ‘ˆ[ğ‘¥]
âƒ¦âƒ¦âƒ¦âƒ¦
2
â‰¤ğœ–1â€–ğ‘¤â€–2 .
Let us take ğœ–
>
0 (with ğœ–
<
ğœ–1) for simplicity to be such that (Eğ‘¥âˆ¼ğœ‡[ğ‘¤Â· ğ‘¥])2
=
(Eğ‘¥âˆ¼ğ‘ˆ[ğ‘¤Â· ğ‘¥] + ğœ–â€–ğ‘¤â€–2)2. This means that
(ï¸‚
E
ğ‘¥âˆ¼ğœ‡[ğ‘¤Â· ğ‘¥]
)ï¸‚2
â‰¤
(ï¸
E
ğ‘¥âˆ¼ğ‘ˆ[ğ‘¤Â· ğ‘¥]
)ï¸2
+ 2ğœ–â€–ğ‘¤â€–2
âƒ’âƒ’âƒ’E
ğ‘¥âˆ¼ğ‘ˆ[ğ‘¤Â· ğ‘¥]
âƒ’âƒ’âƒ’+ ğœ–2â€–ğ‘¤â€–2
2
â‰¤
(ï¸
E
ğ‘¥âˆ¼ğ‘ˆ[ğ‘¤Â· ğ‘¥]
)ï¸2
+ 2ğœ–ğ·â€–ğ‘¤â€–2
2 + ğœ–2â€–ğ‘¤â€–2
2 .
Next we lower-bound the second moment. It holds that
E
ğ‘¥âˆ¼ğœ‡
[ï¸€
(ğ‘¤Â· ğ‘¥)2]ï¸€
= ğ‘¤âŠ¤E
ğ‘¥âˆ¼ğœ‡
[ï¸€
ğ‘¥ğ‘¥âŠ¤]ï¸€
ğ‘¤â‰¥E
ğ‘¥âˆ¼ğ‘ˆ[(ğ‘¤Â· ğ‘¥)2] âˆ’ğœ–2â€–ğ‘¤â€–2
2 ,
for some ğœ–2 > 0. This means that
Varğ‘¥âˆ¼ğœ‡(ğ‘¤Â· ğ‘¥) â‰¥E
ğ‘¥âˆ¼ğ‘ˆ
[ï¸€
(ğ‘¤Â· ğ‘¥)2]ï¸€
âˆ’ğœ–2â€–ğ‘¤â€–2
2 âˆ’
(ï¸
E
ğ‘¥âˆ¼ğ‘ˆ[ğ‘¤Â· ğ‘¥]
)ï¸2
âˆ’2ğœ–ğ·â€–ğ‘¤â€–2
2 âˆ’ğœ–2â€–ğ‘¤â€–2
2 .
Hence,
Varğ‘¥âˆ¼ğœ‡[ğ‘¤Â· ğ‘¥] â‰¥Varğ‘¥âˆ¼ğ‘ˆ[ğ‘¤Â· ğ‘¥] âˆ’3 max{ğœ–2, ğœ–2
1, ğœ–1ğ·}â€–ğ‘¤â€–2
2 .
Our next goal is to relate ğœ‘(Â·; ğœŒâ‹†ğ‘¤) with the uniform measure ğœ‘(Â·; 0). According to the above general
lemma, we have to relate the first and second moments of ğœ‘(Â·; ğœŒâ‹†ğ‘¤) with the ones of the uniform
distribution ğ‘ˆ= ğœ‘(Â·; 0).
The Proof of Proposition 8. Our goal is to apply Lemma 8. First, let us set
ğ‘“ğ‘£(ğœŒ) =
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[ğ‘£Â· ğ‘¥] ,
for any unit vector ğ‘£âˆˆÎ˜. Then it holds that
âƒ¦âƒ¦âƒ¦âƒ¦
E
ğ‘¥âˆ¼ğœ‘(Â·;0)[ğ‘¥] âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[ğ‘¥]
âƒ¦âƒ¦âƒ¦âƒ¦
2
=
sup
ğ‘£:â€–ğ‘£â€–2=1
|ğ‘“ğ‘£(0) âˆ’ğ‘“ğ‘£(ğœŒâ‹†)| .
Using the mean value theorem in [0, ğœŒâ‹†] for any unit vector ğ‘£, we have that there exists a ğœ‰= ğœ‰ğ‘£âˆˆ
(0, ğœŒâ‹†) such that
|ğ‘“ğ‘£(0) âˆ’ğ‘“ğ‘£(ğœŒâ‹†)| = ğœŒâ‹†|ğ‘“â€²
ğ‘£(ğœ‰)| .
It suffices to upper bound ğ‘“â€²
ğ‘£(ğœ‰) for any unit vector ğ‘£and ğœ‰âˆˆ(0, ğœŒâ‹†). Let us compute ğ‘“â€²
ğ‘£. We have
that
ğ‘‘ğ‘“ğ‘£
ğ‘‘ğœŒ=
âˆ«ï¸
ğ‘†
(ğ‘£Â· ğ‘¥) ğ‘‘
ğ‘‘ğœŒ
ğ‘’ğœŒ(ğ‘¤ğ‘¥)
âˆ«ï¸€
ğ‘†ğ‘’ğœŒ(ğ‘¤ğ‘¦)ğ‘‘ğ‘¦ğ‘‘ğ‘¥=
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[(ğ‘£Â· ğ‘¥)(ğ‘¤Â· ğ‘¥)] âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[ğ‘£Â· ğ‘¥]
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[ğ‘¤Â· ğ‘¥] .
25

Since ğ‘¥âˆˆğ’³, we have that
sup
ğ‘£:â€–ğ‘£â€–2=1
sup
ğœ‰âˆˆ(0,ğœŒâ‹†)
|ğ‘“â€²
ğ‘£(ğœ‰)| â‰¤2â€–ğ‘¤â€–2ğ·2 .
This gives that
âƒ¦âƒ¦âƒ¦âƒ¦
E
ğ‘¥âˆ¼ğœ‘(Â·;0)[ğ‘¥] âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[ğ‘¥]
âƒ¦âƒ¦âƒ¦âƒ¦
2
â‰¤2ğœŒâ‹†â€–ğ‘¤â€–2ğ·2 .
We then continue with controlling the second moment: it suffices to find ğœ–2 such that for any ğ‘£âˆˆÎ˜,
it holds
ğ‘£âŠ¤
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[ğ‘¥ğ‘¥âŠ¤]ğ‘£â‰¥ğ‘£âŠ¤
E
ğ‘¥âˆ¼ğœ‘(Â·;0)[ğ‘¥ğ‘¥âŠ¤]ğ‘£âˆ’ğœ–2â€–ğ‘£â€–2
2 .
Let us set ğ‘”ğ‘£(ğœŒ) = Eğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[(ğ‘£Â· ğ‘¥)2] for any vector ğ‘£âˆˆÎ˜. We have that
|ğ‘”ğ‘£(0) âˆ’ğ‘”ğ‘£(ğœŒâ‹†)| = ğœŒâ‹†|ğ‘”â€²
ğ‘£(ğœ‰)| ,
where ğœ‰âˆˆ(0, ğœŒâ‹†). It holds that
âƒ’âƒ’âƒ’âƒ’
ğ‘‘ğ‘”ğ‘£
ğ‘‘ğœŒ
âƒ’âƒ’âƒ’âƒ’=
âƒ’âƒ’âƒ’âƒ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[(ğ‘£Â· ğ‘¥)2(ğ‘¤Â· ğ‘¥)] âˆ’
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[(ğ‘£Â· ğ‘¥)2]
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒğ‘¤)[ğ‘¤Â· ğ‘¥]
âƒ’âƒ’âƒ’âƒ’â‰¤2â€–ğ‘£â€–2â€–ğ‘¤â€–2ğ·3 .
This gives that for any ğ‘£âˆˆÎ˜, it holds
ğ‘£âŠ¤
E
ğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[ğ‘¥ğ‘¥âŠ¤]ğ‘£â‰¥ğ‘£âŠ¤
E
ğ‘¥âˆ¼ğœ‘(Â·;0)[ğ‘¥ğ‘¥âŠ¤]ğ‘£âˆ’2ğœŒâ‹†â€–ğ‘¤â€–2ğ·3â€–ğ‘£â€–2
2 .
Note that the above holds for ğ‘£= ğ‘too. Lemma 8 gives us that
Varğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[ğ‘Â· ğ‘¥] â‰¥Varğ‘¥âˆ¼ğœ‘(Â·;0)[ğ‘Â· ğ‘¥] âˆ’3 max{ğœ–2, ğœ–2
1, ğœ–1ğ·}â€–ğ‘â€–2
2 ,
where ğœ–1 = 2ğœŒâ‹†ğµğ·2 and ğœ–2 = 2ğœŒâ‹†ğµğ·3. This implies that by picking
ğœŒâ‹†= ğ¶0
ğ›¼
ğµğ·3
for some universal constant ğ¶0, we get that
Varğ‘¥âˆ¼ğœ‘(Â·;ğœŒâ‹†ğ‘¤)[ğ‘Â· ğ‘¥] = â„¦(ğ›¼â€–ğ‘â€–2
2) .
In this section, we considered ğœŒâ‹†as indicated by the above Proposition 8.
G
Applications to Combinatorial Problems
In this section we provide a series of combinatorial applications of our theoretical framework
(Theorem 1). In particular, for each one of the following combinatorial problems (that provably
satisfy Assumption 1), it suffices to specify the feature mappings ğœ“ğ‘†, ğœ“â„and compute the parameters
ğ¶, ğ·ğ‘†, ğ·â„, ğ›¼.
G.1
Maximum Cut, Maximum Flow and Max-ğ‘˜-CSPs
We first provide a general lemma for the variance of â€linear tensorsâ€ under the uniform measure.
Lemma 9 (Variance Lower Bound Under Uniform). Let ğ‘›, ğ‘˜âˆˆN. For any ğ‘¤âˆˆR(
ğ‘›
ğ‘˜), it holds that
Varğ‘¥âˆ¼ğ‘ˆ({âˆ’1,1}ğ‘›)[ğ‘¤Â· ğ‘¥âŠ—ğ‘˜] =
âˆ‘ï¸
âˆ…Ì¸=ğ‘†âŠ†[ğ‘›]:|ğ‘†|â‰¤ğ‘˜
ğ‘¤2
ğ‘†.
Proof. For any ğ‘¤âˆˆR(
ğ‘›
ğ‘˜), it holds that
Varğ‘¥âˆ¼ğ‘ˆ({âˆ’1,1}ğ‘›)[ğ‘¤Â· ğ‘¥âŠ—ğ‘˜] =
E
ğ‘¥âˆ¼ğ‘ˆ({âˆ’1,1}ğ‘›)
[ï¸€
(ğ‘¤Â· ğ‘¥âŠ—ğ‘˜)2]ï¸€
âˆ’
E
ğ‘¥âˆ¼ğ‘ˆ({âˆ’1,1}ğ‘›)[ğ‘¤Â· ğ‘¥âŠ—ğ‘˜]2 .
Note that ğ‘¤âˆˆR(
ğ‘›
ğ‘˜) can be written as ğ‘¤= (ğ‘¤âˆ…, ğ‘¤âˆ’âˆ…) where ğ‘¤âˆ…corresponds to the constant term of
the Fourier expansion and ğ‘¤âˆ’âˆ…= (ğ‘¤ğ‘†)âˆ…Ì¸=ğ‘†âŠ†[ğ‘›]:|ğ‘†|â‰¤ğ‘˜is the vector of the remaining coordinates. The
Fourier expansion implies that
Varğ‘¥âˆ¼ğ‘ˆ({âˆ’1,1}ğ‘›)[ğ‘¤Â· ğ‘¥âŠ—ğ‘˜] = â€–ğ‘¤âˆ’âˆ…â€–2
2 ,
which yields the desired equality for the variance.
26

G.1.1
Maximum Cut
Let us consider a graph with ğ‘›nodes and weighted adjacency matrix ğ´with non-negative weights.
Maximum cut is naturally associated with the Ising model and, intuitively, our approach does not
yield an efficient algorithm for solving Max-Cut since we cannot efficiently sample from the Ising
model in general. To provide some further intuition, consider a single-parameter Ising model for
ğº= (ğ‘‰, ğ¸) with Hamiltonian ğ»ğº(ğ‘¥) = âˆ‘ï¸€
(ğ‘–,ğ‘—)âˆˆğ¸
1+ğ‘¥ğ‘–ğ‘¥ğ‘—
2
. Then the partition function is equal
to ğ‘ğº(ğ›½) = âˆ‘ï¸€
ğ‘¥âˆˆ{âˆ’1,1}ğ‘‰exp(ğ›½ğ»ğº(ğ‘¥)). Note that when ğ›½> 0, the Gibbs measure favours
configurations with alligned spins (ferromagnetic case) and when ğ›½< 0, the measure favours
configurations with opposite spins (anti-ferromagnetic case). The antiferromagnetic Ising model
appears to be more challenging. According to physicists the main reason is that its Boltzmann
distribution is prone to a complicated type of long-range correlation known as â€˜replica symmetry
breakingâ€™ [COLMS22]. From the TCS viewpoint, observe that as ğ›½goes to âˆ’âˆ, the mass of the
Gibbs distribution shifts to spin configurations with more edges joining vertices with opposite spins
and concentrates on the maximum cuts of the graph. Hence, being able to efficiently approximate the
log-partition function for general Ising models, would lead to solving the Max-Cut problem.
Theorem 2 (Max-Cut has a Compressed and Efficiently Optimizable Solution Generator). Consider
a prior over Max-Cut instances with ğ‘›nodes. For any ğœ–> 0, there exists a solution generator
ğ’«= {ğ‘(ğ‘¤) : ğ‘¤âˆˆğ’²} such that ğ’«is complete, compressed with description poly(ğ‘›)polylog(1/ğœ–)
and â„’+ ğœ†ğ‘…: ğ’²â†¦â†’R is efficiently optimizable via projected stochastic gradient descent in
poly(ğ‘›, 1/ğœ–) steps for some ğœ†> 0.
Proof of Theorem 2. It suffices to show that Max-Cut satisfies Assumption 1. Consider an input
graph ğºwith ğ‘›nodes and Laplacian matrix ğ¿ğº. Then
MAXCUT = 1
4
max
ğ‘ âˆˆ{âˆ’1,1}ğ‘›ğ‘ âŠ¤ğ¿ğºğ‘ = 1
4
min
ğ‘ âˆˆ{âˆ’1,1}ğ‘›âˆ’ğ‘ âŠ¤ğ¿ğºğ‘ .
We show that there exist feature mappings so that the cost of every solution ğ‘ under any instance/graph
ğºis a bilinear function of the feature vectors (cf. Item 2 of Assumption 1). We consider the correlation-
based feature mapping ğœ“ğ‘†(ğ‘ ) = (ğ‘ ğ‘ âŠ¤)â™­âˆˆRğ‘›2, where by (Â·)â™­we denote the vectorization/flattening
operation and the negative Laplacian for the instance (graph), ğœ“â„(ğº) = (âˆ’ğ¿ğº)â™­âˆˆRğ‘›2. Then simply
setting the matrix ğ‘€to be the identity ğ¼âˆˆRğ‘›2Ã—ğ‘›2 the cost of any solution ğ‘ can be expressed as the
bilinear function ğœ“â„(ğº)âŠ¤ğ‘€ğœ“ğ‘†(ğ‘ ) = (âˆ’ğ¿â™­
ğº)âŠ¤(ğ‘ ğ‘ ğ‘‡)â™­= âˆ’ğ‘ âŠ¤ğ¿ğºğ‘ . We observe that (for unweighted
graphs) with ğ‘›nodes the bit-complexity of the family of all instances â„is roughly ğ‘‚(ğ‘›2), and
therefore the dimensions of the ğœ“ğ‘†, ğœ“â„feature mappings are clearly polynomial in the bit-complexity
of â„. Moreover, considering unweighted graphs, it holds â€–ğœ“â„(ğº)â€–2, â€–ğœ“ğ‘†(ğ‘ )â€–2, â€–ğ‘€â€–F â‰¤poly(ğ‘›).
Therefore, the constants ğ·ğ‘†, ğ·â„, ğ¶are polynomial in the bit-complexity of the instance family.
It remains to show that our solution feature mapping satisfy the variance preservation assumption.
For any ğ‘£, we have that Varğ‘ âˆ¼ğ‘ˆ(ğ‘†)[ğ‘£Â· ğœ“ğ‘†(ğ‘ )] = Varğ‘ âˆ¼ğ‘ˆ({âˆ’1,1}ğ‘›)[ğ‘£Â· (ğ‘ ğ‘ âŠ¤)â™­] = â„¦(â€–ğ‘£â€–2
2), using
Lemma 9 with ğ‘˜= 2, since ğ‘âˆ…= 0 with loss of generality.
G.1.2
Minimum Cut/Maximum Flow
Let us again consider a graph with ğ‘›nodes and Laplacian matrix ğ¿ğº. It is known that the minimum
cut problem is solvable in polynomial time when all the weights are positive. From the discussion
of the maximum cut case, we can intuitively relate minimum cut with positive weights to the
ferromagnetic Ising setting [dPS97]. We remark that we can consider the ferromagnetic parameter
space ğ’²fer = R(
ğ‘›
2)
â‰¥0 and get the variance lower bound from Lemma 9. We constraint projected
SGD in ğ’²fer. This means that during any step of SGD our algorithm has to sample from a mixture
of ferromagnetic models with known mixture weights. The state of the art approximate sampling
algorithm from ferromagnetic Ising models achieves the following performance, improving on prior
work [JS93, LSS19, CLV22, CGG+19].
Proposition 9 (Theorem 1.1 of [CZ22]). Let ğ›¿ğ›½, ğ›¿ğœ†âˆˆ(0, 1) be constants and ğœ‡be the Gibbs
distribution of the ferromagnetic Ising model specified by graph ğº= (ğ‘‰, ğ¸), |ğ‘‰| = ğ‘›, |ğ¸| = ğ‘š,
parameters ğ›½âˆˆ[1 + ğ›¿ğ›½, +âˆ)ğ‘šand external field ğœ†âˆˆ[0, 1 âˆ’ğ›¿ğœ†]ğ‘›. There exists an algorithm that
27

samples ğ‘‹satisfying TV(ğ‘‹, ğœ‡) â‰¤ğœ–for any given parameter ğœ–âˆˆ(0, 1) within running time
ğ‘š
(ï¸‚log ğ‘›
ğœ–
)ï¸‚ğ‘‚ğ›¿ğ›½,ğ›¿ğœ†(1)
.
This algorithm can handle general instances and it only takes a near-linear running time when
parameters are bounded away from the all-ones vector. Our goal is to sample from a mixture of
two such ferromagnetic Ising models which can be done efficiently. For simplicity, we next restrict
ourselves to the unweighted case.
Theorem 3 (Min-Cut has a Compressed, Efficiently Optimizable and Samplable Solution Generator).
Consider a prior over Min-Cut instances with ğ‘›nodes. For any ğœ–> 0, there exists a solution generator
ğ’«= {ğ‘(ğ‘¤) : ğ‘¤âˆˆğ’²} such that ğ’«is complete, compressed with description poly(ğ‘›)polylog(1/ğœ–),
â„’+ ğœ†ğ‘…: ğ’²â†¦â†’R is efficiently optimizable via projected stochastic gradient descent in poly(ğ‘›, 1/ğœ–)
steps for some ğœ†> 0 and efficiently samplable in poly(ğ‘›, 1/ğœ–) steps.
Proof. We have that
MINCUT = 1
4
min
ğ‘¥âˆˆ{âˆ’1,1}ğ‘›ğ‘¥âŠ¤ğ¿ğºğ‘¥.
The analysis (i.e., the selection of the feature mappings) is similar to the one of Theorem 2 with the
sole difference that the parameter space is constrained to be ğ’²fer and ğœ“â„(ğº) = (ğ¿ğº)â™­. We note that
Proposition 9 is applicable during the optimization steps. Having an efficient approximate sampler
for solutions of Min-Cut, it holds that the runtime of the projected SGD algorithm is poly(ğ‘›, 1/ğœ–).
We note that during the execution of the algorithm we do not have access to perfectly unbiased
samples from mixture of ferromagnetic Ising models. However, we remark that SGD is robust to that
inaccuracy in the stochastic oracle. For further details, we refer e.g., to [dâ€™A08]).
G.1.3
Max-ğ‘˜-CSPs
In this problem, we are given a set of variables {ğ‘¥ğ‘¢}ğ‘¢âˆˆğ’°where |ğ’°| = ğ‘›and a set of Boolean
predicates ğ‘ƒ. Each variable ğ‘¥ğ‘¢takes values in {âˆ’1, 1}. Each predicate depends on at most ğ‘˜
variables. For instance, Max-Cut is a Max-2-CSP. Our goal is to assign values to variables so as to
maximize the number of satisfied constraints (i.e., predicates equal to 1). Let us fix a predicate â„âˆˆğ‘ƒ,
i.e., a Boolean function â„: {âˆ’1, 1}ğ‘›â†’{0, 1} which is a ğ‘˜-junta. Using standard Fourier analysis,
the number of satisfied predicates for the assignment ğ‘¥âˆˆ{âˆ’1, 1}ğ‘›is
ğ¹(ğ‘¥) =
|ğ‘ƒ|
âˆ‘ï¸
ğ‘—=1
âˆ‘ï¸
ğ‘†âŠ†[ğ‘›],|ğ‘†|â‰¤ğ‘˜
Ì‚ï¸€â„ğ‘—(ğ‘†)
âˆï¸
ğ‘¢âˆˆğ‘†
ğ‘¥ğ‘¢,
where Ì‚ï¸€â„ğ‘—(ğ‘†) is the Fourier coefficient of the predicate â„ğ‘—at ğ‘†.
Theorem 4 (Max-ğ‘˜-CSPs have a Compressed and Efficiently Optimizable Solution Generator).
Consider a prior over Max-ğ‘˜-CSP instances with ğ‘›variables, where ğ‘˜âˆˆN can be considered
constant compared to ğ‘›. For any ğœ–> 0, there exists a solution generator ğ’«= {ğ‘(ğ‘¤) : ğ‘¤âˆˆğ’²}
such that ğ’«is complete, compressed with description ğ‘‚(ğ‘›ğ‘˜)polylog(1/ğœ–) and â„’+ ğœ†ğ‘…: ğ’²â†¦â†’R
is efficiently optimizable via projected stochastic gradient descent in poly(ğ‘›ğ‘˜, 1/ğœ–) steps for some
ğœ†> 0.
Proof. Any instance of Max-ğ‘˜-CSP is a list of predicates (i.e., Boolean functions) and our goal
is to maximize the number of satisfied predicated with a single assignment ğ‘ âˆˆ{âˆ’1, 1}ğ‘›. We
show that there exist feature mappings so that the cost of every solution ğ‘ under any instance/predi-
cates list ğ‘ƒis a bilinear function of the feature vectors (cf. Item 2 of Assumption 1). We con-
sider the order ğ‘˜correlation-based feature mappings ğœ“ğ‘†(ğ‘ ) = (ğ‘ âŠ—ğ‘˜)â™­âˆˆRğ‘›ğ‘˜, where by (Â·)â™­
we denote the flattening operation of the order ğ‘˜tensor, and, ğœ“â„(ğ‘ƒ) = ğœ“â„(â„1, . . . , â„|ğ‘ƒ|) =
âˆ’âˆ‘ï¸€|ğ‘ƒ|
ğ‘—=1((Ì‚ï¸€â„ğ‘—(ğ‘†))ğ‘†âŠ†[ğ‘›],|ğ‘†|â‰¤ğ‘˜)âŠ¤âˆˆRğ‘›ğ‘˜, where (Ì‚ï¸€â„ğ‘—(ğ‘†))ğ‘†âŠ†[ğ‘›],|ğ‘†|â‰¤ğ‘˜is a vector of size ğ‘›ğ‘˜with
the Fourier coeffients of the ğ‘—-th predicate.
We take ğœ“â„being the coordinate-wise sum of
these coefficients.
The setting the matrix ğ‘€to be the identity matrix ğ¼âˆˆRğ‘›ğ‘˜Ã—ğ‘›ğ‘˜, we get
that the cost of any solution ğ‘ can be expressed as the bilinear function ğœ“â„(ğ‘ƒ)âŠ¤ğ‘€ğœ“ğ‘†(ğ‘ ) =
28

âˆ’âˆ‘ï¸€|ğ‘ƒ|
ğ‘—=1
âˆ‘ï¸€
ğ‘†âŠ†[ğ‘›],|ğ‘†|â‰¤ğ‘˜Ì‚ï¸€â„ğ‘—(ğ‘†) âˆï¸€
ğ‘¢âˆˆğ‘†ğ‘¥ğ‘¢. For any â„: {âˆ’1, 1}ğ‘›â†’{0, 1}, we get that the description
size of any Ì‚ï¸€â„(ğ‘†) is poly(ğ‘›, ğ‘˜) and so the dimensions of the ğœ“ğ‘†, ğœ“â„feature mappings are polynomial
in the description size of â„. Moreover, we get that â€–ğœ“â„(ğ‘ƒ)â€–, â€–ğœ“ğ‘†(ğ‘ )â€–, â€–ğ‘€â€– â‰¤poly(ğ‘›ğ‘˜). Hence,
the constants ğ·ğ‘†, ğ·â„, ğ¶are polynomial in the description size of the instance family. Finally, we
have that for any ğ‘£, Varğ‘ âˆ¼ğ‘ˆ(ğ‘†)[ğ‘£Â· ğœ“ğ‘†(ğ‘ )] = Varğ‘ âˆ¼ğ‘ˆ({âˆ’1,1}ğ‘›)[ğ‘£Â· ğ‘ âŠ—ğ‘˜] = â„¦(â€–ğ‘£â€–2
2), using Lemma 9,
assuming that ğ‘£âˆ…is 0 without loss of generality. This implies the result.
G.2
Bipartite Matching and TSP
G.2.1
Maximum Weight Bipartite Matching
In Maximum Weight Bipartite Matching (MWBM) there exists a complete bipartite graph (ğ´, ğµ)
with |ğ´| = |ğµ| = ğ‘›(the assumptions that the graph is complete and balanced is without loss of
generality) with weight matrix ğ‘Šwhere ğ‘Š(ğ‘–, ğ‘—) indicates the value of the edge (ğ‘–, ğ‘—), ğ‘–âˆˆğ´, ğ‘—âˆˆğµ
and the goal is to match the vertices in order to maximize the value. Hence the goal is to maximize
ğ¿(Î ) = ğ‘ŠÂ· Î  over all permutation matrices. By the structure of the problem some maximum
weight matching is a perfect matching. Furthermore, by negating the weights of the edges we
can state the problem as the following minimization problem: given a bipartite graph (ğ´, ğµ) and
weight matrix ğ‘Šâˆˆ(R âˆª{âˆ})ğ‘›Ã—ğ‘›, find a perfect matching ğ‘€with minimum weight. One of the
fundamental results in combinatorial optimization is the polynomial-time blossom algorithm for
computing minimum-weight perfect matchings by [Edm65].
We begin this section by showing a variance lower bound under the uniform distribution over the
permutation group.
Lemma 10 (Variance Lower Bound). Let ğ‘ˆ(Sğ‘›) be the uniform distribution over ğ‘›Ã— ğ‘›permutation
matrices. For any matrix ğ‘ŠâˆˆRğ‘›Ã—ğ‘›, with âˆ‘ï¸€
ğ‘–ğ‘Šğ‘–ğ‘—= 0 and âˆ‘ï¸€
ğ‘—ğ‘Šğ‘–ğ‘—= 0 we have
VarÎ âˆ¼ğ‘ˆ(Sğ‘›)[ğ‘ŠÂ· Î ] = â€–ğ‘Šâ€–2
F
ğ‘›âˆ’1 .
Proof. We have that EÎ âˆ¼ğ‘ˆ(Sğ‘›)[Î ğ‘–ğ‘—] = 1/ğ‘›and EÎ âˆ¼ğ‘ˆ(Sğ‘›)[Î ğ‘–ğ‘—Î ğ‘ğ‘] = 1{ğ‘–Ì¸=ğ‘âˆ§ğ‘—Ì¸=ğ‘}
ğ‘›(ğ‘›âˆ’1)
+ 1{ğ‘–=ğ‘,ğ‘—=ğ‘}
ğ‘›
.
We have
VarÎ âˆ¼ğ‘ˆ(Sğ‘›)[ğ‘ŠÂ· Î ] =
E
Î âˆ¼ğ‘ˆ(Sğ‘›)[(ğ‘ŠÂ· Î )2] âˆ’
(ï¸‚
E
Î âˆ¼ğ‘ˆ(Sğ‘›)[ğ‘ŠÂ· Î ]
)ï¸‚2
=
âˆ‘ï¸
ğ‘–,ğ‘—,ğ‘,ğ‘
ğ‘Šğ‘ğ‘ğ‘Šğ‘–ğ‘—
(ï¸‚1{ğ‘–Ì¸= ğ‘, ğ‘—Ì¸= ğ‘}
ğ‘›(ğ‘›âˆ’1)
+ 1{ğ‘–= ğ‘, ğ‘—= ğ‘}
ğ‘›
)ï¸‚
âˆ’
â›
ââˆ‘ï¸
ğ‘–,ğ‘—
ğ‘Šğ‘–ğ‘—
ğ‘›
â
â 
2
= 1
ğ‘›
âˆ‘ï¸
ğ‘–,ğ‘—
ğ‘Š2
ğ‘–ğ‘—+
âˆ‘ï¸
ğ‘–,ğ‘—,ğ‘,ğ‘
ğ‘Šğ‘–ğ‘—ğ‘Šğ‘ğ‘
1{ğ‘–Ì¸= ğ‘, ğ‘—Ì¸= ğ‘}
ğ‘›(ğ‘›âˆ’1)
= â€–ğ‘Šâ€–2
F
ğ‘›
+
âˆ‘ï¸
ğ‘–,ğ‘—,ğ‘,ğ‘
ğ‘Šğ‘–ğ‘—ğ‘Šğ‘ğ‘
1{ğ‘–Ì¸= ğ‘, ğ‘—Ì¸= ğ‘}
ğ‘›(ğ‘›âˆ’1)
,
where to obtain the third equality we used our assumption that âˆ‘ï¸€
ğ‘–ğ‘—ğ‘Šğ‘–ğ‘—= 0. We observe that, by
our assumption that âˆ‘ï¸€
ğ‘ğ‘Šğ‘ğ‘= 0 for all ğ‘it holds âˆ‘ï¸€
ğ‘Ì¸=ğ‘—ğ‘Šğ‘ğ‘= âˆ’ğ‘Šğ‘ğ‘—and therefore, we have
âˆ‘ï¸
ğ‘
ğ‘Šğ‘ğ‘1{ğ‘–Ì¸= ğ‘, ğ‘—Ì¸= ğ‘} = 1{ğ‘–Ì¸= ğ‘}
âˆ‘ï¸
ğ‘
ğ‘Šğ‘ğ‘1{ğ‘—Ì¸= ğ‘} = âˆ’1{ğ‘–Ì¸= ğ‘}ğ‘Šğ‘ğ‘—.
Similarly, using the fact that âˆ‘ï¸€
ğ‘Ì¸=ğ‘–ğ‘Šğ‘ğ‘—= âˆ’ğ‘Šğ‘–ğ‘—we obtain that
âˆ‘ï¸
ğ‘ğ‘
ğ‘Šğ‘ğ‘1{ğ‘–Ì¸= ğ‘, ğ‘—Ì¸= ğ‘} =
âˆ‘ï¸
ğ‘
âˆ’ğ‘Šğ‘ğ‘—1{ğ‘–Ì¸= ğ‘} = ğ‘Šğ‘–ğ‘—.
Therefore, using the above identity, we have that
âˆ‘ï¸
ğ‘–,ğ‘—,ğ‘,ğ‘
ğ‘Šğ‘–ğ‘—ğ‘Šğ‘ğ‘
1{ğ‘–Ì¸= ğ‘, ğ‘—Ì¸= ğ‘}
ğ‘›(ğ‘›âˆ’1)
=
âˆ‘ï¸
ğ‘–,ğ‘—
ğ‘Š2
ğ‘–ğ‘—
ğ‘›(ğ‘›âˆ’1) =
â€–ğ‘Šâ€–2
F
ğ‘›(ğ‘›âˆ’1) .
Combining the above we obtain the claimed identity.
29

Remark 8. We note that in MWBM the conditions âˆ‘ï¸€
ğ‘–ğ‘Šğ‘–ğ‘—= 0 and âˆ‘ï¸€
ğ‘—ğ‘Šğ‘–ğ‘—= 0 are without loss of
generality.
We next claim that there exists an efficient algorithm for (approximately) sampling such permutation
matrices.
Lemma 11 (Efficient Sampling). There exists an algorithm that generates approximate samples
from the Gibbs distribution ğ‘(Â·; ğ‘Š) with parameter ğ‘Šover the symmetric group, i.e., ğ‘(Î ; ğ‘Š) âˆ
exp(ğ‘ŠÂ· Î )1{Î  âˆˆSğ‘›}, in poly(ğ‘›) time.
Proof. This lemma essentially requires approximating the permanent of a weighted matrix, since
this would imply that one has an approximation of the partition function. Essentially, our goal is to
generate a random variable ğ‘‹that is ğœ–-close in statistical distance to the probability measure
ğ‘(Î ; ğ‘Š) âˆexp(ğ‘ŠÂ· Î )1{Î  âˆˆSğ‘›} .
Note that the partition function is
ğ‘(ğ‘Š) =
âˆ‘ï¸
Î âˆˆSğ‘›
ğ‘’ğ‘ŠÂ·Î  =
âˆ‘ï¸
Î âˆˆSğ‘›
âˆï¸
(ğ‘–,ğ‘—)
ğ‘’ğ‘Šğ‘–ğ‘—Î ğ‘–ğ‘—=
âˆ‘ï¸
ğœâˆˆSğ‘›
âˆï¸
ğ‘–âˆˆ[ğ‘›]
ğ´ğ‘–,ğœ(ğ‘–) ,
where ğ´is a non-negative real matrix with entries ğ´ğ‘–ğ‘—= exp(ğ‘Šğ‘–ğ‘—). Note that in the third equality,
we used the isomorphism between permutations and permutation matrices. Hence, ğ‘(ğ‘Š) is exactly
the permanent of the matrix ğ´.
Proposition 10 ([JSV04]). There exists a fully polynomial randomized approximation scheme for the
permanent of an arbitrary ğ‘›Ã— ğ‘›matrix ğ´with non-negative entries.
To conclude the proof of the lemma, we need the following standard result.
Proposition 11 (See Appendix H and [Sin12, Jer03]). For self-reducible problems, fully polynomial
approximate integration and fully polynomial approximate sampling are equivalent.
This concludes the proof since weighted matchings are self-reducible (see Appendix H).
The above lemma establishes our goal:
Theorem 5 (MWBM has a Compressed, Efficiently Optimizable and Samplable Solution Gen-
erator). Consider a prior over MWBM instances with ğ‘›nodes. For any ğœ–> 0, there exists a
solution generator ğ’«= {ğ‘(ğ‘¤) : ğ‘¤âˆˆğ’²} such that ğ’«is complete, compressed with description
poly(ğ‘›)polylog(1/ğœ–),â„’+ ğœ†ğ‘…: ğ’²â†¦â†’R is efficiently optimizable via projected stochastic gradient
descent in poly(ğ‘›, 1/ğœ–) steps for some ğœ†> 0 and efficiently samplable in poly(ğ‘›, 1/ğœ–) steps.
Proof. Consider an input graph ğºwith ğ‘›nodes and adjacency matrix ğ¸. The feature vector
corresponding to a matching can be represented as a binary matrix Î  âˆˆ{0, 1}ğ‘›Ã—ğ‘›with âˆ‘ï¸€
ğ‘—Î ğ‘–ğ‘—= 1
for all ğ‘–and âˆ‘ï¸€
ğ‘–Î ğ‘–ğ‘—= 1 for all ğ‘—, i.e., Î  is a permutation matrix. Then
MWBM = max
Î âˆˆSğ‘›ğ¸Â· Î  = min
Î âˆˆSğ‘›âˆ’ğ¸Â· Î  .
Therefore, for a candidate matching ğ‘ , we set ğœ“ğ‘†(ğ‘ ) to be the matrix Î  defined above. Moreover,
the feature vector of the graph is the negative (flattened) adjacency matrix âˆ’ğ¸â™­. The cost oracle
is then ğ¿(ğ‘…; ğ¸) = âˆ’âˆ‘ï¸€
ğ‘–ğ‘—ğ¸ğ‘–ğ‘—ğ‘€ğ‘–ğ‘—ğ‘…ğ‘–ğ‘—perhaps for an unknown weight matrix ğ‘€ğ‘–ğ‘—(see Remark 6).
This means that the dimensions of the feature mappings ğœ“ğ‘†, ğœ“â„are polynomial in the bit complexity
of â„. Moreover, we get that â€–ğœ“â„(ğ¼)â€–F, â€–ğœ“ğ‘†(ğ‘ )â€–F, â€–ğ‘€â€–ğ¹â‰¤poly(ğ‘›). We can employ Lemma 10
to get the variance lower bound under the uniform probability distribution in the subspace induced
by the matrices satisfying Lemma 10, i.e., the matrices of the parameter space (see Remark 9).
Finally, (approximate) sampling from our solution generators can be done efficiently using Lemma 11
and hence (noisy) projected SGD will have a runtime of order poly(ğ‘›, 1/ğœ–) (as in the case of Min-
Cut).
We close this section with a remark about Item 3 of Assumption 1.
30

Remark 9. We note that Item 3 of Assumption 1 can be weakened. We use our variance lower bound
in order to handle inner products of the form ğ‘¤Â· ğ‘¥where ğ‘¤will lie in the parameter space and
ğ‘¥is the featurization of a solution that lies in some space ğ‘‹. Hence it is possible that ğ‘¤lies in a
low-dimensional subspace of ğ‘‹. For our optimization purposes, it suffices to provide variance lower
bounds only in the subspace where ğ‘¤lies into.
G.2.2
Travelling Salesman Problem
Let us consider a weighted clique ğ¾ğ‘›with ğ‘›vertices and weight matrix ğ‘ŠâˆˆRğ‘›Ã—ğ‘›. A solution
to the TSP instance ğ‘Šis a sequence ğœ‹: [ğ‘›] â†’[ğ‘›] of the ğ‘›elements indicating the TSP tour
(ğœ‹(1), ğœ‹(2), . . . , ğœ‹(ğ‘›), ğœ‹(1)) and suffers a cost
ğ¿(ğœ‹) =
ğ‘›âˆ’1
âˆ‘ï¸
ğ‘–=1
ğ‘Šğœ‹(ğ‘–),ğœ‹(ğ‘–+1) + ğ‘Šğœ‹(ğ‘›),ğœ‹(1) .
Crucially, the allowed sequences are a proper subset of all possible permutations. For instance, the
permutations with fixed points or small cycles are not allowed. In particular, the solution space of
TSP corresponds to the set of cyclic permutations with no trivial cycles, i.e., containing an ğ‘›-cycle.
Clearly, the number of ğ‘›-cycles is (ğ‘›âˆ’1)!. The goal is to find a tour of minimum cost. Our first goal
is to write the cost objective as a linear function of the weight matrix ğ‘Šand the feasible solutions,
which correspond to cyclic permutations. To this end, we can think of each cyclic permutation ğœ‹as a
cyclic permutation matrix Î  âˆˆ{0, 1}ğ‘›Ã—ğ‘›. Then, the desired linearization is given by ğ¿(Î ) = ğ‘ŠÂ· Î 
(for a fixed graph instance).
Our next task is to provide a Gibbs measure that generates random cyclic permutations. Let Cğ‘›be
the space of ğ‘›Ã— ğ‘›cyclic permutation matrices. Then we have that the tour Î  is drawn from
ğ‘ğ‘Š(Î ) = exp(ğ‘ŠÂ· Î )1{Î  âˆˆCğ‘›}
âˆ‘ï¸€
Î â€²âˆˆCğ‘›exp(ğ‘ŠÂ· Î â€²) ,
where ğ‘Šis the weight matrix. The following key lemma provides guarantees for the performance
of our approach to TSP. This lemma allows us to show that the number of optimization steps is
poly(ğ‘›, 1/ğœ–).
Lemma 12 (Variance Lower Bound). Let ğ‘ˆ(Cğ‘›) be the uniform distribution over ğ‘›Ã— ğ‘›cyclic
permutation matrices. For any matrix ğ‘ŠâˆˆRğ‘›Ã—ğ‘›, with âˆ‘ï¸€
ğ‘–ğ‘Šğ‘–ğ‘—= 0 and âˆ‘ï¸€
ğ‘—ğ‘Šğ‘–ğ‘—= 0 we have
VarÎ âˆ¼ğ‘ˆ(Cğ‘›)[ğ‘ŠÂ· Î ] â‰¥
â€–ğ‘Šâ€–2
F
(ğ‘›âˆ’1)(ğ‘›âˆ’2) .
Proof. The first step is to compute some standard statistics about cyclic permutations (see Lemma 13).
Lemma 13 and the analysis of Lemma 10 gives us that VarÎ âˆ¼ğ‘ˆ(Cğ‘›)[ğ‘ŠÂ· Î ] is equal to
â€–ğ‘Šâ€–2
F
ğ‘›âˆ’1 +
âˆ‘ï¸
ğ‘–,ğ‘—,ğ‘,ğ‘
ğ‘Šğ‘–ğ‘—ğ‘Šğ‘ğ‘
(ï¸‚1{ğ‘–Ì¸= ğ‘= ğ‘—Ì¸= ğ‘}
(ğ‘›âˆ’1)(ğ‘›âˆ’2)
+ 1{ğ‘—Ì¸= ğ‘= ğ‘–Ì¸= ğ‘}
(ğ‘›âˆ’1)(ğ‘›âˆ’2)
+ 1{ğ‘–Ì¸= ğ‘Ì¸= ğ‘—Ì¸= ğ‘Ì¸= ğ‘–}
(ğ‘›âˆ’1)(ğ‘›âˆ’3)
)ï¸‚
.
Let us set
ğ´1 =
âˆ‘ï¸
ğ‘–,ğ‘—,ğ‘,ğ‘
ğ‘Šğ‘–ğ‘—ğ‘Šğ‘ğ‘1{ğ‘–Ì¸= ğ‘= ğ‘—Ì¸= ğ‘} .
We have that
âˆ‘ï¸
ğ‘
ğ‘Šğ‘ğ‘1{ğ‘–Ì¸= ğ‘}1{ğ‘= ğ‘—}1{ğ‘—Ì¸= ğ‘} = 1{ğ‘–Ì¸= ğ‘}1{ğ‘= ğ‘—}
âˆ‘ï¸
ğ‘
ğ‘Šğ‘ğ‘1{ğ‘—Ì¸= ğ‘} = âˆ’1{ğ‘–Ì¸= ğ‘}1{ğ‘= ğ‘—}ğ‘Šğ‘ğ‘—.
Hence
ğ´1 = âˆ’
âˆ‘ï¸
ğ‘–,ğ‘—,ğ‘
ğ‘Šğ‘–ğ‘—ğ‘Šğ‘ğ‘—1{ğ‘–Ì¸= ğ‘}1{ğ‘= ğ‘—} = âˆ’
âˆ‘ï¸
ğ‘–,ğ‘—
ğ‘Šğ‘–ğ‘—ğ‘Šğ‘—ğ‘—1{ğ‘–Ì¸= ğ‘—} =
âˆ‘ï¸
ğ‘—
ğ‘Š2
ğ‘—ğ‘—.
Due to symmetry, ğ´2 = âˆ‘ï¸€
ğ‘–,ğ‘—,ğ‘,ğ‘ğ‘Šğ‘–ğ‘—ğ‘Šğ‘ğ‘1{ğ‘—Ì¸= ğ‘= ğ‘–Ì¸= ğ‘} = âˆ‘ï¸€
ğ‘—ğ‘Š2
ğ‘—ğ‘—. It remains to argue about
ğ´3 =
âˆ‘ï¸
ğ‘–,ğ‘—,ğ‘,ğ‘
ğ‘Šğ‘–ğ‘—ğ‘Šğ‘ğ‘1{ğ‘–Ì¸= ğ‘Ì¸= ğ‘—Ì¸= ğ‘Ì¸= ğ‘–} .
31

We have that
âˆ‘ï¸
ğ‘
ğ‘Šğ‘ğ‘1{ğ‘–Ì¸= ğ‘}1{ğ‘Ì¸= ğ‘—}1{ğ‘—Ì¸= ğ‘}1{ğ‘Ì¸= ğ‘–} = âˆ’1{ğ‘–Ì¸= ğ‘}1{ğ‘Ì¸= ğ‘—}(ğ‘Šğ‘ğ‘—+ ğ‘Šğ‘ğ‘–) .
This gives that
ğ´3 = âˆ’
âˆ‘ï¸
ğ‘–,ğ‘—,ğ‘
ğ‘Šğ‘–ğ‘—(ğ‘Šğ‘ğ‘—+ ğ‘Šğ‘ğ‘–)1{ğ‘–Ì¸= ğ‘}1{ğ‘Ì¸= ğ‘—} .
Note that
âˆ‘ï¸
ğ‘–,ğ‘—,ğ‘
ğ‘Šğ‘–ğ‘—ğ‘Šğ‘ğ‘—1{ğ‘–Ì¸= ğ‘}1{ğ‘Ì¸= ğ‘—} =
âˆ‘ï¸
ğ‘—,ğ‘
ğ‘Šğ‘ğ‘—1{ğ‘Ì¸= ğ‘—}
âˆ‘ï¸
ğ‘–
ğ‘Šğ‘–ğ‘—1{ğ‘–Ì¸= ğ‘} = âˆ’
âˆ‘ï¸
ğ‘—,ğ‘
ğ‘Š2
ğ‘ğ‘—1{ğ‘Ì¸= ğ‘—} .
This implies that
ğ´3 =
âˆ‘ï¸
ğ‘—Ì¸=ğ‘
ğ‘Š2
ğ‘ğ‘—+
âˆ‘ï¸
ğ‘–Ì¸=ğ‘
ğ‘Š2
ğ‘ğ‘–= 2
âˆ‘ï¸
ğ‘—Ì¸=ğ‘
ğ‘Š2
ğ‘ğ‘—.
In total, this gives that
VarÎ âˆ¼ğ‘ˆ(Cğ‘›)[ğ‘ŠÂ· Î ] = â€–ğ‘Šâ€–2
F
ğ‘›âˆ’1 +
2 âˆ‘ï¸€
ğ‘—ğ‘Š2
ğ‘—ğ‘—
(ğ‘›âˆ’1)(ğ‘›âˆ’2) +
2 âˆ‘ï¸€
ğ‘–Ì¸=ğ‘—ğ‘Š2
ğ‘–ğ‘—
(ğ‘›âˆ’1)(ğ‘›âˆ’3) â‰¥â€–ğ‘Šâ€–2
F
ğ‘›âˆ’1 +
â€–ğ‘Šâ€–2
F
(ğ‘›âˆ’1)(ğ‘›âˆ’2) .
Remark 10. We note that in TSP the conditions âˆ‘ï¸€
ğ‘–ğ‘Šğ‘–ğ‘—= 0 and âˆ‘ï¸€
ğ‘—ğ‘Šğ‘–ğ‘—= 0 are without loss of
generality.
The next lemma is a generic lemma that states some properties of random cyclic permutation matrices.
Lemma 13. Consider a uniformly random cyclic permutation matrix Î . Let us fix ğ‘–Ì¸= ğ‘—and ğ‘Ì¸= ğ‘.
Then
â€¢ E[Î ğ‘–ğ‘—] =
1
ğ‘›âˆ’1.
â€¢ E[Î ğ‘–ğ‘—Î ğ‘ğ‘] = 1{ğ‘–Ì¸=ğ‘=ğ‘—Ì¸=ğ‘}
(ğ‘›âˆ’1)(ğ‘›âˆ’2) + 1{ğ‘—Ì¸=ğ‘=ğ‘–Ì¸=ğ‘}
(ğ‘›âˆ’1)(ğ‘›âˆ’2) + 1{ğ‘–Ì¸=ğ‘Ì¸=ğ‘—Ì¸=ğ‘Ì¸=ğ‘–}
(ğ‘›âˆ’1)(ğ‘›âˆ’3)
+ 1{ğ‘–=ğ‘,ğ‘—=ğ‘}
ğ‘›âˆ’1
.
Proof. First, note that any matrix that corresponds to a cyclic permutation does not contain fixed
points and so the diagonal elements are 0 deterministically. For the first item, the number of cyclic
permutations such that ğ‘–â†’ğ‘—(i.e., Î ğ‘–ğ‘—= 1) is (ğ‘›âˆ’2)!. This implies that the desired expectation is
(ğ‘›âˆ’2)!/|Cğ‘›| = 1/(ğ‘›âˆ’1). For the second item, if ğ‘–= ğ‘, ğ‘—= ğ‘, we recover the first item. Otherwise
if ğ‘–= ğ‘or ğ‘—= ğ‘, then the expectation vanishes since we deal with permutation matrices. Finally, let
us consider the case where ğ‘–Ì¸= ğ‘and ğ‘—Ì¸= ğ‘. Our goal is to count the number of cyclic permutations
with ğ‘–â†’ğ‘—and ğ‘â†’ğ‘.
â€¢ If ğ‘–Ì¸= ğ‘Ì¸= ğ‘—Ì¸= ğ‘Ì¸= ğ‘–, then there are ğ‘›choices to place ğ‘–and ğ‘›âˆ’2 choices to place ğ‘. Then
there are (ğ‘›âˆ’4)! possible orderings for the remaining elements. This gives an expectation
equal to 1/((ğ‘›âˆ’1)(ğ‘›âˆ’3)).
â€¢ If ğ‘–Ì¸= ğ‘= ğ‘—Ì¸= ğ‘or ğ‘—Ì¸= ğ‘= ğ‘–Ì¸= ğ‘, then there are ğ‘›choices for ğ‘–and (ğ‘›âˆ’3)! orderings for
the remaining elements. Hence, the expectation is 1/((ğ‘›âˆ’1)(ğ‘›âˆ’2)).
We note that sampling from our solution generators is the reason that we cannot find an optimal TSP
solution efficiently. In general, an algorithm that has converged to an almost optimal parameter ğ‘Šâ‹†
has to generate samples from the Gibbs measure that is concentrated on cycles with minimum weight.
In this low-temperature regime, sampling is NP-hard. We are now ready to state our result.
Theorem 6 (TSP has a Compressed, Efficiently Optimizable Solution Generator). Consider a
prior over TSP instances with ğ‘›nodes. For any ğœ–> 0, there exists a solution generator ğ’«=
{ğ‘(ğ‘¤) : ğ‘¤âˆˆğ’²} such that ğ’«is complete, compressed with description poly(ğ‘›)polylog(1/ğœ–) and
â„’+ ğœ†ğ‘…: ğ’²â†¦â†’R is efficiently optimizable via projected stochastic gradient descent in poly(ğ‘›, 1/ğœ–)
steps for some ğœ†> 0.
32

Proof. Consider an input graph ğºwith ğ‘›nodes and weighted adjacency matrix ğ¸. The feature vector
is again a permutation matrix Î  with the additional constraint that Î  has to represent a single cycle
(a tour over all cities). Then
TSP = min
Î âˆˆCğ‘›ğ¸Â· Î  .
The cost function for TSP is ğ¿(Î ; ğ¸) = âˆ‘ï¸€
ğ‘–ğ‘—ğ¸ğ‘–ğ‘—ğ‘€ğ‘–ğ‘—Î ğ‘–ğ‘—. We refer to Theorem 5 for the details
about the feature mappings. We can finally use Lemma 12 to obtain a variance lower bound (in the
subspace induced by the parameters satisfying this lemma, see Remark 9) under the uniform measure
over the space of cyclic permutation matrices Cğ‘›.
H
Sampling and Counting
In this section, we give a quick overview of the connections between approximate sampling and
counting. For a formal treatment, we refer to [Sin12].
In what follows, ğœmay be thought of as an encoding of an instance of some combinatorial problem,
and the ğœ”of interest are encodings of the structures we wish to generate. Consider a weight function
ğ‘Šand assume that ğ‘Š(ğœ, ğœ”) is computable in time polynomial in |ğœ|.
Definition 4 (Approximate Sampling). A fully polynomial approximate sampler for (â„¦ğœ, ğœ‹ğœ) is
a Probabilistic Turing Machine which, on inputs ğœand ğœ–âˆˆQ+ (0 < ğœ–â‰¤1), outputs ğœ”âˆˆÎ£â‹†,
according to a measure ğœ‡ğœsatisfying TV(ğœ‹ğœ, ğœ‡ğœ) â‰¤ğœ–, in time bounded by a bivariate polynomial in
|ğœ| and log(1/ğœ–).
One of the main applications of sampling is to approximate integration. In our setting this means
estimating ğ‘(ğœ) to some specified relative error.
Definition 5 (Approximate Integration). A fully polynomial randomized approximation scheme for
ğ‘(ğœ) is a Probabilistic Turing Machine which on input ğœ, ğœ–, outputs an estimate Ì‚ï¸€ğ‘so that
Pr[ğ‘/(1 + ğœ–) â‰¤Ì‚ï¸€ğ‘â‰¤(1 + ğœ–)ğ‘] â‰¥3/4 ,
and which runs in time polynomial in |ğœ| and 1/ğœ–.
Definition 6 (Self-Reducible Problems). An NP search problem is self-reducible if the set of solutions
can be partitioned into polynomially many sets each of which is in a one-to-one correspondence
with the set of solutions of a smaller instance of the problem, and the polynomial size set of smaller
instances are efficiently computable.
For instance, consider the relation MATCH which associates with an undirected graph ğºall matchings
(independent sets of edges) of ğº. Then MATCH is self-reducible since, for any edge ğ‘’= (ğ‘¢, ğ‘£) âˆˆğ¸(ğº),
we have that
MATCH(ğº) = MATCH(ğº1) âˆª{ğ‘€âˆª{ğ‘’} : ğ‘€âˆˆMATCH(ğº2)} ,
where ğº1 is the graph obtained by deleting ğ‘’and ğº2 is the graph obtained be deleting both ğ‘¢and ğ‘£
together with all their incident edges.
Theorem 7 (See Corollary 3.16 in [Sin12]). For self-reducible problems, approximate integration
and good sampling are equivalent.
We remark that the above result holds for the more general class of self-partitionable problems.
I
Details of the Experimental Evaluation
We investigate the effect of the entropy regularizer (see Equation (2)) in a very simple setting: we try
to find the Max-Cut of a fixed graph ğº, i.e., the support of the prior â„›is a single graph. We show that
while the unregularized objective is often â€œstuckâ€ at sub-optimal solutions â€“ and this happens even for
very small instances (15 nodes) â€“ of the Max-Cut problem, the regularized version (with the fast/slow
mixture scheme) is able to find the optimal solutions. We consider an instance randomly generated
by the ErdËosâ€“RÃ©nyi model ğº(ğ‘›, ğ‘) and then optimize the â€œvanillaâ€ loss â„’and the regularized loss
â„’ğœ†defined in Equation (3). The solutions are vectors ğ‘ âˆˆ{Â±1}ğ‘›. We first use the feature mapping
ğœ“ğ‘†(ğ‘ ) = (ğ‘ ğ‘ âŠ¤)â™­described in Section 1.1 and an exponential family solution generator that samples a
33

class FastSlowMixture(torch.nn.Module):
def __init__(self, dimension, rho):
"""
The Model parameters.
"""
super().__init__()
self.l1 = torch.nn.Parameter(torch.empty(30, dimension))
torch.nn.init.kaiming_uniform_(self.l1, a=5**0.5)
self.l2 = torch.nn.Parameter(torch.empty(10, 30))
torch.nn.init.kaiming_uniform_(self.l2, a=5**0.5)
self.l3 = torch.nn.Parameter(torch.empty(1, 10))
torch.nn.init.kaiming_uniform_(self.l3, a=5**0.5)
self.a2 = torch.nn.ReLU()
self.a1 = torch.nn.ReLU()
self.rho = rho
def forward(self, x, is_cold=True):
temp = self.rho * (1. - is_cold) + is_cold
out = x
out = torch.nn.functional.linear(out, temp * self.l1)
out = self.a1(out)
out = torch.nn.functional.linear(out, temp * self.l2)
out = self.a2(out)
out = torch.nn.functional.linear(out, temp * self.l3)
return out
Figure 4: Our implementation of the fast/slow network. The output of the network is the log-density
(score) of a solution ğ‘ âˆˆ{Â±1}dimension. If evaluated with the is-cold set to False, the parameters of
every linear layer are re-scaled by the inverse temperature rho.
solution ğ‘ with probability âˆexp(ğ‘¤Â· ğœ“ğ‘†(ğ‘ )) for some weight vector ğ‘¤âˆˆRğ‘›2. We also consider
optimizing a simple 3-layer ReLU network as solution generator with input ğ‘ âˆˆ{Â±1}ğ‘›on the same
random graphs. We generate 100 random ğº(ğ‘›, ğ‘) graphs with ğ‘›= 15 nodes and ğ‘= 0.5 and train
solution generators using both the â€vanillaâ€ and the entropy-regularized loss functions. We perform
600 iterations and, for the entropy regularization, we progressively decrease the regularization weight,
starting from 10, and dividing it by 2 every 60 iterations. We used a fast/slow mixing with mixture
probability 0.2 and inverse temperature rho=0.03 (see Figure 4).
For convenience, we present a pytorch implementation of our simple 3-layer ReLU network here.
For more details we refer to our full code submitted in the supplementary material.
Out of the 100 trials we found that our proposed objective was always able to find the optimal cut
while the model trained with the vanilla loss was able to find it for approximately 65% of the graphs
(for 65 out of 100 using the linear network and for 66 using the ReLU network). In Figure 2 we show
two instances where the model trained with the â€vanillaâ€ loss gets stuck on a sub-optimal solution
while the entropy-regularized one succeeds in finding the optimal solution. Our experiments show
that the regularization term and the fast/slow mixture scheme that we introduced to achieve our main
theoretical convergence result, see Section 3 and Proposition 4, are potentially useful for training
more realistic models for bigger instances and we leave more extensive experimental evaluation as an
interesting direction for future work.
34

We note that, similarly to our theoretical results, our sampler in this experimental section is of the
form ğ‘’score(ğ‘ ;ğ‘¤), where ğ‘ âˆˆ{âˆ’1, 1}ğ‘›( here ğ‘›is the number of nodes in the graph) is a candidate
solution of the Max-Cut problem. The function used is a 3-layer MLP (see Figure Figure 4). Since
the instances that we consider here are small (ğ‘›= 15) we can explicitly compute the density (score)
of every solution and use that to compute the expected gradient. For larger instances, one could use
some approximate sampler (e.g., via Langevin dynamics) to generate samples. The main message
of the current experimental section is that even for very small instances of Max-Cut (i.e., with 15
nodes), optimizing the vanilla objective is not sufficient and the iteration gets trapped in local optima.
In contrast, our entropy regularized always manages to find the optimal cut.
35

