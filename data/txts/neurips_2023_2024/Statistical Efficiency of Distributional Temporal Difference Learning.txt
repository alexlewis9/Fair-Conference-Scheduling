Statistical Efï¬ciency of Distributional Temporal
Difference Learning
Yang Pengâˆ—
Liangyu Zhangâ€ 
Zhihua Zhangâ€¡
Abstract
Distributional reinforcement learning (DRL) has achieved empirical success in
various domains. One core task in the ï¬eld of DRL is distributional policy evalua-
tion, which involves estimating the return distribution Î·Ï€ for a given policy Ï€. The
distributional temporal difference learning has been accordingly proposed, which
is an extension of the temporal difference learning (TD) in the classic RL area.
In the tabular case, Rowland et al. [2018] and Rowland et al. [2024a] proved the
asymptotic convergence of two instances of distributional TD, namely categori-
cal temporal difference learning (CTD) and quantile temporal difference learning
(QTD), respectively. In this paper, we go a step further and analyze the ï¬nite-
sample performance of distributional TD. To facilitate theoretical analysis, we
propose non-parametric distributional temporal difference learning (NTD). For a
Î³-discounted inï¬nite-horizon tabular Markov decision process, we show that for
NTD we need eO

1
Îµ2p(1âˆ’Î³)2p+1

iterations to achieve an Îµ-optimal estimator with
high probability, when the estimation error is measured by the p-Wasserstein dis-
tance. This sample complexity bound is minimax optimal up to logarithmic fac-
tors in the case of the 1-Wasserstein distance. To achieve this, we establish a novel
Freedmanâ€™s inequality in Hilbert spaces, which would be of independent interest.
In addition, we revisit CTD, showing that the same non-asymptotic convergence
bounds hold for CTD in the case of the p-Wasserstein distance for p â‰¥1.
1
Introduction
In high-stake applications of reinforcement learning (RL), such as healthcare [Lavori and Dawson,
2004, BÃ¶ck et al., 2022] and ï¬nance[Ghysels et al., 2005], only considering the mean of returns is
insufï¬cient. It is necessary to take risk and uncertainties into consideration. Distributional reinforce-
ment learning (DRL) Morimura et al. [2010], Bellemare et al. [2017, 2023] addresses such issues by
modeling the complete distribution of returns instead of their expectations.
In the ï¬eld of DRL, one of the most fundamental tasks is to estimate the return distribution Î·Ï€ for
a given policy Ï€, which is referred to as distributional policy evaluation. Distributional temporal
difference learning (TD) is probably the most widely-used approach for solving the distributional
policy evaluation problem. A key aspect of implementing a distributional TD algorithm is how
to represent the return distribution, an inï¬nite-dimensional object, via a computationally feasible
ï¬nite-dimensional parametrization. This has led to the development of two special instances of dis-
tributional TD: categorical temporal difference learning (CTD) [Bellemare et al., 2017] and quantile
temporal difference learning (QTD) [Dabney et al., 2018]. These algorithms provide computation-
ally tractable parametrizations and updating schemes of the return distribution.
âˆ—School of Mathematical Sciences, Peking University; email: pengyang@pku.edu.cn.
â€ School of Statistics and Management, Shanghai University of Finance and Economics;
email:
zhangliangyu@sufe.edu.cn.
â€¡School of Mathematical Sciences, Peking University; email: zhzhang@math.pku.edu.cn.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).

Previous theoretical works have primarily focused on the asymptotic behaviors of distributional TD.
In particular, Rowland et al. [2018] and Rowland et al. [2024a] showed the asymptotic convergences
of CTD and QTD in the tabular case, respectively. A natural question arises: can we depict the sta-
tistical efï¬ciency of distributional TD by non-asymptotic results similar to the classic TD algorithm
[Li et al., 2024]?
1.1
Contributions
In this paper, we manage to answer the above question afï¬rmatively in the synchronous setting
[Kakade, 2003, Kearns et al., 2002]. Firstly, we introduce non-parametric distributional temporal
difference learning (NTD) in Section 3, which is not practical but aids theoretical understanding.
We show that eO

1
Îµ2p(1âˆ’Î³)2p+1

4 iterations are sufï¬cient to yield an estimator Ë†Î·Ï€, such that the
p-Wasserstein metric between Ë†Î·Ï€ and Î·Ï€ is less than Îµ with high probability (Theorem 4.1). This
bound is minimax optimal (Theorem B.1) in the 1-Wasserstein metric case, if we neglect all loga-
rithmic terms. Next, we revisit the more practical CTD, and show that, in terms of the p-Wasserstein
metric, CTD and NTD have the same non-asymptotic convergence bounds (Theorem 4.2). It is
worth pointing out that to attain such tight bounds in Theorem 4.1, we establish a Freedmanâ€™s in-
equality in Hilbert spaces (Theorem A.2). We would believe it is of independent interest beyond the
current work.
1.2
Related Work
Non-asymptotic results of DRL.
Recently, there has been an emergence of work focusing on
ï¬nite-sample/iteration results of the distributional policy evaluations.
Wu et al. [2023] studied the ofï¬‚ine distributional policy evaluation problem. They solved the prob-
lem via ï¬tted likelihood estimation (FLE) inspired by the classic ofï¬‚ine policy evaluation algorithm
ï¬tted Q evaluation (FQE), and provided a generalization bound in the p-Wasserstein metric case.
Zhang et al. [2023] proposed to solve distributional policy evaluation by the model-based ap-
proach and derived corresponding sample complexity bounds, namely eO

1
Îµ2p(1âˆ’Î³)2p+2

in the
p-Wasserstein metric case, and eO

1
Îµ2(1âˆ’Î³)4

in both the Kolmogorov-Smirnov metric and total
variation metric under different conditions. Rowland et al. [2024b] proposed direct categorical ï¬xed-
point computation (DCFP), a model-based version of CTD, in which they constructed the estimator
by solving a linear system directly instead of performing an iterative algorithm. They showed that
the sample complexity of DCFP is eO

1
Îµ2(1âˆ’Î³)3

in the 1-Wasserstein metric case by introducing
the novel stochastic categorical CDF Bellman operator and equation. Their result matches the mini-
max lower bound (up to logarithmic factors) eâ„¦

1
Îµ2(1âˆ’Î³)3

proposed in [Zhang et al., 2023], which
implies that learning the full return distribution can be as sample-efï¬cient as learning just its expecta-
tion. Itâ€™s worth noting that the algorithms analyzed in both [Zhang et al., 2023] and [Rowland et al.,
2024b] are model-based, hence they are less similar to practical algorithms. While distributional
TD analyzed in this paper, as a model-free method, is more practical, and also involves a more
complicated theoretical analysis.
BÃ¶ck and Heitzinger [2022] also considered model-free method. They proposed speedy categorical
policy evaluation (SCPE), which can be regarded as CTD with an additional acceleration term. They
showed that the sample complexity of SCPE is eO

1
Îµ2(1âˆ’Î³)4

in the 1-Wasserstein metric case.
Compared to [BÃ¶ck and Heitzinger, 2022], our work shows that even if we do not introduce any
acceleration techniques to the original CTD algorithm, it is still possible to attain the near-minimax
optimal sample complexity bounds. Thus, we give sharper bounds based on a simpler algorithm.
Table 1 gives more detailed comparisons of sample complexity with the previous work in the 1-
Wasserstein metric. Note that solving distributional policy evaluation can also address the traditional
4Throughout this paper, the notation f(Â·) = ËœO (g(Â·)) (f(Â·) = Ëœâ„¦(g(Â·))) means that f(Â·) is order-wise no
larger (smaller) than g(Â·), ignoring logarithmic factors poly(log |S| , log |A| , log(
1
1âˆ’Î³ ), log( 1
Îµ), log( 1
Î´ )), as
|S| , |A| ,
1
1âˆ’Î³ , 1
Îµ, 1
Î´ â†’âˆ.
2

Sample Complexity
Algorithms
Task
[Gheshlaghi Azar et al., 2013]
eO

1
Îµ2(1âˆ’Î³)3

Model-based
PE
[Li et al., 2024]
eO

1
Îµ2(1âˆ’Î³)3

TD (Model-free)
PE
[Rowland et al., 2018]
Asymptotic
CTD (Model-free)
DPE
[Rowland et al., 2024a]
Asymptotic
QTD (Model-free)
DPE
[Rowland et al., 2024b]
eO

1
Îµ2(1âˆ’Î³)3

DCFP (Model-based)
DPE
[BÃ¶ck and Heitzinger, 2022]
eO

1
Îµ2(1âˆ’Î³)4

SCPE (Model-free)
DPE
Our Work
eO

1
Îµ2(1âˆ’Î³)3

CTD (Model-free)
DPE
Table 1. Sample complexity of algorithms for solving policy evaluation (PE) in the â„“âˆnorm, and
distributional policy evaluation (DPE) in the supreme 1-Wasserstein metric.
policy evaluation task by taking expectation of the return distribution estimator. And the supreme
1-Wasserstein metric error of the return distribution estimator is not smaller than the â„“âˆerror of the
induced value function estimator (see the proof of Theorem B.1 in Appendix B), we have also listed
the sample complexity of the policy evaluation task in Table 1 for comparison.
Freedmanâ€™s inequality.
Freedmanâ€™s inequality was originally proposed in [Freedman, 1975]. It
can be viewed as a Bernsteinâ€™s inequality for martingales, which is crucial for analyzing stochas-
tic approximation algorithms. Tropp [2011] generalized Freedmanâ€™s inequality to matrix martin-
gales. And Talebi et al. [2022] established Freedman inequalities for martingales in the setting of
noncommutative probability spaces. The closest literature to ours is [Tarres and Yao, 2014] and
[Martinez-Taboada and Ramdas, 2024], where they provided a special case of our Theorem A.2
with H = 0 independently. When H = 0, we can only utilize the deterministic upper bound on
the quadratic variation rather than the high-probability upper bound. In certain problems, such as
the distributional TD learning we aim to investigate, it is impossible to achieve the optimal upper
bound using the H = 0 version. [Martinez-Taboada and Ramdas, 2024] also proposed an empirical
Freedmanâ€™s inequality in (2, D)-smooth Banach space, which can be used to construct conï¬dence
sets or perform hypothesis testing. To the best of our knowledge, we are the ï¬rst to present this
version (Theorem A.2) of Freedmanâ€™s inequality in Hilbert spaces5.
The remainder of this paper is organized as follows. In Section 2, we introduce some background
of DRL and state Freedmanâ€™s inequality in Hilbert spaces. In Section 3, we revisit distributional
TD and propose NTD for further theoretical analysis. In Section 4, we analyze the non-asymptotic
convergence bounds of NTD and CTD. Section 5 presents proof outlines of our theoretical results,
and Section 6 concludes our work. We put the detailed results with Freedmanâ€™s inequality in Hilbert
spaces in Appendix A, and the minimax lower bound of the distributional policy evaluation task in
Appendix B.
2
Background
An inï¬nite-horizon tabular Markov decision process (MDP) is deï¬ned by a 5-tuple M
=
âŸ¨S, A, PR, P, Î³âŸ©, where S represents a ï¬nite state space, A a ï¬nite action space, PR the distri-
bution of rewards, P the transition dynamics, i.e., PR(Â·|s, a) âˆˆâˆ†([0, 1]), P(Â·|s, a) âˆˆâˆ†(S) for any
state action pair (s, a) âˆˆS Ã— A, and Î³ âˆˆ(0, 1) a discount factor. Here we use âˆ†(Â·) to represent
the set of all probability distributions over some set. Given a policy Ï€: S â†’âˆ†(A) and an initial
state s0 = s âˆˆS, a random trajectory {(st, at, tt)âˆ
t=0} can be sampled from M: at | st âˆ¼Ï€(Â· | st),
rt | (st, at) âˆ¼PR(Â· | st, at), st+1 | (st, at) âˆ¼P(Â· | st, at) for any t âˆˆN. Given a trajectory, we
deï¬ne the return by GÏ€(s) := Pâˆ
t=0 Î³trt âˆˆ
h
0,
1
1âˆ’Î³
i
. We denote return distribution Î·Ï€(s) as the
probability distribution of GÏ€(s), and Î·Ï€ := (Î·Ï€(s))sâˆˆS. The expected return V Ï€(s) = EGÏ€(s) is
the value function in the traditional RL setting.
5In this paper, we assume that all the Hilbert spaces we encounter are separable, which can avoid measura-
bility issues, ensure that the expectation can be deï¬ned, and guarantee tightness of any distribution. See Pisier
[2016] for more details about probability in Hilbert space
3

2.1
Distributional Bellman Equation and Operator
Recall that the classic policy evaluation aims at computing the value functions V Ï€. It is known that
V Ï€ = (V Ï€(s))sâˆˆS satisfy the Bellman equation. That is, for any s âˆˆS,
V Ï€(s) = [T Ï€(V Ï€)] (s) = Eaâˆ¼Ï€(Â·|s),râˆ¼PR(Â·|s,a),sâ€²âˆ¼P (Â·|s,a) [r + Î³V Ï€(sâ€²)] .
(1)
The operator T Ï€ : RS â†’RS is called the Bellman operator, and V Ï€ is a ï¬xed point of T Ï€.
The task of distribution policy evaluation is ï¬nding Î·Ï€ given some ï¬xed policy Ï€. Î·Ï€ satisï¬es a
distributional version of the Bellman equation (1). That is, for any s âˆˆS,
Î·Ï€(s) = (T Ï€Î·Ï€) (s) = Eaâˆ¼Ï€(Â·|s),râˆ¼PR(Â·|s,a),sâ€²âˆ¼P (Â·|s,a)
h
(br,Î³)# Î·Ï€(sâ€²)
i
,
(2)
where br,Î³ : R â†’R is an afï¬ne function deï¬ned by br,Î³(x) = r + Î³x. And f#Âµ is the push forward
measure of Âµ through any function f : R â†’R, so that f#Âµ(A) = Âµ(f âˆ’1(A)) for any Borel set A,
where f âˆ’1(A) := {x: f(x) âˆˆA}. The operator T Ï€ : âˆ†
h
0,
1
1âˆ’Î³
iS
â†’âˆ†
h
0,
1
1âˆ’Î³
iS
is known
as the distributional Bellman operator, and Î·Ï€ is a ï¬xed point of T Ï€. For notational simplicity, we
denote âˆ†
h
0,
1
1âˆ’Î³
i
as P from now on.
2.2
T Ï€ as Contraction in P
A key property of the Bellman operator T Ï€ is that it is a Î³-contraction w.r.t. the supreme norm (i.e.
â„“âˆnorm). However, before we can properly discuss the contraction properties of T Ï€, we need to
specify a metric d on P. And for any metric d on P, we denote Â¯d as the corresponding supreme
metric on PS, i.e., Â¯d (Î·, Î·â€²) := maxsâˆˆS d (Î·(s), Î·â€²(s)) for any Î·, Î·â€² âˆˆPS.
Suppose
Âµ
and
Î½
are
two
probability
distributions
on
R
with
ï¬nite
p-moments
for
p
âˆˆ
[1, âˆ].
The p-Wasserstein metric between Âµ and Î½ is deï¬ned as Wp(Âµ, Î½)
:=
 infÎºâˆˆÎ“(Âµ,Î½)
R
R2 |x âˆ’y|p Îº(dx, dy)
1/p. Each element Îº âˆˆÎ“(Âµ, Î½) is a coupling of Âµ and Î½, i.e.,
a joint distribution on R2 with prescribed marginals Âµ and Î½ on each â€œaxis.â€ When p = 1 we have
W1(Âµ, Î½) =
R
R |FÂµ(x) âˆ’FÎ½(x)|dx, where FÂµ and FÎ½ are the cumulative distribution function of
Âµ and Î½, respectively. It can be shown that T Ï€ is a Î³-contraction w.r.t. the supreme p-Wasserstein
metric Â¯Wp.
Proposition 2.1. [Bellemare et al., 2023, Propositions 4.15] The distributional Bellman operator
is a Î³-contraction on PS w.r.t. the supreme p-Wasserstein metric for p âˆˆ[1, âˆ]. That is, for any
Î·, Î·â€² âˆˆPS, we have Â¯Wp (T Ï€Î·, T Ï€Î·â€²) â‰¤Î³ Â¯Wp(Î·, Î·â€²).
The â„“p metric between Âµ and Î½ is deï¬ned as â„“p(Âµ, Î½) =
 R
R |FÂµ(x) âˆ’FÎ½(x)|p dx
 1
p for p âˆˆ[1, âˆ),
and T Ï€ is Î³
1
p -contraction w.r.t. the supreme â„“p metric Â¯â„“p.
Proposition 2.2. [Bellemare et al., 2023, Propositions 4.20] The distributional Bellman operator is
a Î³
1
p -contraction on PS w.r.t. the supreme â„“p metric for p âˆˆ[1, âˆ). That is, for any Î·, Î·â€² âˆˆPS,
we have Â¯â„“p (T Ï€Î·, T Ï€Î·â€²) â‰¤Î³
1
p Â¯â„“p(Î·, Î·â€²).
Note that the â„“1 metric coincides with the 1-Wasserstein metric. And the â„“2 metric is also called the
CramÃ©r metric, which plays an important role in subsequent analysis because the zero-mass signed
measure space equipped with this metric
 M, âˆ¥Â·âˆ¥â„“2

(deï¬ned in Section 5.1) is a Hilbert space6.
Thereby, we can apply Freedmanâ€™s inequality in Hilbert spaces.
2.3
Freedmanâ€™s Inequality in Hilbert Spaces
Just as Freedmanâ€™s inequality is essential for the theory of TD (Theorem 1 in [Li et al., 2024]),
a Hilbert space version of Freedmanâ€™s inequality is indispensable for deriving the minimax non-
asymptotic convergence bound for distributional TD. At the moment, we state a Hilbert space ver-
sion of the original Freedmanâ€™s inequality (Theorem 1.6 in [Freedman, 1975]), and more detailed
results can be found in Appendix A.
6In fact, the space

M, âˆ¥Â·âˆ¥â„“2

is not complete. However, the completeness property does not affect the
non-asymptotic analysis, see Section 5.1 for more details.
4

Let X be a Hilbert space, {Xi}n
i=1 be an X-valued martingale difference sequence adapted to the
ï¬ltration {Fi}n
i=1, Yi := Pi
j=1 Xj be the corresponding martingale, and Wi := Pi
j=1 Ïƒ2
j be the
corresponding quadratic variation process. Here Ïƒ2
j := Ejâˆ’1 âˆ¥Xjâˆ¥2, and Ei [Â·] := E [Â·|Fi] denotes
the conditional expectation.
Theorem 2.1 (Freedmanâ€™s inequality in Hilbert spaces). Suppose maxiâˆˆ[n] âˆ¥Xiâˆ¥â‰¤b for some
constant b > 0. Then, for any Îµ and Ïƒ > 0, the following inequality holds
P
 âˆƒk âˆˆ[n], s.t. âˆ¥Ykâˆ¥â‰¥Îµ and Wk â‰¤Ïƒ2
â‰¤2 exp

âˆ’
Îµ2/2
Ïƒ2 + bÎµ/3

.
3
Distributional Temporal Difference Learning
If the MDP M = âŸ¨S, A, PR, P, Î³âŸ©is known, and because V Ï€ is the ï¬xed point of the contraction
T Ï€, V Ï€ can be evaluated via the famous dynamic programming (DP) algorithm. To be concrete, for
any initialization V (0) âˆˆRS, if we deï¬ne the iteration sequence V (k+1) = T Ï€(V (k)) for k âˆˆN,
we have limkâ†’âˆ
V (k) âˆ’V Ï€
âˆ= 0 by the contraction mapping theorem (Proposition 4.7 in
[Bellemare et al., 2023]).
Similarly, the distributional dynamic programming algorithm deï¬nes the iteration sequence as
Î·(k+1) = T Ï€Î·(k) for any initialization Î·(0). In the same way, we have limkâ†’âˆÂ¯Wp(Î·(k), Î·Ï€) = 0
for p âˆˆ[1, âˆ] and limkâ†’âˆÂ¯â„“p(Î·(k), Î·Ï€) = 0 for p âˆˆ[1, âˆ).
In most application scenarios, the transition dynamic P and reward distribution PR are unknown,
and instead we can only get samples of P and PR in a streaming manner. In this paper, we as-
sume a generative model [Kakade, 2003, Kearns et al., 2002] is accessible, which generates in-
dependent samples for all states in each iteration, i.e., in the t-th iteration, we collect sample
at(s) âˆ¼Ï€(Â·|s), st(s) âˆ¼P(Â·|s, at(s)), rt(s) âˆ¼PR(Â·|s, at(s)) for each s âˆˆS. Similar to TD
[Sutton, 1988] in classic RL, distributional TD also employs the stochastic approximation (SA)
[Robbins and Monro, 1951] technique to address the aforementioned problem and can be viewed as
an approximate version of distributional DP.
Non-parametric Distributional TD
We ï¬rst introduce non-parametric distributional temporal dif-
ference learning (NTD), which is helpful in the theoretical understanding of distributional TD. In the
setting of NTD, we assume the return distributions can be precisely updated without any parametriza-
tion. For any initialization Î·Ï€
0 âˆˆPS, the updating scheme is given by
Î·Ï€
t = (1 âˆ’Î±t)Î·Ï€
tâˆ’1 + Î±tT Ï€
t Î·Ï€
tâˆ’1
for any t â‰¥1. Here Î±t is the step size. The empirical Bellman operator at the t-th iteration T Ï€
t is
deï¬ned as
(T Ï€
t Î·) (s) = (brt(s),Î³)#(Î·(st+1)),
which is an unbiased estimator of (T Ï€Î·) (s). It is evident that NTD is a SA modiï¬cation of distribu-
tional DP. Consequently, we can analyze NTD using the techniques from the SA area.
Categorical Distributional TD
Now, we revisit the more practical CTD. In this case, the updates
in CTD is computationally tractable, due to the following categorical parametrization of probability
distributions:
PK :=
( K
X
k=0
pkÎ´xk : p0, . . . , pK â‰¥0 ,
K
X
k=0
pk = 1
)
,
where K âˆˆN, and 0 â‰¤x0 < Â· Â· Â· < xK â‰¤
1
1âˆ’Î³ are ï¬xed points of the support. For simplicity,
we assume {xk}K
k=0 are equally-spaced, i.e., xk =
k
K(1âˆ’Î³). We denote the gap between two points
by Î¹K =
1
K(1âˆ’Î³). When updating the return distributions, we need to evaluate the â„“2-projection
of PK, Î K : P â†’PK, Î KÂµ := argminË†ÂµâˆˆPK â„“2(Âµ, Ë†Âµ). It can be shown (Proposition 5.14 in
[Bellemare et al., 2023]) that the projection is uniquely given by
Î KÂµ =
K
X
k=0
pk(Âµ)Î´xk, where
pk(Âµ) = EXâˆ¼Âµ
"
1 âˆ’

X âˆ’xk
Î¹K


+
#
,
5

(x)+ := max {x, 0} for any x âˆˆR. It is known that Î K is non-expansive w.r.t. the CramÃ©r metric
(Lemma 5.23 in [Bellemare et al., 2023]), i.e., â„“2(Î KÂµ, Î KÎ½) â‰¤â„“2(Âµ, Î½) for any Âµ, Î½ âˆˆP. For
any Î· âˆˆPS, s âˆˆS, we slightly abuse the notation and deï¬ne (Î KÎ·) (s) := Î KÎ·(s). Î K is still
non-expansive w.r.t. Â¯â„“2. Hence T Ï€,K := Î KT Ï€ is a âˆšÎ³-contraction w.r.t. Â¯â„“2, we denote its unique
ï¬xed point as Î·Ï€,K âˆˆPS
K. The approximation error induced by categorical parametrization is given
by (Proposition 3 in Rowland et al. [2018])
Â¯â„“2(Î·Ï€, Î·Ï€,K) â‰¤
1
âˆš
K(1 âˆ’Î³)
,
Â¯W1(Î·Ï€, Î·Ï€,K) â‰¤
1
âˆš1 âˆ’Î³
Â¯â„“2(Î·Ï€, Î·Ï€,K) â‰¤
1
âˆš
K(1 âˆ’Î³)3/2 .
(3)
Now, we are ready to give the updating scheme of CTD, given any initialization Î·Ï€
0 âˆˆPS
K,
Î·Ï€
t = (1 âˆ’Î±t)Î·Ï€
tâˆ’1 + Î±tÎ KT Ï€
t Î·Ï€
tâˆ’1
for any t â‰¥1. We can ï¬nd that the only difference between CTD and NTD lies in the additional
application of the projection operator Î K at each iteration in CTD.
4
Statistical Analysis
In this section, we state our main results. For both NTD and CTD, we give the non-asymptotic
convergence rates of Â¯
Wp(Î·Ï€
T , Î·Ï€) and Â¯â„“2(Î·Ï€
T , Î·Ï€), respectively.
4.1
Non-asymptotic Analysis of NTD
We ï¬rst provide a non-asymptotic convergence rate of Â¯W1(Î·Ï€
T , Î·Ï€) for NTD, which is minimax
optimal (Theorem B.1) up to logarithmic factors.
Theorem 4.1 (Sample complexity of NTD in the 1-Wasserstein metric). Given any Î´ âˆˆ(0, 1) and
Îµ âˆˆ(0, 1), let the initialization be Î·Ï€
0 âˆˆPS, the total update number T satisfy
T â‰¥C1 log3 T
Îµ2(1 âˆ’Î³)3 log |S| T
Î´
for some large universal constant C1 > 1, i.e., T = eO

1
Îµ2(1âˆ’Î³)3

, and the step size Î±t satisfy
1
1 + c2(1âˆ’âˆšÎ³)t
log t
â‰¤Î±t â‰¤
1
1 + c3(1âˆ’âˆšÎ³)t
log t
for some small universal constants c2 > c3 > 0. Then, with probability at least 1âˆ’Î´, the last iterate
estimator satisï¬es Â¯W1 (Î·Ï€
T , Î·Ï€) â‰¤Îµ.
Because Â¯W1 (Î·Ï€
T , Î·Ï€) â‰¤
1
1âˆ’Î³ always holds, we can translate the high probability bound to a mean
error bound, that is,
E
 Â¯W1 (Î·Ï€
T , Î·Ï€)

â‰¤Îµ(1 âˆ’Î´) +
Î´
1 âˆ’Î³ â‰¤2Îµ
if we take Î´ â‰¤Îµ(1 âˆ’Î³). In the subsequent discussion, we will not state the mean error bound
conclusions for the sake of brevity.
The key idea of our proof is to ï¬rst expand the error term Â¯W1 (Î·Ï€
T , Î·Ï€) over the time steps. Then it
can be decomposed into an initial error term and a martingale term. The initial error term becomes
smaller as the iteration goes due to the contraction properties of T Ï€. To control the martingale
term, we ï¬rst use the basic inequality (Lemma E.1) W1 (Âµ, Î½) â‰¤
1
âˆš1âˆ’Î³ â„“2 (Âµ, Î½), which allows us to
analyze this error term in the Hilbert space (M, âˆ¥Â·âˆ¥â„“2) deï¬ned in Section 5.1. Consequently, we can
bound it using Freedmanâ€™s inequality in the Hilbert space (Theorem A.2). A more detailed outline
of proof can be found in Section 5.2.
Combining Theorem 4.1 with the basic inequality Â¯Wp(Î·, Î·â€²) â‰¤
1
(1âˆ’Î³)
1âˆ’1
p
Â¯W
1
p
1 (Î·, Î·â€²) for any Î·, Î·â€² âˆˆ
PS (Lemma E.1), we can derive that T = eO

1
Îµ2p(1âˆ’Î³)2p+1

iterations are sufï¬cient to ensure
6

Â¯Wp(Î·Ï€
T , Î·Ï€) â‰¤Îµ. As pointed out in the example after Corollary 3.1 in [Zhang et al., 2023], when
p > 1, the slow rate in terms of Îµ is inevitable without additional regularity conditions.
Although the 1-Wasserstein metric cannot bound the CramÃ©r metric properly, by making slight mod-
iï¬cations to the proof we have the following non-asymptotic convergence rate of Â¯â„“2(Î·Ï€
T , Î·Ï€). See
Appendix C.5 for our proof.
Corollary 4.1 (Sample complexity of NTD in the CramÃ©r metric). Given any Î´ âˆˆ(0, 1) and Îµ âˆˆ
(0, 1), let the initial value Î·Ï€
0 âˆˆPS, the total update number T satisfy
T â‰¥
C1 log3 T
Îµ2(1 âˆ’Î³)5/2 log |S| T
Î´
for some large universal constant C1 > 1, i.e., T = eO

1
Îµ2(1âˆ’Î³)5/2

, and the step size Î±t satisfy
1
1 + c2(1âˆ’âˆšÎ³)t
log t
â‰¤Î±t â‰¤
1
1 + c3(1âˆ’âˆšÎ³)t
log t
for some small universal constants c2 > c3 > 0. Then, with probability at least 1âˆ’Î´, the last iterate
estimator satisï¬es Â¯â„“2 (Î·Ï€
T , Î·Ï€) â‰¤Îµ.
4.2
Non-asymptotic Analysis of CTD
We ï¬rst state a parallel result to Theorem 4.1.
Theorem 4.2 (Sample complexity of CTD in the 1-Wasserstein metric). Given any Î´ âˆˆ(0, 1) and
Îµ âˆˆ(0, 1), suppose K >
4
1âˆ’Î³ , the initial value Î·Ï€
0 âˆˆPS
K, the total update number T satisï¬es
T â‰¥C1 log3 T
Îµ2(1 âˆ’Î³)3 log |S| T
Î´
for some large universal constant C1 > 1, i.e., T = eO

1
Îµ2(1âˆ’Î³)3

, and the step size Î±t satisï¬es
1
1 + c2(1âˆ’âˆšÎ³)t
log t
â‰¤Î±t â‰¤
1
1 + c3(1âˆ’âˆšÎ³)t
log t
for some small universal constants c2 > c3 > 0. Then, with probability at least 1 âˆ’Î´, the last
iterate estimator satisï¬es Â¯W1
 Î·Ï€
T , Î·Ï€,K
â‰¤Îµ
2. Furthermore, according to the upper bound (3) of
the approximation error Â¯W1
 Î·Ï€,K, Î·Ï€
, if we take K >
4
Îµ2(1âˆ’Î³)3 , we have Â¯W1 (Î·Ï€
T , Î·Ï€) â‰¤Îµ.
Note that the order (modulo logarithmic factors) of sample complexity of CTD is better than the
previous results of SCPE [BÃ¶ck and Heitzinger, 2022], and we do not need the additional term
introduced in the updating scheme of SCPE.
The proof of this theorem is almost the same as that of Theorem 4.1, we outline the proof in Sec-
tion 5.2. The Â¯W1 metric result can be translated into sample complexity bound eO

1
Îµ2p(1âˆ’Î³)2p+1

in
the Â¯Wp metric. We comment that this theoretical result matches the sample complexity bound in the
model-based setting [Rowland et al., 2024b].
As in the NTD setting, we have the following non-asymptotic convergence rate of Â¯â„“2(Î·Ï€
T , Î·Ï€) as a
corollary of Theorem 4.2. See Appendix C.5 for the proof.
Corollary 4.2 (Sample complexity of CTD in the CramÃ©r metric). For any given Î´ âˆˆ(0, 1) and
Îµ âˆˆ(0, 1), suppose K >
4
1âˆ’Î³ , the initialization is Î·Ï€
0 âˆˆPS
K, the total update number T satisï¬es
T â‰¥
C1 log3 T
Îµ2(1 âˆ’Î³)5/2 log |S| T
Î´
for some large universal constant C1 > 1, i.e., T = eO

1
Îµ2(1âˆ’Î³)5/2

, and the step size Î±t satisï¬es
1
1 + c2(1âˆ’âˆšÎ³)t
log t
â‰¤Î±t â‰¤
1
1 + c3(1âˆ’âˆšÎ³)t
log t
for some small universal constants c2 > c3 > 0. Then, with probability at least 1 âˆ’Î´, the last
iterate estimator satisï¬es Â¯â„“2
 Î·Ï€
T , Î·Ï€,K
â‰¤Îµ
2. Furthermore, according to the upper bound (3) of the
approximation error Â¯â„“2
 Î·Ï€,K, Î·Ï€
, if we take K >
4
Îµ2(1âˆ’Î³)2 , we have Â¯â„“2 (Î·Ï€
T , Î·Ï€) â‰¤Îµ.
7

5
Proof Outlines
In this section, we will outline the proofs of our main theoretical results (Theorem 4.1, Corollary 4.1,
Theorem 4.2, and Corollary 4.2). Before diving into the details of the proofs, we ï¬rst deï¬ne some
notation.
5.1
Zero-mass Signed Measure Space
To analyze the distance between the estimator and the ground-truth Î·Ï€, we will work with the zero-
mass signed measure space M deï¬ned as follows
M :=

Âµ: Âµ is a signed measure with |Âµ| (R) < âˆ, Âµ(R) = 0, supp(Âµ) âŠ†[0,
1
1 âˆ’Î³ ]

,
where |Âµ| is the total variation measure of Âµ, and supp(Âµ) is the support of Âµ. See [Bogachev, 2007]
for more details about signed measures.
For any Âµ âˆˆM, we deï¬ne its cumulative function as FÂµ(x) := Âµ[0, x). We can check that FÂµ is
linear w.r.t. Âµ, that is, FÎ±Âµ+Î²Î½ = Î±FÂµ + Î²FÎ½ for any Î±, Î² âˆˆR, Âµ, Î½ âˆˆM.
To analyze the CramÃ©r metric case, we deï¬ne the following CramÃ©r inner product on M:
âŸ¨Âµ, Î½âŸ©â„“2 :=
Z
1
1âˆ’Î³
0
FÂµ(x)FÎ½(x)dx.
It is easy to verify that âŸ¨Â·, Â·âŸ©â„“2 is indeed an inner product on M. The corresponding norm, called the
CramÃ©r norm, is given by âˆ¥Âµâˆ¥â„“2 =
q
âŸ¨Âµ, ÂµâŸ©â„“2 =
qR
1
1âˆ’Î³
0
(FÂµ(x))2 dx. We have Î½1 âˆ’Î½2 âˆˆM and
âˆ¥Î½1 âˆ’Î½2âˆ¥â„“2 = â„“2 (Î½1, Î½2) for any Î½1, Î½2 âˆˆP.
The W1 norm on M is deï¬ned as âˆ¥Âµâˆ¥W1 :=
R
1
1âˆ’Î³
0
|FÂµ(x)| dx. We have âˆ¥Î½1 âˆ’Î½2âˆ¥W1 = W1 (Î½1, Î½2)
for any Î½1, Î½2 âˆˆP.
We can extend the distributional Bellman operator T Ï€ and the CramÃ©r projection operator Î K nat-
urally to MS. Here, the product space MS is also a Banach space, and we use the supreme norm:
âˆ¥Î·âˆ¥Â¯â„“2 := maxsâˆˆS âˆ¥Î·(s)âˆ¥â„“2, and âˆ¥Î·âˆ¥Â¯
W1 := maxsâˆˆS âˆ¥Î·(s)âˆ¥W1 for any Î· âˆˆMS. We denote by I
the identity operator in MS.
When the norm âˆ¥Â·âˆ¥is applied to A
âˆˆ
L(X), where X is any Banach space, and L(X)
is the space of all bounded linear operators in X, we refer âˆ¥Aâˆ¥to the operator norm
of A, which is deï¬ned as âˆ¥Aâˆ¥
:=
supÎ·âˆˆX,âˆ¥Î·âˆ¥=1 âˆ¥AÎ·âˆ¥.
With this notation, L(X)
=
{A: A is a linear operator mapping from X to X, and âˆ¥Aâˆ¥< âˆ}.
Proposition 5.1. T Ï€ and Î K are linear operators in MS.
Furthermore, âˆ¥T Ï€âˆ¥Â¯â„“2
â‰¤âˆšÎ³,
âˆ¥T Ï€âˆ¥Â¯
W1 â‰¤Î³, âˆ¥Î Kâˆ¥Â¯â„“2 = 1, and âˆ¥Î Kâˆ¥Â¯
W1 â‰¤1.
The proof of the last inequality can be found in the proof of Lemma C.4, while the remaining results
are trivial. We omit the proofs for brevity.
Moreover, we have the following matrix (of operators) representations of T Ï€ and Î K: T Ï€ âˆˆ
L(M)SÃ—S for any Î· âˆˆMS,
(T Ï€Î·) (s) =
X
aâˆˆA,sâ€²âˆˆS
Ï€(a | s)P(sâ€² | s, a)
Z 1
0
(br,Î³)# Î·(sâ€²)PR(dr | s, a) =
X
sâ€²âˆˆS
T Ï€(s, sâ€²)Î·(sâ€²),
where T Ï€(s, sâ€²) âˆˆL(M) for any Î½ âˆˆM,
T Ï€(s, sâ€²)Î½ =
X
aâˆˆA
Ï€(a | s)P(sâ€² | s, a)
Z 1
0
(br,Î³)# Î½PR(dr | s, a).
It can be veriï¬ed that âˆ¥T (s, sâ€²)âˆ¥â„“2 â‰¤âˆšÎ³ P
aâˆˆA Ï€(a | s)P(sâ€² | s, a) =: âˆšÎ³P Ï€(sâ€²|s). Similarly,
âˆ¥T (s, sâ€²)âˆ¥W1 â‰¤Î³P Ï€(sâ€²|s), and Î K = diag
 Î K

M

sâˆˆS âˆˆL(M)SÃ—S. With these represen-
tations, Î KT Ï€ âˆˆL(M)SÃ—S can be interpreted as matrix multiplication, where the scalar mul-
tiplication is replaced by the composition of operators. It can be veriï¬ed that (Î KT Ï€) (s, sâ€²) =
Î KT Ï€(s, sâ€²), and âˆ¥(Î KT Ï€) (s, sâ€²)âˆ¥â„“2 â‰¤âˆšÎ³P Ï€(sâ€²|s).
8

Remark 1: In Lemma E.2, we show that both
 M, âˆ¥Â·âˆ¥â„“2

and
 M, âˆ¥Â·âˆ¥W1

are separable. And in
Lemma E.3, we show that
 M, âˆ¥Â·âˆ¥W1

is not complete. To resolve this problem, we will use their
completions to replace them without loss of generality, because the completeness property does not
affect the separability. For simplicity, we still use M to denote the completion space. According to
the BLT theorem [Theorem 5.19 Hunter and Nachtergaele, 2001], any bounded linear operator can
be extended to the completion space, and still preserves its operator norm.
5.2
Analysis of Theorems 4.1 and 4.2
For simplicity, we abbreviate both âˆ¥Â·âˆ¥Â¯â„“2 and âˆ¥Â·âˆ¥â„“2 as âˆ¥Â·âˆ¥in this part.
For all t âˆˆ[T] :=
{1, 2, Â· Â· Â· , T}, we denote Tt := T Ï€
t , T := T Ï€, Î· := Î·Ï€ for NTD; Tt := Î KT Ï€
t , T := Î KT Ï€,
Î· := Î·Ï€,K for CTD; and Î·t := Î·Ï€
t , âˆ†t := Î·t âˆ’Î· âˆˆMS for both NTD and CTD. According to
Lemma E.4, Î·t âˆˆPS for NTD and Î·t âˆˆPS
K for CTD. Our goal is to bound the Â¯W1 norm of the
error term âˆ¥âˆ†T âˆ¥Â¯
W1. This can be achieved by bounding âˆ¥âˆ†T âˆ¥, as âˆ¥âˆ†T âˆ¥Â¯
W1 â‰¤
1
âˆš1âˆ’Î³ âˆ¥âˆ†T âˆ¥.
According to the updating rule, we have the error decomposition
âˆ†t = Î·t âˆ’Î·
= (1 âˆ’Î±t)Î·tâˆ’1 + Î±tTtÎ·tâˆ’1 âˆ’Î·
= (1 âˆ’Î±t)âˆ†tâˆ’1 + Î±t (TtÎ·tâˆ’1 âˆ’T Î·)
= (1 âˆ’Î±t)âˆ†tâˆ’1 + Î±t (Tt âˆ’T ) Î·tâˆ’1 + Î±tT (Î·tâˆ’1 âˆ’Î·)
= [(1 âˆ’Î±t)I + Î±tT ] âˆ†tâˆ’1 + Î±t (Tt âˆ’T ) Î·tâˆ’1.
Applying it recursively, we can further decompose the error into two terms
âˆ†T =
T
Y
t=1
[(1 âˆ’Î±t)I + Î±tT ] âˆ†0
|
{z
}
(I)
+
T
X
t=1
Î±t
T
Y
i=t+1
[(1 âˆ’Î±i)I + Î±iT ] (Tt âˆ’T ) Î·tâˆ’1
|
{z
}
(II)
,
where Qt
k=1 Ak is deï¬ned as AtAtâˆ’1 Â· Â· Â· A1 for any operators or matrices {Ak}t
k=1 throughout
the paper. Term (I) is an initial error term that becomes negligible when T is large because T is a
contraction. Term (II) can be bounded via Freedmanâ€™s inequality in the Hilbert space (Theorem A.2).
Combining the two upper bound, we can establish a recurrence relation. Solving this relation will
lead to the conclusion.
We ï¬rst establish the conclusion for step sizes that depend on T. Speciï¬cally, we consider
T â‰¥C4 log3 T
Îµ2(1 âˆ’Î³)3 log |S| T
Î´
,
1
1 + c5(1âˆ’âˆšÎ³)T
log2 T
â‰¤Î±t â‰¤
1
1 + c6(1âˆ’âˆšÎ³)t
log2 T
,
where c5 > c6 > 0 are small constants satisfying c5c6 â‰¤
1
8, and C4 > 1 is a large constant
depending only on c5 and c6. As shown in Appendix C.1, once we have established the conclusion
in this setting, we can recover the original conclusion stated in the theorem.
Now, we introduce the following useful quantities involving step sizes and Î³
Î²(t)
k
:=
ï£±
ï£²
ï£³
Qt
i=1
 1 âˆ’Î±i(1 âˆ’âˆšÎ³)

,
if k = 0,
Î±k
Qt
i=k+1
 1 âˆ’Î±i(1 âˆ’âˆšÎ³)

,
if 0 < k < t,
Î±T ,
if k = t.
The following lemma provides useful bounds for Î²(t)
k .
Lemma 5.1. Suppose c5c6 â‰¤1
8. Then, for all t â‰¥
T
c6 log T , we have that
Î²(t)
k
â‰¤1
T 2 , for 0 â‰¤k â‰¤t
2;
Î²(t)
k
â‰¤
2 log3 T
(1 âˆ’âˆšÎ³)T , for t
2 < k â‰¤t.
9

The proof can be found in Appendix C.2. From now on, we only consider t â‰¥
T
c6 log T .
The upper bound of term (I) is given by
(I) â‰¤
tY
k=1
âˆ¥(1âˆ’Î±k)I+Î±kT âˆ¥âˆ¥âˆ†0âˆ¥â‰¤
tY
k=1
((1âˆ’Î±k)+Î±k
âˆšÎ³)
1
âˆš1âˆ’Î³ =
Î²(t)
0
âˆš1âˆ’Î³ â‰¤
1
âˆš1âˆ’Î³T 2 ,
where âˆ¥âˆ†0âˆ¥â‰¤
qR
1
1âˆ’Î³
0
dx =
1
âˆš1âˆ’Î³ .
As for term (II), we have the following upper bound with high probability by utilizing Freedmanâ€™s
inequality (Theorem A.2).
Lemma 5.2. For any Î´ âˆˆ(0, 1), with probability at least 1 âˆ’Î´, we have for all t â‰¥
T
c6 log T , in the
NTD case,

t
X
k=1
Î±k
tY
i=k+1
[(1 âˆ’Î±i)I + Î±iT ] (Tk âˆ’T ) Î·kâˆ’1

â‰¤34
v
u
u
t
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)2T

1 +
max
k: t/2<kâ‰¤t âˆ¥âˆ†kâˆ’1âˆ¥Â¯
W1

.
The conclusion still holds for the CTD case if we take K â‰¥
4
Îµ2(1âˆ’Î³)2 + 1.
The proof can be found in Appendix C.3. Combining the two results, we ï¬nd the following recur-
rence relation in terms of the Â¯W1 norm holds given the choice of T, with probability at least 1 âˆ’Î´,
for all t â‰¥
T
c6 log T
âˆ¥âˆ†tâˆ¥Â¯
W1 â‰¤
1
âˆš1 âˆ’Î³ âˆ¥âˆ†tâˆ¥â‰¤35
v
u
u
t
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3T

1 +
max
k: t/2<kâ‰¤t âˆ¥âˆ†kâˆ’1âˆ¥Â¯
W1

.
In Theorem C.1, we solve the relation and obtain the error bound of the last iterate estimator:
âˆ¥âˆ†T âˆ¥Â¯
W1 â‰¤C7
ï£«
ï£¬
ï£­
v
u
u
t
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3T
+
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3T
ï£¶
ï£·
ï£¸,
where C7 > 1 is a large universal constant depending on c6. Now, we can obtain the conclusion if
taking C4 â‰¥2C2
7 and T â‰¥C4 log3 T
Îµ2(1âˆ’Î³)3 log |S|T
Î´ .
6
Conclusions
In this paper we have studied the statistical performance of the distributional temporal difference
learning (TD) from a non-asymptotic perspective. Speciï¬cally, we have considered two instances
of distributional TD, namely, the non-parametric distributional TD (NTD) and the categorical distri-
butional TD (CTD). For both NTD and CTD, we have shown that eO

1
Îµ2p(1âˆ’Î³)2p+1

iterations are
sufï¬cient to achieve a p-Wasserstein Îµ-optimal estimator, which is minimax optimal (up to logarith-
mic factors). We have established a novel Freedmanâ€™s inequality in Hilbert spaces to prove these
theoretical results, which has independent theoretical value beyond the current work. We leave the
details to Appendix A.
Acknowledgments and Disclosure of Funding
This work has been supported by the National Key Research and Development Project of China
(No. 2022YFA1004002), the National Natural Science Foundation of China (No. 12271011 and
No. 12350001), and the MOE Project of Key Research Institute of Humanities and Social Sciences
(No.22JJD110001).
10

References
M. G. Bellemare, W. Dabney, and R. Munos. A distributional perspective on reinforcement learning.
In International conference on machine learning, pages 449â€“458. PMLR, 2017.
M. G. Bellemare, W. Dabney, and M. Rowland. Distributional Reinforcement Learning. MIT Press,
2023. http://www.distributional-rl.org.
M. BÃ¶ck and C. Heitzinger. Speedy categorical distributional reinforcement learning and complexity
analysis. SIAM Journal on Mathematics of Data Science, 4(2):675â€“693, 2022. doi: 10.1137/
20M1364436. URL https://doi.org/10.1137/20M1364436.
M. BÃ¶ck, J. Malle, D. Pasterk, H. Kukina, R. Hasani, and C. Heitzinger. Superhuman performance
on sepsis mimic-iii data by distributional reinforcement learning. PLoS One, 17(11):e0275358,
2022.
V. I. Bogachev. Measure theory, volume 1. Springer, 2007.
W. Dabney, M. Rowland, M. Bellemare, and R. Munos. Distributional reinforcement learning with
quantile regression. In Proceedings of the AAAI Conference on Artiï¬cial Intelligence, 2018.
V. H. de la Pena. A general class of exponential inequalities for martingales and ratios. The Annals
of Probability, 27(1):537â€“564, 1999.
R. Durrett. Probability: theory and examples, volume 49. Cambridge university press, 2019.
D. A. Freedman. On tail probabilities for martingales. The Annals of Probability, pages 100â€“118,
1975.
M. Gheshlaghi Azar, R. Munos, and H. J. Kappen. Minimax pac bounds on the sample complexity
of reinforcement learning with a generative model. Machine learning, 91:325â€“349, 2013.
E. Ghysels, P. Santa-Clara, and R. Valkanov. There is a risk-return trade-off after all. Journal of
ï¬nancial economics, 76(3):509â€“548, 2005.
J. K. Hunter and B. Nachtergaele. Applied analysis. World Scientiï¬c Publishing Company, 2001.
S. M. Kakade.
On the Sample Complexity of Reinforcement Learning.
PhD thesis, University
College London, 2003.
M. Kearns, Y. Mansour, and A. Y. Ng. A sparse sampling algorithm for near-optimal planning in
large markov decision processes. Machine learning, 49:193â€“208, 2002.
P. W. Lavori and R. Dawson. Dynamic treatment regimes: practical design considerations. Clinical
trials, 1(1):9â€“20, 2004.
G. Li, C. Cai, Y. Chen, Y. Wei, and Y. Chi. Is q-learning minimax optimal? a tight sample complexity
analysis. Operations Research, 72(1):222â€“236, 2024.
D. Martinez-Taboada and A. Ramdas. Empirical bernstein in smooth banach spaces. arXiv preprint
arXiv:2409.06060, 2024.
T. Morimura, M. Sugiyama, H. Kashima, H. Hachiya, and T. Tanaka. Nonparametric return dis-
tribution approximation for reinforcement learning.
In Proceedings of the 27th International
Conference on Machine Learning (ICML-10), pages 799â€“806, 2010.
A. Pananjady and M. J. Wainwright. Instance-dependent â„“âˆ-bounds for policy evaluation in tabular
reinforcement learning. IEEE Transactions on Information Theory, 67(1):566â€“585, 2020.
I. Pinelis. Optimum bounds for the distributions of martingales in banach spaces. The Annals of
Probability, pages 1679â€“1706, 1994.
G. Pisier. Martingales in Banach Spaces. Cambridge Studies in Advanced Mathematics. Cambridge
University Press, 2016. doi: 10.1017/CBO9781316480588.
11

H. Robbins and S. Monro. A stochastic approximation method. The Annals of Mathematical Statis-
tics, pages 400â€“407, 1951.
M. Rowland, M. Bellemare, W. Dabney, R. Munos, and Y. W. Teh. An analysis of categorical
distributional reinforcement learning. In International Conference on Artiï¬cial Intelligence and
Statistics, pages 29â€“37. PMLR, 2018.
M. Rowland, R. Munos, M. G. Azar, Y. Tang, G. Ostrovski, A. Harutyunyan, K. Tuyls,
M.
G.
Bellemare,
and
W.
Dabney.
An
analysis
of
quantile
temporal-difference
learning.
Journal
of
Machine
Learning
Research,
25(163):1â€“47,
2024a.
URL
http://jmlr.org/papers/v25/23-0154.html.
M. Rowland, L. K. Wenliang, R. Munos, C. Lyle, Y. Tang, and W. Dabney. Near-minimax-optimal
distributional reinforcement learning with a generative model. arXiv preprint arXiv:2402.07598,
2024b.
R. S. Sutton. Learning to predict by the methods of temporal differences. Machine learning, 3:9â€“44,
1988.
A. Talebi, G. Sadeghi, and M. Moslehian.
Freedman inequality in noncommutative probability
spaces. Complex Analysis and Operator Theory, 16(2):22, 2022.
P. Tarres and Y. Yao. Online learning as stochastic approximation of regularization paths: Optimality
and almost-sure convergence. IEEE Transactions on Information Theory, 60(9):5716â€“5735, 2014.
J. Tropp.
Freedmanâ€™s inequality for matrix martingales.
Electronic Communications
in
Probability,
16(none):262
â€“
270,
2011.
doi:
10.1214/ECP.v16-1624.
URL
https://doi.org/10.1214/ECP.v16-1624.
C. Villani et al. Optimal transport: old and new, volume 338. Springer, 2009.
R. Wu, M. Uehara, and W. Sun. Distributional ofï¬‚ine policy evaluation with predictive error guar-
antees. In A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett, editors,
Proceedings of the 40th International Conference on Machine Learning, volume 202 of Pro-
ceedings of Machine Learning Research, pages 37685â€“37712. PMLR, 23â€“29 Jul 2023. URL
https://proceedings.mlr.press/v202/wu23s.html.
L. Zhang, Y. Peng, J. Liang, W. Yang, and Z. Zhang. Estimation and inference in distributional
reinforcement learning. arXiv preprint arXiv:2309.17262, 2023.
12

A
The Key Lemma: Freedmanâ€™s Inequality in Hilbert Spaces
Freedmanâ€™s inequality, proposed in [Freedman, 1975], can be viewed as a Bernsteinâ€™s inequality
for martingales, which is crucial for analyzing stochastic approximation algorithms. Compared
to the Azuma-Hoeffding inequality which only utilizes the boundedness of martingale difference
sequences, Freedmanâ€™s inequality incorporates second-order information, namely the quadratic vari-
ation (cumulative conditional variance) of martingales. This may leads to a sharper concentration
result. It has various generalizations, such as matrix Freedmanâ€™s inequality [Tropp, 2011]. However,
to the best of our knowledge, a Freedmanâ€™s inequality in Hilbert spaces has not been established yet.
Just as Freedmanâ€™s inequality is essential for the theory of TD (Theorem 1 in [Li et al., 2024]), it is
indispensable for deriving the minimax non-asymptotic convergence bound for distributional TD.
In this section, we will present a Freedmanâ€™s inequalities in Hilbert spaces. Firstly, we will state
a Hilbert space version of the original Freedmanâ€™s inequality (Theorem 1.6 in [Freedman, 1975]).
After that, we state a generalization of a more powerful version (Theorem 6 in [Li et al., 2024])
to Hilbert spaces. We will provide self-contained proofs in Appendix A.1, primarily inspired by
Theorem 3.2 in [Pinelis, 1994]. The necessary knowledge of martingale theory for the proofs can be
found in any standard textbook, such as [Durrett, 2019].
Let X be a Hilbert space, {Xi}n
i=1 be an X-valued martingale difference sequence adapted to the
ï¬ltration {Fi}n
i=1, Yi := Pi
j=1 Xj be the corresponding martingale, Wi := Pi
j=1 Ïƒ2
j be the cor-
responding quadratic variation process. Here Ïƒ2
j := Ejâˆ’1 âˆ¥Xjâˆ¥2, and Ei [Â·] := E [Â·|Fi] is the
conditional expectation.
Theorem A.1 (Freedmanâ€™s inequality in Hilbert spaces). Suppose maxiâˆˆ[n] âˆ¥Xiâˆ¥â‰¤b for some
constant b > 0. Then, for any Îµ, Ïƒ > 0, the following inequality holds
P
 âˆƒk âˆˆ[n], s.t. âˆ¥Ykâˆ¥â‰¥Îµ and Wk â‰¤Ïƒ2
â‰¤2 exp

âˆ’
Îµ2/2
Ïƒ2 + bÎµ/3

.
(4)
Now, we are ready to state the generalization of Theorem 6 in [Li et al., 2024] to Hilbert spaces,
which is used in our non-asymptotic analysis.
Theorem A.2 (Freedmanâ€™s inequality in Hilbert spaces with bounded quadratic variation). Suppose
maxiâˆˆ[n] âˆ¥Xiâˆ¥â‰¤b and Wn â‰¤Ïƒ2 for some constants b, Ïƒ > 0 almost surely. Then, for any
Î´ âˆˆ(0, 1), and any positive integer H â‰¥1, with probability at least 1 âˆ’Î´, for all k âˆˆ[n], the
following inequality holds
âˆ¥Ykâˆ¥â‰¤
r
8 max
n
Wk, Ïƒ2
2H
o
log 2H
Î´
+ 4
3b log 2H
Î´ .
(5)
The proof can be found in Appendix A.2.
Remark 2: Theorem 2.1 can be straightforwardly extended to the case where (âˆ¥Xiâˆ¥)n
i=1 satisï¬es
the Bernstein condition (Theorem 1.2A in [de la Pena, 1999]), thereby relaxing the boundedness
assumption on âˆ¥Xiâˆ¥. Namely, Eiâˆ’1 âˆ¥Xiâˆ¥k â‰¤
1
2k!Ïƒ2
i bkâˆ’2 for some b > 0, and for all i âˆˆ[n],
k âˆˆ{2, 3, Â· Â· Â·}. In this case, Freedmanâ€™s inequality still holds, albeit with a worse constant.
P
 âˆƒk âˆˆ[n], s.t. âˆ¥Ykâˆ¥â‰¥Îµ and Wk â‰¤Ïƒ2
â‰¤2 exp

âˆ’Îµ2/2
Ïƒ2 + bÎµ

.
(6)
The proof only requires making appropriate modiï¬cations after the ï¬fth line of Equation (12). Note
that Bernstein condition holds if maxiâˆˆ[n] âˆ¥Xiâˆ¥â‰¤b.
A.1
Proof of Theorem 2.1
Proof. For any Î» > 0, t âˆˆ[0, 1] and j âˆˆ[n], let Ï†(t) = Ï†j,Î»(t) := Ejâˆ’1 cosh (Î» âˆ¥Yjâˆ’1 + tXjâˆ¥) =
Ejâˆ’1 cosh (Î»u(t)), where u(t) := âˆ¥Yjâˆ’1 + tXjâˆ¥. We aim to use the Newton-Leibniz formula to es-
tablish the relationship between Ï†(1) = Ejâˆ’1 cosh (Î» âˆ¥Yjâˆ¥) and Ï†(0) = cosh (Î» âˆ¥Yjâˆ’1âˆ¥). This will
allow us to construct a positive supermartingale (Bi)n
i=0. By utilizing the positive supermartingale
and optional stopping theorem, we can derive the desired concentration inequality.
13

Firstly, we calculate the derivative of Ï†.
uâ€²(t) = âŸ¨Yjâˆ’1 + tXj, XjâŸ©
u(t)
,
(7)
Ï†â€²(t) = Î»Ejâˆ’1 [sinh (Î»u(t)) uâ€²(t)]
= Î»Ejâˆ’1

sinh (Î»u(t)) âŸ¨Yjâˆ’1 + tXj, XjâŸ©
u(t)

,
(8)
Ï†â€²(0) = Î»Ejâˆ’1

sinh (Î»u(0)) âŸ¨Yjâˆ’1, XjâŸ©
u(0)

= Î» sinh (Î» âˆ¥Yjâˆ’1âˆ¥) âŸ¨Yjâˆ’1, Ejâˆ’1 [Xj]âŸ©
âˆ¥Yjâˆ’1âˆ¥
= 0.
(9)
By utilizing Newton-Leibniz formula, we have
Ï†(1) = Ï†(0) +
Z 1
0
Ï†â€²(s)ds
= Ï†(0) +
Z 1
0
Z s
0
Ï†â€²â€²(t)dtds
= Ï†(0) +
Z 1
0
(1 âˆ’t)Ï†â€²â€²(t)dt.
(10)
Now, we calculate the second order derivate of Ï†.
Ï†â€²â€²(t) = Î»Ejâˆ’1
 d
dt [sinh (Î»u(t)) uâ€²(t)]

= Î»Ejâˆ’1
h
Î» (uâ€²(t))2 cosh (Î»u(t)) + uâ€²â€²(t) sinh (Î»u(t))
i
â‰¤Î»2Ejâˆ’1
h
(uâ€²(t))2 + uâ€²â€²(t)u(t)

cosh (Î»u(t))
i
= Î»2
2 Ejâˆ’1
h u2â€²â€² (t) cosh (Î»u(t))
i
= Î»2Ejâˆ’1
h
âˆ¥Xjâˆ¥2 cosh (Î» âˆ¥Yjâˆ’1 + tXjâˆ¥)
i
â‰¤Î»2 cosh (Î» âˆ¥Yjâˆ’1âˆ¥) Ejâˆ’1
h
âˆ¥Xjâˆ¥2 exp (Î»t âˆ¥Xjâˆ¥)
i
,
(11)
where in the third line, we used uâ€²â€²(t) =
âˆ¥Xjâˆ¥2u(t)âˆ’âŸ¨Yjâˆ’1+tXj ,XjâŸ©
u(t)
2
u2(t)
â‰¥0 by Cauchy-Schwarz
inequality, and h(x) = x cosh(x) âˆ’sinh(x) â‰¥0 for any x â‰¥0, the inequality holds be-
cause h(0) = 0 and hâ€²(x) = x sinh(x) â‰¥0 for any x â‰¥0.
In the fourth line, we used
 u2â€²â€² (t) = 2

(uâ€²(t))2 + uâ€²â€²(t)u(t)

. In the ï¬fth line, we used
 u2â€²â€² (t) = d2
dt2 âˆ¥Yjâˆ’1 + tXjâˆ¥2 = d
dt (2 âŸ¨Yjâˆ’1 + tXj, XjâŸ©) = 2 âˆ¥Xjâˆ¥2 .
And in the last line, we used
cosh (Î» âˆ¥Yjâˆ’1 + tXjâˆ¥) â‰¤cosh (Î» âˆ¥Yjâˆ’1âˆ¥) exp (Î»t âˆ¥Xjâˆ¥) ,
this holds since
exp (Î» âˆ¥Yjâˆ’1 + tXjâˆ¥) â‰¤exp {Î» (âˆ¥Yjâˆ’1âˆ¥+ t âˆ¥Xjâˆ¥)} = exp (Î» âˆ¥Yjâˆ’1âˆ¥) exp (Î»t âˆ¥Xjâˆ¥) ,
exp (âˆ’Î» âˆ¥Yjâˆ’1 + tXjâˆ¥) â‰¤exp {âˆ’Î» (âˆ¥Yjâˆ’1âˆ¥âˆ’t âˆ¥âˆ’Xjâˆ¥)} = exp (âˆ’Î» âˆ¥Yjâˆ’1âˆ¥) exp (Î»t âˆ¥Xjâˆ¥) .
14

Hence, we can derive the following inequality for all j âˆˆ[n]
Ejâˆ’1 [cosh (Î» âˆ¥Yjâˆ¥)] = Ï†(1) = Ï†(0) +
Z 1
0
(1 âˆ’t)Ï†â€²â€²(t)dt
â‰¤cosh (Î» âˆ¥Yjâˆ’1âˆ¥) + Î»2 cosh (Î» âˆ¥Yjâˆ’1âˆ¥) Ejâˆ’1

âˆ¥Xjâˆ¥2
Z 1
0
(1 âˆ’t) exp (Î»t âˆ¥Xjâˆ¥) dt

= cosh (Î» âˆ¥Yjâˆ’1âˆ¥) + Î»2 cosh (Î» âˆ¥Yjâˆ’1âˆ¥) Ejâˆ’1
"
âˆ¥Xjâˆ¥2 exp (Î» âˆ¥Xjâˆ¥) âˆ’Î» âˆ¥Xjâˆ¥âˆ’1
Î»2 âˆ¥Xjâˆ¥2
#
=Ejâˆ’1 [exp (Î» âˆ¥Xjâˆ¥) âˆ’Î» âˆ¥Xjâˆ¥] cosh (Î» âˆ¥Yjâˆ’1âˆ¥)
=Ejâˆ’1
"
1 +
âˆ
X
k=0
1
(k + 2)! (Î» âˆ¥Xjâˆ¥)k+2
#
cosh (Î» âˆ¥Yjâˆ’1âˆ¥)
â‰¤Ejâˆ’1
"
1 + Î»2 âˆ¥Xjâˆ¥2
2
âˆ
X
k=0
Î»b
3
k#
cosh (Î» âˆ¥Yjâˆ’1âˆ¥)
=
 
1 +
Î»2Ïƒ2
j
2(1 âˆ’Î»b/3)
!
cosh (Î» âˆ¥Yjâˆ’1âˆ¥)
â‰¤exp
(
Î»2Ïƒ2
j
2(1 âˆ’Î»b/3)
)
cosh (Î» âˆ¥Yjâˆ’1âˆ¥) ,
(12)
which holds for any Î» âˆˆ(0, 3
b). In the ï¬fth line, we used Taylor expansion ex = Pâˆ
k=0
xk
k! . In the
sixth line, we used (k + 2)! â‰¥2(3k) and âˆ¥Xjâˆ¥â‰¤b. In the seventh line, we used Taylor expansion
1
1âˆ’x = Pâˆ
k=0 xk for x âˆˆ(âˆ’1, 1).
Let B0 := 1, Bi := exp
n
âˆ’
Î»2Wi
2(1âˆ’Î»b/3)
o
cosh (Î» âˆ¥Yiâˆ¥), then
Eiâˆ’1 [Bi] = exp

âˆ’
Î»2Wiâˆ’1
2(1 âˆ’Î»b/3)

exp

âˆ’
Î»2Ïƒ2
i
2(1 âˆ’Î»b/3)

Eiâˆ’1 [cosh (Î» âˆ¥Yiâˆ¥)]
â‰¤exp

âˆ’
Î»2Wiâˆ’1
2(1 âˆ’Î»b/3)

cosh (Î» âˆ¥Yiâˆ’1âˆ¥)
= Biâˆ’1,
(13)
i.e., (Bi)n
i=0 is positive supermartingale. By optional stopping theorem (Theorem 4.8.4 in [Durrett,
2019]), for any stopping time Ï„, we have E [BÏ„] â‰¤E [B0] = 1.
Let Ï„ := inf {k âˆˆ[n] : âˆ¥Ykâˆ¥â‰¥Îµ} be a stopping time, and inf âˆ…:= âˆ. Deï¬ne an event
A :=

âˆƒk âˆˆ[n], s.t. âˆ¥Ykâˆ¥â‰¥Îµ and Wk â‰¤Ïƒ2	
,
(14)
15

then on A, we have Ï„ < âˆ, âˆ¥YÏ„âˆ¥â‰¥Îµ and WÏ„ â‰¤Ïƒ2, noting that Wk is non-decreasing with k. Our
goal is to provide an upper bound for P(A).
P(A) = E
p
BÏ„
1
âˆšBÏ„
1(A)

â‰¤
s
E [BÏ„] E
 1
BÏ„
1(A)

â‰¤
v
u
u
u
tE
ï£®
ï£°
exp
n
Î»2WÏ„
2(1âˆ’Î»b/3)
o
cosh (Î» âˆ¥YÏ„âˆ¥) 1(A)
ï£¹
ï£»
â‰¤
v
u
u
u
tE
ï£®
ï£°
exp
n
Î»2Ïƒ2
2(1âˆ’Î»b/3)
o
cosh (Î»Îµ)
1(A)
ï£¹
ï£»
â‰¤
s
2 exp

âˆ’Î»Îµ +
Î»2Ïƒ2
2(1 âˆ’Î»b/3)

P(A),
(15)
where in the second line, we used Cauchy-Schwarz inequality. In the third line, we used E [BÏ„] â‰¤1.
In the fourth line, we used âˆ¥YÏ„âˆ¥â‰¥Îµ and WÏ„ â‰¤Ïƒ2 on A, and cosh(x) is increasing when x â‰¥0. In
the last line, we used cosh(x) â‰¥1
2ex.
Hence for any Î» âˆˆ(0, 3
b)
P(A) â‰¤2 exp

âˆ’Î»Îµ +
Î»2Ïƒ2
2 (1 âˆ’Î»b/3)

,
(16)
we can choose Î»â‹†=
Îµ
Ïƒ2+Îµb/3 âˆˆ(0, 3
b), then
P(A) â‰¤2 exp
(
âˆ’Î»â‹†Îµ +
(Î»â‹†)2 Ïƒ2
2 (1 âˆ’Î»â‹†b/3)
)
= 2 exp
ï£±
ï£²
ï£³âˆ’
Îµ2
Ïƒ2 + Îµb/3 +
Ïƒ2
2

1 âˆ’
Îµb/3
Ïƒ2+Îµb/3

Îµ2
(Ïƒ2 + Îµb/3)2
ï£¼
ï£½
ï£¾
= 2 exp

âˆ’
Îµ2/2
Ïƒ2 + Îµb/3

,
(17)
which is the desired conclusion.
A.2
Proof of Theorem A.2
Proof. According to Theorem 2.1, for any Îµ, ËœÏƒ > 0, we have
P
 âˆƒk âˆˆ[n], âˆ¥Ykâˆ¥â‰¥Îµ and Wk â‰¤ËœÏƒ2
â‰¤2 exp

âˆ’
Îµ2/2
ËœÏƒ2+bÎµ/3

.
(18)
We can check that when Îµ =
q
4ËœÏƒ2 log 2
Î´ + 4
3b log 2
Î´ , the upper bound on RHS is less than Î´. Hence,
P
 
âˆƒk âˆˆ[n], âˆ¥Ykâˆ¥â‰¥
r
4ËœÏƒ2 log 2
Î´ + 4
3b log 2
Î´ and Wk â‰¤ËœÏƒ2
!
â‰¤Î´.
(19)
16

For each k âˆˆ[n], deï¬ne the events
H(k)
H :=
(
âˆ¥Ykâˆ¥â‰¥
r
8 max
n
Wk, Ïƒ2
2H
o
log 2H
Î´
+ 4
3b log 2H
Î´
)
,
B(k)
H,H :=
(
âˆ¥Ykâˆ¥â‰¥
r
4 Ïƒ2
2Hâˆ’1 log 2H
Î´
+ 4
3b log 2H
Î´
and Wk â‰¤
Ïƒ2
2Hâˆ’1
)
,
B(k)
h,H :=
(
âˆ¥Ykâˆ¥â‰¥
r
4 Ïƒ2
2hâˆ’1 log 2H
Î´
+ 4
3b log 2H
Î´
and Ïƒ2
2h â‰¤Wk â‰¤
Ïƒ2
2hâˆ’1
)
,
1 â‰¤h â‰¤H âˆ’1.
(20)
By the deï¬nition, we only need to show P
S
kâˆˆ[n] H(k)
H

â‰¤Î´. Since Wk â‰¤Wn â‰¤Ïƒ2 almost
surely, we can ï¬nd that H(k)
H
âŠ†S
hâˆˆ[H] B(k)
h,H (we will justify this later). Then S
kâˆˆ[n] H(k)
H
âŠ†
S
hâˆˆ[H]
S
kâˆˆ[n] B(k)
h,H.
By the inequality (19) with ËœÏƒ2 =
Ïƒ2
2hâˆ’1 and setting Î´ as
Î´
H , we have
P
S
kâˆˆ[n] B(k)
h,H

â‰¤Î´
H for all h âˆˆ[H]. By the union bound, we can arrive at the conclusion:
P
ï£«
ï£­[
kâˆˆ[n]
H(k)
H
ï£¶
ï£¸â‰¤
H
X
h=1
P
ï£«
ï£­[
kâˆˆ[n]
B(k)
h,H
ï£¶
ï£¸â‰¤Î´.
(21)
To justify H(k)
H âŠ†S
hâˆˆ[H] B(k)
h,H, we can consider the decomposition
H(k)
H =
[
hâˆˆ[H]

H(k)
H âˆ©C(k)
h,H

,
(22)
where
C(k)
H,H :=

Wk â‰¤
Ïƒ2
2Hâˆ’1

,
C(k)
h,H :=
Ïƒ2
2h â‰¤Wk â‰¤
Ïƒ2
2hâˆ’1

,
1 â‰¤h â‰¤H âˆ’1.
(23)
The decomposition holds because Wk â‰¤Wn â‰¤Ïƒ2 almost surely. We only need to show that for
each h âˆˆ[H],
H(k)
H âˆ©C(k)
h,H âŠ†B(k)
h,H.
(24)
On the event H(k)
H âˆ©C(k)
h,H, we have
âˆ¥Ykâˆ¥â‰¥
r
8 max
n
Wk, Ïƒ2
2H
o
log 2H
Î´
+ 4
3b log 2H
Î´
â‰¥
r
4 Ïƒ2
2hâˆ’1 log 2H
Î´
+ 4
3b log 2H
Î´ ,
(25)
hence H(k)
H âˆ©C(k)
h,H âŠ†B(k)
h,H.
B
Minimax Lower Bound of Distributional Policy Evaluation
In this section, we still consider inï¬nite-horizon tabular MDP deï¬ned in Section 2, and assume a
generative model is accessible. For any positive integer D, we deï¬ne M (D) as the set of all MDPs
with state space size |S| = D. For any MDP M and policy Ï€, we denote V Ï€
M as the corresponding
value function, and Î·Ï€
M as the corresponding return distribution.
Now, we can state the minimax lower bound of the distributional policy evaluation task in the 1-
Wasserstein metric.
Theorem B.1 (Minimax lower bound of distributional policy evaluation in the 1-Wasserstein metric).
For any positive integer D â‰¥3, and sample size T â‰¥
C
1âˆ’Î³ log D
2 , the following result holds
inf
Ë†Î·
sup
MâˆˆM(D)
sup
Ï€ E
 Â¯W1 (Ë†Î·, Î·Ï€
M)

â‰¥
c
(1 âˆ’Î³)3/2
s
log D
2
T
.
17

Here, c, C > 0 are universal constants, and the inï¬mum Ë†Î· âˆˆPD ranges over all measurable
functions of T samples from the generative model.
The theorem states that for any algorithm, there exist corresponding MDP M and policy Ï€, such that
to ensure E
 Â¯W1 (Ë†Î·, Î·Ï€
M)

â‰¤Îµ for some Îµ > 0, at least Ëœâ„¦

1
Îµ2(1âˆ’Î³)3

samples are required.
Proof of Theorem B.1. For any Î· âˆˆPD, we deï¬ne V(Î·) âˆˆRD as the entry-wise expectation of Î·.
It is easy to check that V(Î·Ï€
M) = V Ï€
M. And recall the dual representation of 1-Wasserstein metric
(Corollary 5.16 in [Villani et al., 2009])
W1(Âµ, Î½) =
sup
f : f is 1-Lipschitz
|EXâˆ¼Âµ [f(X)] âˆ’EY âˆ¼Î½ [f(Y )]| ,
âˆ€Âµ, Î½ âˆˆP,
(26)
we have Â¯W1 (Ë†Î·, Î·Ï€
M) â‰¥âˆ¥V(Ë†Î·) âˆ’V Ï€
Mâˆ¥âˆ. Hence
inf
Ë†Î·
sup
MâˆˆM(D)
sup
Ï€ E
 Â¯W1 (Ë†Î·, Î·Ï€
M)

â‰¥inf
Ë†Î·
sup
MâˆˆM(D)
sup
Ï€ E [âˆ¥V(Ë†Î·) âˆ’V Ï€
Mâˆ¥âˆ]
â‰¥inf
Ë†V
sup
MâˆˆM(D)
sup
Ï€ E
h Ë†V âˆ’V Ï€
M

âˆ
i
â‰¥
c
(1 âˆ’Î³)3/2
s
log D
2
T
,
(27)
where the second inequality holds because V (Ë†Î·) âˆˆRD is also a measurable function of T sam-
ples from the generative model, and the inï¬mum Ë†V âˆˆRD ranges over all measurable functions
of T samples from the generative model.
And the last inequality is due to Theorem 2(b) in
[Pananjady and Wainwright, 2020].
C
Omitted Proofs in Section 5
C.1
Remove the Dependence on T for Step Sizes
We have shown that the conclusion holds for
T â‰¥C4 log3 T
Îµ2(1 âˆ’Î³)3 log |S| T
Î´
,
(28)
1
1 + c5(1âˆ’âˆšÎ³)T
log2 T
â‰¤Î±t â‰¤
1
1 + c6(1âˆ’âˆšÎ³)t
log2 T
,
(29)
where c5c6 â‰¤1
8, c5 > c6 > 0 and C4 > 0.
Then for some c2 > c3 > 0 to be determined, now we assume
1
1 + c2(1âˆ’âˆšÎ³)t
log2 t
â‰¤Î±t â‰¤
1
1 + c3(1âˆ’âˆšÎ³)t
log2 t
.
(30)
Next, we will show that if we consider the result of the T
2 -th iteration with this step size scheme
as the initialization of a new iteration process, then the step sizes in the subsequent T
2 iterations lie
in the previously established range. If this is done, the conclusion still holds if we choose T â‰¥
2C4 log3 T
Îµ2(1âˆ’Î³)3 log |S|T
Î´ , since the initialization Î·Ï€
T/2 âˆˆPS (or PS
K in the case of CTD) is independent
of the samples obtained for T
2 < t â‰¤T.
For any T
2 < t â‰¤T, we denote Ï„ := t âˆ’T
2 , we can see that there exist c2 > c3 > 0, such that the
last inequality in both of the following lines hold simultaneously, which is desired.
ËœÎ±Ï„ := Î±t â‰¤
1
1 + c3(1âˆ’âˆšÎ³)(Ï„+T/2)
log2(Ï„+T/2)
â‰¤
1
1 + c3(1âˆ’âˆšÎ³)Ï„
log2 T
â‰¤
1
1 + c6(1âˆ’âˆšÎ³)Ï„
log2(T/2)
,
(31)
and
ËœÎ±Ï„ = Î±t â‰¥
1
1 + c2(1âˆ’âˆšÎ³)(Ï„+T/2)
log2(Ï„+T/2)
â‰¥
1
1 + 2c2(1âˆ’âˆšÎ³)T/2
log2(T/2)
â‰¥
1
1 + c5(1âˆ’âˆšÎ³)T/2
log2(T/2)
.
(32)
18

C.2
Range of Step Size
Proof of Lemma 5.1.
(1 âˆ’âˆšÎ³)Î±t â‰¥
1 âˆ’âˆšÎ³
1 + c5(1âˆ’âˆšÎ³)T
log2 T
â‰¥
1 âˆ’âˆšÎ³
2c5(1âˆ’âˆšÎ³)T
log2 T
= log2 T
2c5T .
(33)
For any 0 â‰¤k â‰¤t
2,
Î²(t)
k
â‰¤

1 âˆ’Î±t/2(1 âˆ’âˆšÎ³)
t/2
â‰¤

1 âˆ’log2 T
2c5T
t/2
â‰¤

1 âˆ’log2 T
2c5T

T
2c6 log T
=
ï£±
ï£²
ï£³

1 âˆ’log2 T
2c5T
 2c5T
log2 T
ï£¼
ï£½
ï£¾
log T
4c5c6
â‰¤1
T 2 ,
(34)
where in the last inequality, we used c5c6 â‰¤1
8.
And for any t
2 < k â‰¤t,
Î²(t)
k
â‰¤Î±k â‰¤
1
c6(1âˆ’âˆšÎ³)k
log2 T
â‰¤
2 log3 T
(1 âˆ’âˆšÎ³)T .
(35)
C.3
Concentration of the Martingale Term
Proof of Lemma 5.2. We will show that the inequality holds for each t â‰¥
T
c6 log T and then apply the
union bound. For any s âˆˆS, we denote
Î¶k(s) := Î¶(t)
k (s) = Î±k
(
tY
i=k+1
[(1 âˆ’Î±i)I + Î±iT ] (Tk âˆ’T ) Î·kâˆ’1
)
(s),
(36)
where we omit the superscript (t) for brevity, then LHS in the lemma equals

Pt
k=1 Î¶k
 for each
t. Let Fk denote the Ïƒ-ï¬eld that contains all information up to time step k, then {Î¶k(s)}t
k=1 is a
{Fk}t
k=1-martingale difference sequence:
Ekâˆ’1 [Î¶k(s)] = Î±k
(
tY
i=k+1
[(1 âˆ’Î±i)I + Î±iT ] Ekâˆ’1 [(Tk âˆ’T ) Î·kâˆ’1]
)
(s) = 0.
(37)
the ï¬rst equality holds because a Bochner integral can be exchanged with a bounded linear operator
(see Pisier [2016] for more details about Bochner integral), and the second equality holds due to the
deï¬nition of the empirical distributional Bellman operator.
We hope to use Freedmanâ€™s inequality (Theorem A.2) to bound this martingale. To this end, we need
to give a deterministic upper bound of the martingale difference sequence, and an upper bound of
its quadratic variation.
19

Deterministic upper bound of maxkâˆˆ[t] âˆ¥Î¶k(s)âˆ¥.
The norm of the martingale difference âˆ¥Î¶k(s)âˆ¥
can be bounded as follow
âˆ¥Î¶k(s)âˆ¥â‰¤âˆ¥Î¶kâˆ¥
â‰¤Î±k

tY
i=k+1
[(1 âˆ’Î±i)I + Î±iT ]
 âˆ¥(Tk âˆ’T ) Î·kâˆ’1âˆ¥
â‰¤Î±k
tY
i=k+1
((1 âˆ’Î±i) + Î±i
âˆšÎ³)
1
âˆš1 âˆ’Î³
=
Î²(t)
k
âˆš1 âˆ’Î³ .
(38)
Hence, maxkâˆˆ[t] âˆ¥Î¶k(s)âˆ¥â‰¤
maxkâˆˆ[t] Î²(t)
k
âˆš1âˆ’Î³
â‰¤
1
âˆš1âˆ’Î³ max
n
1
T 2 ,
2 log3 T
(1âˆ’âˆšÎ³)T
o
â‰¤
4 log3 T
(1âˆ’Î³)3/2T =: b.
Upper bound of quadratic variation.
Now, letâ€™s calculate the quadratic variation.
We ï¬rst introduce some notations. For any k âˆˆN, we denote Var(Î¾) :=

E
h
âˆ¥Î¾(s)âˆ¥2i
sâˆˆS âˆˆRS,
Vark(Î¾) :=

Ek
h
âˆ¥Î¾(s)âˆ¥2i
sâˆˆS âˆˆRS for any random element Î¾ in MS.
For any Î¾ âˆˆMS, we deï¬ne its one-step update CramÃ©r variation as Ïƒ(Î¾) := Var

(bT âˆ’T )Î¾

âˆˆ
RS, where bT is a random operator and has the same distribution as T1.
For any x, y âˆˆRS, we say x â‰¤y if x(s) â‰¤y(s) for all s âˆˆS.
In this part, âˆ¥xâˆ¥:=
âˆ¥xâˆ¥âˆ= maxsâˆˆS |x(s)|, âˆšx :=
p
x(s)

sâˆˆS. And for any U âˆˆRSÃ—S, âˆ¥Uâˆ¥:= âˆ¥Uâˆ¥âˆ=
supxâˆˆRS,âˆ¥xâˆ¥=1 âˆ¥Uxâˆ¥= maxsâˆˆS
P
sâ€²âˆˆS |U(s, sâ€²)|.
For any {xk}n
k=1 âŠ‚RS, we denote maxkâˆˆ[n] xk as
 maxkâˆˆ[n] xk(s)

sâˆˆS.
We denote I âˆˆRSÃ—S as the identity matrix, 1 âˆˆRS as the all-ones vector, and P := P Ï€ âˆˆRSÃ—S,
i.e., P (s, sâ€²) := P Ï€(sâ€²|s) = P
aâˆˆA Ï€(a|s)P(sâ€²|s, a).
With these notations, the quadratic variation is Wt := Pt
k=1 Varkâˆ’1 (Î¶k). To bound the quadratic
variation Wt, we need to bound Varkâˆ’1 (Î¶k).
Lemma C.1.
Varkâˆ’1 (Î¶k) â‰¤Î±kÎ²(t)
k
tY
i=k+1
[(1 âˆ’Î±i)I + Î±i
âˆšÎ³P ] Ïƒ(Î·kâˆ’1).
20

Hence, the quadratic variation Wt can be bounded as follow
Wt =
t
X
k=1
Vartâˆ’1 (Î¶k)
â‰¤
t
X
k=1
Î±kÎ²(t)
k
tY
i=k+1
[(1 âˆ’Î±i)I + Î±i
âˆšÎ³P ] Ïƒ(Î·kâˆ’1)
â‰¤
t/2
X
k=1
Î±kÎ²(t)
k

tY
i=k+1
[(1 âˆ’Î±i)I + Î±i
âˆšÎ³P ]
 âˆ¥Ïƒ(Î·kâˆ’1)âˆ¥1 +
t
X
k=t/2+1
Î±kÎ²(t)
k
tY
i=k+1
[(1 âˆ’Î±i)I + Î±i
âˆšÎ³P ] Ïƒ(Î·kâˆ’1)
â‰¤
t/2
X
k=1

Î²(t)
k
2
1
1 âˆ’Î³ 1 +

max
k: t/2<kâ‰¤t Î²(t)
k

t
X
k=t/2+1
Î±k
tY
i=k+1
[(1 âˆ’Î±i)I + Î±i
âˆšÎ³P ] Ïƒ(Î·kâˆ’1)
â‰¤
1
2(1 âˆ’Î³)T 3 1 +
2 log3 T
(1 âˆ’âˆšÎ³)T
ï£±
ï£²
ï£³
t
X
k=t/2+1
Î±k
tY
i=k+1
[(1 âˆ’Î±i)I + Î±i
âˆšÎ³P ]
ï£¼
ï£½
ï£¾
max
k: t/2<kâ‰¤t Ïƒ(Î·kâˆ’1)
â‰¤
1
2(1 âˆ’Î³)T 3 1 + 4 log3 T
(1 âˆ’Î³)T (I âˆ’âˆšÎ³P )âˆ’1
max
k: t/2<kâ‰¤t Ïƒ(Î·kâˆ’1),
(39)
where in the fourth line, we used
Î±k

tY
i=k+1
[(1 âˆ’Î±i)I + Î±i
âˆšÎ³P ]
 â‰¤Î±k
tY
i=k+1
[(1 âˆ’Î±i) + Î±i
âˆšÎ³] = Î²(t)
k ,
and
âˆ¥Ïƒ(Î·kâˆ’1)âˆ¥â‰¤
Z
1
1âˆ’Î³
0
dx =
1
1 âˆ’Î³ .
In the last line, we used the fact that maxk: t/2â‰¤k<t Ïƒ(Î·kâˆ’1) â‰¥0 and the following lemma:
Lemma C.2. For any t âˆˆN, (Î±i)iâˆˆ[t] âˆˆ[0, 1]t, the following inequality holds entry-wise:
t
X
k=t/2+1
Î±k
tY
i=k+1
[I âˆ’Î±i (I âˆ’âˆšÎ³P )] â‰¤(I âˆ’âˆšÎ³P )âˆ’1.
(40)
According to (39), we have the following deterministic upper bound for âˆ¥Wtâˆ¥= maxsâˆˆS Wt(s),
âˆ¥Wtâˆ¥â‰¤
1
2(1 âˆ’Î³)T 3 + 4 log3 T
(1 âˆ’Î³)T
(I âˆ’âˆšÎ³P )âˆ’1
max
k: t/2<k<â‰¤t âˆ¥Ïƒ(Î·kâˆ’1)âˆ¥
â‰¤
1
2(1 âˆ’Î³)T 3 +
8 log3 T
(1 âˆ’Î³)3T
â‰¤
9 log3 T
(1 âˆ’Î³)3T
=: Ïƒ2.
(41)
Let H =

2 log2
1
1âˆ’Î³

, we have
Ïƒ2
2H â‰¤9 log3 T
(1 âˆ’Î³)T .
(42)
21

By applying Freedmanâ€™s inequality (Theorem A.2) and utilizing the union bound over s âˆˆS, we
obtain with probability at least 1 âˆ’Î´, for all t âˆˆ[T] and s âˆˆS
 
t
X
k=1
Î¶k(s)

!
sâˆˆS
â‰¤
s
8

Wt + Ïƒ2
2H 1

log
8|S|T log
1
1âˆ’Î³
Î´
+ 4
3b log
8|S|T log
1
1âˆ’Î³
Î´
1
â‰¤
s
16

Wt + 9 log3 T
(1 âˆ’Î³)T 1

log |S|T
Î´
+ 3b log |S|T
Î´
1
â‰¤8
v
u
u
t
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)T

(I âˆ’âˆšÎ³P )âˆ’1
max
k: t/2<kâ‰¤t Ïƒ(Î·kâˆ’1) + 3 Â· 1

+
12
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3/2T
1,
(43)
where we used log
8|S|T log
1
1âˆ’Î³
Î´
â‰¤2 log |S|T
Î´
in the second line, which holds due to the choice of T.
The following lemmas are required for deriving the upper bound, which hold for both cases of NTD
and CTD.
Lemma C.3. For any t âˆˆ[T],
Ïƒ(Î·t) âˆ’Ïƒ(Î·) â‰¤4 âˆ¥âˆ†tâˆ¥Â¯
W1 1.
Lemma C.4.
(I âˆ’âˆšÎ³P )âˆ’1Ïƒ(Î·) â‰¤
4
1 âˆ’Î³ 1.
Combining the upper bound with the two lemmas, we get the desired conclusion
 
t
X
k=1
Î¶k(s)

!
sâˆˆS
â‰¤8
v
u
u
t
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)T

4
max
k: t/2<kâ‰¤t âˆ¥âˆ†kâˆ’1âˆ¥Â¯
W1 (I âˆ’âˆšÎ³P )âˆ’11 +
8
1 âˆ’Î³ 1

+
12
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3/2T
1
â‰¤22
v
u
u
t
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)2T

1 +
max
k: t/2<kâ‰¤t âˆ¥âˆ†kâˆ’1âˆ¥Â¯
W1

1 +
12
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3/2T
1
â‰¤34
v
u
u
t
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)2T

1 +
max
k: t/2<kâ‰¤t âˆ¥âˆ†kâˆ’1âˆ¥Â¯
W1

1,
(44)
where in the last line, we used that, excluding the constant term, the ï¬rst term is larger than the
second term, given the choice of T â‰¥C4 log3 T
Îµ2(1âˆ’Î³)3 log |S|T
Î´ .
C.4
Solve the Recurrence Relation
Theorem C.1. Suppose for all t â‰¥
T
c6 log T ,
âˆ¥âˆ†tâˆ¥Â¯
W1 â‰¤35
v
u
u
t
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3T

1 +
max
k: t/2<kâ‰¤t âˆ¥âˆ†kâˆ’1âˆ¥Â¯
W1

.
Then there exists some large universal constant C7 > 0, such that
âˆ¥âˆ†T âˆ¥Â¯
W1 â‰¤C7
ï£«
ï£¬
ï£­
v
u
u
t
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3T
+
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3T
ï£¶
ï£·
ï£¸.
22

Proof. For any k â‰¥0, we denote
uk := max

âˆ¥âˆ†tâˆ¥Â¯
W1
 2k
T
c6 log T â‰¤t â‰¤T

,
(45)
for 0 â‰¤k â‰¤log2 (c6 log T). We can see that âˆ¥âˆ†T âˆ¥Â¯
W1 â‰¤uk for any valid k. Hence, it sufï¬ces to
show the upper bound holds for uk for any valid k. It can be veriï¬ed that u0 â‰¤
1
1âˆ’Î³ , and for k â‰¥0
uk+1 â‰¤35
v
u
u
t
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3T
(1 + uk).
(46)
We ï¬rst show that once uk â‰¤1, the subsequent values of uk+l will also remain upper bounded by 1.
Namely, if uk â‰¤1 for some k â‰¥1, then
uk+1 â‰¤35
v
u
u
t2
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3T
â‰¤1,
(47)
if T â‰¥2450 log3 T log |S|T
Î´
(1âˆ’Î³)3
.
Let Ï„ := inf {k : uk â‰¤1}, then for any k > Ï„, we have
uk â‰¤35
v
u
u
t2
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3T
=: a.
(48)
For k â‰¤Ï„, we have uk â‰¥1 and thereby
uk+1 â‰¤35
v
u
u
t2
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3T
uk = aâˆšuk,
(49)
i.e.,
log uk+1 âˆ’2 log a â‰¤1
2 (log uk âˆ’2 log a) .
(50)
Apply it recursively, we have
log uk+1 â‰¤2 log a +
1
2
k+1
(log u0 âˆ’2 log a) ,
(51)
i.e.,
uk+1 â‰¤a2 u0
a2
1/2k
= a2(1âˆ’1/2k)u1/2k
0
â‰¤a2(1âˆ’1/2k)
1
(1 âˆ’Î³)1/2k .
(52)
To sum up, for any k â‰¥0, uk+1 is always less than the sum of the upper bounds in cases of k > Ï„
and k â‰¤Ï„,
uk+1 â‰¤a + a2(1âˆ’1/2k)
1
(1 âˆ’Î³)1/2k
(53)
Note that, a2(1âˆ’1/2k) â‰¤max {a, âˆša}, and if we take k â‰¥c8 log log
1
1âˆ’Î³ for any constant c8, we
have
1
(1âˆ’Î³)1/2k = O(1). We can take the constant c8 small enough such that c8 log log
1
1âˆ’Î³ <
log2 (c6 log T) (this can be done and c8 is universal since
1
1âˆ’Î³ = o(T)), and thereby we can ï¬nd a
valid kâ‹†â‰¥c8 log log
1
1âˆ’Î³ + 1. Then
âˆ¥âˆ†T âˆ¥Â¯
W1 â‰¤ukâ‹†â‰¤C7
ï£«
ï£¬
ï£­
v
u
u
t
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3T
+
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)3T
ï£¶
ï£·
ï£¸,
(54)
which is the desired conclusion, and C7 is some large universal constant related to c8.
23

C.5
Analysis of Corollaries 4.1 and 4.2
The difference in the proof compared to Section 5.2 arises in Lemma 5.2 when we control term (II).
Now we further bound the result in Lemma C.3 by the CramÃ©r norm of the error term,
Ïƒ(Î·t) âˆ’Ïƒ(Î·) â‰¤4 âˆ¥âˆ†tâˆ¥Â¯
W1 1 â‰¤
1
âˆš1 âˆ’Î³ âˆ¥âˆ†tâˆ¥1.
(55)
In the same way, we can derive the following recurrence relation: with probability at least 1 âˆ’Î´, for
all t â‰¥
T
c6 log T
âˆ¥âˆ†tâˆ¥â‰¤35
v
u
u
t
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)5/2T

1 +
max
k: t/2<kâ‰¤t âˆ¥âˆ†kâˆ’1âˆ¥

.
(56)
By repeating the reasoning of Theorem C.1, we can obtain the desired conclusion,
âˆ¥âˆ†T âˆ¥â‰¤C7
ï£«
ï£¬
ï£­
v
u
u
t
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)5/2T
+
 log3 T
 
log |S|T
Î´

(1 âˆ’Î³)5/2T
ï£¶
ï£·
ï£¸,
(57)
which is less than Îµ if we take C4 â‰¥2C2
7 and T â‰¥
C4 log3 T
Îµ2(1âˆ’Î³)5/2 log |S|T
Î´ . Here, C7 > 1 is a large
universal constant depending on c6.
C.6
Proof of Lemma C.1
Proof. We ï¬rst introduce some notations. For any matrix of operators U âˆˆL (M)SÃ—S, we denote
U(s) = (U(s, sâ€²))sâ€²âˆˆS âˆˆL (M)S as the s-row of U. And for any Î¾ âˆˆMS, we deï¬ne the vector
inner product operation U(s)Î¾ := P
sâ€²âˆˆS U(s, sâ€²)Î¾(sâ€²) âˆˆM.
We need the following lemma, which holds for both cases of NTD and CTD.
Lemma C.5. For any Î½ âˆˆM, n âˆˆN, (Î±i)iâˆˆ[n] âˆˆ[0, 1]n, let Un = Qn
i=1 [(1 âˆ’Î±i)I + Î±iT ],
Un = Qn
i=1

(1 âˆ’Î±i)I + Î±iâˆšÎ³P

, un = Qn
i=1

(1 âˆ’Î±i) + Î±iâˆšÎ³

then for any s, sâ€² âˆˆS, we
have
âˆ¥Un(s, sâ€²)Î½âˆ¥2 â‰¤unUn(s, sâ€²) âˆ¥Î½âˆ¥2 .
Utilizing this lemma, we get the following result. Recall that bT is a random operator and has the
same distribution as T1. Then, for any non-random Î¾ âˆˆMS,
E
Un(s)(bT âˆ’T )Î¾

2
=E
ï£®
ï£°

X
sâ€²âˆˆS
Un(s, sâ€²)
h
(bT âˆ’T )Î¾
i
(sâ€²)

2ï£¹
ï£»
=E
ï£®
ï£°

X
sâ€²âˆˆS
Un(s, sâ€²)
h
bT (sâ€²)Î¾ âˆ’T (sâ€²)Î¾
i
2ï£¹
ï£»
=
X
sâ€²âˆˆS
E
Un(s, sâ€²)
h
bT (sâ€²)Î¾ âˆ’T (sâ€²)Î¾
i
2
â‰¤un
X
sâ€²âˆˆS
Un(s, sâ€²)E
 bT (sâ€²)Î¾ âˆ’T (sâ€²)Î¾

2
=un
X
sâ€²âˆˆS
Un(s, sâ€²)Ïƒ(Î¾)(sâ€²)
=unUn(s)Ïƒ(Î¾),
(58)
24

where we used different rows of bT are independent, and bT (sâ€²)Î¾ is an unbiased estimator of T (sâ€²)Î¾ âˆˆ
M. Hence, Var

Un(bT âˆ’T )Î¾

â‰¤unUnÏƒ(Î¾).
Now, we are ready to bound Varkâˆ’1 (Î¶k)
Varkâˆ’1 (Î¶k) = Î±2
kVarkâˆ’1
 
tY
i=k+1
[(1 âˆ’Î±i)I + Î±iT ] (Tk âˆ’T ) Î·kâˆ’1
!
â‰¤Î±2
k
tY
i=k+1
[(1 âˆ’Î±i) + Î±i
âˆšÎ³]
tY
i=k+1
[(1 âˆ’Î±i)I + Î±i
âˆšÎ³P ] Ïƒ(Î·kâˆ’1)
= Î±kÎ²(t)
k
tY
i=k+1
[(1 âˆ’Î±i)I + Î±i
âˆšÎ³P ] Ïƒ(Î·kâˆ’1).
(59)
C.7
Proof of Lemma C.2
Proof.
t
X
k=t/2+1
Î±k
tY
i=k+1
[(1 âˆ’Î±i)I + Î±i
âˆšÎ³P ]
=
t
X
k=t/2+1
tY
i=k+1
[(1 âˆ’Î±i)I + Î±i
âˆšÎ³P ] Î±k(I âˆ’âˆšÎ³P )(I âˆ’âˆšÎ³P )âˆ’1
=
t
X
k=t/2+1
(
tY
i=k+1
[(1 âˆ’Î±i)I + Î±i
âˆšÎ³P ] âˆ’
tY
i=k
[(1 âˆ’Î±i)I + Î±i
âˆšÎ³P ]
)
(I âˆ’âˆšÎ³P )âˆ’1
=
ï£±
ï£²
ï£³I âˆ’
tY
i=t/2+1
[(1 âˆ’Î±i)I + Î±i
âˆšÎ³P ]
ï£¼
ï£½
ï£¾(I âˆ’âˆšÎ³P )âˆ’1
â‰¤(I âˆ’âˆšÎ³P )âˆ’1,
(60)
where the inequality holds entry-wise since we can verify that all entries of (I âˆ’âˆšÎ³P )âˆ’1 =
Pâˆ
k=0
 âˆšÎ³P
k and (1 âˆ’Î±i)I + Î±iâˆšÎ³P are non-negative.
C.8
Proof of Lemma C.3
Proof. For any s âˆˆS,
Ïƒ(Î·t)(s) âˆ’Ïƒ(Î·)(s)
=
Z
1
1âˆ’Î³
0

E

F 2
( b
T Î·t)(s)(x)

âˆ’F 2
(T Î·t)(s)(x) âˆ’E

F 2
( b
T Î·)(s)(x)

+ F 2
(T Î·)(s)(x)

dx
=
Z
1
1âˆ’Î³
0

E

F 2
( b
T Î·t)(s)(x) âˆ’F 2
( b
T Î·)(s)(x)

+ F 2
(T Î·)(s)(x) âˆ’F 2
(T Î·t)(s)(x)

dx
=
Z
1
1âˆ’Î³
0
n
E
h
F( b
T Î·t)(s)(x) âˆ’F( b
T Î·)(s)(x)
 
F( b
T Î·t)(s)(x) + F( b
T Î·)(s)(x)
i
+
 F(T Î·)(s)(x) âˆ’F(T Î·t)(s)(x)
  F(T Î·)(s)(x) + F(T Î·t)(s)(x)
 o
dx
â‰¤2
Z
1
1âˆ’Î³
0
n
E
hF( b
T Î·t)(s)(x) âˆ’F( b
T Î·)(s)(x)

i
+
F(T Î·)(s)(x) âˆ’F(T Î·t)(s)(x)

o
dx
=2

E
bT (Î·t âˆ’Î·) (s)

W1

+ âˆ¥T (Î·t âˆ’Î·) (s)âˆ¥W1

.
(61)
25

In the case of NTD, T and bT are Î³-contraction w.r.t. the supreme 1-Wasserstein metric, hence
Ïƒ(Î·t)(s) âˆ’Ïƒ(Î·)(s) â‰¤2

E
bT (Î·t âˆ’Î·) (s)

W1

+ âˆ¥T (Î·t âˆ’Î·) (s)âˆ¥W1

â‰¤4Î³ âˆ¥Î·t âˆ’Î·âˆ¥Â¯
W1
â‰¤4 âˆ¥âˆ†tâˆ¥Â¯
W1 .
(62)
In the case of CTD, if we can show Î K is non-expansive w.r.t. 1-Wasserstein metric, the conclusion
still holds. For any x, y âˆˆ
h
0,
1
1âˆ’Î³
i
such that x < y, we denote x âˆˆ[xk, xk+1) and y âˆˆ[xl, xl+1),
then k â‰¤l, by the deï¬nition of Î K, we have
Î K(Î´x) = xk+1 âˆ’y
Î¹K
Î´xk + y âˆ’xk
Î¹K
Î´xk+1,
(63)
Î K(Î´y) = xl+1 âˆ’y
Î¹K
Î´xl + y âˆ’xl
Î¹K
Î´xl+1.
(64)
If k = l, we can check that W1 (Î KÎ´x, Î KÎ´y) = Î¹K
yâˆ’x
Î¹K
= y âˆ’x.
If k < l, we have
W1 (Î KÎ´x, Î KÎ´y) â‰¤W1 (Î KÎ´x, xk+1) + W1 (xk+1, xl) + W1 (xl, Î KÎ´y) = (xk+1 âˆ’x) + (xl âˆ’
xk+1) + (y âˆ’xxl) = y âˆ’x. Hence, for any Î½1, Î½2 âˆˆP and for any transport plan Îº âˆˆÎ“(Î½1, Î½2),
the previous results tell us the cost of the transport plan Î KÎº âˆˆÎ“ (Î KÎ½1, Î KÎ½2) induced by Î K
is no greater than the cost of Îº. Consequently, W1 (Î KÎ½1, Î KÎ½2) â‰¤W1(Î½1, Î½2), i.e., Î K is non-
expansive w.r.t. 1-Wasserstein metric, which is desired.
C.9
Proof of Lemma C.4
Proof. Firstly, we show that for any v â‰¥0, we have
(I âˆ’âˆšÎ³P )âˆ’1v
 â‰¤2
(I âˆ’Î³P )âˆ’1v

(I âˆ’âˆšÎ³P )âˆ’1v
 =
(I âˆ’âˆšÎ³P )âˆ’1(I âˆ’Î³P )(I âˆ’Î³P )âˆ’1v

=
(I âˆ’âˆšÎ³P )âˆ’1 [(1 âˆ’âˆšÎ³)I + âˆšÎ³(I âˆ’âˆšÎ³P )] (I âˆ’Î³P )âˆ’1v

=

(1 âˆ’âˆšÎ³)(I âˆ’âˆšÎ³P )âˆ’1 + âˆšÎ³I

(I âˆ’Î³P )âˆ’1v

â‰¤(1 âˆ’âˆšÎ³)
(I âˆ’âˆšÎ³P )âˆ’1(I âˆ’Î³P )âˆ’1v
 + âˆšÎ³
(I âˆ’Î³P )âˆ’1v

â‰¤
1 âˆ’âˆšÎ³
1 âˆ’âˆšÎ³ + âˆšÎ³
 (I âˆ’Î³P )âˆ’1v

â‰¤2
(I âˆ’Î³P )âˆ’1v
 .
(65)
In the case of NTD, by Corollary D.1, we have
(I âˆ’Î³P )âˆ’1Ïƒ (Î·)
 â‰¤
1
1 âˆ’Î³ ,
(66)
In the case of CTD, by Corollary 5.12 in [Rowland et al., 2024b], we have
(I âˆ’Î³P )âˆ’1Ïƒ (Î·)
 â‰¤
2
1 âˆ’Î³ ,
(67)
given K >
4
1âˆ’Î³ .
C.10
Proof of Lemma C.5
Proof. We proof this result by induction. For n = 0, we have U0 = I, U0 = I, u0 = 1, thereby the
inequality holds trivially. Suppose the inequality holds true for n âˆ’1. To prove that the inequality
holds for n, it is sufï¬cient to show that, for any Âµ âˆˆM,
âˆ¥[(1 âˆ’Î±n)Î´s,sâ€² + Î±nT (s, sâ€²)] Âµâˆ¥2 â‰¤[(1 âˆ’Î±n) + Î±n
âˆšÎ³] [(1 âˆ’Î±n)Î´s,sâ€² + Î±n
âˆšÎ³P (s, sâ€²)] âˆ¥Âµâˆ¥2 ,
where Î´s,sâ€² = 1 if s = sâ€², and 0 otherwise.
26

LHS can be bounded as follow
âˆ¥[(1 âˆ’Î±n)Î´s,sâ€² + Î±nT (s, sâ€²)] Âµâˆ¥2
=(1 âˆ’Î±n)2Î´s,sâ€² âˆ¥Âµâˆ¥2 + 2(1 âˆ’Î±n)Î±nÎ´s,sâ€² âŸ¨Âµ, T (s, sâ€²)ÂµâŸ©+ Î±2
n âˆ¥T (s, sâ€²)Âµâˆ¥2
â‰¤(1 âˆ’Î±n)2Î´s,sâ€² âˆ¥Âµâˆ¥2 + 2(1 âˆ’Î±n)Î±nÎ´s,sâ€² âˆ¥Âµâˆ¥âˆ¥T (s, sâ€²)Âµâˆ¥+ Î±2
n âˆ¥T (s, sâ€²)Âµâˆ¥2 ,
(68)
where we used Cauchy-Schwarz inequality. We need to give an upper bound for âˆ¥T (s, sâ€²)Âµâˆ¥2.
Note that (Î KT Ï€) (s, sâ€²) = Î K (T Ï€(s, sâ€²)) and âˆ¥Î Kâˆ¥= 1, we only need to consider the case of
NTD, by the deï¬nition of T (s, sâ€²), we have
âˆ¥T (s, sâ€²)Âµâˆ¥2 =
Z
1
1âˆ’Î³
0
"X
aâˆˆA
Ï€(a|s)P(sâ€²|s, a)
Z 1
0
FÂµ
x âˆ’r
Î³

PR(dr|s, a)
#2
dx
= P (s, sâ€²)2
Z
1
1âˆ’Î³
0
"X
aâˆˆA
Ï€(a|s)P(sâ€²|s, a)
P (s, sâ€²)
Z 1
0
FÂµ
x âˆ’r
Î³

PR(dr|s, a)
#2
dx
= P (s, sâ€²)2
Z
1
1âˆ’Î³
0

Eaâˆ¼Ï€(Â·|s),râˆ¼PR(Â·|s,a)

FÂµ
x âˆ’r
Î³
 sâ€²
2
dx
â‰¤P (s, sâ€²)2Eaâˆ¼Ï€(Â·|s),râˆ¼PR(Â·|s,a)
(Z
1
1âˆ’Î³
0

FÂµ
x âˆ’r
Î³
2
dx
sâ€²
)
= Î³P (s, sâ€²)2 âˆ¥Âµâˆ¥2 ,
(69)
where we used Jensenâ€™s inequality and Fubiniâ€™s theorem. Substitute it back to the upper bound,
âˆ¥[(1 âˆ’Î±n)Î´s,sâ€² + Î±nT (s, sâ€²)] Âµâˆ¥2
â‰¤(1 âˆ’Î±n)2Î´s,sâ€² âˆ¥Âµâˆ¥2 + 2(1 âˆ’Î±n)Î±nÎ´s,sâ€² âˆ¥Âµâˆ¥âˆ¥T (s, sâ€²)Âµâˆ¥+ Î±2
n âˆ¥T (s, sâ€²)Âµâˆ¥2
â‰¤

(1 âˆ’Î±n)2Î´s,sâ€² + 2(1 âˆ’Î±n)Î±nÎ´s,sâ€²âˆšÎ³P (s, sâ€²) + Î±2
nÎ³P (s, sâ€²)2
âˆ¥Âµâˆ¥2
=

(1 âˆ’Î±n)2Î´s,sâ€² + Î±n
âˆšÎ³P (s, sâ€²)
2 âˆ¥Âµâˆ¥2
â‰¤[(1 âˆ’Î±n) + Î±n
âˆšÎ³] [(1 âˆ’Î±n)Î´s,sâ€² + Î±n
âˆšÎ³P (s, sâ€²)] âˆ¥Âµâˆ¥2 ,
(70)
which is desired.
D
Stochastic Distributional Bellman Equation and Operator
In this section, we use the same notations as in Appendix C and only consider the NTD setting.
Inspired by stochastic categorical CDF Bellman operator introduced in [Rowland et al., 2024b], we
introduce stochastic distributional Bellman operator T : âˆ†
 PS
â†’âˆ†
 PS
to derive an upper
bound for
(I âˆ’Î³P )âˆ’1Ïƒ(Î·)
 in the case of NTD. For any Ï† âˆˆâˆ†
 PS
, we denote Î·Ï† be the
random element in PS with law Ï†.
T Ï† := Law

bT Î·Ï†

,
(71)
where (bT Î·Ï†)(Ï‰) := (bT )(Ï‰)(Î·Ï†)(Ï‰) âˆˆPS for any Ï‰ âˆˆâ„¦, â„¦is the corresponding probability
space, and bT is independent of Î·Ï†. In this part, bT does not consist of Î K since we only consider
the NTD setting.
We consider the 1-Wasserstein metric W1 on âˆ†
 PS
, the space of all probability measures on the
space
 PS, Â¯â„“2

. Since
 PS, Â¯â„“2

is Polish (complete and separable), the space
 âˆ†
 PS
, W1

is
also Polish (Theorem 6.18 in [Villani et al., 2009]).
Proposition D.1. The stochastic distributional Bellman operator T
is a âˆšÎ³-contraction on
âˆ†
 PS
, i.e., for any Ï†, Ï†â€² âˆˆâˆ†
 PS
, we have
W1 (T Ï†, T Ï†â€²) â‰¤âˆšÎ³W1 (Ï†, Ï†â€²) .
27

Proof. Let Îºâ‹†âˆˆÎ“ (Ï†, Ï†â€²) be the optimal coupling between Ï† and Ï†â€². The existence of Îºâ‹†is
guaranteed by Theorem 4.1 in [Villani et al., 2009]. And let the random element Î¾ = (Î¾1, Î¾2) in
 PS2 has the law Îºâ‹†, where Î¾1 and Î¾2 are both random elements in PS. We denote T Îºâ‹†:=
Law
h
bT Î¾1, bT Î¾2
i
âˆˆÎ“ (T Ï†, T Ï†â€²).
W1 (T Ï†, T Ï†â€²) =
inf
ÎºâˆˆÎ“(T Ï†,T Ï†â€²)
Z
(PS)2
Â¯â„“2 (Î¾, Î¾â€²) Îº (dÎ¾, dÎ¾â€²)
â‰¤
Z
(PS)2
Â¯â„“2 (Î¾, Î¾â€²) T Îºâ‹†(dÎ¾, dÎ¾â€²)
= E
h
Â¯â„“2

bT Î¾1, bT Î¾2
i
â‰¤âˆšÎ³E
Â¯â„“2 (Î¾1, Î¾2)

= âˆšÎ³
Z
(PS)2
Â¯â„“2 (Î¾, Î¾â€²) Îºâ‹†(dÎ¾, dÎ¾â€²)
= âˆšÎ³
inf
ÎºâˆˆÎ“(Ï†,Ï†â€²)
Z
(PS)2
Â¯â„“2 (Î¾, Î¾â€²) Îº (dÎ¾, dÎ¾â€²)
= âˆšÎ³W1 (Ï†, Ï†â€²) .
(72)
By the proposition and contraction mapping theorem, there exists a unique ï¬xed point of T , we
denote Ïˆ âˆˆâˆ†
 PS
as the ï¬xed point. Hence, the stochastic distributional Bellman equation reads
Ïˆ = T Ïˆ.
(73)
We denote Î·Ïˆ as the random element in P with law Ïˆ, then bT Î·Ïˆ and Î·Ïˆ have the same law. As
shown in the following proposition, Î·Ïˆ can be regarded as a noisy version of Î·.
Proposition D.2.
E [Î·Ïˆ] = Î·,
where the expectation is regarded as the Bochner integral in the space of all ï¬nite measures on PS,
which is a normed linear space equipped with CramÃ©r metric as its norm.
Proof.
E [Î·Ïˆ] = E
h
bT Î·Ïˆ
i
= E
n
E
h
bT Î·Ïˆ
Î·Ïˆ
io
= E [T Î·Ïˆ]
= T E [Î·Ïˆ] ,
(74)
where we used bT is independent of Î·Ïˆ. Since E [Î·Ïˆ] is the ï¬xed point of T , we have E [Î·Ïˆ] =
Î·.
Based on the concepts of T and Ïˆ, we can obtain the following second order distributional
Bellman equation, which is similar to the classic second-order Bellman equation (Lemma 7 in
[Gheshlaghi Azar et al., 2013]).
Recall the one-step CramÃ©r variation Ïƒ(Î·) =

E


bT Î·

(s) âˆ’Î·(s)

2
sâˆˆS
âˆˆRS used in the
NTD setting. We denote Ïƒ := Ïƒ(Î·) for simplicity, and Î£ :=

E
h
âˆ¥Î·Ïˆ(s) âˆ’Î·(s)âˆ¥2i
sâˆˆS âˆˆRS.
Proposition D.3 (Second order distributional Bellman equation).
Î£ = Ïƒ + Î³P Î£.
28

Proof. For any s âˆˆS,
Î£(s) = E
h
âˆ¥Î·Ïˆ(s) âˆ’Î·(s)âˆ¥2i
= E


bT Î·Ïˆ

(s) âˆ’Î·(s)

2
= E


bT Î·Ïˆ

(s) âˆ’

bT Î·

(s) +

bT Î·

(s) âˆ’Î·(s)

2
= E


bT Î·

(s) âˆ’Î·(s)

2
+ E


bT Î·Ïˆ

(s) âˆ’

bT Î·

(s)

2
,
(75)
where the last equality holds since the cross term is zero as below
E
hD
bT Î·

(s) âˆ’Î·(s),

bT Î·Ïˆ

(s) âˆ’

bT Î·

(s)
Ei
=E
n
E
hD
bT Î·

(s) âˆ’Î·(s),

bT Î·Ïˆ

(s) âˆ’

bT Î·

(s)
E bT
io
=E
nD
bT Î·

(s) âˆ’Î·(s), E
h
bT Î·Ïˆ

(s)
 bT
i
âˆ’

bT Î·

(s)
Eo
=E
hD
bT Î·

(s) âˆ’Î·(s), 0
Ei
=0.
(76)
The ï¬rst term in (75) is Ïƒ(s), we need to deal with the second term.
E


bT Î·Ïˆ

(s) âˆ’

bT Î·

(s)

2
=E

E


bT Î·Ïˆ

(s) âˆ’

bT Î·

(s)

2 Î·Ïˆ

=E
(
Ea(s)âˆ¼Ï€(Â·|s),sâ€²(s)âˆ¼P (Â·|s,a(s)),r(s)âˆ¼PR(Â·|s,a(s))
"Z
1
1âˆ’Î³
0

F(Î·Ïˆ)(sâ€²(s))
x âˆ’r
Î³

âˆ’FÎ·(sâ€²(s))
x âˆ’r
Î³
2
dx
Î·Ïˆ
#)
=Î³
X
sâ€²âˆˆS
E
h
âˆ¥Î·Ïˆ(sâ€²) âˆ’Î·(sâ€²)âˆ¥2i X
aâˆˆA
Ï€(a|s)P(sâ€²|s, a)
=Î³
X
sâ€²âˆˆS
P (s, sâ€²)Î£(sâ€²).
(77)
Put these together, and we can arrive at the conclusion.
Now, we can derive a tighter upper bound for
(I âˆ’Î³P )âˆ’1Ïƒ(Î·)
.
Corollary D.1.
(I âˆ’Î³P )âˆ’1Ïƒ(Î·)
 â‰¤
(I âˆ’Î³P )âˆ’1Ïƒ
 = âˆ¥Î£âˆ¥â‰¤
1
1 âˆ’Î³ .
Proof. Note that all entries of (Iâˆ’Î³P )âˆ’1 = Pâˆ
k=0 (Î³P )k are positive, thereby (Iâˆ’Î³P )âˆ’1Ïƒ(Î·) â‰¤
(I âˆ’Î³P )âˆ’1Ïƒ = Î£, and Î£(s) = E
h
âˆ¥Î·Ïˆ(s) âˆ’Î·(s)âˆ¥2i
â‰¤
R
1
1âˆ’Î³
0
dx =
1
1âˆ’Î³ for any s âˆˆS.
E
Other Technical Lemmas
Lemma E.1 (Basic Inequalities for Metrics on the Space of Probability Measures). For any
Î½1, Î½2
âˆˆP, we have (â„“2(Î½1, Î½2))2
â‰¤W1(Î½1, Î½2) â‰¤
1
âˆš1âˆ’Î³ â„“2(Î½1, Î½2) and Wp(Î½1, Î½2) â‰¤
1
(1âˆ’Î³)
1âˆ’1
p W
1
p
1 (Î½1, Î½2).
29

Proof. By Cauchy-Schwarz inequality,
W1(Î½1, Î½2)
=
Z
1
1âˆ’Î³
0
|FÎ½1(x) âˆ’FÎ½2(x)|dx
â‰¤
sZ
1
1âˆ’Î³
0
12dx
sZ
1
1âˆ’Î³
0
|FÎ½1(x) âˆ’FÎ½2(x)|2dx
=
1
âˆš1 âˆ’Î³ â„“2(Î½1, Î½2).
And
â„“2(Î½1, Î½2)
=
sZ
1
1âˆ’Î³
0
|FÎ½1(x) âˆ’FÎ½2(x)|2dx
â‰¤
sZ
1
1âˆ’Î³
0
|FÎ½1(x) âˆ’FÎ½2(x)|dx
=
p
W1(Î½1, Î½2).
And
Wp(Î½1, Î½2)
=
 
inf
ÎºâˆˆÎ“(Î½1,Î½2)
Z
[0,
1
1âˆ’Î³ ]
2 |x âˆ’y|p Îº(dx, dy)
!1/p
â‰¤
1
(1 âˆ’Î³)1âˆ’1
p
 
inf
ÎºâˆˆÎ“(Î½1,Î½2)
Z
[0,
1
1âˆ’Î³ ]
2 |x âˆ’y| Îº(dx, dy)
!1/p
=
1
(1 âˆ’Î³)1âˆ’1
p W
1
p
1 (Î½1, Î½2).
Lemma E.2.
 M, âˆ¥Â·âˆ¥â„“2

and
 M, âˆ¥Â·âˆ¥W1

are separable.
Proof. Recall that (P, W1) is separable [Theorem 6.18 Villani et al., 2009], and by Lemma E.1, the
CramÃ©r distance â„“2 can be bounded by 1-Wasserstein distance W1, hence (P, â„“2) is also separable.
Let d be either W1 or â„“2, and A be the countable dense subset of (P, d). For any Ç« > 0, Âµ âˆˆM,
we denote ËœÂµ :=
2Âµ
|Âµ|(R). Then we can ï¬nd a q âˆˆQ, Â¯Âµ+, Â¯Âµâˆ’âˆˆA, s.t.
q âˆ’1
2 |Âµ| (R)
 â‰¤
Ç«|Âµ|(R)
6âˆ¥Âµâˆ¥d ,
d(Â¯Âµ+, ËœÂµ+) â‰¤
Ç«
3q, d(Â¯Âµâˆ’, ËœÂµâˆ’) â‰¤
Ç«
3q. Note that the set of all possible Â¯Âµ = Â¯Âµ+ âˆ’Â¯Âµâˆ’is countable. Let
Ë†Âµ := qÂ¯Âµ, then we have
âˆ¥Âµ âˆ’Ë†Âµâˆ¥d
â‰¤âˆ¥Âµ âˆ’qËœÂµâˆ¥d + âˆ¥qËœÂµ âˆ’Ë†Âµâˆ¥d
=
(1
2 |Âµ| (R) âˆ’q)ËœÂµ

d
+ q âˆ¥(ËœÂµ+ âˆ’Â¯Âµ+) âˆ’(ËœÂµâˆ’âˆ’Â¯Âµâˆ’)âˆ¥d
â‰¤
q âˆ’1
2 |Âµ| (R)

2 âˆ¥Âµâˆ¥d
|Âµ| (R) + q âˆ¥ËœÂµ+ âˆ’Â¯Âµ+âˆ¥d + q âˆ¥ËœÂµâˆ’âˆ’Â¯Âµâˆ’âˆ¥d
â‰¤Ç« |Âµ| (R)
6 âˆ¥Âµâˆ¥d
2 âˆ¥Âµâˆ¥d
|Âµ| (R) + q Ç«
3q + q Ç«
3q
=Ç«.
Hence we have found a countable dense subset for (M, âˆ¥Â·âˆ¥d) for d = W1 or â„“2.
Therefore,
 M, âˆ¥Â·âˆ¥â„“2

and
 M, âˆ¥Â·âˆ¥W1

are separable.
30

Lemma E.3.
 M, âˆ¥Â·âˆ¥W1

is not complete.
Proof. Consider the Cauchy sequence in
 M, âˆ¥Â·âˆ¥W1

Âµn = Pn
i=1

Î´ 1
i + 1
2i âˆ’Î´ 1
i âˆ’1
2i

, which satis-
ï¬es âˆ¥Âµn âˆ’Âµn+kâˆ¥W1 â‰¤Pk
i=1
1
2n+iâˆ’1 â‰¤
1
2nâˆ’1 â†’0, but its limit Pâˆ
i=1

Î´ 1
i + 1
2i âˆ’Î´ 1
i âˆ’1
2i

/âˆˆM
because its total variation is inï¬nity. Hence, this is a Cauchy sequence without a limit, implying the
space is not complete.
Lemma E.4 (Range of Î·Ï€
t ). Suppose that Î±t âˆˆ[0, 1] for all t â‰¥0. Assume that Î·Ï€
0 âˆˆPS, then we
have, for all t â‰¥0, Î·Ï€
t âˆˆPS in the case of NTD. Similarly, assume that Î·Ï€
0 âˆˆPS
K, then we have,
for all t â‰¥0, Î·Ï€
t âˆˆPS
K in the case of CTD.
Proof. We will only prove the case of NTD, and the proof for CTD is similar by utilizing the property
of the projection operator Î K : PS â†’PS
K. We prove the result by induction. It is trivial that
Î·Ï€
t âˆˆPS for t = 0. Suppose that Î·Ï€
tâˆ’1 âˆˆPS, recall the updating scheme of NTD
Î·Ï€
t = (1 âˆ’Î±t)Î·Ï€
tâˆ’1 + Î±tT Ï€
t Î·Ï€
tâˆ’1.
(78)
It is evident that PS is a convex set, considering that PS is a subset of the product signed measure
space, which is a linear space. Therefore, we only need to show that T Ï€
t Î·Ï€
tâˆ’1 âˆˆPS, which trivially
holds since T Ï€
t is a random operator mapping from PS to PS, and Î·Ï€
tâˆ’1 âˆˆPS. By applying the
induction argument, we can arrive at the conclusion.
31

NeurIPS Paper Checklist
1. Claims
Question: Do the main claims made in the abstract and introduction accurately reï¬‚ect the
paperâ€™s contributions and scope?
Answer: [Yes]
Justiï¬cation: The main claims reï¬‚ect the paperâ€™s contributions and scope.
Guidelines:
â€¢ The answer NA means that the abstract and introduction do not include the claims
made in the paper.
â€¢ The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
â€¢ The claims made should match theoretical and experimental results, and reï¬‚ect how
much the results can be expected to generalize to other settings.
â€¢ It is ï¬ne to include aspirational goals as motivation as long as it is clear that these
goals are not attained by the paper.
2. Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justiï¬cation: The theoretical assumptions used in the paper are widely accepted and sup-
ported by a rich body of references in the literature, and the references are cited in our
paper.
Guidelines:
â€¢ The answer NA means that the paper has no limitation while the answer No means
that the paper has limitations, but those are not discussed in the paper.
â€¢ The authors are encouraged to create a separate "Limitations" section in their paper.
â€¢ The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-speciï¬cation, asymptotic approximations only holding locally). The au-
thors should reï¬‚ect on how these assumptions might be violated in practice and what
the implications would be.
â€¢ The authors should reï¬‚ect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
â€¢ The authors should reï¬‚ect on the factors that inï¬‚uence the performance of the ap-
proach. For example, a facial recognition algorithm may perform poorly when image
resolution is low or images are taken in low lighting. Or a speech-to-text system might
not be used reliably to provide closed captions for online lectures because it fails to
handle technical jargon.
â€¢ The authors should discuss the computational efï¬ciency of the proposed algorithms
and how they scale with dataset size.
â€¢ If applicable, the authors should discuss possible limitations of their approach to ad-
dress problems of privacy and fairness.
â€¢ While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that arenâ€™t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be speciï¬cally instructed to not penalize honesty concerning limitations.
3. Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
32

Answer: [Yes]
Justiï¬cation: Our paper provide the full set of assumptions and a self-contained proof.
Guidelines:
â€¢ The answer NA means that the paper does not include theoretical results.
â€¢ All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
â€¢ All assumptions should be clearly stated or referenced in the statement of any theo-
rems.
â€¢ The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a
short proof sketch to provide intuition.
â€¢ Inversely, any informal proof provided in the core of the paper should be comple-
mented by formal proofs provided in appendix or supplemental material.
â€¢ Theorems and Lemmas that the proof relies upon should be properly referenced.
4. Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main
experimental results of the paper to the extent that it affects the main claims and/or conclu-
sions of the paper (regardless of whether the code and data are provided or not)?
Answer: [NA]
Justiï¬cation: Given that our paper focuses on the theoretical analysis of existing popular
algorithms, it does not include experiments.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢ If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
â€¢ If the contribution is a dataset and/or model, the authors should describe the steps
taken to make their results reproducible or veriï¬able.
â€¢ Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture
fully might sufï¬ce, or if the contribution is a speciï¬c model and empirical evaluation,
it may be necessary to either make it possible for others to replicate the model with
the same dataset, or provide access to the model. In general. releasing code and data
is often one good way to accomplish this, but reproducibility can also be provided via
detailed instructions for how to replicate the results, access to a hosted model (e.g., in
the case of a large language model), releasing of a model checkpoint, or other means
that are appropriate to the research performed.
â€¢ While NeurIPS does not require releasing code, the conference does require all sub-
missions to provide some reasonable avenue for reproducibility, which may depend
on the nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear
how to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to re-
produce the model (e.g., with an open-source dataset or instructions for how to
construct the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case au-
thors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5. Open access to data and code
33

Question: Does the paper provide open access to the data and code, with sufï¬cient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [NA]
Justiï¬cation: Given that our paper focuses on the theoretical analysis of existing popular
algorithms, it does not include experiments.
Guidelines:
â€¢ The answer NA means that paper does not include experiments requiring code.
â€¢ Please
see
the
NeurIPS
code
and
data
submission
guidelines
(https://nips.cc/public/guides/CodeSubmissionPolicy)
for
more
de-
tails.
â€¢ While we encourage the release of code and data, we understand that this might not
be possible, so â€œNoâ€ is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
â€¢ The instructions should contain the exact command and environment needed to run
to reproduce the results.
See the NeurIPS code and data submission guidelines
(https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
â€¢ The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
â€¢ The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
â€¢ At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
â€¢ Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6. Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [NA]
Justiï¬cation: Given that our paper focuses on the theoretical analysis of existing popular
algorithms, it does not include experiments.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢ The experimental setting should be presented in the core of the paper to a level of
detail that is necessary to appreciate the results and make sense of them.
â€¢ The full details can be provided either with the code, in appendix, or as supplemental
material.
7. Experiment Statistical Signiï¬cance
Question: Does the paper report error bars suitably and correctly deï¬ned or other appropri-
ate information about the statistical signiï¬cance of the experiments?
Answer: [NA]
Justiï¬cation: Given that our paper focuses on the theoretical analysis of existing popular
algorithms, it does not include experiments.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢ The authors should answer "Yes" if the results are accompanied by error bars, conï¬-
dence intervals, or statistical signiï¬cance tests, at least for the experiments that support
the main claims of the paper.
34

â€¢ The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
â€¢ The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
â€¢ The assumptions made should be given (e.g., Normally distributed errors).
â€¢ It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
â€¢ It is OK to report 1-sigma error bars, but one should state it. The authors should prefer-
ably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of
Normality of errors is not veriï¬ed.
â€¢ For asymmetric distributions, the authors should be careful not to show in tables or
ï¬gures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
â€¢ If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding ï¬gures or tables in the text.
8. Experiments Compute Resources
Question: For each experiment, does the paper provide sufï¬cient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [NA]
Justiï¬cation: Given that our paper focuses on the theoretical analysis of existing popular
algorithms, it does not include experiments.
Guidelines:
â€¢ The answer NA means that the paper does not include experiments.
â€¢ The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
â€¢ The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
â€¢ The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments
that didnâ€™t make it into the paper).
9. Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
Answer: [Yes]
Justiï¬cation: The research conform with NeurIPS Code of Ethics.
Guidelines:
â€¢ The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
â€¢ If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
â€¢ The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10. Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justiï¬cation: Our paper only focuses on theory, hence there is no negative societal impact.
Guidelines:
â€¢ The answer NA means that there is no societal impact of the work performed.
35

â€¢ If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
â€¢ Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake proï¬les, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact spe-
ciï¬c groups), privacy considerations, and security considerations.
â€¢ The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
â€¢ The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
â€¢ If there are negative societal impacts, the authors could also discuss possible mitiga-
tion strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efï¬ciency and accessibility of ML).
11. Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justiï¬cation: Our paper only focuses on theory.
Guidelines:
â€¢ The answer NA means that the paper poses no such risks.
â€¢ Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by re-
quiring that users adhere to usage guidelines or restrictions to access the model or
implementing safety ï¬lters.
â€¢ Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
â€¢ We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12. Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justiï¬cation: The paper does not use existing assets.
Guidelines:
â€¢ The answer NA means that the paper does not use existing assets.
â€¢ The authors should cite the original paper that produced the code package or dataset.
â€¢ The authors should state which version of the asset is used and, if possible, include a
URL.
â€¢ The name of the license (e.g., CC-BY 4.0) should be included for each asset.
â€¢ For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
36

â€¢ If assets are released, the license, copyright information, and terms of use in the pack-
age should be provided. For popular datasets, paperswithcode.com/datasets has
curated licenses for some datasets. Their licensing guide can help determine the li-
cense of a dataset.
â€¢ For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
â€¢ If this information is not available online, the authors are encouraged to reach out to
the assetâ€™s creators.
13. New Assets
Question: Are new assets introduced in the paper well documented and is the documenta-
tion provided alongside the assets?
Answer: [NA]
Justiï¬cation: The paper does not release new assets.
Guidelines:
â€¢ The answer NA means that the paper does not release new assets.
â€¢ Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
â€¢ The paper should discuss whether and how consent was obtained from people whose
asset is used.
â€¢ At submission time, remember to anonymize your assets (if applicable). You can
either create an anonymized URL or include an anonymized zip ï¬le.
14. Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the pa-
per include the full text of instructions given to participants and screenshots, if applicable,
as well as details about compensation (if any)?
Answer: [NA]
Justiï¬cation: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
â€¢ The answer NA means that the paper does not involve crowdsourcing nor research
with human subjects.
â€¢ Including this information in the supplemental material is ï¬ne, but if the main contri-
bution of the paper involves human subjects, then as much detail as possible should
be included in the main paper.
â€¢ According to the NeurIPS Code of Ethics, workers involved in data collection, cura-
tion, or other labor should be paid at least the minimum wage in the country of the
data collector.
15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justiï¬cation: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
â€¢ The answer NA means that the paper does not involve crowdsourcing nor research
with human subjects.
â€¢ Depending on the country in which research is conducted, IRB approval (or equiva-
lent) may be required for any human subjects research. If you obtained IRB approval,
you should clearly state this in the paper.
37

â€¢ We recognize that the procedures for this may vary signiï¬cantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
â€¢ For initial submissions, do not include any information that would break anonymity
(if applicable), such as the institution conducting the review.
38

